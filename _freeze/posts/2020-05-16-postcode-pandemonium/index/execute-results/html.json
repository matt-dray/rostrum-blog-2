{
  "hash": "ea7976d9b4e8af3bff094c9afb71c880",
  "result": {
    "markdown": "---\ntitle: Postcode pandemonium with {data.table}\nauthor: Matt Dray\ndate: 2020-05-16\nslug: postcode-pandemonium\ncategories:\n  - data.table\n  - geospatial\n  - r\n  - tictoc\n---\n\n\n\n\n![Postcodes in Bath are unlikely to score highly (via Wikimedia)](resources/600px-BA_postcode_area_map.svg.png){fig-alt=\"A map of the BA postcode area around Bath, UK.\" width=\"100%\"}\n\n## tl;dr\n\nI used the R package {data.table} to find the highest- and lowest-scoring UK postcodes based on the sum of their numbers and letters (A = 1, B = 2, etc). You can [jump to the results](#results).\n\n## The premise\n\nYesterday I noticed that the hashtag #PostcodePandemonium was trending on Twitter.[^tweet] The premise was to sum the numbers and letters in your [postcode](https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom), where the letters have been converted to their position in the alphabet (i.e. A = 1, B = 2, etc). Highest value 'wins'.\n\nWhich existing postcode has the highest score? And the lowest?\n\n## Process\n\n### Attach packages\n\nI've been using Matt Dowle and Arun Srinivasan's [lightning-fast {data.table} package](https://rdatatable.gitlab.io/data.table/) recently and wanted to use it here to handle millions of UK postcodes. I've prioritised for readability in this post rather than efficiency, but let me know how to improve things.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(data.table)  # a better data.frame\n  library(stringr)     # simple string handling\n  library(tictoc)      # timing\n})\n```\n:::\n\n\nI'm using Sergei Izrailev's [{tictoc} package](http://collectivemedia.github.io/tictoc/) to time the processes throughout.\n\n### Get the data\n\nThe latest postcode data (February 2020) is available on [the Open Geography Portal by the Office for National Statistics](https://geoportal.statistics.gov.uk/datasets/national-statistics-postcode-lookup-february-2020). From there you can download a zipped folder that contains the file we want, `NSPL_FEB_2020_UK.csv`.\n\n<div class=\"tip\"> \n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M256 512A256 256 0 1 0 256 0a256 256 0 1 0 0 512zm0-384c13.3 0 24 10.7 24 24V264c0 13.3-10.7 24-24 24s-24-10.7-24-24V152c0-13.3 10.7-24 24-24zM224 352a32 32 0 1 1 64 0 32 32 0 1 1 -64 0z\"/></svg>`{=html} <b>Note</b>\n\nI re-rendered this post in July 2023 and the link to the February 2020 postcode file no longer works. Instead, we'll use the latest at time of writing: [February 2023](https://geoportal.statistics.gov.uk/datasets/national-statistics-postcode-lookup-2021-census-february-2023/about).\n</div><P>\n\nFirst, you can download the .zip to a temporary location on your machine. The file is pretty large (about 180 MB), so I'm increasing the timeout value for `download.file()` so that the download has time to complete. You might want to consider downloading the file to your local computer and reading it from there.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# URL to postcode zip file\nzip_url <- paste0(\n  \"https://www.arcgis.com/\",\n  \"sharing/rest/content/items/\",\n  \"c7debafcef564e7a9dfb8ca881be4253/data\"\n)\n\n# Setup a temporary folder to download into\ntmp <- tempdir()\nzip_path <- file.path(tmp, \"postcodes.zip\")\n\n# Download the zip file to the tempporary location\noptions(timeout = max(1000, getOption(\"timeout\")))\ndownload.file(zip_url, zip_path)\n```\n:::\n\n\nYou can then `unzip()` the CSV file inside {data.table}'s `fread()` for a rapid read.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic(\"CSV read complete\")\npcodes_dt <- fread(unzip(zip_path, files = \"Data/NSPL21_FEB_2023_UK.csv\"))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCSV read complete: 10.482 sec elapsed\n```\n:::\n\n```{.r .cell-code}\nunlink(tmp)  # remove temp location\n```\n:::\n\n\nAnd we can check the dimensions of this object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rows and columns in the data set\ndim(pcodes_dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2687274      41\n```\n:::\n:::\n\n\nSo there's more than 2.5 million rows. Some postcodes have, however, been terminated over time. We'll need to filter for the postcodes that are still active (thanks to [Robert Kaleta](https://twitter.com/RobertKaleta/status/1261733628461146113) for pointing this out). \n\nWe can also simplify to just the postcode column that we want using {data.table}'s `.()` notation. Data in the `pcds` column has the consistent form of letter, letter, digit, space, digit, letter, letter (e.g. 'AB12 3CD'), which makes them relatively easy to deal with.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for empty date of termination (doterm)\n# Retain only the postcode column\npcodes_dt <- pcodes_dt[is.na(doterm), .(pcds)]\n\nhead(pcodes_dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       pcds\n1: AB10 1AB\n2: AB10 1AF\n3: AB10 1AG\n4: AB10 1AH\n5: AB10 1AL\n6: AB10 1AN\n```\n:::\n\n```{.r .cell-code}\nnrow(pcodes_dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1793019\n```\n:::\n:::\n\n\nYou can see that this removes a large number of terminated postcodes.\n\n### Extract\n\nNow to extract the numbers and letters so that 'AB12 3CD' is broken into A, B, 12, 3, C and D, for example. Note that we want to extract multi-digit numbers if they exist within each half (the 'outward' and 'inward' parts) of the postcode, so 12 rather than 1 and 2, and 12 and 3 rather than 123.\n\nThe walrus operator (`:=`) is used here as a function to create new columns and assign names to them. I've chose to use {stringr}'s `str_extract_all()` function to match the strings we want. The regular expression contains values in the curly braces to indicate the desired character lengths to be matched.\n\nThis will produce two list-columns: one with the letters extracted into it and one with the numbers. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract letters into one list column and numbers into another\npcodes_dt[, `:=`(letter = str_extract_all(pcds, \"[:alpha:]{1}\"),\n                 number = str_extract_all(pcds, \"[:digit:]{1,2}\"))]\n\npcodes_dt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             pcds  letter number\n      1: AB10 1AB A,B,A,B   10,1\n      2: AB10 1AF A,B,A,F   10,1\n      3: AB10 1AG A,B,A,G   10,1\n      4: AB10 1AH A,B,A,H   10,1\n      5: AB10 1AL A,B,A,L   10,1\n     ---                        \n1793015:  ZE3 9JU Z,E,J,U    3,9\n1793016:  ZE3 9JW Z,E,J,W    3,9\n1793017:  ZE3 9JX Z,E,J,X    3,9\n1793018:  ZE3 9JY Z,E,J,Y    3,9\n1793019:  ZE3 9JZ Z,E,J,Z    3,9\n```\n:::\n:::\n\n\nRemember that {data.table} edits in place, so the `pcodes_dt` object will be updated and without the need to overwrite it (i.e. no need to do something like `pcodes_dt <- pcodes_dt[<whatever>]`).\n\n### Numbers and letters\n\nNow to work with the `number` list-column. The values are currently character-class because they were extracted from the postcode strings; they need to be made numeric before they can be summed. `lapply()` is used here to pass the function `as.numeric()` to achieve this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic(\"Make numbers numeric class\")\npcodes_dt[, number := lapply(number, as.numeric)]\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMake numbers numeric class: 4.502 sec elapsed\n```\n:::\n:::\n\n\nAnd now to work with the `letter` list column. The custom function in `lapply()` first turns the letters into the factor class, where the full set of possible levels is provided by the `LETTERS` vector, and then uses `as.numeric()` to convert each factor level to its corresponding numeric value.\n\nThis works on the principle that `as.numeric(factor(c(\"A\", \"B\", \"C\")))` becomes `c(1, 2, 3)`. The first factor level, `A` gets converted to 1, `B` to 2 and so on. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic(\"Convert letters to numbers, make numeric class\")\npcodes_dt[, letter_number := lapply(\n  letter, function(x) as.numeric(factor(x, levels = LETTERS)))]\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConvert letters to numbers, make numeric class: 11.431 sec elapsed\n```\n:::\n:::\n\n\n### Scores\n\nNow to separately sum the number and letter values in each row of the list-columns and add them together for the final score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate summation columns for letters and numbers separately\npcodes_dt[, `:=`(number_sum = lapply(number, sum),\n                 letter_sum = lapply(letter_number, sum))]\n\n# Make the sum columns numeric- rather than list-class\npcodes_dt$number_sum <- as.numeric(pcodes_dt$number_sum)\npcodes_dt$letter_sum <- as.numeric(pcodes_dt$letter_sum)\n\n# Sum the number and letter values\npcodes_dt[, score := number_sum + letter_sum]\n\n# The first few scores\nhead(pcodes_dt[, .(pcds, number_sum, letter_sum, score)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       pcds number_sum letter_sum score\n1: AB10 1AB         11          6    17\n2: AB10 1AF         11         10    21\n3: AB10 1AG         11         11    22\n4: AB10 1AH         11         12    23\n5: AB10 1AL         11         16    27\n6: AB10 1AN         11         18    29\n```\n:::\n:::\n\n\nSo you can see, for example, that AB10 1AB has a number sum of 11 (10 + 1) and a letter sum of 6 (a couple of As and Bs, so 1 + 2 + 1 + 2), totalling 17.\n\n## Results {#results}\n\nNow to order the results, focus on the postcodes and scores alone, and preview the top and bottom scores (provided by default in {data.table}'s print method).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select cols and reorder by score\npcodes_dt[order(-score), .(pcds, score)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             pcds score\n      1: WV99 1ZZ   197\n      2: WV98 1ZZ   196\n      3: WV99 1YZ   196\n      4: WV99 1ZY   196\n      5: SS99 9YX   195\n     ---               \n1793015:   B1 2AA     7\n1793016:  BA1 0BA     7\n1793017:  BA1 1AA     7\n1793018:  BA2 0AA     7\n1793019:  BA1 0AA     6\n```\n:::\n:::\n\n\nSo the top-scoring postcode was WV99 1ZZ with 197 points. It's on an industrial estate in Telford, north-east of Birmingham. You can [view it on Google Maps](https://goo.gl/maps/574KB3wmc6wy9Rms6).\n\nThe lowest scoring postcodes were in Birmingham (Holloway Circus at [B1 1BA](https://goo.gl/maps/ZM7p9ZjFWXBc4nt6A) and Arena Birmingham at [B1 2AA](https://goo.gl/maps/yPgYP74uP3AqMtCa7)) and Bath (near Bath Spa train station at [BA1 1AA](https://goo.gl/maps/eD5jL7dbeb8sAkZf9) and south of Farmborough at [BA2 0AA](https://goo.gl/maps/DN2ZAm1AJAz2oq329)). They scored only 7.\n\nThe distribution of scores looks like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(\n  pcodes_dt$score,\n  xlab = \"Score\",\n  main = \"Histogram of postcode scores\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nIt's slightly skewed, with nearly 350,000 instances of scores between 60 and 70 and very few scores over 150.\n\nLet's check out the summary statistics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(pcodes_dt$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   6.00   54.00   67.00   68.86   81.00  197.00 \n```\n:::\n:::\n\n\nSo the mean score is just under 70.\n\nHow does your score compare?\n\n!['WV' provides 23 + 22 = 45 points in itself (via Wikimedia)](resources/500px-WV_postcode_area_map.svg.png){fig-alt=\"A map of the WV postcode area around Wolverhampton\" width=\"100%\"}\n\n## Environment {.appendix}\n\n<details><summary>Session info</summary>\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nLast rendered: 2023-07-20 20:36:47 BST\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tictoc_1.2        stringr_1.5.0     data.table_1.14.8\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    glue_1.6.2        knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3      \n[13] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[17] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[21] stringi_1.7.12   \n```\n:::\n:::\n\n</details>\n\n[^tweet]: It originated from the social media team at a company controlled by one of the largest corporations in the world, so I don't think it's cynical to say that the whole thing was a marketing ploy.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}