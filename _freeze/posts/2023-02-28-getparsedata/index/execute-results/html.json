{
  "hash": "4932fce86f3c8267860215167c369fdd",
  "result": {
    "markdown": "---\ntitle: I can't be parsed, mate\ndate: 2023-03-03\nslug: getparsedata\ncategories:\n  - lobstr\n  - r\n---\n\n\n![Image by <a href=\"https://pixabay.com/users/keithjj-2328014/\">Keith Johnston</a> from <a href=\"https://pixabay.com\">Pixabay</a>. Deep fried by Matt Dray.[^fry]](resources/handegg.png){fig-alt=\"An American football quarterback about to pass the ball. He has the R logo on his shirt. Text above says 'pass the ball', text below is R code reading 'parse(text = 'the('ball')')'. The format is a 'deep-fried', highly pixellated meme where the centre of the iumage bloats out. A wide-eyed, smiling and crying emoji is in the corner.\" width=\"100%\"}\n\n## tl;dr\n\nR is capable of reading R code. Obviously. You can use `getParseData(parse())` to see what's going on. A very naive intro.\n\n## At an imparse\n\nThere's many things that delight me about R coding.[^train] One meta thing I like is the idea that R has to recognise the code that you give it as... R code.\n\nFor example, does `x<-1` mean 'x is less than minus-one'? Hm, actually R recognises `<-` as a 'left-assignment operator'‚Äîa special 'token'‚Äîthat gives the name `x` the value of `1`. Subtle, but important.\n\nAnother example: the tokens `<-` and `=` have an equivalent role in `x <- 1` and `x = 1`. For style reasons, you'll probably want to replace `=` with `<-`.[^down] But don't just 'find and replace' because `=` is context dependent. Consider:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = subset(mtcars, subset = carb == 8)\n```\n:::\n\n\nHere, `=` is used to assign (`=`), to set a function argument (`=`) and as part of the equivalence operator (`==`). Oof.\n\nHow can a mere human understand this better?\n\n## Parsed tense\n\nThe cool ('cool') thing is that R gives you tools to be able to see the world as R sees it. \n\nThis is sometimes called 'static code analysis', in that you can interrogate the code for syntax errors _before_ it executes. Packages like [{lintr}](https://lintr.r-lib.org/) can even help tidy up ('lint') your code by adjusting or replacing the tokens.[^renkun]\n\nI've used this approach before to:\n\n* [create the {r2eng} package](https://www.rostrum.blog/2020/11/14/hello-r2eng/), which matches tokens against words so an expression can be translated to English (e.g. `<-` is matched to the word 'gets')\n* [write an RStudio addin that auto-labels closing parentheses](https://www.rostrum.blog/2021/08/31/add-biscuits/) with the name of the function they belong to (known cutely as a 'biscuit')\n* [identify and destroy files that contain equals assignment](https://www.rostrum.blog/2021/03/13/assign/) (`x = 1`), rather than the superior assignment arrow (`x <- 1`)\n\nHow might you tinker about with this yourself? Read on for a quickstart.\n\n## Parse the parcel\n\nI'll talk about two main functions: `parse()` and `getParseData()`, which are both part of base R.\n\nYou can pass a string of R code to `parse()` for it to be recognised as an 'expression'. Let's use the equals-rich `subset()` example from above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncode_str <- \"x = subset(mtcars, subset = carb == 8)\"\ncode_expr <- parse(text = code_str)\ncode_expr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nexpression(x = subset(mtcars, subset = carb == 8))\n```\n:::\n\n```{.r .cell-code}\nclass(code_expr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"expression\"\n```\n:::\n:::\n\n\nSo the string is recognised as R code at this point, which will allow us to break it down into its individual tokens. You could jump ahead here and just `eval()`uate this expression object. \n\n\n::: {.cell}\n\n```{.r .cell-code}\neval(code_expr)\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              mpg cyl disp  hp drat   wt qsec vs am gear carb\nMaserati Bora  15   8  301 335 3.54 3.57 14.6  0  1    5    8\n```\n:::\n:::\n\n\nAs a result, the dataframe `x` is now in our environment and, as expected, contains only rows of the `mtcars` that have 8 `carb`uretors.[^carb]\n\nSo we have the power to delay code execution, like some kind of wizard. Jeepers! That's great, but now lets pick apart the frozen expression into its constituent tokens. This is where `getParseData()` comes in.\n\nThe function takes an expression object as the input and returns a dataframe with one token per row and several columns of handy information related to positioning and the relatedness between the tokens.\n\nFor now I'm going to simplify the output to show only the units of `text` that have been recognised as tokens, along with the name that R gives to each `token` under the hood (e.g. `<-` is recognised as `LEFT_ASSIGN`).[^tokens]\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncode_parsed <- getParseData(parse(text = code_str, keep.source = TRUE))\ncode_parsed[code_parsed$text != \"\", c(\"text\", \"token\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     text                token\n1       x               SYMBOL\n2       =            EQ_ASSIGN\n5  subset SYMBOL_FUNCTION_CALL\n6       (                  '('\n8  mtcars               SYMBOL\n9       ,                  ','\n14 subset           SYMBOL_SUB\n15      =               EQ_SUB\n16   carb               SYMBOL\n17     ==                   EQ\n19      8            NUM_CONST\n21      )                  ')'\n```\n:::\n:::\n\n\nOh neato, so you can see `=` is indeed recognised as the token `EQ_ASSIGN` ('equals assign'), `=` as `EQ_SUB` (equals in the context of supplying function arguments) and `==` as in `EQ` (the equivalence operator).\n\nIf you're wondering, the `keep.source = TRUE` bit was needed to encourage `parse()` to return its output, which is a necessary step within this non-interactive blog post.\n\n## Parseltongue\n\nWant to take a look at the tokens in a given string of R code yourself? You can use this little function that contains `parse()` and `getParseData()` and returns you the simplified dataframe I showed above if `simplify = TRUE`, otherwise it gives the full read out.[^ex] \n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_out <- function(string, simplify = TRUE) {\n  p <- parse(text = string, keep.source = TRUE)\n  pd <- getParseData(p)\n  if (simplify) {\n    keep_cols <- c(\"token\", \"text\")\n    pd <- pd[pd$text != \"\", keep_cols]\n  }\n  pd\n}\n```\n:::\n\n\nSo you could use it like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_out(\n  \"mean(CO2[CO2$Plant == 'Qn1', CO2$uptake]) -> mean_uptake\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  token        text\n1  SYMBOL_FUNCTION_CALL        mean\n2                   '('           (\n4                SYMBOL         CO2\n5                   '['           [\n7                SYMBOL         CO2\n8                   '$'           $\n10               SYMBOL       Plant\n12                   EQ          ==\n13            STR_CONST       'Qn1'\n14                  ','           ,\n20               SYMBOL         CO2\n21                  '$'           $\n23               SYMBOL      uptake\n25                  ']'           ]\n30                  ')'           )\n35         RIGHT_ASSIGN          ->\n36               SYMBOL mean_uptake\n```\n:::\n:::\n\n\n<div class=\"tip\"> ‚ÑπÔ∏è <b>Update</b>\n\nSince I wrote this post, it's become possible to [include editable R blocks in a rendered Quarto document](https://github.com/coatless/quarto-webr), which can be run in the browser thanks to [WebR](https://docs.r-wasm.org/webr/latest/)(!). [I've made a quick demo](https://webr-parse-test.netlify.app/) and [post](https://www.rostrum.blog/2023/03/16/webr-quarto/) so you can play around with a simplified version of the parsing function above.\n\n</div>\n\n## Lateral parse\n\nI'll leave you with another interesting thing that shows you the inner workings of R, which you might not realise as you run your code. We can look at how the code is actually executed, not just the tokens that it's composed of.\n\nConsider how the {magrittr} pipe `%>%` is used. Here I've slightly adjusted the input to filter for 6 and 8 `carb`uretors; you'll see why in a second.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_out(\"mtcars %>% subset(carb %in% c(6, 8))\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  token   text\n1                SYMBOL mtcars\n2               SPECIAL    %>%\n4  SYMBOL_FUNCTION_CALL subset\n5                   '('      (\n7                SYMBOL   carb\n8               SPECIAL   %in%\n10 SYMBOL_FUNCTION_CALL      c\n11                  '('      (\n13            NUM_CONST      6\n15                  ','      ,\n19            NUM_CONST      8\n21                  ')'      )\n26                  ')'      )\n```\n:::\n:::\n\n\nOkay yeah, `%>%` is recognised as a token called `SPECIAL` between the left-hand side of `mtcars` and the right-hand side of `subset(carb %in% c(6, 8))`. Notice also that `%in%` is also recognised as `SPECIAL`. \n\nIn fact, this is how R recognises ['infix operators'](https://adv-r.hadley.nz/functions.html?q=infix%20operator#infix-functions) that are bound by percent symbols. This is some special syntactical magic that lets you put the function name _between_ two arguments. So `x %>% head` is equivalent to `` `%>%`(mtcars, head) ``. Perhaps `SPECIAL` instead of a more specific name because infix operators can be created on the fly?\n\nIf `%>%` is `SPECIAL`, how do you think the base pipe is recognised in this simpler example?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparse_out(\"mtcars |> head()\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 token   text\n1               SYMBOL mtcars\n2                 PIPE     |>\n4 SYMBOL_FUNCTION_CALL   head\n5                  '('      (\n7                  ')'      )\n```\n:::\n:::\n\n\nNot that surprising: it's recognised as `PIPE` and not a `SPECIAL`, since it's a proper base R token in its own right ([as of R v4.1](https://www.rostrum.blog/2022/06/01/try-r/)) .\n\nOkay, so we've seen how R parses these tokens, what about how it actually executes the code? One way to see this is to look at an 'abstract syntax tree' with [the {lobstr} package](https://lobstr.r-lib.org/).[^lobstr] A 'tree' to show the nested structure of code and variables and so on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)    # install from CRAN\nlibrary(magrittr)  # install from CRAN\nast(mtcars %>% head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚ñà‚îÄ`%>%` \n‚îú‚îÄmtcars \n‚îî‚îÄ‚ñà‚îÄhead \n```\n:::\n:::\n\n\nYeah, like I said: `x %>% head()` is ultimately executed by R like a normal function (block symbol in the output from `ast()` above), in the form `` `%>%`(mtcars, head) ``. You can see how the `` `%>%` `` is a parent to `mtcars` and `head()` below it.\n\nSo the same happens for the base pipe, right?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nast(mtcars |> head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚ñà‚îÄhead \n‚îî‚îÄmtcars \n```\n:::\n:::\n\n\nSurprise! `mtcars |> head` is not executed like `` `|>`(mtcars, head) ``. It's literally executed like `head(mtcars)`. The base pipe is so special because it's baked right into the R source code as a separate type of token that is recognised to have a job distinct from a basic `SPECIAL`. This should make it a little faster to run compared to `%>%` as well.\n\n## Parse away\n\nWell, 'cool' I guess. Now it's up to you: you can either parse on this knowledge, or leave it in the parsed.[^end]\n\n## Environment {.appendix}\n\n<details><summary>Session info</summary>\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nLast rendered: 2023-06-29 18:17:50 CEST\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 lobstr_1.1.2  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         knitr_1.43.1     \n [5] htmltools_0.5.5   rmarkdown_2.22    cli_3.6.1         compiler_4.3.1   \n [9] rstudioapi_0.14   tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[13] rlang_1.1.1       jsonlite_1.8.5    crayon_1.5.2      htmlwidgets_1.6.2\n```\n:::\n:::\n\n</details>\n\n[^fry]: You too [can use R to deep fry a meme](https://www.rostrum.blog/2021/11/07/deepfry/).\n[^train]: Things that I'm sure are quite trivial to gatekeepers. I learnt minimal amounts of R to help me wrangle ecological data and 'do statistics'. I'm not a computer scientist, nor was I trained as a programmer. \n[^down]: Of course, I'm not mentioning right assignment (`->`) here, nor the plucky upstart of [down-asignment](https://www.rostrum.blog/2022/06/07/assign-down/), which is certain to be the future for assignment in R.\n[^tokens]: You can [see a list of these with English translations](https://github.com/wch/r-source/blob/0ee550ff68f22b8a1807377e728f99f2775cc43c/src/main/gram.y#L2312-L2350) in Winston Chang's GitHub copy of R's source code. So `NUM_CONST` is 'numeric constant', for example.\n[^carb]: Not `carb`ohydrates. 'Non-car people' should take a look at the 'Format' section of `?mtcars`. I mean, `drat` means 'rear axle ratio', what?\n[^lobstr]: A package with one of my favourite names and [hex logos](https://lobstr.r-lib.org/logo.png). The 'str' is from 'structure', as in 'the structure of code'. The logo is a lobster snipping apart the 'lob' from 'str' text. I mean, \\*(lobster) chef's kiss\\* on that one. ü¶û\n[^end]: Yeah, I'm hoping you didn't read this far. Obviously I didn't know how to end the post, sorry.\n[^ex]: An exercise for the reader is to alter this function to accept an R script file rather than a string (hint: `parse()` takes a `file` argument).\n[^renkun]: You may also enjoy [a post by Kun Ren](https://renkun.me/2020/11/08/using-parse-data-to-analyze-r-code/) about how this approach is useful for static analysis in [the {languageserver} package](https://github.com/REditorSupport/languageserver), which is a handy download for using R in VS Code.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}