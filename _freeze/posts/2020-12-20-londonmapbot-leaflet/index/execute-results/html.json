{
  "hash": "faaf1bac1519e81d833de7fd649c847b",
  "result": {
    "markdown": "---\ntitle: Mapping londonmapbot tweets with {leaflet}\ndate: 2020-12-20\nslug: londonmapbot-leaflet\ncategories:\n  - geospatial\n  - leaflet\n  - PostcodesioR\n  - r\n  - rtweet\n  - sf\n  - twitter\n---\n\n::: {.cell}\n\n:::\n\n\n![Closest I've been to Leicester Square since the start of lockdown.](resources/leicester-square.png){fig-alt=\"Screenshot of a leaflet map showing Leicester Square, London, with a popup giving geographic information and a satellite view.\" width=\"100%\"}\n\n## tl;dr\n\nI recently [made a Twitter bot with R, {rtweet}, MapBox and GitHub Actions](https://www.rostrum.blog/2020/09/21/londonmapbot/) -- [londonmapbot](https://twitter.com/londonmapbot) -- that tweets images of random coordinates in London. I decided to explore them interactively by creating a simple [{leaflet}](https://rstudio.github.io/leaflet/) map. You can [jump directly to the map](#map)).\n\n<div class=\"tip\">\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M256 512A256 256 0 1 0 256 0a256 256 0 1 0 0 512zm0-384c13.3 0 24 10.7 24 24V264c0 13.3-10.7 24-24 24s-24-10.7-24-24V152c0-13.3 10.7-24 24-24zM224 352a32 32 0 1 1 64 0 32 32 0 1 1 -64 0z\"/></svg>`{=html} <b>Note</b>\n\nTwitter changed its API terms in 2023. As a result, you probably can't re-run the code in this blog. [Read about](https://www.rostrum.blog/2023/02/09/londonmapbotstodon/) how I moved londonmapbot to Mastodon at [botsin.space/@londonmapbot](https://botsin.space/@londonmapbot) because of these changes.\n</div>\n\n## The bot\n\nI built [the londonmapbot Twitter bot](https://www.twitter.com/londonmapbot/) as a fun little project to get to grips with [GitHub Actions](https://github.com/features/actions). An action is scheduled every 30 minutes to run some R code that (1) selects random coordinates in London, (2) fetches a satellite image from [the MapBox API](https://docs.mapbox.com/api/overview/), (3) generates an [OpenStreetMap](https://www.openstreetmap.org/) URL, all of which are (4) passed to [{rtweet}](https://docs.ropensci.org/rtweet/) to post to the londonmapbot account.\n\nThe outputs have been compelling so far. The composition is usually 'accidentally' pleasing. Sometimes landmarks are captured, like [The Shard](https://twitter.com/londonmapbot/status/1334220239467376643?s=20), [The Natural History Museum and V&A](https://twitter.com/londonmapbot/status/1333173374332395522?s=20) and [Heathrow](https://twitter.com/londonmapbot/status/1333702486545354752?s=20). \n\n![The Shard looks pointy even in 2D.](resources/shard.png){fig-alt=\"Screenshot of a tweet by londonmapbot showing a satellite view of the area round London Bridge Station and The Shard.\" width=\"100%\"}\n\nI was wondering whether the bot has 'found' other landmarks that I hadn't noticed or whether it's found my house. [The londonmapbot source code](https://github.com/matt-dray/londonmapbot) doesn't have a log file for all the coordinates it's generated, so I figured the easiest way to get this information and explore it would be to grab all the tweets -- which contain the coordinates as text -- and then map the results.\n\n## Packages\n\nI'm loading [the tidyverse](https://www.tidyverse.org/) for data manipulation with {dplyr}, {tidyr} and {stringr}. [{rtweet}](https://docs.ropensci.org/rtweet/) greatly simplifies the Twitter API and the objects it returns. We'll use it to fetch all the tweets from londonmapbot.\n\nI'm using a few geography-related packages: \n\n* [{sf}](https://r-spatial.github.io/sf/) for tidy dataframes with spatial information\n* [{geojsonio}](https://docs.ropensci.org/geojsonio/) to read spatial files in geojson format\n* [{PostcodesioR}](https://docs.ropensci.org/PostcodesioR/) to fetch additional geographic data given our x-y information\n* [{leaflet}](https://rstudio.github.io/leaflet/) to build interactive maps from spatial data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(rtweet)\n  library(sf)\n  library(geojsonio)\n  library(PostcodesioR)\n  library(leaflet)\n})\n```\n:::\n\n\nA particular shoutout to [rOpenSci](https://ropensci.org/) for this post: {rtweet}, {geojsonio} and {PostcodesioR} have all passed muster to become part of the rOpenSci suite of approved packages.\n\n## Fetch tweets\n\n{rtweet} does all the legwork to fetch and parse information from the Twitter API, saving you loads of effort.\n\nThe `rtweet::get_timeline()` function is amazing in its user-side simplicity. Pass the account name from which to fetch tweets, along with the number of tweets to get (3200 is the maximum). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_tweets <- get_timeline(\"londonmapbot\", n = 3200)\nlmb_tweets[1:5, c(\"created_at\", \"text\")]  # limited preview\n```\n:::\n\n```\n# A tibble: 5 x 2\n  created_at          text                                                      \n  <dttm>              <chr>                                                     \n1 2020-12-29 09:36:20 \"51.5519, -0.33\\nhttps://t.co/ica9ZypBLS https://t.co/5gS…\n2 2020-12-29 08:59:46 \"51.4392, 0.1636\\nhttps://t.co/2DsbbLYIDG https://t.co/KV…\n3 2020-12-29 06:28:48 \"51.6773, -0.2555\\nhttps://t.co/1hu2VoxCBF https://t.co/b…\n4 2020-12-29 05:56:15 \"51.674, -0.4042\\nhttps://t.co/HMhmUVVrIn https://t.co/mP…\n5 2020-12-29 05:31:03 \"51.4451, 0.1058\\nhttps://t.co/nWuqy4s7am https://t.co/qv…\n```\n\n{rtweet} has a function to quick-plot tweets over time. There's meant to be a tweet every half-hour from londonmapbot, but GitHub Actions has been a little inconsistent and sometimes fails to post.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrtweet::ts_plot(lmb_tweets) +  # plot daily tweets\n  labs(\n    title = \"@londonmapbot tweets per day\",\n    x = \"\", y = \"\", caption = \"Data collected via {rtweet}\"\n  )\n```\n:::\n\n![](resources/ts-plot-1.png){fig-alt=\"Tweet volume from the londonmapbot account between September and December 2020. The amount is inconsistent and is about 25 to 40 tweets per day.\" width=\"100%\"}\n\n## Extract tweet information\n\nThe dataframe returned by {rtweet} contains nearly 100 columns. For our purposes we can minimise to:\n\n* the unique tweet identifier, `status_id`, which we can use to build a URL back to the tweet\n* the datetime the tweet was `created_at`\n* the tweet text content, from which we can isolate the latitude and longitude values\n* the `media_url` to the MapBox image attached to each tweet\n* the full OpenStreetMap link in each tweet via `urls_expanded_urls` \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_simple <- lmb_tweets %>% \n  filter(str_detect(text, \"^\\\\d\")) %>%  # must start with a digit\n  separate(  # break column into new columns given separator\n    text,  # column to separate\n    into = c(\"lat\", \"lon\"),  # names to split into\n    sep = \"\\\\s\",  # separate on spaces\n    extra = \"drop\" # discard split elements\n  ) %>% \n  mutate(  # tidy up variables \n    lat = str_remove(lat, \",\"),\n    across(c(lat, lon), as.numeric)\n  ) %>% \n  select(  # focus variables\n    status_id, created_at, lat, lon,\n    osm_url = urls_expanded_url, media_url\n  )\n\nlmb_simple[1:5, c(\"status_id\", \"lat\", \"lon\")]  # limited preview\n```\n:::\n\n```\n# A tibble: 5 x 3\n  status_id             lat    lon\n  <chr>               <dbl>  <dbl>\n1 1343853346478841862  51.6 -0.33 \n2 1343844145518026752  51.4  0.164\n3 1343806154397409280  51.7 -0.256\n4 1343797964645523456  51.7 -0.404\n5 1343791619049480192  51.4  0.106\n```\n\n## Reverse geocode\n\nTweets from londonmapbot are really simple by design; they only have the latitude and longitude, a link to OpenStreetMap and a satellite image pulled from [the MapBox API](https://docs.mapbox.com/api/overview/). It might be interesting to provide additional geographic information.\n\n{PostcodesioR} can perform a 'reverse geocode'[^wrassle] of our coordinates. Give latitude and longitude to `PostcodesioR::reverse_geocoding()` and it returns a list with various administrative geographies for that point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_geocode <-  lmb_simple %>% \n  mutate(\n    reverse_geocode = map2(\n      .x = lon, .y = lat,\n      ~reverse_geocoding(.x, .y, limit = 1)  # limit to first result\n    )\n  ) %>% \n  unnest(cols = reverse_geocode) %>%  # unpack listcol\n  hoist(reverse_geocode, \"postcode\") %>%  # pull out postcode into a \n  hoist(reverse_geocode, \"admin_district\") # pull out borough\n\nlmb_geocode[1:5, c(\"lat\", \"lon\", \"postcode\", \"admin_district\")]  # limited preview\n```\n:::\n\n```\n# A tibble: 5 x 4\n    lat    lon postcode admin_district\n  <dbl>  <dbl> <chr>    <chr>         \n1  51.6 -0.33  UB6 7QT  Ealing        \n2  51.4  0.164 DA5 2DJ  Bexley        \n3  51.7 -0.256 WD6 5PL  Hertsmere     \n4  51.7 -0.404 WD24 5TU Watford       \n5  51.4  0.106 DA15 9BQ Bexley\n```\n\nThe object returned from the reverse geocode is a nested list that we can `tidyr::hoist()` the geographic information from. Here we grabbed the postcode and 'administrative district', which for our purposes is the London borough that the point is in.\n\n## Convert to spatial object\n\nRight now we have a dataframe where the geographic information is stored as numeric values. We can use the {sf} package to convert and handle this information as spatial information instead. \n\nBasically we can use {sf} to 'geographise' our dataframe. It can add geometry (points in our case), dimensions (XY, meaning 2D), the maximum geographic extent (a 'bounding box' that roughly covers London) and recognition of the coordinate reference system ('4236' for latitude-longitude).\n\nThe `sf::st_as_sf()` function performs the magic of converting our tidy dataframe into a tidy spatial dataframe. You'll see that the print method provides us the extra spatial metadata and that our geographic information has been stored in a special `geometry` column with class `sfc_POINT`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_sf <- lmb_geocode %>% \n  st_as_sf(\n    coords = c(\"lon\", \"lat\"),  # xy columns\n    crs = 4326,  # coordinate reference system code\n    remove = FALSE  # retain the xy columns\n  )\n\nlmb_sf[1:5, c(\"status_id\", \"geometry\")]  # limited preview\n```\n:::\n\n```\nSimple feature collection with 5 features and 1 field\ngeometry type:  POINT\ndimension:      XY\nbbox:           xmin: -0.4042 ymin: 51.4392 xmax: 0.1636 ymax: 51.6773\nCRS:            EPSG:4326\n# A tibble: 5 x 2\n  status_id                    geometry\n  <chr>                     <POINT [°]>\n1 1343853346478841862   (-0.33 51.5519)\n2 1343844145518026752  (0.1636 51.4392)\n3 1343806154397409280 (-0.2555 51.6773)\n4 1343797964645523456  (-0.4042 51.674)\n5 1343791619049480192  (0.1058 51.4451)\n```\n\n## Map it\n\n### London boundary geojson\n\nCoordinates for londonmapbot tweets are selected randomly within a rectangle roughly within the boundary of the M25 motorway. We can grab a polygon of the Greater London boundary to see which points fall within the 'true' extent of London. \n\nTo do this, I'm using a set of boundaries for England's regions[^nuts] via the [Office for National Statistics's Open Geography Portal](https://geoportal.statistics.gov.uk/datasets/nuts-level-1-january-2018-ultra-generalised-clipped-boundaries-in-the-united-kingdom) API. The polygons are 'ultra generalised' to be represented by very few points (every 500m). This means it doesn't follow the exact boundary of London, but that's okay: it's only being used as a guide and we get the benefit of a small polygon file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nldn_sf <- geojson_read(\n  paste0(  # API endpoint for NUTS1 geography geojson\n    \"https://opendata.arcgis.com/datasets/\",\n    \"01fd6b2d7600446d8af768005992f76a_4.geojson\"\n  ), \n  what = \"sp\"  # read as spatial object\n) %>% \n  st_as_sf() %>%  # convert to sf object\n  filter(nuts118nm == \"London\")  # London polygon only\n\nldn_sf[, c(\"nuts118nm\", \"geometry\")]  # limited preview\n```\n:::\n\n```\nSimple feature collection with 1 feature and 1 field\ngeometry type:  MULTIPOLYGON\ndimension:      XY\nbbox:           xmin: -0.5097014 ymin: 51.28676 xmax: 0.3340242 ymax: 51.69188\nCRS:            unknown\n  nuts118nm                       geometry\n1    London MULTIPOLYGON (((-0.01191868...\n```\n\n{ggplot2} has a geom for quick-plotting of {sf} objects, so we can check the boundary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ldn_sf) +\n  geom_sf() +\n  labs(\n    title = \"London boundary\",\n    subtitle = \"Ultra-generalised NUTS1 extent\",\n    caption = \"Data collected via ONS Open Geography Portal API\"\n  )\n```\n:::\n\n\n![](resources/ldn-map-1.png){fig-alt=\"A simple map of London's administratve boundary.\" width=\"100%\"}\n\n### Build map with {leaflet}\n\nYou can build up layers in {leaflet} in a similar kind of way to a {ggplot2} graphic. The base map is applied with `addProviderTiles()`, followed by the London boundary with `addPolygons()`, with the points added as circle-shaped points with `addCircleMarkers()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_map <- leaflet(ldn_sf, width = '100%') %>% \n  addProviderTiles(\"CartoDB.Positron\") %>%\n  addPolygons(  # generalised London boundary\n    color = \"black\", weight = 2,\n    opacity = 1, fillOpacity = 0.2\n  ) %>% \n  addCircleMarkers(  # locations as points\n    lng = lmb_sf$lon, lat = lmb_sf$lat,  # xy\n    radius = 5, stroke = FALSE,  # marker design\n    fillOpacity = 0.5, fillColor = \"#0000FF\",  # marker colours\n    clusterOptions = markerClusterOptions(),  # bunch-up markers\n    popup = ~paste0(  # dynamic HTML-creation for popup content\n      emo::ji(\"round_pushpin\"), \" \", lmb_sf$lat, \", \", lmb_sf$lon, \"<br>\",\n      emo::ji(\"postbox\"), lmb_sf$admin_district, \n      \", \", lmb_sf$postcode, \"<br>\",\n      emo::ji(\"bird\"), \" <a href='https://twitter.com/londonmapbot/status/\",\n      lmb_sf$status_id, \"'>Tweet</a><br>\",\n      emo::ji(\"world_map\"), \" \", \"<a href='\",\n      lmb_sf$osm_url, \"' width='100%'>OpenStreetMap</a><br><br>\",\n      \"<img src='\", lmb_sf$media_url, \"' width='200'>\"\n    )\n  )\n```\n:::\n\n\nThe markers, which are blue dots, have rich pop-ups when clicked. The information is generated dynamically for each point by pasting HTML strings with the content of the dataframe. Props to [Matt Kerlogue](https://lapsedgeographer.london/)'s [narrowbotR](https://twitter.com/narrowbotR), which uses this emoji-info layout in its automated tweets.\n\nTo keep the design simple and uncluttered, I've intentionally used a muted base map ('Positron' from CartoDB) and limited the amount of pop-up content.\n\nIn the pop-up you'll see information from the tweet, including the satellite image and printed coordinates; URLs to the original tweet and OpenStreetMap; plus the reverse-geocoded info we got from {PostcodesioR}. \n\nSince there are thousands of points, it makes sense to cluster them with `markerClusterOptions()` to avoid graphical and navigational troubles. Click a cluster to expand until you reach a marker.\n\n## The map {#map}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmb_map\n```\n:::\n\n\nIf you can't see the satellite photos in each pop-up you may need to change browser.\n\nAnd no, it hasn't captured my house yet!\n\n## Development\n\nI made this for my own amusement and as an excuse to use {PostcodesioR} and reacquaint myself with {leaflet}. If I were going to develop it, I would make a Shiny app that continuously refreshes with the latest tweet information. I may revisit londonmapbot in future, or create a new bot; in which case the reverse geocoding capabilities of {PostcodesioR} could come in handy for providing more content in tweet text.\n\n## Environment {.appendix}\n\n<details><summary>Session info</summary>\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nLast rendered: 2023-07-18 19:03:41 BST\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21    \n```\n:::\n:::\n\n</details><p>\n\n[^nuts]: Technically we're using the [NUTS1 regional designations](https://en.wikipedia.org/wiki/NUTS_1_statistical_regions_of_England), a [Eurostat](https://en.wikipedia.org/wiki/Eurostat) standard.\n[^wrassle]: I'm going to assume this is also a wrestling move.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}