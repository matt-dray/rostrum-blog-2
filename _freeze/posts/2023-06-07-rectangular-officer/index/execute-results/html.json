{
  "hash": "a6831cab6cdacf5a08db004c1b02d6db",
  "result": {
    "markdown": "---\ntitle: \"Rectangularise Word tables extracted by {officer}\"\ndate: 2023-06-07\nslug: rectangular-officer\ncategories:\n  - ms-office\n  - officer\n  - officerExtras\n  - public-sector\n  - r\n---\n\n\n\n\n![](resources/owl.png){fig-alt=\"The 'draw the rest of the owl' meme. The title is 'how to draw an owl' but it's been scribble dout and replaced with comic sans text that says 'How to extract an R data.frame from a Word table'. There are two steps: 'draw some circles' and then 'draw the rest of the owl'. The text for these has been replaced with Comic Sans that reads 'let officer do all the hard work' and then 'overengineer an unecessary new function.'\" width=\"100%\"}\n\n## tl;dr\n\n[{officer} is an R package](https://davidgohel.github.io/officer/) that lets you extract elements of a Word document, including tables, into a tidy dataframe. I've written a function to 're-rectangularise' extracted Word tables into a list of R dataframes.\n\n<div class=\"tip\"> ℹ️ <b>Update</b>\n\nTurns out that [Eli Pousson](https://elipousson.github.io/) has written the [{officerExtras} package](https://elipousson.github.io/officerExtras) ([install it from GitHub](https://github.com/elipousson/officerExtras/)), which already contains this functionality in [the `officer_tables()` and `officer_table()` functions](https://elipousson.github.io/officerExtras/reference/officer_tables.html). At least this proves my idea wasn't too far-fetched!\n\nAlso you can just use [`docxtractr::docx_extract_all_tbls()` by Bob Rudis](https://github.com/hrbrmstr/docxtractr) to extract all the tables in one go, lol.\n\n</div>\n\n## What's the officer, problem?\n\nSomeone on Slack asked about some difficulty with scraping a table from a Word document. We've all been there.\n\nMy mind immediately went to [{officer} by David Gohel](https://davidgohel.github.io/officer/), which is part of [the 'officeverse'](https://ardata-fr.github.io/officeverse/) for reading, creating and manipulating common Microsoft documents with R[^ms]. \n\nIn particular, the function `officer::docx_summary()` extracts all the elements of a Word doc into a tidy dataframe[^tidyxl]. Each row of that dataframe is a heading, or a paragraph, or the contents of a table cell[^merge].\n\nThis means tables are 'unstacked', with a row per 'cell' of the original Word table. How could you convert these tidy Word tables into dataframes for further use in R? There's [a suggestion in the docs](https://ardata-fr.github.io/officeverse/extract-content.html#word-tables), but I [drew the rest of the heckin' owl](https://knowyourmeme.com/memes/how-to-draw-an-owl) by creating a slightly overengineered function to do it[^curiosity].\n\n## 'Allo 'allo\n\nFirst, you can download the {officer} package from CRAN:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"officer\") # if not yet installed\nlibrary(officer)\n```\n:::\n\n\nLet's create a Word document to test with and save it to a temporary location:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a test docx file\ndoc_test <- read_docx() |>\n  body_add_par(\"This is a test\", style = \"heading 1\") |>\n  body_add_par(\"Below is a table.\", style = \"Normal\") |>\n  body_add_table(mtcars[1:3, 1:5]) |> \n  body_add_par(\"Below is another table\", style = \"Normal\") |>\n  body_add_table(airquality[1:3, 1:5])\n\n# Save docx to temp location\ntemp_docx <- tempfile(fileext = \".docx\")\nprint(doc_test, target = temp_docx)\n```\n:::\n\n\nThe package has a nice system of pipeable functions for building up document. This code created a file with a heading, followed by two tables that each have a line of text above them.\n\nWe can read the document with `read_docx()` and extract the contents into a tidy dataframe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the file from temp path\ndoc_path <- list.files(tempdir(), pattern = \".docx$\", full.names = TRUE)\ndoc_in <- read_docx(doc_path)\n\n# Get the content of the document as a dataframe\ndoc_tidy <- docx_summary(doc_in)\nstr(doc_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t43 obs. of  11 variables:\n $ doc_index   : int  1 2 3 3 3 3 3 3 3 3 ...\n $ content_type: chr  \"paragraph\" \"paragraph\" \"table cell\" \"table cell\" ...\n $ style_name  : chr  \"heading 1\" \"Normal\" NA NA ...\n $ text        : chr  \"This is a test\" \"Below is a table.\" \"mpg\" \"21.0\" ...\n $ level       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ num_id      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ row_id      : int  NA NA 1 2 3 4 1 2 3 4 ...\n $ is_header   : logi  NA NA TRUE FALSE FALSE FALSE ...\n $ cell_id     : num  NA NA 1 1 1 1 2 2 2 2 ...\n $ col_span    : num  NA NA 1 1 1 1 1 1 1 1 ...\n $ row_span    : int  NA NA 1 1 1 1 1 1 1 1 ...\n```\n:::\n:::\n\n\nThe `doc_in` object has 'rdocx' class that carries the extracted elements and associated style information. Running `docx_summary()` converts this to the single tidy dataframe that we're after.\n\nYou can see we have information here about the content of our doc. For purposes of this post, we care about:\n\n* `text`, which is the actual written content\n* `content_type`, which can tell us if we're looking at table cells\n* `doc_index`, which assigns an ID value so document elements stay together (e.g. cells of a table will all carry the same `doc_index`)\n* `cell_id` and `row_id`, which tell us the x and y cell locations in tables\n* `is_header`, which can tell us if the row contains a table header.\n\nNow to extract the table elements and 're-rectangularise' back into a dataframe.\n\n## Cop a load of this\n\nI've made two functions using base R:\n\n1. `rectangularise_tables()` (note the plural) takes the dataframe provided by `docx_summary()` and outputs a list of dataframes, one per table in the original Word file\n1. `.rectangularise_table()` (not pluralised and starts with a dot for disambiguation), which runs inside `rectangularise_tables()` to reformat the tidy representation of a single Word table into an R dataframe\n\nYou'll need to copy both of these into your session and run them. For convenience, [I've added them to a GitHub gist](https://gist.github.com/matt-dray/d4837f106bcee80ea39235b6465a7cac). I've added commentary so you can see what's happening in each bit.\n\n<details><summary>Click to expand the `rectangularise_tables()` definition.</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrectangularise_tables <- function(\n    docx_summary,  # output dataframe from docx_summary\n    assume_headers = TRUE,  # assume headers in first row?\n    type_convert = TRUE  # try to coerce columns to most likely data type?\n) {\n  \n  # Check inputs\n  \n  is_data.frame <- inherits(docx_summary, \"data.frame\")\n  \n  docx_summary_names <- c(\n    \"doc_index\", \"content_type\", \"style_name\", \"text\", \"level\", \"num_id\", \n    \"row_id\", \"is_header\", \"cell_id\", \"col_span\", \"row_span\"\n  )  # column names we can expect in the output from docx_summary\n  \n  is_docx_summary <- all(names(docx_summary) %in% docx_summary_names)\n  \n  if (!is_data.frame | !is_docx_summary) {\n    stop(\n      paste(\n        \"Argument 'docx_summary' must be a data.frame created with\",\n        \"'officer::docx_summary'.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Get only the rows that relate to Word tables\n  docx_summary_tables <- \n    docx_summary[docx_summary[[\"content_type\"]] %in% \"table cell\", ]\n  \n  # Get the ID value for each Word table\n  doc_indices <- unique(docx_summary_tables[[\"doc_index\"]])\n  \n  # Initiate an empty list to hold dataframe representations of the Word tables\n  tables_out <- vector(mode = \"list\", length = length(doc_indices))\n  names(tables_out) <- paste0(\"doc_index_\", doc_indices)\n  \n  # For each Word table, 'rectangularise' into a dataframe and add to the list\n  for (doc_index in doc_indices) {\n    \n    docx_summary_table <- \n      docx_summary_tables[docx_summary_tables[[\"doc_index\"]] == doc_index, ]\n    \n    extracted_table <- .rectangularise_table(docx_summary_table, assume_headers)\n    \n    list_element_name <- paste0(\"doc_index_\", doc_index)\n    tables_out[[list_element_name]] <- extracted_table\n    \n  }\n  \n  # Optionally convert columns to appropriate type (integer, etc)\n  if (type_convert) {\n    tables_out <- lapply(tables_out, type.convert, as.is = TRUE)\n  }\n  \n  return(tables_out)\n  \n}\n```\n:::\n\n\n</details>\n\n<details><summary>Click to expand the `.rectangularise_table()` definition.</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.rectangularise_table <- function(\n    table_cells,  # docx_summary output filtered for 'table cells' only\n    assume_headers = TRUE  # assume headers in first row?\n) {\n  \n  # Check inputs\n  \n  is_table_cells <- all(table_cells[[\"content_type\"]] == \"table cell\")\n  is_one_table <- length(unique(table_cells[[\"doc_index\"]])) == 1\n  \n  if (!is_table_cells | !is_one_table) {\n    stop(\n      paste(\n        \"Argument 'table_cells' must be a dataframe created with\",\n        \"'officer::docx_summary' where 'content_type' is filtered for\",\n        \"'table cell' only.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Split each Word table into a list element, isolate headers and cell contents\n  cell_id_split <- split(table_cells, table_cells[[\"cell_id\"]])\n  headers <- lapply(cell_id_split, function(x) x[x[[\"is_header\"]], \"text\"])\n  content <- lapply(cell_id_split, function(x) x[!x[[\"is_header\"]], \"text\"])\n  table_out <- as.data.frame(content)\n  \n  # Column headers are identified by TRUE in the is_header column, but may not\n  # be marked up as such. Use them as dataframe headers if they exist.\n  has_headers <- length(unlist(headers)) > 0\n  if (has_headers) {\n    names(table_out) <- headers\n  }\n  \n  # If headers are not identified by is_header, assume that the first row of the\n  # Word table contains the headers. The user can control this behaviour with\n  # the argument assume_headers.\n  if (!has_headers & assume_headers) {\n    headers <- table_out[1, ]  # assume first row is headers\n    table_out <- table_out[2:nrow(table_out), ]  # rest of table is content\n    names(table_out) <- headers\n  }\n  \n  return(table_out)\n  \n}\n```\n:::\n\n\n</details>\n\nYou'll notice the `assume_headers` argument. The headers for a Word table are marked by `TRUE` in the `is_header` column of the output from `docx_summary()`. Except when they aren't. It's possible that you'll read a Word doc where the table headers aren't identified. Set `assume_headers` to `TRUE` (the default) to allow `rectangularise_table()` to instead use the first row of the table as headers. The setting will apply to all tables; I reckon that it's all or nothing whether table headers will be marked up in a given Word document.\n\nYou may also have seen the `type_convert` argument[^type]. By default, the `text` column in the output from `docx_summary()` will be character class, but the actual data might be integers, for example. [As explained in a recent blog post](https://www.rostrum.blog/2023/04/23/type-convert/), the `type.convert()` function attempts to coerce a column to the appropriate data type if possible.\n\nAnd now we can see that the dataset works using our test document:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_list <- rectangularise_tables(doc_tidy)\nstr(df_list)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ doc_index_3:'data.frame':\t3 obs. of  5 variables:\n  ..$ mpg : num [1:3] 21 21 22.8\n  ..$ cyl : int [1:3] 6 6 4\n  ..$ disp: int [1:3] 160 160 108\n  ..$ hp  : int [1:3] 110 110 93\n  ..$ drat: num [1:3] 3.9 3.9 3.85\n $ doc_index_5:'data.frame':\t3 obs. of  5 variables:\n  ..$ Ozone  : int [1:3] 41 36 12\n  ..$ Solar.R: int [1:3] 190 118 149\n  ..$ Wind   : num [1:3] 7.4 8 12.6\n  ..$ Temp   : int [1:3] 67 72 74\n  ..$ Month  : int [1:3] 5 5 5\n```\n:::\n:::\n\nSmashing. We have a list of two dataframes: one for each of the tables in the test document. I took the liberty of naming the list elements like `doc_index_*` so you can trace which `doc_index` they were in the original output from `docx_summary()`.\n\n## PrisonR\n\nTo summarise, this is absolutely not the worst code-related crime I've committed on this blog. Sorry guv! I'll definitely be sentenced to the most severe punishment if caught and tried: several minutes of hard labour, or 'refactoring' as they call it on the inside. \n\nAt worst I'll build an Andy-Dufresne-style tunnel out of my prison cell and hide the entrance behind years of accumulated hex stickers.\n\n<div class=\"tip\"> ℹ️ <b>Update</b>\n\nAs a bonus, I later wrote a quick reproducible example that part-solves the original reason for this post. Here I've used {docxtractr} to extract tables from docx files in separate subfolders and then combine them.\n\n<details><summary>Click to expand code.</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Attach packages (all are available from CRAN)\nlibrary(docxtractr)  # to extract tables from docx files\nlibrary(officer)  # to create dummy docx files\nlibrary(charlatan)  # to generate fake data\n\n# Create multiple dummy docx files in separate temporary folders\n\nmy_folder <- tempdir()  # temporary locations to store the files\nn_files <- 5  # the number of dummy files to generate\n\nfor (i in seq(n_files)) {\n  \n  # Create subfolders\n  subfolder_name <- paste0(\"subfolder_\", i)\n  dir.create(file.path(my_folder, subfolder_name))\n  \n  # Create dummy dataframe\n  \n  n_fake <- 10  # number of fake data items to generate\n  \n  temp_df <- data.frame(\n    name = ch_name(n_fake),\n    job = ch_job(n_fake),\n    phone = ch_phone_number(n_fake)\n  )\n  \n  # Add dummy dataframe to a docx file and save it\n  path <- file.path(my_folder, subfolder_name, paste0(\"df_\", i, \".docx\"))\n  officer::read_docx() |> body_add_table(temp_df) |> print(target = path)\n  \n}\n\n# Get the file paths to all the docx files\ndocx_paths <- list.files(\n  my_folder,\n  pattern = \".docx$\",\n  full.names = TRUE,  # return full filepaths\n  recursive = TRUE  # look in all subfolders\n)\n\n# Preallocate a list to be filled with extracted tables, one element per file\nextracted_tables <- vector(\"list\", n_files)\n\n# Extract tables and add to the list (not tested: I think that read_docx will\n# read .doc files, but only if you have LibreOffice installed.\nfor (i in docx_paths) {\n  tables <- docxtractr::read_docx(i) |> docx_extract_all_tbls()\n  extracted_tables[basename(i)] <- tables\n}\n\n# In this simple demo, the dataframes in each list element can be appended\n# because they all have the same column names and types.\ndo.call(rbind, extracted_tables)\n```\n:::\n\n\n</div>\n\n## Environment {.appendix}\n\n<details><summary>Session info</summary>\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nLast rendered: 2023-06-29 18:16:59 CEST\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] officer_0.6.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.22    xml2_1.3.4       \n [9] cli_3.6.1         zip_2.3.0         askpass_1.1       openssl_2.0.6    \n[13] textshaping_0.3.6 systemfonts_1.0.4 compiler_4.3.1    rstudioapi_0.14  \n[17] tools_4.3.1       ragg_1.2.5        evaluate_0.21     yaml_2.3.7       \n[21] rlang_1.1.1       jsonlite_1.8.5    htmlwidgets_1.6.2 uuid_1.1-0       \n```\n:::\n:::\n\n</details>\n\n[^ms]: Related: I have some experience with R-to-Excel: [my {a11ytables} package](https://co-analysis.github.io/a11ytables/) generates best-practice spreadsheets [using {openxlsx}](https://ycphs.github.io/openxlsx/).\n[^merge]: Merged cells in the table end up being unmerged, with the upper- and left-most cells holding the content and the remianing cells being assigned `NA`.\n[^curiosity]: I did this for my own curiosity, really. Just like everything else on this blog! As mentioned, check out [{docxtractr}](https://github.com/hrbrmstr/docxtractr) and [{officerExtras}](https://elipousson.github.io/officerExtras) for better implementations.\n[^tidyxl]: It would be wrong for me not to point out that you can extract Excel and ODS cells into 'tidy' dataframes with [Duncan Garmonsway's {tidyxl}](https://nacnudus.github.io/tidyxl/index.html) and [Matt Kerlogue's {tidyods}](https://mattkerlogue.github.io/tidyods/). No, they haven't sponsored this post (invoices in the mail, chaps).\n[^type]: What a handy function. This was useful enough that Eli has now added it to [{officerExtras}](https://elipousson.github.io/officerExtras/reference/officer_tables.html).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}