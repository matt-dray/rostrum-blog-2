[
  {
    "objectID": "about.html#tldr",
    "href": "about.html#tldr",
    "title": "rostrum.blog",
    "section": "tl;dr",
    "text": "tl;dr\nFun and learning with R, usually off-piste. It’s a bonus if you find any of it useful and/or amusing. All views belong to us."
  },
  {
    "objectID": "about.html#creators",
    "href": "about.html#creators",
    "title": "rostrum.blog",
    "section": "Creators",
    "text": "Creators\n\nMatt Dray\nPersonal site | Github | Mastodon\nI use R professionally for analysis and reproducibility, and as an amateur for memes and ironic trolling. I make R do odd things, often with the aid of important pop-culture references like Pokémon and Dawson’s Creek.\n\n\nAdriana De Palma\nPersonal website\nMy job involves using R to understand the health of nature globally. I spend at least 50% of my spare time talking through Matt’s latest idea about what weird thing he could do with R."
  },
  {
    "objectID": "about.html#meta",
    "href": "about.html#meta",
    "title": "rostrum.blog",
    "section": "Meta",
    "text": "Meta\n\nFind the source on GitHub\nMade with Quarto\nDeployed with Netlify\nCheck out R Weekly for more R content\n‘rostrum’ because this used to be an ecology blog (!) and a rostrum is both an insect’s mouthparts and a podium-like piece of furniture that you orate from"
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html",
    "href": "posts/2023-10-17-nhs-r-2023/index.html",
    "title": "Base slaps!",
    "section": "",
    "text": "I gave a lightning talk at the NHS-R Conference 2023 about base R."
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#tldr",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#tldr",
    "title": "Base slaps!",
    "section": "",
    "text": "I gave a lightning talk at the NHS-R Conference 2023 about base R."
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#video",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#video",
    "title": "Base slaps!",
    "section": "Video",
    "text": "Video\nYou can choose to watch the video on YouTube1."
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#slides",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#slides",
    "title": "Base slaps!",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded below2 or they can be opened in a dedicated tab. Click on them and press → to advance, F to go fullscreen, and S to pop-out the speaker notes3.\n\n\n\n\n\n\n\n\nThe source is on GitHub. The slides are written with Quarto, of course."
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#premise",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#premise",
    "title": "Base slaps!",
    "section": "Premise",
    "text": "Premise\nThe abstract for the talk:\n\nDid you hear? Base R is dead! Or is it? I’ve spent most of my time in the public sector using the tidyverse, but I started learning R before the tidyverse existed (to be polite, you could call me ‘seasoned’). Recently I’ve started to write more base R code again. Why? I’ll talk about how base R can do loads of neat stuff out of the box without you needing to install and update any packages (dependencies aren’t bad things per se, but can cause trouble if not managed appropriately). I’ll also tell you about some recent additions, like the base pipe and lambda function notation, which demonstrate how base R is responding to the needs of the modern coder. Oh, and you can also do wacky stuff like make an interactive pixel-art creator, a persistent Tamagotchi pet, or a procedural dungeon-crawler. Note that this talk does not constitute a ‘base versus tidyverse’ flamewar. It’s purely to appreciate the elegance of good ol’ base R and to highlight some things it can do that you might not have realised (or like me, you forgot a long time ago).\n\nIn other words, the content of the talk was neither new nor earth-shattering4. The basic premise was ‘base R is pretty neat, don’t forget it exists!’\nI have a narrow window of experience. I work in the public sector, mostly with people who publish statistical reports. The default for data preparation and analysis is often the tidyverse. That’s fine, for many reasons, but it may be overkill for small projects. Arguably, at worst, reproducibility may be jeopardised. And we love reproducibility in the public sector.\nMy plea to fellow public-sector coders: use your tool of choice, but consider if base R can do it alone5. Or, at very least, become more acquainted with the built-in functions and (spoiler alert) maybe build some off-piste packages for a laugh."
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#content",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#content",
    "title": "Base slaps!",
    "section": "Content",
    "text": "Content\nThe talk mentions three beneficial things related to base R:\n\nStability.\nDependency.\nModernity.\n\nRe stability, vanilla R has changed little over time. Code written a couple of decades ago has a high chance of running now and will (likely) be executable for a long time into the future6. As a result, I contend that R is a horseshoe crab (unchanged for aeons, cryptically beautiful). And that R users are Milhouse in this relevant gif (look deep inside yourself, you are Milhouse).\n\nRe dependencies, R’s extensibility is one of its greatest strengths, but reducing the dependency count could help improve reproducibility and reduce headaches7. I used an obligatory (adapted) xkcd comic to illustrate this. Note that base R is the literal, unyielding base of the teetering tower of packages used by your project (incredible metaphor).\n\nRe ‘modernity’, high stability hasn’t stopped base R from also being adapted to meet the expectations of a contemporary coder. R version 4.0 has given us a ‘modern base aesthetic’ (trademark pending) of pipes (|&gt;), lambdas (\\()) and string literals (r\"{}\"). R has morphed, much like the morphing of its janky old logo to the (perhaps already-outdated, lol) contemporary ‘flat’ design of the new logo8?\n\nBut wait! A bonus thing:\n\n‘Oddity’.\n\nRe oddity, base R has some hidden-gem functions that you can use for serious—or utterly nonserious things—like:\n\nlocator() to click a plot and have coordinates returned (e.g. in my experimental {pixeltrix} package for interactive pixel art)\nreadline() to accept user input interactively (e.g. i my experimental {r.oguelike} package for a ‘procedural dungeon-crawler’ in the R console)\nR_user_dir() as a location for storing user data (e.g. in my experimental {tamRgo} package for a persistent cyber pet in the R console)\n\nDespite all this, base R isn’t perfect for everyone in every situation9. Base flaps sometimes, that’s fine. You can argue it’s more terse and less readable than the verb-driven tidyverse, for example. But we have a duty in the public sector to think about long-term code survival. And high employee turnover rates mean we should perhaps default to the most vanilla tool.\nI like base R for writing functions and code I want to live for a long time, for example. I use the tidyverse for everyday data wrangling.\nBut ultimately, I just wanted to do this terrible ‘base slaps’/‘slap bass’ pun, sorry. But also, I hear that zoomers say ‘slaps’ to mean ‘cool’. I think. Oh dear, this was a flimsy premise for a talk. Cringe-driven development?"
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#environment",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#environment",
    "title": "Base slaps!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-11-28 23:20:58 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] assertthat_0.2.1    digest_0.6.33       R6_2.5.1           \n [4] fastmap_1.1.1       xfun_0.41           magrittr_2.0.3     \n [7] glue_1.6.2          stringr_1.5.0       knitr_1.45         \n[10] htmltools_0.5.6.1   rmarkdown_2.25      lifecycle_1.0.3    \n[13] cli_3.6.1           vctrs_0.6.4         compiler_4.3.1     \n[16] httr_1.4.7          vembedr_0.1.5       rstudioapi_0.15.0  \n[19] tools_4.3.1         xaringanExtra_0.7.0 curl_5.1.0         \n[22] evaluate_0.23       yaml_2.3.7          rlang_1.1.1        \n[25] jsonlite_1.8.7      htmlwidgets_1.6.2   stringi_1.7.12"
  },
  {
    "objectID": "posts/2023-10-17-nhs-r-2023/index.html#footnotes",
    "href": "posts/2023-10-17-nhs-r-2023/index.html#footnotes",
    "title": "Base slaps!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNo Matt Dray presentation is complete without a ‘Dr Dre’ pun at beginning, lol. Only made funnier by my ongoing work with RAP (Reproducible Analytical Pipelines).↩︎\nI think there’ll be a video; I’ll link to it here when it’s released.↩︎\nAmusingly, these notes are absolutely not what I said in the talk itself, lol.↩︎\nAlthough at least one attendee’s mind was blown to discover that you can simultaneously assign and print an expression by wrapping it in brackets, like (x &lt;- 1).↩︎\nBut to be clear: I don’t think you should ‘just replace all your code with base R code’. There’s very few examples of where that would make sense. But is it worth importing all of {dplyr} if you just want to select(), filter() and mutate() a data.frame? Maybe, maybe not.↩︎\nUntil we all switch to the Julia and/or Rust languages, amirite.↩︎\nBearing in mind that tools like {renv}, Docker and Nix (thanks Bruno) can help coordinate dependencies. But that’s yet another tool to manage.↩︎\nI think this was incepted into my brain by Jeroen in the {magick} docs.↩︎\nSee the wishlist that Henrik Bengtsson has been hosting.↩︎"
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html",
    "href": "posts/2020-01-31-reprobioinformatics/index.html",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "",
    "text": "REPRODUCIBILITY 4 LYFE (via Bioinformatics London’s Meetup page)."
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html#tldr",
    "href": "posts/2020-01-31-reprobioinformatics/index.html#tldr",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "tl;dr",
    "text": "tl;dr\nI spoke at the latest Bioinformatics London Meetup (event link, Twitter) about workflow reproducibility tools in R. I explained the benefits of Will Landau’s {drake} package for doing this."
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html#order-order",
    "href": "posts/2020-01-31-reprobioinformatics/index.html#order-order",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "Order, order",
    "text": "Order, order\nRich FitzJohn opened proceedings with an excellent introduction to his {orderly} package (source) that is intended for ‘lightweight reproducible reporting’.\nIn short, the user declares inputs (anything, including things like SQL queries and CSV files) and artefacts (results) of their analysis. {orderly} loads what is declared, evaluates and runs what is necessary, and verifies that the declared artefacts are made. A bunch of metadata is stored alongside the analysis that can be used later to determine the source of any dependency changes.\nI followed up with the basics of {drake}. My slides are in the following section.\nWe were also lucky to have a celebrity guest on the line: the creator of {drake}, Will Landau, who said some words about the package’s development and took questions. Will was also able to extend gratitude to Rich for having developed {remake}, a workflow manager for R that was a precursor to the development of {drake}."
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html#slides",
    "href": "posts/2020-01-31-reprobioinformatics/index.html#slides",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "Slides",
    "text": "Slides\nYou can open the slides in a dedicated tab (press P for presenter notes) or see the source. The slides introduce the idea of a workflow manager to improve reproducibility and how {drake} can fill that gap.\n\n\n\n\n\n\n\n\nThe second half of the presentation contains a small and simple demonstration of {drake} in action using R’s excellent built-in beaver-temperature datasets.\nBonus reproducibility: the {drake} analysis takes place in the slides themselves and is recreated from scratch when they’re regenerated. This is made possible by {xaringan}, Yihui Xie’s package for reproducible presentations.\nI also created a single file containing the code that was run in the slides.\n\n\nClick for the {drake} code.\n\n\n# Reproducible workflows with {drake}\n# Bioinformatics London Meetup, 2020-01-30\n# This is a script file containing the code from the talk slides\n# Source: github.com/matt-dray/drakebioinformatics\n# Slides available here: matt-dray.github.io/drake-bioinformatics/\n\n# Packages ----------------------------------------------------------------\n\n# All available from CRAN with install.packages()\nlibrary(drake)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rphylopic)  # get CC0 organism graphics\n\n# Functions ---------------------------------------------------------------\n\n# Simple beaver plot\nb_plot &lt;- function(data, image) {\n  ggplot(data, aes(id, temp)) +\n    geom_boxplot() +\n    labs(title = \"Beaver temperature\") +\n    add_phylopic(image)\n}\n\n# Simple beaver summary table\nb_table &lt;- function(data) {\n  beavers_trim &lt;- data %&gt;% \n    group_by(id) %&gt;% \n    summarise(\n      mean = mean(temp), sd = sd(temp),\n      min = min(temp, max = max(temp))\n      ) %&gt;% ungroup()\n  return(beavers_trim)\n}\n\n# Plan --------------------------------------------------------------------\n\n# Wrap analysis steps in drake_plan()\n\nplan &lt;- drake_plan(\n  \n  # 1. Wrangle data\n  \n  b1 = mutate(beaver1, id = \"A\"),  # built-in dataset\n  b2 = mutate(beaver2, id = \"B\"),  # built-in dataset\n  beavers = bind_rows(b1, b2),\n  \n  # 1. Get phylopic image\n  \n  uid = \"be8670c2-a5bd-4b44-88e8-92f8b0c7f4c6\",\n  png = image_data(uid, size = \"512\")[[1]],\n  \n  # 3. Generate outputs\n  # The .Rmd is avaiable from github.com/matt-dray/drake-bioinformatics\n  \n  plot = b_plot(beavers, png),\n  table = b_table(beavers),\n  report = rmarkdown::render(\n    knitr_in(\"beavers-report.Rmd\"),  # note knitr_in()\n    output_file = file_out(\"beaver-report.html\"),  # note file_out()\n    quiet = TRUE\n  )\n  \n)\n\n# Make --------------------------------------------------------------------\n\ndrake::make(plan)  # executes the analysis steps in the plan\n\n# Inspection --------------------------------------------------------------\n\n# Get cached objects\ncached()  # check what's in the cache\nreadd()  # return an object from the cache\n\n# Create network graph\nconfig &lt;- drake_config(plan)  # make a configuration file for the plan\nvis_drake_graph(config)  # build an interactive network graph using the config\n\n# Make changes ------------------------------------------------------------\n\n# Let's say something in your workflow changed. What is now out of date?\n\noutdated()  # prints the targets that are out of date\n\nvis_drake_graph(config)  # rebuild grpah to see impacted targets coloured black\n\ndrake::make(plan)  # re-make the plan!"
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html#related",
    "href": "posts/2020-01-31-reprobioinformatics/index.html#related",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "Related",
    "text": "Related\nI don’t shut up about reproducibility in R. That’s why I’ve coined the word ‘reproducevangelism’. Here’s a couple of related posts:\n\nReproducibility in R: three things\nCan {drake} RAP?"
  },
  {
    "objectID": "posts/2020-01-31-reprobioinformatics/index.html#environment",
    "href": "posts/2020-01-31-reprobioinformatics/index.html#environment",
    "title": "{orderly} and {drake} at Bioinformatics London",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 16:20:16 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html",
    "href": "posts/2021-02-02-sonify-covid/index.html",
    "title": "What does a year of COVID-19 sound like?",
    "section": "",
    "text": "Landing page of coronavirus.data.gov.uk dashboard."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#tldr",
    "href": "posts/2021-02-02-sonify-covid/index.html#tldr",
    "title": "What does a year of COVID-19 sound like?",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {sonify} package in R to represent a year of the UK’s COVID-19 data in audio format. You can jump straight to the audio."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#listen-to-your-data",
    "href": "posts/2021-02-02-sonify-covid/index.html#listen-to-your-data",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Listen to your data",
    "text": "Listen to your data\nI watched an excellent talk at the rstudio::global(2021) conference by JooYoung Seo titled ‘Accessible Data Science Beyond Visual Models: Non-Visual Interactions with R and RStudio Packages’. You can access the video or his blog on the subject.\nIn the talk he mentioned the {sonify} package for R, which lets you represent data with sound rather than with visuals. For example, values of x and y that increase linearly can be represented by a sound that rises in pitch.\nI wondered: what would COVID-19 data sound like, given it’s been a year since the UK’s first cases?"
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#covid-19-data",
    "href": "posts/2021-02-02-sonify-covid/index.html#covid-19-data",
    "title": "What does a year of COVID-19 sound like?",
    "section": "COVID-19 data",
    "text": "COVID-19 data\nGOV.UK, the UK government’s website, has a ‘daily dashboard’ of COVID-19 statistics. There are four prominent statistics:\n\nCases (people tested positive)\nDeaths (deaths within 28 days of a positive test)\nHealthcare (patients admitted to hospital)\nTesting (virus tests conducted)\n\nThe downloads page contains these data and more, both UK-wide and at local levels. This post isn’t an analysis, but I implore you to take a look a the data yourself and read the details about how the data were collected.\nHelpfully, you can generate a permanent API link from which to fetch data1. Here I’m grabbing the UK-wide stats mentioned above:\n\ndata &lt;- read.csv(\n  paste0(\n    \"https://api.coronavirus.data.gov.uk/v2/data\",\n    \"?areaType=overview\", # UK wide\n    \"&metric=newCasesBySpecimenDate\",  # cases\n    \"&metric=newDeaths28DaysByDeathDate\",  # deaths\n    \"&metric=newAdmissions\",  # healthcare\n    \"&metric=newVirusTests\",  # testing\n    \"&format=csv\"  # CSV output\n  ),\n  stringsAsFactors = FALSE\n)\n\nI’ll apply some minor cleaning to order by date and isolate the first 365 days, which takes us to 28 January 2021.\n\ndata &lt;- data[order(data$date), ]  # order by date\ndata &lt;- data[1:365, ]  # first year\nrange(data$date)\n\n[1] \"2020-01-30\" \"2021-01-28\"\nI read this into R as a data.frame object with one row per day.\n\ntail(data[, c(1, 5:8)])\n\n         date newCasesBySpecimenDate newDeaths28DaysByDeathDate\n18 2021-01-23                  21851                       1151\n17 2021-01-24                  17191                       1134\n16 2021-01-25                  29976                       1152\n15 2021-01-26                  27036                       1044\n14 2021-01-27                  25720                       1093\n13 2021-01-28                  24092                       1083\n    newAdmissions newVirusTests\n18           3100        484485\n17           3109        412204\n16           2925        542893\n15           3136        596845\n14           3050        771710\n13           3039        753031\nHow quickly a year goes."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#av-functions",
    "href": "posts/2021-02-02-sonify-covid/index.html#av-functions",
    "title": "What does a year of COVID-19 sound like?",
    "section": "AV functions",
    "text": "AV functions\nYou can skip to the next section if you aren’t interested in the code that will be producing the audio and plots.\n\nAudio\nI’ve written a small function using sonify::sonify() to generate audio clips that represent each COVID-19 variable over time.\nYou pass sonify() your x and y points as you would the plot() function. It has a number of audio-related arguments that let you modify things like the waveform and interpolation, but I’m sticking to the defaults here. This produces a five-second clip in stereo, so you’ll hear the sound move from left to right as you listen.\nThe {tuneR} package has the function tuneR::writeWav() to write out the audio to a local .wav file (my desktop in this case).\n\nsonify_covid &lt;- function(y, out_dir = \"~/Desktop\") {\n\n    tuneR::writeWave(\n      sonify::sonify(\n        x = as.Date(data$date), y = data[[y]],\n        play = FALSE  # suppress audio from playing\n      ),\n      file.path(out_dir, paste0(y, \".wav\"))\n    )\n  \n}\n\n# Apply the function each variable\npurrr::walk(names(data[5:8]), sonify_covid)\n\nThese clips are embedded above the plots in the section below. A download link is included on the player. If you have trouble playing or downloading any of the clips, you can also access them in a playlist on SoundCloud.\n\n\nVisual\nI’m including plots so you can follow how the visuals map to the sound. The plots are going to be intentionally sparse because the focus of the post is the sound the data make. The function takes a COVID-19 variable from our dataset and plots it over time with {ggplot2}.\n\nlibrary(ggplot2)  # attach plotting package\n\nplot_covid &lt;- function(y) {\n\n  ggplot() +\n    geom_point(\n      aes(as.Date(data$date), data[[y]] / 1000),\n      shape = 21  # empty-circle character\n    ) +\n    labs(\n      caption = \"Data: https://coronavirus.data.gov.uk/\",\n      x = \"Date\", y = \"Count (thousands)\"\n    ) +\n    theme_minimal()\n  \n}\n\nYou can then pass in the variable like plot_covid(newAdmissions), although I’ve hidden this code in the next section."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#sonified",
    "href": "posts/2021-02-02-sonify-covid/index.html#sonified",
    "title": "What does a year of COVID-19 sound like?",
    "section": "COVID-19 sonified",
    "text": "COVID-19 sonified\nIn each clip, a higher pitch indicates a higher value; a more continuous tone indicates that the points are tightly distributed; and the sound moving from the left to right audio channel indicates change over time.\nAll of these datasets start on the same date, 30 January 2020, which is when the first cases were recorded according to the newCasesBySpecimenDate variable. They all end 365 days later on 28 January 2021.\nThese data are quite well suited to sonification, given the peaks and troughs. In particular, the death and healthcare variables spike quickly, fall back down, rise again, drop slightly and then peak once more. You won’t notice that initial spike for the cases variable, given the relatively lower testing rate at the time.\n\nCases\nThis audio and plot show the number of people who have tested positive over time.\n\n\n\n\n\n\n\n\nDeath\nThis audio and plot show the number of recorded deaths within 28 days of a positive test over time.\n\n\n\n\n\n\n\n\nHealthcare\nThis audio and plot show the number of patients admitted to hospital over time.\n\n\n\n\n\n\n\n\nTesting\nThis audio and plot show the number of virus tests conducted over time."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#coda",
    "href": "posts/2021-02-02-sonify-covid/index.html#coda",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Coda",
    "text": "Coda\nSonification has been used for a variety of applications during the pandemic as an alternate means of conveying the data.\nFor example, Jan Willem Tulp has created a page that ‘dings’ each time there’s a new case around the world. For something more complex, Mark D. Temple has published in the BMC Bioinformatics journal a paper about sonifying the COVID-19 genome (!). Meanwhile, Pedro Pereira Sarmento has sonified data to investigate the impacts of COVID-19 on air pollution.\nI’m probably not the first to sonify coronavirus data in this way, and probably not even the first to do it with R, but it seemed a good time to take a look (listen?) back on things. I’m interested to hear more about what approaches others have taken."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#environment",
    "href": "posts/2021-02-02-sonify-covid/index.html#environment",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-11 23:20:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#footnotes",
    "href": "posts/2021-02-02-sonify-covid/index.html#footnotes",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFair usage applies. Ten requests per any 100–second period, with a max rate limit of 100 per hour. Five metrics max per request. Identical requests only refreshed every 150 seconds.↩︎"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "href": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "title": "Convert a Word table to Markdown",
    "section": "tl;dr",
    "text": "tl;dr\nI made a function that shouldn’t need to exist in an ideal world: it takes a copied Microsoft Word table and outputs a Markdown version (well, a Govspeak version)."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "href": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "title": "Convert a Word table to Markdown",
    "section": "Govspeak when you’re spoken to",
    "text": "Govspeak when you’re spoken to\nI’ve written about three painful things recently:\n\nForcing data scientists to expose their tools so we can all use and learn from them.\n‘Rectangularising’ tables scraped out of a Word document via the {officer} package.\nEasier ways to coerce dataframe columns to their ‘intended’ data type.\n\nToday I bring you a terrible Cerberus with these three heads1.\nThe challenge: sometimes public sector statisticians produce Word documents that need to be converted to a special type of simplified plaintext Markdown, called Govspeak, before they can be uploaded for publication as HTML files on GOV.UK2.\nThis is fine: we have specific publishing specialists who can take care of it. It can be a little tedious, however. What if we could speed up and make more efficient the process of converting from Word to Govspeak?\nThere’s a specific Govspeak converter online that you can paste into. But it doesn’t have full coverage of the things that might appear in a Word doc, including tables. Other online converters exist, but I don’t think we should rely on third parties that are probably intended for producing general Markdown rather than Govspeak, specifically"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "href": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "title": "Convert a Word table to Markdown",
    "section": "Markdown? Word up.",
    "text": "Markdown? Word up.\nI’ve started an R package called {wordup} that aims to take a Word document and convert it to Govspeak. It’s early days in the sense that it doesn’t yet do, well… very much. But I thought the package name was funny (if unoriginal) and worth squatting. Maybe I’ll never get around to developing it, who knows.\nTo install (which is really not worth it right now, unless you want to raise an issue or pull request):\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/wordup\")\nlibrary(wordup)\n\nFor now, the principle is that you can unzip a Word document to expose a bunch of xml files (yet another thing I’ve been writing about recently, lol) that contain all the information needed to build the Word document3. As such, you can read that xml and extract all the information, styles, etc, and massage it programmatically into Govspeak format.\nPart of the process will involve taking a Word table, specifically, and converting it to a Govspeak-friendly form. I figured this might be a nice standalone tool in its itself, so I had a stab at what it could look like."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "href": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "title": "Convert a Word table to Markdown",
    "section": "Fantabulars",
    "text": "Fantabulars\nSo right now the wordup::table_to_govspeak() function (whose name could change at any time) does three things:\n\nHandles inputs.\nGuesses data types.\nApplies extra styles.\n\nYou can either (a) copy-paste a Word table into the function, or (b) simply copy it to the clipboard, where it can be read by the function using the {clipr} package. The function will take the string—which is basically tabs (\\t) to indicate gaps between cells and newlines (\\n) to indicate rows—and reorient it initially into a dataframe.\nOf course, all the columns will be character-class at this point. We can immediately run type.convert() over the whole dataframe to coerce each column to a more appropriate data type, if appropriate. So a character column composed of c(\"10\", \"20\", \"30) will become a numeric column of values c(10, 20, 30). But this doesn’t work for numeric values that have symbols in them, like commas as thousands separators (1,200), per cent symbols (82%) and placeholder markers to indicate things like suppressed values ([c])4. To get around this, we can strip the nuisance characters and then see if what remains looks like a number.\nFinally, there’s some specific features of Govspeak tables that need attention. It’s acceptable to have row labels, where each value in every cell of the first column should be prefaced with an octothorpe (#), and totals columns, where the entire row should be emboldened with double-asterisks (**) either side of the cells’ values.\nWhat results can be sort of… magic really. You copy a Word table in its entirety to your clipboard, run the function, and bang: the Govspeak Markdown is returned. You can see this in action in the gif at the top of this page.\nSo I can literally copy a table like this to my clipboard:\n\n\n\nColumn 1\nColumn 2\nColumn 3\nColumn 4\nColumn 5\n\n\n\n\nX\n100\n1,000\n1%\n15\n\n\nY\n200\n2,000\n2%\n12\n\n\nZ\n300\n3,000\n3%\n[c]\n\n\nTotals\n600\n6,000\n6%\n[c]\n\n\n\nAnd run this:\n\nwordup::table_to_govspeak()\n\nTo print this (and have it copied to your clipboard as the message says):\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| X | 100 | 1,000 | 1% | 15 |\n| Y | 200 | 2,000 | 2% | 12 |\n| Z | 300 | 3,000 | 3% | [c] |\n| Totals | 600 | 6,000 | 6% | [c] |\nThe output table has been written to the clipboard.\nBoom. Note the crucial feature that the third, fourth and fifth columns are recognised as numeric—despite containing the strings ,, % and [c]—and therefore right-aligned (------:). This is entirely due to the argument ignore_regex, which defaults to removing commas, percentage symbols or anything in square brackets before it guesses what data type the column is5.\nAnd we can do fancy things like:\n\nwordup::table_to_govspeak(\n  has_row_titles = TRUE,\n  totals_rows = 4L\n)\n\nWhich outputs this thing:\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| # X | 100 | 1,000 | 1% | 15 |\n| # Y | 200 | 2,000 | 2% | 12 |\n| # Z | 300 | 3,000 | 3% | [c] |\n| # **Totals** | **600** | **6,000** | **6%** | **[c]** |\nThe output table has been written to the clipboard.\nOf course, in practice this might get a little more complicated if you need to manually specify in the function declaration that there’s a column of row titles or some totals rows. Pish-posh. The point is that I think this is probably better than trying to (a) write the Govspeak table by hand or (b) trying to use the Govspeak converter, which just doesn’t work for this task. This also has mild, opinionated, Govspeak-related benefits over using a straightforward knitr::kable().\nIs this perfect? Ahaha, no. There’s a lot to add or improve, but I think this is a decent start and solves a (niche) problem for now6."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#environment",
    "href": "posts/2023-06-21-wordup-tables/index.html#environment",
    "title": "Convert a Word table to Markdown",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-04 09:56:28 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] wordup_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#footnotes",
    "href": "posts/2023-06-21-wordup-tables/index.html#footnotes",
    "title": "Convert a Word table to Markdown",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWrangling Word content with R is certainly a Herculean labour, amirite, classics fans? I know there are classicists who write R. Own up. There’s no shame. Adriana is one of you.↩︎\nIn case you were wondering: yes, this is a ‘solved’ problem where teams use Reproducible Analytical Pipelines (RAP) to produce statistical publications. They can convert directly from R Markdown to Govspeak using something like {mojspeakr}. But not every team is using R to produce their statistical publications. The wider R community on social media may be aware of Bruno’s recently-released book on the principles of RAP. The RAP movement started in the UK government but appears to be taking off internationally.↩︎\nThis technique is currently in the news (if you move in certain geeky circles, which you do, because you’re reading this), because an unzipped Excel file appeared to expose a… suspicious sequence of formulae executions that underpinned a published academic paper.↩︎\nThere’s specific best-practice government guidance for the symbols that should be used for this purpose, such as ‘[c]’ to mean that the data is suppressed due to reasons of confidentiality.↩︎\nThere are pre-existing functions that can parse numbers containing strings, like readr::parse_number(\"10%\") returns 10. But this particular function can’t handle arbitrary strings in your number, like the placeholder [c] used to represent suppressed values.↩︎\nI think you might be used to that by now if you’ve read this blog more than once.↩︎"
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html",
    "href": "posts/2019-08-25-holepunch-drake/index.html",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "",
    "text": "drake-meme.jpg"
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html#tldr",
    "href": "posts/2019-08-25-holepunch-drake/index.html#tldr",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "tl;dr",
    "text": "tl;dr\nBinder lets people explore your GitHub-based R code in a live, browser-based instance of RStudio – for free. Set-up for R projects is quick with {holepunch}.\nI’ve used {holepunch} on my {drake} demo repo. Click the ‘launch binder’ badge in the repo’s README."
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html#icing-on-the-drake",
    "href": "posts/2019-08-25-holepunch-drake/index.html#icing-on-the-drake",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "Icing on the {drake}",
    "text": "Icing on the {drake}\nI wrote about how Will Landau’s excellent {drake} package could be used to minimise errors and speed up the production of statistical reports by the UK government. I put a demo of this in a GitHub repo.\nThere are two things I’d like:\n\nTo improve trust further, citizens should be able to quickly open and explore the code behind a statistical report in the environment that the analyst was actually working in, with the correct R version and package dependencies.\nWhen I’m demonstrating the {drake} example, everyone in the room should have access to the same, consistent environment. This will minimise technical issues and ensure the code is being run in the intended environment.\n\nTurns out that these issues can be solved with Binder. Point 1 is addressed by adding a special badge to your README. This helps solve Point 2, proven by Landau in his {learndrake} course-in-a-package repo.\nBut what is Binder?"
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html#in-a-binder",
    "href": "posts/2019-08-25-holepunch-drake/index.html#in-a-binder",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "In a Bind(er)",
    "text": "In a Bind(er)\nBinder is an open source project that makes it easier to share and explore the code from a GitHub repository.\nThe repo owner specifies an environment (e.g. R version and package dependencies) and people can click a badge in the README to launch the code in a live instance of RStudio. Magic.\nHere’s what the Binder badge looks like in the README:\n\nClick it to launch the Binder loading page:\n\nThat results in RStudio being launched in the browser with all the folders and files from the repo:\n\nSome caveats:\n\nThis may take a short while to load. You may need to retry the build or try a different browser if it fails to load at all.\nIt may not be available for free forever.\nThere’s a maximum repo size of a couple of gigabytes."
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html#holepunch-drunk",
    "href": "posts/2019-08-25-holepunch-drake/index.html#holepunch-drunk",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "{holepunch}-drunk",
    "text": "{holepunch}-drunk\nBut wait: Karthik Ram has made the {holepunch} package so that R users can set up Binder for their repo in a just a few lines of code.\nDo read the docs, but after install.packages(\"holepunch\") and library(holepunch):\n\nwrite_compendium_description() to create a DESCRIPTION file listing the repo’s dependencies (just like what you need for an R package)\nwrite_dockerfile() to set up a dockerfile (from The Rocker Project) that installs RStudio and an R version of your choice\ngenerate_badge() to get some code for a ‘launch binder’ badge that you can copy-paste to your repo’s README\n\nThen you can push the changes to GitHub and the ‘launch binder’ badge will appear your README. Clicking it generates an RStudio instance with the specifications as per the DESCRIPTION and dockerfile.\nSo, not many steps to achieve something this cool!\nRead Karl Broman’s blog post for another view from an R user and check out Karthik Ram’s rstudio::conf 2019 talk (see the slides or watch the video)."
  },
  {
    "objectID": "posts/2019-08-25-holepunch-drake/index.html#environment",
    "href": "posts/2019-08-25-holepunch-drake/index.html#environment",
    "title": "{holepunch} a {drake} and put it in a Binder",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-24 20:40:08 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#tldr",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#tldr",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "tl;dr",
    "text": "tl;dr\nVersion 1.0 of the {rtweet} package has been released with breaking changes. I’ve updated the R script of londonmapbot so that its scheduled GitHub Action doesn’t fail.\n\n Note\nlondonmapbot no longer posts to Twitter due to API changes. It can be found on Mastodon instead at botsin.space/@londonmapbot. You can read about that in a more recent post."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#new-hymn-sheet",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#new-hymn-sheet",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "New hymn sheet",
    "text": "New hymn sheet\nI wrote a Twitter bot a while ago called londonmapbot. See the recent talk at LondonR or the blogpost about its inception.\nBasically, an R script runs on schedule via a GitHub Action. It generates a random point in Greater London and pulls a corresponding satellite image from MapBox. The picture, the coordinates and an OpenStreetMap link are then posted to Twitter with the {rtweet} package.\nI updated recently the R script in the londonmapbot source code due to some breaking changes in {rtweet}, which Lluís Revilla Sancho recently bumped to the landmark version 1.0. Congratulations!"
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#change-your-tune",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#change-your-tune",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Change your tune",
    "text": "Change your tune\nI made two major changes to the londonmapbot R script given {rtweet} v1.0:\n\nI used rtweet_bot() to authorise with the Twitter API, instead of create_token()\nI provided alt text with the media_alt_text argument to post_tweet()\n\nOther folks who use the same approach as londonmapbot will likely need to make these fundamental changes as well.1\nI also made a third change—to specify the filetype of the downloaded MapBox image—that will only be relevant if you forked londonmapbot or if your tweets use a downloaded image.\n\n1. Authentication\nYou need to authenticate with the Twitter API before a tweet can be posted.\nPrior to {rtweet} v1.0 you provided your tokens and keys in the create_token() function, but this will now fail with the error create_token() was deprecated in rtweet 1.0.0..\nThere are now three options for passing tokens and keys, depending on the need: rtweet_app(), rtweet_user() and rtweet_bot(). The last of these is what we need, because:\n\n[It] authenticates a bot that takes actions on behalf of an app [which] is most appropriate if you want to create a Twitter account that is run by a computer, rather than a human\n\nAs with create_token(), we still need to provide the api_key, api_secret, access_token and access_secret. As outlined in the first londonmapbot blogpost, these can be stored as named secrets in the GitHub repo itself and called into the environment with Sys.getenv().\nSo, I changed the R code to this:\n\nlondonmapbot_token &lt;- rtweet::rtweet_bot(\n  api_key       = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  api_secret    = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token  = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\nWhere it was previously this:\n\nlondonmapbot_token &lt;- rtweet::create_token(\n  app = \"londonmapbot\",\n  consumer_key    = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  consumer_secret = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token    = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret   = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\nNote that you no longer need to pass the app name as an argument and that you use api_* rather than consumer_* in the arguments.\n\n\n2. Alt text\nYou can no longer post an image without alt text, which is a positive move for the package. If you try to upload without alt text, you’ll get Error: Media and alt_text must be character vectors.\nTo add alt text, you must add the argument media_alt_text to the post_tweet() function.\nSince the sampled location is different in every londonmapbot tweet, it’s not ideal to provide a single blanket statement for all images that are returned from MapBox. Sometimes the image will contain an airport, sometimes the Thames, usually a golf course.\nFor now I’ve settled on a fixed string that will be posted as the alt text for every image. This is better than nothing, but should be improved so that it’s more dynamic.\nMaybe we could infer something from the average colour of the image (I wrote about this before) or maybe predict what the terrain is, given there’s plenty of training data from old londonmapbot tweets.\nRegardless, I added alt text to the code like this:\n\nalt_text &lt;- paste(\n  \"A satellite image of a random location in Greater London,\",\n  \"provided by MapBox. Typically contains a residential or\",\n  \"industrial area, some fields or a golf course.\"\n)\n\nrtweet::post_tweet(\n  status         = latlon_details,\n  media          = temp_file,\n  media_alt_text = alt_text,\n  token          = londonmapbot_token\n)\n\nWhere it was previously like this:\n\nrtweet::post_tweet(\n  status = latlon_details,\n  media  = temp_file,\n  token  = londonmapbot_token\n)\n\nSee the image at the top of this blogpost for an example of the alt text now provided to each londonmapbot tweet.\n\n\n3. File extension\nThe R script behind londonmapbot downloads a MapBox satellite image to a temporary file created with tempfile(). It was always bad practice to omit the argument fileext = \".jpeg\" from this function, which is used to provide a file extension to the temporary filepath of the downloaded image.\nI noticed that the absence of an explicit file extension seemed to be causing an error in the execution of the R script, so I made sure to change the code to this:\n\ntemp_file &lt;- tempfile(fileext = \".jpeg\")\ndownload.file(img_url, temp_file)\n\nFrom this:\n\ntemp_file &lt;- tempfile()\ndownload.file(img_url, temp_file)\n\nA subtle change, but a necessary one. You may need to do this too if you followed what londonmapbot was doing previously."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#rest",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#rest",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Rest",
    "text": "Rest\nThis post may not have impacted you if you aren’t the in niche user group of ‘people who may have forked or used a repo template for londonmapbot to adapt and make their own Twitter bot based on {rtweet} and GitHub Actions, or otherwise used it as inspiration to create their own bot’.2\nBut it’s worth recording this in long-form in case you ever come across the sorts of {rtweet} errors I’m talking about here."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#environment",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#environment",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:12:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#footnotes",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#footnotes",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat may well be a number of people in the Twitter list called ‘The mapbotverse’, which is a collection of 25 or so bots that I think use code from, or were inspired by, londonmapbot.↩︎\nBut you too could join us in this really neat club for cool folks! Follow the instructions in my LondonR talk and take a look at Oscar Baruffa’s guide.↩︎"
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#tldr",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#tldr",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "tl;dr",
    "text": "tl;dr\nCan you match the tidyverse function to its package? I used {learnr} innapropriately to hack a ‘tidyquiz’ to test you.\nThe app isn’t hosted online, but it’s in a package that you can install and run locally with the very latest tidyverse functions:\n\nremotes::install_github(\"matt-dray/tidyquiz\") to install {tidyquiz} (it’s a package!)\nlibrary(tidyquiz) to load it\nlearnr::run_tutorial(\"tidy\", package = \"tidyquiz\") to open in your browser"
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#the-problem",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#the-problem",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "The problem",
    "text": "The problem\nI saw a (probably) tongue-in-cheek tweet from Ryan Timpe:\n\nHardest part about #rstats package development: remembering which functions are from {dplyr} and which are from {tidyr}.\n\nIt’s easy enough to get out of this pickle, but maybe there’s a deeper problem? What if the purpose of each tidyverse isn’t clear enough?1 Is there too much arbitrary jargon in the tidyverse?\nEnjoy your existential crisis. Meanwhile, I’ve made a little quiz to see if you can remember whether unnest() is from {dplyr} or {tidyr}2. In fact, it’s an interactive multi-choice test that presents you a random function from the tidyverse and challenges you to select the correct package."
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#step-0-the-approach",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#step-0-the-approach",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Step 0: the approach",
    "text": "Step 0: the approach\nI wanted:\n\nTo get a tidy data frame of all the tidyverse package-function combos\nA user to be presented with an interactive question about one of these tidyverse functions\nThe ability to generate a new question from within the document\nTo share this quiz easily, without a server\n\nRead the rest of this post to see how I tackled these. Or, you know, spoilers:\n\nThe tidyverse_packages() function from {tidyverse}\nThe {learnr} package\nAn actionButton() and Shiny reactivity\nYou can put a {learnr} quiz in a package and call it from there!"
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#step-1-package-function-combos",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#step-1-package-function-combos",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Step 1: package-function combos",
    "text": "Step 1: package-function combos\nThe {tidyverse} package is a package that loads packages.3 It’s a convenient way to load the eight core packages of the tidyverse.\n\nsuppressPackageStartupMessages(library(tidyverse))\n\nBut there’s more than these core eight. To access a list of functions for each package, we first need to load all the packages. We can get a character vector of them all with tidyverse_packages().\n\ntidy_pkgs &lt;- tidyverse_packages()\ntidy_pkgs\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\n\n Note\nI re-rendered this post in August 2023, when more packages had been added to the tidyverse. For example, the {conflicted} package, which is why I have to namespace-qualify my use of filter() later in this post!\n\n\nWe can pass this character vector to p_load(). This convenient function from {pacman} installs and loads them all for us.\n\nlibrary(pacman)\n\np_load(\n  char = tidy_pkgs,\n  character.only = TRUE  # read elements of character vector\n)\n\nNow we can get the functions from each package by mapping over them with {purrr} and {pacman}’s p_functions().\n\ntidy_funs &lt;- tidy_pkgs %&gt;% \n  enframe(name = NULL, value = \"package\") %&gt;%  # make tibble\n  mutate(\n    functions = map(\n      package,  # for each package...\n      ~p_functions(.x, character.only = TRUE)  # ...get the functions within\n    )\n  ) %&gt;% \n  unnest()  # unpack the listcol elements\n\nWarning: `cols` is now required when using `unnest()`.\nℹ Please use `cols = c(functions)`.\n\n\nHere’s a small sample:\n\nsample_n(tidy_funs, 10)  # random sample\n\n# A tibble: 10 × 2\n   package    functions          \n   &lt;chr&gt;      &lt;chr&gt;              \n 1 ggplot2    draw_key_abline    \n 2 ggplot2    geom_curve         \n 3 cli        pb_percent         \n 4 httr       oauth_service_token\n 5 conflicted conflict_prefer    \n 6 ggplot2    GeomErrorbar       \n 7 cli        bg_red             \n 8 rstudioapi documentSaveAll    \n 9 httr       hmac_sha1          \n10 dbplyr     sql_quote          \n\n\nOut of interest we can look at the packages with the most and fewest functions:\n\ncount(tidy_funs, package, sort = TRUE) %&gt;% slice(1:5)\n\n# A tibble: 5 × 2\n  package       n\n  &lt;chr&gt;     &lt;int&gt;\n1 ggplot2     536\n2 rlang       440\n3 dplyr       293\n4 cli         231\n5 lubridate   205\n\ncount(tidy_funs, package) %&gt;% arrange(n) %&gt;% slice(1:5)\n\n# A tibble: 5 × 2\n  package        n\n  &lt;chr&gt;      &lt;int&gt;\n1 dtplyr         2\n2 conflicted     5\n3 tidyverse      6\n4 broom          9\n5 ragg          10\n\n\nAnother source of confusion might be that some functions exist in multiple packages. How many functions?\n\ncount(tidy_funs, functions, sort = TRUE) %&gt;% \n  dplyr::filter(n &gt; 1) %&gt;%\n  nrow()\n\n[1] 111\n\n\nOkay, we have our data set, so let’s get quizzical."
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#step-2-interactive-questions-with-learnr",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#step-2-interactive-questions-with-learnr",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Step 2: interactive questions with {learnr}",
    "text": "Step 2: interactive questions with {learnr}\nThe {learnr} package helps you turn an R Markdown document into an interactive tutorial with a little help from Shiny. One option is to create a multiple-choice question, which is exactly what we need.\nI should say that {learnr} wasn’t really intended for what I’ve done – it’s better suited to longform tutorials – but using it means that I didn’t have to write the logic for a multi-choice quiz question. Shrug.\nHaving installed the package and started a {learnr}-flavoured R Markdown4 we can create a question inside a code chunk in this form:\n\nquiz(\n  caption = \"Question 1\",\n  question(\n    text = \"What is Pokemon #399?\",  # question\n    answer(\"Bidoof\"), correct = TRUE),  # right answer\n    answer(\"Drifloom\"),   # wrong\n    answer(\"Pyukumuku\"),  # wrong\n    answer(\"Rayquaza\"),   # wrong\n    random_answer_order = TRUE  # answers ordered randomly\n  )\n)\n\nBut this example is hard-coded. In our case we want to replace the subject of the question and the answers any time we want to be presented with a new question.\nLooks like we’ll need a button for users to press to signal that they want a new question."
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#step-3-generate-new-questions-with-shiny",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#step-3-generate-new-questions-with-shiny",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Step 3: generate new questions with Shiny",
    "text": "Step 3: generate new questions with Shiny\nSince {learnr} operates in a Shiny runtime in our R Markdown file, it’s no problem to use Shiny’s actionButton().\n\nactionButton(\"goButton\", \"Get Question\")  # button\n\nYou can press the button in the app to generate a new seed base don the current time and date. The seed is then used to randomly select a new question for the user.\nTo make this reactive – so that nothing will happen until the button is pressed – we can write Shiny server code in an R Markdown chunk by setting context=\"server\" in the chunk options. So here’s how we get a new seed after clicking:\n\nseed &lt;- eventReactive(\n  input$goButton,\n  {\n    seed_temp &lt;- as.numeric(Sys.time())\n    return(seed_temp)\n  }\n)\n\nThen our code needs to sample a row from the full data frame of package-function combos and isolate the name of the function the user will be quizzed on. This code is within eventReactive() and will only trigger when the button has been activated. Second, we use renderText() to take the function name and paste it into a string to create our question.\n\n# Set the reactive element\nfun_name &lt;- eventReactive(\n  input$goButton,  # on input\n  { \n    seed_val &lt;- seed()  # the newly-generated seed value\n    set.seed(seed_val)  # user-selected value is seed value\n    fun_sample &lt;- sample_n(tidy_funs, 1)  # sample a package-function combo\n    fun_name &lt;- select(fun_sample, functions) %&gt;% pull()  # just the function name\n    return(fun_name)  # return the package value\n  }\n)\n\n# Set the output\n# Generate a question that includes the sampled function name \noutput$fun_name_out &lt;- renderText({\n  paste0(\"The function `\", fun_name(), \"` is from which tidyverse package?\")\n})\n\nWe can repeat this for getting the right answer and alter the code slightly to generate a few wrong answers. A wrong answer is selected randomly from the data frame of tidyverse functions, but only once the correct answer and already-selected wrong answers have been removed. I’ve also coded it so that any package that has a function with the same name – a conflict – will also be removed before a ‘wrong’ answer is chosen.\nSo rather than the hard-coded example of a multi-choice question in Step 2, our quiz question code will look like this:\n\nquiz(\n  caption = \"Question \",\n  question(\n    text = as.character(textOutput(\"fun_name_out\")),\n    answer(as.character(textOutput(\"ans_correct_out\")), correct = TRUE),\n    answer(as.character(textOutput(\"ans_wrong1_out\"))),\n    answer(as.character(textOutput(\"ans_wrong2_out\"))),\n    answer(as.character(textOutput(\"ans_wrong3_out\"))),\n    random_answer_order = TRUE\n  )\n)\n\nSo now the text outputs will be rendered into the quiz question and this won’t change until the the ‘Get Question’ button is clicked.\nActually, that’s sort-of a lie. {learnr} remembers how it’s users have performed; it saves their progress. To erase this, we need to click ‘Start Over’ from the menu pane to clear that memory."
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#get-the-code",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#get-the-code",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Get the code",
    "text": "Get the code\nBrowse the code on GitHub and leave an issue with thoughts or suggestions.\nFor example, it could definitely be improved if the user got a set of 10 questions that were graded to give a final mark. Maybe I’ll implement this one day.\nFor now, give it a go and let me know if you ever find out if drop_na() is in {dplyr} or {tidyr}.5"
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#environment",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#environment",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 22:56:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] xml2_1.3.5          rvest_1.0.3         rstudioapi_0.15.0  \n [4] rlang_1.1.1         reprex_2.0.2        readxl_1.4.2       \n [7] ragg_1.2.5          pillar_1.9.0        modelr_0.1.11      \n[10] magrittr_2.0.3      jsonlite_1.8.7      httr_1.4.6         \n[13] hms_1.1.3           haven_2.5.2         googlesheets4_1.1.1\n[16] googledrive_2.1.1   dtplyr_1.3.1        dbplyr_2.3.2       \n[19] cli_3.6.1           conflicted_1.2.0    broom_1.0.5        \n[22] pacman_0.5.1        lubridate_1.9.2     forcats_1.0.0      \n[25] stringr_1.5.0       dplyr_1.1.2         purrr_1.0.1        \n[28] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1       \n[31] ggplot2_3.4.2       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      xfun_0.39         htmlwidgets_1.6.2 gargle_1.5.1     \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.1       generics_0.1.3   \n [9] fansi_1.0.4       pkgconfig_2.0.3   data.table_1.14.8 lifecycle_1.0.3  \n[13] compiler_4.3.1    textshaping_0.3.6 munsell_0.5.0     fontawesome_0.5.1\n[17] htmltools_0.5.5   yaml_2.3.7        cachem_1.0.8      tidyselect_1.2.0 \n[21] digest_0.6.33     stringi_1.7.12    fastmap_1.1.1     grid_4.3.1       \n[25] colorspace_2.1-0  utf8_1.2.3        withr_2.5.0       scales_1.2.1     \n[29] backports_1.4.1   timechange_0.2.0  rmarkdown_2.23    cellranger_1.1.0 \n[33] memoise_2.0.1     evaluate_0.21     knitr_1.43.1      glue_1.6.2       \n[37] DBI_1.1.3         R6_2.5.1          systemfonts_1.0.4 fs_1.6.3"
  },
  {
    "objectID": "posts/2019-03-18-tidyverse-quiz/index.html#footnotes",
    "href": "posts/2019-03-18-tidyverse-quiz/index.html#footnotes",
    "title": "A tidyverse functions quiz with {learnr}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSeems even Hadley gets it wrong sometimes.↩︎\nAm I tricking you? Is it actually from neither?↩︎\nThe meme writes itself. Or rather, you can do it for me.↩︎\nAfter installing {learnr} you can go to new R Markdown &gt; From Template &gt; Interactive Tutorial.↩︎\nAm I tricking you? Is it actually from neither?↩︎"
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html",
    "href": "posts/2018-07-12-accessible-accessibility/index.html",
    "title": "How accessible is my post about accessibility?",
    "section": "",
    "text": "The accessibility empathy lab at the Government Digital Services building"
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#tldr",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#tldr",
    "title": "How accessible is my post about accessibility?",
    "section": "tl;dr",
    "text": "tl;dr\nKeep yourself honest by checking how accessible your digital work is. Tenon is a web-based tool that can help with this."
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#digital-accessibility",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#digital-accessibility",
    "title": "How accessible is my post about accessibility?",
    "section": "Digital accessibility",
    "text": "Digital accessibility\nI wrote about an accessibility workshop at the recent Sprint 18 conference.\nI’ve since been to a more in-depth workshop with Government Digital Service (GDS), who have just launched the latest version of their ‘testing for accessibility’ guidance in the Service Manual and also the GOV.UK Design System, which contains reusable GOV.UK styles, patterns and components with accessibility in mind.\nAt the session I learnt a bit more about some web-based services that can evaluate web pages against the Web Content Accessibility Guidelines (WCAG 2.0). Tenon and WAVE were mentioned specifically and you can find more in the World Wide Web Consortium’s (W3C) list of web accessibility evaluation tools.\nWhat better way to investigate one of these services that to test it on myself? I’m going to assess the accessibility of my post about accessibility (at time of writing). So meta.\n\nTenon example\nTenon is a web service that tests for compliance against WCAG 2.01. It reports back on errors and warnings and assigns an order of priority for fixing the problems.\nTenon offers an API for automating accessibility tests. You can test the service in your browser by inputting a URL into the search box on their website."
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#output",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#output",
    "title": "How accessible is my post about accessibility?",
    "section": "Output",
    "text": "Output\nThe service reported back that 4 of 74 tests failed for the post.\n\n\n\nIn-browser results of Tenon’s test\n\n\nThe in-browser output also provides a CSV report of the failures. I’ve hosted my report in a GitHub Gist.\nAn example of an error is that one of my images was missing alt-text. Tenon reported:\n\nthe line of HTML code causing the error\nthe priority for fixing the issue\nthe line location in the HTML code\nthe specific WCAG 2.0 guideline that was breached\na description of why this is a problem\na link to a recommended fix for the problem\n\n\n\n\nExample of an error, where it is, and a recommended fix"
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#reflection",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#reflection",
    "title": "How accessible is my post about accessibility?",
    "section": "Reflection",
    "text": "Reflection\nNot too bad.\nThe default settings for the blog’s Hugo theme was accountable for at least one issue: the Hugo logo in the footer is missing alt-text, so it can’t be described by a screen reader.\nI also had problems where I actually did have alt-text in place. These were identified as being too long. I tried to be as descriptive as possible, but went too far. For example, I used these 24 words for one image:\n\nThumbnail views of example posters including designing for users on the autistic spectrum, for users of screen readers and for users with low vision\n\nThat’s verbose. I could do this in half the number of words:\n\nPosters by the Home Office showing the dos and don’ts of accessibility\n\nThe use of implicit headings was also flagged. This was because I had whole lines—audience questions—tagged as &lt;strong&gt; (meaning bold). It would be preferable for all section titles to use the header tags (first-level header is &lt;h1&gt;, second-level is &lt;h2&gt;, etc), since these a recognised specifically by screen readers."
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#behaviour-change",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#behaviour-change",
    "title": "How accessible is my post about accessibility?",
    "section": "Behaviour change",
    "text": "Behaviour change\nI will:\n\nkeep my alternative text short but descriptive\nuse explicit headers using the HTML header tags (&lt;h1&gt;, etc)\ninvestigate default settings for accessibility before using them\n\nOther improvements could be made. For example, I also ran the webpage through WAVE web accessibility tool and one of the errors was the low contrast between the white background and the light grey of the date and author name. These could be made darker.\nThe obvious next step is to assess the accessibility of my post that assesses the accessibility of my post about accessibility. Or perhaps the world isn’t ready for accessibility inception.\n\n\n\n‘Design accessible services’ advice posters made by the Home Office"
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#environment",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#environment",
    "title": "How accessible is my post about accessibility?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 22:38:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-07-12-accessible-accessibility/index.html#footnotes",
    "href": "posts/2018-07-12-accessible-accessibility/index.html#footnotes",
    "title": "How accessible is my post about accessibility?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOther tools are available. I mention this service because it was discussed specifically in the workshop.↩︎"
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#tldr",
    "href": "posts/2022-01-14-wordle/index.html#tldr",
    "title": "Wordle, twirdle and eldrow",
    "section": "tl;dr",
    "text": "tl;dr\nTwo toy R functions for playing with Wordle results: twirdle() extracts gameplay data from tweets, and eldrow() finds potential prior guesses given the answer.\n\n Note\nThe Twitter API is pretty borked as of mid-2023, so the functions in this post are unlikely to work anymore."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#whats-the-wordle",
    "href": "posts/2022-01-14-wordle/index.html#whats-the-wordle",
    "title": "Wordle, twirdle and eldrow",
    "section": "What’s the Wordle?",
    "text": "What’s the Wordle?\nNothing is more zeitgeisty right now than Wordle, a once-a-day web-based five-letter-word-guessing puzzle-logic game.\nThe app lets you copy your results in a consistent format for pasting into a tweet or whatever.\n\nIt begins with a string of meta information, ‘Wordle X Y/Z’, where X is the edition number, Y is the attempts taken and Z is the maximum allowed guesses. Then there’s a grid of coloured emoji squares, where each row represents a guessed word and each emoji a letter.\nGreen emojis (orange in colorblind mode) represent a letter in the correct place, yellow (blue in colorblind mode) in the wrong place and white for an incorrect letter (or black if playing in dark mode). The emojis obscure your guesses so that people can see how well you did without spoiling the answer.\nFolks have already put together some neat R tools, like solvers and ways to play in the console or in other languages. See mikefc’s {wordle} R package and Pachá’s Shiny app, for example."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#wordle-up",
    "href": "posts/2022-01-14-wordle/index.html#wordle-up",
    "title": "Wordle, twirdle and eldrow",
    "section": "Wordle up",
    "text": "Wordle up\nSurprise: I haven’t actually played the game.1\nBut that didn’t stop me from writing a couple of modest functions to practice my regex and base-R skills: twirdle() and eldrow().2\nAs ever, I can call them ‘toy’ functions and get away without proper error-checking and code optimisation.\n\ntwirdle\nThe consistent Wordle template makes it straightforward to extract people’s results from tweets. I’ve made the twirdle() function to do this.3\ntwirdle() makes use of regular expressions and functions like regmatches() and regexpr() to extract:\n\nthe Wordle edition number, e.g. ‘206’\nthe attempts required, e.g. ‘4’, but also failures symbolised with ‘X’\nthe maximum allowed attempts (max), i.e. ‘6’\nwhether the user was playing in light or dark mode\nwhether the user was using colorblind mode\na string of characters representing the emoji grid, e.g. \"YG----G-GYGGGGG\", to symbolise a correct guess (i.e. a Green emoji), a correct letter but in the wrong place (i.e. Yellow), and a miss (-)\nthe tweet status_id so you can visit the original tweets\n\n\nCode\n\n\nClick for the full twirdle() function definition\n\n\ntwirdle &lt;- function(tweets) {\n  \n  g   &lt;- \"\\U1F7E9\"\n  o   &lt;- \"\\U1F7E7\"\n  y   &lt;- \"\\U1F7E8\"\n  blu &lt;- \"\\U1F7E6\"\n  bla &lt;- \"\\U2B1B\"\n  w   &lt;- \"\\U2B1C\"\n  \n  rx_all   &lt;- paste(g, o, y, blu, bla, w, sep = \"|\")\n  rx_right &lt;- paste(g, o, sep = \"|\")\n  rx_place &lt;- paste(y, blu, sep = \"|\")\n  rx_wrong &lt;- paste(bla, w, sep = \"|\")\n  rx_color &lt;- paste(o, blu, sep = \"|\")\n\n  tweets$meta &lt;- regexpr(\n    \"Wordle \\\\d{1,} [\\\\d{1}|X]/\\\\d{1}\",\n    tweets$text,\n    perl = TRUE\n  )\n  \n  tweets$meta &lt;- setNames(\n    tweets$meta, \n    ifelse(tweets$meta &lt; 0, FALSE, TRUE)\n  )\n  \n  tweets$meta &lt;- ifelse(\n    names(tweets$meta),\n    regmatches(tweets$text, tweets$meta),\n    NA_character_\n  )\n  \n  tweets &lt;- tweets[!is.na(tweets$meta), ]\n  \n  tweets$edition &lt;- as.numeric(\n    regmatches(\n      tweets$meta, \n      regexpr(\"\\\\d{1,}\", tweets$meta)\n    )\n  )\n  \n  tweets$attempts &lt;- regmatches(\n    tweets$meta,\n    regexpr(\"[\\\\d{1}|X](?=/)\", tweets$meta, perl = TRUE)\n  )\n  \n  tweets$attempts &lt;- ifelse(\n    tweets$attempts == \"X\",\n    NA_character_,\n    tweets$attempts\n  )\n  \n  tweets$attempts &lt;- as.numeric(tweets$attempts)\n  \n  tweets$allowed &lt;- as.numeric(\n    regmatches(\n      tweets$meta, \n      regexpr(\"(?&lt;=/)\\\\d{1}\", tweets$meta, perl = TRUE)\n    )\n  )\n  \n  tweets$grid &lt;- regmatches(\n    tweets$text, \n    gregexpr(rx_all, tweets$text) \n  )\n  \n  tweets$grid &lt;- lapply(\n    tweets$grid, \n    function(x) paste(x, collapse = \"\")\n  )\n  \n  tweets$colorblind &lt;- ifelse(\n    grepl(rx_color, tweets$grid), TRUE, FALSE\n  )\n  \n  tweets$mode &lt;- ifelse(\n    grepl(bla, tweets$grid), \"dark\",\n    ifelse(grepl(w, tweets$grid), \"light\", \"unknown\")\n  )\n  \n  tweets$grid &lt;- gsub(rx_right, \"G\", tweets$grid)\n  tweets$grid &lt;- gsub(rx_place, \"Y\", tweets$grid)\n  tweets$grid &lt;- gsub(rx_wrong, \"-\", tweets$grid)\n  \n  tweets[, c(\"edition\", \"attempts\", \"allowed\", \"mode\",\n             \"colorblind\", \"grid\", \"status_id\")]\n  \n}\n\n\nI also put the code for the function in a GitHub Gist.\n\n\nExample\nTo give an example of twirdle() in action, let’s first grab a small number of tweets using the {rtweet} package by Mike Kearney. I think it’s best to supply the query string of search_tweets() with the word ‘Wordle’ and at least one white or black emoji (signifying an incorrect letter).4\n\ntweets &lt;- rtweet::search_tweets(\n  q = \"Wordle \\U2B1B OR \\U2B1C\",\n  n = 10,  # return 10 tweets\n  include_rts = FALSE  # no retweets\n)\n\nAnd now we can pass the returned dataframe of tweets to twirdle(). It outputs a row per tweet, but there may be fewer tweets than we asked for because the content doesn’t conform to the output provided by Wordle. Sometimes people add their own comments into the results, disrupting the expected format. There’s also a Spanish version that has ‘(ES)’ in the meta information that we’re going to exclude for our purposes.\nNote that anyone who didn’t complete the puzzle in six tries gets a score of ‘X/6’, which is returned as NA_real_ in the attempts column.\n\ntwirdle(tweets)\n\n# A tibble: 7 × 7\n  edition attempts allowed mode  colorblind grid                 status_id      \n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;      &lt;chr&gt;                &lt;chr&gt;          \n1     213        5       6 light FALSE      GY--YGGG--GGG--GGG-… 14834445690229…\n2     213        3       6 dark  FALSE      Y-----YY--GGGGG      14834445680161…\n3     213        6       6 dark  FALSE      --Y-----YG-G--G--G-… 14834445678988…\n4     213        6       6 light FALSE      -----Y------Y-G-G--… 14834445674540…\n5     213       NA       6 light FALSE      ---Y---G-YGGG--GGG-… 14834445662083…\n6     213        5       6 dark  FALSE      -G------YYGGG--GGG-… 14834445661120…\n7     213        3       6 dark  FALSE      ----Y--GY--GG--GGG-… 14834445648075…\nYou could use this to do a number of things, like calculate the mean number of attempts for each day’s puzzle, look for guess patterns at scale, or maybe see whether dark-mode users are more skilled than light-mode users.\n\n\n\neldrow\nOf course, the whole purpose of sharing an encoded emoji grid is to prevent spoilers. No-one reading your result can see the answer or your guesses.\nBut, if you do know the answer, could you backwards-engineer prior guesses from the emoji grid?\nIntroducing eldrow(),5 which does exactly this with some help from mikefc’s {wordle} package for filtering from the Wordle wordlist.6\nYou pass to it the answer and the encoding of the last guess in the form \"Y-GY-\". As per the twirdle() output, the characters G, Y and - refer to a letter in the right place, wrong place, or not in the word. The function returns a vector of all the possible words given the guess and the answer.\nOne thing it doesn’t deal with is whether people are playing in ‘hard mode’, where ‘any revealed hints must be used in subsequent guesses’. I think you could infer if someone was playing this way, but you could never be completely sure.\n\nCode\n\n\nClick for the full eldrow() definition\n\n\neldrow &lt;- function(guess, answer, words = wordle::wordle_dict){\n  \n  answer &lt;- tolower(answer)\n  guess &lt;- toupper(guess)\n  \n  guess_chars &lt;- strsplit(guess, \"\")[[1]]\n  answer_chars &lt;- strsplit(answer, \"\")[[1]]\n  \n  exact &lt;- ifelse(guess_chars == \"G\", answer_chars, \".\") |&gt;\n    paste0(collapse = \"\")\n  \n  wrong_spot &lt;- gsub(\n    \"\\\\.\", \"\", ifelse(guess_chars == \"Y\", answer_chars, \".\")\n  )\n  \n  exact_chars &lt;- regmatches(exact, gregexpr(\"\\\\w\", exact))[[1]]\n  correct_chars_table &lt;- table(\n    c(exact_chars, wrong_spot[wrong_spot != \"\"])\n  )\n  min_count &lt;- as.vector(correct_chars_table)\n  names(min_count) &lt;- names(correct_chars_table)\n  \n  possibles &lt;- wordle::filter_words(\n    words, exact, wrong_spot, min_count, min_count\n  )\n  \n  possibles &lt;- possibles[which(possibles != answer)]\n  possibles[order(possibles)]\n  \n}\n\n\nI also put the code for this in a GitHub Gist.\n\n\nExample\nSo, let’s say someone took three attempts at the word ‘shirt’7 and their first and second guesses gave encodings of \"YGG--\" then \"-GGG-\".\nWe can start by passing the answer and the encoding for the prior guess.\n\nguess_2 &lt;- eldrow(guess = \"-GGG-\", answer = \"shirt\")\nguess_2\n\n [1] \"chirk\" \"chirl\" \"chirm\" \"chiro\" \"chirp\" \"chirt\" \"chiru\" \"shire\" \"shirk\"\n[10] \"shirs\" \"third\" \"thirl\" \"whirl\" \"whirs\"\nOkay, so logicically they could have guessed any of these 14 options before their final, correct guess.\nNaturally, we can extrapolate one step further back and infer the earlier potential guesses.\nYou can iterate over these 14 possible words as the answer argument to eldrow(), setting the guess argument to the encoding for the previous attempt (i.e. \"YGG--\" was the first guess in our example).\n\nguesses_1_2 &lt;- lapply(\n  guess_2,\n  \\(x) eldrow(\"YGG--\", x)\n) |&gt; \n  lapply(\\(x) x[which(x != \"shirt\")]) |&gt;\n  setNames(guess_2)\n\nstr(guesses_1_2)\n\nList of 14\n $ chirk: chr \"thick\"\n $ chirl: chr \"thick\"\n $ chirm: chr \"thick\"\n $ chiro: chr \"thick\"\n $ chirp: chr \"thick\"\n $ chirt: chr \"thick\"\n $ chiru: chr \"thick\"\n $ shire: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ shirk: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ shirs: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ third: chr [1:13] \"ahint\" \"chirt\" \"chits\" \"shift\" ...\n $ thirl: chr [1:13] \"ahint\" \"chirt\" \"chits\" \"shift\" ...\n $ whirl: chr(0) \n $ whirs: chr(0)\nThe output is a list with elements containing the potential first guesses and is named for each of the potential second guesses. So, logically, a possible set of guesses by this imaginary person was ‘shift’ then ‘third’ then ‘shirts’.\nOf course, you can eliminate any potential second guesses that failed to yield a potential first guess, like ‘whirl’ in this example.\nYou’ll also notice a number of the potential first guesses are the same word. The more they appear, the more likely that word is to have been the actual starting guess, I suppose?\n\nwords &lt;- c()\nfor (i in guesses_1_2) {\n  words &lt;- c(words, i)\n}\n\ncounts &lt;- as.data.frame(\n  table(words),\n  responseName = \"n\"\n)\ncounts$total &lt;- sum(counts$n)\ncounts$percent &lt;- round(100 * (counts$n / counts$total), 1)\n\nlikeliest &lt;- counts[order(-counts$percent), ]\nrownames(likeliest) &lt;- NULL\nhead(likeliest, 3)\n\n  words n total percent\n1 thick 7    99     7.1\n2 chits 5    99     5.1\n3 whist 5    99     5.1\nSo, purely on the basis of this frequency, ‘thick’ was most likely to be the first guess in this contrived example. You might want to consider how likely someone is to actually submit some of these words, given their obscurity.8"
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#hurdle",
    "href": "posts/2022-01-14-wordle/index.html#hurdle",
    "title": "Wordle, twirdle and eldrow",
    "section": "Hurdle?",
    "text": "Hurdle?\nI hope you weren’t expecting anything more from this post. Maybe consider some meme variants, like Curdle, Birdle, Tetris, or this absolute banger.\nOkay, show’s over, you can stop the Wordling now."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#environment",
    "href": "posts/2022-01-14-wordle/index.html#environment",
    "title": "Wordle, twirdle and eldrow",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:17:30 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#footnotes",
    "href": "posts/2022-01-14-wordle/index.html#footnotes",
    "title": "Wordle, twirdle and eldrow",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI am simply manipulating you for clicks.↩︎\nUs pros call this ‘function-name driven development’, or FNDD. It’s very simple, you just choose a funny function name and work backwards from there.↩︎\nDO YOU SEE IT IS LIKE ‘TWITTER’ AND ‘WORDLE’ FUSED TOGETHER, LOL.↩︎\nI initially put five green emoji in the query string, since all successful Wordles end this way. But then you miss out those people who didn’t get a correct answer by the sixth guess.↩︎\nDO YOU SEE IT IS LIKE ‘WORDLE’ BACKWARDS? HA HA HA.↩︎\nThis is a little manoeuvre I like to call ‘mikefc-Driven Development’ (MDD). See a very recent post on this blog for an example.↩︎\nNo spoilers here. I have no idea if this word has ever been a correct answer in Wordle to date.↩︎\n‘Thick Chitswhist’ is a Star Wars Expanded Universe character, I think?↩︎"
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#tldr",
    "href": "posts/2019-03-04-polite-webscrape/index.html#tldr",
    "title": "Web scraping the {polite} way",
    "section": "tl;dr",
    "text": "tl;dr\nIf you webscrape with R, you should use the the {polite} package. It helps you respect website terms by seeking permission before you scrape."
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#ahoy-hoy",
    "href": "posts/2019-03-04-polite-webscrape/index.html#ahoy-hoy",
    "title": "Web scraping the {polite} way",
    "section": "Ahoy-hoy",
    "text": "Ahoy-hoy\nAh, salutations, and welcome to this blog post about polite web scraping. Please do come in. I’ll take your coat. How are you? Would you like a cup of tea? Oh, I insist!\nSpeaking of tea, perhaps you’d care to join me in genial conversation about it. Where to begin? Let’s draw inspiration from popular posts on the Tea subreddit of Reddit. I’ll fetch the post titles using the {rvest} package from Hadley Wickham and get the correct CSS selector using SelectorGadget by Andrew Cantino and Kyle Maxwell.\n\n# Load some packages we need\nlibrary(rvest)  # scrape a site\nlibrary(dplyr)  # data manipulation\n\n# CSS for post titles found using SelectorGadget\n# (This is a bit of an odd one)\ncss_select &lt;- \"._3wqmjmv3tb_k-PROt7qFZe ._eYtD2XCVieq6emjKBH3m\"\n\n# Scrape a specific named page\ntea_scrape &lt;- read_html(\"https://www.reddit.com/r/tea\") %&gt;%  # read the page\n  html_nodes(css = css_select) %&gt;%  # read post titles\n  html_text()  # convert to text\n\nprint(tea_scrape)\n\n[1] \"What's in your cup? Daily discussion, questions and stories - September 08, 2019\"                                                                 \n[2] \"Marketing Monday! - September 02, 2019\"                                                                                                           \n[3] \"Uncle Iroh asking the big questions.\"                                                                                                             \n[4] \"The officially licensed browser game of Game of Thrones has launched! Millions of fans have put themselves into the battlefield! What about you?\" \n[5] \"They mocked me. They said that I was a fool for drinking leaf water.\"                                                                             \n[6] \"100 years old tea bush on my estate in Uganda.\"                                                                                                   \n[7] \"Cold brew colors\"                                                                                                                                 \n[8] \"Finally completed the interior of my tea house only needed a fire minor touches not now it’s perfect, so excited to have this as a daily tea spot\"\nThat’ll provide us with some conversational fodder, wot wot."
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#it-costs-nothing-to-be-polite",
    "href": "posts/2019-03-04-polite-webscrape/index.html#it-costs-nothing-to-be-polite",
    "title": "Web scraping the {polite} way",
    "section": "It costs nothing to be polite",
    "text": "It costs nothing to be polite\nMercy! I failed to doff adequately my cap before entering the website! They must take me for some sort of street urchin.\nForgive me. Perhaps you’ll allow me to show you a more respectful method via the {polite} package in development from the esteemed gentleman Dmytro Perepolkin? An excellent way ‘to promote responsible web etiquette’."
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#a-reverential-bow",
    "href": "posts/2019-03-04-polite-webscrape/index.html#a-reverential-bow",
    "title": "Web scraping the {polite} way",
    "section": "A reverential bow()",
    "text": "A reverential bow()\nPerhaps the website owners don’t want people to keep barging in willy-nilly without so much as a ‘ahoy-hoy’.\nWe should identify ourselves and our intent with a humble bow(). We can expect a curt but informative response from the site—via its robots.txt file—that tells us where we can visit and how frequently.\n\n# remotes::install_github(\"dmi3kno/polite\")  # to install\nlibrary(polite)  # respectful webscraping\n\n# Make our intentions known to the website\nreddit_bow &lt;- bow(\n  url = \"https://www.reddit.com/\",  # base URL\n  user_agent = \"M Dray &lt;https://rostrum.blog&gt;\",  # identify ourselves\n  force = TRUE\n)\n\nprint(reddit_bow)\n\n## &lt;polite session&gt; https://www.reddit.com/\n##      User-agent: M Dray &lt;https://rostrum.blog&gt;\n##      robots.txt: 32 rules are defined for 4 bots\n##     Crawl delay: 5 sec\n##   The path is scrapable for this user-agent\nSuper-duper. The (literal) bottom line is that we’re allowed to scrape. The website does have 32 rules to stop unruly behaviour though, and even calls out four very naughty bots that are obviously not very polite. We’re invited to give a five-second delay between requests to allow for maximum respect."
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#give-a-nod",
    "href": "posts/2019-03-04-polite-webscrape/index.html#give-a-nod",
    "title": "Web scraping the {polite} way",
    "section": "Give a nod()",
    "text": "Give a nod()\nAhem, conversation appears to be wearing a little thin; perhaps I can interest you by widening the remit of our chitchat? Rather than merely iterating though subpages of the same subreddit, we can visit the front pages of a few different subreddits. Let’s celebrate the small failures and triumphs of being British; a classic topic of polite conversation in Britain.\nWe’ve already given a bow() and made out intentions clear; a knowing nod() will be sufficient for the next steps. Here’s a little function to nod() to the site each time we iterate over a vector of subreddit names. Our gentlemanly agreement remains intact from our earlier bow().\n\nlibrary(purrr)  # functional programming tools\nlibrary(tidyr)  # tidy-up data structure\n\nget_posts &lt;- function(subreddit_name, bow = reddit_bow, css_select){\n  \n  # 1. Agree modification of session path with host\n  session &lt;- nod(\n    bow = bow,\n    path = paste0(\"r/\", subreddit_name)\n  )\n  \n  # 2. Scrape the page from the new path\n  scraped_page &lt;- scrape(session)\n  \n  # 3. Extract from xpath on the altered URL\n  node_result &lt;- html_nodes(\n    scraped_page,\n    css = css_select\n  )\n  \n  # 4. Render result as text\n  text_result &lt;- html_text(node_result)\n  \n  # 5. Return the text value\n  return(text_result)\n  \n}\n\nSmashing. Care to join me in applying this function over a vector of subreddit names? Tally ho.\n\n# A vector of subreddits to iterate over\nsubreddits &lt;- set_names(c(\"BritishProblems\", \"BritishSuccess\"))\n\n# Get top posts for named subreddits\ntop_posts &lt;- map_df(\n  subreddits,\n  ~get_posts(.x, css_select = \"._3wqmjmv3tb_k-PROt7qFZe ._eYtD2XCVieq6emjKBH3m\")\n) %&gt;% \n  gather(\n    BritishProblems, BritishSuccess,\n    key = subreddit, value = post_text\n  )\n\nknitr::kable(top_posts)\n\nBravo, what excellent manners we’ve demonstrated. You can also iterate over different query strings – for example if your target website displays information over several subpages – with the params argument of the scrape() function.\nOh, you have to leave? No, no, you haven’t overstayed your welcome! It was truly marvellous to see you. Don’t forget your brolly, old chap, and don’t forget to print the session info for this post. Pip pip!"
  },
  {
    "objectID": "posts/2019-03-04-polite-webscrape/index.html#environment",
    "href": "posts/2019-03-04-polite-webscrape/index.html#environment",
    "title": "Web scraping the {polite} way",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 23:36:13 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#tldr",
    "href": "posts/2019-12-23-oystr/index.html#tldr",
    "title": "Handle London travel data with {oystr}",
    "section": "tl;dr",
    "text": "tl;dr\n\nProblem: I wanted to analyse my Transport for London (TfL) travel data\nSolution: I came up with the R package name {oystr} and a hex sticker design\nPractical solution: I actually wrote the package\nSelf-flagellation: it has zero dependencies\nFurther problem: TfL won’t give me information I need to complete it properly\nResult: blog it and move on\nRevelation: I’ve spent more than 53 days on TfL trains since Autumn 2014"
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#clam-ouring-for-a-package",
    "href": "posts/2019-12-23-oystr/index.html#clam-ouring-for-a-package",
    "title": "Handle London travel data with {oystr}",
    "section": "Clam-ouring for a package",
    "text": "Clam-ouring for a package\nTransport for London (TfL) operates the travel system in London. To use their services you ‘tap in’ with an Oyster card.\nYou can sign up for monthly CSV files of your Oyster journey data, or you can sign in and download it from their website, but they’re not in a fully machine-readable state. Hence the {oystr} package.\nInstall and load with:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"oystr\")\nlibrary(oystr)\n\n{oystr} has two main functions:\n\noy_read() to read in CSV files from a folder and stitch them together\noy_clean() to wrangle the data into shape and engineer new columns\n\nThere’s two functions that deal with summarising the data, but are very much under development at time of writing:\n\noy_summary() to create a list of basic data summaries, like most visited stations\noy_lineplot() to create a simple plots of data over time\n\nThere’s also two example data sets:\n\njourneys_read is what a journey-history data set looks like when read in by oy_read()\njourneys_clean is what that read-in data set looks like when cleaned by oy_clean()\n\nThere’s also Oyster-related colours in oy_col().\nYou can read more on the {oystr} website, including a vignette, and find the source on GitHub.\n\nWinkle out the data\nThe oy_read() function is straightforward: basically, you supply a folder path and it finds the Oyster journey CSV files with the expected column names, reads them and binds them all together. That ends up looking like this:\n\nstr(journeys_read)\n\n'data.frame':   102 obs. of  8 variables:\n $ Date          : chr  \"31-Aug-2018\" \"31-Aug-2018\" \"28-Aug-2018\" \"28-Aug-2018\" ...\n $ Start.Time    : chr  \"16:11\" \"06:47\" \"18:57\" \"13:49\" ...\n $ End.Time      : chr  \"16:50\" \"07:34\" \"19:44\" \"14:43\" ...\n $ Journey.Action: chr  \"Station A to Station B\" \"Station B to Station A\" \"Station C to Station R\" \"Station R to Station L\" ...\n $ Charge        : chr  \"0\" \"0\" \"0\" \"0\" ...\n $ Credit        : chr  \"NA\" \"NA\" \"NA\" \"NA\" ...\n $ Balance       : num  8 8 8 8 8 8 8 8 8 8 ...\n $ Note          : chr  \"NA\" \"NA\" \"NA\" \"NA\" ...\n\n\nBut this isn’t enough. The data files have several columns, like Date, Start time and Balance (see an anonymised example) that need sorting.\nThe oy_clean() function is the real MVP1. It does things like:\n\nenforce the datetime class where needed\nengineer an end date (some journeys ended a different day to when they started)\ncalculate journey duration\nextract mode of transport, start and end stations, bus routes, etc\n\nThat ends up looking like this:\n\nstr(journeys_clean)\n\n'data.frame':   102 obs. of  13 variables:\n $ datetime_start  : POSIXct, format: \"2018-08-31 16:11:00\" \"2018-08-31 06:47:00\" ...\n $ datetime_end    : POSIXct, format: \"2018-08-31 16:50:00\" \"2018-08-31 07:34:00\" ...\n $ weekday_start   : Ord.factor w/ 7 levels \"Monday\"&lt;\"Tuesday\"&lt;..: 5 5 2 2 7 7 7 7 6 6 ...\n $ journey_duration: 'difftime' num  39 47 47 54 ...\n  ..- attr(*, \"units\")= chr \"mins\"\n $ mode            : chr  \"Train\" \"Train\" \"Train\" \"Train\" ...\n $ station_start   : chr  \"Station A\" \"Station B\" \"Station C\" \"Station R\" ...\n $ station_end     : chr  \"Station A\" \"Station B\" \"Station C\" \"Station R\" ...\n $ bus_route       : chr  NA NA NA NA ...\n $ payment         : chr  NA NA NA NA ...\n $ charge          : chr  \"0\" \"0\" \"0\" \"0\" ...\n $ credit          : chr  \"NA\" \"NA\" \"NA\" \"NA\" ...\n $ balance         : num  8 8 8 8 8 8 8 8 8 8 ...\n $ note            : chr  \"NA\" \"NA\" \"NA\" \"NA\" ...\n\n\n\n\nLike it or limpet\nIt was tricky to deal with the Journey/Action column. It’s a bin for all sorts of things like:\n\nBus journey, route 87\nSt James's Park to Kings Cross [London Underground / National Rail]\"\nEntered and exited Pimlico\n[No touch-in] to Waterloo (platforms 1-11) [National Rail]\"\nSeason ticket added on touch in, Liverpool Street [National Rail]\nAutomated Refund, Southbury\nTopped up,\n\nIn fact, I don’t know all the possibilities for this column and TfL won’t tell me: I sent a help request and was told that this information isn’t available. I could do a Freedom of Information (FOI) request, but I can only get my own Oyster history. Which I already have.\nThis limits how useful this package can be for other people; I can’t handle formats for the Journey/Action column that I haven’t seen before. So I might as well write about where I’ve got to with {oystr} and encourage you to add to this list of possible formats I’ve started.\n\n\nBeing un-shellfish with dependencies\nAs an aside, I set myself a small challenge for {oystr}: to use only base R functions and avoid dependencies. These are packages that would have to be installed to make {oystr} work.\nWhy do this? In part because:\n\nI admire the philosophy of the tinyverse (‘lightweight is the right weight’)\nmy last package, {altcheckr}, was stuffed with dependencies\nI’ve been writing too much tidyverse code and want the sweet nostalgia hit of some classic base R code\nI’m a hero and I care about my users (me); you’re (I’m) welcome\n\nTo be more specific, I wanted to avoid required packages in the ‘Imports’ and ‘Remotes’ fields of the the DESCRIPTION file. Packages in the ‘Suggests’ field are fine; for example, {testthat} and {knitr} are required for development, but not by the user."
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#flexing-the-packages-mussels",
    "href": "posts/2019-12-23-oystr/index.html#flexing-the-packages-mussels",
    "title": "Handle London travel data with {oystr}",
    "section": "Flexing the package’s mussels",
    "text": "Flexing the package’s mussels\nOkey dokey, so for about five years I’ve been collecting my Oyster data as monthly CSVs emailed to me by TfL, though some months are missing. I won’t be sharing these data, but here’s some quick examples of applying {oystr} to it.\n\n# Read all the CSV files from a folder path\ndata_read &lt;- oy_read(\"~/Desktop/oyster\")\n\nNext is oy_clean() to wrangle the data into shape.\n\n# Pass the data frame output from oy_read()\ndata_clean &lt;- oy_clean(data_read)\n\nAs a quick overview, there’s 1794 rows of data in the output, of which 97 per cent is train journeys. The earliest recorded journey start is 2014-09-01 07:32:00.\nWe can take this cleaned data and summarise it in various ways. For example, the oy_summary() function provides a list where each element is a basic summary.\n\ntrain_summ &lt;- oy_summary(data_clean, mode = \"Train\")\nnames(train_summ)  # list element names\n\n[1] \"count_journeys\"   \"stations_popular\" \"stations_matrix\"  \"duration_total\"  \n[5] \"day_popular\"\nSo for example, I can use train_summ$duration_total to find out that I’ve spent 76321 mins on TfL’s trains.\nThat’s 53 days.\nYou could also plot the data. Here’s a histogram coloured with Oyster-related colours from oy_cols().\n\npar(mar = c(4.5, 4.5, 5, 0))\n\nhist(\n  as.numeric(data_clean$journey_duration),\n  main = NULL, xlab = \"Journey duration (mins)\", \n  col = oy_cols(\"oyster_cyan\"), border = oy_cols(\"oyster_blue\"),\n  breaks = seq(0, 120, 5), las = 1\n)\n\ntitle &lt;- \"Matt Dray's journeys are 40 to 45 mins long, mostly\"\nsub &lt;- paste(\"Travelling sweatily via TfL trains since Autumn 2014\")\nmtext(side = 3, line = c(3, 2), adj = 0, cex = c(1.2, 1), c(title, sub))\n\n\nSo that’s my commute dominating the peak of that histogram. The two-hour journey went right across the network from Southbury in London’s north-west to Hounslow in the south-west. I assume the three-minute journey from South Kensington to Gloucester Road to avoid zombie-dinosaur attacks outside the Natural History Museum.\nObviously you could take the cleaned data and do some other neat stuff. Maybe I’ll do another post about this in future."
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#shuck-it-up",
    "href": "posts/2019-12-23-oystr/index.html#shuck-it-up",
    "title": "Handle London travel data with {oystr}",
    "section": "Shuck it up",
    "text": "Shuck it up\nThere’s plenty to do. The main task is to handle all formats of the Journey/Action column and then use this to inform how the summary and plot functions should be improved. Ultimately, oy_read() and oy_clean() work for me right now, but you may run into trouble if you actually try to use the package.\nEventually I’d like the package to be at least as good as the sticker.\nFeel free to suggest or make improvements and don’t forget to add to my log of Journey/Action formats if you’ve seen some different things."
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#environment",
    "href": "posts/2019-12-23-oystr/index.html#environment",
    "title": "Handle London travel data with {oystr}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-23 11:22:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] oystr_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-12-23-oystr/index.html#footnotes",
    "href": "posts/2019-12-23-oystr/index.html#footnotes",
    "title": "Handle London travel data with {oystr}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMVP means ‘Most Valuable Primate’, but also Minimum Viable Product.↩︎"
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html",
    "href": "posts/2019-01-18-deer-collisions/index.html",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "",
    "text": "Oh dear, roe deer (Marek Szczepanek, CC BY-SA 4.0)"
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#tldr",
    "href": "posts/2019-01-18-deer-collisions/index.html#tldr",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a Shiny app with open data about deerstrikes by cars in Scotland."
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#open-data",
    "href": "posts/2019-01-18-deer-collisions/index.html#open-data",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "Open data",
    "text": "Open data\nDeer roam Scotland. So do humans. It’s a problem when they meet at high speed.\nThe National Deer-Vehicle Collisions Project, administered by The Deer Initiative, has been monitoring data on deer-vehicle collisions in the UK.\nThe data are open. I found the data set when skimming through data.gov.uk (a classic weekend activity for all the family). It links to the SNH Natural Spaces site where you can download the data as shapefile, GML or KML under the Open Government Licence.\nI couldn’t find an interactive visualisation of these data and I want to spend more time working with the {shiny} package,1 so why not."
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#a-simple-shiny-app",
    "href": "posts/2019-01-18-deer-collisions/index.html#a-simple-shiny-app",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "A simple Shiny app",
    "text": "A simple Shiny app\nHere’s a preview of the app in action:\n\nAlong with {shiny}, the app was built primarily with the R packages:\n\n{shinydashboard} for a nice layout and value boxes\n{leaflet} for the interactive map\n{DT} for the interactive datatable\n\nThe interface is a simple dashboard in three parts: a sidebar, a main panel and three value boxes.\nThe sidebar contains three collapsible sections with an ‘about’ section, a ‘how to’ section and a section with interactive filters. You can type or select collisions from a specified time (year and/or month) and place (the local authority in which it happened).\nThe main panel has two tabs. One is an interactive map that indicates the collisions with clickable markers. The second tab contains an interactive table. The data shown in these views is a result of the filters that have been applied via the sidebar. The interactive table also allows for further data filtering and you can download the results.\nThe value boxes each show one statistic related to the filtered data: the number of collisions; total collisions for the given local authorities and years; and the total collisions in the selected years. These update as you change your selections."
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#run-the-app",
    "href": "posts/2019-01-18-deer-collisions/index.html#run-the-app",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "Run the app",
    "text": "Run the app\nThe code for the app is available on GitHub. You can also download the cleaned data in CSV or RDS format.\nYou can run the app from an R session by installing {shiny} from CRAN and then executing the following lines:\n\nshiny::runGitHub(\n  repo = \"scot-deer-collisions\", \n  username = \"matt-dray\"\n)"
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#limitations",
    "href": "posts/2019-01-18-deer-collisions/index.html#limitations",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "Limitations",
    "text": "Limitations\nI used to host the app for free on shinyapps.io, but it’s since made way for other projects. That means you’ll have to download it to run it. The code will continue to exist on GitHub though, where you can leave an issue or fork it to make it better.\nIn terms of app design, I limited the filters to year, month and local authority. I could have included deer species and road, but the data are sparse and the formatting wasn’t great. I cleaned these variables up a bit and they’re available as filterable columns in the interactive table.\nThere’s also a large number of data points and it doesn’t make sense to show them all at once because it slows the app down. There are methods for improving this, but I assume most people will be looking at specific local authorities or roads rather than the country as a whole."
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#environment",
    "href": "posts/2019-01-18-deer-collisions/index.html#environment",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-04 08:43:46 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-01-18-deer-collisions/index.html#footnotes",
    "href": "posts/2019-01-18-deer-collisions/index.html#footnotes",
    "title": "Map deer-vehicle colisions with {shiny}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut see this post about a Shiny app I made that that one colleague described as ‘very depressing’.↩︎"
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html",
    "href": "posts/2019-01-04-rprofile-motivate/index.html",
    "title": "Motivate yourself with an .Rprofile",
    "section": "",
    "text": "My dream is to pet this kitty (via Giphy)"
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#tldr",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#tldr",
    "title": "Motivate yourself with an .Rprofile",
    "section": "tl;dr",
    "text": "tl;dr\nYou can create an R startup message by editing your .Rprofile, which you can open with usethis::edit_r_profile()."
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#whats-an-r-profile",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#whats-an-r-profile",
    "title": "Motivate yourself with an .Rprofile",
    "section": "What’s an R profile?",
    "text": "What’s an R profile?\nIt’s a file that contains R code that runs when you start or restart R. You can use it to customise your environment. For example, you could set options, create functions or load packages.\nThere’s lots of information in the R startup chapter of Colin Gillespie’s’s Efficient R Programming book.\nBut beware: use of an R profile may not be particularly reproducible if the .Rprofile file is unavailable to others who are executing your code. For example, you might use your profile to load packages that aren’t installed by another user.\nYou can use your favourite search engine to find examples of people’s R profiles. For example, in:\n\nTony Fischetti’s On the Lambda blog\nKris Eberwein’s post on how to pimp your Rprofile\nStephen Turner’s post on Getting Genetics Done blog\nJesse Lecy’s GitHub repo\n\nI’m going to create something a little more… fun."
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#how-to-edit-your-.rprofile",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#how-to-edit-your-.rprofile",
    "title": "Motivate yourself with an .Rprofile",
    "section": "How to edit your .Rprofile",
    "text": "How to edit your .Rprofile\nYou could navigate to where the .Rprofile file is stored on your machine and edit it, but it’s easier to use the edit_r_profile() function from the usethis package.\n\nusethis::edit_r_profile()\n\n• Modify '/Users/mattdray/.Rprofile'• Restart R for changes to take effect\nThe output from running this line shows the filepath to the .Rprofile and reminds you to restart R to reload the R profile and its newly-saved changes."
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#a-frivolous-use-case",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#a-frivolous-use-case",
    "title": "Motivate yourself with an .Rprofile",
    "section": "A frivolous use case",
    "text": "A frivolous use case\nYou could use your R profile to display a little message at start-up.\nIt’s four days into 2019 and you may be struggling with those new year resolutions. You’re probably going to need a motivational quote.\nWe can load the emo package within the R profile and add emojis to our messages. There’s a handy function – emo::ji_glue() – that allows you to paste text with emojis.\nThe following code selects one element at random from a set of motivational messages and prints it to the console on start-up.\n\nlibrary(emo)  # devtools::install_github(\"hadley/emo\")\n\ncat(\n  sample(\n    x = c(\n      ji_glue(\"Don't let your dreams be dreams! :rainbow:\"),\n      ji_glue(\"Nothing is impossible! :raised_hands:\"),\n      ji_glue(\"Be brave! :triumph:\"),\n      ji_glue(\"Do the thing! Yeah! :white_check_mark:\"),\n      ji_glue(\"Haters gon' hate! :tipping_hand_woman:\"),\n      ji_glue(\"Crush your enemies! :fist:\"),\n      ji_glue(\"Generic motivational quote! :clap:\")\n    ),\n    size = 1\n  )\n)\n\nYou need a blank line at the end of the file. One will be added for you on save when editing in RStudio."
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#outcome",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#outcome",
    "title": "Motivate yourself with an .Rprofile",
    "section": "Outcome",
    "text": "Outcome\nHere’s the code in the script window and the result of having restarted R a few times.\n{fig-alt=alt=“An RStudio window showing the .Rprofile script and several messages being printed to the console with successive restarts of the RStudio.” width=“100%”}\nJust don’t get stuck in a loop of restarting R over and over again so you can see the messages. You might get overmotivated. Or you’ll spend so long restarting that you’ll have wasted loads of time and will need more motivational quotes to encourage yourself not to do it anymore.\n\n Note\nI forgot that there’s a great package called {praise} via RLadies that can generate the positive messages for you. Check it out."
  },
  {
    "objectID": "posts/2019-01-04-rprofile-motivate/index.html#environment",
    "href": "posts/2019-01-04-rprofile-motivate/index.html#environment",
    "title": "Motivate yourself with an .Rprofile",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-04 08:54:32 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "title": "Panic! In The Toolshed",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote some slides to tell data scientists in the public sector what they already know: share the tools you’ve developed."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "title": "Panic! In The Toolshed",
    "section": "An axe to grind",
    "text": "An axe to grind\nI’m speaking today at an event for UK government data scientists with a theme of ‘the data science toolshed’. My plea is small: I want public sector workers to share the tools they make1.\nWe should build modular things like R packages that are easy to use and develop; make them available to everyone to minimise duplication and encourage collaboration; and maximise reach by telling everyone about it. This is how we improve quality and build our community. And save money for the taxpayer.\nHandily, this is already expressed in the government’s Technology Code of Practice:\n\nShare, reuse and collaborate: avoid duplicating effort and unnecessary costs by collaborating across government and sharing and reusing technology, data, and services.\n\nI’ve had a small experience with this: I made the {a11ytables} R package to help producers of stats publications automate the creation of best-practice, accessible spreadsheets. It’s now being used in several organisations and is referenced from the government’s best-practice guidance.\nSuccess? Maybe. But also PANIK: I’ve left the organisation where I made it; I was the sole developer; I worry that I should have thought about this sooner; that I should fork and update it; that updating users will be hard; that links to the old package will break; and so on. Hopefully people will learn something from these missteps."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "title": "Panic! In The Toolshed",
    "section": "Burying the hatchet",
    "text": "Burying the hatchet\nThe slides are live on the internet and embedded below, or you can view the source on GitHub. Press s to pop out the speaker notes, o for a slide overview and f for fullscreen.\n\n\n\n\n\n\n\n\nThe slides were made with Revealjs via Quarto, because of course they were."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "title": "Panic! In The Toolshed",
    "section": "Clamp down",
    "text": "Clamp down\nSo, we should sustainabilise (not a word), centralise and advertise the useful things we make. Maybe we could have a list of tools we’ve produced collectively in the public sector? Something like an ‘Awesome’ list or a CRAN task view. Maybe that would make it easier to find and develop existing solutions instead of building from scratch all the time.\nBuild a toolshed. They will come?"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "title": "Panic! In The Toolshed",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:03:30 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#footnotes",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#footnotes",
    "title": "Panic! In The Toolshed",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI get that it’s not always possible to share things because of sensitivity issues. If you can’t open it up to the world, then what’s the highest level that you can release it? Organisation, division, team? If you can’t share the tool, then what can you tell people about the experience of developing and using it?↩︎"
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#tldr",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#tldr",
    "title": "An isometric dungeon chase in R",
    "section": "tl;dr",
    "text": "tl;dr\nI made an interactive isometric-dungeon demo in R, thanks to {r.oguelike} for dungeon building and mikefc’s {isocubes} for drawing isometric cube graphics and {eventloop} for continuous keypress inputs."
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#a-new-dimension",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#a-new-dimension",
    "title": "An isometric dungeon chase in R",
    "section": "A new dimension",
    "text": "A new dimension\nMike (AKA mikefc, AKA coolbutuseless) is well known for off-label R creations that desecrate the assumption that ‘R is a language for statistical computing’.\nMike revealed the {isocubes} package recently, which lets you print objects made of isometric cubes to a graphics device. I immediately thought of the toy {r.oguelike} package I’ve been developing recently, which has the goal of creating (really) basic features of a roguelike game in R.1 The dungeons are currently ASCII tiles printed to the console. How would it look in isometric?\nIn a frenzied series of tweets, I built up a little toy that creates a procedural isometric dungeon and adds a user-controlled player character and a pathfinding enemy. The steps were to:\n\nBuild an isometric dungeon (tweet)\nAdd a player (tweet)\nAccept continuous input (tweet)\nAdd a pathfinding enemy (tweet)\n\nThis post talks through those steps. You can find the code for the final product in a GitHub Gist. It is absolutely not polished and really is just a Frankenstein’s monster of code that I stapled together.\n\n1. Build an isometric dungeon\n{r.oguelike} creates procedural dungeons in the form of a matrix where # symbols are non-traversable wall tiles and . indicates traversable floor tiles. I wrote about the inception of the package in a recent blog post.\nWe can swap the characters for height values, where the floor is 1 and the walls are 2, and {isocubes} will project the walls one cube above the plane of the floor. We can also use this information to provide colours; black for the floor and brown for the walls, for example, so it looks like a cavern.\nHere’s a few examples:\n\nI think that looks pretty good (ignore the graphical artefacts from the gif compression). I didn’t time how long it took for each image to be rendered because it was near-instantaneous.\nBut we don’t want to just look at pictures of dungeons, we want to explore them.\n\n\n2. Add a player\n{r.oguelike} lets a user move a character around the the floor tiles. The player is represented by @ in the dungeon matrix, which we can again substitute with a height value of 1 so it’s one cube higher than the floor. Of course, we should colour it to distinguish it from the walls; I chose blue.\nThe user’s keyboard input is accepted by readline() and this determines the character’s movement. Typing W then Enter will make the player move north one tile, for example. In {r.oguelike}, a keypress input causes the current location to be overwritten with a floor tile (.); the tile above to be replaced with the player symbol (@); and then the updated matrix is re-printed to the console.\nAgain, this all takes place inside the matrix that represents the dungeon, so we can also just lift this functionality into the {isocubes} version. Here you can see a series of user inputs to the console that result in the player moving around the floor tiles.\n\nIt was really pleasing when I got this to work, but it’s also quite tedious to tap in a key and hit enter for each movement.\n\n\n3. Accept continuous input\n{r.oguelike} simply prints the dungeon matrix to the console at the end of each turn, whereas our {isocubes} version takes place in a graphics window that’s refreshed with every turn.\nMike also has a package called {eventloop},2 which he suggested might be useful for continuous input from the user. The package contains:\n\na framework for rendering interactive graphics and handling mouse+keyboard events from the user at speeds fast enough to be considered interesting for games and other realtime applications\n\nBear in mind that it doesn’t work on Windows. Read more about it in Mike’s blog.\nHere you can see the result of incorporating {eventloop}. The user is pressing the arrow keys—which you can see being printed to the console—to move the player. This is way more seamless than the previous readline() method.\n\nThis is a nice demo, but it would be great to make this more of a ‘game’.\n\n\n4. Add a pathfinding enemy\n{r.oguelike} has an enemy character, represented in the dungeon matrix as E. Again, we can replace this with a height of 1 and colour it yellow, for example.\nI wrote recently about implementing simple breadth-first pathfinding so that the enemy can head toward wherever the player currently is. At time of writing I haven’t fully implemented the pathfinding into {r.oguelike}, but that didn’t stop me adding it into the code for this isometric demo.\nHere you can see the enemy cube (yellow) hunting down the player-controlled cube (blue). I was motivated to add a capture condition and decided to have fun with it.\n\nI hope you enjoyed the victory dance at the end of the gif (it was the best I could do with the limited graphics).3\n\n Note\nAfter this post was published, the {oblicubes} package was published by Trevor L Davies. It allows you to use oblique projections. So obviously I had a go with {r.oguelike}.\n\n\n\nClick for the required code changes.\n\nIn the code I wrote, you pretty much replace:\n\ncoords &lt;- isocubes::coords_heightmap(dungeon_h, col = dungeon_c)\n\ncubes  &lt;- isocubes::isocubesGrob(\n  coords,\n  max_y = ncol(dungeon_h) + 0.1 * ncol(dungeon_h),\n  fill = coords$col,\n  xo = 0.7\n)\n\ngrid::grid.newpage()  # 'clear'\ngrid::grid.draw(cubes)  # render\n\nWith:\n\ncoords &lt;- oblicubes::xyz_heightmap(\n  dungeon_h,\n  col = dungeon_c,\n  scale = 0.3,\n  ground = \"xy\"\n)\n\ngrid::grid.newpage()  # 'clear'\noblicubes::grid.oblicubes(coords)  # render"
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#the-fourth-dimension",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#the-fourth-dimension",
    "title": "An isometric dungeon chase in R",
    "section": "The fourth dimension",
    "text": "The fourth dimension\nI need to tie up some loose ends in the current version of {r.oguelike}, but I’m considering the possibilities for {isocubes} and {eventloop} in future. Maybe the start_game() function could have an argument where the user can choose 2D or 3D (isometric or oblique) representations of the game.\nI also have a few ideas of how I can use my basic {r.oguelike} ‘engine’ with {isocubes} to develop some other, non-roguelike games. For example, Dmytro (AKA Deemah) suggested {rsokoban}. Sokoban is a game where you solve small tile-based puzzles by pushing crates onto designated spots. I was also reminded of Q*bert, where you try and touch all the floor tiles to change their colour.\nSo many ideas for off-label R use, so little time."
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#postscript",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#postscript",
    "title": "An isometric dungeon chase in R",
    "section": "Postscript",
    "text": "Postscript\nI lied a bit earlier. The actual first thought I had when seeing {isocubes} was pixel art. I wrote a post (exactly) one year ago where I converted some vectors into little pixel drawings using R’s image() function.\nIt’s fairly straightforward to convert those vectors into a format accepted by {isocubes}, which means you can have an isometric sprite of Link from The Legend of Zelda, or a rainbow version of the insect logo for this blog.\n\nI wrote a GitHub Gist with the code for these images, so feel free to steal. Let me know what you end up making."
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#environment",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#environment",
    "title": "An isometric dungeon chase in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-28-isometric-dungeon/index.html#footnotes",
    "href": "posts/2022-06-28-isometric-dungeon/index.html#footnotes",
    "title": "An isometric dungeon chase in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut yo, have you seen what Wolfgang has been up to re roguelikes in R? What the actual heck.↩︎\nYou can find more examples of {eventloop} in a dedicated GitHub repo, including apps, games, sounds and graphics.↩︎\nYes, the ‘game’ is an existential one: was the enemy chasing you, or were you the enemy all along?↩︎"
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#tldr",
    "href": "posts/2022-03-31-hastings-half/index.html#tldr",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "tl;dr",
    "text": "tl;dr\nI made a small R Markdown site that contains interactive maps of the route of the Hastings Half Marathon."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#half-distance-double-delay",
    "href": "posts/2022-03-31-hastings-half/index.html#half-distance-double-delay",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Half distance, double delay",
    "text": "Half distance, double delay\nI signed up for the Hastings Half Marathon in March 2019 and finally got to run it in March 2022 after two years of pandemic-related cancellations.\nI managed a time of 1:44:151 in terrific conditions and raised money for Sands, the stillbirth and neonatal death charity (at time of writing you can still donate).\nAs a nice bonus, the finisher’s medal featured Alan Turing, who spent some of his childhood in the area."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#running-or-climbing",
    "href": "posts/2022-03-31-hastings-half/index.html#running-or-climbing",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Running or climbing?",
    "text": "Running or climbing?\nThe Hastings Half is a popular and an interesting course, mostly because of the third dimension: there are two short, sharp early climbs, then a long sweeping one, later returning downhill to finish along the seafront of the town.2\nThere are precious few resources online that illustrate the course, however. You can find a low-quality map on the official website and get an elevation profile elsewhere, but I thought it might be useful to create a quick and tiny webpage with the x, y and z dimensions in an interactive format."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#run-route-run-code",
    "href": "posts/2022-03-31-hastings-half/index.html#run-route-run-code",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Run route, run code",
    "text": "Run route, run code\nSo, I recorded the route with my Apple Watch and downloaded the data as a GPX file, which contains geospatial data in an XML-like format. I’ve talked about Apple Health data before, and also about a small package I made to read GPX data, called {gpx3d}, which came in handy.\nWith that data I made three interactive maps using R:\n\nA birds-eye view with {leaflet}, which allows zooming and panning and has markers for each of the kilometres\nAn elevation profile with {plotly}, which shows the distance and elevation on hover\nA 3D trace of the course with {ggrgl}, which can be dragged to show relative distance and elevation\n\nI embedded these maps in three separate tabs of a {flexdashboard}, an R Markdown format that lets you create simple, single page dashboards. I used {bslib}, {thematic}, {emo} and Google Fonts for styles and embellishment.\nI pushed the files to a GitHub repo and served the HTML via GitHub Pages to a dedicated webpage at matt-dray.github.io/hastings-half/.\nHere are some screenshots of each page:\n\n\n\nScreenshot of the interactive route map, made with {leaflet}\n\n\n\n\n\nScreenshot of the interactive elevation profile, made with {plotly}\n\n\n\n\n\nScreenshot of the interactive 3D trace, made with {ggrgl}"
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#see-you-in-2023",
    "href": "posts/2022-03-31-hastings-half/index.html#see-you-in-2023",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "See you in 2023",
    "text": "See you in 2023\nUltimately the webpage is a very quick demo, but I hope others will be able to use to get a sense of the course.\nThe next step will be to add fourth and fifth dimensions: smell and sound. As soon as you reach the bottom of All Saints Street you hit the historic Old Town seafront, where you’re immediately perked up by the scent of frying chips and the screech of extremely raucous seagulls.\nThere’s no place like home."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#environment",
    "href": "posts/2022-03-31-hastings-half/index.html#environment",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 15:43:15 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#footnotes",
    "href": "posts/2022-03-31-hastings-half/index.html#footnotes",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA time of 1:44 while wearing number 144, coincidentally.↩︎\nJust pray that the cold sea wind isn’t blowing in your face for those several kilometres; it feels like running in frozen treacle.↩︎"
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#tldr",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#tldr",
    "title": "Govspeakify tables with {shinylive}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a demo Shiny app that’s hosted with GitHub Pages but runs serverless in the browser, thanks to {shinylive}. It converts a copied table to Govspeak Markdown, the format required for publishing reports by the UK’s government."
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#rise",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#rise",
    "title": "Govspeakify tables with {shinylive}",
    "section": "Rise",
    "text": "Rise\nStatistical reports in the UK public sector are often prepared as Word documents. However, they need to be uploaded to the UK government’s publishing system as a special, simplified flavour of Markdown called ‘Govspeak’. There’s an online tool to help with this, but it doesn’t yet handle the conversion of tables.\nI wrote recently about a little function I made to transform Word tables to Govspeak. It suits me to run the function within R, but this approach isn’t ideal for colleagues who aren’t R users (imagine!).\nA Shiny app could be useful here. But that’s a bit of a faff; where would I serve it from? I don’t have access to a server and all my free slots on shinyapps.io are taken up.\nBut! Thanks to recent developments1 in Shinylive and {webR}, I can serve the app from GitHub pages and have all the computation happen in the user’s browser. This is a gamechanger."
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#and-shine",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#and-shine",
    "title": "Govspeakify tables with {shinylive}",
    "section": "And shine",
    "text": "And shine\nThe first step was to create a Shiny app to ‘govspeakify’ a table. Nothing fancy, I just wanted:\n\nA text field to receive a copied table.\nSome interactive options for additional Govspeak formatting2.\nA button to convert the table to Govspeak.\nThe Govspeak output printed to the screen.\nA button to copy the output to the clipboard.\n\nSo, a button-click triggers the conversion of the pasted table via eventReactive(), given the user-supplied formatting options. The output is presented back to the user, along with a button to copy it, thanks to {rclipboard}.\nYou can find the app code in a GitHub repo. I prepared the app in a single app.R file, along with an R/conversion.R file with bespoke functions. I housed these in a govspeakify-tables subfolder.\nThere’s a number of things I want to add or improve to this proof of concept. For example, some more defensive programming to protect against invalid inputs and perhaps some more explanations and styling. Also the ability to upload a full docx file, extract and ‘govspeakify’ all tables and return them in a text file.\nYou’ll be able to break the app very easily, but it does what I need it to do for now."
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#and-live",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#and-live",
    "title": "Govspeakify tables with {shinylive}",
    "section": "And live!",
    "text": "And live!\nSo, I have the Shiny app; how do we prepare it? The {shinylive} package has a one-liner function that will generate a single folder containing your app and all the necessary bits and bobs from the Shinylive project so it can be served by GitHub Pages but perform computations in the user’s browser.\nThe steps are:\n\nRun shinylive::export(\"govspeakify-tables\", \"docs\") to take the Shiny app and assets from the govspeakify-tables folder and generate a deployable version of it in a folder called docs/ (since this is a folder name that GitHub Pages can serve from).\nRun httpuv::runStaticServer(\"docs\") to launch the app in a local static server and check that it works as intended (this requires the development version of {httpuv} at the time of writing, which you can install from GitHub). You could also test it out by pasting code into the online Shinylive editor.\nPush to your GitHub repo and set up GitHub Pages to serve the docs/ folder (from the repo, go to the ‘Settings’ tab, click ‘Pages’ in the sidebar, select the ‘main’ branch and ‘/docs’ folder from the dropdowns, then click the ‘Save’ button).\n\nGitHub will take a moment to ready your app, but it’s then available on the web via a URL in the form ‘https://username.github.io/repo-name’. The Govspeakify Tables app can be found here: https://matt-dray.github.io/govspeakify-tables (may take a sec to load).\nSome of these instructions and links may change as tools like Shinylive (the asset-preparation system), {shinylive} (the package) and {webR} continue to develop. I realised later that Rami has also recorded these steps in a README, so you may want to look there in future for more up-to-date information.\nBottom line: Shinylive is a huge deal for creating small, nimble apps that are free from the tyranny of server management.\n\n Note\nI later saw Nicola Rennie’s TidyTuesday Shinylive app and Veerle van Leemput’s post about a Hangman Shinylive app that are worth checking out too.\n\n\n Note\nIt occurred to me that the arrival of Shinylive might finally be the death knell for {crosstalk}. {crosstalk} allows for certain htmlwidgets to speak to each other so that, for example, you can select from a dropdown and the points displayed on a graph or table will get filtered. In other words, you get a Shiny-like experience without {shiny} and without a server. I spoke about {crosstalk} in 2018 and it hasn’t really been developed since then. I think I’ll probably use Shinylive in Quarto from now on."
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#environment",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#environment",
    "title": "Govspeakify tables with {shinylive}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-10-11 17:12:59 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.25    knitr_1.44        jsonlite_1.8.7    xfun_0.40        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.2 evaluate_0.22"
  },
  {
    "objectID": "posts/2023-10-08-govspeakify-tables/index.html#footnotes",
    "href": "posts/2023-10-08-govspeakify-tables/index.html#footnotes",
    "title": "Govspeakify tables with {shinylive}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThanks to George Stagg, Winston Chang, Barret Schloerke and many others! See Joe Cheng’s slides from Shinylive at the 2023 Posit conference.↩︎\nTo mark-up row titles (i.e. content in the first column is suffixed with #) and totals rows (all content in the row is emboldened between asterisks), and to provide a regular expression for characters to ignore when evaluating numeric columns (e.g. recognise that \"75%\" is 75 and \"1,000\" is 1000) so that they’ll be marked-up as right-aligned in the output.↩︎"
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html",
    "href": "posts/2019-07-23-can-drake-rap/index.html",
    "title": "Can {drake} RAP?",
    "section": "",
    "text": "A drake, Sir Drake, Drake, Drake, Drake and {drake}."
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#tldr",
    "href": "posts/2019-07-23-can-drake-rap/index.html#tldr",
    "title": "Can {drake} RAP?",
    "section": "tl;dr",
    "text": "tl;dr\nThe {drake} package records file interdependecies in your analysis. When files are changed, {drake} only re-runs the parts that need to be re-run. This saves time and reduces error.\nThis could be useful for Reproducible Analytical Pipelines (RAP), an automated approach to producing UK government statistics that minimises error and speeds production."
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#make-it-to-make-it",
    "href": "posts/2019-07-23-can-drake-rap/index.html#make-it-to-make-it",
    "title": "Can {drake} RAP?",
    "section": "Make it to make it",
    "text": "Make it to make it\nAnalysis projects can become complicated as multiple inputs, script files and outputs build up.\nCan you remember exactly which scripts need to be re-executed after a file changes? Or will you have to re-run the entire project from scratch? This is tedious and open to error if you miss something.\nA ‘makefile’ can help you. In short, it’s a text file in which you write each step of your analysis in a recipe-like format. Dependencies between data, code and outputs are recorded.\nA makefile ensures that only the affected file and those downstream from it will be re-executed. This saves compute time and means you don’t have to remember any dependencies yourself."
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#drake-it-to-make-it",
    "href": "posts/2019-07-23-can-drake-rap/index.html#drake-it-to-make-it",
    "title": "Can {drake} RAP?",
    "section": "{drake} it to make it",
    "text": "{drake} it to make it\n{drake} is a package by Will Landau that gives you makefiles with R syntax. It can be installed with install.packages(\"drake).\nThis post contains a very simple example of {drake} in action, but there’s so much more to it. Fortunately, there’s lots of information:\n\nuser manual\ndocumentation\ncheat sheet by Kirill Müller\n‘drake for workflow happiness’ slides by Amanda Dobbyn – which embraces the Drake meme\nGarrick Aden-Buie’s introductory talk, including slides and an RStudio Cloud Project\n\nWill Landau has also put together:\n\nthe {learndrake} package to… learn {drake}\na Shiny app for planning {drake} projects"
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#demo-drake-lays-an-egg",
    "href": "posts/2019-07-23-can-drake-rap/index.html#demo-drake-lays-an-egg",
    "title": "Can {drake} RAP?",
    "section": "Demo: {drake} lays an egg",
    "text": "Demo: {drake} lays an egg\nI think there’s potential for {drake} in Reproducible Analytical Pipelines (RAP): a wholly code-based method for producing the UK government’s statistical reports that improves reproducibility and automation, minimises errors and speeds-up production.\nI’ve made a very simple {drake} demo for an imaginary RAP project. The demo recreates a very small part of a statistical publication that tracks UK egg production1.\nThe demo code is on GitHub and the demo report has also been published to the web. Here’s a screenshot of the demo:\n\nBig shout-out to Duncan Garmonsway for the {govdown} package that recreates the style of GOV.UK—the website of the UK government—in R Markdown.\nThe rest of this post explains the steps in the demo:\n\nPrepare R scripts\nLoad the scripts\nVisualise\nMake the plan\nMake a change\n\n\n1. Prepare the scripts\nThe repo has three simple scripts2 containing the code for the analysis:\n\npackages.R loads the packages we need for our analysis with library()\nfunctions.R contains our own custom functions\negg-report.Rmd is the R Markdown report that will be output to HTML\nplan.R is where the steps of the analysis are written\n\nThe plan.R file needs a little more explanation. It contains the drake_plan() function, to which you pass each function required for the analysis. The functions can be in any order; {drake} works out the order from the dependencies between the scripts and outputs.\nThe demo plan is very simple, with only four functions wrapped inside drake_plan():\n\negg_plan &lt;- drake_plan(  # Create a drake_plan object called egg_plan\n  \n  # 1. Read the dataset\n  raw_data = read_ods(\n    path = \"data/eggs-packers-02may19a.ods\",\n    sheet = \"Packers_Annual\",\n    skip = 8\n  ),  # separate each function with a comma\n  \n  # 2. Prepare the data with a bespoke function\n  # from the functions.R file\n  data = clean_data(raw_data),\n  \n  # 3. Generate a plot using a bespoke function\n  # from the functions.R file\n  plot = create_plot(data),\n  \n  # 4. Finally, render the R Markdown report\n  # drake::knitr_in() marks the .Rmd file as a dependency\n  # drake::file_out() marks the .HTML as an output\n  report = rmarkdown::render(\n    knitr_in(\"egg-report.Rmd\"),\n    output_file = file_out(\"docs/egg-report.html\"),\n    quiet = TRUE\n  )\n\n)\n\n\n\n2. Load the scripts\nThe data and code are all in place. How do we run the analysis?\nEverything we need is stored in a small file called make.R. It starts by calling source() for each R script:\n\nsource(packages.R)   # load the packages\nsource(functions.R)  # load the bespoke functions\nsource(plan.R)       # load the plan\n\nSourcing the plan file results in the drake_plan() function being run. The output is a special drake_plan data frame object, which is called egg_plan in our demo. It has columns called ‘target’ and ‘command’ and a row for each function in our analysis:\n\negg_plan\n\n# A tibble: 4 x 2\n  target   command                                                                           \n  &lt;chr&gt;    &lt;expr&gt;                                                                            \n1 raw_data read_ods(path = \"data/eggs-packers-02may19a.ods\", sheet = \"Packers_Annual\",      …\n2 data     clean_data(raw_data)                                                             …\n3 plot     create_plot(data)                                                                …\n4 report   render(knitr_in(\"egg-report.Rmd\"), output_file = file_out(\"docs/egg-report.html\")…\nThe plan object acts like an instruction booklet, which can be read ‘to each target (data and outputs), apply the named command (the functions of the analysis)’. So the contents of the egg_plan data frame can be read\n\nRead the raw data (the target) with readODS::read_ods() (the command)\nClean the data (target) with the custom clean_data() function (command)\nPlot the data (target) with the custom plot_data() function (command)\nCreate an R Markdown report (target) with rmarkdown::render() (command)\n\nSo we have the instructions stored in an object. Now we can (optionally) produce a dependency graph of these targets to get an idea of the relationships between the elements of the analysis.\n\n\n3. Visualise\nThe first step to create the visual is to extract information about the egg_plan in a configuration (‘config’) list object. One element of the config is, for example, an igraph object that helps construct graphs from your workflow. The function to get this is drake_config().\n\negg_config &lt;- drake_config(egg_plan)\n\nA number of {drake} functions can take the config object and do something with the information inside it. In our case, we’re going to pass the config to vis_drake_graph(), which builds an interactive dependency graph using {visNetwork}.\n\nvis_drake_graph(egg_config)\n\nThis generates an interactive output (see it here). Here’s a screenshot:\n\nThe visualisation is shape-coded by target type (e.g. functions are triangles) and colour-coded to show whether everything is up-to-date (e.g. green if it is). Arrows show the file dependencies (e.g. both the clean_data function and raw_data file come together to produce the data object).\n\n\n4. Make the plan\nHaving satisfied yourself that the plan looks correct, running the plan is as simple as:\n\nmake(egg_plan)\n\nThis executes all the instructions laid out in the egg_plan object and our HTML report pops out at the end.\nOf course, re-running the plan straight away again does… nothing. No code needs to be re-executed if nothing’s changed!\n\nSide note: the cache\nTurns out that {drake} is storing all the intermediate objects that were created when making your plan. They’re cached in a hidden .drake/ folder so they can be retrieved without needing to be re-created.\nThis means you can use the .drake/ cache to supply objects to an R Markdown file, which is achieved by either readd()ing or loadd()ing them. For example, the plot in the demo R Markdown file was called with loadd(plot).\n\n\n\n5. Make a change\nIf anything changes in our data or code then the downstream targets will be out of sync. Let’s pretend we’ve changed a line of code in the create_plot() function, which could be something is superficial as altering its title. What do you think will happen?\nWell, {drake} knows there’s been a change. You can check this by running source(\"R/functions.R\") in make.R again and then run outdated(egg_config). This prints the name of the altered file plus the other files impacted by it.\nWe can see this by recreating the dependency graph (see it here): the plot target is outdated, as are the targets downstream that depend on it (report and the egg-report.html file). This is indicated by them being coloured black. Here’s a static version:\n\nSo now we can see the real power of {drake}, as re-running the plan now will regenerate only the outdated files."
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#in-review",
    "href": "posts/2019-07-23-can-drake-rap/index.html#in-review",
    "title": "Can {drake} RAP?",
    "section": "In review",
    "text": "In review\nAt its simplest, you create a plan.R and you make() it.\nHopefully you’ve seen how {drake}:\n\nremembers the dependencies between the files of your analysis\nonly re-runs what needs to be re-run\n\nI think this alone can help build the reliability and trustworthiness of published statistical reports.\nOf course, this is a very simple use of {drake} and should act as a starting point. {drake} does a lot more, like high-performance computing and memory management, that may also come in useful for RAP."
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#environment",
    "href": "posts/2019-07-23-can-drake-rap/index.html#environment",
    "title": "Can {drake} RAP?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 20:33:27 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-07-23-can-drake-rap/index.html#footnotes",
    "href": "posts/2019-07-23-can-drake-rap/index.html#footnotes",
    "title": "Can {drake} RAP?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis publication could be a good candidate for RAP: content remains fairly similar between quarterly releases and it’s required to meet high standards of quality because it’s badged as National Statistics.↩︎\nYou don’t have to restrict yourself to this configuration of scripts, but it can make it easier to handle your project.↩︎"
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#tldr",
    "href": "posts/2021-03-23-shiny-badge/index.html#tldr",
    "title": "Make a {shiny} app README badge",
    "section": "tl;dr",
    "text": "tl;dr\nUse the {badgr} package to make a clickable README badge for a repo that contains an R Shiny app:"
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#badgr-badgr-badgr",
    "href": "posts/2021-03-23-shiny-badge/index.html#badgr-badgr-badgr",
    "title": "Make a {shiny} app README badge",
    "section": "Badgr badgr badgr",
    "text": "Badgr badgr badgr\nI made the {badgr} R package to take advantage of the full flexibility of shields.io—a service that builds README badges from a supplied URL string—from within R itself.1 You can find the source for the package on GitHub, visit its site built with {pkgdown}, or read a blog post about its inception.\nWait, what’s a README badge? It’s one of those little clickable buttons that provides at-a-glance info about a code repository, like its test coverage or build status.\nTurns out you can make custom badges by building a special URL to shields.io. For example, I use a custom badge to tell people that a repo has an associated rostrum.blog post (the rightmost of the badges in the screenshot at the top of this post).\nRecently I added a badge to each of my GitHub repositories that contain a Shiny app. The purpose is to let visitors:\n\nknow that the repo contains a Shiny app\nknow whether the app is hosted on the internet\nclick the badge to go directly to the live app\n\nI put out a tweet about this that got a little traction, so I figured it would be worthwhile to record the idea more permanently."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#install",
    "href": "posts/2021-03-23-shiny-badge/index.html#install",
    "title": "Make a {shiny} app README badge",
    "section": "Install",
    "text": "Install\nFirst, you can install the {badgr} package from GitHub using the {remotes} package.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/badgr\")\n\nAt time of writing, the package should ‘just work’, though it’s dependent ultimately on the shields.io service, of course. Leave an issue if you find something wrong."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#template",
    "href": "posts/2021-03-23-shiny-badge/index.html#template",
    "title": "Make a {shiny} app README badge",
    "section": "Template",
    "text": "Template\nThe code is in a GitHub Gist, should you want to access or bookmark it there. It’s a call to the get_badge() function:\n\nbadgr::get_badge(\n  \n  # Badge label\n  label = \"Shiny\",  # left-side text\n  label_color = \"white\",  # left-side colour\n  \n  # Badge message\n  message = \"shinyapps.io\",  # right-side text\n  color = \"blue\",  # right-side colour\n  \n  # Logo\n  logo_simple = \"RStudio\",  # named icon from simpleicons.org\n  logo_color = \"blue\",  # colour of simpleicons.org icon\n  \n  # Markdown link\n  md_link = \"https://matt.dray.shinyapps.io/randoflag/\",  # clickable link URL\n  \n  # Convenience arguments\n  browser_preview = TRUE, # preview badge in your browser\n  to_clipboard = TRUE  # copies markdown to paste into readme\n  \n)\n\n# Opening browser to display badge preview\n# Badge Markdown added to clipboard\n# [1] \"[![](https://img.shields.io/badge/Shiny-shinyapps.io-blue?style=flat&labelColor=white&logo=RStudio&logoColor=blue)](https://matt.dray.shinyapps.io/randoflag/)\"\nThe output is a Markdown string that you can paste into your README. You can see the string is actually a link within a link: the URL to the shields.io badge is wrapped by a link to the Shiny app itself.\nConveniently, the to_clipboard = TRUE argument copies the string to your clipboard and browser_preview = TRUE opens a browser window with a preview of your badge in a new tab. You’ll notice these outcomes are referenced in the output from the function.\nPasting that string into your Markdown or R Markdown README results in this badge when rendered:\n\n\n\n\n\nIn this example, the badge is from the repo for ‘randoflag’, which is a guessing-game Shiny app hosted on shinyapps.io, which serves a random emoji flag. You can read about that app in an earlier blog post.\nNote also that {badgr} is capable of incorporating bespoke icons, but we didn’t need to provide a custom RStudio logo because shields.io can easily display any icon that’s already part of simpleicons.org."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#variants",
    "href": "posts/2021-03-23-shiny-badge/index.html#variants",
    "title": "Make a {shiny} app README badge",
    "section": "Variants",
    "text": "Variants\nI think the badge is a useful at-a-glance recognition that the repo contains a Shiny app, whether it’s hosted or not, and a convenient clickable link to the app itself.\nI think the wording on the right-hand side of the badge is a good place to indicate the app’s status. Text variants could, for example, be:\n\nshinyapps.io (the app is live on RStudio’s shinyapps.io service)\nnot hosted (the repo contains a Shiny app, but it’s not hosted online)\nnot yet hosted (the Shiny app in the repo is in development, but not yet live on the internet)\n\nI’ve used all three of these so far, but you can use whatever text you want, really.\nI’ve already got use out of custom Shiny badges for my repos. I look forward to seeing some more in the wild."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#environment",
    "href": "posts/2021-03-23-shiny-badge/index.html#environment",
    "title": "Make a {shiny} app README badge",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-14 22:07:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] badgr_0.1.1\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     base64enc_0.1-3   fastmap_1.1.1     xfun_0.39        \n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       clipr_0.8.0      \n[13] evaluate_0.21     yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7   \n[17] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#footnotes",
    "href": "posts/2021-03-23-shiny-badge/index.html#footnotes",
    "title": "Make a {shiny} app README badge",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee also on CRAN the {badger} R package from Guangchuang Yu, which has a number of pre-baked badges for simplicity.↩︎"
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#tldr",
    "href": "posts/2022-09-24-pixeltrix/index.html#tldr",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve written {pixeltrix}, an R package that lets you select ‘pixels’ interactively from a plot window and returns your final image as a matrix. You could use it to design sprites, for example."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#pixel-perfect",
    "href": "posts/2022-09-24-pixeltrix/index.html#pixel-perfect",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Pixel perfect",
    "text": "Pixel perfect\nI’ve written before about creating very simple pixel art in R. To create a sprite of Link from The Legend of Zelda I had to write out by hand a vector that encoded its pixel values. It was tedious.\nThere are, however, a couple of options in R to take an image and extract the pixels from it: see Florian Privé’s Shiny app in the {pixelart} package and Mike Cheng’s (AKA coolbutuseless) blog post that also describes how to animate them.1\nBut what if you want to create a sprite from scratch? It would be great if you could click pixels interactively and be returned a matrix encoding your image.\nI couldn’t find an R package to do this, so I decided to make a very simple one: {pixeltrix} (as in ‘pixel’ and ‘matrix’, but also as in ‘tricks’2, lol).\nIt’s written entirely in base R (no Shiny or server needed) and can be run in the R console. It’s basically a repeat loop that runs image() to plot squares3 (hereafter ‘pixels’) and locator()4 to let you click those pixels on and off. The coordinates of each click are matched to the nearest pixel centre, the pixel’s value is incremented by 1 (or wrapped back to zero) and the image is redrawn.\nThe package is still in development, but I think it’s reached a useable state for my own purposes.\n\nℹ️ Update\nI lied. The package has been updated since this post. You can read about the changes in a more recent blogpost. Highlight: you can make animations now."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#enter-the-matrix",
    "href": "posts/2022-09-24-pixeltrix/index.html#enter-the-matrix",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Enter the matrix",
    "text": "Enter the matrix\nThe package is available for download from GitHub. I have some ideas on how to improve it; go ahead and add your own ideas to the issues tracker.\n\n# install.packages(remotes)  # if not yet installed\nremotes::install_github(\"matt-dray/pixeltrix\") # v0.1 in this post\nlibrary(pixeltrix)\n\nThe main function is click_pixels(), to which you pass plot dimensions (how many pixels tall and wide), the number of pixel ‘states’ (the number of values a pixel can take, so binary would be 2) and whether you want to put a grid over the plot (makes it easier to see where the pixels are).\n\nclick_pixels(\n  n_rows   = 3,\n  n_cols   = 3,\n  n_states = 2,\n  grid = TRUE\n) -&gt; x\n\nThis opens a plot window. Repeatedly click a pixel to cycle it through the number of states you asked for. For example, n_states = 4 means you cycle it through values of 0, 1, 2 and 3 (wrapping back to 0), which will be manifested in the plot as different shades of grey.\nNote that you can only click one pixel at a time, so you’ll have to do a lot of clicking if your n_states value is high. Colouring stuff in really slowly is called ‘mindfulness’, I believe; good for your wellbeing.\nWhen you’re done, you press the Esc key, or the ‘Finish’ button in the plot window of RStudio. I saved all the images below via the ‘Export’ button in RStudio.\n\nYou’re returned a matrix that contains the value of each pixel in your image. So if you had set n_states = 3, a twice-clicked pixel gets the value 2, an unclicked pixel defaults to a value of 0, etc.\n\nx\n\n     [,1] [,2] [,3]\n[1,]    1    0    1\n[2,]    0    1    0\n[3,]    1    0    1\nThis matrix is basically a blueprint of the image you created. You can take this and do other things with it. Maybe you’ll make art by passing it to ggplot() to match each of the pixel-state values to a colour. Maybe you’ll use it to plan your crochet or cross-stitch5, or to teach spatial epidemiology (!).\nIf you want to edit your matrix, you can pass it into edit_pixels(). This means you don’t have to start over from scratch with click_pixels() if you only want to change something small. Note that you can provide a higher n_states value to edit_pixels() than the current maximum in the matrix you provided."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#sprite-club",
    "href": "posts/2022-09-24-pixeltrix/index.html#sprite-club",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Sprite club",
    "text": "Sprite club\nMy main purpose for the package is to create simple sprites.\nI used {pixeltrix} to make each of the sprites below. They took about a minute each. It would’ve taken much longer to write their matrices by hand and to keep passing them to image() to visuliase them and make sure there weren’t any mistakes.\n\nTamagotchi\nHere’s a 1-bit original kuchipatchi sprite from the original 90s Tamagotchi digital pets. It uses the default of two pixel states (binary): so 0 for white and 1 for grey.\n\nclick_pixels(14, 14) -&gt; tam_sprite\n\n\n\n\nClick to expand matrix\n\n\ntam_sprite\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n [1,]    0    0    0    0    1    1    1    1    1     1     0     0     0     0\n [2,]    0    0    0    1    0    0    0    0    0     0     1     0     0     0\n [3,]    0    1    1    0    1    0    0    0    0     1     0     1     0     0\n [4,]    1    0    0    0    0    0    0    0    0     0     0     0     1     0\n [5,]    0    1    1    1    0    0    0    0    0     0     0     0     1     0\n [6,]    1    0    0    0    0    0    0    0    0     0     0     0     1     0\n [7,]    0    1    1    1    0    0    0    0    0     0     0     0     1     0\n [8,]    0    0    0    1    0    0    0    0    1     0     1     0     0     1\n [9,]    0    0    0    1    0    0    0    0    1     0     1     0     0     1\n[10,]    0    0    0    1    0    0    0    0    0     1     0     0     0     1\n[11,]    0    0    0    0    1    0    0    0    0     0     0     0     1     0\n[12,]    0    0    0    0    0    1    0    1    1     1     0     1     0     0\n[13,]    0    0    0    0    0    1    0    1    0     1     0     1     0     0\n[14,]    0    0    0    0    0    0    1    0    0     0     1     0     0     0\n\n\nPokémon\nHere’s the player character from the first generation of Pokémon games on the Game Boy. It uses three states (n_states = 3): value 0 is white, 1 is light grey and 2 is dark grey.\n\nclick_pixels(14, 16, 3) -&gt; poke_sprite\n\n\n\n\nClick to expand matrix\n\n\npoke_sprite\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n [1,]    0    0    0    0    2    2    2    2    2     2     0     0     0     0\n [2,]    0    0    0    2    1    1    1    1    1     1     2     0     0     0\n [3,]    0    0    2    1    1    1    1    1    1     1     1     2     0     0\n [4,]    0    0    2    1    1    1    1    1    1     1     1     2     0     0\n [5,]    0    2    2    2    1    0    0    0    0     1     2     2     2     0\n [6,]    0    2    2    0    2    2    2    2    2     2     0     2     2     0\n [7,]    2    0    2    0    0    0    0    0    0     0     0     2     0     2\n [8,]    2    0    0    0    0    2    0    0    2     0     0     0     0     2\n [9,]    0    2    2    0    0    2    0    0    2     0     0     2     2     0\n[10,]    0    2    2    2    0    0    1    1    0     0     2     2     2     0\n[11,]    2    0    0    2    2    2    2    2    2     2     2     0     0     2\n[12,]    2    0    0    2    2    2    2    2    2     2     2     0     0     2\n[13,]    0    2    2    2    1    1    2    2    1     1     2     2     2     0\n[14,]    0    0    2    1    2    2    1    1    2     2     1     2     0     0\n[15,]    0    0    2    1    1    1    2    2    1     1     1     2     0     0\n[16,]    0    0    0    2    2    2    0    0    2     2     2     0     0     0"
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#why",
    "href": "posts/2022-09-24-pixeltrix/index.html#why",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Why?",
    "text": "Why?\nTurns out the {pixeltrix} package is actually yak-shaving for another package I’m developing: {tamRgo}.\n{tamRgo} is a (very much work-in-progress) conceptual package for a Tamagotchi-like experience in the R console. You get a persistent interactive digital pet on your computer whose stats update in ‘real time’ while you’re away.\nI want to print a largeish canvas of pixels to visualise multiple pet ‘species’ and for the various interactions you can have (playing, feeding, cleaning). {pixeltrix} makes it much easier to design these scenes and returns matrices that I can add directly to {tamRgo}.\n\nℹ️ Update\nI’ve now written a post about {tamRgo}, where you can see how {pixeltrix} was used for the character sprites."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#environment",
    "href": "posts/2022-09-24-pixeltrix/index.html#environment",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:52:13 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] pixeltrix_0.2.1.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#footnotes",
    "href": "posts/2022-09-24-pixeltrix/index.html#footnotes",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can even go into the third dimension (i.e. voxels) with Mike’s {isocubes} and its extension {oblicubes} by Trevor L Davies. I used these in a demo of ‘3D’ dungeon-making with my {r.oguelike} package.↩︎\nIllusions, Michael.↩︎\nThe only awkward part is that image() doesn’t plot with bounds of 0 to 1. There’s an overhang dependent on the number of squares you want to draw. This results in some small but awkward calculations so that the clicks can be mapped properly to the nearest pixel and so the grid overlay can be placed correctly.↩︎\nI’ve written before about using the locator() function to select points on fictitious maps.↩︎\nBut see also Sharon Machlis’s ‘Overlay Mosaic Crochet Pattern Chart Generator’ Shiny app for crochet patterns and Ben Vigreux’s {embroidr} for planning embroidery projects.↩︎"
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#lewitt-remix",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#lewitt-remix",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "LeWitt ReMix",
    "text": "LeWitt ReMix\nThe third #RecreationThursday challenge involved Sol LeWitt’s Colour Bands (2000), which you can see on this prints catalogue. In short, each piece is square and contains patterns of colourful concentric lines that are arranged into panels of varying shapes with black borders.\nRather than recreate his artworks exactly, I decided to riff on the approach with a (very basic) Shiny app, which adds different types of lines and some randomisation.\nYou can access it by clicking this button (until I take it down1): \nAlternatively, download and launch it locally via an R session:\n\nshiny::runGitHub(\n  \"viz-recreation\", \"matt-dray\", \"main\",\n  \"2021-07-01_rt_lewitt/lewitt-remix-app\"\n)\n\nOr you can go to the app’s source on GitHub.\nIn the app, you can change a few parameters and then hit the ‘Generate’ button for a new variant, which can be downloaded to your computer. I’ve limited the inputs so that you get relatively ‘sensible’ outputs (whatever that means).\nYou could create something that looks similar to LeWitt’s original, or go off-piste and create a much larger number of panels or much thicker lines. Have fun!\nRead on for an explanation and for some examples."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#approach",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#approach",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Approach",
    "text": "Approach\nOnce again, I’ve used only base R functions to generate the outputs, just like my previous #RecreationThursday attempt. I have nothing against other tools, I just don’t care much for dependencies.\n\nThe trick\nI’ve used a cunning shortcut to mimic LeWitt: rather than draw any lines or shapes, I’ve just over-plotted points of decreasing size and variable colour with R’s built-in plotting characters. For example, 21 is a filled circle, 22 a square and so on. Here’s the shapes I used:\n\n\n\n\n\nWhen several of these plotting points are stacked on the same origin, it gives the effect of concentric lines. Here’s an example of plotting 50 unfilled circles of decreasing size on the same point:\n\n# Set variables\nshape &lt;- 21  # plotting character\nshp_n &lt;- 50  # number of points to plot\nshp_x &lt;- 2   # point size multiplier ('thickness')\npal   &lt;- rainbow(5)  # colours\n\n# Set margins to zero, see only the plot\npar(mar = rep(0, 4))\n\n# Plot concentric circles\nplot(\n  x    = rep(0, shp_n),\n  y    = rep(0, shp_n),\n  axes = FALSE,\n  pch  = shape,\n  cex  = shp_x * shp_n:1,\n  col  = pal\n)\n\n\n\n\nIf these circles are filled from largest to smallest, it will give the impression that lines have been created, when really it is a stack of points. I’ve added in a ‘multiplier’ variable that increases the gap from the edge of one point to the edge of the next smallest. The larger that variable, the large the gap, which in the output makes it look like the ‘lines’ are thicker.\n\n\nFunctions\nThere are two custom functions in the app: one function uses this point-stacking principle to generate a single-panel LeWitt remix and the other function calls multiple of these panels into a square grid.2\nThe arguments include the plotting character (circle, diamond, etc), the origin position that the centre of the point-stack will take (named for cardinal directions, like NE to place the origin in the top-right), the colours, the number of shapes to overplot (you want enough to completely cover the plot surface), the apparent ‘thickness’ of the ‘lines’ in the output, and the width of the box3 that surrounds the image.\n\n\nFunction demos\nSo here’s a demo of the function4 that generates a single panel. It uses uses the triangle plotting characters, which originate in the centre and alternate through rainbow colours. This is not too dissimilar from LeWitt’s originals.\n\n# Grab the functions from the repo\nsource(\"https://raw.githubusercontent.com/matt-dray/viz-recreation/main/2021-07-01_rt_lewitt/lewitt-remix-app/global.R\")\n\n# Demo: plot a single panel\njust_lewitt(\n  shape = 24,          # triangle plotting character\n  place = \"C\",         # 'centre'\n  pal   = rainbow(7),  # colours\n  shp_n = 200,         # number of points to plot\n  shp_x = 4,           # 'line thickness'\n  box_w = 20           # outer box thickness\n)\n\n\n\n\nAnd below is a panel made of four calls to the single-panel function. Elements like shape and the placement of the origin point are randomised.\nAlso, rather than use LeWitt’s colouring scheme, I decided to randomise the colour palette by sampling seven colours from R’s built-in named colours(). This can produce some pretty garish results, but also some quite pleasing ones too. (I’m colourblind, so your mileage may vary.)\n\n# Set a seed for reproducibility\nset.seed(5)\n\n# Set up a colour palette\nmy_pal &lt;- sample(colours(), 7)\n\n# Demo: plot a grid of randomised panels\njust_lewitt2(\n  dimn  = 2,       # x and y dimensions of grid\n  pal   = my_pal,  # colour palette\n  shp_x = 4,       # 'line thickness'\n  box_w = 10       # outer box thickness\n)\n\n\n\n\nThis can end up looking like an eye-popping Magic Eye puzzle.\n\nset.seed(7)\njust_lewitt2(\n  dimn  = 10,\n  pal   = sample(colours(), 7),\n  shp_x = 1,\n  box_w = 0\n)\n\n\n\n\nOr a bit like semaphore.\n\nset.seed(7)\njust_lewitt2(\n  dimn  = 2,\n  pal   = sample(colours(), 7),\n  shp_x = 20,\n  box_w = 0\n)\n\n\n\n\nOr whatever this is.\n\nset.seed(2)\njust_lewitt2(\n  dimn  = 10,\n  pal   = sample(colours(), 7),\n  shp_x = 1,\n  box_w = 20\n)\n\n\n\n\nUh-oh, I think I may have slipped through space-time.\n\nset.seed(11)\njust_lewitt2(\n  dimn  = 2,\n  pal   = sample(colours(), 7),\n  shp_x = 0.4,\n  box_w = 0\n)\n\n\n\n\nThe Shiny app basically fills these function arguments with your inputs, providing some randomness with a new seed that’s generated with each click of the ‘Generate’ button or if you move any of the sliders.\nYou can control the number of panels in the grid, the ‘thickness’ of the lines (which, remember, is just the relative gap between the overlapping plot points) and the thickness of the border (I could have made this value respond to other inputs, but I particularly like ignoring ‘balance’ and choosing extremely thick borders, or none at all).5\nI would love it if you tried out the app, used the ‘Download’ button to save a PNG copy6, and then showed me on Twitter."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#get-involved",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#get-involved",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Get involved",
    "text": "Get involved\nCheck out #RecreationThursday on Twitter. It’s a community challenge to recreate an art piece selected each fortnight by a rotating curator.\nThe timetable, art pieces, curators and example alt-text are available in Sharla Gelfand’s RecreationThursday repo on GitHub."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#environment",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#environment",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info"
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#footnotes",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#footnotes",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor now it’s hosted on the free version of shinyapps.io, which hosts a limited number of apps per user. I may take it down at some point to make room for an app in future, but the code will be available from the repo.↩︎\nLeWitt’s art isn’t just square. Some panels extend the length of the piece, while sometimes the borders aren’t boxes, but follow the edge of the curved lines, for example. I’ve kept to a grid for simplicity.↩︎\nBoxes are drawn on a panel-by-panel basis, so the ‘interior’ borders appear thicker because of the additive effect of surrounding boxes.↩︎\nThese are named like just_lewitt() because I like to start functions with verbs and thought it sounded a bit like a certain brand slogan.↩︎\nNote that there are no inputs for each panel’s plotting-point shape, nor the centre of origin within the panel (top-left, bottom-right, etc), nor the colours. Because chaos.↩︎\nThe filename of the output includes the date of creation and the values of each slider you selected, so you could get roughly recreate the format of the thing you generated. But I don’t want it to be that easy.↩︎"
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html",
    "title": "Wot3LdnEmojis",
    "section": "",
    "text": "I made Wot3LdnEmojis: a London-only clone of What3Emojis using London-related emojis and very little R code.\n\n\n\n\n\n\nHover over a grid cell to get the emoji-triplet reference. Zoom and pan, change to dark mode, toggle the grid."
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html#tldr",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html#tldr",
    "title": "Wot3LdnEmojis",
    "section": "",
    "text": "I made Wot3LdnEmojis: a London-only clone of What3Emojis using London-related emojis and very little R code.\n\n\n\n\n\n\nHover over a grid cell to get the emoji-triplet reference. Zoom and pan, change to dark mode, toggle the grid."
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html#u-wot-m8",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html#u-wot-m8",
    "title": "Wot3LdnEmojis",
    "section": "U wot m8",
    "text": "U wot m8\nBy now you’ve heard about various ‘alternative’ location systems that split the world into a grid and assign each with a value that’s more human-interpretable than latitude and longitude. For example, Google Plus Codes and What3Words.\nThe latter has been in the news a lot.1 In the meantime, their product has spawned a raft of spoofs, like the NSFW Four Kings Map, What3Emojis and What2Numbers, lol.2\nI like What3Emojis because it’s tongue-in-cheek3, yes, but they also understand the 21st Century mantra that:\n\nNo system is perfect, except for emoji.\n\nThe What3Emojis code is openly available, but of course I wondered how easy it would be to make something like this in R.\nI’ve limited it to London because us Londoners aren’t aware of anything outside of the M25. Read on for the how-to of this obnoxiously-named, cockney-baiting Wot3LdnEmojis system."
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html#adam-n-eve-it",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html#adam-n-eve-it",
    "title": "Wot3LdnEmojis",
    "section": "Adam ‘n’ Eve it",
    "text": "Adam ‘n’ Eve it\nFirst we need to attach the {sf} package for geospatial operations; {leaflet} for interactive mapping; and {tidyverse} for data wrangling. We’ll also set a seed here for reproducible results.4\n\nsuppressPackageStartupMessages({\n  library(sf)\n  library(leaflet)\n  library(tidyverse)\n})\nset.seed(9002488)\n\nWe can grab the official Greater London boundary from a GeoJSON of geographic units in the UK5, which is served by the Open Geography Portal from the Office for National Statistics.\nOr we would, if the site wasn’t down when I went to run this. Instead, we can use the handy JSONs hosted by Martin Chorley on GitHub. Hero.\n\nnuts_path &lt;- paste0(\n  \"https://raw.githubusercontent.com/martinjc/UK-GeoJSON/\",\n  \"master/json/eurostat/ew/nuts1.json\"\n)\n\nldn_sf &lt;- st_read(nuts_path, quiet = TRUE) %&gt;% \n  filter(NUTS112NM == \"London\")\n\nldn_sf\n\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -0.5102962 ymin: 51.28676 xmax: 0.3339957 ymax: 51.69187\nGeodetic CRS:  WGS 84\n  NUTS112CD NUTS112NM                       geometry\n1       UKI    London MULTIPOLYGON (((-0.3210316 ...\n\n\nSo, it’s an sf-class object that behaves like a dataframe, but has some extra geospatial information stored in it.\nWe’ve got the boundary, how do we do a grid?\nWhat3Emojis say they used ‘gazillions of 4m×4m triangles’ in their grid, but I don’t have the computing power for that and I can’t count that high.\nInstead, I bring you low-fidelity, massive hexagons. But hexagons are the patron shape of R users, so I think that’s okay.\n{sf} has st_make_grid() makes gridding easy. We can pass arguments for size and shape, then st_intersection() limits the grid to the area inside the London boundary only.\n\ngrid_sf &lt;- ldn_sf %&gt;% \n  st_make_grid(cellsize = 0.01, square = FALSE, flat_topped = TRUE) %&gt;% \n  st_intersection(ldn_sf)\n\nlength(grid_sf)\n\n[1] 2554\n\n\nI’ve checked the length of the object so we know how many grid cells we need to label uniquely. The fewest number of emoji we’ll need is therefore 14, since 14^3 is 2744.\nOf course, I have chosen emojis that at least vaguely represent London. Below I’ve added names and commented with my interpretation. Let me know if you have better ideas.\n\nldn_emo &lt;- c(\n  metro           = \"🚇\",  # the tube\n  guard           = \"💂\",  # Queen's Guard\n  queen           = \"👸\",  # HMQE2\n  castle          = \"🏰\",  # Tower of London\n  ferris_wheel    = \"🎡\",  # London Eye\n  bell            = \"🔔\",  # Big Ben (not a clock!)\n  whale           = \"🐋\",  # Natural History Museum\n  cityscape       = \"🏙️\",  # Canary Wharf\n  cucumber        = \"🥒\",  # The Gherkin\n  performing_arts = \"🎭\",  # Theatre District\n  stadium         = \"🏟️\",  # Wembley Stadium\n  dragon          = \"🐉\",  # City of London emblem\n  bird            = \"🐦\",  # pigeon\n  deciduous_tree  = \"🌳\"   # London plane tree\n)\n\nDepending on your operating system, there’s a chance you might note be able to see some of these emoji. Oh no! Ah well.\nYou may also have noticed that it’s utterly ridiculous to use London-related emojis to label locations in London. ‘Where are you?’ ‘London Eye, London Eye, London Eye’. ‘You’re at the London Eye?’ ‘No.’ Oh no! Ah well.\nAnyway, we can get all three-way combinations of these with expand.grid(), then shuffle them randomly.\n\nldn_emo_combo &lt;- expand.grid(\n  emo_a = ldn_emo, emo_b = ldn_emo, emo_c = ldn_emo\n) %&gt;% \n  sample_n(length(grid_sf)) %&gt;%\n  transmute(emo_triplet = paste(emo_a, emo_b, emo_c))\n\nldn_emo_combo$emo_triplet[1:3]\n\n[1] \"🐋 🏟️ 🌳\"  \"🚇 🏰 🎡\" \"🏟️ 🎭 🥒\" \n\n\nThen it’s a case of adding the emoji information into the grid_sf object, which can be done via st_df().\n\ngrid_sf_emo &lt;- grid_sf %&gt;% \n  st_sf(ldn_emo_combo) %&gt;%\n  rename(., geometry = .)\n\nhead(grid_sf_emo)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -0.1289476 ymin: 51.28676 xmax: 0.07882465 ymax: 51.29676\nGeodetic CRS:  WGS 84\n  emo_triplet                       geometry\n1     🐋 🏟️ 🌳 POLYGON ((-0.123496 51.2868...\n2    🚇 🏰 🎡 POLYGON ((-0.114679 51.2917...\n3     🏟️ 🎭 🥒 POLYGON ((0.06512026 51.290...\n4    🐦 🎡 🐋 POLYGON ((0.07882465 51.291...\n5     🏟️ 🌳 🎭 POLYGON ((-0.1149681 51.291...\n6       🏟️ 🏟️ 🏟️ POLYGON ((-0.1003241 51.296...\n\n\nYou can see the triplets have been added as an extra column so there’s one triplet per grid cell.\nTime to create the interactive map with {leaflet}, which is built up in layers.\nI’ve added a light and a dark underlying map that you can toggle between6 I’ve also made the hexagons transparent with thin borders to it’s easier to see the map, but you can toggle the grid on and off to help pinpoint a location.\n\nleaflet() %&gt;% \n  addProviderTiles(\"CartoDB.Voyager\", group = \"Light\") %&gt;%\n  addProviderTiles(\"CartoDB.DarkMatter\", group = \"Dark\") %&gt;%\n  addPolygons(\n    data = grid_sf_emo, group = \"Grid\", \n    color = \"grey\", weight = 1, opacity = 0.5,\n    fill = TRUE, fillOpacity = 0,\n    label = paste(grid_sf_emo$emo_triplet),\n    labelOptions = labelOptions(\n      direction = \"top\", style = list(\"font-size\" = \"35px\")\n    ),\n    highlightOptions = highlightOptions(color = \"blue\", weight = 3,)\n  ) %&gt;% \n  addLayersControl(\n    baseGroups = c(\"Light\", \"Dark\"),\n    overlayGroups = \"Grid\",\n    position = \"topright\",\n    options = layersControlOptions(collapsed = FALSE)\n  )\n\nI found:\n\nBuckingham Palace at 🔔🐦🥒 (Big Ben, pigeon, gherkin)\nLeicester Square at 🌳🌳🏙️ (plane tree, plane tree, Canary Wharf)\nThe Shard at 🐦🐋💂 (pigeon, whale, guard)\nWimbledon at 💂🌳🏟 (guard, plane tree, Wembley)\nThe Millennium Dome at 👸🚇🐉 (Queen, tube, dragon)\n\nLiterally minutes of fun. Of course, you shouldn’t use this map for anything whatsoever, possibly not even for your own amusement. I, on the other hand, can do whatever I like."
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html#environment",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html#environment",
    "title": "Wot3LdnEmojis",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:22 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] leaflet_2.1.2   lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [5] dplyr_1.1.2     purrr_1.0.1     readr_2.1.4     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.2   tidyverse_2.0.0 sf_1.0-14      \n\nloaded via a namespace (and not attached):\n [1] s2_1.1.4                utf8_1.2.3              generics_0.1.3         \n [4] class_7.3-22            KernSmooth_2.23-21      stringi_1.7.12         \n [7] hms_1.1.3               digest_0.6.33           magrittr_2.0.3         \n[10] timechange_0.2.0        evaluate_0.21           grid_4.3.1             \n[13] fastmap_1.1.1           jsonlite_1.8.7          e1071_1.7-13           \n[16] DBI_1.1.3               fansi_1.0.4             crosstalk_1.2.0        \n[19] scales_1.2.1            cli_3.6.1               rlang_1.1.1            \n[22] units_0.8-2             ellipsis_0.3.2          munsell_0.5.0          \n[25] withr_2.5.0             yaml_2.3.7              tools_4.3.1            \n[28] tzdb_0.4.0              colorspace_2.1-0        vctrs_0.6.3            \n[31] R6_2.5.1                proxy_0.4-27            lifecycle_1.0.3        \n[34] classInt_0.4-9          leaflet.providers_1.9.0 htmlwidgets_1.6.2      \n[37] pkgconfig_2.0.3         pillar_1.9.0            gtable_0.3.3           \n[40] glue_1.6.2              Rcpp_1.0.11             xfun_0.39              \n[43] tidyselect_1.2.0        rstudioapi_0.15.0       knitr_1.43.1           \n[46] htmltools_0.5.5         rmarkdown_2.23          wk_0.7.3               \n[49] compiler_4.3.1"
  },
  {
    "objectID": "posts/2021-09-14-wot3ldnemojis/index.html#footnotes",
    "href": "posts/2021-09-14-wot3ldnemojis/index.html#footnotes",
    "title": "Wot3LdnEmojis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis post is not about that company or its practices. See instead, for example, the excellent YouTube videos by Andrew Steele and Mia Mulder, or Terence Eden’s blog post. Even the BBC covered it.↩︎\nI was genuinely tricked by this website’s joke, fair play.↩︎\nThis blog is obviously a fan of emojis, see the one about creating SVG versions of the original emoji set or the one about a package for generating ‘emojiscapes’.↩︎\nThe seed value has a meaning related to London; guess what it is.↩︎\nThe file contains NUTS level 1, which is a European standard for administrative geographies. Now the UK has left the EU, it has technically switched to something called ‘International Territorial Units’ (ITU), which I think are the same boundaries as NUTS for the time being.↩︎\nDarkmode required to prevent damage to poor Millennial eyes when doomscrolling at 0300.↩︎"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#tldr",
    "href": "posts/2023-01-08-petrov/index.html#tldr",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "tl;dr",
    "text": "tl;dr\nIn which I prove wrong a tweeted Opta football statistic, using R and Transfermarkt data. Oh wait, actually Opta were right. Ah, heck."
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#petrov-rescue",
    "href": "posts/2023-01-08-petrov/index.html#petrov-rescue",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Petrov Rescue",
    "text": "Petrov Rescue\nBasically, for little reason, I dislike the style of the tweets on the Twitter feed for Opta1 (the company who do all the football stats).\nWhat is so outrageous? Each tweet always ends in a single, summary word that makes me cringe.\nWait, what? Let’s take a look at their most recent tweet at time of writing:\n\n14 - Harry Kane has scored 14 goals in his last 14 appearances in the FA Cup, averaging a goal every 63 minutes in the competition in this period. Guarantee.\n\n‘Guarantee’. Gah.\nOr this tweet:\n\n16 - Since his first appearance in the competition in January 2016, Leicester’s Kelechi Iheanacho has scored more FA Cup goals than any other player (16). Specialist.\n\n‘Specialist’. Sigh.\nA completely small and pointless thing to be annoyed by, right?\nBut here’s the scenario. Over the yuletide period (on Christmas day!) they ran this tweet:\n\n1 - Stiliyan Petrov (@StanPetrov19) is the only player to have played in the Premier League whose name contains all the letters in the word ‘Nativity’. Star.\n\nObviously, I have absolutely nothing against ‘Big Stan’. He’s a legend; a ‘star’, if you will. Captain of Aston Villa! Bulgaria! Battled leukaemia and still made it to nearly 600 games. One of the best Bulgarian/Premier League ‘Petrovs’, along with cult legend Martin.\nBut could this stat possibly be true? Surely there’s at least one other player. Perhaps a window of opportunity for me to avenge my feelings of cringe?\nOh, and obviously you can ignore the candid dismissals in the tweet’s replies, for example:\n\nWhat are we supposed to do with this information? [Picture of wryly-smiling duck.]\n\nNo, this is more important than any Opta tweet ever: what if it’s… wrong?"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#stan-in-r-but-not-rstan",
    "href": "posts/2023-01-08-petrov/index.html#stan-in-r-but-not-rstan",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Stan in R, but not {rstan}",
    "text": "Stan in R, but not {rstan}\nSo I looked into it using R, of course.\nTurns out it’s pretty straightforward with the excellent {worldfootballR} package by Jason Zivkovic, which helps fetch player data from Transfermarkt (among other suppliers).\nBasically, we can fetch data about footballers from every team in a given league’s season since its inception. So, aha, you cannot escape, Opta!\nMy little {soccercolleagues} package that I wrote about in early 2022 is built heavily (heavily!) around {worldfootballR} and has a convenience function we can use.\nThe niche2 primary objective of {soccercolleagues} is to let you find pairs of football players that were colleagues at some point. Like: ‘which current Premier League footballer has been team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?’3\nFollow along. As ever, you can install the {soccercolleagues} package from GitHub:\n\nif(!require(remotes)) install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/soccercolleagues\")\n\nWe’ll also use the {tidyverse} for wrangling.\n\nlibrary(soccercolleagues)\nlibrary(tidyverse)\n\nSo we can ask Transfermarkt for all the years of the English Premier League, which began in 1992:\n\n# This will take quite a long time...\nepl_players &lt;- soccercolleagues::get_players(\n  seasons = 1992:2022,\n  country = \"England\"\n)\n\nAnd now we can look for the players whose names contain the letters in ‘nativity’:\n\nepl_players |&gt;\n  distinct(player_name) |&gt;\n  mutate(\n    player_name = str_remove_all(tolower(player_name), \" \"),\n    n_count = str_count(player_name, \"n\"),\n    a_count = str_count(player_name, \"a\"),\n    t_count = str_count(player_name, \"t\"),\n    i_count = str_count(player_name, \"i\"),\n    v_count = str_count(player_name, \"v\"),\n    y_count = str_count(player_name, \"y\")\n  ) |&gt;\n  filter(\n    n_count &gt;= 1 &\n      a_count &gt;= 1 &\n      t_count &gt;= 2 &\n      i_count &gt;= 2 &\n      v_count &gt;= 1 &\n      y_count &gt;= 1\n  )\n\n# A tibble: 1 × 7\n  player_name    n_count a_count t_count i_count v_count y_count\n  &lt;chr&gt;            &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n1 stiliyanpetrov       1       1       2       2       1       1\nOof… they were right. He is the only one.\nWow, this humble pie is so delicious, thank you so much Opta for unintentionally spoonfeeding it to me.\nTo be clear: Opta’s data analysts have a good track record, as far as I know. But I’ve got my eye on you! You’ll slip up one day!\n…But wait. Opta were misnaming Stan as ‘Stylian Petrov’ in tweets as late as 2012. Get rekt! You missed the extra ‘i’ you need in ‘nativity’, fools! Put respect on Stiliyan’s name!\n‘Result’.4"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#environment",
    "href": "posts/2023-01-08-petrov/index.html#environment",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#footnotes",
    "href": "posts/2023-01-08-petrov/index.html#footnotes",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis post is not guerilla marketing for Opta. It would be extremely guerilla if they wanted to advertise on this blog.↩︎\nThere is definitely a burgeoning crossover of football stats and R users, see Ryo, Ben and Tony, for example.↩︎\nHint: it’s a very ‘boring’ footballer, lol.↩︎\nBy which I mean I lost 1-0.↩︎"
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#tldr",
    "href": "posts/2019-06-11-r-repo-template/index.html#tldr",
    "title": "A GitHub repo template for R analysis",
    "section": "tl;dr",
    "text": "tl;dr\nI made a simple GitHub repo template for analysis projects. You can go to the repo and hit the ‘use this template’ to try it out."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#sharing-is-caring",
    "href": "posts/2019-06-11-r-repo-template/index.html#sharing-is-caring",
    "title": "A GitHub repo template for R analysis",
    "section": "Sharing is caring",
    "text": "Sharing is caring\nGitHub has introduced repository templates to make it easier to share frequently-used repo structures and boilerplate code. You can copy a whole repo as many times as you like, unlike forks.\nFollowing a template can help keep your work organised and encourage consistency within and between projects. I can see this being useful for sharing optimal workflows across boundaries like government departments."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#tada",
    "href": "posts/2019-06-11-r-repo-template/index.html#tada",
    "title": "A GitHub repo template for R analysis",
    "section": "Tada",
    "text": "Tada\nI’ve made a lightweight repo template to make it easier for me to start very simple analysis projects with R.\nIt’s opinionated, but others may find it useful.\n\nTo use it, either:\n\nGo to the repo and click the green ‘use this template button’\nAppend the repo URL with ‘/generate’ to go straight to the repo copying page\n\nThe screen looks like when you create a new repo from scratch, but it mentions that ‘the new repository will start with the same files and folders’ as the template repo. Add a name and description for the repo copy and hit the ‘create repository from template’ button.\n\nThat’s it."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#basic-template-structure",
    "href": "posts/2019-06-11-r-repo-template/index.html#basic-template-structure",
    "title": "A GitHub repo template for R analysis",
    "section": "Basic template structure",
    "text": "Basic template structure\nMuch of the sentiment for creating this sort of folder structure has been described in detail elsewhere, including by Richard Fitzjohn and Joris Muller.\nIn short, the root has:\n\nexecutable R files, separated into ‘sensible’ units of analysis (‘read’, ‘tidy’, etc)\nan R Project file (.Rproj)\na .gitignore for R, with .DS_Store added\na README.md to summarise the project as a whole\n\nThere are folders for:\n\nR functions (R/)\nraw, untouched, read-only data sets (data/)\nreport source and output files (doc/)\nexternal files (ext/), such as pre-trained models\n\nOf course, these can be added to, removed or renamed as required."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#bulk-it-up",
    "href": "posts/2019-06-11-r-repo-template/index.html#bulk-it-up",
    "title": "A GitHub repo template for R analysis",
    "section": "Bulk it up",
    "text": "Bulk it up\nIt’s not enough to have structure alone. There are plenty of guides for code and file creation. For example:\n\nfiles should be named appropriately (advice from Jenny Bryan)\ncode should be consistent and follow a style guide (e.g. the tidyverse style guide), which is made easier with a linter, like {lintr}\nREADMEs are provided throughout, but documentation should continue in the analysis files themselves, with sensible comments throughout\n\nThe repo template focuses primarily on folder structure. It misses out some additional tools, including some that need a bit of further setup. You should think about including them anyway. For example:\n\nsome form of dependency management, like {renv}\ncontinuous integration, like Travis CI\na makefile, integration with {drake}, or similar\nDocker\nmuch much more\n\nThere’s a certain amount of personal preference in the tools and techniques for these things and it’s probably best left to the user.\nLet me know what you think is missing or what you would add."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#alternatives",
    "href": "posts/2019-06-11-r-repo-template/index.html#alternatives",
    "title": "A GitHub repo template for R analysis",
    "section": "Alternatives",
    "text": "Alternatives\nCopying a repo template might not be optimal for you, but you can generate the structure for an analytical project in other ways.\nOne example is the {starters} package from Locke Data, which can be installed with remotes::install_github(\"lockedata/starters\"). The create_analysis_project() function sets up a project folder for you with various arguments to add certain folders and setup things like dependency management, git and continuous integration.\nAnother option is to set up your analysis as a package, as outlined by Thomas J Leeper, for example. Jenny Bryan and Hadley Wickham’s {usethis} package provides lots of functions to help you create a package and add things to it, like create_project() and use_git().\nI like these two options more than the template, to be honest. The template is really for quick, simple analysis; mostly for my own purposes."
  },
  {
    "objectID": "posts/2019-06-11-r-repo-template/index.html#environment",
    "href": "posts/2019-06-11-r-repo-template/index.html#environment",
    "title": "A GitHub repo template for R analysis",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 21:44:48 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html",
    "href": "posts/2021-03-23-xml-health/index.html",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "",
    "text": "Run barcode: one year of runs, darker bands are longer distances."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#tldr",
    "href": "posts/2021-03-23-xml-health/index.html#tldr",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can export your Apple Health data as an XML file. This includes workouts linked from other apps, like Nike Run Club. I used the R packages {xml2} and the tidyverse to extract and clean my step counts and running activity.\n\n Note\nI revisited the theme of this post in 2023, but the format of the Apple Health download had changed. I updated the code needed to analyse the data and wrote a new post."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#app-storage",
    "href": "posts/2021-03-23-xml-health/index.html#app-storage",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "App storage",
    "text": "App storage\nMy healthcare provider peeks at the Apple Health app and rewards me if I meet daily step-count targets. I know my usual pattern of steps has been disrupted since the start of COVID-19 lockdowns, which began in the UK a year ago today.\nTo keep the step counter ticking over, I took up a new hobby on lockdown day one: running. I’ve recorded this activity on the Nike Run Club app, which I’ve linked to Apple Health.\nI’ve in excess of 99 problems and at least two of them are related specifically to these health data:\n\nI don’t think my healthcare supplier is rewarding my step counts correctly and I need evidence1\nIt’s not easy to get data out of the Nike Run Club app for further analysis\n\nLuckily, you can export the data—which is stored locally on your iPhone—including any workouts linked from other apps. It’s provided as XML, which is a sensible, structured storage format, but not necessarily that familiar to the general R user.\nThis post looks at how to extract the data of interest and do something useful with it."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#warm-up",
    "href": "posts/2021-03-23-xml-health/index.html#warm-up",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Warm up",
    "text": "Warm up\nTo export activity data from the Health app (iOS 14.4):\n\nOpen the Health app and tap your icon in the top right corner\nScroll down and tap ‘Export All Health Data’\nTap ‘Export’ in the pop-up and the sharing tray will slide up for you to choose where to send the data\n\nYou’ll get a zipped folder containing two XML files, export_cda.xml and export.xml, the latter of which contains your data. I stored and unzipped my folder locally for the purposes of this post.\n\ntemp &lt;- tempdir()\nunzip(zipfile = \"~/Downloads/export.zip\", exdir = temp)\n\nMy unzipped folder was about 140 MB and contained about 5 years of data.\nWe’ll also need a few R packages. The {xml2} package is on CRAN2 and has the tools you need to read and reshape XML files. It may be familiar if you’ve ever done any webscraping with R.3\nWe’ll also iterate to accumulate with the {purrr} package and do the ol’ wrangle-jangle with some other tidyverse packages.\n\nlibrary(xml2)       # read and wrangle XML\nlibrary(tidyverse)  # {purrr}, {dplyr}, {ggplot2}, {forcats}\nlibrary(lubridate)  # date/time handling"
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#x-tract",
    "href": "posts/2021-03-23-xml-health/index.html#x-tract",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "X-tract",
    "text": "X-tract\nThe aptly named xml2::read_xml() function will let you read your export.xml file.\n\nxml_in &lt;- read_xml(file.path(temp, \"apple_health_export/export.xml\"))\n\nHere’s a truncated view of the file’s structure:\n\nxml_in\n\n{xml_document}\n&lt;HealthData locale=\"en_GB\"&gt;\n [1] &lt;ExportDate value=\"2021-03-21 17:03:31 +0000\"/&gt;\n [2] &lt;Me HKCharacteristicTypeIdentifierDateOfBirth=\"\" HKCharacteristicTypeIde ...\n [3] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MD’s phone\" ...\n [4] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MD’s phone\" ...\n [5] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MD’s phone\" ...\n....\n\n\nThe object has the class xml_document. You can see metadata in the first few rows and then you can see the actual data is stored in a series of ‘nodes’. Each record is an individual entry in our activity log and has attributes like type (e.g. step count), sourceName (i.e. the device name) and unit (e.g. a count).\nWe’re interested in extracting data from two types of node:\n\nRecord for the step counts, as previewed above\nWorkouts, which is where the Nike Run Club app data is stored\n\nYou can extract specific parts of an XML file by reference to their xpaths, which are special regex-like strings that point to specific places in the document. The function xml2::xml_find_all() takes an xpath and returns the matching information.\nWe need only supply the simple high-level xpaths //Record and //Workouts for our needs. The forward slashes read like ‘select all the nodes in the document with the following name’.\nOnce extracted, we can get the attributes—like type, sourceName, etc—of each node using xml2::xml_attr()."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#step-to-it",
    "href": "posts/2021-03-23-xml-health/index.html#step-to-it",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Step to it",
    "text": "Step to it\nSo, let’s grab all the ‘record’ nodes and preview the first one.\n\nrecords &lt;- xml_find_all(xml_in, \"//Record\")\nrecords[[1]]\n\n{xml_node}\n&lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MD’s phone\" unit=\"count\" creationDate=\"2015-06-21 16:57:31 +0000\" startDate=\"2015-06-21 16:31:17 +0000\" endDate=\"2015-06-21 16:33:00 +0000\" value=\"28\"&gt;\n\n\nEach record is a single ‘bout’ of activity as perceived by the app. You can see the first record is a step count from my phone on 21 June 2015, which lasted about two minutes and consisted of 28 steps.\nFor my purposes I only care about three attributes: the date4, the type of activity and the associated value. We can pass a named vector of each attribute to xml2::xml_attr() using purrr::map_dfr() to collate the output into a tidy rectangle.\n\nrecords_df &lt;- map_dfr(  # rowbind to dataframe\n  c(date = \"creationDate\", type = \"type\", steps = \"value\"),\n  ~xml_attr(records, .x)\n)\n\nglimpse(records_df)  # preview\n\nRows: 487,590\nColumns: 3\n$ date  &lt;chr&gt; \"2015-06-21 16:57:31 +0000\", \"2015-06-21 16:57:31 +0000\", \"2015-…\n$ type  &lt;chr&gt; \"HKQuantityTypeIdentifierStepCount\", \"HKQuantityTypeIdentifierSt…\n$ steps &lt;chr&gt; \"28\", \"15\", \"44\", \"69\", \"80\", \"95\", \"1\", \"33\", \"41\", \"15\", \"24\",…\n\n\nSo what type of activity has been logged in the Record nodes?\n\npull(distinct(records_df, type))\n\n [1] \"HKQuantityTypeIdentifierStepCount\"                     \n [2] \"HKQuantityTypeIdentifierDistanceWalkingRunning\"        \n [3] \"HKQuantityTypeIdentifierActiveEnergyBurned\"            \n [4] \"HKQuantityTypeIdentifierFlightsClimbed\"                \n [5] \"HKQuantityTypeIdentifierHeadphoneAudioExposure\"        \n [6] \"HKQuantityTypeIdentifierWalkingDoubleSupportPercentage\"\n [7] \"HKQuantityTypeIdentifierWalkingSpeed\"                  \n [8] \"HKQuantityTypeIdentifierWalkingStepLength\"             \n [9] \"HKQuantityTypeIdentifierWalkingAsymmetryPercentage\"    \n[10] \"HKCategoryTypeIdentifierSleepAnalysis\"                 \n[11] \"HKCategoryTypeIdentifierMindfulSession\"                \n\n\nI’m interested in step counts, so I’ll isolate HKQuantityTypeIdentifierStepCount, convert the date to datetime class and then summarise the number of steps per day.\n\nrecords_out &lt;- records_df %&gt;% \n  filter(type == \"HKQuantityTypeIdentifierStepCount\") %&gt;%\n  mutate(date = as.Date(date), steps = as.integer(steps)) %&gt;%\n  group_by(date) %&gt;%\n  summarise(steps = sum(steps), .groups = \"drop\") %&gt;% \n  mutate(\n    points = case_when(\n      steps &gt; 12500 ~ 8L, steps &gt; 10000 ~ 5L, steps &gt; 7000 ~ 3L,\n      TRUE ~ 0L\n    )\n  )\n\nglimpse(records_out)\n\nRows: 2,094\nColumns: 3\n$ date   &lt;date&gt; 2015-06-21, 2015-06-22, 2015-06-23, 2015-06-24, 2015-06-25, 20…\n$ steps  &lt;int&gt; 647, 11273, 10071, 3586, 5206, 10362, 19036, 3980, 11850, 15937…\n$ points &lt;int&gt; 0, 5, 5, 0, 0, 5, 8, 0, 5, 8, 3, 5, 5, 0, 0, 5, 5, 3, 0, 8, 8, …\n\n\nI also created a new column that generates a ‘points’ value that my healthcare provider assigns to meeting certain step-count thresholds. Now I, tiny David, can sling this evidence into the eye of the behemoth cyclops that is my healthcare provider.\nI recommend checking first if the data look sensible, because my highest step count was apparently 10,692,175. I don’t recall walking to Chicago and back to London on that day.\n\nOn a walkabout\nThere’s so many ways you could investigate the step count data, like how frequency changes by day of the week or time of year, for example.\nHere’s a quick exploration: how did my step-count frequency change in the year up to 23 March 2020—the announcement of the UK’s first lockdown—and in the year since?\n\nrecords_out %&gt;% \n  mutate(\n    covid_year = case_when(\n      date &gt;= \"2020-03-23\" & date &lt; \"2021-03-23\" ~ \"Year post-lockdown\",\n      date &gt;= \"2019-03-23\" & date &lt; \"2020-03-23\" ~ \"Year pre-lockdown\", \n      TRUE ~ NA_character_\n    )\n  ) %&gt;% \n  filter(!is.na(covid_year)) %&gt;% \n  ggplot() + \n  geom_histogram(aes(steps / 1000), binwidth = 1) + \n  facet_grid(~fct_rev(covid_year)) +\n  labs(x = \"Steps (thousands)\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\nHa, not a surprise, but interesting to see it visually: there’s been a far higher proportion of days with a very small number of steps in the lockdown year. The second peak of the bimodal distribution has also fallen to a lower value with a more gradual tail. This is understandable: I used to walk on parts of my commute and lunchtimes, whereas my lockdown days have involved running or basically nothing."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#jog-on",
    "href": "posts/2021-03-23-xml-health/index.html#jog-on",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Jog on",
    "text": "Jog on\nNow let’s look at the year’s worth of running data from the Workout nodes of the XML.\n\nworkouts &lt;- xml_find_all(xml_in, \"//Workout\")\nworkouts[[1]]\n\n{xml_node}\n&lt;Workout workoutActivityType=\"HKWorkoutActivityTypeRunning\" duration=\"24.81425000031789\" durationUnit=\"min\" totalDistance=\"5.043024469383905\" totalDistanceUnit=\"km\" totalEnergyBurned=\"384.382\" totalEnergyBurnedUnit=\"kcal\" sourceName=\"Nike Run Club\" sourceVersion=\"2003161908\" creationDate=\"2020-03-23 08:01:39 +0000\" startDate=\"2020-03-23 07:36:45 +0000\" endDate=\"2020-03-23 08:01:39 +0000\"&gt;\n[1] &lt;MetadataEntry key=\"HKIndoorWorkout\" value=\"0\"/&gt;\n[2] &lt;WorkoutEvent type=\"HKWorkoutEventTypePause\" date=\"2020-03-23 08:01:34 +0 ...\n\n\nThe attributes are slightly different for workouts compared to records. This time I care about the activity type (just runs), the date, the distance and the time taken. Unfortunately there isn’t any data on split times in this file, which means I can’t calculate record times, nor is there other detail like altitude gained.\n\nworkouts_df &lt;- map_dfr(\n  c(date = \"creationDate\", type = \"workoutActivityType\",\n    km = \"totalDistance\", dur = \"duration\"),\n  ~xml_attr(workouts, .x)\n) \n\nglimpse(workouts_df)\n\nRows: 215\nColumns: 4\n$ date &lt;chr&gt; \"2020-03-23 08:01:39 +0000\", \"2020-03-25 08:14:38 +0000\", \"2020-0…\n$ type &lt;chr&gt; \"HKWorkoutActivityTypeRunning\", \"HKWorkoutActivityTypeRunning\", \"…\n$ km   &lt;chr&gt; \"5.043024469383905\", \"5.0160254470843\", \"5.014558848776319\", \"5.0…\n$ dur  &lt;chr&gt; \"24.81425000031789\", \"24.46356666882833\", \"24.37278333504995\", \"2…\n\n\nWe can do a bit of light wrangling to convert ‘decimal minutes’ to seconds, compute a rough pace, and round the values for readability. I used lubridate::seconds_to_period() to generate a period-class value that presents the data in days, hours, minutes and seconds.\n\nworkouts_out &lt;- workouts_df %&gt;% \n  filter(type == \"HKWorkoutActivityTypeRunning\", km &gt; 1) %&gt;% \n  mutate(\n    date = as.Date(date),\n    across(c(dur, km), as.numeric), dur = round(dur, 3)\n  ) %&gt;% \n  separate(col = dur, into = c(\"mins\", \"mins_dec\"), sep = \"\\\\.\") %&gt;% \n  transmute(\n    date, km,\n    s = (as.numeric(mins) * 60) + ((as.numeric(mins_dec) / 1000) * 60),\n    mins = seconds_to_period(round(s)),\n    avg_pace = seconds_to_period(round(s / km)),\n    s = round(s), km = round(km, 2)\n  )\n\nglimpse(workouts_out)\n\nRows: 164\nColumns: 5\n$ date     &lt;date&gt; 2020-03-23, 2020-03-25, 2020-03-27, 2020-03-29, 2020-03-31, …\n$ km       &lt;dbl&gt; 5.04, 5.02, 5.01, 5.03, 5.03, 5.02, 5.02, 5.02, 5.01, 5.02, 5…\n$ s        &lt;dbl&gt; 1489, 1468, 1462, 1545, 1476, 1435, 1414, 1468, 1410, 1366, 1…\n$ mins     &lt;Period&gt; 24M 49S, 24M 28S, 24M 22S, 25M 45S, 24M 36S, 23M 55S, 23M …\n$ avg_pace &lt;Period&gt; 4M 55S, 4M 53S, 4M 52S, 5M 7S, 4M 53S, 4M 46S, 4M 42S, 4M …\n\n\n\nHigh-vis apparel\nThe data are now quite rich and there’s many ways to explore it. As a starter, here’s some basic summaries for the year to 23 March 2021:\n\nworkouts_out %&gt;% \n  summarise(\n    `Total runs` = n(),\n    `Total distance (km)` = round(sum(km)),\n    `Total time` = seconds_to_period(sum(s)),\n    `Days per run` = round((max(date) - min(date)) / `Total runs`, 1),\n    `Best average pace` = seconds_to_period(min(round(s / km))),\n    `Total runs of 5 to 10 km` = nrow(filter(., km &gt;= 5 & km &lt; 10)),\n    `Total runs of 10 to 21.1 km` = nrow(filter(., km &gt;= 10 & km &lt; 21.1)),\n    `Total runs of over 21.1 km` = nrow(filter(., km &gt; 21.1))\n  ) %&gt;% \n  mutate(across(everything(), as.character)) %&gt;% \n  pivot_longer(everything(), names_to = \"Summary\", values_to = \"Value\") %&gt;% \n  knitr::kable()\n\n\n\n\nSummary\nValue\n\n\n\n\nTotal runs\n164\n\n\nTotal distance (km)\n1306\n\n\nTotal time\n4d 14H 39M 15S\n\n\nDays per run\n2.2\n\n\nBest average pace\n4M 22S\n\n\nTotal runs of 5 to 10 km\n98\n\n\nTotal runs of 10 to 21.1 km\n62\n\n\nTotal runs of over 21.1 km\n3\n\n\n\n\n\nIn terms of visualisation, I’m interested in what my pattern of run distance looks like. The code below produces plots for run distances by date (top left), cumulative distance by date (bottom left), and a histogram of run distances in 1 km bins (right).\n\np1 &lt;- ggplot(workouts_out) + \n  geom_point(aes(date, km), shape = 1) +\n  labs(x = \"\", y = \"Distance (km)\") +\n  theme_light()\n\np2 &lt;- workouts_out %&gt;% \n  mutate(km_cum = cumsum(km)) %&gt;% \n  ggplot() +\n  geom_line(aes(date, km_cum)) +\n  labs(x = \"\", y = \"Cumulative distance (km)\") +\n  theme_light()\n\np3 &lt;- ggplot(workouts_out) +\n  geom_histogram(aes(km), binwidth = 1) +\n  labs(x = \"Distance (1 km bins)\", y = \"Frequency\") +\n  theme_light()\n\nlibrary(patchwork)  # easy plot layouts\n(p1 / p2) | p3\n\n\n\n\nYou can see I started with a lot of 5 km runs in April and May 2020, before branching out to 10 km or more. I’ve been pretty consistent in running every two or three days and that’s reflected in the chart of cumulative distance. The histogram shows that most runs have been just above 5 km, with another peak just above 10 km. That makes sense: I intentionally set out to run at least these distances.\nAnother idea is that you you could use the {calendR} package to plot a calendar of your activity.5 Or you could do something more abstract: here’s a ‘run barcode’ with a line per run for the full year. The darker the line, the further the distance travelled.\n\nrun_days &lt;- left_join(\n  tibble(date = as_date(ymd(\"2020-03-23\"):ymd(\"2021-03-22\"))),\n  workouts_out %&gt;% \n    filter(date &gt;= \"2020-03-23\" & date &lt; \"2021-03-23\") %&gt;%\n    group_by(date) %&gt;% summarise(km = sum(km), .groups = \"drop\"),\n  by = \"date\"\n) %&gt;% replace_na(list(run = 0))\n\npar(mar = rep(0, 4))\nimage(matrix(run_days$km), col = grey.colors(11, 0.8, 0))\nbox(col = \"white\")\n\n\n\n\nA few things stick out to me when scanning this barcode. The three black bands are the half-marathons; the white space (i.e. no runs) after the first of these indicates the rest my knees needed afterwards. There’s a thick grey band after halfway, which is when I tried to run seven days in a row (the app is gamified and you get a special badge for doing that). You can also see how the pattern was more regular at the start, but I’ve since settled into a routine of just trying to fit in three runs and about 25 km per week."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#cool-down",
    "href": "posts/2021-03-23-xml-health/index.html#cool-down",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Cool down",
    "text": "Cool down\nSo the premise was quite simple: download your Apple Health data, read the XML file, extract the nodes of interest, wrangle lightly and present it. I’ve only done a basic exploration of the data, but there’s so much more you could do.\nAfter starting this post, I noticed that Mark Koester has written an in-depth post about Apple Health data, with a focus on Python code for achieving a similar goal. It notes third-party tools like QS Access for extracting data into a friendlier CSV format, for example.\nIt’ll be interesting to revisit this in another year’s time to see how a ‘return to normality’ (whatever that means) might impact these patterns of activity."
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#environment",
    "href": "posts/2021-03-23-xml-health/index.html#environment",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:14 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] patchwork_1.1.2 lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [5] dplyr_1.1.2     purrr_1.0.1     readr_2.1.4     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.2   tidyverse_2.0.0 xml2_1.3.5     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    compiler_4.3.1    tidyselect_1.2.0 \n [5] scales_1.2.1      yaml_2.3.7        fastmap_1.1.1     R6_2.5.1         \n [9] labeling_0.4.2    generics_0.1.3    knitr_1.43.1      htmlwidgets_1.6.2\n[13] munsell_0.5.0     pillar_1.9.0      tzdb_0.4.0        rlang_1.1.1      \n[17] utf8_1.2.3        stringi_1.7.12    xfun_0.39         timechange_0.2.0 \n[21] cli_3.6.1         withr_2.5.0       magrittr_2.0.3    digest_0.6.33    \n[25] grid_4.3.1        rstudioapi_0.15.0 fontawesome_0.5.1 hms_1.1.3        \n[29] lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21     glue_1.6.2       \n[33] farver_2.1.1      fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[37] tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-03-23-xml-health/index.html#footnotes",
    "href": "posts/2021-03-23-xml-health/index.html#footnotes",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn this vein, you can also use your Google Maps data to convince the church to marry you, as per Duncan Garmonsway.↩︎\n‘2’ because it’s a binding to libxml2, but perhaps also because it’s the spiritual successor to {XML}, which is R’s veteran package for XML handling.↩︎\nFor example, see previous posts about travelling the NBA and polite webscraping.↩︎\nLuckily, I live at +0000, so no time-related data wrangling is required for me.↩︎\nAnother reference to Duncan’s post.↩︎"
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html",
    "title": "Generate The Mountain Goats lyrics",
    "section": "",
    "text": "John Darnielle with the green-scaled slipcase for In League with Dragons (via Merge Records)"
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#tldr",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#tldr",
    "title": "Generate The Mountain Goats lyrics",
    "section": "tl;dr",
    "text": "tl;dr\nYou can generate text using the {markovifyR} package. Why not do it for lyrics collected with The {spotifyr} package? And why not do it for a band with a huge back catalogue like The Mountain Goats?"
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#in-league-with-dragons",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#in-league-with-dragons",
    "title": "Generate The Mountain Goats lyrics",
    "section": "In League with Dragons",
    "text": "In League with Dragons\nThe Mountain Goats released In League with Dragons today, their seventeenth studio album.\nJohn Darnielle has written a lot of words across the Mountain Goat’s back catalogue. His lyrics are poetic and descriptive, covering fictional and autobiographical themes that include substance abuse, professional wrestling and cadaver-sniffing dogs.\nCan we generate new Mountain Goats lyrics given this rich text data set? This is a short post to do exactly that using the {spotifyr}, {genius} and {markovifyR} packages for R.\nHit play below while reading to generate the right mood."
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#get-lyrics",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#get-lyrics",
    "title": "Generate The Mountain Goats lyrics",
    "section": "Get lyrics",
    "text": "Get lyrics\nThe {spotifyr} package pulls artist and album information from the music streaming service Spotify, along with some interesting audio features like ‘danceability’ and ‘acousticness’. It also fetches lyrics from Genius via the {genius} package .\nFirst get a developer account for the Spotify API. Run usethis::edit_r_environ() and add your client ID and secret in the form SPOTIFY_CLIENT_ID=X and SPOTIFY_CLIENT_SECRET=Y. The get_spotify_access_token() function will add an access token to your environment, which will authenticate each API request.\n\nlibrary(spotifyr)  # install.packages(\"spotifyr\")\naccess_token &lt;- get_spotify_access_token()\n\nThe get_discography() function fetches a named artist’s back-catalogue, including the lyrics. Beware: this may include some duplicates from different regions or because of reissues or deluxe versions.\n\ngoat_discography &lt;- spotifyr::get_discography(\"the mountain goats\")\n\nYou can run the line above, or you can just use download.file() to get an RDS version stored on rostrum.blog (note that this file will become out of date as the Mountain Goats release more material, which they frequently do!).\nI’ve done this already and saved the file for future use. I’ll read that in now:\n\n\n[1] 399  41\n\n\nThis is a relatively wide data frame with 41 columns of data for nearly 400 songs. Let’s simplify the columns and for fun we can look at five random sings and their ‘energy’.\n\nlibrary(dplyr)  # for data manipulation and %&gt;%\n\ngoat_disco &lt;- goat_discography %&gt;% \n  ungroup() %&gt;% \n  select(\n    album_name, album_release_year,  # album\n    track_name, track_number, duration_ms,  # track info\n    key_name, mode_name, key_mode, tempo, time_signature,  # music info\n    danceability, energy, loudness, mode, speechiness,  # audio features\n    acousticness, instrumentalness, liveness, valence,  # audio features\n    lyrics\n  )\n\nsample_n(goat_disco, 5) %&gt;%\n  select(album_name, track_name, energy)  # a sample\n\n# A tibble: 5 × 3\n  album_name        track_name                energy\n  &lt;chr&gt;             &lt;chr&gt;                      &lt;dbl&gt;\n1 Heretic Pride     Michael Myers Resplendent  0.269\n2 Bitter Melon Farm The Bad Doctor             0.459\n3 Heretic Pride     Autoclave                  0.781\n4 Zopilote Machine  Alpha Incipiens            0.713\n5 Sweden            Tollund Man                0.513\n\n\nI’ll be saving this data frame for some other analysis, but for now we’ll need only the lyrics. The lyrics are stored in a list-column as a separate tibble (data frame) per song.\n\nlibrary(tidyr)  # for unnest()\n\ngoat_lyrics &lt;- goat_disco %&gt;%\n  filter(lyrics != \"NULL\") %&gt;%  # remove rows where lyrics weren't collected\n  unnest(lyrics) %&gt;%  # unpack the lyrics list-column\n  filter(!is.na(lyric)) %&gt;%  # remove empty lyrics\n  select(-line) %&gt;%  # unneeded column\n  group_by(lyric) %&gt;% slice(1) %&gt;%  ungroup() %&gt;% # remove duplicate lyrics\n  pull(lyric)  # convert column to character vector\n\nsample(goat_lyrics, 10)  # a sample\n\n [1] \"Say that the time is near\"                                 \n [2] \"And watch for the cars\"                                    \n [3] \"Never forget what it felt like to live in rooms like these\"\n [4] \"Grow fat and grow old and go blind and be content\"         \n [5] \"He made a banquet for the stray dogs of the air\"           \n [6] \"Sky grey and misty\"                                        \n [7] \"Swing low sweet chariot\"                                   \n [8] \"From the fragile outline of your hips\"                     \n [9] \"But as the sun becomes a blazing orange ball of fire\"      \n[10] \"I hear your voice getting stronger and louder\""
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#generate-lyrics",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#generate-lyrics",
    "title": "Generate The Mountain Goats lyrics",
    "section": "Generate lyrics",
    "text": "Generate lyrics\nWe can use a Markov chain to generate new lyrics based on our data set. Basically, it will predict the next word from the current one based on the likelihood from our input data set. You can read more about this principle elsewhere.\nThe {markovifyR} package is a wrapper for the Python package markovify, which ‘is a simple, extensible Markov chain generator’. You can install markovify at the command line via R’s system() function, then install {markovifyR} from GitHub and {furrr} from CRAN.\n\n# system(\"pip3 install markovify\")\nlibrary(markovifyR)  # remotes::install_github(\"abresler/markovifyR\")\nlibrary(furrr)  # install.packages(\"furrr\")\n\nNow we can generate the model given all the lyrics.\n\nmarkov_model &lt;- generate_markovify_model(\n    input_text = goat_lyrics,\n    markov_state_size = 2L,\n    max_overlap_total = 25,\n    max_overlap_ratio = 0.7\n  )\n\nYou can meddle with these controls, but I’ve kept to the suggested defaults for now. Note that ‘overlap’ relates to the likelihood of generating whole sentences that already exist. See markovify for more detail.\n\nGenerate lines\nUse the markovify_text() function with our markov_model object to generate single lines.\nFans of the Mountain Goats will no doubt recognise some of the phrases from existing songs.\n\ngoat_speak &lt;- markovify_text(\n  markov_model = markov_model,\n  maximum_sentence_length = NULL,\n  output_column_name = 'goat_speak',\n  count = 5,\n  tries = 100,\n  only_distinct = TRUE,\n  return_message = TRUE\n)\n\ngoat_speak: Like a trashcan fire in a folding chair\ngoat_speak: Darkness climbing up the variables\ngoat_speak: And when the rain on our tongues\ngoat_speak: Wear black back to where I go, do what you said that you make\ngoat_speak: I know you're leaving too\n\n\nI ran this function a few times and here a few outputs that made me laugh (or think):\n\nBut I felt all the Portuguese water dogs?\nI write reminders on my kimono that I could not remember\nLeann Rimes on the ocean\nSunset spilling through your megaphone\nIt’s the most gorgeous cow I’d ever wanted\nI hope I never liked Morrissey\nWent and got the case of vodka from a disco in old east Berlin\nFresh coffee at sunrise, warm my lips like a dying man\nBut my love is like a tattoo into my ear\nAnd you brought me a bowl of cooked wild grasses\nWe had hot caramel sticking to her skin\nAnd then the special chicken\nAnd a bird we would have liked brought the Norman invasion\nHow come there’s peacocks in the face of the rainbow\n\n\n\nGenerate a verse\nYou can also choose to seed the first word in the sentence. You can do this in such a way that you can create a sort-of possible-sounding stanza.\n\ngoat_speak &lt;- markovify_text(\n  markov_model = markov_model,\n  maximum_sentence_length = NULL,\n  output_column_name = 'goat_lyric',\n  start_words = c(\"I\", \"And\", \"But\", \"So\"),\n  count = 1,\n  tries = 100,\n  only_distinct = TRUE,\n  return_message = TRUE\n)\n\ngoat_lyric: I was sure my heart and I should have said something evil and then orange then opting for secession\ngoat_lyric: And I will walk down to the main square\ngoat_lyric: But I knew you were knocking\ngoat_lyric: So you can breathe now\n\n\n…or not.\nI think John Darnielle probably remains the best generator of Mountain Goats lyrics for now."
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#further-reading",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#further-reading",
    "title": "Generate The Mountain Goats lyrics",
    "section": "Further reading",
    "text": "Further reading\nTo learn more about the band:\n\nI only listen to the Mountain Goats podcast\nThe Mountain Goats official website\nThe Mountain Goats wiki\nThe annotated Mountain Goats\nthemountaingoats.net fan site"
  },
  {
    "objectID": "posts/2019-04-25-gen-tmg-lyrics/index.html#environment",
    "href": "posts/2019-04-25-gen-tmg-lyrics/index.html#environment",
    "title": "Generate The Mountain Goats lyrics",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 16:31:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1      furrr_0.3.1      future_1.33.0    markovifyR_0.102\n[5] tidyr_1.3.0      dplyr_1.1.2      readr_2.1.4      spotifyr_2.2.4  \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    xml2_1.3.5        lattice_0.21-8   \n [5] stringi_1.7.12    listenv_0.9.0     hms_1.1.3         digest_0.6.33    \n [9] magrittr_2.0.3    grid_4.3.1        evaluate_0.21     timechange_0.2.0 \n[13] fastmap_1.1.1     rprojroot_2.0.3   Matrix_1.5-4.1    jsonlite_1.8.7   \n[17] httr_1.4.6        rvest_1.0.3       fansi_1.0.4       codetools_0.2-19 \n[21] cli_3.6.1         crayon_1.5.2      rlang_1.1.1       parallelly_1.36.0\n[25] withr_2.5.0       yaml_2.3.7        tools_4.3.1       parallel_4.3.1   \n[29] tzdb_0.4.0        here_1.0.1        globals_0.16.2    reticulate_1.30  \n[33] curl_5.0.1        assertthat_0.2.1  png_0.1-8         vctrs_0.6.3      \n[37] R6_2.5.1          lifecycle_1.0.3   lubridate_1.9.2   snakecase_0.11.0 \n[41] stringr_1.5.0     htmlwidgets_1.6.2 janitor_2.2.0     pkgconfig_2.0.3  \n[45] pillar_1.9.0      Rcpp_1.0.11       glue_1.6.2        xfun_0.39        \n[49] tibble_3.2.1      tidyselect_1.2.0  rstudioapi_0.15.0 knitr_1.43.1     \n[53] htmltools_0.5.5   rmarkdown_2.23    compiler_4.3.1"
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#tldr",
    "href": "posts/2020-02-05-slickr/index.html#tldr",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can make fun little scrolling ‘carousel’ type widgets in R with the {slickR} package. I’ve made an example that shows Pokémon sprites (above). Click the small sprites at the bottom to scroll the carousel to that Pokémon’s evolution chain; click the full-size sprites to go to that character’s Bulbapedia page."
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#merry-go-round",
    "href": "posts/2020-02-05-slickr/index.html#merry-go-round",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "Merry-go-round",
    "text": "Merry-go-round\nI was browsing GitHub and the {slickR} package by Jonathan Sidi was suggested as a repo to explore.\n{slickR} is an htmlwidget that generates carousels using the Slick JavaScript library by Ken Wheeler.\nYou’ve seen carousels before. They’re pretty ubiquitous for scrolling horizontally through images on websites. {slickR} provides a neat way of embedding these in R Markdown documents and Shiny apps. Plus, the elements in the carousel can be basically anything (iframes, plots, etc), not just images."
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#pokédemo",
    "href": "posts/2020-02-05-slickr/index.html#pokédemo",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "PokéDemo",
    "text": "PokéDemo\nI followed the excellent guidance on the {slickR} site to set up a basic carousel featuring Pokémon sprites1 from the Pokémon Black and White games, which I collected via veekun.com.\nI’ve embedded the demo at the top of this page, but you can visit it on a dedicated page or see its source. These are probably best viewed on a desktop machine.\nIn fact, it’s three carousels that are stacked and synchronised: one with the front sprite, one with the back sprite and one that shows the number and name of the Pokémon. Click a sprite to go to the relevant page on Bulbapedia, the Pokémon wiki.\nI’ve also set each page to display three ’mon at a time and that each page will advance by three. This is so that I can display one Pokémon evolutionary chain per page, since the max chain length is three (e.g. Bulbasaur &gt; Ivysaur &gt; Venusaur). I added a blank spacer pad where a chain was shorter than three (e.g. Rattata &gt; Raticate &gt; BLANK, or Farfetch’d &gt; BLANK &gt; BLANK).\nThe pages auto-advance in the demo above, but can be advanced manually in the standalone version by clicking the directional arrows, or by using your arrow keys if the widget has been selected.\nIt’s also possible to jump to a specific evolutionary chain by using the page ‘dots’ underneath the carousel. Here, you can click one of the tiny sprites to jump to the page that contains the evolutionary chain that starts with that Pokémon."
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#carousel-mechanics",
    "href": "posts/2020-02-05-slickr/index.html#carousel-mechanics",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "Carousel mechanics",
    "text": "Carousel mechanics\nBelow is some illustrative code for the demo. The code for the full carousel demo is available from the matt-dray/pkmn_slickr repo.\nAgain, do check out the really helpful NBA example on the {slickR} website for more examples.\n\nOne carousel\nHere’s an example of the code for an individual carousel that displays just the front-facing sprite:\n\nfront_carousel &lt;- slickR(\n  obj = pkmn2$sprite_front_src,\n  objLinks = pkmn2$url,\n  height = 200, width = \"100%\"\n) +\n  settings(\n    autoplay = TRUE, arrows = FALSE,\n    slidesToShow = 3, slidesToScroll = 3\n  )\n\nBasically, You call the slickR() function with arguments that define the object to display and also things like links (objLinks) and the size of the elements. Here, pkmn2$sprite_front_src is a vector of sprite image sources, for example.\nYou can then tweak the look and behaviour by adding settings() with a + (like {ggplot2}). Here, autoplay advances the slides automatically; arrows dictates whether to show manually-clickable advancement buttons; and slidesToShow and slidesToScroll control the number of elements seen on one ‘page’ of elements and how many elements to advance by.\n\n\nSynced sandwich\nI created two more of these {slickR} objects for the back sprite and the Pokémon name and number, with slight differences compared to the code above.\nI then sandwiched all three together like this:\n\ncarousel &lt;-\n  front_carousel %synch%\n  back_carousel %synch%\n  names_carousel \n\nThe %synch% operator makes sure that advancing any of the carousels advances them all together.\n\n\nSprite dots\nThe third of the three carousels, the names_carousel has the argument dots = TRUE in its settings. This makes dots appear under the carousel to show which ‘page’ the carousel is currently displaying. You can also click these dots to jump to a given page.\nYou can change these dots to other things, like numeric values. I was able to use the guidance to replace the dots with sprites. This means you can click a mini sprite under the carousel to jump to the page where that Pokémon starts an evolutionary chain."
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#stop-let-me-off",
    "href": "posts/2020-02-05-slickr/index.html#stop-let-me-off",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "Stop, let me off",
    "text": "Stop, let me off\nI have a lot of ideas for how to use this package, but for more on {slickR} in the meantime, check out:\n\nthe {slickR} site\nthe basic walkthrough\nhow to use {slickR} in Shiny and other advanced things\nthe package source"
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#environment",
    "href": "posts/2020-02-05-slickr/index.html#environment",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 19:28:19 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-02-05-slickr/index.html#footnotes",
    "href": "posts/2020-02-05-slickr/index.html#footnotes",
    "title": "A Pokémon sprite carousel with {slickR}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPokémon and Pokémon character names are trademarks of Nintendo. Copyright is 1995–2020 Nintendo/Creatures Inc/GAME FREAK inc↩︎"
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#tldr",
    "href": "posts/2019-02-27-hadley-number/index.html#tldr",
    "title": "What’s your Hadley Number?",
    "section": "tl;dr",
    "text": "tl;dr\nI made the {kevinbacran} R package (as in ‘Kevin Bacon’ + ‘CRAN’, lol) to find the network separation between any two authors on CRAN.\nThen I made a Shiny app to demonstrate the Six Degrees of Kevin Bacon. Except it’s for CRAN authors. And Hadley Wickham is Kevin Bacon."
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#six-degrees",
    "href": "posts/2019-02-27-hadley-number/index.html#six-degrees",
    "title": "What’s your Hadley Number?",
    "section": "Six degrees",
    "text": "Six degrees\nPeople are connected to each other in networks. What is the average separation of any two people in the network? There’s a popular idea of there being six degrees of separation.\nInstead of separation between any two people, we can measure separation from one fixed person. For example, we can calculate a Bacon Number for actors connected to Kevin Bacon, ‘centre of the entertainment universe’.\nIt works like this: you have a Bacon Number of zero if you are Kevin Bacon (hi Kevin, thanks for reading my blog). You have a Bacon Number of one if you were in a film with him. Your number is two if you were in a film with someone who was in a film with Kevin Bacon.\nA more classic example is the Erdős Number, which expresses the separation of mathematicians from the prolific Paul Erdős via published academic papers. And yes, there’s an Erdős-Bacon Number for actor-mathematicians.1\nWe can extend this approach to any network. One nerdy example is shared authorship on packages published on the Comprehensive R Archive Network (CRAN), the go-to repository for packages for the R programming language. {kevinbacran} can help you do this."
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#the-kevinbacran-package",
    "href": "posts/2019-02-27-hadley-number/index.html#the-kevinbacran-package",
    "title": "What’s your Hadley Number?",
    "section": "The {kevinbacran} package",
    "text": "The {kevinbacran} package\nYou can learn about the package on the {kevinbacran} site2, see the code on GitHub and feel free to leave an issue.\nIt is currently incomplete, potentially unstable, inefficient and untested. It’s main purpose was to sate curiosity and provide some helper functions for the Shiny app.\nThe package has only four functions3:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nkb_combos()\nFetch CRAN data, clean author names, get author combos per package, create network graph object\n\n\nkb_pair()\nGets network graph of the shortest distance between two authors from the kb_combos() graph\n\n\nkb_distance()\nSeparation (number of edges) between authors in kb_pair()\n\n\nkb_plot()\nReturns a {ggraph} plot from the kb_pair() object\n\n\n\nThe package relies heavily on others, particularly {cranly}, {tidygraph}, {ggraph}, and {dplyr} and {purrr}. The code for getting author combinations per package is from Duncan Garmonsway4."
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#the-app",
    "href": "posts/2019-02-27-hadley-number/index.html#the-app",
    "title": "What’s your Hadley Number?",
    "section": "The app",
    "text": "The app\nWe could use the functions mentioned to obtain graphs between all authors and a single named author of our choosing. We’re going to use Hadley Wickham as the target, since he is among the most named authors on CRAN. This may be largely explained by his involvement in the tidyverse suite of packages and their use in packages maintained by other authors.\nBelow is an embedded version of the Shiny app, but you can access it in full from its own page on shinyapps.io5, or download the code from GitHub.\nType an author name and hit go. You’ll get the Hadley Number and a graph to represent a shortest path between them.\n\n\n\n\n\n\n\n\nYou may notice:\n\nthat your name is missing (perhaps you’re not on CRAN, or a shortest path could not be reached)\nthe author names look weird or the same people are listed under variant names ({cranly} is excellent at cleaning names, but the author field is very unstructured; just ask Duncan Garmonsway6)\nthat some of the labels overlap and are hard to read (try hitting the Go button again)\n\nYou are very welcome to use, improve or ignore the code for the app on GitHub, where you can leave issues."
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#read-next",
    "href": "posts/2019-02-27-hadley-number/index.html#read-next",
    "title": "What’s your Hadley Number?",
    "section": "Read next",
    "text": "Read next\nThe purpose of this post and the app were to give a flavour of the possibilities for {kevinbacran}. Of course, graph theory is a whole area of study and I haven’t incorporated any analysis of the characteristics of the CRAN network here (e.g. measures of centrality or detection of communities).\nFortunately, Duncan Garmonsway’s ‘With added bacran’ blog post covers:\n\nWho has the highest Hadley number?\nWhat is the longest ‘shortest path’ between any two CRAN authors?\nWhat is the largest network disconnected from Hadley?\nIs Hadley the most central author?\n\nAlso, if you choose to use your Hadley Number to gain street cred, you may be interested in Robin Edwards’s Hadley Index repo:\n\nHow early did you start following Hadley Wickham? Can be used as a last resort to resolve R arguments.\n\n\n Note\nI later discovered Ash Baldry has made a similar Shiny app where you can get a Wickham Number, or the degrees of separation between any two CRAN authors."
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#environment",
    "href": "posts/2019-02-27-hadley-number/index.html#environment",
    "title": "What’s your Hadley Number?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-03 18:40:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] fontawesome_0.5.1   evaluate_0.21"
  },
  {
    "objectID": "posts/2019-02-27-hadley-number/index.html#footnotes",
    "href": "posts/2019-02-27-hadley-number/index.html#footnotes",
    "title": "What’s your Hadley Number?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd yes, there’s an Erdős-Bacon-Sabbath Number for mathematician-actor-musicians.↩︎\nThanks to the marvellous {pkgdown} package from Hadley Wickham and Jay Hesselberth.↩︎\nSubject to change.↩︎\nOriginally used code from William Chase’s blog.↩︎\nHosted for free on shinyapps.io. I might take it down at any point. You can download the code if it’s no longer hosted online.↩︎\nA post that uses a similar approach to getting at author names to calculate an h-index for package authors.↩︎"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html",
    "href": "posts/2022-02-04-soccercolleagues/index.html",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "",
    "text": "Lee Bowyer and Kieran Dyer: ‘team mates’ (BBC via Giphy)"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#tldr",
    "href": "posts/2022-02-04-soccercolleagues/index.html#tldr",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a quick R package called {soccercolleagues} that for a given player, or players, lets you (a) find all their former team mates in common and (b) sample from them for quiz-based purposes."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#lord-of-the-ings",
    "href": "posts/2022-02-04-soccercolleagues/index.html#lord-of-the-ings",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Lord of the Ings",
    "text": "Lord of the Ings\nQuiz question:\n\nWhich current Premier League footballer has been team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?\n\nI’ve seen this type of question in pub quizzes, on social media and forwarded on by assorted football nerds. Some are harder than a Roy Keane challenge\nBut why use your brain when you could backwards-engineer it programmatically?\nI figured I could use R and the {worldfootballR} package by Jason Zivkovic to fetch squad data from the Transfermarkt website, then isolate team mates that these players have in common.\nAnd why not make it an R package in the process?"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#announce-soccercolleagues",
    "href": "posts/2022-02-04-soccercolleagues/index.html#announce-soccercolleagues",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Announce {soccercolleagues}!",
    "text": "Announce {soccercolleagues}!\nI’m pleased to announce the signing of the promising young {soccercolleagues}1 package on a free. Will it live up to the hype?\nThe package is available via GitHub, which you can install with help from {remotes}.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/soccercolleagues\")\nlibrary(soccercolleagues)\n\nIn a departure from my usual package production, I’ve made use of the tidyverse in this one. It also uses the native R pipe, so you’ll need R v4.1 or above.2 It works on my computer, which is good enough for me.\nAs with many packages showcased on this blog, you should consider this a low-effort artisanal meme. Definitely a proof of concept. I’m not sure if I’ll ever come back and improve it. Feel free to add issues or submit pull requests."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#get-stuck-in",
    "href": "posts/2022-02-04-soccercolleagues/index.html#get-stuck-in",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Get stuck in",
    "text": "Get stuck in\n{soccercolleageus} has three main functions:\n\nget_players() to fetch squad data from Transfermarkt\nget_colleagues() to return all the players by season who have been team mates with a named set of players\nsample_colleagues() to select a random set of team mates for a named player or players\n\nThere’s also a secret tiny Shiny app, accessed with open_colleagues_quiz(), but it (literally) only presents five player names with buttons to (a) reveal a sampled team mate in common, and (b) generate a new set of player names. You’ll need to install {shiny} and {shinyjs} separately if you want to use it (don’t use it).\nLet’s talk through the main functions.\n\n1. Get squads by league and season\nFirst, let’s get all the players from all teams in a given league for a given set of seasons.\nI designed the package entirely with the English Premier League in mind because that’s the league I’m most accustomed to and because Transfermarkt has data for all its seasons, which began in 1992.3\nYou pass to get_players() the seasons you want and the country that the league is from. Beware: this could take several minutes.\n\nepl_players &lt;- get_players(\n  seasons = 1992:2020,\n  country = \"England\"\n)\n\nglimpse(epl_players)\n\nRows: 20,643\nColumns: 11\n$ player_name    &lt;chr&gt; \"Paul Gerrard\", \"Jon Hallworth\", \"John Keeley\", \"Ian Gray\", \"Craig…\n$ player_pos     &lt;chr&gt; \"Goalkeeper\", \"Goalkeeper\", \"Goalkeeper\", \"Goalkeeper\", \"Centre-Ba…\n$ player_age     &lt;dbl&gt; 19, 26, 30, 17, 20, 19, 19, 40, 29, 26, 27, 24, 26, 26, 26, 25, 26…\n$ nationality    &lt;chr&gt; \"England\", \"England\", \"England\", \"England\", \"England\", \"England\", …\n$ in_squad       &lt;dbl&gt; 27, 16, 29, 12, 35, 1, 35, 1, 40, 9, 33, 36, 41, 37, 6, 42, 15, 32…\n$ appearances    &lt;dbl&gt; 25, 16, 1, 0, 24, 0, 33, 0, 40, 5, 33, 31, 41, 32, 6, 42, 14, 32, …\n$ goals          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 3, 0, 5, 9, 0, 3, 3, 6, 0, 3, 3, 2, …\n$ minutes_played &lt;dbl&gt; 2250, 1440, 90, 0, 2114, 0, 2953, 0, 3600, 341, 2799, 2522, 3647, …\n$ team_url       &lt;chr&gt; \"https://www.transfermarkt.com/oldham-athletic/startseite/verein/1…\n$ team_name      &lt;chr&gt; \"oldham-athletic\", \"oldham-athletic\", \"oldham-athletic\", \"oldham-a…\n$ season         &lt;chr&gt; \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1…\nA dataframe is returned with lots of handy stuff like the player name, team name, season and a bunch of player data. Obviously you could take this data away and do whatever you like with it, it’s quite a neat dataset for other, less esoteric analysis of the history of the Premier League.\n\n\n2. Find team mates\nNow to filter this information for a given focus player or players.\nYou provide the dataframe output of get_players() to get_colleagues() as the all_players() argument, along with a vector of players names. The function filters the dataframe down to just the team mates of the selected player or players for the teams and seasons in which they played together.\n\nteammates &lt;- get_colleagues(\n  all_players = epl_players,\n  players = c(\"Kolo Touré\", \"Yaya Touré\")\n)\n\nRows: 348\nColumns: 12\n$ focus_name     &lt;chr&gt; \"Kolo Touré\", \"Kolo Touré\", \"Kolo Touré\", \"Kolo Touré\", \"Kolo Tour…\n$ player_name    &lt;chr&gt; \"Stuart Taylor\", \"Richard Wright\", \"Patrick Vieira\", \"Stuart Taylo…\n$ player_pos     &lt;chr&gt; \"Goalkeeper\", \"Goalkeeper\", \"Defensive Midfield\", \"Goalkeeper\", \"D…\n$ player_age     &lt;dbl&gt; 20, 23, 25, 21, 26, 22, 17, 27, 23, 18, 28, 19, 21, 20, 22, 21, 24…\n$ nationality    &lt;chr&gt; \"England\", \"England\", \"France\", \"England\", \"France\", \"England\", \"F…\n$ in_squad       &lt;dbl&gt; 21, 43, 54, 20, 42, 4, 31, 44, 7, 26, 44, 14, 13, 40, 45, 50, 41, …\n$ appearances    &lt;dbl&gt; 15, 22, 54, 13, 42, 0, 22, 44, 0, 24, 44, 11, 13, 40, 44, 49, 40, …\n$ goals          &lt;dbl&gt; 0, 0, 3, 0, 4, 0, 0, 3, 0, 0, 7, 0, 4, 0, 12, 0, 1, 30, 1, 0, 7, 1…\n$ minutes_played &lt;dbl&gt; 1220, 1929, 4702, 1081, 3563, 0, 1347, 3822, 0, 1456, 3926, 728, 1…\n$ team_url       &lt;chr&gt; \"https://www.transfermarkt.com/fc-arsenal/startseite/verein/11/sai…\n$ team_name      &lt;chr&gt; \"fc-arsenal\", \"fc-arsenal\", \"fc-arsenal\", \"fc-arsenal\", \"fc-arsena…\n$ season         &lt;chr&gt; \"2001\", \"2001\", \"2001\", \"2002\", \"2002\", \"2003\", \"2003\", \"2003\", \"2…\nYou can see how this could be used to solve our original problem: you can take a named player’s unique team mates and find how many are in common with other named players.\nWhile get_colleagues() effectively returns a filtered dataframe, there’s another function to whittle this down to simpler output.\n\n\n3. Sample from common team mates\nGiven a named player or players, the sample_colleagues() function returns a vector of team mates of size n. These are sampled with a weighting by the total number of Premier League minutes played (a very rough way of outputting more well-known players).\nYou could apply the function to a single named player if you want, which outputs five sampled team mates.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = \"Craig Bellamy\"\n)\n\n[1] \"Jordan Henderson\"   \"Rob Lee\"  \"Freddie Ljungberg\"\n[4] \"Patrick Vieira\"   \"Celestine Babayaro\"\nOf course, if your chosen player is the only common team mate for the set of output players, then you’ve got a decent quiz question to test your pals with!\nTo check, we can feed these names back into sample_colleagues(). I’ve set the argument n = 2: if we get two names then we know the player isn’t the only one in common for these five.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = c(\n    \"Jordan Henderson\",\n    \"Rob Lee\",\n    \"Freddie Ljungberg\",\n    \"Patrick Vieira\",\n    \"Celestine Babayaro\"\n  ),\n  n = 2 \n)\n\n[1] Craig Bellamy\nLegend, journeyman."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#theres-only-one-insert-player",
    "href": "posts/2022-02-04-soccercolleagues/index.html#theres-only-one-insert-player",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "There’s only one [insert player]",
    "text": "There’s only one [insert player]\nSo what’s the answer to the original question?4\n\nWhich current Premier League footballer was team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?\n\nNow we can answer programmatically.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = c(\n    \"Kevin Phillips\",\n    \"Mark Viduka\",\n    \"Dejan Lovren\",\n    \"Danny Ings\",\n    \"Nicky Butt\"\n  ),\n  n = 1\n)\n\n\n\nClick for answer!\n\n[1] James Milner\n\nDid you get it? Was it too easy, too boring?5"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#environment",
    "href": "posts/2022-02-04-soccercolleagues/index.html#environment",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:32 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] soccercolleagues_0.0.0.9001\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#footnotes",
    "href": "posts/2022-02-04-soccercolleagues/index.html#footnotes",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYeah, couldn’t think of a pun quick enough, but I thought the idea of team mates as ‘colleagues’ is quite funny to me.↩︎\nI’m not trying to be restrictive, I just started coding it this way and don’t have the time to refactor it.↩︎\nYou could instead try one of the many other leagues like Italy’s Serie A, South Korea’s K League, or Tunisia’s Ligue I Pro.↩︎\nI don’t think this is too hard. A friend sent me a harder one where the answer was Alan Hutton, so.↩︎\nA sneaky clue there.↩︎"
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html",
    "href": "posts/2018-06-30-markov-chain-phd/index.html",
    "title": "Markov-chaining my PhD thesis",
    "section": "",
    "text": "This is science?"
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html#tldr",
    "href": "posts/2018-06-30-markov-chain-phd/index.html#tldr",
    "title": "Markov-chaining my PhD thesis",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a thesis, but a Markov chain can rewrite it and make about as much sense as the original.\nSee also an updated version of this blog for a better approach."
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html#doc-rot",
    "href": "posts/2018-06-30-markov-chain-phd/index.html#doc-rot",
    "title": "Markov-chaining my PhD thesis",
    "section": "Doc rot",
    "text": "Doc rot\nI wrote a PhD thesis in 2014 called ‘Effects of multiple environmental stressors on litter chemical composition and decomposition’. See my viva presentation slides here if you don’t really like words.\nOn graduation day, a stranger came up to me and, to paraphrase, said ‘you doctors should be proud of what you’ve achieved, you’re doing a great service’. I didn’t have the heart to tell him that I wasn’t a medical doctor. No, I was something nobler and altogether more unique: a doctor of rotting leaves.\nYou’re thinking: ‘gosh, what a complicated subject that must be; how could I ever hope to achieve such greatness?’ The answer is that you should simply take my thesis and use a Markov chain to generate new sentences until you have a fresh new thesis. The output will make probably as much sense as the original but won’t be detected easily by plagiarism software.\nHeck, I’ll even do it for you in this post.\nYou’re welcome. Don’t forget to cite me."
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html#text-generation",
    "href": "posts/2018-06-30-markov-chain-phd/index.html#text-generation",
    "title": "Markov-chaining my PhD thesis",
    "section": "Text generation",
    "text": "Text generation\nI’ll be using a very simple approach: Markov chains.\nBasically, after providing an input data set, a Markov chain can generate the next word in a sentence given the current word. Selection of the new word is random but weighted by occurrences in your input file.\nThere’s a great post on Hackernoon that explains Markov chains for text generation. For interactive visuals of Markov chains, go to setosa.io.\nText generation is an expanding field and there are much more successful and complicated methods for doing it. For example, Andrej Karpathy generated some pretty convincing Shakespeare passages, Wikipedia pages and geometry papers in LaTeX using the ‘unreasonably effective’ and ‘magical’ power of Recurrent Neural Networks (RNNs)."
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html#generate-text",
    "href": "posts/2018-06-30-markov-chain-phd/index.html#generate-text",
    "title": "Markov-chaining my PhD thesis",
    "section": "Generate text",
    "text": "Generate text\n\nCode source\nI’ll be using modified R code written by Kory Becker from this GitHub gist.\nIn a similar vein, Roel Hogervorst did a swell job of generating Captain Picard text in R from Star Trek: The Next Generation scripts, which is certainly in our wheelhouse.\n\n\nData\nBecause I’m helpful I’ve created a text file version of my thesis. You can get it raw from my draytasets (haha) GitHub repo.\nAlternatively you could get the data from the {dray} package.\n\nlibrary(dray)  # remotes::install_github(\"matt-dray/dray\")\n\nStill D-R-A-Y\n\nphd_text &lt;- dray::phd\n\nWe’ll alter the data slightly for it to be ready for passing into the Markov chain.\n\n# Remove blank lines\nphd_text &lt;- phd_text[nchar(phd_text) &gt; 0]\n\n# Put spaces around common punctuation\n# so they're not interpreted as part of a word\nphd_text &lt;- gsub(\".\", \" .\", phd_text, fixed = TRUE)\nphd_text &lt;- gsub(\",\", \" ,\", phd_text, fixed = TRUE)\nphd_text &lt;- gsub(\"(\", \"( \", phd_text, fixed = TRUE)\nphd_text &lt;- gsub(\")\", \" )\", phd_text, fixed = TRUE)\n\n# Split into single tokens\nterms &lt;- unlist(strsplit(phd_text, \" \"))\n\n\n\nScript\nRead the markovchain package and fit a Markov chain to the text data.\n\nlibrary(markovchain)  # install.packages(\"markovchain\")\nfit &lt;- markovchainFit(data = terms)\n\nWe’re going to seed the start of each ‘sentence’ (a sequence of n words, where we specify n). We’ll do this by supplying one of 50 unique values to the set.seed() function in turn. This seed then starts the chain within the markovchainSequence() function.\n\nmarkov_output &lt;- data.frame(output = rep(NA, 50))\n\nfor (i in 1:50) {\n  \n  set.seed(i)  # fresh seed for each element\n  \n  markov_text &lt;- paste(\n    markovchainSequence(n = 50, markovchain = fit$estimate),\n    collapse = \" \"\n  )\n  \n  markov_output$output[i] &lt;- markov_text\n  \n}\n\n\n\nFull output\nThis table shows 50 samples of length 50 that I generated with the code above, each beginning with a randomly-selected token.\n\n\n\n\n\n\n\n\n\nCherry-picked phrases\nThe output is mostly trash because the Markov chain doesn’t have built in grammar or an understanding of sentence structure. It only ‘looks ahead’ given the current state.\nYou can also see that brackets don’t get closed, for example, though an opening bracket is often followed by an author citation or result of a statistical test, as we might expect given the source material.\nI’ve selected some things from the output that basically look like normal(ish) phrases. Simply rearrange these to build a thesis!\nMy favourites (my comments in square brackets):\n\n\n\n\n\n\n\nGenerated sentence\nComment\n\n\n\n\nNot all invertebrate species are among tree species\nLiterally true\n\n\nEffect of deciduous trees may be appreciated\nWell, they should be thanked for giving us oxygen and fruits\n\n\nSpecies-specific utilization of Cardiff University\nHumans inside, pigeons on the roof\n\n\nLitter was affected by Wallace , Dordrecht\nWho is this Dutch guy who’s interfering with my studies?\n\n\nBags permitted entry of stream ecosystem\nI should hope so; I was investigating the effect of the stream ecosystem on the leaf litter stored in those bags\n\n\nPermutational Analysis and xylophagous invertebrates can affect ecosystem service provision\nMy analysis will affect the thing its analysing? The curse f the observer effect.\n\n\nMost studies could shift invertebrate communities\nHang on, this is the observer effect again; I thought I was studying ecology, not physics\n\n\nThis thesis is responsible for broad underlying principles to mass loss\nHealth warning: my thesis actually causes decay (possibly to your brain cells)\n\n\nCarbon dioxide enrichment altered chemical composition\nAha, actually true\n\n\n\nSome other things that vaguely make sense:\n\nThe response variables were returned to predict leaf litters\nshredder feeding was established for nutrient and urban pollution\nLeaf litter chemical composition are comprised of differing acidity in Ystradffin\nthe no-choice situation with deionised water availability may reflect invertebrate feeding preferences\nground coarsely using a wide spectrum of stream ecosystem functioning\ncages were already apparent\nSchematic of aquatic invertebrate species for identifying the invertebrate assemblages during model fitting\nPopulus tremuloides clone under elevated CO2 had consistently been related to remove debris dams in woodland environments\nthe need to account for microphytobenthic biofilms are particularly affected by the Linnean Society , and lignin concentration\nThese findings suggest that the roles could not differ between time and bottom-up control of decomposition\nrural litter decomposition of litter layer of leaf litter will influence invertebrate communities\nthe effects of carbon concentration in species’ feeding responses between tree species with caution given the 1970s , regardless of four weeks\nResults were visualised in the breakdown\nMeasurements were in altered twig decay rates\nLitter was little work in decomposing leaf litter of litter resulted in a range of twigs , as a result in upland streams\nThe basis of carbon compounds have influenced feeding preferences\nAnnual Review of the physical toughness of rotting detritus altered chemical composition and woodlice Porcellio species\nNitrogen concentrations and nitrogen transformations in both leaves grown under ambient CO2 levels of trembling aspen and invertebrate assemblage\n\nSo now you can just paste all this together. Congratulations on your doctorate!"
  },
  {
    "objectID": "posts/2018-06-30-markov-chain-phd/index.html#environment",
    "href": "posts/2018-06-30-markov-chain-phd/index.html#environment",
    "title": "Markov-chaining my PhD thesis",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 23:02:14 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] markovchain_0.9.3 dray_0.0.0.9000  \n\nloaded via a namespace (and not attached):\n [1] Matrix_1.6-0       expm_0.999-7       jsonlite_1.8.7     compiler_4.3.1    \n [5] plotrix_3.8-2      Rcpp_1.0.11        parallel_4.3.1     jquerylib_0.1.4   \n [9] yaml_2.3.7         fastmap_1.1.1      lattice_0.21-8     R6_2.5.1          \n[13] igraph_1.5.0.1     knitr_1.43.1       htmlwidgets_1.6.2  tibble_3.2.1      \n[17] bslib_0.5.0        pillar_1.9.0       RColorBrewer_1.1-3 rlang_1.1.1       \n[21] utf8_1.2.3         wordcloud_2.6      DT_0.28            cachem_1.0.8      \n[25] xfun_0.39          sass_0.4.7         RcppParallel_5.1.7 cli_3.6.1         \n[29] magrittr_2.0.3     crosstalk_1.2.0    digest_0.6.33      grid_4.3.1        \n[33] rstudioapi_0.15.0  lifecycle_1.0.3    vctrs_0.6.3        evaluate_0.21     \n[37] glue_1.6.2         stats4_4.3.1       fansi_1.0.4        gifski_1.12.0-1   \n[41] rmarkdown_2.23     ellipsis_0.3.2     tools_4.3.1        pkgconfig_2.0.3   \n[45] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html",
    "href": "posts/2018-05-25-cloud-pie/index.html",
    "title": "Cloudy with a chance of pie",
    "section": "",
    "text": "Multiple visualisation ‘wrongs’ come together to make a new and powerful ‘right’ way to visualise text data, lol."
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#tldr",
    "href": "posts/2018-05-25-cloud-pie/index.html#tldr",
    "title": "Cloudy with a chance of pie",
    "section": "",
    "text": "Multiple visualisation ‘wrongs’ come together to make a new and powerful ‘right’ way to visualise text data, lol."
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#the-pinnacle-of-visualisation",
    "href": "posts/2018-05-25-cloud-pie/index.html#the-pinnacle-of-visualisation",
    "title": "Cloudy with a chance of pie",
    "section": "The pinnacle of visualisation",
    "text": "The pinnacle of visualisation\nGreat news everyone: I’ve taken the best of two stellar data visualisations and smashed them together into something that can only be described as perfection.\nLet me set the scene. There’s three things we can agree on:\n\nEveryone loves pie charts, particularly when they’re in 3D, exploded and tilted.\nWord clouds aren’t at all overused.\nI have too much time on my hands.\n\nWith that in mind, I’ve artfully melded clouds and pies into the function cloud_pie(), which I think sounds rather sweet.\nYou can find the function in my personal package {dray}, which I made following Hilary Parker’s excellent ‘Writing an R Package from Scratch’ blogpost.\n\nremotes::install_github(\"matt-dray/dray\")"
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#pie-in-the-sky",
    "href": "posts/2018-05-25-cloud-pie/index.html#pie-in-the-sky",
    "title": "Cloudy with a chance of pie",
    "section": "Pie in the sky",
    "text": "Pie in the sky\ncloud_pie() depends on the {plotrix} and {wordcloud} packages and takes three arguments:\n\ndata: summary dataframe with two columns: categories, and counts for those categories\nname_col: column containing the category names\ncount_col: column containing the counts for each category\n\ndata must be a dataframe with a column of categories (i.e. name_col) and a column of count values associated with those categories (i.e. count_col).\nIt’s also completely untested and will probably break if you actually try to use it. So let’s try to use it."
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#pokémon-data-of-course",
    "href": "posts/2018-05-25-cloud-pie/index.html#pokémon-data-of-course",
    "title": "Cloudy with a chance of pie",
    "section": "Pokémon data, of course",
    "text": "Pokémon data, of course\nLet’s use the same data as in the Pokéballs in Super Smash Bros blog post, which is hosted on GitHub.\n\nlibrary(dplyr, warn.conflicts = FALSE)\n\npkmn_raw &lt;- read.csv(\n  \"https://raw.githubusercontent.com/matt-dray/draytasets/master/ssb_pokeballs.csv\"\n)\n\npkmn_summary &lt;- pkmn_raw %&gt;%\n  group_by(pokemon) %&gt;%\n  count() %&gt;%\n  ungroup()\n\nglimpse(pkmn_summary)\n\nRows: 13\nColumns: 2\n$ pokemon &lt;chr&gt; \"beedrill\", \"blastoise\", \"chansey\", \"charizard\", \"clefairy\", \"…\n$ n       &lt;int&gt; 26, 25, 26, 23, 18, 26, 25, 24, 20, 3, 25, 26, 23"
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#the-big-reveal",
    "href": "posts/2018-05-25-cloud-pie/index.html#the-big-reveal",
    "title": "Cloudy with a chance of pie",
    "section": "The big reveal",
    "text": "The big reveal\nAccept your fate.\n\ndray::cloud_pie(\n  data = pkmn_summary,\n  name_col = \"pokemon\",\n  count_col = \"n\"\n)\n\nWarning in wordcloud(words = data[[name_col]], freq = data[[count_col]], :\nsnorlax could not be fit on page. It will not be plotted.\n\n\n\n\n\nDid I forget to mention that the typeface is gothic and colours are selected randomly from the named colours that R knows about? The words and pie slices are sized by frequency and match up by colour. Sensational.\nOh, and, haha, sometimes the wordcloud will miss out some words if they don’t fit nicely. Doesn’t matter: people will be so overawed by the plot’s overall beauty that they won’t notice a few missing values, amirite."
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#you-know-what-to-do",
    "href": "posts/2018-05-25-cloud-pie/index.html#you-know-what-to-do",
    "title": "Cloudy with a chance of pie",
    "section": "You know what to do",
    "text": "You know what to do\nLet me know if you decide to nominate me for an Information is Beautiful award."
  },
  {
    "objectID": "posts/2018-05-25-cloud-pie/index.html#environment",
    "href": "posts/2018-05-25-cloud-pie/index.html#environment",
    "title": "Cloudy with a chance of pie",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-24 20:40:15 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        cli_3.6.1          knitr_1.43.1       rlang_1.1.1       \n [5] xfun_0.39          gifski_1.12.0-1    generics_0.1.3     jsonlite_1.8.7    \n [9] dray_0.0.0.9000    glue_1.6.2         htmltools_0.5.5    wordcloud_2.6     \n[13] fansi_1.0.4        rmarkdown_2.23     evaluate_0.21      tibble_3.2.1      \n[17] fastmap_1.1.1      yaml_2.3.7         lifecycle_1.0.3    compiler_4.3.1    \n[21] RColorBrewer_1.1-3 Rcpp_1.0.11        htmlwidgets_1.6.2  pkgconfig_2.0.3   \n[25] rstudioapi_0.15.0  digest_0.6.33      R6_2.5.1           tidyselect_1.2.0  \n[29] utf8_1.2.3         pillar_1.9.0       magrittr_2.0.3     tools_4.3.1       \n[33] plotrix_3.8-2"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#tldr",
    "href": "posts/2020-09-15-rstudio-settings/index.html#tldr",
    "title": "Rate my RStudio setup",
    "section": "tl;dr",
    "text": "tl;dr\nI share my (current!) RStudio setup and some features of the IDE I often use. Tell me about your setup."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#configuration-ideation",
    "href": "posts/2020-09-15-rstudio-settings/index.html#configuration-ideation",
    "title": "Rate my RStudio setup",
    "section": "Configuration IDEation",
    "text": "Configuration IDEation\nR has a decent community online. People love to share opinions about design, customisation and workflow efficiencies. Why is there little at the intersection?\nWhat I do see is people excited to hear about a checkbox or shortcut they never knew existed. I also hear from colleagues who are learning R and want to know more about customising their experience.\nSo, this post covers some elements of my personal RStudio setup and some bits and bobs about how I use some of the features.1 It’s utterly non-exhaustive, but may be useful for someone. I may add some things every now and again.\nClick a section header to jump:\n\nTheme\nFont\nLayout\nAddins\nOther GUI elements and settings\n\nDocument outline\nMagic wand\nKeyboard shortcuts\n.RData\nOdds and ends\n\n\n\n How to\nThese boxes appear throughout this post to tell you how to change your RStudio settings."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#theme",
    "href": "posts/2020-09-15-rstudio-settings/index.html#theme",
    "title": "Rate my RStudio setup",
    "section": "Theme",
    "text": "Theme\n\n\n\nSyntax highlighting in action with viridis.\n\n\nI’m using the viridis theme by Cédric Scherer. It’s based on the viridis colour palette by David Cooley, which is designed with colour blindness in mind.\n\n How to\nYou can change to an inbuilt theme at Tools &gt; Global options &gt; Appearance &gt; Editor theme. Add a new theme by clicking Add… and provide a new .tmtheme or .rstheme from file. You can find and tweak examples using the online tmTheme Editor tool by Allen Bargi.\n\n\nI’m red-green colourblind and the syntax highlighting of this theme lets me distinguish easily between the different code elements. I also like the de-emphasised look of the comments, which are italicised and less bright, making it easier to focus on the code.\n\n How to\nI also use syntax highlighting in the console. You can get this by checking the box at Tools &gt; Global Options &gt; Code &gt; Display &gt; Show syntax highlighting in console input.\n\n\nSometimes I switch to a light theme, like the default one, when writing text-rich blog posts. Syntax highlighting is less important for me in these instances and dark-on-light text can be easier to read."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#font",
    "href": "posts/2020-09-15-rstudio-settings/index.html#font",
    "title": "Rate my RStudio setup",
    "section": "Font",
    "text": "Font\nI’m using FiraCode, an extension of the Fira typeface designed originally by Carrois Type Design. I installed this to my machine after downloading from Google Fonts).\n\n How to\nSet the font in RStudio at Tools &gt; Global Options &gt; Appearance &gt; Editor font.\n\n\nI find FiraCode easy to read for both coding and for writing prose. It’s monospaced, of course, but gets away with being a decent sans-serif for longer text blocks too.\n\n\n\nThe assignment arrow and ‘not equal to’ characters are smushed into ligatures.\n\n\nFiraCode’s main draw is its ligatures. This is when certain sets of adjacent characters are combined to appear as a single character. For example, the assignment operator gets condensed from &lt; and - to a single, unbroken arrow character. This helps me locate and parse expressions more easily, but ligatures are certainly a Marmite topic."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#layout",
    "href": "posts/2020-09-15-rstudio-settings/index.html#layout",
    "title": "Rate my RStudio setup",
    "section": "Layout",
    "text": "Layout\nI have the console pane on the right-hand side rather than the default of being on the left (see the image at the top of this post). I tend to want to maximise the script and console panes side-by-side so I can focus purely on inputs and outputs.\n\n How to\nYou can change this setting by clicking the Workspace Panes button (looks like a window) on the ‘taskbar’ at the top of the interface, to the left of the Addins menu. From there you can change the individual tabs of the panes too, by clicking Pane Layout….\n\n\nI don’t see a lot people doing this, but I think this kind of view is favoured in IDEs like VSCode.\n\n\n\nAre you right-paned or left-paned?\n\n\nI also like to maximise the amount I can see on my screen by zooming out and reducing the font size.\n\n How to\nYou can set font size at Tools &gt; Global Options &gt; Appearance &gt; Editor font size and Zoom is in the same location."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#addins",
    "href": "posts/2020-09-15-rstudio-settings/index.html#addins",
    "title": "Rate my RStudio setup",
    "section": "Addins",
    "text": "Addins\n\n\n\nAddins: exactly what it says on the tin.\n\n\nRStudio has a system of ‘addins’ that act as extensions for RStudio. They let you execute shortcuts and other commands via a dropdown menu in the GUI or a keyboard shortcut. Often these are functions that relate to the GUI in some way, like modifying selected text.\n\n How to\nAddins are delivered in R packages. You can access them from the Addins dropdown menu. There’s no official catalogue, but see a list of addins in the readme for {addinslist} by Dean Attali, which can also be installed as an addin that adds-in addins, capiche?\n\n\nI have many, many addins, but want to point out a few I use often:\n\n{blogdown} by Yihui Xie has an addin with selections for new posts and serving the site, which I use frequently\n{remedy} by ThinkR has a bunch of useful Markdown-insertion functions, while my {blogsnip} package has a few functions for helping me write {blogdown} posts (e.g. inserting code for an accessible image)2\n{datapasta} by Miles McBain lets me add data copied from elsewhere into R, with a handy function for pasting in as a vector\n{annotater} by Luis Verde adds a comment next to your library() calls to indicate packages’ purposes and versions, which I find useful when writing ad hoc scripts in a team that includes people who aren’t necessarily familiar with the packages being used\n\n\n How to\nYou can set keyboard shortcuts for addins with Tools &gt; Modify Keyboard Shortcuts…."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#other-settings",
    "href": "posts/2020-09-15-rstudio-settings/index.html#other-settings",
    "title": "Rate my RStudio setup",
    "section": "Other GUI elements and settings",
    "text": "Other GUI elements and settings\n\nDocument outline\nRStudio has a feature that lets you use comments with multiple hyphens to signal breaks in your code, which make it easier to visually separate different sections. You can insert one of these section breaks with Shift + Cmd + R, which provides a prompt for you to name the section.\n\n\n\nNot one, but two ways of navigating between sections.\n\n\nThe names of the sections can then be accessed from:\n\nthe document outline panel, which can be accessed by clicking the stacked-lines button in the top-right of the script pane (Shift + Cmd + O)\nthe ‘jump to’ menu in the lower left of the script pane, which also has a little icon to show you what type of section your cursor is in (for example, it’ll show an ‘f’ if you’re in a function definition)\n\n\n\nMagic wand\n\n\n\nSleight-of-cursor.\n\n\nThe ‘magic wand’ menu is available in the script pane and has some features that act a bit like addins. Some frequently-used tools in there for me are:\n\nReflow comment to break a long, ragged comment across multiple lines so it fits into the conventional 80-character width limit (also Ctrl + Shift + /)\nInsert roxygen skeleton to insert a basic {roxygen2} function-documentation block above your function when your cursor is inside it (also Alt + Shift + Cmd + R)\nRename in scope, which selects all instances of the given object name that you’ve highlighted in the script, which means you can then change them all at once without getting into the potential danger of a find-and-replace-all (also Alt + Shift + Cmd + M)\n\n\n\nKeyboard shortcuts\nRStudio has modifiable keyboard shortcuts. There’s a number of default shortcuts that I use frequently:\n\n\n\n\n\n\n\nKeys\nAction\n\n\n\n\nCmd + M\nInsert a {magrittr} pipe (%&gt;%)\n\n\nCmd + -\nInsert an assignment arrow (&lt;-)\n\n\nCmd + Shift + Fn + F10\nRestart RStudio\n\n\nCmd + Shift + C\nComment out a selected block\n\n\nCmd + I\nAuto-indent a line\n\n\nCmd + Shift + R\nAdd a section label\n\n\nCmd + D\nDocument an in-development package\n\n\nCmd + L\nLoad an in-development package\n\n\n\nSome shortcuts require you to be an octopus to reach all the keys (I’m looking at you, shortcut-to-restart-RStudio), so modifying your frequently used shortcuts might be a good idea. I’ve got a keyboard with F13 to F15 keys that are otherwise going to waste and as of a recent update, these can be used as mappable RStudio keys.\n\n How to\nYou can see the keyboard shortcuts at Tools &gt; Keyboard Shortcuts Help and modify them in Tools &gt; Modify Keyboard Shortcuts….\n\n\n\n\n.RData\nI like to restart RStudio every few minutes so I know that my environment is empty. This stops me from modifying objects and forgetting about it, which could result in erroneous output.\nThere are default settings that let RStudio open from where you left off, so that the contents of your environment are intact. I don’t like this and it’s advised against in places like the R for Data Science book by Wickham and Grolemund.\n\n How to\nYou can turn off this behaviour in Tools &gt; Global Options &gt; General &gt; Basic &gt; Workspace by unchecking Restore .Rdata on startup and setting Save workspace to .RData on exit to Never.\n\n\n\nOdds and ends\nRapid fire! I also like:\n\nthe 80-character-width guide to show me where to set a line break (Tools &gt; Code &gt; Display &gt; Show margin)\nto be able to scroll beyond the end of a script, so the last line can be seen further up the page (Tools &gt; Code &gt; Display &gt; Allow scroll past end of document)\nto see .Last.value in the environment pane so I can see the most recently created object (Tools &gt; Global options &gt; Advanced &gt; Show .Last.value in environment listing)\nto click the little RStudio cube-logo in the upper-right of the file pane to return to the working directory\nthe spellcheck function (see the ‘ABC-and-tick’ button at the top of the scripting window)\nusing multiple cursors by holding Alt and dragging down, which makes insertion and deletion across multiple lines much easier\n\nYou can learn more tips and tricks from:\n\nthe RStudio cheatsheet\nRStudio tips on Twitter\na recent post by Antoine Soetewey\nthis dataquest post"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#it-never-ends",
    "href": "posts/2020-09-15-rstudio-settings/index.html#it-never-ends",
    "title": "Rate my RStudio setup",
    "section": "It never ends",
    "text": "It never ends\nThemes and fonts can always be tweaked. You’ll get bored of them at some point, or something better will come along. RStudio’s customisability and ongoing development also means that’s a constant stream of new addins and discovered tricks.\nI don’t really make use of snippets and I haven’t really mapped any new keyboard shortcuts. I want to look into Garrick Aden-Buie’s {shrtcuts} package (blog, package site) in particular.\nI tend to use the terminal window for everything Git-based and I know very little of the Git GUI built into RStudio. I’m comfortable with that, but many I’d like to learn a bit more so I can help colleagues transition more easily into using version control.\nLet me know about your themes, fonts, layouts, settings and tips and tricks for RStudio or whatever other IDE you use.\nSee back here when we’ve all switched to another IDE and made this post redundant.3"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#environment",
    "href": "posts/2020-09-15-rstudio-settings/index.html#environment",
    "title": "Rate my RStudio setup",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:38:19 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#footnotes",
    "href": "posts/2020-09-15-rstudio-settings/index.html#footnotes",
    "title": "Rate my RStudio setup",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that I do most of my day-to-day coding on a work machine: a MacBook Air 13-inch (2017) running macOS Sierra with R v3.6.1 and RStudio v1.3.1073. Things may differ for you compared to what I write here.↩︎\nI wrote about {blogsnip} in another post.↩︎\nVANILLA R GUI FOR LIFE.↩︎"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html",
    "href": "posts/2020-09-27-targets-dsfest/index.html",
    "title": "Hit your reproducibility {targets}",
    "section": "",
    "text": "An excuse to use the dam good (lol) beavers1 data (Nature on PBS via Giphy)"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#tldr",
    "href": "posts/2020-09-27-targets-dsfest/index.html#tldr",
    "title": "Hit your reproducibility {targets}",
    "section": "tl;dr",
    "text": "tl;dr\nI spoke at the UK Government Data Science Festival about Will Landau’s R package {targets} for workflow reproducibility. You can jump to the embedded slides below."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#targets",
    "href": "posts/2020-09-27-targets-dsfest/index.html#targets",
    "title": "Hit your reproducibility {targets}",
    "section": "{targets}",
    "text": "{targets}\nReproducibility is an important part of any data analysis. Will people be able to re-run your code from scratch on a different machine without you present?\nR has lots of solutions for making your analysis reproducible, but one thing that gets overlooked is the reproducibility of the workflow itself. In other words, the interdependencies between functions, file and objects and the order in which they run.\n\n\n\n\n\nThe R package {targets} ‘remembers’ these relationships. In short, {targets} makes sure that only the impacted objects are re-run when you update your analysis. This means you don’t have to recreate everything from scratch each time.\nA very basic overview of using {targets}:\n\nWrite a pipeline script\nInspect the pipeline (including visually)\nExecute the pipeline\nChange stuff\nGo to 2\n\nWith functions:\n\ntar_script() creates a _targets.R file, which is where you declare you write functions and options and create your targets with tar_targets(), declaring the pipeline with tar_pipeline()\ntar_manifest() lets you check the configuration of your targets\ntar_visnetwork visualises your pipeline as a graph network\ntar_make() executes your pipeline, which caches outputs and metadata in a _targets/ directory that can be read from with tar_read() and tar_load() (you could use )\ntar_outdated() prints any targets that need to be updated following any changes to other targets, after which you can reinspect your pipeline and re-make it\n\nI’m not going to use this post to explain how to use the package in depth, but do check out the {targets} manual or the many other resources I’ve listed in the resources section below."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#slides",
    "href": "posts/2020-09-27-targets-dsfest/index.html#slides",
    "title": "Hit your reproducibility {targets}",
    "section": "Slides and code",
    "text": "Slides and code\nThe slides1 are embedded below. The presentation considers the need for workflow reproducibility followed by a small, contrived demo of the {targets} package in action: a short pipeline for rendering an R Markdown report with a plot and a table.2\n\n\n\n\n\n\n\n\nYou can also open the slides in a dedicated browser window. Press P for presenter notes, O for a slide overview and F for fullscreen.\nThe presentation’s source is in a GitHub repo that also contains {targets}-related files and scripts for running the example seen in the slides. See the ‘Demo code’ section of the README for details.\nIt wasn’t possible in this talk to go into greater depth on other excellent {targets} features like parallel computing and branching, but you can read about them in the {targets} manual."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#but-drake",
    "href": "posts/2020-09-27-targets-dsfest/index.html#but-drake",
    "title": "Hit your reproducibility {targets}",
    "section": "But… {drake}?",
    "text": "But… {drake}?\nYou may have noticed I have cunningly plagiarised myself by re-using slides from a presentation to Bioinformatics London in January 2020.\n\nThat presentation was about {drake}, another workflow reproducibility package by Will Landau. I also wrote about the {drake} package as a tool for the Reproducible Analytical Pipelines (RAP) movement in UK government.\nSo what’s the difference between the two packages? In Will’s own words:\n\nyears of community feedback [on {drake}] have exposed major user-side limitations regarding data management, collaboration, parallel efficiency, and pipeline archetypes\n\n{drake} is the more mature package and certainly it works, but {targets} is designed to address certain {drake} issues that only became apparent with ongoing, large-scale user testing in the wild. While {targets} addresses these problems, it’s worth noting that it’s still in development (v0.0.0.9002 at time of writing) and changes may be implemented that limit the usefulness of this post in future.\nOn the plus side, the {targets} package–along with the helper package {tarchetypes}, which I haven’t had time to mention here–is going through a peer review with rOpenSci (as of October 2020), which will help perfect the package and give people even greater confidence in its suitability for everyday use.\nUltimately it’s up to the user to decide which package they’d prefer to use for now, but {targets} looks to be the future for workflow reproducibility implemented within the R ecosystem."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#resources",
    "href": "posts/2020-09-27-targets-dsfest/index.html#resources",
    "title": "Hit your reproducibility {targets}",
    "section": "Resources",
    "text": "Resources\nWill has put a lot of effort into making some top quality documentation for {targets}, along with some handy learning tools:\n\nthe user manual, which includes a walkthrough\nthe reference website, which includes the statement of need vignette\nA tutorial, which can be run in the cloud\ntargetsketch: a Shiny app for learning and visualising\na repo with a minimal example (more complex examples are available too)\nslides from the Los Angeles R Users Group Meetup (October 2020)"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#environment",
    "href": "posts/2020-09-27-targets-dsfest/index.html#environment",
    "title": "Hit your reproducibility {targets}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 19:09:17 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#footnotes",
    "href": "posts/2020-09-27-targets-dsfest/index.html#footnotes",
    "title": "Hit your reproducibility {targets}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCreated with {xaringan} by Yihui Xie with some bonus features via {xaringanExtra} by Garrick Aden-Buie.↩︎\nUsing the excellent beaver1 and beaver2 datasets.↩︎"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#tldr",
    "href": "posts/2018-06-05-tid-ye-text/index.html#tldr",
    "title": "Tid-ye-text with {geniusr}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use {geniusr} to get artist and song data from the Genius API and {tidytext} to wrangle the text."
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#genius",
    "href": "posts/2018-06-05-tid-ye-text/index.html#genius",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Genius?",
    "text": "Genius?\nKanye West released his latest album—ye—last week1 after a(nother) pretty turbulent and controversial period of his life2. So what’s been on his mind?\nI think the real question is why don’t we scrape Yeezus’s lyrics from the web and analyse them using R? Obviously."
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#genius-1",
    "href": "posts/2018-06-05-tid-ye-text/index.html#genius-1",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Genius",
    "text": "Genius\nGenius is a website where you can upload and comment on song lyrics. It’s like Pop Up Video for young people.\nYou can access the lyrics data via Genius’s API3. Luckily, the R package {geniusr} was developed by Ewen Henderson for exactly this purpose.4"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#access-the-api",
    "href": "posts/2018-06-05-tid-ye-text/index.html#access-the-api",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Access the API",
    "text": "Access the API\nYou need to register with Genius so you can get tokens for accessing their API. To do this:\n\nCreate a new Genius API client.\nClick ‘generate access token’ under ‘client access token’ to generate an access token.\nAfter install.packages(\"geniusr\"), library(geniusr) you’ll be prompted to enter the access token when you try to use a {geniusr} function\n\nI stored the token in my .Renviron file. This is a file for store variables that R will look for and load automatically on startup. Edit the file on your system by running usethis::edit_r_environ() and adding the line GENIUS_API_TOKEN=X, replacing X with your token.\nIf you don’t store your token this way then you’ll be prompted for a new token every time you start a new R session, which could get quite tedious. It also means you don’t have to store it in plain sight"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#use-geniusr",
    "href": "posts/2018-06-05-tid-ye-text/index.html#use-geniusr",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Use {geniusr}",
    "text": "Use {geniusr}\n\nFind Kanye\nFirst we need to find the artist ID for Kanye. We can use search_artist() to look for him.\n\nlibrary(dplyr)\nlibrary(geniusr)\n\nsearch_artist(\"kanye west\") %&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\nartist_id\nartist_name\nartist_url\n\n\n\n\n72\nKanye West\nhttps://genius.com/artists/Kanye-west\n\n\n652275\nJAY-Z & Kanye West\nhttps://genius.com/artists/Jay-z-and-kanye-west\n\n\n\nKanye’s ID on Genius is 72 as a solo artist. We can save this value as the object kanye_id and use it to get metadata about him. This includes the web address for his artist page on Genius, a link to the image of him used on the site and the number of people ‘following’ his lyrics page.\n\nkanye_id &lt;- 72\nartist_meta &lt;-get_artist_meta(artist_id = kanye_id)\nglimpse(artist_meta)\n\nObservations: 1\nVariables: 5\n$ artist_id        &lt;int&gt; 72\n$ artist_name      &lt;chr&gt; \"Kanye West\"\n$ artist_url       &lt;chr&gt; \"https://genius.com/artists/Kanye-west\"\n$ artist_image_url &lt;chr&gt; \"https://images.genius.com/92fee84306e9a1ec88...\n$ followers_count  &lt;int&gt; 8754\n\n\nGet songs\nNow we can use Kanye’s artist ID to obtain all his songs on Genius.\n\nkanye_songs &lt;- get_artist_songs(artist_id = kanye_id)\n\nkanye_songs %&gt;%\n  sample_n(5) %&gt;%\n  select(song_name) %&gt;% \n  knitr::kable()\n\n\n\n\nsong_name\n\n\n\n\nCan’t Tell Me Nothing (Official Remix) (Ft. Jeezy)\n\n\nLast Call\n\n\nOh Oh\n\n\nSee You In My Nightmares (Live From VH1 Storytellers)\n\n\nParanoid (Ft. Mr. Hudson)\n\n\n\nWe can also access a greater list of data for each song, including the album name and release date. We can use the map_df function from the {purrr} package to look for the meta data for each song in turn.\n\nlibrary(purrr)\n\nsongs_meta &lt;- map_df(kanye_songs$song_id, get_song_meta)\n\nsample_n(songs_meta, 10) %&gt;% \n  select(song_name, album_name) %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\nsong_name\nalbum_name\n\n\n\n\nNever See Me Again\nNA\n\n\nOlskoolicegre\nI’m Good\n\n\nJust Soprano Freestyle\nNA\n\n\nBET Cypher 2010 (Kanye West, Big Sean, Pusha T, & Common) (Ft. Big Sean, Common, CyHi The Prynce & Pusha-T)\nNA\n\n\n\nLooking at the album names, it seems we’ve got songs from 37 albums at least plus a bunch that are unknown or unclassified.\n\nunique(songs_meta$album_name)\n\n[1] NA                                                                \n[2] \"Def Poetry Jam\"                                                  \n[3] \"Kanye West's Visionary Streams of Consciousness\"                 \n[4] \"Zane Lowe BBC Radio Interviews (Kanye West)\"                     \n[5] \"The Life of Pablo\"                                               \n[6] \"808s & Heartbreak\"                                               \n[7] \"Late Registration\"                                               \n[8] \"The College Dropout\"                                             \n[9] \"Freshmen Adjustment\"                                             \n[10] \"World Record Holders\"                                            \n[11] \"ye\"                                                              \n[12] \"My Beautiful Dark Twisted Fantasy\"                               \n[13] \"VH1 Storytellers\"                                                \n[14] \"Get Well Soon...\"                                                \n[15] \"Freshmen Adjustment Vol. 2\"                                      \n[16] \"The Cons, Volume 5: Refuse to Die\"                               \n[17] \"Graduation\"                                                      \n[18] \"Can't Tell Me Nothing\"                                           \n[19] \"Kon the Louis Vuitton Don\"                                       \n[20] \"Yeezus\"                                                          \n[21] \"I'm Good\"                                                        \n[22] \"Graduation \\\"Bonus Tracks, Remixes, Unreleased\\\" EP\"             \n[23] \"Turbo Grafx 16*\"                                                 \n[24] \"G.O.O.D. Fridays\"                                                \n[25] \"Kanye West Presents Good Music Cruel Summer\"                     \n[26] \"Kanye's Poop-di-Scoopty 2018\"                                    \n[27] \"King\"                                                            \n[28] \"Freshmen Adjustment Vol. 3\"                                      \n[29] \"2016 G.O.O.D. Fridays\"                                           \n[30] \"Welcome to Kanye's Soul Mix Show\"                                \n[31] \"Late Orchestration\"                                              \n[32] \"College Dropout: Video Anthology\"                                \n[33] \"The Lost Tapes\"                                                  \n[34] \"NBA 2K13 Soundtrack\"                                             \n[35] \"Rapper's Delight\"                                                \n[36] \"Boys Don't Cry (Magazine)\"                                       \n[37] \"The Man With the Iron Fists (Original Motion Picture Soundtrack)\"\n[38] \"Coach Carter (Music from the Motion Picture)\"\nSo you can see ye is definitely in the list of albums and we can filter our data frame so we just get the seven tracks from that particular album. Maybe we’ll explore the other lyrics more deeply another day.\n\nye &lt;- songs_meta %&gt;% filter(album_name == \"ye\")\nselect(ye, song_name)\n\n# A tibble: 7 x 1\nsong_name                  \n&lt;chr&gt;                      \n1 All Mine                   \n2 Ghost Town                 \n3 I Thought About Killing You\n4 No Mistakes                \n5 Violent Crimes             \n6 Wouldn't Leave             \n7 Yikes\nWe can fetch the lyrics from Genius for each song now that we have their details. We can do this using map_df() again to apply the scrape_lyrics_url() function to each row of our dataframe, where each row represents a single song.\n\nye_lyrics &lt;- map_df(\n  ye$song_lyrics_url,\n  scrape_lyrics_url\n)\n\nye_lyrics &lt;- ye_lyrics %&gt;%\n  group_by(song_name) %&gt;% \n  mutate(line_number = row_number()) %&gt;% \n  ungroup() %&gt;% \n  left_join(ye, by = \"song_name\")\n\nye_lyrics %&gt;% \n  sample_n(10) %&gt;% \n  select(line, song_name) %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\nline\nsong_name\n\n\n\n\nIt’s a different type of rules that we obey\nI Thought About Killing You\n\n\nThis not what we had in mind\nGhost Town\n\n\nWe could wait longer than this\nWouldn’t Leave\n\n\nNot havin’ ménages, I’m just bein’ silly\nViolent Crimes\n\n\nShit could get menacin’, frightenin’, find help\nYikes\n\n\nThank you for all of the glory, you will be remembered, aw\nViolent Crimes\n\n\nSometimes I take all the shine\nGhost Town\n\n\nBaby, don’t you bet it all\nGhost Town\n\n\nPremeditated murder\nI Thought About Killing You\n\n\nBut that’s not the case here\nI Thought About Killing You"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#break-the-lyrics-down",
    "href": "posts/2018-06-05-tid-ye-text/index.html#break-the-lyrics-down",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Break the lyrics down",
    "text": "Break the lyrics down\n\nWords\n\nExtract\nNow we’ve got the lines separated, we can bring in the {tidytext} package from Julia Silge and David Robinson to break the lines into ‘tokens’ for further text analysis. Tokens are individual units of text prepared for analysis. In our case, we’re looking at individual words, or ‘unigrams’.\nWe should probabaly remove stop words. These are words don’t really have much meaning in this context because of their ubiquity, like ‘if’, ‘and’ and ‘but’. We can get rid of these by anti-joining a pre-prepared list of such words.\n\nlibrary(tidytext)\n\nye_words &lt;- ye_lyrics %&gt;%\n  unnest_tokens(word, line) %&gt;%  # separate out tokens\n  anti_join(tidytext::stop_words)  # remove 'if', 'and', etc\n\nye_words %&gt;%\n  sample_n(5) %&gt;% \n  select(word, song_name) %&gt;% \n  knitr::kable()\n\n\n\n\nword\nsong_name\n\n\n\n\nyesterday\nViolent Crimes\n\n\ndrop\nI Thought About Killing You\n\n\nhuh\nYikes\n\n\npublicly\nWouldn’t Leave\n\n\ndrama’ll\nGhost Town\n\n\n\nNote that this isn’t completely successful. Kanye also uses colloquialisms and words like ‘ima’; a contraction of two stop words that isn’t represented in our stop-word dictionary.\n\n\nCount words\nNow we’ve tokenised the lyrics to removed stopwords, let’s also show this as a plot. For simplicity, we’ll show only the words that appeared more than five times.\nI’ve sampled even colours from the album cover of ye, stored as hexadecimal values in a named vector. We can select from these to decorate our plot, because why not. The album cover is a Wyoming mountainscape, taken on Kanye’s own iPhone shortly before he held a listening party for the new album. Scrawled in green lettering over the image is the phrase ‘I hate being Bi-Polar it’s awesome’.\n\nye_cols &lt;- c(\n  mountain_blue = \"#233956\",\n  grass_blue = \"#0e1e27\",\n  cloud_blue1 = \"#7a8aa2\",\n  cloud_white = \"#dfd7c9\",\n  cloud_grey = \"#b5b2b0\",\n  cloud_blue2 = \"#9da3ae\",\n  text_green = \"#31ef56\"\n)\n\nOkay, on with the plot.\n\nlibrary(ggplot2)\n\nye_words %&gt;%\n  count(word, sort = TRUE) %&gt;%  # tally words\n  filter(n &gt; 5) %&gt;%  # more than 5 occurrences \n  mutate(word = reorder(word, n)) %&gt;%  # order by count\n  ggplot(aes(word, n)) +\n  geom_col(fill = ye_cols[\"mountain_blue\"]) +\n  labs(\n    title = \"Frequency of words in 'ye' (2018) by Kanye West\",\n    subtitle = \"Using the geniusr and tidytext packages\",\n    x = \"\", y = \"Count\",\n    caption = \"Lyrics from genius.com\"\n  ) +\n  coord_flip() +\n  theme(  # apply ye theming\n    plot.title = element_text(colour = ye_cols[\"cloud_white\"]),\n    plot.subtitle = element_text(colour = ye_cols[\"cloud_white\"]),\n    plot.caption = element_text(colour = ye_cols[\"cloud_blue1\"]),\n    axis.title = element_text(colour = ye_cols[\"text_green\"]),\n    axis.text = element_text(colour = ye_cols[\"text_green\"]),\n    plot.background = element_rect(fill = ye_cols[\"grass_blue\"]),\n    panel.background = element_rect(fill = ye_cols[\"cloud_grey\"]),\n    panel.grid = element_line(ye_cols[\"cloud_grey\"])\n  )\n\n\n\n\n\nBigrams\n\nExtract\nTokenising by individual words is fine, but we aren’t restricted to unigrams. We can also tokenise by bigrams, which are pairs of adjacent words. For example, ‘damn croissant’ is a bigram in the sentence ‘hurry up with my damn croissaint’.\n\nye_bigrams &lt;- ye_lyrics %&gt;%\n  unnest_tokens(\n    bigram,\n    line,\n    token = \"ngrams\",\n    n = 2\n  )\n\nRemoving stopwords is tricker than for tokenising by word. We should tokenise by bigram first, then separate the words and match them to our stopword list.\n\nlibrary(tidyr)\n\nye_bigrams_separated &lt;- ye_bigrams %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\nThen we can filter to remove the stopwords.\n\nye_bigrams_filtered &lt;- ye_bigrams_separated %&gt;%\n  dplyr::filter(\n    !word1 %in% stop_words$word,\n    !word2 %in% stop_words$word\n  ) %&gt;%\n  mutate(bigram = paste(word1, word2))\n\nThe results look a bit like this:\n\nye_bigrams_filtered %&gt;% \n  sample_n(5) %&gt;% \n  select(bigram, song_name) %&gt;%\n  knitr::kable()\n\n\n\n\nbigram\nsong_name\n\n\n\n\nbleed yeah\nGhost Town\n\n\nfallin dreamin\nViolent Crimes\n\n\npremeditated murder\nI Thought About Killing You\n\n\ngonna leave\nAll Mine\n\n\nayy i’ma\nAll Mine\n\n\n\n\n\nCount bigrams\nSo let’s plot the most frequent bigram occurrences, like we did for the single words\n\nye_bigrams_filtered %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  filter(n &gt; 3) %&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(bigram, n)) +\n  geom_col(fill = ye_cols[\"mountain_blue\"]) +\n  labs(\n    title = \"Frequency of bigrams in 'ye' (2018) by Kanye West\",\n    subtitle = \"Using the geniusr and tidytext packages\",\n    x = \"\", y = \"Count\",\n    caption = \"Lyrics from genius.com\"\n  ) +\n  coord_flip() +\n  theme(\n    plot.title = element_text(colour = ye_cols[\"cloud_white\"]),\n    plot.subtitle = element_text(colour = ye_cols[\"cloud_white\"]),\n    plot.caption = element_text(colour = ye_cols[\"cloud_blue1\"]),\n    axis.title = element_text(colour = ye_cols[\"text_green\"]),\n    axis.text = element_text(colour = ye_cols[\"text_green\"]),\n    plot.background = element_rect(fill = ye_cols[\"grass_blue\"]),\n    panel.background = element_rect(fill = ye_cols[\"cloud_grey\"]),\n    panel.grid = element_line(ye_cols[\"cloud_grey\"])\n  )"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#what-did-we-learn",
    "href": "posts/2018-06-05-tid-ye-text/index.html#what-did-we-learn",
    "title": "Tid-ye-text with {geniusr}",
    "section": "What did we learn?",
    "text": "What did we learn?\nIt’s difficult to get a deep insight from looking at individual words from a 24-minute, seven-song album. You might argue that looking for deep insight from Kanye West’s lyrics is a fool’s errand anyway.\nDespite this, ‘love’ and ‘feel’ were in the top 10, which might indicate Kanye expressing his feelings. ‘Bad’, ‘mistake’ and ‘pray’ were also repeated a bunch of times, which might also indicate what’s on Ye’s mind.\nMost of the other most common words should probably have been removed as stop words but weren’t in our stop-word dictionary (e.g. ‘yeah’, ‘mhm’, ‘i’ma’, ‘gon’, ‘ayy’, ‘wanna’). Perhaps unsurprisingly, the flexibility of various swear words means they’re pretty high up the list.\nWe’ve seen how simple it is to use the {geniusr} functions search_artist(), get_artist_meta(), get_artist_songs(), get_songs_meta() and scrape_lyrics_url() in conjunction with {purrr}, followed by some tidytext.\nThe next step might be to look at Ye’s entire back catalogue and see how his lyrics have changed over time and how they compare to ye in particular.\nObviously I only made this post for the ‘tid-ye-text’ pun, so take it or leave it."
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#environment",
    "href": "posts/2018-06-05-tid-ye-text/index.html#environment",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 22:11:46 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-06-05-tid-ye-text/index.html#footnotes",
    "href": "posts/2018-06-05-tid-ye-text/index.html#footnotes",
    "title": "Tid-ye-text with {geniusr}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is not a review of the album. There’s plenty of those already.↩︎\nThis is also not a commentary on his many controversies.↩︎\nAn API is an ‘Application Programme Interface’, which is a fancy way of saying ‘computers talking to computers’.↩︎\nNote that there’s also a {geniusR} package, which has a very similar name, but has to be installed from GitHub rather than CRAN.↩︎"
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "",
    "text": "I made a couple of packages that contain RStudio Addins: {quartostamp} inserts little divs and classes into your Quarto documents, while {snorkel} inserts Rd tags into your {roxygen2} function documentation."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#tldr",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#tldr",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "",
    "text": "I made a couple of packages that contain RStudio Addins: {quartostamp} inserts little divs and classes into your Quarto documents, while {snorkel} inserts Rd tags into your {roxygen2} function documentation."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#al-addin",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#al-addin",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Al Addin",
    "text": "Al Addin\nRStudio Addins let you access R functions interactively at the click of a button (or with a keyboard shortcut, or via the RStudio command palette). I particularly like them for easy sharing of insertable pre-written code.\nSee Dean Attali’s {addinslist} package for examples or the {shrtcts} package by Garrick Aden-Buie for an alternative approach to ‘make anything an RStudio shortcut’.\nOn my part:\n\nI wrote about the little {backtick} Addin package that inserts backticks (`) and backtick constructions1\nI wrote about the {r2eng} package, which has an Addin that lets you highlight some R code and then speak that expression out loud in English\nI wrote about the {blogsnip} Addin package that can manipulate code used to write this blog\nthe {a11ytables} package has an Addin to insert code skeletons for creating publishable best-practice spreadsheets\n\nRStudio Addins are kinda straightforward to put into in an R package. Put your functions in R/ as usual, then write an inst/rstudio/addins.dcf file to declare your functions (e.g. see {backtick}’s .dcf). Learn more from Sharon Machlis and Jozef Hajnala.\nThe user can then select the functions from the ‘Addins’ dropdown in the RStudio IDE.\nOf late I’ve written two packages—{quartostamp} and {snorkel}—that contain RStudio Addins to help me write code structures that I struggle to remember when writing Quarto documents and function documentation.\nOthers seem to have found these useful, so I thought I’d ‘officially’ signal that they exist."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#package-quartostamp",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#package-quartostamp",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Package {quartostamp}",
    "text": "Package {quartostamp}\n\nQuarto—‘new R Markdown’—is all the rage right now, having been officially launched at the recent rstudio::conf(2022) conference. Folks are going bonkers for tools and techniques to learn and implement it. A good place to begin is the Awesome Quarto List by Mickaël Canouil.\nFeatured there is {quartostamp}, a little R package I made that contains an RStudio Addin to insert into your Quarto doc a number of useful divs and classes. As the README puts it:\n\nWhy ‘quartostamp’? You could physically stamp some pre-prepared type into a literal quarto document; you can digitally stamp some pre-written elements into your qmd file.\n\n\n\n\nHex logo for {quartostamp}.\n\n\nYou can install it from GitHub like:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/quartostamp\")\n\nAs an example, did you forget how to insert speaker notes into a presentation? Go to Addins &gt; Insert Speaker Notes and this will be inserted to your doc:\n::: {.notes}\nSpeaker notes go here.\n:::\nThat’s a straightforward one; a two-column layout is more complex. Go to Addins &gt; Insert Column Layout and you get this:\n:::: {.columns}\n\n::: {.column width='40%'}\nLeft column\n:::\n\n::: {.column width='60%'}\nRight column\n:::\n\n::::\nThese elements are basically lifted from the docs, so big shoutout to the authors JJ Allaire, Charles Teague, Carlos Scheidegger, Yihui Xie and Christophe Dervieux.\nGo to the package website to see the current list of functions available in the Addin. Click them to learn more, including a preview of the actual text that will be inserted into your document.\nI think the limits of the package are the content that you would insert in the body of your Quarto doc, or to places like Revealjs slide headings. In other words, not Quarto YAML nor chunk options. These are autocompleted in RStudio, or otherwise dealt with already elsewhere.\nDo submit your ideas for {quartostamp} as issues or pull requests in the GitHub repo.\n\n Note\nThe package was updated in June 2023 to version 0.1.0, which lets you highlight some text and run the addin so that the selected text becomes the body of the stamp. A simple dummy skeleton is inserted if you use the addin without highlighting any text, as described above.\nFor example, you can write some bullets, highlight them, select ‘Insert Speaker Notes’ and you’ll get the appropriate markup for those bullets to be rendered as speaker notes in your Quarto presentation."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#package-snorkel",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#package-snorkel",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Package {snorkel}",
    "text": "Package {snorkel}\n\nThe {snorkel} package2 is another solution to storing syntax outside of my own brain. In this case, it helps out with formatting text in {roxygen2} function documentation.3\nThe reason for the name should be obvious.4 As the package README puts it:\n\nYou put a snorkel in your mouth to help you breathe oxygen; you put a {snorkel} in your addins to help you write with {roxygen2}.\n\nYes, this is package-name-driven development; I thought of the name before writing anything.\nInstall from GitHub like:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/snorkel\")\n\nSo, how would you embolden a word in your function documentation? Highlight the word and then go to Addins &gt; Format Bold and you get:\n#' I am a \\strong{bold} boy.\nHere’s something more complex: how can you link to a function in an external package? Write the package function in the form package::function, highlight it and then select Addins &gt; Link To Function (Another Package) and you get:\n#' When the crowd say 'Bo \\code{\\link[dplyr]{select}}a'.\nThe functions in the Addin insert code mentioned in the {roxygen2} docs, so big shoutout to the authors Hadley Wickham, Peter Danenberg, Gabor Csárdi, Manuel Eugster and RStudio.\nThe package website has a list of the functions available in the Addin,5 which you can click to see previews of what each one will insert.\nFor now I think the functions in the package should focus just on the Rd tags that format the documentation, rather than the {roxygen2} tags (like @description, @params, etc). The latter are already autocompleted in RStudio, so I feel like there’s less need. Similarly, the package doesn’t include functions to insert Markdown into function documentation, but perhaps it could be expanded in future.\nNew functionality is always welcome; please raise an issue or pull request in the GitHub repo."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#addin-your-suggestions",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#addin-your-suggestions",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Addin your suggestions",
    "text": "Addin your suggestions\nI made these primarily for myself; I’m really bad at remembering syntax. I always need ‘a brain outside my brain’. Maybe they’ll be useful for you too.\nPerhaps you can help out by expanding the list of functions in these packages. Please add any suggestions or features in an issue or pull request in either GitHub repo.\nSo, don’t be a cad, it would be maddenin’ and saddenin’ if you hadn’t added in your Addin ideas, so be a rad chad and add your addins in the Addins."
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#environment",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#environment",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 10:00:28 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       fontawesome_0.5.2 evaluate_0.23"
  },
  {
    "objectID": "posts/2022-08-11-quartostamp-snorkel/index.html#footnotes",
    "href": "posts/2022-08-11-quartostamp-snorkel/index.html#footnotes",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, there are use cases for this! For example, Italian keyboards don’t have a backtick?!↩︎\nI sort-of announced this before in the {backtick} post, but then John Mackintosh signal-boosted it on Twitter and folks seemed interested, so here we are.↩︎\nBut note that you can write documentation with Markdown! I may expand the package to cover this in future.↩︎\nAlthough I still like ‘{aqualung}’ as a package name.↩︎\nYes, there is an Easter-egg function in the package for your wellbeing.↩︎"
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#tldr",
    "href": "posts/2021-11-27-lubridate-fns/index.html#tldr",
    "title": "{itdepends} on {lubridate}",
    "section": "tl;dr",
    "text": "tl;dr\nI used {itdepends} to see how CRAN packages depend on {lubridate}, which was not removed from CRAN recently."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#lubrigate",
    "href": "posts/2021-11-27-lubridate-fns/index.html#lubrigate",
    "title": "{itdepends} on {lubridate}",
    "section": "Lubrigate",
    "text": "Lubrigate\nA test failure in {lubridate} led to hundreds of R developers being emailed about its potential expulsion from CRAN, which also threatened the hundreds of packages that depend on it.\nI see the benefit of minimising dependencies. I also understand the drawbacks of reinventing the wheel. Maybe {lubridate} is a good dependency: a simple API, part of the popular {tidyverse}, and it handles stuff you can’t be bothered with (like what’s 29 February plus one year?).\nJim Hester spoke at rstudio::conf(2019) about dependencies. His {itdepends} package helps you understand their scale and impact on your package.1\nSo, for fun, I’m looking at how {lubridate} is used by packages that import it."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#crank-it-up",
    "href": "posts/2021-11-27-lubridate-fns/index.html#crank-it-up",
    "title": "{itdepends} on {lubridate}",
    "section": "CRANk it up",
    "text": "CRANk it up\nCRAN_package_db() is a convenient function that returns information about packages available on CRAN. We can filter it for the packages that import {lubridate}, i.e. they have {lubridate} in the Imports section of their DESCRIPTION file.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tidyr)\nlibrary(stringr)\n\ncran &lt;- tools::CRAN_package_db()\n\nimports_lubridate &lt;- cran |&gt; \n  filter(str_detect(Imports, \"lubridate\")) |&gt; \n  pull(Package)\n\nsample(imports_lubridate, 5)  # random sample\n\n[1] \"quantdates\"  \"GetDFPData2\" \"esmprep\"     \"strand\"      \"votesmart\"\nRight, so that’s 494 packages out of 18,515 (3%). Is that a lot? Well, the tidyverse package {dplyr}—the Swiss Army knife of data wrangling—is listed in the Imports of 2353 by comparison."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#install",
    "href": "posts/2021-11-27-lubridate-fns/index.html#install",
    "title": "{itdepends} on {lubridate}",
    "section": "InstALL",
    "text": "InstALL\nSo, perhaps this is a little nuts, but we’re going to install all the {lubridate}-dependent packages because {itdepends} works with locally-installed packages.\n\ntmp &lt;- tempdir()  # temporary folder\n\npurrr::walk(\n  imports_lubridate,\n  ~install.packages(\n    .x, \n    destdir = tmp, \n    dependencies = FALSE,  # skip installing dependencies\n    repos = \"https://cran.ma.imperial.ac.uk/\"  # mirror\n  )\n)\n\nThis takes a little while. There’s probably faster methods, like maybe the {pak} package, but for now I just used what worked. I’ve also hidden the output, obviously. It’s also possible that some packages will error out and won’t install. Oh no! Ah well."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#it-depends-on-itdepends",
    "href": "posts/2021-11-27-lubridate-fns/index.html#it-depends-on-itdepends",
    "title": "{itdepends} on {lubridate}",
    "section": "It depends on {itdepends}",
    "text": "It depends on {itdepends}\n{itdepends} is not available from CRAN, but you can install from GitHub.\n\nremotes::install_github(\"jimhester/itdepends\")\n\nNow we can pass each of package name to the dep_usage_package() function of {itdepends} in a loop. We get back a dataframe for each package, listing each function call it makes and the package that the function comes from.\nI’ve added a mildly unorthodox use of next, borrowed from StackOverflow, because I was having trouble with the loop after a failure.\n\ndep_list &lt;- vector(\"list\", length(imports_lubridate)) |&gt; \n  setNames(imports_lubridate)\n\nfor (i in imports_lubridate) {\n  \n  skip &lt;- FALSE\n  \n  tryCatch({ \n    dep_list[[i]] &lt;- itdepends::dep_usage_pkg(i)\n    dep_list[[i]]$focus &lt;- i\n  },\n  error = function(e) { \n    dep_list[[i]] &lt;- data.frame(\n      pkg   = NA_character_,\n      fun   = NA_character_,\n      focus = NA_character_\n    )\n    skip &lt;&lt;- TRUE \n  })\n  \n  if (skip) next\n  \n}\n\nI absolutely do not claim this to be the best, most optimised approach. But it works for me."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#dependensheeesh",
    "href": "posts/2021-11-27-lubridate-fns/index.html#dependensheeesh",
    "title": "{itdepends} on {lubridate}",
    "section": "Dependensheeesh",
    "text": "Dependensheeesh\nNow that {itdepends} has extracted all the function calls from each of the packages, we can take a look at their frequencies.\n\nExample\nHere’s the top 10 most-used functions from the first package alphabetically: {academictwitteR}.\n\nex_pkg &lt;- \"academictwitteR\"\n\ndep_list[[ex_pkg]] |&gt; \n  count(pkg, fun, sort = TRUE) |&gt;\n  slice(1:5)\n\n# A tibble: 5 × 3\n  pkg   fun       n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 base  &lt;-      228\n2 base  {       197\n3 base  if      109\n4 base  $        90\n5 base  !        42\nIt’s not particularly exciting to know that the top 5 are made up of base R functions like the assignment arrow (&lt;-), the dollar-sign ($) data accessor2 and the square bracket ([). We also don’t really care about the package’s internal functions. Let’s filter out these packages and re-count\n\nbase_pkgs &lt;- sessionInfo()$basePkgs\n\ndep_list[[ex_pkg]] |&gt;\n  filter(!pkg %in% c(base_pkgs, ex_pkg)) |&gt; \n  count(pkg, fun, sort = TRUE) |&gt; \n  slice(1:10)\n\n# A tibble: 10 × 3\n   pkg       fun                n\n   &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt;\n 1 lifecycle deprecate_soft    16\n 2 magrittr  %&gt;%               14\n 3 dplyr     bind_rows          8\n 4 dplyr     left_join          5\n 5 dplyr     select_if          5\n 6 httr      status_code        4\n 7 jsonlite  read_json          4\n 8 purrr     map_dfr            4\n 9 tibble    tibble             4\n10 dplyr     distinct           3\nAha. We can see immediately that the authors have made use of tidyverse to write their package, since you can see {dplyr}, {tibble}, etc, in there. This makes the use of {lubridate} relatively unsurprising.\nHere’s the {lubridate} functions used by this package.\n\ndep_list[[ex_pkg]] |&gt;\n  filter(pkg == \"lubridate\") |&gt; \n  count(pkg, fun, sort = TRUE)\n\n# A tibble: 4 × 3\n  pkg       fun             n\n  &lt;chr&gt;     &lt;chr&gt;       &lt;int&gt;\n1 lubridate as_datetime     1\n2 lubridate seconds         1\n3 lubridate with_tz         1\n4 lubridate ymd_hms         1\nSo this package uses four {lubridate} functions for conversion and formatting of datetimes.\n\n\nAll packages\nNow let’s take a look at the function calls across all the packages that import {lubridate}. I’m first going to convert the list of results to a dataframe.\n\ndep_df &lt;- do.call(rbind, dep_list)\n\n\nFunction use by package\nThis is a count of the number of uses of each {lubridate} function by each of the the focus packages (i.e. the packages we installed).\n\npkg_fn_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  count(focus, fun, sort = TRUE)\n\npkg_fn_count |&gt; slice(1:5)\n\n# A tibble: 5 × 3\n  focus        fun         n\n  &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt;\n1 PriceIndices month    1096\n2 PriceIndices year      678\n3 tidyndr      as_date    53\n4 RClimacell   with_tz    52\n5 RobinHood    ymd_hms    52\nHoly moley, the {PriceIndices} package calls month() and year(), used to extract elements of a date, over 1400 times combined.\n\n\nUnique function use by package\nWe can also look at things like the packages that make calls to the greatest number of unique {lubridate} functions. Here’s the top 5.\n\nfn_distinct_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  distinct(focus, fun) |&gt;\n  count(focus, sort = TRUE) \n\nfn_distinct_count |&gt; slice(1:5)\n\n# A tibble: 5 × 2\n  focus              n\n  &lt;chr&gt;          &lt;int&gt;\n1 photobiology      26\n2 mctq              25\n3 fmdates           21\n4 finbif            15\n5 xml2relational    15\nSo these packages are using more than 10 unique functions from {lubridate}, which is pretty extensive usage. It may be tricky to do away with the convenience of the dependnecy in these cases, especially.\nConversely, a quick histogram reveals that a large number of packages are actually using just a single {lubridate} function.\n\nhist(\n  fn_distinct_count$n,\n  breaks = 30,\n  main = \"Unique {lubridate} functions used by\\npackages importing {lubridate}\",\n  xlab = \"Function count\"\n)\n\n\nMaybe the dependency could be dropped in these cases?\nOut of interest, which {lubridate} function is the most frequent in packages that use just one?\n\nfocus_one_fn &lt;- fn_distinct_count |&gt;\n  filter(n == 1) |&gt;\n  pull(focus)\n\npkg_fn_count |&gt; \n  filter(focus %in% focus_one_fn) |&gt; \n  count(fun, sort = TRUE) |&gt; \n  slice(1:5)\n\n# A tibble: 5 × 2\n  fun             n\n  &lt;chr&gt;       &lt;int&gt;\n1 as_datetime     7\n2 as_date         6\n3 ymd             6\n4 ymd_hms         6\n5 is.Date         4\nLooks like some pretty standard functions, like converting to a date (as_date(), as_datetime()) or to parse dates with a particular time component (ymd_hms for year, month, date, hour, minute, seconds, and ymd()).\nI think this is interesting: some packages are importing {lubridate} in its entirety to use a single function. And these functions have base R equivalents with no package-dependency cost. Without diving too deep, this implies that people are using {lubridate} because of syntax familiarity or perhaps because they’re already loading other tidyverse packages anyway.\n\n\nNon-unique function use by package\nWhat about total calls to {lubridate} functions by each of the dependent package? This is on-unique, so could include one function being called multiple times by a given package.\n\nfn_nondistinct_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  count(focus, sort = TRUE)\n\ndep_df |&gt; \n  count(focus) |&gt; \n  left_join(\n    fn_nondistinct_count,\n    by = \"focus\",\n    suffix = c(\"_total\", \"_lub\")\n  ) |&gt; \n  mutate(percent_lub = round(100 * n_lub / n_total, 1)) |&gt; \n  arrange(desc(percent_lub)) |&gt;\n  slice(1:5)\n\n# A tibble: 5 × 4\n  focus        n_total n_lub percent_lub\n  &lt;chr&gt;          &lt;int&gt; &lt;int&gt;       &lt;dbl&gt;\n1 RClimacell      2241   225        10  \n2 riem             113     9         8  \n3 quantdates       534    42         7.9\n4 rtrends          101     8         7.9\n5 PriceIndices   23235  1805         7.8\nWow, 10% of calls by the {RClimacell} package involve {lubridate} functions. Make sense: this package relates to weather readings at certain time intervals.\nAnd another quick histogram of what the distribution looks like.\n\nhist(\n  fn_nondistinct_count$n,\n  breaks = 30,\n  main = \"Non-unique {lubridate} functions used by\\npackages importing {lubridate}\",\n  xlab = \"Function count\"\n)\n\n\nHuh, so the number of non-unique {lubridate} calls is almost always less than 50 per package. Seems in general that a small number of {lubridate} functions are called per dependent package, but they might be called a lot."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#you-do-you",
    "href": "posts/2021-11-27-lubridate-fns/index.html#you-do-you",
    "title": "{itdepends} on {lubridate}",
    "section": "You do you",
    "text": "You do you\nDoes the information here imply that many developers could consider removing their small number of {lubridate} calls in favour of date-related base functions? Maybe. That’s up to the developers.\nUltimately, {itdepends} might be a useful tool for you to work out if you need all the dependencies you have. Other tools are out there; I read recently about Ashley Baldry’s {depcheck} package, for example\nIt might be interesting to redo this investigation for all CRAN packages and their dependencies, but I don’t have a personal CRAN mirror and I don’t write particularly performant code.\nAnyway, don’t listen to me: I write joke packages that I don’t put on CRAN, lol."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#environment",
    "href": "posts/2021-11-27-lubridate-fns/index.html#environment",
    "title": "{itdepends} on {lubridate}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 20:42:28 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#footnotes",
    "href": "posts/2021-11-27-lubridate-fns/index.html#footnotes",
    "title": "{itdepends} on {lubridate}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTim reminded me of this package/nerdsniped me.↩︎\nYou should be aware of the international conspiracy behind the use of this symbol in R.↩︎"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html",
    "href": "posts/2021-01-28-adv-r-names/index.html",
    "title": "R’s names and values as anchovy pizza",
    "section": "",
    "text": "Queued two hours for this. R’s names and values system is faster to learn, but not as delicious."
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html#tldr",
    "href": "posts/2021-01-28-adv-r-names/index.html#tldr",
    "title": "R’s names and values as anchovy pizza",
    "section": "tl;dr",
    "text": "tl;dr\nI bought Hadley Wickham’s Advanced R book1 to help me better understand R’s quirks. Can names and values (chapter 2) be explained with a contrived pizzeria analogy?2"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html#a-pizza-by-any-other-name",
    "href": "posts/2021-01-28-adv-r-names/index.html#a-pizza-by-any-other-name",
    "title": "R’s names and values as anchovy pizza",
    "section": "A pizza by any other name",
    "text": "A pizza by any other name\nWelcome to the pizzeria. It’s called ‘La PizzRia’ because our owner likes to code and is really lazy at puns.\n\nToppings as vectors\nOur specialty (and only!) pizza is pizza alla napoletana, which is topped with mozzarella, tomatoes and anchovies.\n\n# Create a character-vector object\nnapoletana &lt;- c(\"mozzarella\", \"tomato\", \"anchovy\")\n\nThe English version of the menu calls it ‘Neapolitan’ pizza, but it’s the same thing.\n\nneapolitan &lt;- napoletana       # copy the object\nall(neapolitan == napoletana)  # they're equal\n\n[1] TRUE\n\n\nWe store our unique sets of pizza toppings in a special recipe book. If you look up ‘napoletana’ and ‘Neapolitan’ in the book’s index, you’ll see they point to the same recipe.\n\n# The {lobstr} package helps understand object structure\nlibrary(lobstr)  # after install.packages(\"lobstr\")\n\n# Get the specific object 'address' in your computer's memory\n# Both names point to the same object\nobj_addr(napoletana)  # original object\n\n[1] \"0x129af4728\"\n\nobj_addr(neapolitan)  # the copy\n\n[1] \"0x129af4728\"\n\n\nBasically, the pizzaiolos don’t care: different names, same pizza. The recipe codes are the same.\n\n Advanced R, p19\n“The object, or value, doesn’t have a name; it’s actually the name that has a value.”\n\n\n\n\nCopying a recipe, modifying it\nWe recently added pizza pugliese to the menu. We copied our napoletana in the recipe book and then modified it to have onions instead of anchovies.\n\npugliese &lt;- napoletana       # copy the object\nall(pugliese == napoletana)  # the objects are the same\n\n[1] TRUE\n\npugliese[[3]] &lt;- \"onion\"  # modify the third element\npugliese == napoletana    # they're no longer the same\n\n[1]  TRUE  TRUE FALSE\n\n\nWhen we look up these names in the index of our recipe book, we see that they point to different places, despite having copied the napoletana to get the pugliese.\n\n# Now the names point to different objects\n# We modified the copy, so it becomes a new object in memory\nobj_addr(napoletana)  # original object\n\n[1] \"0x129af4728\"\n\nobj_addr(pugliese)    # the modified copy\n\n[1] \"0x12b32ec68\"\n\n\n\n Advanced R, p22\n“This behaviour is called copy-on-modify.”\n\n\nSo, here’s our full pizza lineup in Italian and English.\n\napulian &lt;- pugliese  # specify English name for the pugliese\n\n# A comparison of the pizza object structures\nknitr::kable(\n  tibble::tribble(\n    ~Language, ~Name, ~`Toppings`, ~`Recipe code`, \n    \"ITA\", \"Pizza alla napoletana\", napoletana, obj_addr(napoletana),\n    \"ENG\", \"Neapolitan pizza\", neapolitan, obj_addr(neapolitan),\n    \"ITA\", \"Pizza pugliese\", pugliese, obj_addr(pugliese),\n    \"ENG\", \"Apulian pizza\", apulian, obj_addr(apulian)\n  )\n)\n\n\n\n\n\n\n\n\n\n\nLanguage\nName\nToppings\nRecipe code\n\n\n\n\nITA\nPizza alla napoletana\nmozzarella, tomato , anchovy\n0x129af4728\n\n\nENG\nNeapolitan pizza\nmozzarella, tomato , anchovy\n0x129af4728\n\n\nITA\nPizza pugliese\nmozzarella, tomato , onion\n0x12b32ec68\n\n\nENG\nApulian pizza\nmozzarella, tomato , onion\n0x12b32ec68\n\n\n\n\n\nPizza alla napoletana and its copy, Neapolitan pizza, point to the same recipe code.\nPizza pugliese was a copy of pizza alla napoletana, but it now points to a different recipe code. Why? An element was changed, anchovies to onions, so a new recipe code was required.\nFinally, Apulian pizza is a copy of the pizza pugliese recipe, so they both point to the same unique topping set.\n\n\nToppings as lists\nOur knowledge management system was, however, a bit inefficient: the mozzarella and tomato toppings existed twice in our recipe book; once for each pizza.\nSo we decided to update our recipe system to store each topping separately, each with its own special reference code too.\nAgain, we wrote down the pizza napoletana toppings, copied them, then switched the anchovies for onions. Like in our old system, the two pizzas differ in their third element.\n\n# Toppings now as list elements\nnapoletana &lt;- list(\"mozzarella\", \"tomato\", \"anchovy\")\npugliese &lt;- napoletana          # make a copy\nidentical(pugliese, napoletana) # they're the same\n\n[1] TRUE\n\npugliese[[3]] &lt;- \"onion\"        # make a change\nidentical(pugliese, napoletana) # now they're different\n\n[1] FALSE\n\n\nSo in the new system, each topping has its own unique ingredient code. This means both pizza recipes point to the same ingredient codes for tomato and mozzarella.\n\n# Compare addresses in memory for the lists\n# Each 'block' below is a list object (pizza)\n# Each element is a character vector (topping)\nref(napoletana, pugliese)\n\n█ [1:0x11ab4fb38] &lt;list&gt; \n├─[2:0x12a21e6a8] &lt;chr&gt; \n├─[3:0x12a21e638] &lt;chr&gt; \n└─[4:0x12a21e600] &lt;chr&gt; \n \n█ [5:0x11ab55d68] &lt;list&gt; \n├─[2:0x12a21e6a8] \n├─[3:0x12a21e638] \n└─[6:0x12a21e4b0] &lt;chr&gt; \n\n\nBasically, our pizza names point to pizza recipes that themselves point out to toppings.\n\n Advanced R, p25\n“This list is more complex [than a vector] because instead of storing the values itself, it stores references to them.”\n\n\nThis means we can be more efficient in storing our pizza recipes: we write down ‘mozzarella’ and ‘tomatoes’ only once. This could become much more efficient when storing more than the two pizzas we have on La PizzRia’s menu.3\n\n\nCustomer orders as data frames\nHow do we manage orders? Wait-staff write down each order in a column, with a row for each topping.\n\n Advanced R, p26\n“Data frames are lists of vectors.”\n\n\nLet’s say a couple orders a pizza napoletana and a pizza pugliese.\n\n# Create a data.frame, which is a list of vectors\n# Column behaviour is vector behaviour\norder &lt;- data.frame(\n  napoletana = c(\"mozzarella\", \"tomato\", \"anchovy\"),\n  pugliese = c(\"mozzarella\", \"tomato\", \"onion\")\n)\n\norder\n\n  napoletana   pugliese\n1 mozzarella mozzarella\n2     tomato     tomato\n3    anchovy      onion\n\n\nAs we know, these pizzas both have mozzarella and tomatoes, but the third topping is different.\nBut wait: the customer who ordered the napoletana is hungry for more anchovies!\n\norder_update &lt;- order  # copy the data.frame object\norder_update[3, 1] &lt;- \"anchovy (extra)\"  # modify the new object\norder_update\n\n       napoletana   pugliese\n1      mozzarella mozzarella\n2          tomato     tomato\n3 anchovy (extra)      onion\n\n\nWe use a code reference system for our orders too and it works just like our old recipe system.\nSince one of the pizza orders was changed, our reference code for the entire order was changed too.\nThe napoletana was modified after it was copied, so the recipe code for that pizza was updated. The pugliese didn’t change, so its code was maintained.\n\n# Compare the data.frame structures\n# Modified column gets new code, object gets new code\n# Second column unchanged, code stays the same\nref(order, order_update)\n\n█ [1:0x12abc7548] &lt;df[,2]&gt; \n├─napoletana = [2:0x12c1de9f8] &lt;chr&gt; \n└─pugliese = [3:0x12c1de908] &lt;chr&gt; \n \n█ [4:0x129ba3408] &lt;df[,2]&gt; \n├─napoletana = [5:0x129d1c948] &lt;chr&gt; \n└─pugliese = [3:0x12c1de908] \n\n\n\n Advanced R, p26\n“If you modify a column, only that column needs to be modified.”\n\n\nThe mozzarella is especially bountiful this year; the waiter suggests both patrons take advantage.\nThey strongly agree. The order is copied once more and the waiter modifies the ‘cheese row’ for both pizzas.\n\norder_final &lt;- order_update  # copy the object\norder_final[1, 1:2] &lt;- \"mozzarella (extra)\"  # modify row one of both columns\norder_final\n\n          napoletana           pugliese\n1 mozzarella (extra) mozzarella (extra)\n2             tomato             tomato\n3    anchovy (extra)              onion\n\n\nAltering the cheese row means both pizza columns are copied and given new codes. Of course, the order gets a whole new code of its own because the toppings were changed.\n\n# Compare data.frame structures again\n# All columns modified, so copies made\n# data.frame and column memory locations all differ\nref(order, order_final)\n\n█ [1:0x12abc7548] &lt;df[,2]&gt; \n├─napoletana = [2:0x12c1de9f8] &lt;chr&gt; \n└─pugliese = [3:0x12c1de908] &lt;chr&gt; \n \n█ [4:0x1188f7b88] &lt;df[,2]&gt; \n├─napoletana = [5:0x11ab42df8] &lt;chr&gt; \n└─pugliese = [6:0x11ab42da8] &lt;chr&gt; \n\n\n\n Advanced R, p27\n“If you modify a row, every column is modified, which means every column must be copied.”\n\n\nBuon appetito!"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html#il-conto",
    "href": "posts/2021-01-28-adv-r-names/index.html#il-conto",
    "title": "R’s names and values as anchovy pizza",
    "section": "Il conto",
    "text": "Il conto\nSo can names and values be explained with this analogy?\nKinda? The basic premise is there: names and pizzas, names and values, etc. But it’s definitely contrived. Why are wait staff writing down pizza orders in a dataframe, etc?\nI’ve also deceived you with some ‘polite fiction’, in Hadley’s words. In a numeric vector, the name points to the values. In a character vector, the name actually points to a vector of pointers, which themselves reference unique character strings.\n\n Advanced R, p27\n“R actually uses a global string pool where each element of a character vector is a pointer to a unique string in the pool.”\n\n\nBut I don’t think that’s a big deal for getting the point across.\nAnyway, your order’s here.\nMangia! Mangia!"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html#environment",
    "href": "posts/2021-01-28-adv-r-names/index.html#environment",
    "title": "R’s names and values as anchovy pizza",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:28:58 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lobstr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     utf8_1.2.3        fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 magrittr_2.0.3    glue_1.6.2        tibble_3.2.1     \n [9] knitr_1.43.1      pkgconfig_2.0.3   htmltools_0.5.5   rmarkdown_2.23   \n[13] lifecycle_1.0.3   cli_3.6.1         fansi_1.0.4       vctrs_0.6.3      \n[17] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       pillar_1.9.0     \n[21] evaluate_0.21     yaml_2.3.7        crayon_1.5.2      rlang_1.1.1      \n[25] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-names/index.html#footnotes",
    "href": "posts/2021-01-28-adv-r-names/index.html#footnotes",
    "title": "R’s names and values as anchovy pizza",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSecond edition. You can buy the book, or view it for free online.↩︎\nInitially I went with the pop-culture reference about how a Quarter Pounder with Cheese is called a Royale with Cheese in Paris (or indeed, a Krusty Burger with Cheese is called a Quarter Pounder with Cheese at McDonald’s), but the reference was better than the actual utility of the metaphor.↩︎\nOf course, if you’re really serious about pizza, you only offer two options. L’antica Pizzeria Da Michele, which is where I took the photos at the top of this post, offers only marinara and margherita. Do the simple things well.↩︎"
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html",
    "title": "Postcode pandemonium with {data.table}",
    "section": "",
    "text": "Postcodes in Bath are unlikely to score highly (via Wikimedia)"
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#tldr",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#tldr",
    "title": "Postcode pandemonium with {data.table}",
    "section": "tl;dr",
    "text": "tl;dr\nI used the R package {data.table} to find the highest- and lowest-scoring UK postcodes based on the sum of their numbers and letters (A = 1, B = 2, etc). You can jump to the results."
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#the-premise",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#the-premise",
    "title": "Postcode pandemonium with {data.table}",
    "section": "The premise",
    "text": "The premise\nYesterday I noticed that the hashtag #PostcodePandemonium was trending on Twitter.1 The premise was to sum the numbers and letters in your postcode, where the letters have been converted to their position in the alphabet (i.e. A = 1, B = 2, etc). Highest value ‘wins’.\nWhich existing postcode has the highest score? And the lowest?"
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#process",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#process",
    "title": "Postcode pandemonium with {data.table}",
    "section": "Process",
    "text": "Process\n\nAttach packages\nI’ve been using Matt Dowle and Arun Srinivasan’s lightning-fast {data.table} package recently and wanted to use it here to handle millions of UK postcodes. I’ve prioritised for readability in this post rather than efficiency, but let me know how to improve things.\n\nsuppressPackageStartupMessages({\n  library(data.table)  # a better data.frame\n  library(stringr)     # simple string handling\n  library(tictoc)      # timing\n})\n\nI’m using Sergei Izrailev’s {tictoc} package to time the processes throughout.\n\n\nGet the data\nThe latest postcode data (February 2020) is available on the Open Geography Portal by the Office for National Statistics. From there you can download a zipped folder that contains the file we want, NSPL_FEB_2020_UK.csv.\n\n Note\nI re-rendered this post in July 2023 and the link to the February 2020 postcode file no longer works. Instead, we’ll use the latest at time of writing: February 2023.\n\n\nFirst, you can download the .zip to a temporary location on your machine. The file is pretty large (about 180 MB), so I’m increasing the timeout value for download.file() so that the download has time to complete. You might want to consider downloading the file to your local computer and reading it from there.\n\n# URL to postcode zip file\nzip_url &lt;- paste0(\n  \"https://www.arcgis.com/\",\n  \"sharing/rest/content/items/\",\n  \"c7debafcef564e7a9dfb8ca881be4253/data\"\n)\n\n# Setup a temporary folder to download into\ntmp &lt;- tempdir()\nzip_path &lt;- file.path(tmp, \"postcodes.zip\")\n\n# Download the zip file to the tempporary location\noptions(timeout = max(1000, getOption(\"timeout\")))\ndownload.file(zip_url, zip_path)\n\nYou can then unzip() the CSV file inside {data.table}’s fread() for a rapid read.\n\ntic(\"CSV read complete\")\npcodes_dt &lt;- fread(unzip(zip_path, files = \"Data/NSPL21_FEB_2023_UK.csv\"))\ntoc()\n\nCSV read complete: 10.482 sec elapsed\n\nunlink(tmp)  # remove temp location\n\nAnd we can check the dimensions of this object.\n\n# Rows and columns in the data set\ndim(pcodes_dt)\n\n[1] 2687274      41\n\n\nSo there’s more than 2.5 million rows. Some postcodes have, however, been terminated over time. We’ll need to filter for the postcodes that are still active (thanks to Robert Kaleta for pointing this out).\nWe can also simplify to just the postcode column that we want using {data.table}‘s .() notation. Data in the pcds column has the consistent form of letter, letter, digit, space, digit, letter, letter (e.g. ’AB12 3CD’), which makes them relatively easy to deal with.\n\n# Filter for empty date of termination (doterm)\n# Retain only the postcode column\npcodes_dt &lt;- pcodes_dt[is.na(doterm), .(pcds)]\n\nhead(pcodes_dt)\n\n       pcds\n1: AB10 1AB\n2: AB10 1AF\n3: AB10 1AG\n4: AB10 1AH\n5: AB10 1AL\n6: AB10 1AN\n\nnrow(pcodes_dt)\n\n[1] 1793019\n\n\nYou can see that this removes a large number of terminated postcodes.\n\n\nExtract\nNow to extract the numbers and letters so that ‘AB12 3CD’ is broken into A, B, 12, 3, C and D, for example. Note that we want to extract multi-digit numbers if they exist within each half (the ‘outward’ and ‘inward’ parts) of the postcode, so 12 rather than 1 and 2, and 12 and 3 rather than 123.\nThe walrus operator (:=) is used here as a function to create new columns and assign names to them. I’ve chose to use {stringr}’s str_extract_all() function to match the strings we want. The regular expression contains values in the curly braces to indicate the desired character lengths to be matched.\nThis will produce two list-columns: one with the letters extracted into it and one with the numbers.\n\n# Extract letters into one list column and numbers into another\npcodes_dt[, `:=`(letter = str_extract_all(pcds, \"[:alpha:]{1}\"),\n                 number = str_extract_all(pcds, \"[:digit:]{1,2}\"))]\n\npcodes_dt\n\n             pcds  letter number\n      1: AB10 1AB A,B,A,B   10,1\n      2: AB10 1AF A,B,A,F   10,1\n      3: AB10 1AG A,B,A,G   10,1\n      4: AB10 1AH A,B,A,H   10,1\n      5: AB10 1AL A,B,A,L   10,1\n     ---                        \n1793015:  ZE3 9JU Z,E,J,U    3,9\n1793016:  ZE3 9JW Z,E,J,W    3,9\n1793017:  ZE3 9JX Z,E,J,X    3,9\n1793018:  ZE3 9JY Z,E,J,Y    3,9\n1793019:  ZE3 9JZ Z,E,J,Z    3,9\n\n\nRemember that {data.table} edits in place, so the pcodes_dt object will be updated and without the need to overwrite it (i.e. no need to do something like pcodes_dt &lt;- pcodes_dt[&lt;whatever&gt;]).\n\n\nNumbers and letters\nNow to work with the number list-column. The values are currently character-class because they were extracted from the postcode strings; they need to be made numeric before they can be summed. lapply() is used here to pass the function as.numeric() to achieve this.\n\ntic(\"Make numbers numeric class\")\npcodes_dt[, number := lapply(number, as.numeric)]\ntoc()\n\nMake numbers numeric class: 4.502 sec elapsed\n\n\nAnd now to work with the letter list column. The custom function in lapply() first turns the letters into the factor class, where the full set of possible levels is provided by the LETTERS vector, and then uses as.numeric() to convert each factor level to its corresponding numeric value.\nThis works on the principle that as.numeric(factor(c(\"A\", \"B\", \"C\"))) becomes c(1, 2, 3). The first factor level, A gets converted to 1, B to 2 and so on.\n\ntic(\"Convert letters to numbers, make numeric class\")\npcodes_dt[, letter_number := lapply(\n  letter, function(x) as.numeric(factor(x, levels = LETTERS)))]\ntoc()\n\nConvert letters to numbers, make numeric class: 11.431 sec elapsed\n\n\n\n\nScores\nNow to separately sum the number and letter values in each row of the list-columns and add them together for the final score.\n\n# Generate summation columns for letters and numbers separately\npcodes_dt[, `:=`(number_sum = lapply(number, sum),\n                 letter_sum = lapply(letter_number, sum))]\n\n# Make the sum columns numeric- rather than list-class\npcodes_dt$number_sum &lt;- as.numeric(pcodes_dt$number_sum)\npcodes_dt$letter_sum &lt;- as.numeric(pcodes_dt$letter_sum)\n\n# Sum the number and letter values\npcodes_dt[, score := number_sum + letter_sum]\n\n# The first few scores\nhead(pcodes_dt[, .(pcds, number_sum, letter_sum, score)])\n\n       pcds number_sum letter_sum score\n1: AB10 1AB         11          6    17\n2: AB10 1AF         11         10    21\n3: AB10 1AG         11         11    22\n4: AB10 1AH         11         12    23\n5: AB10 1AL         11         16    27\n6: AB10 1AN         11         18    29\n\n\nSo you can see, for example, that AB10 1AB has a number sum of 11 (10 + 1) and a letter sum of 6 (a couple of As and Bs, so 1 + 2 + 1 + 2), totalling 17."
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#results",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#results",
    "title": "Postcode pandemonium with {data.table}",
    "section": "Results",
    "text": "Results\nNow to order the results, focus on the postcodes and scores alone, and preview the top and bottom scores (provided by default in {data.table}’s print method).\n\n# Select cols and reorder by score\npcodes_dt[order(-score), .(pcds, score)]\n\n             pcds score\n      1: WV99 1ZZ   197\n      2: WV98 1ZZ   196\n      3: WV99 1YZ   196\n      4: WV99 1ZY   196\n      5: SS99 9YX   195\n     ---               \n1793015:   B1 2AA     7\n1793016:  BA1 0BA     7\n1793017:  BA1 1AA     7\n1793018:  BA2 0AA     7\n1793019:  BA1 0AA     6\n\n\nSo the top-scoring postcode was WV99 1ZZ with 197 points. It’s on an industrial estate in Telford, north-east of Birmingham. You can view it on Google Maps.\nThe lowest scoring postcodes were in Birmingham (Holloway Circus at B1 1BA and Arena Birmingham at B1 2AA) and Bath (near Bath Spa train station at BA1 1AA and south of Farmborough at BA2 0AA). They scored only 7.\nThe distribution of scores looks like this:\n\nhist(\n  pcodes_dt$score,\n  xlab = \"Score\",\n  main = \"Histogram of postcode scores\"\n)\n\n\n\n\nIt’s slightly skewed, with nearly 350,000 instances of scores between 60 and 70 and very few scores over 150.\nLet’s check out the summary statistics.\n\nsummary(pcodes_dt$score)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   6.00   54.00   67.00   68.86   81.00  197.00 \n\n\nSo the mean score is just under 70.\nHow does your score compare?\n\n\n\n‘WV’ provides 23 + 22 = 45 points in itself (via Wikimedia)"
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#environment",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#environment",
    "title": "Postcode pandemonium with {data.table}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-20 20:36:47 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tictoc_1.2        stringr_1.5.0     data.table_1.14.8\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    glue_1.6.2        knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3      \n[13] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[17] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[21] stringi_1.7.12"
  },
  {
    "objectID": "posts/2020-05-16-postcode-pandemonium/index.html#footnotes",
    "href": "posts/2020-05-16-postcode-pandemonium/index.html#footnotes",
    "title": "Postcode pandemonium with {data.table}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt originated from the social media team at a company controlled by one of the largest corporations in the world, so I don’t think it’s cynical to say that the whole thing was a marketing ploy.↩︎"
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#tldr",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#tldr",
    "title": "GitHub Actions for R packages",
    "section": "tl;dr",
    "text": "tl;dr\nYou can trigger GitHub Actions to build and test your R package after a push or pull request. Create .github/workflows/ in your repo and add pre-prepared actions by the r-lib team with usethis::use_github_action()."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#shortcut",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#shortcut",
    "title": "GitHub Actions for R packages",
    "section": "Shortcut",
    "text": "Shortcut\nI refer back to this post a lot, so here’s some jump-links to the sections with the code I need:\n\nBuild check\nTest coverage\nBuild {pkgdown} site\n\nOtherwise read on for a more thorough explanation of GitHub Actions in the context of R packages."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#lights-camera",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#lights-camera",
    "title": "GitHub Actions for R packages",
    "section": "Lights, camera…",
    "text": "Lights, camera…\nGitHub Actions is a service that can be triggered to run workflows that build, test and deploy your code on GitHub. In other words, a continuous integration platform baked right into GitHub.\nBefore you start, I recommend checking out Jim Hester’s talk from rstudio::conf 2020 and reading the GitHub Actions with R book.\nGitHub Actions can be really helpful for developing R packages.1 For example, you can trigger actions with a push or pull request (PR) that:\n\nrun an R CMD build check of your package on multiple platforms\nrun your {testthat} unit tests\ncheck test coverage with {covr} and Codecov\nrebuild your {pkgdown} website\n\nChecking the build and coverage are standard practices for package development. They help ensure that your package works and is stable. GitHub Actions provides the icing on the cake by doing these things automatically.\nThese are all important for users of your package too. Build and coverage results show the robustness of the code and a website makes your documentation much easier to access.\nI wrote this post to remind me how to do it."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#actions",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#actions",
    "title": "GitHub Actions for R packages",
    "section": "…Actions",
    "text": "…Actions\nHow are actions stored, recognised and triggered?\nActions are expressed in YAML script files that read like a recipe for what to run and when to run it. You put these files in your repo at the path .github/workflows/, where GitHub recognises them. The information is interpreted and the actions are run remotely given the specified trigger.\nYou can learn more about the content of these YAML files from the GitHub actions with R book.\nYou could set these up manually, but actually you can shortcut the process with the {usethis} package and some pre-written examples."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#usethis-and-r-lib",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#usethis-and-r-lib",
    "title": "GitHub Actions for R packages",
    "section": "{usethis} and r-lib",
    "text": "{usethis} and r-lib\n{usethis} helps to shortcut the tedious setup steps of R packages and projects. It also includes functions to add GitHub Actions to your R package for you.\nIn particular, usethis::use_github_action() will add a YAML file to .github/workflows/ where GitHub Actions will find it; you just supply the name of a pre-written action.\nWhere do these pre-written actions come from? Well, the kind folks at r-lib have made a repo of R-focused examples that you can use.\n\nExample: {r2eng} package\nI recently used this method to set up GitHub Actions for the in-development {r2eng} package.\n{r2eng} has three actions in the workflow folder:\n\nR-CMD-check.yaml (see the YAML file) to run a build check\ntest-coverage.yaml (YAML) to assess how much of the code is protected by testing\npkgdown.yaml (YAML) to build the package’s website with {pkgdown}\n\nThis is a typical, minimal set of actions that suit me when developing R packages. Let’s talk them through.\n\n1. Build check\nAn R CMD check2 runs a bunch of tests on your package (including your own unit tests) and returns errors, notes and warnings. You’re aiming for a passing build to prove the package is up to scratch.\n{usethis} has three actions-related functions specifically for setting up the build check. The standard one will run the R CMD check on macOS, Linux and Windows to make sure it passes across all these platforms.3\nRun this line to add the R-CMD-check.yaml action to the .github/workflows/ folder:\n\nusethis::use_github_action_check_standard()\n\nNote that this function will create .github/workflows/ if it doesn’t already exist.\nFolllowing a push or PR, GitHub Actions will now automatically set up and run a build check on each OS to make sure the package meets the requirements.\n\n\n2. Test coverage\nThe R CMD check runs your unit tests, but it doesn’t calculate how much of your code is actually covered by testing. Ideally you want this to be 100%, but also bear in mind that the metric doesn’t take account of the volume or quality of tests.\nI use another r-lib package, {covr}, to interactively check how much of my code is tested. (In particular, the covr::report() function provides an interactive HTML report showing the total percentage and a line-by-line breakdown of where tests are missing.)\nYou can set up the free services Codecov or Coveralls to make your results public. You’ll need to have signed up for these services and granted their access to the repo you want to report on.\n{usethis} makes it easy to set up these services for your repo: it adds the relevant YAML files, a line to the ‘Suggests’ section of your DESCRIPTION, and a badge to your README.\n\nusethis::use_coverage(\"codecov\")\n\nYou can see an example in action on the Codecov page for {r2eng}, which shows the percentage of coverage, a breakdown of the lines ‘hit’ and ‘missed’, and the commits that led to checks.\nOf course, you can automate this. Run this line to add the test-coverage.yaml action to the .github/workflows/ folder\n\nusethis::use_github_action(\"test-coverage\")\n\nThe ‘test-coverage’ GitHub Action will recheck coverage when you next push to the repo, with the results being updated on your coverage service of choice.\n\n\n3. Build {pkgdown} site\n{pkgdown}, also from r-lib, can automatically and painlessly generate a simple website from your package’s documentation, which you are free to customise. You can serve the site on the web via GitHub Pages so users can access the docs easily online.\nFor example, here’s the {pkgdown} website for the {r2eng} package, which uses default settings at time of writing. You can see that the README has become the home page and there are ‘Reference’ and ‘Changelog’ tabs that autopoulate with the function documentation and NEWS file. Additional tabs are added here depending on the contents of your repo; for example, vignettes are added to an ‘Articles’ tab if they exist.\nThe GitHub Actions with R book has a section on {pkgdown}. In short, the steps are:\n\nSet-up an empty ‘gh-pages’ branch in your repo (the book has some code to do this from the command line)4\nBack in the main branch, run the {usethis} usethis::use_pkgdown() to activate {pkgdown} for your package repo\nRun usethis::use_github_action(\"pkgdown\") to add the YAML file that tells GitHub Actions to build the website on push\nPush to your repo and GitHub Actions will generate the website files in the gh-pages branch\nFrom your repo settings, set GitHub Pages to serve from the root of the gh-pages branch\nWait a few minutes and navigate to your site (in the form ‘username.github.io/reponame’)\n\nGitHub Actions will now rebuild the site automatically every time you make changes and push them."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#tickety-boo",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#tickety-boo",
    "title": "GitHub Actions for R packages",
    "section": "Tickety-boo",
    "text": "Tickety-boo\nYou’ll get the full results of the actions in the ‘Actions’ tab of your repo on GitHub. A successful check gets a satisfying tick next it. A failing test gets a cross. You can select a result and expand the results to trace exactly what the error was.\n\n\n\nSuccessful builds in the ‘pkgdown’ workflow.\n\n\nThis is handy because you and your users can check the results of your checks from the ‘Actions’ tab of you repo without leaving GitHub.\nIt also means you can spot a failing PR and provide more commits to fix it before it gets merged.\n\n\n\nTicks! Ticks! Ticks!\n\n\nYou can also generate Markdown badges5 for your README that display the results of these actions and automatically update when they’re re-run. These are great for an at-a-glance understanding of a package’s development state. {usethis} adds these to your README automatically, but it’s useful to know that you can get these badges from GitHub itself.\n\n\n\nMore easily obtained than having to defeat a Pokémon gym leader.\n\n\nFor example, you can see badges in the {r2eng} README, like this one showing the percentage of test coverage:\n\n\n\n\n\nClicking them takes you to the relevant codecov.io page for the full breakdown of results."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#other-platforms-are-available",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#other-platforms-are-available",
    "title": "GitHub Actions for R packages",
    "section": "Other platforms are available",
    "text": "Other platforms are available\nSo, I think a combo of {usethis} and r-lib’s pre-prepared YAML files is the simplest route to auto-checking your R package and rebuilding its site.\nThere are many other YAML examples from r-lib though, and you can write your own. There’s also an ‘awesome list’ of more general-purpose actions to explore.\nIt’s important to note that there are several other platforms for continuous integration, like Travis CI and Appveyor (see Roger Peng’s book for an overview), but this requires you to setup multiple accounts and configuration files. At time of writing, GitHub Actions has the benefit of testing across all the major operating systems and is easier to set up (learn more in Jim Hester’s talk).\nAnyway, good luck in putting a GitHub Action in action on GitHub."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#environment",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#environment",
    "title": "GitHub Actions for R packages",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:21:21 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#footnotes",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#footnotes",
    "title": "GitHub Actions for R packages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can do other interesting things with it, like run code on schedule. I used GitHub Actions to automate the posting of tweets to a Twitter bot account, @londonmapbot, for example.↩︎\nLearn more about checks from Hadley Wickham and Karl Broman.↩︎\nThe other two functions test on macOS only (use_github_action_check_release()) and on all three operating systems and also on some minor R releases too (use_github_action_check_full()), though the latter is considered ‘overkill’ according to the documentation.↩︎\nFor posterity, and in case the book ever disappears, the code that creates an empty ‘gh-pages’ branch from the command line is like:\ngit checkout --orphan gh-pages\ngit rm -rf .\ngit commit --allow-empty -m 'Initial gh-pages commit'\ngit push origin gh-pages\ngit checkout main\n↩︎\nI showed how to create these sorts of badges in an earlier blog post: ‘Make a README badge with {badgr}’.↩︎"
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html",
    "href": "posts/2018-07-17-world-cup-age-app/index.html",
    "title": "Footballers are younger than you",
    "section": "",
    "text": "I wrote an R Shiny app that tells you how many players at World Cup 2018 were younger than you. It’s designed to make you feel old. You’re welcome."
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#tldr",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#tldr",
    "title": "Footballers are younger than you",
    "section": "",
    "text": "I wrote an R Shiny app that tells you how many players at World Cup 2018 were younger than you. It’s designed to make you feel old. You’re welcome."
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#the-world-cup-final",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#the-world-cup-final",
    "title": "Footballers are younger than you",
    "section": "The World Cup Final",
    "text": "The World Cup Final\nSo the World Cup is over for another year.\nI managed luckily to get tickets for the final, where Karpatlya—a Hungarian diaspora in Ukraine—overcame the powerful Northern Cyprus team on penalties at the Queen Elizabeth Stadium in Enfield, North London.\nAnother successful tournament from the Confederation of Independent Football Associations (CONIFA).\n\n\n\nExtremely rare and valuable tickets for the (CONIFA) World Cup final."
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#it-didnt-come-home",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#it-didnt-come-home",
    "title": "Footballers are younger than you",
    "section": "It didn’t come home",
    "text": "It didn’t come home\nOh and also the far-less popular FIFA World Cup has also finished.\nWonderkid Kylian Mbappé picked up the young player of the tournament as France lifted the trophy for the second time in their history.\nYes, 19-year-old Mbappé is young enough to have been born after France’s last World Cup win in 1998. That makes me feel old.\nIt seems only yesterday that I was dreaming of starting alongside hall-of-famer Bermudan Shaun Goater in the extremely successful Manchester City squad at the turn of the millennium.1 (That reference probably dates me quite well.)\nObviously I can still make it as an elite footballer. Right? What better way to find out than to build an app with R Shiny."
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#the-app",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#the-app",
    "title": "Footballers are younger than you",
    "section": "The app",
    "text": "The app\nYou can clone the GitHub repo and run the app,2 or from an active R session you can run the following to download and run it:\n\nshiny::runGitHub(\"wc18-age\", \"matt-dray\")\n\nThe app depends on the packages {shiny}, {shinythemes} and {DT}. I used the data set in the AllezCannes/WorldCupSquads GitHub repo, which contains player data scraped from Wikipedia by user philstraforelli.\nThe app asks merely for your birth date—selectable from the dropdown menu—and calculates the number and percentage of players younger than you, with an interactive table that lists who they are.\n\nA colleague suggested that wasn’t enough punishment. So I updated it to tell you how many of the players you could be parent to (assuming you had them when you were age 18).\nHere’s some solid reviews I’ve received so far:\n\nVery depressing\n\n\nI knew I was too old to become a great footballer\n\n\nJust what I needed to see\n\nEnjoy! And take inspiration from Kazuyoshi ‘King Kazu’ Miura, a Japanese 51-year-old (born 1967) who is still playing at time of writing. He’s apparently just played a match for Yokohama FC alongside 16-year-old Koki Saito (born 2001), who in theory is young enough to be his grandson!\n\n Note\nI re-rendered this post in 2023 and King Kazu is still playing aged 56! He’s at a Portuguese club with another player called Kazu, who was born in 2000. King Kazu had 14 years and 11 clubs under his belt when young Kazu was born."
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#environment",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#environment",
    "title": "Footballers are younger than you",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 22:36:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2018-07-17-world-cup-age-app/index.html#footnotes",
    "href": "posts/2018-07-17-world-cup-age-app/index.html#footnotes",
    "title": "Footballers are younger than you",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSeason 2000/2001: 18th place and relegation to Division 1. After having climbed from Division 2 to the Prem in the preceding two seasons, lol. Who said being a Man City fan was boring?↩︎\nIt was hosted originally on shinyapps.io, but I took it down to make room for another app.↩︎"
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html",
    "href": "posts/2020-03-12-knit-with-params/index.html",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "",
    "text": "Driving a Wedge (via Giphy)."
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#tldr",
    "href": "posts/2020-03-12-knit-with-params/index.html#tldr",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "tl;dr",
    "text": "tl;dr\nYou want to use R to generate multiple reports from a single template, each containing different data.\nHow? Create a parameterised R Markdown template with a params YAML argument. Iterate over param values with rmarkdown::render() inside purrr::map().\nI made a demo of this approach that focuses on parameterised {xaringan} slides. It includes a further {purrr} step with pagedown::chrome_print() to render the HTML outputs to PDF."
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#parambulate",
    "href": "posts/2020-03-12-knit-with-params/index.html#parambulate",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "Parambulate",
    "text": "Parambulate\nR Markdown lets you integrate code into a document, which is great for automating the production of reproducible reports.\nParameterised R Markdown reports let you control the content of your output by providing a variable to the document at rendering time. You can create multiple reports with different data, but the same template.\nHow does this work? You provide a special params argument to the YAML header of your R Markdown document. Let’s say we have a template that renders a report about Star Wars characters1: starwars-template.Rmd. We might use a name param to declare a character name:\n---\ntitle: Star Wars\nauthor: Matt Dray\ndate: 2020-03-12\nparams:\n  name: \"Obi-Wan Kenobi\"\n---\nNow \"Obi-Wan Kenobi\" will be supplied wherever you reference params$name in the code of your document.\nMaybe you’re filtering the dplyr::starwars data set to get eye color, so filter(starwars, name == params$name) %&gt;% pull(eye_color) will return blue-gray when rendered.\nChange the param to name: Chewbacca and every instance of params$name will take the new value on render. Our call to get eye color will now return blue."
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#automate",
    "href": "posts/2020-03-12-knit-with-params/index.html#automate",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "Automate",
    "text": "Automate\nHow can you automate the process of opening the document and changing the parameter value by hand?\nYou can supply a different value via the params argument of render() from the {rmarkdown} package:\n\nrmarkdown::render(\n  input = \"starwars-template.Rmd\", # the template\n  params = list(names = \"Wedge Antilles\")  # different param\n)\n\nAnd if you have multiple values to supply? You can iterate with the map() function from {purrr} to supply several parameter values in turn, resulting in a separate output for each one.\n\n# Create a vector of the elements to iterate over\ncharacters &lt;- c(\"Chewbacca\", \"Obi-Wan Kenobi\", \"Wedge Antilles\")\n\n# Render to HTML the template for each param\npurrr::map(\n  .x = characters,  # vector of param values\n  .f = ~render(\n    input = \"starwars-template.Rmd\",  # R Markdown filepath\n    params = list(name = .x),  # iterated parameter value\n    output_file = paste0(.x, \".html\")  # iterated output path\n    )\n  )\n)\n\nNote that you can have parameterised reports with more than one param and can provide various combinations to render(). Use map2() or pmap() from {purrr} to iterate with multiple params.\nDon’t forget you can also use the {furrr} package’s future_map() to speed up the process, since it takes advantage of parallel processing."
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#demo-ninja-knitting",
    "href": "posts/2020-03-12-knit-with-params/index.html#demo-ninja-knitting",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "Demo: Ninja Knitting",
    "text": "Demo: Ninja Knitting\nI’ve created a demo on GitHub that extends the ideas above to a {xaringan} slide template to produce ‘micro-dossiers’ on some Star Wars characters. It uses iterative rendering, but also has another iterative step to convert the HTML outputs to PDF format.\nThere are two main files in the demo:\n\nAn R Markdown template (with CSS files2 to tweak the default style)\nAn R script to generate HTML and PDF outputs\n\nThe R script basically does three things:\n\nPrepares the dplyr::starwars data set\nUses purrr::map() with the params argument to render a HTML report per character\nUses pagedown::chrome_print() to render each HTML document to PDF\n\nchrome_print() is a handy function that uses the Chrome browser’s ability to print from HTML to PDF, but without actually opening Chrome3.\nYou can find all the HTML files and PDF files from the GitHub repo.4 Here’s an example that uses the param name: \"Obi-Wan Kenobi\":\n\n\n\n\n\n\n\n\nAnd here’s another, this time with the param set to name: \"Wedge Antilles\":\n\n\n\n\n\n\n\n\nI think it was Yoda who said something like:\n\nR Markdown is the path to automated {xaringan} PDF production. R Markdown leads to parameterised reports. Parameterised reports lead to multiple HTMLs. Multiple HTMLs leads to multiple PDFs.\n\nSo wise."
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#environment",
    "href": "posts/2020-03-12-knit-with-params/index.html#environment",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 16:06:08 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-03-12-knit-with-params/index.html#footnotes",
    "href": "posts/2020-03-12-knit-with-params/index.html#footnotes",
    "title": "Iterate parameterised {xaringan} reports",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBecause Jedi and Sith are basically space samurai ninjas, no?↩︎\nI’ve tried to use Libre Gothic to approximate the Star Wars title crawl font; hopefully this renders correctly for you.↩︎\nYou’ll need Chrome or Chromium installed to use this function.↩︎\nYou can also view each of the HTML files online in the form https://matt-dray.github.io/ninja-knitting/obiwankenobi.html (change ‘obiwankenobi.html’ to ‘chewbacca.html’ for example).↩︎"
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#tldr",
    "href": "posts/2020-11-14-hello-r2eng/index.html#tldr",
    "title": "Translate R to English with {r2eng}",
    "section": "tl;dr",
    "text": "tl;dr\nI created the work-in-progress {r2eng} package (source, site) to help translate R expressions to speakable English. Inspired by Amelia McNamara and with a huge amount of help from Chung-hong Chan."
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#communication-is-hard",
    "href": "posts/2020-11-14-hello-r2eng/index.html#communication-is-hard",
    "title": "Translate R to English with {r2eng}",
    "section": "Communication is hard",
    "text": "Communication is hard\nAmelia McNamara (site, Twitter) gave a talk at the useR! 2020 conference called ‘Speaking R’. Watch the video on YouTube, or take a look at the slides.\nTo summarise greatly: R code should be speakable so that we can teach, learn and communicate with minimal friction.\n‘Speakable’ means I should be able to read an R expression to you as an English sentence (rather than reading out individual characters) and we should be able to understand each other.\nBut this is all easier said than… said.\nIdeally we’d have an agreed dictionary that maps each R token to an equivalent English phrase. But there will always be variation between users and across communities; between beginners and aficionados; and given differences in spoken language.\nThen there’s context. We might agree that the operator %&gt;% is called a ‘pipe’, but you might say the word ‘then’ when reading an expression. So data %&gt;% print() might be spoken as ‘data then print’.\nThe order of parsing may also differ between people. Something as simple as x &lt;- 1 could be ‘x gets 1’, ‘assign the value 1 to the variable named x’, or something else entirely. Now imagine that on the scale of an entire script.\nI don’t think we can completely ‘solve’ any of this, but we could probably develop the conversation with the help of a tool accessible from R itself."
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#hello-r2eng",
    "href": "posts/2020-11-14-hello-r2eng/index.html#hello-r2eng",
    "title": "Translate R to English with {r2eng}",
    "section": "Hello {r2eng}",
    "text": "Hello {r2eng}\nThis is where the {r2eng} package comes in. The goal is to take an R expression and translate it to an equivalent speakable, English sentence, from within R itself.\nThe initial focus has been to:\n\nconcentrate on translating to English (I’m biased)\nmap the most common R operators (e.g. assignment, maths, brackets)\nuse commonly-used (but currently opinionated1) English translations for R operators (‘gets’ for &lt;-)\nwork on a simple one-to-one, left-to-right mapping of R to English\nkeep the API simple, so you just supply an expression and get a result\nsimply begin an approach to address what was raised in Amelia’s presentation\n\nObviously the package is not finished, let alone perfect, and it requires more theoretical and practical considerations to make it truly useful. Clearly I don’t have all the answers and I’m certainly not an arbiter of language, but I think the purpose is defined and it certainly works for simple cases.\nAt worst, I hope the package will encourage discussion. There’s been some interest on Twitter and on the RStudio Community site, but do consider contributing thoughts and ideas to the {r2eng} GitHub repo.\nIn this vein, it’s important to highlight Chung-hong Chan’s valuable contributions to the package. Check out his website and find him on Twitter. Chung-hong was responsible for updating {r2eng} to handle non-standard evaluation in the translate() function and for replacing my original simple R-to-English lookup with a proper parsing method for interpreting R expressions.\n\nInstallation\nYou can install the package from GitHub using the {remotes} package. The package is in development version 0.0.0.9005 at the time of writing and this post discusses functionality for that version. Things may change.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r2eng\")\n\n\n\nHow it works\n\nRecognising tokens\nThe secret sauce of the package is that it recognises the ‘tokens’ that make up an R expression. So the assignment operator, &lt;-, is recognised as a single token rather than the less-than (&lt;) and hyphen (-) characters typed sequentially.\nThis power is brought to {r2eng} thanks to {lintr}, a package by Jim Hester that assesses your code for possible errors and style improvements.\nAn important part of this process is parsing R expressions and recognising tokens using the lintr::get_source_expressions() function. For example, that &lt;- operator is recognised as the special token LEFT_ASSIGN under the hood.\nThis is some deep R magic. You can see a special grammar file file in the R source code that carries these mappings.2\nPut simply, {r2eng} hijacks this process, adds a step that maps each token to English terms, then recombines the text into a sentence.\n\n\nSpeech\nBy default, {r2eng} will translate an R expression and then your computer will speak it out loud.\nThis is relatively straightforward on a Mac: the resulting English text is handed to your machine with a system() call and is vocalised by the built-in VoiceOver text-to-speech converter. This functionality is not built into Windows by default, so the system() call fails silently.\nOf course, this assumes that VoiceOver will do a good job of parsing the English expression from {r2eng}, but that isn’t guaranteed because of issues like localised pronunciation and uncommon words. I’ve written before about how text-to-speech isn’t necessarily that good at recognising R package names, for example.\nIn theory, and assuming that the translation gets good, {r2eng} could be used as a simple accessibility tool because it can interpret R-specific tokens in a way that VoiceOver cannot.\n\n\n\nUsing {r2eng}\nYou can find further examples in the package README, but I’ll explain here the main functionality.\nFirst I’ll attach the package after having installed it.\n\nlibrary(r2eng)\n\n\nThe translate() function\nThere are two main functions in {r2eng}: translate() and translate_string(). They convert from a bare or quoted R expression, respectively, to English.\ntranslate() takes advantage of non-standard evaluation: you pass bare (i.e. unquoted) R code to the expression argument and a few things happen.\n\ntranslate(data &lt;- 1 + 1)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nFirst, it prints both the original R expression and the corresponding English translation. Second, and only if you are using macOS, the English string is passed to a system command that vocalises the string.\nHere’s a more complex example using some {dplyr} functions. Note that we don’t need to attach {dplyr} to be able to translate.\n\ntranslate(\n  data %&gt;% select(x, y) %&gt;% dplyr::filter(y == \"example\"),\n  function_call_end = \"\"\n)\n\nOriginal expression: data %&gt;% select(x, y) %&gt;% dplyr::filter(y == \"example\")\nEnglish expression: data then select open paren x , y close paren then dplyr double-colon filter open paren y double equals string \"example\" close paren\n\n\nNote the function_call_end argument in this example. The default is \"of \", which would would have made the translation data then select of open paren x y close paren, etc. Feedback suggested that this was how some users spoke the English translation out loud, so the functionality has been included for now.\nWhile translate() takes a bare expression, translate_string() takes a string.\n\nlibrary(magrittr)  # attach for pipes\n\"data&lt;-1+1\" %&gt;%\n  translate_string(speak = FALSE)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nWe get the same sort of output as the translate() example, but this time I set the speak argument to FALSE to stop the English text from being ‘spoken’ by my computer and I also eliminated spaces from the input to demonstrate that they’re ignored.\n\n\nr2eng objects\nOf course, you can assign a translation to an object.\n\nmy_translation &lt;- \n  translate(data &lt;- 1 + 1, speak = FALSE)\n\nThe object is a special r2eng S3 class of object, which is also a list.\n\nclass(my_translation)\n\n[1] \"list\"  \"r2eng\"\n\n\nYou can apply some methods to such an object: print(), speak() and evaluate().\nPrint the object to see that custom console output again:\n\nprint(my_translation)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nRe-call the system command that ‘speaks’ the R expression out loud (again, only on macOS).\n\nspeak(my_translation)\n\nAnd you can actually evaluate the R expression you supplied to translate() in the first place. So the expression we supplied, data &lt;- 1 + 1, is evaluated so that calling data gives us the result of 1 + 1.\n\nevaluate(my_translation)\ndata\n\n[1] 2\n\n\n\n\nr2eng-class list elements\nYou can also access the R expression, the English translation and the mapping between them as elements of your r2eng list object.\nHere’s the R expression again:\n\nmy_translation$r_expression\n\n[1] \"data &lt;- 1 + 1\"\n\n\nAnd the translated output:\n\nmy_translation$eng_expression\n\n[1] \" data gets 1 plus 1 \"\n\n\nAnd a data.frame object that contains the mapping.\n\nmap &lt;- my_translation$translation_map\nmap[map$text != \"\", ]  # filter out text spaces\n\n        token text  eng\n1      SYMBOL data data\n2 LEFT_ASSIGN   &lt;- gets\n4   NUM_CONST    1    1\n6         '+'    + plus\n7   NUM_CONST    1    1\n\n\nThis element is a good summary of what {r2eng} is doing under the hood: it breaks the R expression into recognised tokens and maps words to them where it knows what the corresponding English for that token should be. So &lt;- is recognised as the token LEFT_ASSIGN, which is mapped internally to the English text gets.\n\n\n\nBonus material\n\nRStudio Addin\nThe print() and speak() functions can be accessed via an RStudio addin that’s installed with the package (you may need to restart RStudio after installation). To use them, highlight an R expression in your script and select from the RStudio addins menu:\n\n‘Speak R Expression In English’ to vocalise the expression through your computer’s speakers (macOS only)\n‘Print R Expression In English’ to output an English translation to the console\n\nThese can be mapped to keyboard shortcuts so you can highlight and translate quickly without specifically calling translate() and print() or speak().\n\n\nBinder demo\nMaybe you don’t want to install the package. That’s fine. Instead, you can try out the package by opening this Binder instance of RStudio with {r2eng} and the tidyverse pre-installed. Click this badge to launch it:\n\n\n\n\n\nThe downside is that you can’t use the speak method. Make sure to set the argument speak = FALSE in translate() or translate_string(), or you’ll get a warning message when you run your code.\nYou can find the source for this at the try-r2eng GitHub repo and you can read one of my posts on how to set up Binder using Karthik Ram’s {holepunch} package."
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#theres-lots-to-do",
    "href": "posts/2020-11-14-hello-r2eng/index.html#theres-lots-to-do",
    "title": "Translate R to English with {r2eng}",
    "section": "There’s lots to do",
    "text": "There’s lots to do\nAs mentioned, this is really just the beginning.\nThere’s plenty of room for simple improvements, as well as some long term possibilities. For example, we could:\n\nexpand the list of R tokens that can be translated\nallow for context-dependent translation where the same token can be used for more than one application\ndo user-research to find out the most common English terms used\nprovide instructions to make the speak method possible on non-Mac platforms\ninclude full script awareness so that we aren’t limited by left-to-right interpretation\nexpand the package for non-English languages, or create {r2es}, {r2fr}, etc\netc\n\nHopefully we can work on some of these things and this won’t be the last post about {r2eng} on this blog. In the meantime, do consider contributing to the GitHub repo."
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#environment",
    "href": "posts/2020-11-14-hello-r2eng/index.html#environment",
    "title": "Translate R to English with {r2eng}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:28:55 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3   r2eng_0.0.0.9005\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        crayon_1.5.2       cli_3.6.1          knitr_1.43.1      \n [5] rlang_1.1.1        xfun_0.39          rex_1.2.1          processx_3.8.2    \n [9] purrr_1.0.1        xmlparsedata_1.0.5 jsonlite_1.8.7     rprojroot_2.0.3   \n[13] htmltools_0.5.5    ps_1.7.5           rmarkdown_2.23     evaluate_0.21     \n[17] fastmap_1.1.1      lifecycle_1.0.3    yaml_2.3.7         cyclocomp_1.1.0   \n[21] compiler_4.3.1     lintr_3.0.2        htmlwidgets_1.6.2  rstudioapi_0.15.0 \n[25] digest_0.6.33      R6_2.5.1           callr_3.7.3        tools_4.3.1       \n[29] withr_2.5.0        lazyeval_0.2.2     xml2_1.3.5         remotes_2.4.2     \n[33] desc_1.4.2"
  },
  {
    "objectID": "posts/2020-11-14-hello-r2eng/index.html#footnotes",
    "href": "posts/2020-11-14-hello-r2eng/index.html#footnotes",
    "title": "Translate R to English with {r2eng}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA good example of opinionated word choice is this character: (. Is it an ‘open bracket’, ‘open parenthesis’, ‘open paren’, ‘mouth for an emoticon smiley’, or something else entirely? {r2eng} uses ‘open paren’, largely for brevity.↩︎\nI first saw the gram.y file in action in Andrew Craig’s interesting TokyoR talk about extending R to accept function definitions in the form (x) =&gt; x + 1.↩︎"
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#tldr",
    "href": "posts/2022-07-08-rproj-dupes/index.html#tldr",
    "title": "Stop opening the same RStudio Project twice",
    "section": "tl;dr",
    "text": "tl;dr\nI keep opening more than one instance of the same RStudio Project and it’s annoying me, so I wrote a function to warn me on startup."
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#double-trouble",
    "href": "posts/2022-07-08-rproj-dupes/index.html#double-trouble",
    "title": "Stop opening the same RStudio Project twice",
    "section": "Double trouble",
    "text": "Double trouble\nSometimes I write code in an RStudio Project and then go and do something else. My memory is terrible, so later I might open a second instance of the same project and wonder what happened to that code I’d written before.\nIs there a way to stop this from happening? Maybe there’s a setting in RStudio or something? Maybe I should just Google it?\nNah, instead I hacked together a little function that can be run on startup to warn me—via both text and audio—if I have multiple RStudio sessions open with the same name. It’s called check_rproj_dupes().\nNote that the function checks which OS you’re using with .Platform$OS.type, with the hope that one day I (or you) will write some corresponding code that will work on Windows. I don’t use Windows, so I can’t test anything.\nThe code has a few steps:\n\nPass the ps (process status) command with flag -e (show all running processes) to the shell via the system() function, which is captured in a vector when intern = TRUE\nUse grepl() to isolate the strings that contain the ‘.RProj’ RStudio Project extension\nExtract the full paths to the .RProj files\nExtract the basenames from the paths (i.e. just the filename for the .RProj)\nCompare the basenames to see which are duplicated\nDisplay any matches in a warning message and, if speak = TRUE, read aloud a warning message that’s passed to the say function via system()\n\nYeah, this could be simplified, but I’m no code golfer. I just want it to work and for it to be pretty obvious what it’s doing.\nHere it is (or see it in a GitHub Gist, where you can write your suggestions for how to improve it):\n\ncheck_rproj_dupes &lt;- function(speak = FALSE) {\n\n  os &lt;- .Platform$OS.type\n\n  if (os == \"unix\") {\n\n    ps_out &lt;- system(\"ps -e\", intern = TRUE)\n    ps_rproj &lt;- ps_out[grepl(\".Rproj\", ps_out)]\n    ps_split &lt;- strsplit(ps_rproj, \"\\\\s\")\n    rproj_paths &lt;- lapply(ps_split, function(x) x[grepl(\".Rproj$\", x)])\n    rproj_basenames &lt;- lapply(rproj_paths, basename)\n    rproj_dupes &lt;- sort(unlist(rproj_basenames[duplicated(rproj_basenames)]))\n\n  }\n\n  if (os == \"windows\") {\n    stop(\"Sorry, check_rproj_dupes() doesn't work on Windows yet :-(\")\n  }\n\n  if (length(rproj_dupes) &gt; 0) {\n\n    if (speak & os == \"unix\") {\n\n      dupes_string &lt;- paste(rproj_dupes, collapse = \", \")\n      dupes_string_say &lt;- gsub(\"\\\\.Rproj\", \" dot ar proj \", dupes_string)\n\n      message &lt;- paste(\n        \"say ha, you fool, you have more than one open RStudio Project with\",\n        ifelse(length(rproj_dupes) == 1, \"this name:\", \"these names:\"),\n        dupes_string_say\n      )\n\n      system(message)\n\n    }\n\n    warning(\n      \"You've got open RStudio Projects with the same name:\\n\",\n      paste(\"-\", rproj_dupes, collapse = \"\\n\"), \"\\n\",\n      call. = FALSE\n    )\n\n  }\n\n}\n\ncheck_rproj_dupes()\nrm(check_rproj_dupes)\n\nHow would you actually use this though?\nYou can add it to your ‘hidden’ .Rprofile file, which is a place that you can store code that runs whenever RStudio is started.1 Perhaps the easiest way to open it is with usethis::edit_r_profile(). Then you can paste in all the code from the block above.2\nOn startup, the code will run and if there’s no problem, then you’ll see no message. No news is good news.\nBut let’s say I had opened sandbox.Rproj earlier and was now opening the file again. In this second RStudio instance, the usual R startup message will print, followed by a warning:\nWarning message:\nYou've got open RStudio Projects with the same name:\n- sandbox.Rproj \nIf speak = TRUE then you’ll also hear this:\n\n\n\n\n\nSo hopefully now I will be less confused when trying to manage my RStudio sessions. At worst I’ll be shocked to hear the creepy computer voice tell me I’m a fool."
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#environment",
    "href": "posts/2022-07-08-rproj-dupes/index.html#environment",
    "title": "Stop opening the same RStudio Project twice",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-11 23:13:39 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#footnotes",
    "href": "posts/2022-07-08-rproj-dupes/index.html#footnotes",
    "title": "Stop opening the same RStudio Project twice",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI tend not to put anything in here that would hamper reproducibility, i.e. another user shouldn’t have to run anything in my .Rprofile to be able to re-run my scripts on their computer.↩︎\nThe code is in a GitHub Gist too, so in theory you could pass the URL to the raw code to source(). But don’t do that because you shouldn’t trust me or anyone. And also it won’t work if you aren’t connected to the internet.↩︎"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html",
    "href": "posts/2022-06-10-basic-search/index.html",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "",
    "text": "The enemy E chases the player @ who collects gold $ and and an apple a."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#tldr",
    "href": "posts/2022-06-10-basic-search/index.html#tldr",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve experimented with simple breadth-first search for {r.oguelike}, a work-in-progress game-in-a-package for R. This means enemies can pathfind and chase down the player character."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#hunting-the-hunter",
    "href": "posts/2022-06-10-basic-search/index.html#hunting-the-hunter",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Hunting the hunter",
    "text": "Hunting the hunter\nI’ve written before about the inception of {r.oguelike}, a concept for a roguelike game written in R, along with a simple method for creating procedural tile-based cave-like dungeons.\n\nSo far the enemies in the game have been stationary.\nI could let them wander randomly on each turn, which is easy to implement, but boring and unrealistic. Far better would be to introduce some kind of pathfinding via an algorithm, which would make enemies head toward the player character to engage in battle.\nIn this post I’ll start with a naive approach—simply labelling all tiles with distance from the target—then show how an approach called ‘breadth-first search’ can alleviate the problem."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#layers-deep",
    "href": "posts/2022-06-10-basic-search/index.html#layers-deep",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Layers deep",
    "text": "Layers deep\nThere’s a number of ways I could implement pathfinding in R. For purposes of this post, I’m using an approach that I think makes it easier to grasp conceptually.\nEach dungeon will be composed of two related matrices: one matrix is the tile map, which holds the tiles the user sees (i.e. # for walls, . for floor, @ for the player character, E for enemy); the second matrix isn’t seen by the user, but holds travel-distance scores used by the enemy character to find a path to the target.\nI’ll use m throughout as the name of the matrix object holding the tile map and d as the name of the matrix object holding the distance map.\nBear in mind that the characters can only move one tile per turn in a north, south, east or west direction, which has implications for how we label tiles with their distances."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#dont-keep-it-simple-stupid",
    "href": "posts/2022-06-10-basic-search/index.html#dont-keep-it-simple-stupid",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Don’t keep it simple, stupid",
    "text": "Don’t keep it simple, stupid\nConsider this very basic dungeon room that hosts an enemy character E that is seeking the player character @. It’s just an R matrix object, but we can print it nicely so it’s easier to read.\n\n\nClick for R code\n\nManually create a basic, rectangular dungeon room:\n\n# Create room\nn_rows &lt;- 9\nn_cols &lt;- 10\nm &lt;- matrix(rep(\".\", n_rows * n_cols), n_rows, n_cols)\nm[1, ] &lt;- \"#\"  # walls\nm[, 1] &lt;- \"#\"\nm[nrow(m), ] &lt;- \"#\"\nm[, ncol(m)] &lt;- \"#\"\n\n# Add player and enemy\nm[7, 3] &lt;- \"@\"  # player\nm[3, 3] &lt;- \"E\"  # enemy\n\nFor convenience, a function that pretty-prints the matrix to the console:\n\n# Function to print the map nicely\nprint_tiles &lt;- function(x) {\n  for (i in seq(nrow(x))) {\n    cat(x[i, ], \"\\n\")\n  }\n}\n\n\nprint_tiles(m)\n\n\n\nprint_tiles(m)\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# . . . . . . . . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\nWhat’s the simplest way that the enemy can find a path to the player?\nProbably it’s to label every traversable tile with a Manhattan-distance (i.e. like a taxicab would move on the gridded streets of New York) away from the player’s position. Then the enemy can check its neighbouring tiles on each turn and select the next highest distance score until it reaches the player.\nSo, below I’ve created a distance map by assigning the player position a score of 100, then I’ve decreased the score by 1 with each additional tile away from the player (remembering that characters can only move north, south, east or west). Walls score zero, so they’re effectively ignored.\n\n\nClick for R code\n\n\nget_distance &lt;- function(m, peak_score) {\n\n  # Initiate distance matrix filled with zero\n  n_rows &lt;- nrow(m)\n  n_cols &lt;- ncol(m)\n  d &lt;- matrix(rep(0, n_cols * n_rows), n_rows, n_cols)\n\n  # Player location gets peak_score\n  player_loc &lt;- which(m == \"@\", arr.ind = TRUE)\n  m[player_loc[1], player_loc[2]] &lt;- peak_score\n\n  # Surrounding tiles get successively smaller distance scores\n  for (col_ind in seq(n_cols)) {\n    for (row_ind in seq(n_rows)) {\n      distance &lt;- abs(player_loc[1] - row_ind) + abs(player_loc[2] - col_ind)\n      value &lt;- peak_score - distance\n      if (value &lt; 0) value &lt;- 0\n      d[row_ind, col_ind] &lt;- value\n    }\n  }\n\n  # Walls aren't traversable, assign low value\n  walls &lt;- which(m == \"#\")\n  d[walls] &lt;- 0\n\n  d\n\n}\n\n\nget_distance(m, 100)\n\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    0    0    0    0    0    0    0    0     0\n [2,]    0   94   95   94   93   92   91   90   89     0\n [3,]    0   95   96   95   94   93   92   91   90     0\n [4,]    0   96   97   96   95   94   93   92   91     0\n [5,]    0   97   98   97   96   95   94   93   92     0\n [6,]    0   98   99   98   97   96   95   94   93     0\n [7,]    0   99  100   99   98   97   96   95   94     0\n [8,]    0   98   99   98   97   96   95   94   93     0\n [9,]    0    0    0    0    0    0    0    0    0     0\n\n\nSee how the player-position at [7,3] is 100 and the values then drop by 1 in all directions?\nSo the enemy would move south from its start position at [3,3] to the target position at [7,3], moving along a score gradient of 96 to 100.\nThere’s an issue with this though: obstacles. What do you think will happen if we put a dividing wall between the characters? Here’s the same room with a wall splitting the characters, plus the distance matrix using the same approach as above.\n\n\nClick for R code\n\n\nm[5, 2:8] &lt;- \"#\"\n\n\nprint_tiles(m)\n\n\n\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# # # # # # # # . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\n\n\nClick for R code\n\n\nd &lt;- get_distance(m, 100)\n\nd\n\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    0    0    0    0    0    0    0    0     0\n [2,]    0   94   95   94   93   92   91   90   89     0\n [3,]    0   95   96   95   94   93   92   91   90     0\n [4,]    0   96   97   96   95   94   93   92   91     0\n [5,]    0    0    0    0    0    0    0    0   92     0\n [6,]    0   98   99   98   97   96   95   94   93     0\n [7,]    0   99  100   99   98   97   96   95   94     0\n [8,]    0   98   99   98   97   96   95   94   93     0\n [9,]    0    0    0    0    0    0    0    0    0     0\n\n\nSo, as before, the enemy begins on a distance score of 96 at [3,3] and will move south to 97 on [4,3].\nNow what? The wall has been scored as zero, so the enemy looks around for the largest distance score of its remaining neighbours. They all score 96, so the enemy character just selects randomly one of west, north or east.\nUhoh: this means the enemy will be stuck in an infinite loop between the adjacent scores of 96 and 97. This isn’t very intelligent.\nHow can we account for blockages like this?"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#here-comes-the-flood-fill",
    "href": "posts/2022-06-10-basic-search/index.html#here-comes-the-flood-fill",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Here comes the flood-fill",
    "text": "Here comes the flood-fill\nPerhaps a better approach is to ‘flood fill’ the distance scores. Imagine the start point is a source of water and it’s filling up the dungeon. Obviously the water will have to flow around walls and the hardest-to-reach areas will be filled last.\nA basic flood-fill approach we can implement is ‘breadth-first’, which visits tiles in a ‘frontier’ expanding from the start point. Distance scores are assigned once to frontier tiles and neighbours are consecutively added to a ‘queue’ to be checked.\nThis is slightly expensive because every traversable tile has to be assessed, but it means that multiple enemies can all use the same distance map to navigate.1\nWe don’t need to get too complicated for {r.oguelike}; it just has to work. I’ll illustrate the breadth-first approach with a pretty basic and verbose implementation.2\n\nDeep breadth-first\nNow to implement it in R. Reminder: we’ll use two matrices to represent the tile grid (seen by player) and the distance grid (just holds the distance scores).\nI’m going to use three main functions:\n\ninitiate_distance_map(), which creates a distance-map matrix of equal size to the tile map and fills all traversable spaces with zero and all non-traversable spaces with Infinity (which the character will want to avoid)\npopulate_distance_map, which flood-fills the traversable space by expanding a frontier from the start point, assigning a distance score to each neighbour that’s +1 of the score of the parent tile and adding those neighbours to the frontier queue so they can be inspected next\nmove_enemy() to move the enemy character one tile per turn towards the tile with the lowest distance score (i.e. the tile that holds the player @)\n\n\nCreate the distance-score matrix\nUsing the same obstacle map from earlier in the post, we can first initiate a complementary distance-score matrix:\n\ninitiate_distance_map &lt;- function(m) {\n\n  d &lt;- m  # copy the tile map\n  d[which(d != \"#\")] &lt;- 0  # set non-wall tiles to 0\n  d[which(d == \"#\")] &lt;- Inf  # set wall tiles to infinity\n  matrix(as.numeric(d), nrow(d), ncol(d))  # recast as numeric\n\n}\n\nNow we can adjust those distance scores. The algorithm is basically:\n\nCreate a frontier vector of tile indices (i.e. the edges of the flood-fill as it moves outward) and add the starting tile (i.e. the tile index that holds the player character)\nCreate a vector to hold tile indices that we’ve already visited\nBegin a loop where:\n\nthe first tile in the frontier queue becomes the ‘current’ tile\nthe current tile is removed to the frontier\nthe current tile is added to the visited list\nthe tile indices of the current tile’s neighbours (north, south, east and west) are identified\nif not yet visited, the neighbours are assigned distance scores that are +1 of the current tile\n\nContinue the loop until you run out of tiles in the frontier queue\n\nI’ve written a small sub-function to handle neighbour-finding:\n\nget_neighbours &lt;- function(m, current) {\n\n  n_rows &lt;- nrow(m)\n\n  c(\n    if (m[current - n_rows] != \"#\") current - n_rows,\n    if (m[current - 1] != \"#\") current - 1,\n    if (m[current + 1] != \"#\") current + 1,\n    if (m[current + n_rows] != \"#\") current + n_rows\n  )\n\n}\n\nWhich plugs into the main function for implementing the algorithm that assigns distance scores:\n\npopulate_distance_map &lt;- function(m, d) {\n\n  start &lt;- which(m == \"@\")  # start tile, i.e. player tile\n  \n  # Initiate vectors\n  frontier &lt;- start  # to be assessed\n  visited &lt;- c()  # have been assessed\n\n  while (length(frontier) &gt; 0) {\n\n    current  &lt;- frontier[1]  # set first tile of frontier as current\n    frontier &lt;- frontier[!frontier == current]  # remove current tile from frontier\n    visited  &lt;- append(visited, current)  # mark current as visited\n\n    neighbours &lt;- get_neighbours(m, current)  # get vector of neighbour indices\n    neighbours &lt;- neighbours[!neighbours %in% visited]\n\n    for (neighbour in neighbours) {\n      if (!neighbour %in% visited) {  # only assign distance to unvisited neighbours\n        d[neighbour] &lt;- d[current] + 1  # assign distance, one more than parent\n      }\n    }\n\n    frontier &lt;- append(frontier, neighbours)  # add neighbour to the frontier\n\n  }\n\n  d\n\n}\n\n\n\nMove to target\nFinally, here’s the function that lets the enemy check its neighbours for the lowest distance score and move one tile in that direction:\n\nmove_enemy &lt;- function(m, d) {\n\n  # Find tiles of interest\n  en_loc &lt;- which(m == \"E\")\n  player_loc &lt;- which(m == \"@\")\n  n_rows &lt;- nrow(m)\n\n  # Get neighbour tile indices\n  ind &lt;- c(\n    n = en_loc - 1,\n    s = en_loc + 1,\n    e = en_loc + n_rows,\n    w = en_loc - n_rows\n  )\n\n  # Get tile content for neighbours\n  tiles &lt;- c(\n    n = m[ind[\"n\"]],\n    s = m[ind[\"s\"]],\n    e = m[ind[\"e\"]],\n    w = m[ind[\"w\"]]\n  )\n\n  # Get the distance score for a tile if traversable/target\n  dist &lt;- c(\n    n = if (tiles[\"n\"] %in% c(\".\", \"@\")) d[ind[\"n\"]],\n    s = if (tiles[\"s\"] %in% c(\".\", \"@\")) d[ind[\"s\"]],\n    e = if (tiles[\"e\"] %in% c(\".\", \"@\")) d[ind[\"e\"]],\n    w = if (tiles[\"w\"] %in% c(\".\", \"@\")) d[ind[\"w\"]]\n  )\n\n  # Sample a direction if there's ties, move there\n  direction &lt;- sample(names(dist[dist == min(dist)]), 1)\n  en_loc_new &lt;- ind[names(ind) == direction]\n  m[en_loc] &lt;- \".\"  # replace old location with floor tile\n  m[en_loc_new] &lt;- \"E\"  # place enemy in new location\n\n  m\n\n}\n\n\n\nPut it all together\nNow to apply the functions to our dungeon room, with its minor obstacle. Here’s a reminder of the layout:\n\nprint_tiles(m)\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# # # # # # # # . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\nNow we can initiate the distance-score matrix:\n\nd &lt;- initiate_distance_map(m)\nd\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n [2,]  Inf    0    0    0    0    0    0    0    0   Inf\n [3,]  Inf    0    0    0    0    0    0    0    0   Inf\n [4,]  Inf    0    0    0    0    0    0    0    0   Inf\n [5,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf    0   Inf\n [6,]  Inf    0    0    0    0    0    0    0    0   Inf\n [7,]  Inf    0    0    0    0    0    0    0    0   Inf\n [8,]  Inf    0    0    0    0    0    0    0    0   Inf\n [9,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n\n\nThen populate the distance scores from the target:\n\nd &lt;- populate_distance_map(m, d)\nd\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n [2,]  Inf   18   17   16   15   14   13   12   11   Inf\n [3,]  Inf   17   16   15   14   13   12   11   10   Inf\n [4,]  Inf   16   15   14   13   12   11   10    9   Inf\n [5,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf    8   Inf\n [6,]  Inf    2    1    2    3    4    5    6    7   Inf\n [7,]  Inf    1    0    1    2    3    4    5    6   Inf\n [8,]  Inf    2    1    2    3    4    5    6    7   Inf\n [9,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n\n\nSuccess. You can see the start tile at [7,3] scores zero and emanates out to the right, around the obstacle, before wrapping back to the top-left and toward the enemy at position [3,3].\nThe enemy needs only to move to the neighbouring tile with the lowest distance score. So from 16 to 15 on either [4,3] or [3,4], then to 14, to 13, etc.\nSee how this time the character won’t get stuck trying to move south? The distance scores decrease from left to right before curving round the wall in the direction of the player’s tile.\nFor fun, we can print to the console an animation of the movement, which I’ve captured in gif form.\n\n\nClick for R code\n\n\nrepeat {\n  cat(\"\\014\")  # clear console\n  m &lt;- move_enemy(m, d)  # move enemy\n  print_tiles(m)  # print to console\n  Sys.sleep(0.5)  # wait\n  if (!any(m == \"@\")) break  # stop if player captured\n}\n\n\n\nYou can see the enemy go round the wall and reach the player using a pretty efficient path.\nAnd in a more dungeonlike room:"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#the-end-of-the-tunnel",
    "href": "posts/2022-06-10-basic-search/index.html#the-end-of-the-tunnel",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "The end of the tunnel?",
    "text": "The end of the tunnel?\nI’ve smashed this together quickly with some completely un-optimised code. Once I’ve ironed out some kinks, it’ll go into the {r.oguelike} package proper.\nOf course, I’ll need to consider:\n\na moving player-character, so the distances map will need to be updated every turn\nlimiting the range of the frontier to some specified distance away from the player, so that an enemy will only begin pathfinding when a player is closer and more ‘detectable’3\na ‘vision-cone’ so the enemy only ‘sees’ the player if there’s a clear set of floor tiles between them\nallowing different enemy classes to move differently, e.g. attack immediately, randomly, or when the player is within a certain distance\n\nAs a basic preview, here’s what it looks like when you throw the pathfinding into a procedurally-generated dungeon from {r.oguelike}:\n\nThis gives a nice impression of the panic that might set in if you’re down to 1 HP and a monster is chasing you into a dead-end.\nPanic: a quintessential roguelike ‘feature’!"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#environment",
    "href": "posts/2022-06-10-basic-search/index.html#environment",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:57:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#footnotes",
    "href": "posts/2022-06-10-basic-search/index.html#footnotes",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, there are cleverer ways to do this. More advanced techniques include Dijkstra, which allows for weighted edges (e.g. a ‘cost’ for travelling over terrain types), and A-star, which uses a heuristic to improve the efficiency of finding the shortest path between two points. Learn more in sensational introductions and implementations on Red Blob Games by Amit Patel.↩︎\nPerhaps unsurprisingly, there’s not much on the web about implementing these algorithms in R for purposes of tile-based game development, specifically. There are implementations of theses algorithms, however, like Michael Chow’s A-star on GitHub, which could be adapted.↩︎\nThis behaviour probably makes more in-game sense. Unless you imagine the enemy has really great senses of smell or hearing and can detect the player wherever they are. Or your player character has just rolled low dexterity and is clumsy and loud.↩︎"
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#tldr",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#tldr",
    "title": "londonmapbot at LondonR",
    "section": "tl;dr",
    "text": "tl;dr\nI spoke at a LondonR hootenanny1 (in-person!) about how to create your own simple Twitter bot powered by GitHub Actions and {rtweet}, just like my @londonmapbot creation.\n\n Note\nThe bot no longer runs on Twitter. You can read about how I ported it to Mastodon at @londonmapbot@botsin.space."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#the-mapbotverse",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#the-mapbotverse",
    "title": "londonmapbot at LondonR",
    "section": "The mapbotverse",
    "text": "The mapbotverse\nI created a Twitter bot called @londonmapbot. It uses the {rtweet} package by Mike Kearney to tweet out a random satellite image of Greater London via Mapbox, scheduled and executed by GitHub Actions.\nI’ve written about this before:\n\nA Twitter bot with {rtweet} and GitHub Actions (original post)\nMapping londonmapbot tweets with {leaflet}\nWhat colour is London?\n\nI’ve noticed a number of other projects have used or developed the londonmapbot code, or else are inspired by it. I’ve created a Twitter List containing the ones I know about, which—in earnest—I’ve called ‘the mapbotverse’.\nIt includes bots that tweet maps more cleverly, or do something else, like:\n\nRoberto Jiménez’s @esmapbot, which tweets images of Spain sampled from within a geojson of the country’s borders\nMatt Kerlogue’s @narrowbotR, which tweets canal and river locations with geographically-coincident Flickr images, which have been rated for photo quality (!)\nOscar Baruffa’s @BigBookofR, which tweets out a random section of the excellent Big Book of R resource\n\nI talked at LondonR about how you can be at least as cool as these folks.\nYes, you too can fork the source for londonmapbot on GitHub, or click the green ‘use this template’ button in the repo to begin your own mapbot. Or you can can create something from scratch. Let me know what you get up to."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#slides",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#slides",
    "title": "londonmapbot at LondonR",
    "section": "Slides",
    "text": "Slides\nObviously I created some slides for the event. Consider them a more up-to-date (and simpler) version of my original blogpost.\nBelow is the presentation embedded2, but you can also visit the slides online, or go to the source on GitHub.\n\n Note\n{rtweet} version 1.0 was released with breaking changes in July 2022 and so I’ve tweaked the slides to reflect this. You can read a separate blogpost about these changes.\n\n\n\n\n\n\n\n\n\nWith the slides selected, press the left and right keys to navigate, F to go fullscreen and P to see the presenter notes."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#bonus",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#bonus",
    "title": "londonmapbot at LondonR",
    "section": "Bonus",
    "text": "Bonus\nJust after the talk, I found out I could mark the bot as ‘automated’ from Twitter settings at: More &gt; Settings and Privacy &gt; Your account &gt; Account information &gt; Automation. I just had to log in as the ‘managing account’ (i.e. my personal account) to connect the two profiles. This is now required as per terms of service, I believe.\n\nSo now the profile has a little robot icon and the phrase ‘automated by @mattdray’."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#inevitable-bot-uprising",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#inevitable-bot-uprising",
    "title": "londonmapbot at LondonR",
    "section": "Inevitable bot uprising",
    "text": "Inevitable bot uprising\nIt’s another maybe two-or-so years until all of Twitter (Earth?) is just a bot singularity, so I suggest you get in early. I reckon a mapbot is a pretty cheap way to get in on the hype."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#environment",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#environment",
    "title": "londonmapbot at LondonR",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:16:49 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] fontawesome_0.5.1   evaluate_0.21"
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#footnotes",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#footnotes",
    "title": "londonmapbot at LondonR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPast tense, unless you are reading this before 2022-02-17, in which case you are very keen. Well done, 10 points to Hufflepuff!f↩︎\nHi again to folks reading this before the event has happened. The slides are basically finished, but I may tweak them before the actual event. In which case what you see here may change slightly before the big day. Another 10 points to Hufflepuff!↩︎"
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#tldr",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#tldr",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a cunning solution to fix an issue in the {quartostamp} R package. Spoiler: it was completely unnecessary. A lesson!"
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#put-it-on-my-tab",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#put-it-on-my-tab",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "Put it on my tab",
    "text": "Put it on my tab\n{quartostamp} is an R package that contains an RStudio Addin to help insert and modify code in Quarto documents. I originally made it to help me write Quarto presentations: I kept forgetting the correct syntax for things like inserting speaker notes and column layouts.1\nZoë made a great, subtle point in a GitHub issue: the ‘Insert Tabset’ option uses level-3 Markdown headers (###) for its tab titles, but shouldn’t they be level 2 (##)?\nTo illustrate, here’s what {quartostamp} was inserting for a tabset:\n::: {.panel-tabset}\n\n### Tab A\n\nContent for Tab A\n\n### Tab B\n\nContent for Tab B\n\n:::\nWhich would render like this:\n\nTab ATab B\n\n\nContent for Tab A\n\n\nContent for Tab B\n\n\n\nSo ### Tab A in the YAML should be ## Tab A, for example.\nI think I’d used level 3 headers because second-level headers demarcate new slides in a Quarto presentation and the specific guidance for presentations appears to suggest ###.\nSo, obviously, an instance of ## in a tabset header could break someone’s slides and I should come up with some convoluted solution, right? What could go wrong? (This is a literary technique called ‘foreshadowing’, dear reader.)"
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#a-stab-at-the-tabs",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#a-stab-at-the-tabs",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "A stab at the tabs",
    "text": "A stab at the tabs\nSo, what to do? It seemed as though there were three options:\n\nHave two versions of the tabset function that insert ## or ###.\nSwitch to ## only .\nRetain only ###.\n\nEach is a relatively easy change. But number 1 is a non-starter because it’s confusing from a user’s perspective. Number 2 would disrupt people making presentations; they’d have to manually add the extra # each time. Number 3 is probably the least worst, but might be surprising for general Quarto users.\nSo, a bonus idea:\n\nAdapt the heading level automatically, based on the document format.\n\nThat sounds complicated. Is it?"
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#a-dash-to-hash",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#a-dash-to-hash",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "A dash to hash",
    "text": "A dash to hash\nQuarto docs start with a text-based ‘YAML header’. This contains a bunch of key-value metadata like the document title, author, etc, between ‘fences’ given by triple hyphens (---). At simplest:\n---\nformat: revealjs\n---\nOr more likely, something nested like this:\n---\ntitle: Chocolate Hobnobs\nsubtitle: The best biscuits\nauthor: Matt Dray\nformat:\n  revealjs: \n    theme: [default, biscuits.scss]\n    menu: false\ntitle-slide-attributes:\n  data-background-image: hobnob.png\n---\nSo we have to somehow read the YAML header of the Quarto file we’re working on and then extract the format information to see if it’s a presentation or not.\nSo I ended up doing this:\n\nDetect information about the active Quarto document in the RStudio script pane with rstudioapi::getActiveDocumentContext().\nIsolate the text content.\nDetect the lower limit of the document’s YAML header (i.e. the second, closing instance of the --- YAML fence).\nUse yaml::yaml.load() to parse the YAML header.\nDetect if a format key-value pair is present\nDetect if at least one listed format is revealjs (the Javascript library Quarto uses to make presentations).\nIf yes, construct a level 3 header (###), otherwise level 2 (##).\nInsert the tabset code into the Quarto file."
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#hash-in-the-trash",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#hash-in-the-trash",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "Hash in the trash",
    "text": "Hash in the trash\nExcept guess what? The presence of ## inside tabset code actually doesn’t create a new slide. I should’ve tested this before I started writing a solution. I think Quarto checks context: if Markdown is provided within ::: fences then it’s evaluated in that context. That makes sense!\n\n\nClick for a Quarto reprex\n\nPop this in a qmd file and hit ‘render’.\n---\ntitle: \"Testing tabset titles\"\nformat: revealjs\n---\n\n## Using level 3\n\n::: {.panel-tabset}\n\n### Tab A\n\nContent for Tab A\n\n### Tab B\n\nContent for Tab B\n\n:::\n\n## Using level 2\n\n::: {.panel-tabset}\n\n## Tab A\n\nContent for Tab A\n\n## Tab B\n\nContent for Tab B\n\n:::\n\n\nOn the plus side, I had fun solving the ‘problem’ and thinking creatively to extract and parse the YAML and write logic to handle each case. I don’t claim it’s optimised, but I’ve added it below for posterity.\nFirst, a function that uses {rstudioapi} to read the active Quarto doc in the RStudio source pane and outputs TRUE if it’s a revealjs presentation.\n\n.check_revealjs &lt;- function() {\n\n  # Fetch lines from the source\n  active_doc &lt;- rstudioapi::getActiveDocumentContext()\n  contents &lt;- active_doc[[\"contents\"]]\n\n  # Identify the lines that compose the YAML header\n  yaml_end_index &lt;- which(contents == \"---\")[2]\n  yaml_only &lt;- contents[seq(yaml_end_index)]\n\n  # Parse the YAML header, detect 'format' key\n  yaml_parsed &lt;- yaml::yaml.load(yaml_only)\n  has_format &lt;- \"format\" %in% names(yaml_parsed)\n\n  # Detect if the format is revealjs\n  \n  is_revealjs &lt;- FALSE  # default\n\n  if (has_format) {\n\n    formats &lt;- yaml_parsed[[\"format\"]]\n\n    # Format structure could differ, depends on YAML nesting\n    formats_is_vec &lt;- inherits(formats, \"character\")\n    formats_is_list &lt;- inherits(formats, \"list\")\n\n    if (formats_is_vec) {\n      is_revealjs &lt;- \"revealjs\" %in% formats\n    }\n\n    if (formats_is_list) {\n      is_revealjs &lt;- \"revealjs\" %in% names(formats)\n    }\n\n  }\n\n  return(is_revealjs)\n\n}\n\nThe output from .check_revealjs() could then be used in a modified stamp_tabset() (the function that powers the ‘Insert Tabset’ option from the Addins menu) where TRUE inserts a level 3 header, otherwise a level 2 header.\n\nstamp_tabset &lt;- function() {\n\n  is_revealjs &lt;- .check_revealjs()\n\n  # Set headers to level 2 by default\n  heading_level &lt;- 2\n\n  # Set as level 3 if the active doc is a revealjs presentation\n  if (is_revealjs) {\n    heading_level &lt;- 3\n  }\n\n  # Generate tabset header Markdown depending on doc format\n  tabset_heading_md &lt;- paste(rep(\"#\", heading_level), collapse = \"\")\n\n  # Insert tabset code with appropriate heading level\n  .replace_text(\n    pre = paste0(\n      \"::: {.panel-tabset}\\n\",\n      \"\\n\",\n      paste(tabset_heading_md, \"Tab A\\n\"),\n      \"\\n\"\n    ),\n    body = \"Content for Tab A\\n\",\n    post = paste0(\n      \"\\n\",\n      paste(tabset_heading_md, \"Tab B\\n\"),\n      \"\\n\",\n      \"Content for Tab B\\n\",\n      \"\\n\",\n      \":::\\n\"\n    )\n  )\n}\n\nYou can see the actual current state of the code in the matt-dray/quartostamp GitHub repo, which also has the source for the .replace_text() function show in the code block above."
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#hash-and-burn",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#hash-and-burn",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "Hash and burn",
    "text": "Hash and burn\nWhich leads us to a bonus bonus idea:\n\nMerge Zoë’s pull request that simply changes ### to ##.\n\nAnd so {quartostamp} version 0.1.1 is now available!\nI look forward to further developments. But less so for ‘antidevelopments’ like these, lol."
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#environment",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#environment",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-09-04 12:03:31 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-09-01-quarto-yaml-detect/index.html#footnotes",
    "href": "posts/2023-09-01-quarto-yaml-detect/index.html#footnotes",
    "title": "Autodetect Quarto formats with {quartostamp}. Or not.",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe package got some great feature requests: Indrajeet asked for callout boxes and Zoë suggested that the package could modify existing text as well as insert skeleton code.↩︎"
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html",
    "href": "posts/2021-05-22-mission-across-iow/index.html",
    "title": "Mission Across the Isle of Wight",
    "section": "",
    "text": "Isle of Wight, coloured off-white."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#tldr",
    "href": "posts/2021-05-22-mission-across-iow/index.html#tldr",
    "title": "Mission Across the Isle of Wight",
    "section": "tl;dr",
    "text": "tl;dr\nI used R to identify and map hazards on a potential straight-line walking route across the Isle of Wight, mimicking Tom ‘GeoWizard’ Davies’s ‘Mission Across’ series of YouTube videos. You can jump straight to the interactive map."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#geowizard",
    "href": "posts/2021-05-22-mission-across-iow/index.html#geowizard",
    "title": "Mission Across the Isle of Wight",
    "section": "GeoWizard",
    "text": "GeoWizard\nTom ‘GeoWizard’ Davies is perhaps best known for his YouTube channel, where he posts Twitch stream highlights of Geoguessr, a game where you pinpoint a randomised location based only Google StreetView.\nHe also chronicles real-life trekking adventures, usually with a twist. Particularly captivating are the ‘Mission Across’ videos, where Tom attempts to cross a country in a straight line on foot. That includes having to clamber over hedges, swim across ponds, get stuck in bogs and risk the wrath of local farmers and landowners. So far this has covered Wales, Wales again and Norway, with a Scotland series due this month.\nOf course, this requires a lot of planning to decide what the best route is and to make sure you don’t traipse directly through someone’s living room in your muddy boots. Typically this might involve lots of time in GIS software and various online mapping services.\nI learnt recently of the {osmextract} package for the R language, which fetches geographic features from OpenStreetMap, and wondered how easy it would be to use R to do a light-touch assessment of straight line routes in a ‘Mission Across’ style. Basically, can we work out the number and type of obstructions we’d face on a given route?\nYou can jump straight to an interactive map with my example for the Isle of Wight, or keep reading for the code and an explanation.\nAs an aside, Tom has also made the album ‘16 Bit Adventure’ under the moniker ‘Amynedd’; music which accompanies the ‘Mission Across’ videos. Press play here for inspiration as you read on."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#code-walkthrough",
    "href": "posts/2021-05-22-mission-across-iow/index.html#code-walkthrough",
    "title": "Mission Across the Isle of Wight",
    "section": "Code walkthrough",
    "text": "Code walkthrough\n\nPackages\nR is very capable as a code-led tool for geospatial manipulation and mapping. Along with {tidyverse} for data wrangling, there’s a few geospatial packages we need: {geojsonio} lets us read GeoJSON files, {sf} is for handling ‘special features’ geometry in a ‘tidy’ way, and {leaflet} lets us create interactive maps. {osmextract} was the main motivation for this post; it fetches OpenStreetMap features pretty painlessly.\n\nsuppressPackageStartupMessages({\n  library(geojsonio)\n  library(leaflet)\n  library(leaflet.extras)\n  library(osmextract)\n  library(sf)\n  library(tidyverse)\n})\n\nAll these packages can all be downloaded from CRAN with install.packages().\nWhile we’re here, I’m going to turn off ‘spherical geometry’. This is a fancy way of saying that we’re going to pretend the Earth is flat (!) to avoid some awkward geospatial maths. I don’t think that’s going to be a big deal for the scale of this demo.\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\n\n\n\nThe boundary\nFor purposes of this post, I wanted to look at a small, contained, ‘regularly-shaped’ geographic area to keep things simple. It didn’t have to be a country.\nI settled on the Isle of Wight (IOW)1, a small island off the south-coast of England. It’s mostly rural, with farms, hedges and waterways to cross, but there are certainly more built-up areas. It also helps that the IOW is featured in the {osmextract} documentation!\n\n\n\nThe Isle of Wight: a vexillologist’s delight.\n\n\nFirst thing is to fetch a polygon that represents the extent of the island. Fortunately, Local Authority District (LAD) boundaries for the UK are available to download from the Official for National Statistics (ONS) in GeoJSON form2. We can download the file and filter for the IOW, specifically.\n\n# Download geojson\ngeojson_url &lt;- \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/LAD_DEC_2020_UK_BGC/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\ntmp &lt;- tempdir()\ngeojson_path &lt;- file.path(tmp, \"lads.geojson\")\ndownload.file(geojson_url, geojson_path)\n\n# Read LAD boundaries, filter to IOW\niow_extent &lt;- geojson_read(geojson_path, what = \"sp\") %&gt;% \n  st_as_sf(crs = 4326) %&gt;%\n  filter(LAD20NM == \"Isle of Wight\")\n\nunlink(tmp)\n\nI’ve used boundaries that are ‘clipped to the coastline’ because I don’t think you should have to swim out to the low-water mark to complete such a challenge.\n\n\nOpenStreetMap features\nWe want to identify features like hedgerows, buildings and waterways that will become obstructions for our imaginary walk across the island. The oe_get() function from {osmextra} is an easy way to pull features from OpenStreetMap en masse. You can supply a location and receive features within that area.\nFirst, the polygonal features, which you can get with argument layer = \"multipolygons\". You can see that a geometry column is returned, which contains the coordinates for the polygons.\n\n# Fetch polygonal features for IoW\nosm_polys &lt;- oe_get(\n  \"Isle of Wight\", # geographic area of interest\n  layer = \"multipolygons\",  # fetch polygons\n  stringsAsFactors = FALSE,  # return character-class\n  quiet = TRUE  # don't print info\n) %&gt;%\n  st_transform(crs = 4326)  # latlong coord reference system\n\n# Limited preview\nglimpse(select(osm_polys, osm_id, name, type, geometry))\n\nRows: 84,599\nColumns: 4\n$ osm_id   &lt;chr&gt; \"4763\", \"5922\", \"6022\", \"7141\", \"7316\", \"29744\", \"70978\", \"71…\n$ name     &lt;chr&gt; NA, NA, NA, NA, NA, \"Ryde Canoe Lake\", \"Quarr Abbey\", NA, \"Be…\n$ type     &lt;chr&gt; \"multipolygon\", \"multipolygon\", \"multipolygon\", \"multipolygon…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((-1.251425 5..., MULTIPOLYGON (((…\n\n\nOf course, we can grab line features too. The default for layer is lines, so we don’t need to supply this argument.\n\n# Fetch line features for IoW\nosm_lines &lt;-  oe_get(\n  \"Isle of Wight\", \n  stringsAsFactors = FALSE,\n  quiet = TRUE\n) %&gt;%\n  st_transform(crs = 4326)\n\nFor convenience, I’m simplifying the features down to the ones we care about. For Tom, hedgerows were a constant nuisance, waterways were cold and perilous, and buildings could contain angry landowners. We want to avoid them all, ideally.\nWe can create a function to extract named features (we want rows containing ‘barriers’, ‘buildings’, ‘natural’ and ‘waterway’ features), and then iterate over our lines and polygons to isolate them. I’ve put them into a single object so it’s easier to reference them later.\n\n# Filter for a single feature type from oe_get() output\n# 'sf_in' is output from oe_get(); 'feature' is the feature we want\nisolate_feature &lt;- function(sf_in, feature) {\n  sf_in %&gt;% \n    filter(!is.na(sf_in[[feature]])) %&gt;%  # filter for feature\n    select(osm_id, type = all_of(feature), geometry)  # simplify object\n}\n\n# Get all the features as a list object with one element per feature\nfeatures &lt;- map2(\n  list(osm_lines, osm_polys, osm_polys, osm_lines),\n  list(\"barrier\", \"building\", \"natural\", \"waterway\"),\n  isolate_feature\n) %&gt;% \n  set_names(\"barrs\", \"bldgs\", \"natur\", \"wways\")\n\n# Limited preview of the waterways data\nglimpse(features$wways)\n\nRows: 2,714\nColumns: 3\n$ osm_id   &lt;chr&gt; \"3027797\", \"3127808\", \"4680059\", \"5171926\", \"5171930\", \"51722…\n$ type     &lt;chr&gt; \"river\", \"river\", \"river\", \"stream\", \"ditch\", \"river\", \"strea…\n$ geometry &lt;LINESTRING [°]&gt; LINESTRING (-1.272943 50.62..., LINESTRING (-1.290…\n\n\n\n\nThe line\nWe need to specify a straight-line route.3 For this demonstration, and in interests fo speed, I’ve just chosen one that looks alright by eye in terms of obstructions. Kinda.\nOf course, you can use the approach outlined in this post to try other lines and discover quantitatively which ones have the fewest obstructions. That’s the subject of an upcoming Shiny app, which will allow the user to provide a line and get feedback on the number and count of hazards.\nCrucially, the line is clipped to the boundary of the island, so it goes from coast to coast.\n\n# Create a straight line\n# 'x1', etc, are start/end latlongs; 'boundary_poly' is the GeoJSON\nmake_line &lt;- function(x1, y1, x2, y2, boundary_poly) {\n  x &lt;- st_linestring(matrix(c(y1, y2, x1, x2), ncol = 2))  # to matrix\n  y &lt;- st_sfc(x, crs = 4326)  # set coord reference system\n  st_intersection(y, boundary_poly)  # clip line to island boundary\n}\n\n# Hard-coded start/end latlongs\nstart_x &lt;- 50.658; start_y &lt;- -1.472\nend_x &lt;- 50.707; end_y &lt;- -1.101\n\n# Build line between the points, clip to IOW boundary\nline &lt;- make_line(start_x, start_y, end_x, end_y, iow_extent)\n\nalthough coordinates are longitude/latitude, st_intersection assumes that they\nare planar\n\n# Preview\nglimpse(line)\n\nsfc_LINESTRING of length 1; first list element:  'XY' num [1:2, 1:2] -1.47 -1.1 50.66 50.71\n\n\nHere’s a quick preview of where our line is:\n\nggplot() +\n  geom_sf(data = iow_extent) +\n  geom_sf(data = line) +\n  ggthemes::theme_map()\n\n\n\n\n\n\nThe platinum zone\nIn practice it’s very difficult to keep exactly to the line and some deviation may be required at a landowner’s request, for example. What’s an acceptable amount of wiggle room?\nTom spoke in one of his videos about assigning scores to a mission based on minimal deviation from the line. For example, staying within 25 m of the line either side would be a ‘platinum’ standard.\nWe can build a buffer around our line to create a platinum zone, which will be a useful visual aid in the final map.\n\n# Create a buffer around the straight line\n# 'line' as created with make_line(); 25m is 'platinum' standard\nmake_buffer &lt;- function(straight_line, buffer_size = 25) { \n  x &lt;- st_transform(straight_line, crs = 27700)  # line to draw buffer around\n  y &lt;- st_buffer(x, dist = buffer_size)\n  st_transform(y, crs = 4326)  # reset coord reference system\n}\n\n# Generate a 25m buffer ('platinum standard') around the line\nbuffer &lt;- make_buffer(line)\n\n# Preview\nglimpse(buffer)\n\nsfc_POLYGON of length 1; first list element: List of 1\n $ : num [1:123, 1:2] -1.1 -1.1 -1.1 -1.1 -1.1 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n\n\n\n\nObstructions\nOur features object currently has all the lines and polygons within the IOW boundary, but we only want the ones that come in contact with (i.e. intersect) with our proposed route. The st_intersects() function from {sf} does exactly that.\n\n# Extract features that intersect with the line or buffer geometry\n# 'features_sf' contains the features; 'path_sf' for what to intersect\nfind_obs &lt;- function(features_sf, path_sf) { \n  row_nums &lt;- st_intersects(path_sf, features_sf)[[1]]  # rows with obstruction\n  slice(features_sf, row_nums)  # extract matching rows\n}\n\n# Find intersection between features and line\nobstructions &lt;- map(features, ~find_obs(.x, line)) %&gt;% \n  set_names(\"barrs\", \"bldgs\", \"natur\", \"wways\")\n\n# Limited preview\nglimpse(obstructions$wways)\n\nRows: 11\nColumns: 3\n$ osm_id   &lt;chr&gt; \"471224569\", \"552565448\", \"552565555\", \"552565565\", \"55650679…\n$ type     &lt;chr&gt; \"stream\", \"stream\", \"stream\", \"stream\", \"ditch\", \"ditch\", \"di…\n$ geometry &lt;LINESTRING [°]&gt; LINESTRING (-1.285131 50.67..., LINESTRING (-1.216…\n\n\nWe can create a quick table to see what the obstructions are for this route.\n\ntribble(\n  ~Type, ~Count,\n  \"Barriers\", nrow(obstructions$barrs),\n  \"Buildings\", nrow(obstructions$bldgs),\n  \"Waterways\", nrow(obstructions$wways),\n  \"Water bodies\", nrow(filter(obstructions$natur, type == \"water\")\n  )\n) %&gt;% knitr::kable()\n\n\n\n\nType\nCount\n\n\n\n\nBarriers\n92\n\n\nBuildings\n7\n\n\nWaterways\n11\n\n\nWater bodies\n4\n\n\n\n\n\nYou can see how this information is useful if you wanted to try other straight-line paths and see how they stack up against each other. Maybe you want to reduce the number of barriers (typically hedgerows); maybe you don’t mind swimming across a large water body.\n\n\nMap\nSo we have the objects we need: our straight-line route, the platinum-zone buffer and all the features that cross our path. Now to map it. We can use the {leaflet} package to layer these up on an interactive map, allowing the user to inspect the route and the hazards along the way.\n\n\nClick to expand the full mapping code\n\nThe basic approach here is to addproviderTiles() for underlying maps (I’ve chosen these to help add extra context to the route); use addPolygons and addPolylines() to supply the line, buffer and the features as separate ‘layers’ that can be turned on or off; use addAwesomeMarkers() for clickable pop-up feature labels; and supply additional mapping conveniences with addMeasure() and, from {leaflet.extras}, addFullscreenControl() (both functions do what their names suggest).\n\n# Set multi-use variables\nmarker_fill &lt;- \"darkblue\"\nicon_fill &lt;- \"white\"\ncol_line &lt;- \"#000\"\ncol_artifical &lt;- \"#F00\"\ncol_water &lt;- \"#00F\"\nweight_line &lt;- 1\nweight_obstruction &lt;- 2\nalpha_all &lt;- 0.5\n\n# Interactive map\nleaflet() %&gt;% \n  # Base groups: map tiles\n  addProviderTiles(\"CartoDB.PositronNoLabels\", group = \"Simple\") %&gt;%\n  addProviderTiles(\"Esri.WorldTopoMap\", group = \"Terrain\") %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"Satellite\") %&gt;%\n  # Overlay groups: line and buffer\n  addPolygons(\n    data = buffer, group = \"Line/buffer\", \n    color = col_line, weight = weight_line, dashArray = 4, \n    fill = TRUE, opacity = alpha_all\n  ) %&gt;% \n  addPolylines(\n    data = line, group = \"Line/buffer\",\n    color = col_line, weight = weight_line, \n    fill = FALSE\n  ) %&gt;%\n  # Overlay groups: start and end points\n  addAwesomeMarkers(\n    lng = start_y, lat = start_x, group = \"Start/end\",\n    icon = awesomeIcons(\n      markerColor = \"blue\",\n      icon = \"play\", library = \"fa\", iconColor = \"#FFF\"\n    ),\n    popup = paste0(\"&lt;center&gt;Start&lt;br&gt;\", start_x, \", \", start_y, \"&lt;center&gt;\")\n  ) %&gt;% \n  addAwesomeMarkers(\n    lng = end_y, lat = end_x, group = \"Start/end\",\n    icon = awesomeIcons(\n      markerColor = \"blue\",\n      icon = \"stop\", library = \"fa\", iconColor = \"#FFF\"\n    ),\n    popup = paste0(\"&lt;center&gt;End&lt;br&gt;\", end_x, \", \", end_y, \"&lt;center&gt;\")\n  ) %&gt;% \n  # Overlay groups: features in buffer\n  addPolylines(\n    data = obstructions$barrs, group = \"Barriers\",\n    color = col_artifical, weight = weight_obstruction,\n    label = paste(\"Barrier:\", obstructions$barrs$type)\n  ) %&gt;% \n  addPolygons(\n    data = obstructions$bldgs, group = \"Buildings\",\n    color = col_artifical, weight = weight_obstruction, \n    fillColor = col_artifical, fillOpacity = alpha_all,\n    label = paste(\"Building:\", obstructions$bldgs$type)\n  ) %&gt;%\n  addPolygons(\n    data = filter(obstructions$natur, type == \"water\"), group = \"Water\",\n    color = col_water, weight = weight_obstruction, \n    fillColor = col_water, fillOpacity = alpha_all,\n    label = \"Water body\"\n  ) %&gt;% \n  addPolylines(\n    data = obstructions$wways, group = \"Water\",\n    color = col_water, weight = weight_obstruction,\n    label = paste(\"Waterway:\", obstructions$wways$type)\n  ) %&gt;% \n  # Control which layers are shown\n  addLayersControl(\n    baseGroups = c(\"Simple\", \"Terrain\", \"Satellite\"),  # radio button\n    overlayGroups = c(  # checkboxes\n      \"Line/buffer\", \"Start/end\",  # line-related\n      \"Water\", \"Barriers\", \"Buildings\"  # obstructions\n    ),\n    position = \"topright\",\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;% \n  # Other map features\n  addMeasure(  # tool for users to measure distances\n    position = \"topleft\",\n    primaryLengthUnit = \"meters\",\n    primaryAreaUnit = \"sqmeters\"\n  ) %&gt;% \n  addFullscreenControl()  # clickable full-screen button\n\n\n\n\n\n\n\n\nSo, you can inspect the route interactively by zoom and dragging, by hovering over highlighted features to see what they are, and by turning on and off the different map and feature layers for more or less context."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#next",
    "href": "posts/2021-05-22-mission-across-iow/index.html#next",
    "title": "Mission Across the Isle of Wight",
    "section": "Next",
    "text": "Next\nThere’s a lot of stuff missing from this approach to make it useful for actually planning a straight-line route. For example, I haven’t included elevation or land-use type (you don’t want to spend a few kilometres in a marsh). You’re also restricted to a two-dimensional overhead view.\nOf course, I also hard-coded the start and end points for this demo. The real power of this approach would be to let the user choose where they want to start and end and feed back on the identity and number of obstructions for each line suggested. To this end, I’ve started developing a simple Shiny app."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#disclaimer",
    "href": "posts/2021-05-22-mission-across-iow/index.html#disclaimer",
    "title": "Mission Across the Isle of Wight",
    "section": "Disclaimer",
    "text": "Disclaimer\nAm I encouraging you to trespass? No. Am I encouraging you to take advantage of {osmextra}, {sf} and {leaflet} for mapping in R? Yes."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#environment",
    "href": "posts/2021-05-22-mission-across-iow/index.html#environment",
    "title": "Mission Across the Isle of Wight",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 13:42:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2      forcats_1.0.0        stringr_1.5.0       \n [4] dplyr_1.1.2          purrr_1.0.1          readr_2.1.4         \n [7] tidyr_1.3.0          tibble_3.2.1         ggplot2_3.4.2       \n[10] tidyverse_2.0.0      sf_1.0-14            osmextract_0.4.1    \n[13] leaflet.extras_1.0.0 leaflet_2.1.2        geojsonio_0.11.1    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            xfun_0.39               htmlwidgets_1.6.2      \n [4] lattice_0.21-8          tzdb_0.4.0              leaflet.providers_1.9.0\n [7] vctrs_0.6.3             tools_4.3.1             crosstalk_1.2.0        \n[10] generics_0.1.3          curl_5.0.1              proxy_0.4-27           \n[13] fansi_1.0.4             pkgconfig_2.0.3         KernSmooth_2.23-21     \n[16] lifecycle_1.0.3         farver_2.1.1            compiler_4.3.1         \n[19] munsell_0.5.0           jqr_1.2.3               htmltools_0.5.5        \n[22] class_7.3-22            yaml_2.3.7              lazyeval_0.2.2         \n[25] pillar_1.9.0            ellipsis_0.3.2          classInt_0.4-9         \n[28] tidyselect_1.2.0        digest_0.6.31           stringi_1.7.12         \n[31] ggthemes_4.2.4          fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.1               magrittr_2.0.3         \n[37] crul_1.4.0              utf8_1.2.3              e1071_1.7-13           \n[40] withr_2.5.0             scales_1.2.1            sp_2.0-0               \n[43] timechange_0.2.0        httr_1.4.6              rmarkdown_2.23         \n[46] hms_1.1.3               evaluate_0.21           knitr_1.43.1           \n[49] V8_4.3.2                geojson_0.3.4           rlang_1.1.1            \n[52] Rcpp_1.0.11             glue_1.6.2              DBI_1.1.3              \n[55] httpcode_0.3.0          geojsonsf_2.0.3         rstudioapi_0.15.0      \n[58] jsonlite_1.8.7          R6_2.5.1                units_0.8-2"
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#footnotes",
    "href": "posts/2021-05-22-mission-across-iow/index.html#footnotes",
    "title": "Mission Across the Isle of Wight",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs far as I know this does not relate to the island hosting any wights in the Game of Thrones sense. Might want to factor that into your planning if you do decide to cross the island. Maybe do it in summer.↩︎\nI’m using here the ‘LAD boundaries (December 2020) UK BGC from the ONS Open Geography Portal Generalised (20m) - clipped to the coastline (Mean High Water mark)’.↩︎\nI’m not sure that Tom has ever defined what it means to ‘cross a country’, exactly. Clearly doing it at a narrow point makes sense. But couldn’t you just find a kink in the border and cross it? Your straight line could be 1 m long!↩︎"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#tldr",
    "href": "posts/2021-06-08-recreate-spear/index.html#tldr",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "tl;dr",
    "text": "tl;dr\nFor a competition I recreated a data visulisation using base R.\n\n Note\nI won the ‘most accurate’ prize, lol."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#cottonviz",
    "href": "posts/2021-06-08-recreate-spear/index.html#cottonviz",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "#CottonViz",
    "text": "#CottonViz\nThe Young Statistician’s and History of Stats sections of the Royal Statistical Society (RSS) have challenged people to recreate1 or remix Mary Eleanor Spear’s visualisation of cotton supplies in the United States in the 1940s:2\n\nI thought it would be interesting to recreate it using only R’s built-in base graphics. This might be a nice demo of zero-dependency plotting for R users who are more familiar with {ggplot2}.3\nLong-story short, here’s what popped out at the end of my scripting:\n\nIt’s certainly not an identical match to the original, but it gets most of the way there.4\nYou can find the scripts for both the recreation and gif in my matt-dray/viz-recreation GitHub repo.\nThe rest of this post is a walkthrough of the code used to create the final output. It’s in five sections: (1) set-up, (2) line plot, (3) bar plot, (4) margin labels and (5) saving, with a closing section reflecting on tricky parts and potential improvements."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#set-up",
    "href": "posts/2021-06-08-recreate-spear/index.html#set-up",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "1. Set-up",
    "text": "1. Set-up\n\nData\nThe dataset is available to download from the RSS website, but it’s small enough that I can just recreate it here exactly.\n\ncotton &lt;- data.frame(\n  Year = 1942:1948,\n  `US consumption` = c(11160, 9993,  9693,  9423,  10072, 9374,  7833),\n  Exports          = c(1480,  1139,  2007,  3613,  3545,  1968,  4785),\n  Stocks           = c(10657, 10744, 11164, 7326,  2530,  3080,  5283),\n  `Total supply`   = c(23297, 21876, 22864, 20362, 16147, 14422, 17901),\n  check.names = FALSE  # allows for spaces in variable names\n)\n\n\n\nFonts\nI’ve used two font families that weren’t pre-installed on my system:\n\nRouted Gothic, a very close match for the general text of the plot\nHussar Bold Condensed, a not-that-great match for the main title, but it’ll do\n\nIt was sufficient for me to install these fonts on my system (macOS Big Sur running R v4.0.5) and invoke them by name, as you’ll see through the rest of this walkthrough. Your mileage may vary.\n\n\nConstants\nI’ve set a few values as objects so they can be reused and changed more easily without having to copy-paste in the body of the script. Note that I’ve used the convention here that constants are ALL_CAPS, so they’re easier to spot in the plotting code.\n\n\nClick for constants (I hid this because it’s dull)\n\n\n# Constants: general\nCEX       &lt;- 0.8      # font size\nYDIV      &lt;- 1000     # division for y-axis\nBLACK     &lt;- \"black\"  # easy to supply off-black instead\nWHITE     &lt;- \"white\"\nXTICK_LEN &lt;- 0.02     # x axis tick length\nYTICK_LEN &lt;- 0.03\n\n# Constants: lineplot (LP)\nLP_YLIM      &lt;- c(0, 12)  # y-axis limite\nLP_WIDTH     &lt;- 3         # width of lines\nLP_YTICK_SEQ &lt;- seq(2, 10, 2)  # y tick locations \nLP_YLAB_SEQ  &lt;- seq(0, 12, 2)  # y label locations\n\n# Constants: barplot (BP)\nBP_YLIM        &lt;- c(0, 25)\nBP_YTICK_SEQ   &lt;- seq(5, 20, 5)\nBP_YLAB_SEQ    &lt;- seq(0, 25, 5)\nBP_SPACE       &lt;- 0.5  # space between bars\nBP_HATCH_ANGLE &lt;- 45   # hatchmark angle\nBP_HATCH_HI    &lt;- 25   # hatchmark density\nBP_HATCH_MID   &lt;- 22\nBP_HATCH_LO    &lt;- 12\n\n\n\n\nStart a graphics device\nWith base plotting you first open a new ‘device’ so that your plotting calls can be captured. You specify things here like the write path and dimensions. When you’ve finished your plotting code, you run dev.off() to close the device and save the output.\nHere I’m using png() so the output is a PNG file. This function is part of the suite of in-built graphics devices from the {grDevices} package, which also includes things like the lossless tiff() format.\n\npng(\n  \"~/Desktop/cottonviz.png\",  # set to a path of your choice\n  width  = 20,\n  height = 12.2,\n  units  = \"cm\",\n  res    = 1200\n)\n\nYou can think of this as setting up a canvas and then you’re going to layer plot objects over the top of it (perhaps not too dissimilar to {ggplot2}). Beware: things like units and placement of elements will be related to the height and width that you’ve declared here.\nThat means you shouldn’t necessarily rely on the graphics windows opened by R or RStudio when previewing the final output; you should rely only on a saved output.\n\n\nPlotting parameters\nWith base R you can set various par()ameters that apply to your plot as a whole. The chart we’re recreating is one row of two plots, so we can use mfrow = c(1, 2), for example. We can also set some global things like the font family.\n\n# Set plotting parameters\npar(\n  mgp = c(0, 0.2, 0),   # gap to tick labels\n  mar = c(3, 2, 4, 1),  # margins\n  mfrow = c(1, 2),      # plot layout\n  ann = FALSE,          # annotation\n  cex.axis = CEX,       # axis font size\n  family = \"Routed Gothic\"  # font family\n)\n\nI’ve selected ‘Routed Gothic’ as the font family and I think it’s a great match. It’s based on the Leroy lettering set that was often used for hand-labelling technical drawings."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#line-plot",
    "href": "posts/2021-06-08-recreate-spear/index.html#line-plot",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "2. Line plot",
    "text": "2. Line plot\nSo, here’s the first ‘hack’. I’m going to set up a ‘fake’ scatter plot with no content and then we’re going to add our desired content to it sequentially. This provides the correct plot dimensions to which we can add bespoke details.\n\n# Dummy x-y scatter plot\nplot(\n  x = cotton$Year,\n  y = cotton$`US consumption` / YDIV,\n  axes = FALSE,    # no axes\n  pch = \"\",        # expunge axes/points\n  ylim = LP_YLIM,  # y-axis min/max limits\n  xaxs = \"i\",      # set 'absolute origin'\n  yaxs = \"i\"\n)\n\nNote the use of yaxs and xaxs = \"i\" which ensures that the axis limits are exactly at the minimum and maximum values for the axis (e.g. it forces [0,0] to be in the extreme lower-left.)\nNow we can build up the plot axes with manual calls to axis().\nIn short, we supply to axis() the side (1 is the x-axis) and the locations for things like labels and tck (ticks). I’ve used separate calls for ticks and labels on the primary y-axis (side = 2) because the min and max values (0 and 12) are actually set just above and below the ticks. I’ve copied the primary y-axis call for a secondary y-axis (side = 4) too.\n\n# Manual x-axis\naxis(\n  side = 1,\n  at = 1942:1948,\n  labels = c(1942, paste0(\"'\", 43:48)),  # i.e. 1942, '43, '44, etc\n  tck = XTICK_LEN,   # tick length\n  col = WHITE,       # i.e. axis isn't visible\n  col.ticks = BLACK  # i.e. axis ticks are visible\n)\n\n# Manual y-axis (just ticks)\naxis(\n  side = 2,\n  at = LP_YTICK_SEQ,  # no ticks needed for origin/max\n  labels = FALSE, \n  tck = YTICK_LEN, \n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# Manual y-axis (just labels)\naxis(\n  side = 2,\n  at = c(0.2, LP_YTICK_SEQ, 11.8),  # min/max labels above/below tick\n  labels = LP_YLAB_SEQ, \n  las = 1,\n  tck = 0,\n  col = WHITE, \n  col.ticks = BLACK\n)\n\n# Manual secondary y-axis (just ticks)\naxis(\n  side = 4,\n  at = LP_YTICK_SEQ,\n  labels = FALSE,\n  tck = YTICK_LEN,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\nI don’t know of a way to make the y-axis label appear horizontally at the top of the axis, so I’ve used mtext() to place a label in the margin (hence the ‘m’ in mtext) space above the plot.\n\n# Y-axis label: horizontal at top of axis\nmtext(\"Millions of Boles\", side = 3, cex = CEX - 0.1, adj = -0.07)\n\nThis gives us all the ticks and labels, but we’re missing the axes themselves. Spear used a box around the whole plot; you can do this in R with a call to box().\n\n# Bounding box around plot boundary\nbox()\n\nHere’s what the plot looks like at this point:\n\nNext we need to actually plot some data! We can use mapply() to pass the parameters to a custom function that contains calls to lines() and text(), which lay down the trace and label for each group iteratively.\n\n# Generate lines and labels for each group iteratively\nmapply(\n  function(type, lty, x, y, label) { \n    lines(cotton$Year, cotton[[type]] / YDIV, lty = lty, lwd = LP_WIDTH)\n    text(x, y, label, cex = CEX)\n  },\n  type = c(\"US consumption\", \"Exports\", \"Stocks\"),\n  lty = c(\"solid\", \"longdash\", \"dashed\"),\n  x = c(1946.5, 1943.7, 1946.2), \n  y = c(11, 3.2, 6.8),\n  label = c(\"U. S. Consumption\", \"Exports\", \"Carry – over\\nstocks\")\n)\n\nI would normally do iterative things with the map() family of functions from the {purrr} package by Lionel Henry and Hadley Wickham, so I welcome suggestions on appropriate use of the various base *apply() functions in this scenario.\nFinally we can add the arrows that point to the lines from the labels. Base R has a handy arrows() function to which you supply start and end coordinates and parameters for the arrowhead. I used an advanced-coder technique called ‘trial-and-error’ for this.\n\n# Add arrows from labels to lines\narrows(\n  x0 = c(1945.4, 1944.2, 1945.5),  # arrow origin\n  y0 = c(10.8, 3.2, 7.1),\n  x1 = c(1945, 1944.4, 1945.2),    # arrowhead\n  y1 = c(9.6, 3, 6.8),\n  angle = 12,    # 'pointy-ness'\n  length = 0.07  # arrowhead length\n)\n\nExcellent, that’s the line plot completed. The plot now looks like this:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#bar-plot",
    "href": "posts/2021-06-08-recreate-spear/index.html#bar-plot",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "3. Bar plot",
    "text": "3. Bar plot\nThe barplot() function is a little different to the plot() function.\nIt doesn’t take the data as x and y arguments; we can instead pass it a single object that contains our data with each column corresponding to columns in the plot.\n\n# Convert dataframe structure for passing to barplot()\ncotton_transpose &lt;- t(cotton)[2:4,] / YDIV\ncolnames(cotton_transpose) &lt;- c(\"\", paste0(\"'\", 43:48))\ncotton_transpose\n\n                         '43    '44   '45    '46   '47   '48\nUS consumption 11.160  9.993  9.693 9.423 10.072 9.374 7.833\nExports         1.480  1.139  2.007 3.613  3.545 1.968 4.785\nStocks         10.657 10.744 11.164 7.326  2.530 3.080 5.283\n\n\nNote that I’ve supplied column names here in the form they’ll appear on the plot (e.g. '43), except for the first column, which I’ve left blank because the axis label needs to be applied separately for that one case (1942).\nSpear’s cotton barplot uses hatching (i.e. parallel lines in one direction) and crosshatching (i.e. perpendicular lines laid over each other) to ‘shade’ the bars. This approach was used a lot in manual charting because colour wasn’t necessarily available, and it was easy enough to achieve with a set square and rule.\nR lets you control the density and angle of shading in a barplot(), but the angle can only take one value. To create a crosshatch, you need to lay down a separate barplot() layer that is composed only of hatching in one direction. You can then supply a second barplot() call with the hatching in the other direction.\n\n# Barplot layer with hatching only (allows for crosshatching)\nbarplot(\n  cotton_transpose, \n  axes = FALSE,      # suppress axes\n  xaxt = \"n\",        # suppress x-axis bar labels\n  ylim = BP_YLIM,\n  space = BP_SPACE,  # space between bars\n  border = WHITE,    # border around bars\n  col = BLACK,\n  density = rep(c(BP_HATCH_HI, 0, BP_HATCH_LO), 7),  # line 'closeness'\n  angle = 360 - BP_HATCH_ANGLE  # top-left to bottom-right\n)\n\nThis is the bar plot with only the first layer of hatching:\n\nNote that this layer of hatching is only required in the bottom and top bars of the stack because they will end up being crosshatched, specifically. The middle bar will only be hatched, not crosshatched, so it’s blank in this first layer.\nNow we can apply the rest of the bar plot. Since we want to add this barplot() call on top of the previous one, we need to use the argument add = TRUE.\n\n# Barplot layer with features\nbarplot(\n  cotton_transpose, \n  axes = FALSE,\n  ylim = BP_YLIM,\n  space = BP_SPACE,\n  col = BLACK,\n  density = rep(c(BP_HATCH_HI, BP_HATCH_MID, BP_HATCH_LO), 7),\n  angle = BP_HATCH_ANGLE, # bottom-left to upper-right\n  add = TRUE              # add as layer on top of existing plot\n)\n\nAnd now we have both layers of hatching, the bar boundaries and the x-axis bar labels:\n\nYou’ll notice I suppressed the axes again. The approach to building the bespoke bar plot axes is very similar to that of the line plot, using axis(), box() and mtext().\n\n# Manual y-axis (just ticks)\naxis(\n  side = 2,\n  at = BP_YTICK_SEQ,\n  tck = YTICK_LEN,\n  labels = FALSE,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# Manual y-axis (just labels)\naxis(\n  side = 2,\n  at = c(0.4, BP_YTICK_SEQ, 24.6), \n  tck = 0, \n  labels = BP_YLAB_SEQ, \n  las = 1, \n  col = WHITE\n)\n\n# Manual secondary y-axis (just ticks)\naxis(\n  side = 4,\n  at = BP_YTICK_SEQ,\n  labels = FALSE,\n  tck = YTICK_LEN,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# X-axis label: horizontal at top of axis\nmtext(\"Millions of Boles\", side = 3, adj = -0.09, cex = CEX - 0.1)\n\n# The first label is at the origin\nmtext(\"1942\", side = 1, line = 0.2, adj = -0.06, cex = CEX)\n\n# Bounding box around plot boundary\nbox()\n\nAwkwardly, the first x-axis label in the bar plot (1942) has to be created manually because it’s placed under the origin point in the original chart, rather than under the bar itself, which is the default.\nFinally we can add the labels over the top of the bars. I’ve done this in a similar iterative manner as the line plot, where there’s a call to create a white box with rect(), over which a text() label can be applied.\n\n# Apply labels iteratively\nmapply(\n  function(x, y, xleft, ybottom, xright, ytop, label) { \n    rect(xleft, ybottom, xright, ytop, col = WHITE, border = NA)\n    text(x, y, label, cex = CEX)\n  },\n  xleft   = c(4.4,  4.3,  3.2),\n  ybottom = c(14.4, 10.4, 6.4),\n  xright  = c(6.6,  6.7,  7.8),\n  ytop    = c(15.6, 11.6, 7.6),\n  x = 5.5,\n  y = c(15, 11, 7),\n  label = c(\"STOCKS*\", \"EXPORTS\", \"U. S. CONSUMPTION\")\n)\n\nAnd here’s our visualisation with both plots completed:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#margin-labels",
    "href": "posts/2021-06-08-recreate-spear/index.html#margin-labels",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "4. Margin labels",
    "text": "4. Margin labels\nWith both charts completed, we can add with mtext() the titles and captions that exist for the plot as a whole.\nThe main title uses a different font family than was specified in par(), so we override it with the family argument.\nI couldn’t find a good (free) approximation of the font family that Spear used, so I’ve used one that has a similar ‘feel’, even if many of the typographical features are wrong (e.g. single-storey ‘a’). Here I’ve settled with ‘Hussar Bold Condensed’. Let me know if you recognise Spear’s actual font.\n\n# Main title\nmtext(\n  text = \"Distribution   of   United   States   Cotton\",\n  outer = TRUE,  # outer plot margin\n  side = 3,      # i.e. the top\n  line = -3,     # relative to outside to plot limit\n  cex = CEX + 0.5,\n  family = \"Hussar Bold Condensed\",\n  font = 2       # bold type\n)\n\nI left extra spaces between the words in the title text to approximate their placement in Spear’s image.\nThe remaining labels were just a case of fiddling with the line and at arguments to get them in the right place.\n\n# 'Subtitle' for line plot\nmtext(\n  text = \"MULTIPLE CURVE\",\n  outer = TRUE,\n  side = 3,\n  line = -1,\n  adj = 0.06,  # nudge\n  cex = CEX,\n  font = 3  # italic\n)\n\n# 'Subtitle' for bar plot\nmtext(\n  text = \"COMPONENT COLUMN\",\n  outer = TRUE,\n  side = 3,\n  line = -1,\n  adj = 0.68,\n  cex = CEX,\n  font = 3\n)\n\n# Caption: source\nmtext(\n  text = \"Source: U. S. Department of Agriculture\",\n  outer = TRUE,\n  side = 1,  # bottom\n  line = -1,\n  adj = 0.02,\n  cex = CEX\n)\n\n# Caption: stocks asterisk\nmtext(\n  text = \"*END OF SEASON, JULY 31\",\n  outer = TRUE,\n  side = 1,\n  line = -2,\n  adj = 0.94,\n  cex = CEX - 0.2,\n)\n\n# Caption: US cotton\nmtext(\n  text = \"U. S. Supply of U. S. Cotton\",\n  outer = TRUE,\n  side = 1,\n  line = -1,\n  adj = 0.97,\n  cex = CEX\n)\n\nAnd so the final output looks like this:\n\nAnd a gif of the steps of the chart’s creation, ending with the original image:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#saving",
    "href": "posts/2021-06-08-recreate-spear/index.html#saving",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "5. Saving",
    "text": "5. Saving\nHaving opened a graphics device earlier with png() and then added out plotting elements, we can now close the graphics device and save the output.\n\ndev.off()\n\nYou’ll want to run all the code from start to finish to encompass the png() call at the start and the dev.off() call at the end. I’ve put all the code in a GitHub repo should you want to use it."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#reflections",
    "href": "posts/2021-06-08-recreate-spear/index.html#reflections",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "Reflections",
    "text": "Reflections\nThe final output certainly isn’t a perfect match for the original, but I think it gets 90% of the way there without the need for endless tweaking. There were some particularly tricky things I was able to deal with, but also some things that I need to improve to make the recreation identical to the original.\n\nTricky parts\nThere were a few non-standard plot elements that needed to be dealt with, but are relatively trivial with base R functions. To review:\n\nthe minimum and maximum labels on the y axis are not on the ticks, they’re slightly above and below them, respectively\nhatching can only be done in one direction, so it requires an ‘under-layer’ of hatching in the opposite direction to that of the main plot itself\nthere’s no function in base to apply a text label with a filled box under it; you need to use text() and rect() together\nthe x-axis labels aren’t all the same: the first is 1942 and the rest are in the form '43\nthe first x-axis label on the bar chart, 1942 is not actually under the bar, but under the origin\n\n\n\nImprovements\nThere’s a lot of things I could do, but there would be a few things to prioritise:\n\nI’ve used a lot of manual adjustments to get the chart elements in roughly the right place; that’s fine for a one-off chart like this, but isn’t that useful for making this code more generic\nI didn’t get the ruler out and measure everything, so there are slight differences when the original and recreation are overlaid\nI haven’t really optimised the code or tried to tidy it up; there may be some unnecessary lines that were part of development that don’t need to be in the final script\nI’ve tried to match the font families as best I can, but the font used in the main title is particularly difficult to find a (free) match for\nR’s built-in line dashes aren’t quite the same as Spear’s, but I think they’re close enough\n\nAnd finally a bonus improvement, though it requires you to download a package. We can save our plot with maximum resolution, etc, but for fun we can invoke some of the artefacts that are present in Spear’s plot with some help from the {magick} image-processing package via Jeroen Ooms and rOpenSci (e.g. see below for how to add blur).\n\nlibrary(magick)  # install from CRAN\n\n# Read the plot PNG\ncottonviz &lt;- image_read(\"~/Desktop/cottonviz.png\")  # set to your path\n\n# Apply blurring parameters\ncottonviz_blur &lt;- image_blur(\n  cottonviz,\n  radius = 14, sigma = 7  # blur parameters\n)\n\n# Save the image\nimage_write(\n  cottonviz_blur,\n  \"~/Desktop/cottonviz_blur.png\"  # set to your path\n)\n\nThat would end up looking like this:\n\nWith a bit more tweaking and addition of some noise, you could probably do a good job of mimicking the ‘aged’ look of the original."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#environment",
    "href": "posts/2021-06-08-recreate-spear/index.html#environment",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:36:08 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.7.4\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7        rlang_1.1.1      \n[17] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#footnotes",
    "href": "posts/2021-06-08-recreate-spear/index.html#footnotes",
    "title": "Recreating Spear’s #CottonViz in base R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs an aside, check out #RecreationThursday on Twitter. It’s a community challenge to recreate an art piece selected each fortnight by a rotating curator (i.e. the curator changes, not that they’re physically spinning).↩︎\nI admit to not knowing much about Spear, so I’m glad that she was selected as the subject of the challenge. One thing I learnt is that Spear might be best known for the box plot, which she originated as the ‘range plot’ in her book Charting Statistics.↩︎\nI haven’t spent much time with base plotting in the last five years (!) and I’m getting increasingly agitated by mounting dependencies in my projects. Locals have been confused recently by a strange fellow walking the streets, repeating the tinyverse mantra of ‘lightweight is the right weight’.↩︎\nYou may have noticed that the ‘US consumption’ line appears a little different to that in Spear’s original, where the line is flatter. I don’t yet know if this is an issue with the supplied data.↩︎"
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#tldr",
    "href": "posts/2021-07-23-london-colour/index.html#tldr",
    "title": "What colour is London?",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {rtweet} and {magick} R packages to fetch tweets of random satellite images of London from londonmapbot and then reduced each one to a single representative colour.\n\n Note\nlondonmapbot no longer posts to Twitter due to API changes. It can be found on Mastodon instead at botsin.space/@londonmapbot. You can read about that in a more recent post."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#greengrey-belt",
    "href": "posts/2021-07-23-london-colour/index.html#greengrey-belt",
    "title": "What colour is London?",
    "section": "Green/grey belt",
    "text": "Green/grey belt\nI created the @londonmapbot Twitter bot to tweet out satellite images of random points in Greater London. You can read earlier posts about how it was made and how I mapped the points interactively.\nI figured we could sample these to get to ‘the colours of London’, which can be mapped or tiled.\nThis is not too dissimilar to efforts to find the ‘average colour’ of countries of the world, which Erin wrote a nice post about, for example.1 The difference is that we aren’t finding a colour to represent London, we’re representing London with a series of single-colour points.\nThis is relatively trivial with the packages {rtweet} to pull tweets and {magick} to manipulate the images. We can use {sf} to place the points on a map and {ggplot2} for other visualisations."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#get-bot-log",
    "href": "posts/2021-07-23-london-colour/index.html#get-bot-log",
    "title": "What colour is London?",
    "section": "Get bot log",
    "text": "Get bot log\nFirst, load the packages we need. You’ll need to use install.packages() for each one if you haven’t already installed them.\n\nsuppressPackageStartupMessages({\n  library(rtweet)\n  library(magick)\n  library(tidyverse)\n  library(sf)\n})\n\n{rtweet} makes it very easy to collect tweet content. To the get_timeline() function you can pass an account name and the number of tweets you want to fetch. You’ll need to set up authenication first, of course.\n\ntweets_read &lt;- get_timeline(\"londonmapbot\", n = 625)\n\nWhy do I want 625? Well, the bot has tweeted out nearly 9000 images at time of writing, but I want a useable number for this post. (Spoiler: I also want to make a 25 by 25 grid of squares as one of my outputs.)\nThe function actually returns more than 625 because {rtweet} maximises the number of tweets it fetches for each API call. Better to return more than you asked for, rather than less.\nThe returned tibble contains a lot of information. I’m only interested in the media_url and text columns, from which I can extract the satellite image URLs and, with some regular expressions, the coordinate information that’s provided in the body of the tweet.\n\ntweets &lt;- tweets_read %&gt;% \n  transmute(media_url = unlist(media_url), text) %&gt;% \n  transmute(\n    media_url,\n    latitude = str_extract(text, \"^\\\\d{2}.\\\\d{1,4}\"),\n    longitude = str_extract(text, \"(?&lt;=, ).*(?=\\nhttps)\")\n  ) %&gt;% \n  slice(1:625)\n\nSo we’ve got a tibble with 3 columns and 625 rows.\n\nglimpse(tweets)\n\nRows: 625\nColumns: 3\n$ media_url &lt;chr&gt; \"http://pbs.twimg.com/media/E7BOglJVgAEE3XL.jpg\", \"http://pb…\n$ latitude  &lt;chr&gt; \"51.5651\", \"51.4665\", \"51.3752\", \"51.5041\", \"51.5668\", \"51.3…\n$ longitude &lt;chr&gt; \"0.0466\", \"-0.3526\", \"-0.1997\", \"-0.0174\", \"-0.1882\", \"-0.13…\nI’m going to iterate through each URL to download the associated image to a temporary directory. I’ve used a walk() function from {purrr} rather than map() because we aren’t returning anything; we’re saving a file to a folder.\nSpecifically, I used walk2(), which lets me supply two values to the iterate process: the URL and also the iteration number for that URL. That means I can print a message in the form ‘Fetching 1 of 625’ and get a rough idea of progress.\nI’ve also added a Sys.sleep() call to slow the process, as not to hammer the Twitter API too hard.2\n\n# Function: download images from URLs\ndownload_images &lt;- function(paths, dir) {\n  \n  Sys.sleep(sample(0:2, 1))  # random pause\n  \n  tw_df &lt;- data.frame(number = 1:length(paths), url = paths)\n  \n  purrr::walk2(\n    tw_df$number, tw_df$url, \n    ~ { cat(\"Fetching\", .x, \"of\", length(tw_df$number), \"\\n\")\n      download.file(.y, file.path(dir, basename(.y))) }\n  )\n  \n}\n\nSo, you can pass a vector of URLs and a directory path to the function. For purposes of this post, I’m going to save the files to a temporary folder.\nThat call takes a little while and the duration will vary given the random pauses built into the function. I’ve hidden the output because there would be 625 items printed to the console. An example of the output:\n\nFetching 479 of 625 \ntrying URL 'http://pbs.twimg.com/media/E6Akw2fXMAA3VSk.jpg'\nContent type 'image/jpeg' length 113537 bytes (110 KB)\n==================================================\n  downloaded 110 KB\n\nTo prove this has worked, we can fetch all the image paths from the directory in which they’re stored and count how many there are.\n\nfiles &lt;- list.files(tmp, \".jpg$\", full.names = TRUE)\nlength(files)\n\n[1] 625\nGreat, as expected. Now we have a set of satellite images that we can manipulate."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#demo-one-image",
    "href": "posts/2021-07-23-london-colour/index.html#demo-one-image",
    "title": "What colour is London?",
    "section": "Demo: one image",
    "text": "Demo: one image\nAs a demo, let’s take a look at the first image.\n\nex_in &lt;- image_read(files[1])\nex_in\n\n\nNow we can crop out the logos, reduce its colours and resize it using functions from the {magick} package.\n‘Quantization’ is the process we’ll use on each image; it’s basically the algorithmic simplification of an image to the colours that best represent it. You could, for example, use this for reducing the number of colours in an image to make it easier to compress while minimising information loss. We’re going to quantize to just one colour to find the colour that best represents the image. Note that this isn’t the same as ‘taking an average colour’.\n\nex_square &lt;- ex_in %&gt;%\n  image_crop(\"x420-0\") %&gt;%\n  image_quantize(1) %&gt;% \n  image_resize(\"100x100!\")\n\nex_square\n\n\nSo the colour of that square is what you get when you quantize the original satellite image down to one colour. What is that colour? We can extract the hex code.\n\nex_rgb &lt;- image_data(ex_square, channels = \"rgb\")[1:3]\nex_hex &lt;- toupper(paste0(\"#\", paste(as.character(ex_rgb), collapse = \"\")))\nex_hex\n\n[1] \"#48503E\"\nOf course, we can generally expect that the colour will be somewhere between very green (city fringes, parks, golf courses) and very grey (urban), while some may be more blue (reservoirs)."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#all-images",
    "href": "posts/2021-07-23-london-colour/index.html#all-images",
    "title": "What colour is London?",
    "section": "All images",
    "text": "All images\nThe image_*() functions in {magick} are generally vectorised, so we can pass it all of the paths to our files and apply the wrangling steps across all of the images at once.\n\nimgs_in &lt;- image_read(files)\nimgs &lt;- image_crop(imgs_in, \"x420-0\")\n\nI want to grab the single quantized hex value representing each image.\n\nimgs_dat &lt;- imgs %&gt;% image_quantize(1) %&gt;% image_resize(\"1x1!\")\nhex_dat &lt;- map(1:625, ~image_data(imgs_dat, \"rgb\", frame = .x))\nhex_cols &lt;- hex_dat %&gt;% \n  map_chr(~paste0(\"#\", toupper(paste(.[1:3], collapse = \"\"))))\n\nhead(hex_cols)\n\n[1] \"#48503E\" \"#535C3F\" \"#435034\" \"#415534\" \"#5D6152\" \"#535F44\"\nNow we can bind these to our tweets dataset.\n\ntweets_cols &lt;- tweets %&gt;% bind_cols(hex = hex_cols)\nglimpse(tweets_cols)\n\nRows: 625\nColumns: 4\n$ media_url &lt;chr&gt; \"http://pbs.twimg.com/media/E7BOglJVgAEE3XL.jpg\", \"http://pb…\n$ latitude  &lt;chr&gt; \"51.5651\", \"51.4665\", \"51.3752\", \"51.5041\", \"51.5668\", \"51.3…\n$ longitude &lt;chr&gt; \"0.0466\", \"-0.3526\", \"-0.1997\", \"-0.0174\", \"-0.1882\", \"-0.13…\n$ hex       &lt;chr&gt; \"#48503E\", \"#535C3F\", \"#435034\", \"#415534\", \"#5D6152\", \"#535…\n\nVisualisation: map\nThe obvious thing to do is to create a map with each point marking the location of a satellite image tweeted by londonmapbot, filled with the single representative colour for that image.\nThe bot samples from a square roughly covering Greater London within the M25, so it might be nice to show the outline of London for reference. The {sf} package makes it straightforward to read a GeoJSON of the NUTS1 boundaries for the UK via the Open Geography Portal API, then convert it to latitude-longitude coordinates and filter for London only.\n\nnuts_path &lt;- \"https://opendata.arcgis.com/datasets/01fd6b2d7600446d8af768005992f76a_4.geojson\"\nldn_sf &lt;- st_read(nuts_path) %&gt;% \n  st_transform(crs = 4326) %&gt;%\n  filter(nuts118nm == \"London\")\n\nReading layer `NUTS_Level_1_(January_2018)_Boundaries' from data source `https://opendata.arcgis.com/datasets/01fd6b2d7600446d8af768005992f76a_4.geojson' using driver `GeoJSON'\nSimple feature collection with 12 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -8.649996 ymin: 49.88234 xmax: 1.762942 ymax: 60.86078\nGeodetic CRS:  WGS 84\nAnd we can convert our tweets tibble to an sf-class spatial object as well, given that it contains coordinate information.\n\ntweets_sf &lt;- tweets_cols %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nThen it’s a case of adding these to a map, which in this case is a {ggplot2} object. The geom_sf() function is great at accepting and understanding polygons and points.\n\nggplot() +\n  geom_sf(data = tweets_sf, col = hex_cols, size = 3) +\n  geom_sf(data = ldn_sf, alpha = 0, size = 1, col = \"black\") +\n  theme_void()\n\n\n\n\n\n\nAre there any patterns here? Maybe it’s greener in the suburbs? (It’s a serious question; I’m a deuteranope.)3\n\n\nVisualisation: tiles\nRecently I’ve written some posts involving R and abstract art (like pixel art and a Shiny app to remix art by Sol LeWitt).\nSo why not get more abstract with these data points? We can create squares of each colour and tile them.\nHere the tiles are laid out row by row from right to left, in a more-or-less random order.\n\nhex_tiles &lt;- crossing(x = 1:25, y = 1:25) %&gt;% \n  bind_cols(hex = tweets_cols$hex)\n\nggplot() +\n  geom_tile(aes(hex_tiles$x, hex_tiles$y), fill = hex_tiles$hex) +\n  theme_void()\n\n\n\n\n\n\nFor fans of order, we could instead arrange them by brightness, or ‘luminance’.4 Here I’ve modified a simple approach by Wouter van der Bijl from a StackOverflow post.\n\n# Get luminance for hex values\nrgb_vals &lt;- col2rgb(tweets_cols$hex)  # Hex to RGB\nlab_vals &lt;- convertColor(t(rgb_vals), 'sRGB', 'Lab')  # RGB to Lab\nhex_lum &lt;- tweets_cols$hex[order(lab_vals[, 'L'])]  # luminance order\n\n# Set up dummy xy tile locations\ncross_xy &lt;- crossing(y = 1:25, x = 1:25)\n\n# Create tibble of x, y, hex luminance\nhex_tiles_bright &lt;- tibble(\n  x = cross_xy$x,\n  y = rev(cross_xy$y),\n  hex = hex_lum\n)\n\n# Plot so 'lightest' in top left, 'darkest' in bottom right\nggplot(hex_tiles_bright) +\n  geom_tile(aes(x, y), fill = rev(hex_tiles_bright$hex)) +\n  theme_void()\n\n\n\n\n\n\nThe colours make me think of the classic smoggy ‘pea souper’ of London in times past, which is fitting.\nOr, y’know, sewage.\nOf course, there’s lots more images available in the londonmapbot feed and many other ways to visualise these data, so I may return to this idea in the future."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#environment",
    "href": "posts/2021-07-23-london-colour/index.html#environment",
    "title": "What colour is London?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:33:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#footnotes",
    "href": "posts/2021-07-23-london-colour/index.html#footnotes",
    "title": "What colour is London?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI didn’t find Erin’s post until after starting my post, but I see that there are similarities in tools: Erin makes use of many of the {magick} functions that I have, for example. This makes me think I’ve used a sensible approach.↩︎\nI’m being relatively polite by doing this, it’s probably not strictly necessary.↩︎\nAs in the ‘nope’ to green/brown/red sort of colourblindness.↩︎\nColour is a hard concept and the idea of ‘brightness’ is no exception. We’re keeping things naïve here.↩︎"
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html",
    "href": "posts/2021-09-12-extract-punct/index.html",
    "title": "Extract punctuation from books with R",
    "section": "",
    "text": "The start of ‘Moby Dick’ by Herman Melville"
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html#tldr",
    "href": "posts/2021-09-12-extract-punct/index.html#tldr",
    "title": "Extract punctuation from books with R",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote an R function to extract only the punctuation marks from a provided text. It prints prettily to the console, but you can also take a character vector away for further analysis."
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html#punct-rock",
    "href": "posts/2021-09-12-extract-punct/index.html#punct-rock",
    "title": "Extract punctuation from books with R",
    "section": "Punct rock",
    "text": "Punct rock\nA few years ago Adam J Calhoun did a small but really neat thing: extracted and presented only the punctuation from some books. It appeared again recently in my Twitter timeline.\nI love the aesthetic of the neatly printed characters, but it also tells us something (obvious?) about writing styles.\nLong story short: old-timey folk often wrote convoluted sentences; literature and essays from a hundred or more years ago are especially rich with semi-colons, commas, more commas and of course, as the audience is well-aware, even more commas, which to modern eyes can be a little tiring; certainly it’s a style that is out of fashion, but was pretty hip for, let’s say, Herman Melville, when writing his behemoth of a novel, Moby Dick; Or, The Whale.\nWhereas Hemingway was terse."
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html#youve-been-punct",
    "href": "posts/2021-09-12-extract-punct/index.html#youve-been-punct",
    "title": "Extract punctuation from books with R",
    "section": "You’ve been punct",
    "text": "You’ve been punct\nSo I wrote a small, opinionated R function called extract_punct() that grabs the punctuation characters for a given text.\nSomeone has probably done this in R before. I saw that Julia Silge wrote a post on quantifying punctuation like Calhoun’s original, but it doesn’t involve printing the characters.\nThe purpose of this post is just to show how to do the extraction and print it nicely to the console, though the function allows you to take away a character vector for further analysis.\n\nFunctuation\nBelow is the definition for extract_punct(). You supply your content to text, and then you set the arguments:\n\nsort = FALSE to return the punctuation in the order it appears in the text, or TRUE to order it ‘alphabetically’\nvec_only = TRUE to early-return the punctuation characters as a vector for you to do with as you please\nvec_only = FALSE to print the results to the console with cat()\nwidth to decide where the line breaks will go in the printed output (defaults to 80)\ncolour = TRUE to have each punctuation character returned in colour thanks to the {crayon} package by Gábor Csárdi1, or FALSE to return without colour\n\n\nextract_punct &lt;- function(\n    text,              # input text\n    sort = FALSE,      # order the characters?\n    vec_only = FALSE,  # return as char vector?\n    width = 80,        # width of output\n    colour = TRUE      # colour output?\n) {   \n  \n  # Extract punctuation with regular expression\n  punct_rx  &lt;- \"[\\\\.,:;!?\\\"\\'\\\\()]\"\n  matches   &lt;- regexpr(punct_rx, text)\n  punct_vec &lt;- regmatches(text, matches)\n  \n  # Sort alphabetically?\n  if (sort) punct_vec &lt;- punct_vec[order(punct_vec)]\n  \n  # Early return of character vector\n  if (vec_only) return(punct_vec)\n  \n  # Colour the characters\n  punct_vec &lt;- sapply(\n    punct_vec, switch,\n    \".\"  = crayon::blue(\".\"),\n    \"!\"  = crayon::blue(\"!\"),\n    \"?\"  = crayon::blue(\"?\"),\n    \",\"  = crayon::yellow(\",\"),\n    \";\"  = crayon::yellow(\";\"),\n    \":\"  = crayon::yellow(\":\"),\n    \"\\\"\" = crayon::red(\"\\\"\"),\n    \"'\"  = crayon::red(\"'\"),\n    \"(\"  = crayon::silver(\"(\"),\n    \")\"  = crayon::silver(\")\")\n  )\n  \n  # Print without colour\n  if (!is.null(width) & !colour) {\n    cat(names(punct_vec), sep = \"\", fill = width)\n  }\n  \n  # Convoluted colour printing, requires flattening a matrix\n  if (!is.null(width) & colour) {\n    div_size &lt;- length(punct_vec) %/% width * width\n    mat_flat &lt;- c(rbind(\"\\n\", matrix(punct_vec[1:div_size], nrow = width)))\n    leftover &lt;- c(\"\\n\", punct_vec[div_size:length(punct_vec)])\n    cat(mat_flat[2:length(mat_flat)], leftover, sep = \"\")\n  }\n  \n}\n\nThere’s no defensive programming or testing here; this is just for fun for the purposes of this blog post. Maybe it’ll work on your machine?\nNote that I’ve selected a subset of possible punctuation marks. There’s no reason why you couldn’t update the punct_rx object, which contains a regular expression, to include more marks. You could even use R’s built-in \"[[:punct:]]\" declaration to capture them all.\nI decided to colour by ‘type’ of mark: terminal (period, exclamation and question), ‘continuing’ marks (comma, semi-colon and colon), parenthetical (open and close) and quote signifiers (quotation marks and apostrophes, recognising that apostrophes are more likely to be used for contractions).\nThere were a couple of technical annoyances to deal with in the function definition; let me know what you would improve.2\n\n\n{gutenbergr}, dead ahead!\nLet’s inspect the punctuation from some books on Project Gutenberg, ‘a volunteer effort to digitize, archive, and distribute literary works’.\nHelpfully, we can interact with Project Gutenberg’s library via the {gutenbergr} package by David Robinson.3\nHere’s some random books.\n\nlibrary(gutenbergr)\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(stringr)\n\nsample_n(gutenberg_metadata, 5) %&gt;% select(1:3)\n\n# A tibble: 5 × 3\n  gutenberg_id title                                    author          \n         &lt;int&gt; &lt;chr&gt;                                    &lt;chr&gt;           \n1        54611 Mental diseases: a public health problem May, James Vance\n2        56216 Rodney, the Overseer                     Castlemon, Harry\n3         2512 The Cruise of the Snark                  London, Jack    \n4        62321 The Flame Breathers                      Cummings, Ray   \n5        50613 My Short Story Book                      Various         \n\n\nYou could filter for a particular author or title, like Franz Kafka.\n\ngutenberg_metadata %&gt;% \n  filter(str_detect(author, \"Kafka\")) %&gt;%\n  select(1:3) %&gt;%\n  slice(1:5)\n\n# A tibble: 5 × 3\n  gutenberg_id title                    author      \n         &lt;int&gt; &lt;chr&gt;                    &lt;chr&gt;       \n1         5200 Metamorphosis            Kafka, Franz\n2         7849 The Trial                Kafka, Franz\n3        16304 Der Heizer: Ein Fragment Kafka, Franz\n4        19638 Auf der Galerie          Kafka, Franz\n5        20045 Großer Lärm              Kafka, Franz\n\n\nI’ve chosen Edwin A Abbott’s Flatland (1884) for the main example in this post. It’s relatively short, so we can get the gist of the output from extract_punct() without printing hundreds of lines. Also it’s a really fun little book that blew my mind.4\nWe can take a book’s ‘Gutenberg ID’, pass to gutenberg_works() 5 to isolate it, and then download it.\n\n Note\nAt time of rendering, the regular Project Gutenberg mirror at aleph.guternberg.org was down, but you can pass an alternative mirror URL to gutenberg_download().\n\n\nid &lt;- gutenberg_works() %&gt;% \n  filter(str_detect(title, \"Flatland\")) %&gt;%\n  pull(gutenberg_id)\n\nalt_mirror &lt;- \"http://mirrors.xmission.com/gutenberg/\"\n\nbook &lt;- gutenberg_download(\n  id,\n  mirror = alt_mirror,\n  strip = TRUE,   # removes Gutenberg headers/footers\n  verbose = FALSE\n)\n\nbook %&gt;% \n  filter(!is.na(text)) %&gt;% \n  sample_n(5) %&gt;%\n  select(text)\n\n# A tibble: 5 × 1\n  text                                                                  \n  &lt;chr&gt;                                                                 \n1 distinguish them?                                                     \n2 in vehemence till at last methought it rivalled the roar of an army of\n3 _I_. Say they so? Oh, believe them not. Or if it indeed be so, that   \n4 vanished. I winked once or twice to make sure that I was not dreaming.\n5 complex.                                                              \n\n\nRight, so now we can pass the text to the extract_punct() function to return all the punctuation in the order it appears, with linebreak every 70 characters so the text fits the width of this blog.\n\nextract_punct(book$text, width = 70, colour = FALSE)\n\n,,...,,,,,,,,.,,,,.:.,;,..,.;,,(),(),,,,..;,;(..,(),.,.;;,.:.,.,,,;.;.\n),,.,..,,,,.,,,.:,,,?.,,,;;!.,,;;,(,(,:,,,.,.,.;,.....,(.(;.;..(),,,,,\n;,.;,,,.(.,.,,(..,,.?,?.;;..,,.,,,,,,,,.,,,.,,).,,.!,!,,..,;,,;.,;,,,;\n.,.,,,,,....,,.,,;,..;;;;?,,,,,.:.;.,,).,.,,,,;,;.,.,;.,,.,.,,..,,.,,,\n.;..,.,,,..,,..;,,.,..,,,..;;,..,;.;,,.,,,;.;.;,,.,,;.;.,,.,,,,?.,,,.;\n,,,,,,..,,,.,,,,,.,,.,..,;.,.,,,.;,..;.,...,,....!,,,,,.,,,,,.,,..,,,,\n,,?,.,,..,(,,,,.,,,,.;,.,,.;,,.,,,,,.,,..;.,,,..;:.,..;.,,,..,;.,,;,..\n.,?,,((.(,;,;,((,:,.,,.,,,.,,,,,,()..,,,,,,,.,.,,,.,.,,.,,,,,,.,..,,..\n,.(;,,...,,;,,,...,,.,,,,;,,,.,.,;;,...,,...,,..;,;;,?,,,,.,:,:?.;.;,,\n.:.,,,.,,,,;,;;,!,,.;.,?,???!,!,,.(,.,:.,.;,,.,.,;,,.;,,,,?.,.,,,.,,.;\n;,..,...;.,..,...,,(),;,.,,,..;;.,;,,;,,,,..;..,;,..,,,.,,,,,,,,,.,,,,\n,(),,;.,,,,..,,.,,,(.,,(;(((,;,.;;,...,;,,.,,....,,,.,,.,,,.,..,.;.,.,\n.;,...;,,.,,(.,;,,...,,.;.;,.,.;,,,.,,,,,,,.,.,.,;..;;,,,.,,,,;.,,;,,;\n,.,,..,,,.;...,,.;,,..,.,..,,;.,..,..,,;,,;,;,,,,.,,:,.,,,,,,.;,.:,.,.\n,,.,.,.,,.;,;,;,.,,,,,...,,..,;,,,,,,.,,,;,;,,;.,,,;;.,,.,??,.,,,.,;,,\n,,,;.;,;,,.,.,,,:,..,.;,,.,...,,;,;;,,,.,;.,,.,,,,;.,,.,;..,.,,,,,;,;;\n,;:..,,,..;.,.,!,.,.(),.,;,,,.,,,,?,.,;.;.:,,.,,,.,,;.,;,.;...,,...,,.\n,,;.(,,,,??,;.,....,.,.?.,??;.;,.,,,.,,;,.!?!,?;.,.,,..,;.,..,,,.,,.?,\n;,;,;.,.,;,,,.,,.,..,..,,???,;.!,,,.,;,.,?,,,,,:!,.,.,..!!!!;,.,,,,.,,\n.,...,.........,.....,?,,.?.,..,,,,,,.;,,,?.,,.,..;,,..,,!.!;,..:,,.;,\n,.;,...;,,,;,.,,.,.;.,,.,,,,,:.;:;,.,,,.,,,,,,(.,,;,;..;,.,.;,??,.;,,.\n!;,.,.,.?.?,,.,.,,,?,;.,;,,,..,:..,,,,),,,,.,..,,...?.,,,.?..,...;,.,.\n..,...,...,;...,.(),...,,,.,,..,.?....?.,,,,,,....,.,;..?...,,?.:..,.,\n.....,,,,,.,..,,,,,,,,..,;,..;..??..,.,,,,,,.,.,,.,.,..,....,.?.....,.\n.,..,,;..,,?..,,.,...:.....?.,..,?.,,;,?....,,,..,.,:;,...,:...,,;.,..\n...,.,:,;....,,;;,,.,,.,,,,,,?..!,.,.,,..:.,....!!.!.,.;;..,.,,.:;,,,,\n,,.,,..,,,...,!,,,.!,;.,.,,,,.,,,,...,,,,,.,::.,..,.,?.!,...,.?,,,.,.,\n,,.,.:,,,,,,,,.,..,,.,.(,,,.!,;,..,...,,,,,,;,,,.,...,.,..,.,;,,.,;..,\n,;,.;.,,.,,,,,:,,;,.!,.,.,,.,.,;....?.,.,,.,,,,,,,,.....,,..;?..,,,,,.\n......,;,.,,,,,,...,,,,,,,,.?,?,?,,?,,?,??,,?,,:,,;.;.,,,?..(..,....,,\n?(.;..,.,,,,,.,,.,,.,...,.!..;,..,,,.,,;,,..;,.;,,.,.,.,.,,,.,;;,,..;,\n;;.,..;,,!,,,,,,,,?,,,,:,,,,.,,.!,!,!,,.:.,,,;.,,,.,,...,..,,,..,,.,;,\n.,,,,,,.,?,;,.,,.,,.,,,.,,.,.,,.!.,.,,,;;,,,!,,,,,,,,..,;.,;..,,,,,:,,\n;(..,,.,,.,;(.;,.?,.,,.,,;,.,,,,,.,;,.?,,.;,,.,;.,,:.,.)?,,,.,.,,.,.,,\n.;.,,,.,.,,,.,,..,;,,;;,,,,,,,,,,,.,,,,,,((,),,.,,,,..,,;..,(,.;,,;,:,\n;(,,,..??.,(),,,?,.!,,.,()..(.;,..,,.(.(,;..,,,,,,,.;,,,,,.\n\n\nI passed colour = FALSE because the blog can’t render the colours. Set colour = TRUE to have the characters returned in your console with a different colour for each type of mark. That looks like this:\n\n\n\nAll punctuation from ‘Flatland’ by Edward A Abbott\n\n\nFor fun, we can also get the same output as before, but ordered by character.\n\nextract_punct(book$text, sort = TRUE, width = 70, colour = FALSE)\n\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;::::::::::::::::::::::::::::::::::::::!!!!!!!!!!!!!\n!!!!!!!!!!!!!!!!!!!!!!!???????????????????????????????????????????????\n??????????????????????????............................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n..................................................................((((\n(((((((((((((((((((((((((((((((((((((((((()))))))))))))))))\n\n\n\n\nFull stop\nSo that’s the general gist.\nHere’s a few more books from Project Gutenberg. Expand to see the punctuation for each one:\n\n\nPride and Prejudice by Jane Austen (1813)\n\n\nextract_punct(\n  gutenberg_download(1342, alt_mirror, verbose = FALSE)$text,\n  width = 70\n)\n\n::..,:...:,:.,..;,.,.,.,,,.,.,,;.,;.,,;);,;,,,;,.,);,,,,,.;.,;,,,,,,.,\n,,.;,,.,,,,,,;,.,.,,,.,,.,.,;.,.,..,,,.,.,;,,..;),.,,,,,,,,.,,.,.,,;.,\n,..,.;.,,.:.,.,,,.;.,.;,,.,.;.,;)(),.,.,.,.;,...,,,,,,,,,,,....,.,,.(,\n.,.,.,,.,.,.;.,,?,,.,,,.;.,,..,,.(;,,.,,(,)().;..;.,..,,..,,.,,,,.,,..\n;,,.,.;,,,,,..;,..,,,.;,,,,,.,,,,,,.,?.;,.,.,...:.........,...........\n?,.....!......,..:.,.,,..?.,..?,:..,;,.,.?.?,.?..??,..,,.,.,,,.,..;.,,\n;..:.,;...,..,,.,.,..,..,.::.:....,;..,..,,,...,..,,.,.,,.,;.,.,;...,,\n..!?,,?,,,..;,...;,.,..,.,,,.,,.,.,,..::..,.,;,..,.;.,.,..,;,,;.,,,.;,\n.:.;..;,.,,.,.;,,,,.,;,,,..:,...,,.,..,;..,......,!;.,,,,.:.?,:.,..,,.\n..,.;,.,.,.;.,,,;.;.;,..,,,!.,!....,,,;.!!,.,..,,!,...?.?.,.!,..;.:,!.\n,,,,.;.,;,,.;;;;,;.;..,.;,,,.;,;,.,.;,,.,,.,,;,.;..;,;.,,...,.;.:..,.,\n;,,,,,,,.,.,.;.,,;,,..?,,,:!,,.?,..:.,.,;.,..,,;....,.,,,,..,,,,,,,,.;\n.,,,;.;;....,.;,,,,,;,,,..,;.,.,;..,,,.,,,,,,...,;,;,.;...;.:,,,,.,,.;\n.,,..:;,..,;,:,.;,...?.,.,:.,,,,,,?;..,,!!,.,.,.,,,,,.;,,.,,,,..,,,,.,\n:.,,,,.,?.,.,;.:;,,,.,,,,,..,.,;,..,;?,,,..,.,!,..,...!??.;,,..,;,:...\n,,,...,.;,,.,,,;,.;.....,.,,.,,,..,,,.,.,,;,,....,;,.,;.;.,,,,,,;..,.!\n.,?,;,.,..,,:.,.;....,,,.:,,...,,,,,.,.,.,:.,,..,?,;,;.,,.,,:,,,,.,,,;\n......,.;,,,..,,.,,,,.;.,.,.,.::.,.,..,,;,.,.;..,,,,.,,,,..,!,,,.,...,\n..,,?.,.,.,,,,,.?;,,.,;,.,,,,.,,,,?,,,,,.,.;;..,.,,...!...,.:,,.,;,,??\n..!.!,.!,.,.,.;..,,.;,.,,,.,...?.,.,,.,.,;;,...,.;,.;...,.:..,..,..,,;\n,.,;.,..,..!,,..,,,,....,,,.,,.;,..,.,.;.,..,.,..;.,,,,,,,,,.,.,.,,...\n,.,,!;.?,,;,.;,,,;..,.,,,,!,,..;.,.,,,,..;..,;.,,,,,..,,..;.,..,.,...,\n,..,..,.,,,.!...!,.,...?.,,.?.,,;.,.,,..,.;.,,..?;,,.,.,,,,,.,..;.;,,,\n,..,.;,..?,.,.,,,...,.,..,.,,,,?,,,,,,;..,,.,..,;,..,.,,..,,.,.,,..,;,\n,?,.,.;,.;..,;,.,.,.,,,,,,.,.:,.?....,,,...,,,...,..,,,..,..:..,,;..,.\n,,.;,..;,.,...,..,..,..,,,.,,!!!..;,,,?;.,,,.,;..,.,.,,,,..,:.,,,..,,.\n,,.,.,,:;.,.,.,..;,..,..,,.,.,.....,...?..,,..,...,..,,.,.,..,;..,,.,,\n.,;,.;,.,;;;.,;....;,.:,,,,,,,..,,,;,,.,;..;;.,,.,;...,!!....;.,:;.,.,\n.,;..:;,,.,.,,.?,,,,;,:.;,,,,.,;,,.,,;,,,,,,.,,.,.,,.,,.,,.,.,.?,,..,.\n..,.,...,,.,.,,.;,,;.,,.,.,,..;.,.,..,,.;.,,,,,,.;,..,.,;,.,,,,,..,,,.\n,.,,;.,,,..?.;,.;.;,..,.,;,..;,,.,,:..;)...,,,?.,;,,,.,..,;,,...;;.;,,\n.;,,,,,;,.;,..,;..,,,,,;,..,.;,:;.;,,,.;,,.;,.,,.,,,,,...;,,,.,,..:,;,\n,.,...,;,.,.?..,..,,..,,,.,,.,,,.;,,,.,,,.,,.,,,,,;,...,,,.,..,,;,..,,\n,;;,,,,.,,,;,,.,,.:,,,;,,,:..,;,,,..,;..,,,;,..,;,,,,,...;.,,.,.,.,,.,\n,.,...,.,..,,;,,,..,.;....,,,,..;,.,;.,,.,.,,.,.,.;,.!...;.!?.,,,,,,.,\n.,!.,,.,?,.,,..,,,!,,,.,.,,!.,,.,:,,;..,;,,.!.,.,;.;.?;,.,,,,;.?.;.;.,\n,.,,.,?..,.;...;,.,,...,,.,,.,,..,.,.,;,..,.,.,..;,,,;,;,,.,,.....;,,;\n.,,.:.,..;.;,.,,.,.,?.,..,.,?..;,,.;,,.,,;,.,...,..,..,.,.,,,,.,.;.,..\n,;,,.,,;,;,,.;!,,.,,,,,,;,.,.,,;,.,..,..,...,,.,,,.,,,.,;,,.,,.;,;,,.:\n,,..,,,,,,,:.!!.,,,.,..;,,,..,,,,.;;.,.;,.,?,.,,.,.,.;,.,..,,,.;.,,.,,\n;,.,..:,)!,:..;,,,,....?!.;.;.?.,,,;.?,?.,.?,.?..,;,.,.,,;,,.,,,,;,.;,\n,..;,.,.;,,,.,,;!....,.;,.,,,.,.,.,.;,,..;..,....,,,.,.,.;,,.,.,.!,...\n...;.,,,,,,,;.,.,;,.,,,.;.,;,.,.,..,..,;.,.;(...,;,.,;,,.,;.,.,;....,.\n.,...;..,,.;,.,,,;,.,;.,.,,,.,,.,,;.,..,,.,;.,.,,,,,,;,.;,,..,.,.;;..,\n..,,..;.,.,..,.,...,.,!,;.,.;,..,,.,;,.:...,,..,,?,,!.,,,..,,,.;,,.,,,\n;.,;.,,,.,,,,(;;,.!,,.,,.,,.;,.;,.,(,,...,;.,,..,..,.,,,;.,,.(.,..,.,,\n,,.,,,,,,,,;,.,.,.,.:,.,;,.,.,,,..,..,.!;,.,,,...;,,,.,,,.,,.,.,.,,,.,\n,,,..,,,,.;..,.,...?.....,...?,..,,...;.,,.,,;.,..,;,,.;..,.,!,:,;,,.,\n..,,.,..,.....,.,.,,.,,.,,.:,,,,:,,;,.,,,.,;.,;,..,,,.;,,...,.,,,,,..,\n.,.;,,,:;.:.,,,,,;,;.,:,;.,,,.,;,.;:.,.,.,,?..,;,,,.:,.,.,..?..;.,.,,.\n;;,.,,?,;;(!?,...,..,;.,:,,;.,,;,,..;..:,,?,,,,?,.;.,..;,.,,;,,.,,.,.;\n,..;,.,,.;:..,.;,.,,;,.,,...;,;,.;,.;.,;.:.,,,...;...,,.:,,.,.,.;,;,.,\n,,.,;,.,,.;,,?.,,..;,.,;.,,.,.,:;,,....:;,,.;,,.?;,,.,,,..,.;.;..;,.!,\n.:...,,,.,;,,!.:;,.,,;,,,,..;.;;;,;;...:;..;,,!:;.,;..,..;.,,,,..,.,,,\n,,,....;.,....;,..,,.,,.,:;.,,....,.,.:.,...,.,..,,,,..,.,?..,;?,.,,.,\n,,.,...,..,.;,,,.,;.,;,,;,,;,,!...,.,...,,,.,;..,.,,,,.,;,..!,..,;,.,;\n,.,;..,,.,;..,......,..;,,.?;.,,.;..:,,,.;..,?;,.,.,;..;,.,,;,,.,,....\n.,.,,....,;..:,..,.,,.;,.,,.,,..,,...,..,.,....,..,,.,..,,.,,..,,:.,..\n,,,.;,,;.?,!..?.,.,.,,.;,!,,..?.,,,,.,.;,,.;,.,.,.,,;,...,.;,....,,..,\n;..:?..:,,;.,.:,..,,,,,.,....;,;,,,,?..,.,,...,.;,..;,;,,,,,.,,..,..,.\n,..:,.:.;,.:,,;.,.,.;,,;....,,,,,.,.:,...,;.,;,.:,,.,,,;,.,,,,,.,;.,.,\n,,.,,,,..,.,..,...,;,..;,,..,..,,,.;,,,,..,;,.,,.;,,..,.:.,,,.;,.,;,.;\n...,.,,,..,,,,,,;,..,,..;,,.,,,.,,.,.;,,.,,...,.,??;,.,.,??,,?..?..,,,\n.,;.,.,,,.,;,.,.?,..,,..:.;,.,,...,.,,..,,:;.,,,.;,,.,;.,,..,,,,.;,.,,\n.,.,,.,,,,,,.,.,,..,,,,.....,,,,.,;,,,.,..,,;,,,:.,!,;,;.?,!!....?,.,.\n..;,,.;.,.:,...,,.,..(?,,...,,,,,....,,.,;.,.,.,.,,.,.,,,,,,,..,,,,,.,\n,.:,;.,.,..,,,,.,,.,.,,.,,.,,.,,.,..,,,.,;,...,,.,,,?,,.,..?..,..?,?,,\n...,?.!!.,.?.,.,.,,.,..,,.?,,,!!?,.,...,.,.;.,..,.;..,,..,,,..,,,.;,,,\n,,...;,.,,;,,.;:,;.,.,,.,..;,..;,,.,,,.,,.:;,,..,:,.,,,..,,.;,,,,,.;,:\n..;,.,,,.,,,.,.,.,,,,,,,.,.;.?:;.,.:.,.,;,,..,.,.,;,.:;,,,;,.;,,,?,.!,\n,,,...,;.,..,,.,,,....,;.,,.,,...,;,,.,,,,.,,.,,.,,,!,...;,,,?.,?,.,.,\n,,.,..,..,.,,,.,,,:;,,,.;..,.,.;,,,,,.,.,,,,.;.,;,.?;..,,.,.,..;.,....\n,,...,.??.,..,,;,..,......;,?,,.,,:.?..,,,,.,;,.,.,;,,,...;,.,;,:,,.,.\n,,;,,,.,,,:.,.;,.,,,.,;,.,.?.,.,,,,,.,,?,,.?..,..,.,..,.??.,.,.,.,;?,,\n,,..;.,.,?;.,,...,...,,!.,..?,...,;,...?,.,..,.??.;.,,.,.,.,.,......,,\n;.,;,.,,,,,.,.,;,.;.,,;..,..,,,,,,..,,,;,.,;,,,,.,...,....,.,.,,,.,,,;\n.,;...;,,,.,,.....,..,..!,,,,,,.,,,?,,,..,,,,.,..?,,.,,,...??,,?!.,...\n!.,!.,,,.,,,,.??;,,,.;.;.,,,,,;.,,,.,..,,..,,!.,,.,.,:..:;.,,.,.,,.,.,\n:.,...,,.,.,,,,.,,,,,,,,.;.,,,,,.,,,,,.,,.,,,,...,,.,;.,;,.,.,.,.;.,;.\n,,.,,,:.,.,,.,,.:,...,,,,...,,.,.;,.,,,,.,.;..,;.;,.,,..,,,,..,.;,,...\n,,..;..,,.,,,.,.,.,,.,..,..,..,.;;,.;,,.,,.;,..;.,;..;,.,,....,,,.,;,.\n..,,.,.;,,,.;,.;,.;..,,.,,!,,,,,;,.;,.,;,.,,,.,....,,.:...,,,.,..,,..,\n;.,,....,.,..;.,;,,.!;,:,.;.;,,;;,;,;..,,!!,.!..,,.,.;.,?;..,,.,.;,,..\n;,,,.,,,,;,.,;,,.;.:.;,,.;,.,,;.?..,.;!;,...,;,,.,,;.,....:.,.,,,,,.,.\n.....,,.,..;..!.,.;;,:;,..;.:,;,;.,,.,;,;?,;.,,.;,.,.,,,,..;,,,,,.:...\n;.,;..,,;..;,.,.,,.,..,,,;,.,,.;.....,..!,.,,,,.,,.,,.:,,.:.!!!,,!,,.,\n,,..,,,,,,,,.:.,,,,,,,.,,?,,,;,.,,,.,.,;!.,!,.,,,..,.,,..:!;!.,,..?,,!\n,;,,!,,..?.!!.;!.!,;:;,,,;,..,,,.,.;,,,;:,,,;,.,,;;,,..!,,....,,..,,,.\n.,,.;,,.;,..;.;.,;.,.,!?.,.,.!,,,,..;.,,,!.!!.,..;.!!....,,;.,.,.,,...\n..,.,...;,,,..,.....,.,..;.,.!,..,,;,,.,?...;,:.,;,,..,,.,.,,,...,.;.,\n.:...,..,,.!.?;.,.,!!.,...;.;.,,,.,..,,..,,,.,;,.,.,.,.,,,.!?..,,,,.,,\n;;;;,..,,?.,,;,..;....,.;,,;,.,..,.,,,.:.,,..;,..,;,.,,,;,,,,,,,.,,,;.\n,?.?,.,!,??,,.,.,,;,;,,,.,.,,.,,.,.,.,;.,..;,,;,.:.,.,.,..;..;.,.,,,,,\n,,.,.;,;,,,,.,,.;,,,:;,,,,,.;.;.,,;,,;,.,,.,;,,,,.;..,;,,,,;,,,,:;;.,.\n,....,,,,.;,.,,..,,;,;,.,,?...,:..,..;..,.,.,,,?,;,,.,:.,;,,,.,.,,,.,;\n,.,.;!,,..;.;,.,.,,;,,;.;,,.,!,.,;.,;,.!..,.,.,..,..,;....,,,;,,....?,\n!:..:,.?,;,,,..,,,,,.,.:,..,.,,..,,.,.,.,,,,.....!,..;,,;,.,...,.,.;,,\n.,...,.,..,..?!!!;,,:.,;,,;,.;,,.;,.;.,.,,,.,;,.,,,.,,.,;,.!!!,,;..,!!\n.,!.,,:;,,.,.,.;.,.,,,;,,,,..;,,:,,.,,.,,,,,,,,,,.,,.;,;;,,....;,,,.,,\n;.:,...,,,;,,,.,..;?...,,,.,..,,;,..,,..;.,,,?;.,,;.;;..,.,,.,...;.;.;\n.,,;,..;.,,.?:,.,.,.,.,.,..!.,.;,,;,,,,.,;,.,.;,,..;.;.,,,.,,.,,..,.;;\n.,,.,..,..,,.,...;,,;,.,...,.,.;.,,;,.,.:.,.,,,,..;,,,,,;,,;,.;..,,,,.\n;,,,.,,,,,.;,.,,.,,,,,,.,,,,.,,....,.,;,,.,,,..;.,,;,,,,;;,.,.,;,..,,.\n,,,,,,,,,;,,,,,,;.,.,.:.,,.,.,,.,..,,.,.,.,;,;,,,.,;::,,,,.,,;.,;,.,.;\n,..,.;,,.,;.,,,;,,.:;;,.,,,,;,,,..,,,.,.,,,.;,.;,:;..,.!..,,.,.;;,,.;,\n,;;.,,;,!,.,;.,..,..,;,..;;,,..;,..,,,,;.,,;.,,,),.,;,......,,,.,,.,.,\n,.,.,,..;,,.,,,....,;,,!:,,,.;.;,,,,.,..,.;,!,;,,,,..!;,;;.,,.,,,.?,..\n,.:,..;....,!,,.,,,,.,,,;?..,,..;.;,;,,;,,,;;,,,,,,!,,.,..,,,,,;,,,.,.\n,,,,,,.;,....,;.,,,.,;.,.,!!,,;;,,.,,,.,.,.,,.?;;.?.?;.,;,,.,;,,:.,;.,\n.?,.?,.,.?...?,.,!.,,;,,??,..,?,.,;,,,.,?,,..;,.,,,,?..,,?,?.;.?.,.,.;\n,,.??,...,;,,...,.,,.;.,.:;,,,,,.,.;,.,,,,,;,,,,.,.?,?.,.,?,..!?!,,,.,\n,,.,;,,.,,,.,,.?,.;!,?;.;,,.,,.;,.,.,.;.,..;,,,.!.,;,,,;,,,.,.,,,.,,,,\n.,,:,,.,..,;.,,,.??,,.,:,??;,,.,,?,..,..?,??.,.,!,,,.?.,:,,,.,,,,,..,,\n.;..,.,..,...!,?:.,.....,,,.,.:,.,,..,,,..;,,,.;,.:..,,;,;.,;.,..,..,,\n,.,,,,;.,;,,,..:,.;,,,;,,.:,,.,,...;.,,,;,;..;..,,;,:,,,,.,,,,;,.,:.;,\n,..,:,?,;.,,.,.;,;,..,;..,;.;.,,.,.!.,...,.,;.,,.;,,,....;;.,;,..,.!..\n?;,,.,,,,.,!,,,,!!.,,,.,,,...,,,,,,,,.,,;;,,,.,,.,,,,,,?;.,.,,,,,.::.,\n:;,,,;,,,,,,.,,,,.;..,...??,.?;.!.,.,,?.!!,:;.!,.,.!.,:.!?..,!..,,,,,,\n?,,...,.!!!,:,.,.,,.,.,.?,,.,..,...,,!,.,..,!,.,..,?,.,!,.;,,,.;.,,.,?\n?..,,,.,,,:...,,.,..;,..;,.,,......,.,,,.,.;,,.,;.,.;.;.;..,,.,,,..,..\n,,,.;,.,,.,.,,.,;;...,,.,.,,;,.,;.;.,...,,....,.,!,.,,,:,,..,..,.,;.,.\n,.,.;.,.;,,.,.,,..;....,.,,,,.!..,,.,,,,,,,.;,,,.:..;.,,,,...;,;.;,...\n..,;,,,.;,,,;,...;,,...,,.!.,;,,;,,,..,.,,,...,;.,,?..;.,,,.!,;.,..,..\n,.;.;,;,;,..;;.,,,,?,.!,...,,.,.,.,;.,.,,.,,.,.,..,!!,.,.,,,,;..,,;,;,\n,.,,,.,;.,;,.;:,:...,,;.,,,,.;,...,,,;..,,,..,..,..;;..,..,,.,.;...,,,\n..;.,,,.;.;.,..,.,,..;,,.;,,..,.:.,..;)..,,;,,...,,.,,,.;.,,.,;,.;.,;,\n,,.,.,;.,,.,),;,..,....,.,.,,,,!;,,,..;,,....;;,...,!..,.,,.,.,.,.....\n.,,,.,?,..,;..,....;?.,..;?..!.?..,,!?,,!,,;,.!,,;,,..:,:...,;.;,,.,,,\n....,,,...,.,....,,.,.,,),.,..,:;,,,.;,;...;,.,;,,.,,!,,.,,,.,,,,,.,..\n,..,.,;..,;.,.,.,..,..,,.;..,,.!.!...,,.....,,.;,,,.,.,,;,.,,.,,,,,,.,\n..,,.,.,,.,.:..;,,.,.?;.,,..;.....,,,.,..,;.,.,!.,.,;.,...,!,..,.!!,,.\n.;,,;.,,.,,..,..;,.:.,,..,?.,;,.,.,..,.,.,.;,,.;,,,,..;.,;,..,,,,;..,.\n,.;,,.;,.,,.,.;;,,.,,?.,,!!??.,;?;?..;,,,,;,,.;,,.;,,?.,.;;..?!,:..;,,\n,,..,.,.,,,.!!?.,;.:,.,,..,,,,.?,.,.,,.,.,,!,,..,,,.,?,;,,,,,.,..,,..,\n.;,.;,,,;,..;,.,;...,,.,,.,;,,.;,,,;,!?,,.,,,,.!,,,,.,!,,.?.,..;,,,,.;\n,..,,..,;,,,.,..,,...!?.!.!,.!,..;.,,;,.;:,.;,,!.,?.,.,,.,..,,?,.,.;,.\n!.?!.,.,.,.;..,,,;..;,,,.,,:;,.,,,..,,,?.,,.,,,.,,:.,..,,,.:;,..,.;.,,\n,.;.:.?.,:,...,.,.,;,.,,,,,,.,,..,,.!??.,...,.;...,,..;..,.,.,..,;,,??\n??;,..,?,,,,;.,,.,??;..;.!.,,.;?,!.,...?.,,,,,,..?.,.....;?,?.,,;..,..\n,?,?,,...,,?,?.,,.,,,,.,,.!..;,,.;,.,.,!!,,,;.:.;.,..,,,,..,,.,.,;.,;,\n,.,,,,,.;.,,..,.,,..,,,;.,.,,...,,,.;..,,,...,.,;.,,.,,.,:,..,?,!,..?,\n,;,.,,.,,.,.;.,.!,,,,?,!,;!,.,.?;,....,,:..,..,,.,...;;,;.;,.....,,,..\n;.,,.,,...,,;.,,,,.;.,:;,..,,,;,,.,,.,.,.,.?,..,,..,,,.,,...,,.,..??,.\n,.,..,;,.,;.,.,....,,.,,,..,,,,.,!...?.,,..!..,.,.,,,.,.,;,,.,.,,...;.\n?.,,.,,..,;,.,,.;,..,.,,....;..,..:..,,.,.,,;;,;.:;..,,:,,.....;...,!.\n?..?,.?.?,.?,.,.?,.,;..,.;,,!,.;:..!,!?,,.;.,,,?...,..,.,,;,;,:.;;,;,.\n,..,,,,,;,.,,?,;,.,,?,?..,.;.,,..,,.....,,,,,,,.,.,,.,,!.;.,.,,;,.,,.,\n.,.,,.,!?!!.!.!!;,..,,.,,;,,;,,.;.,;.:...,.?;?,..,,.;..,.,,:,.,..,?!.;\n;?,,,....,!,!.,,?.....,.??,.,,?,;.,,,.,;,,:,,,;,.....,,.,...,....,.,.,\n..,..,..,,.,,..,,.,.;;..,,;,,......,,,,...,.,:;,,.,;,,;,,;..;,.,.;,.,,\n,:,.,;.;.;.,,.,,.,,;.,.,:,.,.;,,.;,;,.;.,;,.,..,.;,,,.,,,;,,..,,,::,\n\n\n\n\n\nThe Metamorphosis by Franz Kafka (1915)\n\n\nextract_punct(\n  gutenberg_download(5200, alt_mirror, verbose = FALSE)$text,\n  width = 70\n)\n\n,.,,.,?,.,,..,,,.,,,.,.,,,.!;;..,.,.;,,,!,....,!,.;.?,?,.,.,?.,.?,.,,.\n.?,.,,.,:,,.,,,,::?,.:,,.,,.,.,.;.,;,,;,.,,;;,,,,.,.,..,,,,..,.,.,,.:.\n,...,.,.,.;,,,?...,..,,.?,?,,?,,,,.;.,.;.,.:..,...,,.!;...,;.;;,,.,,,.\n?,;.?.?,?..,.,,.,.,?,.,,,.,...,.;,,,,,,...!,.!.;..,,!,,,.,;..,,.,;...?\n,,....?.,,,.?;.,,,,.,,.,,..,..,..,;,,.,;:!,.,,.,:..,.,.,,..,,..,.,.,.;\n;.;,.,..,,.,.,,,,.,.,...,,.,,,,,.!,.,..,,,..;,.,!!.;.,,,;,,,,;,;..,:,,\n;;;.,,..;;.;;.,,,,(),.,.,,,,.,.,,.,;,.,.!,.,,....,;;,.,,,.,...,..,,,.,\n.;..,,.;.,,.,.,,.,,.,.?,.,;;.,;.,,,.,,.;.,,.,,,..,,,,,,,,,.,.,.,,?,,..\n.,,.,;;;.,,,..,.,,.,;,.,.,.,.,.,.,,,.,,..,,.,,,.,,,.,.,,;..,.,;.,,.,.,\n,,,....,,.,.,..,,,,,..,.,.,.,,,.,,.,.,..,,,.,,.,;,;...?,.,,,.,,.,.,,,,\n,;,,,.,.;,,..,.,.;,.,,,.,,..,.,.,...,.,.,,,,...:?,,,,..,,,,,.;;,.,,,,,\n.;,;.,,;..,.,.,,.,,.;,.(,,?.,,.,?,.,,;;.,,.,,,,,,,....,.,,.,,,,.,.,.,,\n,.,.;;,,.,.,,.,.,..;.,.,,,,.!.,,,:.,.;,;;;;;;;.,,;,,.,,,.?.:.,,.,.,,,.\n,!..;.,,;,,,,;,.,;;,.,,,,,.,,.,.,.,.,,..;;,,,.;.,.,.,,;,,(),,.,.,,,.,,\n.,(.,,,.,,..;;;,.!.,;,..,,.,,.,..,,..,!,.,?;;.,,.,,.,;,.,,,..,;,,.,,;,\n,,,,,,,,,,,,,.,..,;..,,,,,.;,,;;,,.,,.,.,.,...,,,.!,.,.,.,..,,,.,.,.,.\n,.,,...,.,,.,,,.,.,,,,.,..,,,,.,..,.,,,.,.,,.,,..,?,,?..,.;,;;.;,..;,.\n,.,;,,,.,...,..?.,,,;;,?.,,,.,.,.,...,..,,,,..,.,,.,,..:..,,.,.,...,,.\n.,.,,...,,.,,,,,,?,,.,,.,....,.!,.,.,.,,...,.,....,.,.,,..,...,!,...,.\n,....,.,.,.,.,.,:,.....;,.,.,,......,,.,,...,;?....;...,.,....,;...,.;\n;.;;,,,;.,.,.,..,.,,..,,.;,.,,,,...,..,,.,.,;,,.,,...,.\n\n\n\n\n\nMoby Dick; Or, The Whale by Herman Melville (1851)\n\n\nextract_punct(\n  gutenberg_download(2489, alt_mirror, verbose = FALSE)$text,\n  width = 70\n)\n\n'.(.,,..;,;,,'.;.,.,.,,..,?.;!,;,?!.;...,,?.,,.,,,,...,.,;.,.'.?!?,,?,\n,,?,.,,,;,,,..',,,.,.,,,;,,.,.,,,,.,,,,.,..,?,,??,;,,.,,....,,,.!,.().\n.,,;,.,..:\"\"\",,,,;,,,...;,.;..,.,,,,,,,,.,,,,,,,,,;.,?,,?,,.,.,,,,,,\",\n,,,,,.,.?.,.!,,.,.;.,?\",..;.'.,,,,,\"?..,,,,,,',.,\",,.,,,.;.,,,.(;;.???\n;?,,.,,,.,,,.,,,,.,,,,,,,,..,,.....'.??,.;;,..;;.,..,.,,,,.,.,,,.,'''.\n,(,..,.,,,.,,,.'';,(,,'\"',.,.'.'..,;,.\".\"\".'\"?\",\",.,,..,;';,,,.,',.,,,\n.,,.,,.(,.,.,.,.,,.,,?',....,,.,,,,,.,,,.?\"'\",.,;,..,,.,,.,;,.,,,,.,,?\n.,,,'..',,\"?,.,,,,\"?,,?\",\"\"\"'\"''\"'\"\"\"\"\",;.,,,.,.,,;.\".,,(''''.,,,?\"\",.\n;,.,,;,,;;,,,.\";;,,,;,,.,'.,.?,.,..,?,,.,..,,,..,',,.,,.,,.,..,,,.,',,\n.;.,,..,.,,.,.;';.,.,.,....,.,..,,.,.,.,;,,.,..,,.,,,..,,,,..,.,;,.,);\n.;,,.,.,,,.,,,,,,;,,,.\".\".\",.,,\".\"?\"?,\".\"....',.\";..,'\",,..;,,,,.,;..,\n,.,;,,.,,...,,,,,:.,,,;,.;;,,.,,.;,..,,'.,.,.\";.',,,,;,,,.,,,,,,,,;,,,\n.'.,,.,;;,....,;.,,,.,,,,,.,;,,,.,,,,,.,.,,',..,;,,.,,;,,;..';.;,;?',\"\n.,,,;,,,..,;..;,.!,,.,;,.'.',,,,,.,..;..;;.,,,,,.,..!,',.,.,.,,,...,,;\n;,;.?,,..,,;,.,.,.;',;.,,,.',.,..,,..,.,.:,,,,.,,,',,,.,,,.,,..;,.,;,,\n.!,.!!,..,,,,,;;,;;;.,.,,,..,..?.,...,;,.,.,,;,',,,.,,.,,,,,,,,,,,.,,,\n.,,,,.,,,..,.;,,?,,.,',.,;'',;..',.?;.,.,.,.!,'.;,.,;,,,'.,;,,,.,;,.,,\n.,.,,'.\".'!',;?;.,,.,.,.;.\",.'..,,.,;,,!,.,,.,.;,,.;.,;'.',,;,...,,\"'!\n.,;,,...?,',\",,;.,'..,.;'.,',.,','\"',,;,.,..,!!\",;,,,''\",.!..,,'.,,.,.\n,,,.,,.,,.\",;,,..?,,,,.\"!!;,,,;.,.\",,.;,',..,,.,,...,,';;,.,;,,,:\".;,,\n,,.,,.,,,,.''.,,;;,'!\".!!!,,,!;,,,.?,.,.,.,,.,!..?,,.,;.,;,.,,;,.;,,..\n..;,.,..,,;.,,,.,,,.,,...,..;.,;;..,.,,;,;,;.....,..,;'.,,,..,,.',.;,;\n;,,.,.,;,,',.;,.;.?,??.?.;;;,.;.;.',,;,,,,;,,,,.,.,,,,.,...,;,,.;,.'.,\n;.,.,,...,,,,,.,,.,.,;..;.'.,.,.,.,,;;,.;;.,.,,,,.,;,;.;,..,,,,;.;..,,\n.,.,,.,,;.,,,,',,.,,''.,,\".,,.,.,,,.,,,,.,.,;;,.,,;.,,'.',,,,,,,;.,,;.\n\",.,,,;,,;;..,,.!;.,;.;,;,,,;.,...,;,,.\"\"\",?\"\".\",;\";,.,,,;.,.;.,,,,,,,\n.,.,.,,,...;?.;,,\".;,!;.;.,';;;,,,,......,,,!;,,;';,!,,;,,,';.;.,.;;;,\n,,;,,;,.,,,,,.,,;,,.,,.,,.,,.;,;'!?,,,.\"\";.,,,,\"\"\",,,\",\"?,.,.,!.,,:..\"\n,,;,'\"',;,..;.,',',,;,;\"'',;.).,\"..,,,,,,,;,,';,.,;'.,,.,;,,,,,'.,;;,.\n,;;.;.,'..,.,.,,,,'....,,..,,.,..,,;,.,.,,',.,;'.;.,;,,,..\".\"?\"\"?\"\"\"'\"\n?..,??.,,,.\".\"\"\"\"\"\".,.,,,.\"\",!,,,,.\".?\"\"\"'!?\"\"'\",\",?,.,,'.,,.;.\"?\"'\",'\n,..\"...;,;,.,.,,,..;,;,,,,;,,;,,'.,..,,,,,,,,,,..,;,.,,'.,;,,.,,.,,.,,\n,,,,,..,,,.;,;;.\",.,,,\"\"\"\"\".,,,'..;,';,,.,,,.,,,.,,.,:;,,',,.,;,,\"?\"',\n,!,,,,,;\"!\";.\",,\",,.\".\",.\",,;,\".',.!,,,,,.,.,,.',.'.\"?\"\".\"?\"\",'.,;,,;,\n,,...\".\"\"';;,.,',,;.!,\"?\"....,,.;,.;,,,.',.,:?!,,.,.;;;,,.',',;,,.,,,.\n;,.,,.,,.\"!.;;.,.',;,,\"!,..;..!..,,.\"!!,,\"\"!\";??,.,.,''!?,,.,,.\",,..\",\n;.,,!;..\"?\",,,,,\",,;,,.,.,',..,(,',.;;,.\"..,,,;..,.,,;.,;;,,,';;..,,,,\n,;.,,.;..,;.;.',\".,,;,;'.,.,;,,.,.;,,,,,,,\",\"\"',?\",.\"',,,.\",\"'\"''\";.\",\n,,,;;;.\"\";',',;,?,,;,\",''\";\",.,,.,',,?,,,;',,,\"',;;,.;!'.\".'.;.,.\",;.,\n?\",!?;,.;;,..,.\",,,.;.,,\"\".\",.\"\"\"\"\"''\"\",.\";\",\".\"\"\"'\".\".;\"\"\",\"..,??,,?,\n,'\"'.,.\"\",,,?;';,.\",;\".!'\".\"\".\"!',,,.,,..,,,;;;;.,..,,,,',:;.'',.,,.,.\n,,.',,.,,,,.,.,;,,',,.''',,,,,.,..,.,,.,,.,;.,,,.,.,..'.\",!\",,,\"\"\"\"\",\"\n,.\",.\"\"\".\",,?,;\";,?\"\",;..,,,,,,...\".,,;;.;.\"\".\",,,',.,,,,;,,;;,,,,\"\",,\n,.;.\"\"\".\"\",.\";,.;;..,,,,,,,\",'\",!,.;,,,,.,,.,.,\".\";,.\".,.,,,,,.,;',.;,\n,.,;,..\"\",;,,..,,,,;,.,,,,\".,...,,,,,..,,,;;;;,;;;;;;,,\",,.,,,!!,'.\",,\n,;.'.',.,.,\",;;,.,,',!,,.;.,.;,.;,.'';,;;,,,,,!!,;;,.,,.,,,.).,;...,,.\n;'','.!,;!,;;'?,?,;;,,.?;,,,,,,,...,,,.,,,,,.,.,'!,,.,,.,.,;.,.,,,.,;,\n,,.,.,??,,?,.?.,,.;.?,,.?',,.,.?.,,..,;;;,,;,.,,?,,..?,,,,,,..?,,,,!,.\n,..,..,,..,,,,..,.,.,;,.,,,,,.,.,.\"'\",;;.,,.;.,;'?,,,.;,,,,,,,.,';.;;,\n.,;..,.;,!!,,;,';,!!,,;;!;!.,;;,.,.,.,,...,,,,.,,,;...,,;.,,;,;,;,.,,;\n,;;,,.,;'.;;;,;,.,',,;,,,,,;'.,.,',..,,,,;.,.,,,,..,;;,.;.,.,,,,.,,..,\n,,,,,.!,'.,',,;,.,;,.,.,;,.',..,,.,,.,,.,,;,,;,.,,,,.,.,.,,,,,,,,,,,.,\n',,,,,,.,,,,.';..',.;',,;,,,;.,,,.,,.,,.;,,,,.,,.,,,,.,;,,.,,,,,..,;.'\n;..,,',.,,,,;,;,.,,,,.,,,,;,,.\"?,.,\",\".\",\"',,\",.,?.,.!.;'',,?;..,,?.,,\n,';',,,...?;.,;,.,,,,?.,,,.!;,.?,..;..\",,,.,,,,.,,,,,,.;,.,,,,.,?,,,,,\n.'.,'.',,?,;,;,;',.,\"\",,.\",\",'';.';.,.,.\",\".(\"\"\".,.,,,,;;;;;,.;.,.,...\n,,;,..,,.,.;,.,,,,.,;.,...;.;,!.?;;.:,.,.,,.,,,.,,..,,,..;:..,.,,,,,.,\n;,...,(.,,;.:(,.;;.;;..,,.;;,..,,;,..,..,;...,.\".:;.?;;;,,..;.,.,..,,,\n,,,.,,,.,.,,,...;;,,.,,,,;,\",,,,,?,.,,;.;,..,,.'.,.,;,....,..,...,,...\n,.,.;.,..:;.,,,,..,,.,.,.,..',..,,...,,,,,,..,.,,,.,.,.;.;,,..,..',..,\n,;,,.,.,,,..,...,.,.;..';.,...,,,,,....;.,..,..,....,.....,,,.;.,.,;.)\n.,',,..,..,,;,,,,;;;,,;,:,.,.;,..,,,.',,,.,,;,.,.;.,,),,;.,,,,.'.(),,,\n;;,,,.;,.;,;,,,.,,.,.,,,,',,.,.,;.,,.,;,;.,!;,,;,.,,,,',,,,,,,.,;,,',,\n,,,,,,;',;?;.,;',.,,.,,...'.,.,';,;,,,;,...,.;,,,,,,,!....,,,;.,,,..,.\n:',,,,',.,..',.,.;.,,.,,.',.,;.,',,,.,',;,..,;.,,,.,,,,;;.,,.,,,,,;,.,\n,',.;,.;,,.,,,!,.',.,,,.,,.;,,;,'.,,:;,,,.,;;,,;;.,;,,,.,;;,,;,,.;,,,,\n,,,.,;(.:.,,,.,;.;;;,,,.,,,,.'('',;;,,(,.,.,,.,,;,'.,,(.;.,.,,,.'(,;,.\n,','\"'';,,,,,'.,,,';.,,,,.,.'.,!;.,;,.,,.,:\".,\",.;;.\",.;;,,,,,,.;'.,;.\n,.,,.(,,.,.,,,,,,.,,,,.\".;,.,,.\".\"',,,;.,;..\"\".\".\"\"\"\",;,.,,,\".\"?,,,,.,\n,,;,,,\".\":;,,.\".\"\".\",\",\"\"\";,;.!\",.,?\";.,\"!:,',,..\":!\"\"'!\",,,?\".,,,\",\"!\n,\".,.,?,',;,,,,,.!...,.;,?.,;,,.,(..\",;;,.;;.,,.,\",.,,;.,!\".,....\",;.!\n..\".,;;,...\",..,??.,,,,\"?.,.\",!.'!;.,;,;;..,.;,;;',,!?,;,!!',.;!',!!.,\n,;...!,,'!;;,,;,.;!,,...'..,!.!,,,,!,,!,,!(!,',..,,.,,!!?'',,.?(,,(,,,\n',,,,.,,',,!',!,.,!,';'';'.,.!(',',!'..;,!;,,!(,!(.(,!,,!!'.,!'..!,(.!\n!('.!!,(!!!((,,!;!'?!'!.,!,,,,!!!!!,.,;,?'((.(..''';(,(!!('!!!.,'!!(?!\n,?'!,!!',!,;,,..,.;;,;,,,;;,.,,,;,.,;;,,..,;,.,,;;,.,.,,,,,.;;,,,;,.,,\n,.,,..,,,,,,,,,;,,.,.;,.'.,\".;,,,,,,;,...,;,,.,,;.,.,;,;,,.,,,..,,,()(\n).,,;;,);,,.,.,,,;,,,;,,.,,,,,.,,,..,;,,.,,,',,;,.,',.,,,.,.;;;;,;;;,.\n;,.,;,,,,;;,,,,,,,,,',;;;.,.;,,;..,;,.;,,,',,,,.,;.,,,;,.,,,.,,,,,,.,;\n.,.,.,!,..,',,,,,.',;,,,,,,??;.,,,',;,..;,,,,;\";;;,,;,,,,,;,,;;;,;,,;,\n,,,;,,;,,.,,,,;?,..,,,;,;,.,.,,..\",,,,,?,.,,,,,.,,.,,.,,;!'',...,;,;.?\n;;,.,,;,,,..,.,,,.,,;.,;,..,,..?,,...,,!,.,,;,,.;,,.,,.,?,,;?..,,,.,,,\n,?,,(,,,,,,,,,?,,,?,;;,(,,'.;;.,;,..:,;,,;;;,,?:,,.,,.;,,,.,;,,,,,,?,;\n?;.,,,;;!;.,.,;,,'.,,?;;,?,;,;,,;,,,,,,..?!\":,..,.,.,,,\"\"\".\"\",\".!\"\"'.\"\n;.,.\",,,,;.,,,,,,,.,,;.,.,.,',;,.,',,..,,,;.;;;,,,,,,.',,('.,.,,,,...,\n,,;.,,,,;,.,,.,,,,..,,.;;.,,;.,.,..,.;,,,,.,';,,,?,.,,,,!...,,,,;,,,;;\n,.,.,,.;,,,.,,;,.,.,,,.;;.;,,;,,.;,,.:,(,,;;,,,,.;;,.;,.,',,.:,.;,,.,,\n.,,,.,,,;,'?!??!,..,,,,,,.,,,.,,,,:,,,,,,,'?.?,,'!':;,;,..,,;:.,;,.\".,\n,,;,.,;;.';,,.:,,,.,...,'.'?.',,.:\",,..,,,,.,.,;.',.,,,...:.,,',,,.',;\n,;,,.,,,,.,.,,,,.;,,!.,,;,,.;,,(.,,.,,.,,,..,,..,,..,.,.,,,,.,,,.,;;'.\n,.,,.,,;,,,;.',',.'.,;(),.;,,,..;,,,,,,,,.,.,,,..';,,,,.,,.,,,;.,,.,,,\n.,,.,,,,;,,,.,,.;.',;,;,.,;,,,.,,.,,.,'',,,.\"\"\".,..\".\",.,.,.,,;,.,.;,.\n,.'..,,.,',.,.,.,;,,.',,\"\"\"\",;,,,.',,,,,.\"\",\".!\"\"',\",.?..;,,,:,.'',,'.\n!',...,,,.,,.,.,',\"!\";'\"\"!,..,!\",,..',';,.;,;'.,.,,.;,.,,;';.,..,,\"!,,\n.,,.',,..,.,,.\".,,.\"\".,',.,.,.,;,..,;',.,.;,..;,,,,!,;,,.,,,,...\";,.,,\n..,'.!,;'\",,,,,?;',;.,,,\"',.,;,!;,;,;;;;,,;,;;,,.,.;;.,,.;.\";.,;:,,,;.\n,.\";.,;..;,,.,.;,,!.;.,,;,..,.,.,,,.,,.,';.,..,,,',,,.,;,.,,,.,,.\",;?.\n\",,,,'\".\";,'\"'.!,.,;;',;'',.,,..,.;.;,.,,.'\",.\"\";,\",,.,..;;;?.,,,,.,.,\n,;,,:,,;,,;,';.;.'.,;;,,,.,,,.,';;.,,,,,',,,;,,,;;;,,,,.;.,,,.,;,;,,!;\n,,.,'.,,,;,.'.,.,,,,,;.,,,,.,,,;,;,,,.,,,,,,,,;,,,.,;,,,,.,.,;,,,.;,.,\n,.,..,,.,;,,.,.;;..',;,..,.,,.!,,,.,,,.,..,.,,;,,.\",,;..';,,,,!\",,,,',\n.\",.,,,!?,,,,,.,;.:,,.,.,,,;,,;:,',,.,,;.,;.,.',,;..,.;,.,.,.;,,,,,;.,\n.',,;',,.,.'\"?,',!?;\".';....,.?,;,.,,.;',..,,'.,.;',,.,.;,.,;,.,',;',,\n,,,'(,,.,..',,.,,..,,,,.,,',.,.','.;,\",,..,.,;,,,,;,,,.\",,,;,,,,.\",\",,\n;.,,'.,,,;,;,;,;,;,,;;,.,;,;,;,,'.;,\",,.,;,,,,!,.,,\",;,.,,,,.,;,.\";,;'\n.,,',,,,\",.\",,.;,',',...\"'',,'.\",,.,;,,.\";.;.,.,,;,.\",.;.,;,,,.\",,,;.;\n'.\";,,,.\",.,;.;,:\".,;;,,(..;.\".\",?\".\",\";.\";;,;;;;,.;,,,,\",\",\",.:,,;!.\"\n,.,,.;.;.;;,,,;,,.,,.\".'..\",,,,,;,,.,.;,,.\",,\";,.,.\".\",!\",..\",;';;?;;.\n\"\"',;;'\"\",,,\"'\";,\",,.,,,\",,.;,.\";,;.;,,.,.,..\"\"\"\",,;,;(),,.;,.,,,;..\",\n,,.,,,;;\".,,.;,.'\",,,,,\"',,,\",,\",,!\".\"\"\",,,,,,,.;,.\"\".,.,.\";,,'.',,,,,\n,,;,.\",).',,.,\",,,,.'.,.\"\"\"';,\"\"\"\",,;,'.',,\"...\",,!\"?\".\"\",\";\",,.',;,,.\n,.,,,,,,.,,;,.,,,,;;.\",,,;,.,\".;,\".,,,.;;,,,.\".;,.,,.\"\"'\"\",.\",,!\",\",,;\n.,\",,,\",;.\"\"\"?!.\"'\"?\"..\"\";..\".',\".\",;.,.,.,.,,,',,.,',,,..,,.,.,,'..?\"\n,,,.,.',.'.,;,.,,,\".,,.,\",,,,.,,,.\",.,,.!,.,\";,.,,.,(,.,..,.,(,,,,',.,\n:..;,.,.,;,,,;,',.,,..',,;'.,,,..,,,,.,..,;..,,,.;'.;',.,...,.,,.,,,..\n,,.,',,..;;.,.,,.,.,,.,.;,,,.,,..,,;,?,.,,.,,.,,,,.(.,,\",;,,..:,(;.;;,\n;,.;;,(,;).,..,.,,,,,,,,,.;,.,.,;,,,,,;.,,,,,,.,,...,.;\".,,,.,;.,,,,,,\n.,,..,.',!,,..,,,,.,;,.\",,,,.,.,,,.,...;,,?.,;;;',,,,,.,.;..,?;.,;;.,,\n.,.;,.,.;,;;?,,.,,;,,..,,,;.,,,,..,\"!,.,,.,;;,.;.,,,.,,,.;;.,,\",\"\".;.,\n,.,;.,;,;.;,.,,.,,,,,,,,;,;;'.;,(,,..,;..,,\"\".,.,,.;.;,,;,.,.;,.,.,.',\n,,;,,,';,,,,;,,;,.,.;,.,,,;.?,,',,,,,,,,;,,.:,,,,,..;,.,,,.\",,,.;,,;,.\n,;.,.,.,;;;,,,,,.';,,.\".;,,,,.,.,.\"'.,,...,.,\".',..,,.\";,,,,,!\";..!.\"'\n.,.\"...,,.;',,,.\")....,,;,.,,.;,.,,.,.\",.,;'...,,,,;(,.\".',,,..\",,,.,!\n,,,.\"\";..,,,,;,.,;,;'..,\",,.,;;;;,,!,,,.,.,.;,.;,.,,.,,.,,,..,,;;,.,,,\n.,,.,(..:,,,,.,,,,..,,.'';.,,;;.,;,.;;.,,,.,,,,;,,';,,,',,..,;(,,.,,,;\n,.,,.,.,..\"!,,();;,,',,,')..,.,.,',;',,;,,,,;,,,,,,,,.\",,;,,,,;,,,',,,\n\",,,,!,..;,;,,,,\".,!\",',,\"\".\",!'\"'.\",.;..'?.;;,.\"\",';;'\",,,\"'\",.\".\"\",\"\n\"\",,,.\"\",\"\";.\".\",?.,,\"?\"\",,\"\"\"'\",.\"?\".\"??\"\".',,.?'!,\",.\";',.;,;,,\"'!\"'\n;,,.,,.,.,...,,,,..,..\",'.,..'.;,.,...,),;,,'.'.,,;:,;;;.'?;,,.,,,????\n.,,,.;;,,,.,;,,,,,,.',,.,;,,,,,,,;.';,..,.'.;';,.,,\";;,.;.,,,',,;,,.,,\n.;;.,;;,.,.,\",,;,,,.,,.,,.,,;,.,,,..;,,.,.,;,.,.,';',,,,;,,,,.,.,,;.;,\n;,,,.,',.,.,.,,;,.,.,..,,,.,.;..,.;,,,,,;,;,;,,;,,,.,.,,.!..,.!.!!.;.,\n,,.,,..,,.',.;....,,,',,,.;,!,,.,,.,,:;,,,,,,;,.?,..;,,'.''.,,;'',..,.\n,.,',,.;,,,,.',;.'.;,;;,,\"\",.\"!\"!;,.',,,.,..,;,,,';,;''.,,',;,..,,),;.\n,.',.,.;.,\"!,.,.:,,;,,,,''...;,,,.,,',,.,,.,;.;,,.,,;,..\",.\"!\",.\".\"!\".\n,'.,;,.,,,,,,;,,,,;,.,.,,;.,,.,,,,',,,.,..;,,..,,\",\"!;;,,.,..,.,\";,,.,\n(,\".\".\"\",.',,,.,.,,.,.,;..'.?,',..,,.,,,'('.,,..,;.;,...,,;'.;.,,;,.,,\n.,.,;.,.,..,.;.,.,,..,..,,.,,,,?,,!;?!\"\",,,???,.\",..,,,?\"\";,,\";.\",..\"\"\n;?\",.;.;''.,,,,.;,;,,..,,.,.,.;,,,',,.;,..;,,,,.,,.,,,',,.,.,,.\",.\"\",'\n?\"\"''.'\",,\".?',,\".\",\"\"\"\",,'\"\",,,,,.,,,'.\",\",\",?\";?'?\"\";'''\",',?\"\"\"\"?\"'\n,,,,,;,\"\";,,',;,.\"\"\"\",.\"',',.;;..,,;,,.,.,.;,,.',,,...;',:?,.'',,,\",,,\n,'.,,.',.;.,,.,,,,;',;.,;..,,'...;.,,,;.,,,.,,,,,..,;,,..,,;.,.,,,,'';\n?.,',,..,.,,,,!.,,;',,,.,,,;,.;,.;..',''().',.,,,.,,\",',;\",..!'.,.,.,,\n!,;,,,.,,.,,',..,.\":\",,,..,\"..,,;;.,',,?,..;.,.;';,.,;.',.,''?;.,,,,.,\n,.,;,;,.;;;.'.,,;..,,.,:,,,'..,?,,...,,,,,;;,,.,.,,,;.;;,,,..;??..',,;\n.,,...,.,,,..,.,;,.,;.,,,.,,,';,,,',;,.,,,.,',,.,.,.,.,..,,,,,.,,,,',.\n.,,.,;.,;;,;;!,,!\".,,..,;.,;,,.,;.\",;,,\"??\".,,,;',!,..,.,.\";;.\",.,,,,,\n,.,,,;..,,,;.,',','',,;.,,,,.,,,,,;;.,,,,?,;.,.,,..,,;,.;;,.,;.',,,.,.\n.,,.,..'.,.',',.,.;,,,.,'.?,..,.;,.,;;..'..','.,...,.;';,.,.,.,',,.,,.\n);,,,.',.,...,,...,...;,,,.;,,.',.,,',...,,,;,.,,,.\".\",?,\"',,;.,;;,,;(\n.,';,.,,',,..,,,,,.,,,.,,,.\"','?,;,.,\",\".,,,.;'.,.,.\"!!\";',?''.?\",,,',\n,!,'.\".;?\",;.,,,!,,.,,,,.'.,,;.,,,,,,;,,.',,,,,;.!,,.\";..!!,;.!!'.;,;,\n,.,,,;;.,;,.;,!.,.,;,,,!.?\"?,;!.,,,,'!\",,.,,.\",,,'.,,.,,,;,.,;,.,,,,.,\n,,,..,,.,,.,.\"\".,,,,.,;;;,,.,.,,.,,,.,,,;.,.?..,,,;,;,..,.,,,.\"!.,.\",.\n,,,;.,.,;,.,,.,..;;.,,.;.,,,.';,.'..,,!.,;,,,.,,.,,;,,,.;.;,,.,.,,.;,.\n,,.,.,.;,,,';.,,.,,;,.,,.(),.,:,,,.;.,;.?,.,.,,;,.,,,,,;,.?,!?..,,;,':\n,'(),,,'.'.;.(,',,,,,;\",..,,''.?.,,,,.,.,.,,..,,.,;;,;;.,,,'..;,,,,,,.\n,,.,,.,.,.;,,.,,;,,.;,.;.,,,',,.,,,\";,,!,.,.,.,,;,,'),.,.,;,.,..,';..,\n,,,;,,..,(;.,.,,.;,,.,.,;,,.,.;,,,.,.!,;,.;,;;,...,,,(,,.,.,,,;.;,,.;.\n.,.,.?;?..,;,,.,;,,',..,,,,.,,,.,..,:,;,,.,,,.;,.,;.,;,,,'.,.,,,.,;.',\n,,,.,..,.;,,;.,,,.,,,;.,,;..,,,,,,.,;,,,.,,,'.;,:...,,.:,,,.,.;,,,.,,:\n;',;.,',.;,.:,,.!.;,.:,;,,.'...,,.,,.,.,..,,,,.,.,',.,;;,,,.,.,;.,.,,,\n,;,,,,,.;.,;,,:,,,,,.,,,,,.,,,.,;,,,;,,,.,;,,.??,'.;,';',,.,,;.;!,,,;,\n.,,.,,.,,,,,.,,,;.,,.,,,.',,,,,,,;;,;,.,.,!,;.,.;;.,;,,,,,.,;.,,;;',.;\n,,,.,;.,,,,.,',,,,;,.,,,,.,..,.,,,.,.,..,,',.,.,,,.',.,;.,.,;,;,,.,;,,\n,...,.!.,,,',,..;.,,.,..,,,.,,,,;,,;,,.,,.,.,,;,,,,.;.;,,,,..,;;;,.,;.\n;.,.,,.;,;;,,,,,.;,,'.\"!\"\",;;,.,,..,,,;:,.'.;..,,;.,,.,,;,.,,.,(,;,,.,\n,,.,;;,,.,,..,;;..,,;\",!!!,.;,,,,',.,;,.,.;,,.,.,.,.,,,.,,,,.,.;,.,...\n.,,.,,.,,.,,!;,;;,,.,,'.,.,;,,;,,,;;;;;,,,.,.,,,,,,,.,..;,.,,,,,,..,,.\n,,.!,,.,,,,;,,;,,,.,.,.''.,..,.:,,,.;,.;.,..,;;,.,.,,,.,,..,,,,.,,,;,'\n..,,,;,;,;.;,.,,;,;,.',.,??;,,;'(,?,,,,..,??.???,\",,,,.,.;,,,,,.,,.,,.\n;.,,,;,;,',,;,.,\"\"\"\"\"'?\"\"?\"\".\"\"\",.,,,.(,(),,...,.,,\",'';.?;'.,,.,\",.,,\n'..\"..,,.;,,,.;.,.,.,;.,.,.,.\"';,,';,.!',.,',...;,.',,,;.,,.,,.\";,,;,\"\n?\".\"\"\"\"\",,\",,,.\"\",.\"?,\".\"',?.\";,.\"...,...,.,.',.,',.,,,.,.,,,.,,,..,,.\n,.\"\",'\",,.,\"\",..\";,,,.\".\"'.\".,(.\"\"'\",,',,,',,.;,',,.,;,.,.,,,,,,,\",,,;\n;,;,'.,,.,.,,,,,,,..,,!,,'',,',;.,.,.,,,',,.?,,,;,;,.,,,.,,,,,(,,.;,,;\n,;,,,;,'.,,?,';.,,.,',.,,.,,.,,;,'',,,,;,,,;.,;,,.;,.,,,,,;,,,,,,,,,,;\n,...,,,,\".,.,,.,.;,,;,,.,,,.;;;,.,,.....,,,..,.?,,,,;;,.,,',.;,,,;,,,.\n,',;..;.'',,,,,,,,,...;,,,;,,;,,;;,;,.!;;'.;,,,;;.!,,;;;.,.,,.,,...'.,\n,,...,,.,,.,,,,.,.,,...',,,,,.,,,,,'.,,,.',,?;,,,';,,,;;,,.,,,.,.,;,,,\n..,.;,,';!!.,,,,...,.,,,,.,.,.,,.,,,.,,,.,.,..'..\"....,..,.,.,;..;.,,.\n.,,.,.,,,.,,,,,,,.,;,,;,,,;,,.,.,,,,.,..,,;.,,..,.,,,.',,,!,!;.;,,',.,\n.,.'.',;;,,.,\".,;,.;,',.,.,.,,'',,,;.,,.;;;);,,;,,:.,;,,,;,.,,.,,.;',;\n;.,!,...;,....,;;',;,.,,;.,.,:,,.,;,,,;,,,\",,';,;,'!,,,,,,,.,,;,,,,,.,\n,,.,,.,,.,,.;,',..,;,,.:,;.';,,.,.\";.,;,.;;,!,,\",,';,.,.,.,,,\";.,'..,,\n,?!,'.;:!'.,,,,,',;!;,!,;!,;,,,',;,,.,,,;\",?,,;\";.,;;'.\".;.;?.\",.?,,,'\n;.,,;.,,,!\"\"!\"\"\"\"\",!;.\",,,\".,'!,;?,.'.,,\",.,,,,;'\"\",.\"\",,.,,,',',.,,;.\n,,,,,,;.,,.,,,,(,,,.,,,)!,?\",;\",\"\"\".,;'.,,\".\",\",,\".\";;,',,.,',,',.,',.\n,,,,.,.,;\",;,(,.,,.;;,.,\",\",\".;\",',,,!,.\",;,,;\";.\",,,...\"',,.,,\";\".?,\"\n.\"'',.\"\"\"\"?.\".\",'';,,,;,,,,,\",..;,.\",'?\",!!'\"?\"\"?,'''.,.,,,;,.,;;(,.;.\n,,,.,',.:,,.,.,\".,,;.,.,..,,;.;),;,,;,,.,;,,,..;.,.';;.,,;;..,,,;.;,,,\n.,,.,\"..,,;,,;:,,,,,,,,.,;,,,,,;,.,,,,.,,,,,,,,,'.,;;;;.,,.,;.,,,.,,?;\n?,?;;,;.,;.,,.,?,,,,,,.,,;,,,,,,.,,.;,,;,..,',,;;,.!?!;;;.;,.;.,,,;.,,\n,,..,,;;,.,!,;,.,.,,.,\".,,,',,.,',.;.;;.,,.,;.',,.,';,,,;.,,,,.;;,,.,:\n;.,.,.,,,,,.;,,,....,,.,,;..,,,,,,,;;..,',.,,.,.,.',..;,.,;,.,,....,;'\n.,.?.!,,,,,.!.,,,,,,;,,;,.,,.,,,,,,;,..,,..,,.,.;,.,,;,,.,;,''.?.,,.,;\n,.,,,.,.,,\";.,.,,','),,.,,',,,.,().,,...,;,,,,!,().,).?',,,;,,,'.;.,';\n;,,,.,,,,;,..,;;.,,,(,,,,,,(,,.,,,,,,;,.:,.;,,,,,.,,;.,,,.,,,,,.:,,.,,\n;.,,;,',,,',..,(,,,,,,.',;,,.,;;.,.:,';,.,,;.,;,.,.,,,,,;,';..,,;,.,,,\n';,,;,,(,,,;.;,.,;,,,,,,,;.,,.:,,;,.,;,,.:,.,,..;,..,;,,.;,.,;,;,,,;,;\n',;?;;,;,,;..,,;,,,,,,,,.,.,;,,.(,..,,..,(.'(;(;.,.',,,;;((,,,!!,,,;,,\n,.!,.,,;.';?;.,;,?.,?',,,.,?,??',,'?,,,;,?,,,.,;.,,,;,!;,!;',?,,,!.;(.\n,.(,''.''.,',,,,.,,.,.,,,!;.,,;;..,,;,;,.,,.;,,,,.\".\".\"?\".,\"\"\"!,';,.\"\"\n?,,'\",;;,\"!\",(',.,.,,;,\",',;,\":,.,,,,.;,,,;.;,,,,,;,...,,.,;.,;,,.,!,,\n,.;;'.,.,;,,,,,.,,,.,,,,.;.,,;,;,,;,,.,,:,;.,'.,,.,,'.\".,,,.,,,.,,,;,.\n,.,.;,;,,,,,...,,;\"?,?';..\",,.,.;\"?!;!''!,!.,,;,',;,:..,,,,,,,(),,.,,,\n;,.,,;;;;,,\"!;,;.,;..',,,;.,.,,,,,';,',(;.,,;;,!,,,,',,;.,,...,..,,.;.\n,,,..,',',;,.,,,',,,,',;.,,,;,,,.?;;;;;;;!;;,,,,,,,;;!,,!,,.,,,,,,,,.\"\n;;\";.\"..?,?\"\"?\"\",\"\"',;,'\"\"'!.,,...\".\".,.',,!,,,,,,.\",;,,,\"\"\"?\",.,.\"!,,\n,,\"!?,,\",.,,.,,,\",;;'.,;,,.,.,,,;.,;,;,',.,,;,,'.;,,.;.,.,.,,,,.:,;:,,\n.,??:.,,\",.;.,:\"!,,,,,.;;.,;,;.,;.,,,';,,;,;;,,.,;,,,.;,,.,.,,.,',.,;,\n.\".\"\".\"\",,\",,!,;,;.,,,.,,,.;;;;,,,,,,.,,.\",;.!;;,'!.\";,,,,\"!,,,;,\".,;;\n;;;',,'',,,,.\"?\"\";;.\"..\"\"\"\",?.\"\"\",,'.;,,,;.;.,.';',,,.,',.;.':??.;,,,\"\n;,,:;!',,'.!;;.;!,,,,\";,,.,,\";,,\",',;:.:.,,,.,.,,;.,.',\"\",,,;!,',,''',\n,,,',,\";.\".,..\"\"?\",,??,!\"\",..;;,,.\"\";.,;,,;,,'',,\",,\".,,\";,,.\",,\"!,,,;\n'\",;,.,.,;,.;.,..\",?.;',''..\",';,,,,,.\"!;;,;.\",;.;.;,,;,,;;',.,;.\";.,;\n,.,,!...;..,..,,;!\"',;;,',;,,.',,',,\",:!.,,,;..,.\".\"\"\"\".!.,..!.,.,.?,,\n?\",;?,,.?,,;,?,?,,.,''?\"\".,.,,,;,,,,.,,;;,,..\"?.,.,,,';.,,,.,;;,..,!!,\n!.,,,.,.,,,..,,.\";.,;..'.;.???,'?,,..,.;...?';;,;.?..,?\"'\",!',?!\"',.',\n,\".,',.;.,,,,',,.\".!,,\"\"\";;.,;.,,,.,\".,.';,,,;'.;,;,,,,.,.,,.,.;'.,.\",\n.;!,,,.,,,\",;.,;.,,,,,,,,,.;,,,!,,.,.,.',;,,.,.;.,,.;\".\",,,,,,.,,,.\".\"\n'\"',\";?\"\"\"\"';,!.,,.\"!.\".,.\".!.\"';.!!\"\"\"\"\"\".!\";!\".,,..\",,;;,\".,;,,'\"\"',\n'''.,,.,,,',,,.,.,.,;..,,,.,,,.,.;(),,,,.,;,,,,,..;,.;;,,,,.\"\"\".\"..\"\"\"\n.\"\".!.\".;'?;';.,,;....;..;',.'!,,,.',.'!,,;..;.!\"!\"\"\"?\"\"\"'\",,?.\"\"?;.\",\n.\"',.,\"\"\".\"\"\"!\".,,,.,(\"!,.!'.!,',.?,!!,,;,,.\",,\"\",,,.'..\"\",',,,;.,.;;,\n,;,.,;.;;,;.,.;,\"''?'\"\",.,,,\"?\";,,'',,;',,.,';'.,,;''.,,.\".,,,\"\",,,;,.\n;,;,,;;,,,,..(,,....;\";.\"!;\",,.\";\"\",.,;.(\",,...,.,..,!?!,...;.,,,;;;,;\n,,,.,,.,..,',;';,;;,',..,,,;,;,;,;,.;;.;:,,;'.;,;.,,;.,,;,..,,,'!,;';.\n,,\"!;,;,,,,,,,;.,,,,,.,;,,.;,;;',;;.;.,;,.\",,.':.',..;,,;;,,,;',,,\"\".\"\n\",.\",!;,\"\";;\";\"\";,.,'\"\"!.;,,.,;,,,,;.,;,,,;;;;.,!',;.,,.,,,,,.;.;.,..\"\n\"\"!!!,!.;',!,!,,,?,,,!,,?,?.!,.!,?;.,,.!\"!!';,!!,\".;;.\",'!,',\",;,,??;;\n;,,,!,?,,.,;!';,.,,,'.,,,,,,,,,\",,.\"\"\",;,,.!,.,,',,..\".\",\"..!,'!,!!;.\"\n;\"!';.;,.;,,,,..,,,;.,;,',,.,.;;;!.,,.,;.,.,,,,;,,,,.,,\"'..;\",',..,,,,\n.,;.,'.,,.,,.;,,,',.,'.,;,,,,,;,.,,,.,.,';.',,.,,;,;.,..(,,.,;,.'.','.\n;,.,.,,,.,',;,,.,!'.,';,,.,.,';,;.\"\"\"\"\".\"!!;,,.,,,,,.,.,,;,;,,,'.;,,,,\n,.,';,';!\",(.\".\",';;,?!;,\"\"\"\",;!,.,;,,!,,.,\".\"\";.,,.,;,,.,,;,,:,,,',.,\n,,,,;,.,'?,.;,.\"'!,!\".\",!!.,.;,.;;,;.;.,,;,;,,...,,;.!\",\",;,;,.,,!,;.,\n,.,.\".,,,\"!.,,;.\".,,,.,,'.',,;,.;;,,,,;,.;!!,,'.,,;;,;,,,.,,,;;';,,,,,\n,;,;,.,,',,,.;;;.';,,,\";\".\"\",,,.?\"\"..\"\"!\"\".!'.\"\"!.\".\",,,!!,!;!\"\",;:???\n!\"',,'..,;',;,,,,.,\"\":,'!':!,,;,.',;;,,\"\";!,.;'.;.,,;,.;.,,!,.?,,.;,,!\n',,,,.;,!\"\",'..!,,.\",,.\"\"\".;.,.\"!,!;.,!.,..!'';,..,,',;,,.;.;,,\"\"\"\"\"!\"\n\";.;\";\"\".\";\";.;,,;.;.;,,.\"\"?,;,.,,;,.;;?!!!\"!!,,,;,.\"!:;,.;,.;.,,.\";,.\n,,;'';,;',,;..\"...;,,,?;,,;,.,.\",!,,,,,,;,.,.;.,,,';:';.;;,.\"!.\"\"\"?!.,\n',;,,.,,,,.,;,,,,,.,,,\"!,;;;;,;.\"\",:,,;.,;,;,.\",'?,!,!\";!?;!.,,,!!\"','\n,,,,.,,'..,\"\",;,,\".;,??.,,;;.,,!;;;,,',.,?,;,.,,,.,,,;,.,;,;,,,,;;.\".'\n.,';,,,,.,,,,,,,.,,,(,.,..\",,,\";'\";',,,,,,,,,,,,(,,,,,,,',.,,;;,,,,!!;\n,,,!\".\"..\".\"..\",;\"',.\",.'\",,,.\",.,.'.\"',,.\"..\"'\".'\"...\"..\".\",','.\"..\",\n...\".'.'\"('\".'\",..\",,;,.\".'\",,.'\",;'\",..\".'\".',,..,\",).'\",,'.\"'.\",.'\",\n'\",,'.\",..\"..\",.,\",,,.'\",'\"'.\".\",,.\"','\",.\",,.,\",'.\",'\".\",'.\",,,;:',,,\n,'\"';,.'\",'.\",'\",.\".'\".'\".\",.,,\";,,..\",.\",..\";;;,,,),,.\"\",,...\"\"\"\"\"\"!\"\n\"!\"\"\".\",.\",;;..\".,.'.\".\"'..\".(,.\",,'\";.\".,,.\",,..\",..\"(..\"..\",..\",'.\",\n,;.\"!.\",..\n\n\n\nFeel free to experiment with extract_punct() and let me know how it goes. Maybe include en and em dashes, or interrobang or something."
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html#environment",
    "href": "posts/2021-09-12-extract-punct/index.html#environment",
    "title": "Extract punctuation from books with R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:28:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] stringr_1.5.0    dplyr_1.1.2      gutenbergr_0.2.3\n\nloaded via a namespace (and not attached):\n [1] bit_4.0.5         jsonlite_1.8.7    compiler_4.3.1    crayon_1.5.2     \n [5] tidyselect_1.2.0  parallel_4.3.1    yaml_2.3.7        fastmap_1.1.1    \n [9] readr_2.1.4       R6_2.5.1          generics_0.1.3    knitr_1.43.1     \n[13] htmlwidgets_1.6.2 tibble_3.2.1      pillar_1.9.0      tzdb_0.4.0       \n[17] rlang_1.1.1       utf8_1.2.3        stringi_1.7.12    xfun_0.39        \n[21] lazyeval_0.2.2    bit64_4.0.5       cli_3.6.1         withr_2.5.0      \n[25] magrittr_2.0.3    digest_0.6.33     vroom_1.6.3       rstudioapi_0.15.0\n[29] fontawesome_0.5.1 hms_1.1.3         lifecycle_1.0.3   vctrs_0.6.3      \n[33] evaluate_0.21     glue_1.6.2        fansi_1.0.4       rmarkdown_2.23   \n[37] purrr_1.0.1       tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-09-12-extract-punct/index.html#footnotes",
    "href": "posts/2021-09-12-extract-punct/index.html#footnotes",
    "title": "Extract punctuation from books with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nReaders may remember {crayon} from my recent post about the {dehex} package.↩︎\nIn particular, it’s easy to print the character vector of punctuation characters and linebreak it with the fill argument of cat(), but this behaviour is altered when you convert the characters to {crayon} strings. Instead, extract_punct() inserts newline characters at the desired print width using a crummy trick that flattens a matrix of the punctuation characters. Of course, matrices are ‘square’, so there are leftover punctuation characters that have to be dealt with separately and pasted on to the end, lol.↩︎\nNo, not the legendary San Antonio Spurs center from the 90s.↩︎\nI think I first learnt about this from Carl Sagan.↩︎\nNote that you can use gutenberg_works() for a pre-filtered dataset with English-only texts, are in text format and whose text is not under copyright.↩︎"
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#tldr",
    "href": "posts/2021-04-10-dialga/index.html#tldr",
    "title": "Convert R to cron to English with {dialga}",
    "section": "tl;dr",
    "text": "tl;dr\nI made the small proof-of-concept R package {dialga} to help build and interpret standard cron expressions using familiar R syntax. r2cron() converts R to cron; cron2eng() converts cron to English."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#cronwhat",
    "href": "posts/2021-04-10-dialga/index.html#cronwhat",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Cronwhat?",
    "text": "Cronwhat?\nYou can schedule scripts to run at specific times using software on your computer called ‘cron’. You can set up ‘cron jobs’ to specify what needs to be run. A key part of the recipe is a short cron string that provides instructions about when to run it.\nThe problem: cron strings are a bit cryptic if you’re not a sysadmin and don’t set up cron jobs very often. Here’s a contrived example: \"0/15 * 1,3,20 6 2,3\". What the heck does that mean?\nCase study: me. I’ve been scheduling GitHub Actions using cron strings to specify when the actions should be triggered. For example, I set up a Twitter bot called londonmapbot that currently tweets a random aerial image every half-hour.\nThere’s a bunch of webservices like crontab.guru that help you construct cron expressions. I wondered if I could build one in R. It’s basically just a bunch of string handling and if statements, right? And while you’re at it, why not offer translation the other way? You have a cron string and you want to ‘translate’ it to English. Could be helpful."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#new-development-paradigm",
    "href": "posts/2021-04-10-dialga/index.html#new-development-paradigm",
    "title": "Convert R to cron to English with {dialga}",
    "section": "New development paradigm",
    "text": "New development paradigm\nAn aside. Two things: the package is about time and I’ve been looking recently at Repokémon, a site that tracks which Pokémon have GitHub repos named after them.\nTherefore the package is called Dialga,1 named for the ‘temporal Pokémon’, which is the legendary mascot of the Pokémon Diamond game. The hex logo uses colours from the game’s sprite.\n\n\n\nDialga sprite from Pokémon Diamond (bulbapedia.bulbagarden.net)\n\n\nWe’ve been here before. Consider {safar6}, my R package that contains an R6-class object that lets you play a text version of the Safari Zone from Pokémon Red and Blue. Or a Pokémon carousel widget with {slickr}. Or Pokéballs in Super Smash Bros.\nI call this approach Pokémon-Driven Development (PDD). I think PDD has real promise in the development of pointless side-projects like this one. Use it wisely."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#dialga-demo",
    "href": "posts/2021-04-10-dialga/index.html#dialga-demo",
    "title": "Convert R to cron to English with {dialga}",
    "section": "{dialga} demo",
    "text": "{dialga} demo\nThe package is available on GitHub; there are no plans for it to go on CRAN. You can use the {remotes} package to help you download {dialga} easily from the web.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/dialga\")\nlibrary(dialga)\n\nIn the same vein as the {r2eng} package, the two functions are named r2cron() and cron2eng(). This is pretty self-explanatory: r2cron() takes R inputs as integer vectors and spits out a cron string, and cron2eng() takes a valid cron string and prints out a readable English version.\nAs ever, it was banged-out in a couple of days and I can’t promise it’s bug-free. Let me know if you find anything broken horribly.\n\n Note\nThe package moved to v0.1 since this post was published. The update removed all dependencies, improved the documentation and set clipboard-copying behaviour to FALSE by default. Feel free to offer more improvements.\n\n\nA primer\nBut first, a quick demo on standard cron expressions. Their format is a string of five time-period ‘slots’ separated by spaces. The slots from left to right specify the minutes, hours, days of the month, months, and days of the week that you want to schedule your script to run.\nThe format required for the values in these slots can be expressed relatively easily as R code, which is what r2cron() uses as input. For example, this table shows cron-string formats for the minutes slot and the corresponding R integer vector for them:\n\n\n\n\n\n\n\n\nDescription\nCron\nR\n\n\n\n\nEvery minute (minutes 0 to 59)\n*\n0:59\n\n\nA single minute (5)\n5\n5\n\n\nA consecutive sequence of minutes (1, 2 and 3)\n1-3\n1:3\n\n\nSeveral irregularly-spaced minutes (1, 15 and 17)\n1,15,17\nc(1, 15, 17)\n\n\nA sequence of minutes at regular intervals for the whole hour, starting with some value (every 15 minutes starting at minute 0)\n0/15\nseq(0, 59, 15)\n\n\n\nThe same principles extend to the other time-period slots, but the ranges will obviously differ. For example, the hour slot can take values 1 to 23 (i.e. a 24-hour clock), while the days of the week are zero-indexed from 0 (Sunday) to 6 (Saturday). An asterisk is a special character meaning every unit of that time period, like every minute and every hour.\nSo ‘every 30th minute past the hour’ would be \"30 * * * *\". The contrived example string from the opening of this post—\"0/15 * 1,3,20 6 2,3\"—translates as ‘every 15 minutes starting from minute 0 of every hour, on the 1st, 3rd and 20th of June; and Mondays and Tuesdays’.\nTo help simplify things, the r2cron() function lets you specify each slot in turn as arguments. Each input is an R expression like in the table above. You don’t have to worry about cron-specific symbols, you just provide the appropriate integer vector.\n\n\nSimple example\nHow would you specify the 28th minute past 11PM every day with r2cron()? You pass the value 28 to the minutes argument and 23 to the hours argument. The resulting cron string has a 28 in the minutes slot and a 23 in the hours slot, as expected.\n\nx &lt;- dialga::r2cron(\n  minutes = 28, \n  hours = 23  # 24-hour clock\n)\n\nx\n\n[1] \"28 23 * * *\"\n\n\nGreat, there’s our cron string!\nYou may have noticed from the documentation that there’s also a clip argument. This is for your convenience; when set to TRUE, the output will be copied to the clipboard for you to paste elsewhere, like into the YAML of a GitHub Action in my case. You will need separately to install {clipr} yourself from CRAN if you want this functionality in {dialga}.\nCool, but how do we know this worked? We could pass the cron string into cron2eng() to confirm it.\n\ndialga::cron2eng(x)\n\nCron string '28 23 * * *' means:\n  - minute(s) 28\n  - hour(s) 11PM\n  - every day(s) of the month\n  - every month(s)\n  - any day(s) of the week\n\n\nThis text output isn’t sophisticated, but it communicates the point. I’ve chosen to keep it simple by breaking it into bullet points, rather than wrestling the output into a potentially confusing single sentence.\nOf course, this means you could pipe these functions together to go from R to cron to English in one go.\n\nlibrary(magrittr)  # for %&gt;%\n\ndialga::r2cron(minutes = 28, hours = 23) %&gt;% \n  dialga::cron2eng()\n\nCron string '28 23 * * *' means:\n  - minute(s) 28\n  - hour(s) 11PM\n  - every day(s) of the month\n  - every month(s)\n  - any day(s) of the week\n\n\nIt might be nice to produce eventually an eng2cron() function that goes directly from a text description to the appropriate cron string, but I think that would be a fair amount of effort.\n\n\nMore complex example\nWe can see the flexibility of r2cron() with an unlikely scheduling request like ‘every 20 minutes from the top of the hour (minute 0) of 3PM, 4PM and 5PM, on the 1st days of April, October and November, plus every weekend’. Again, we can specify these as R integer vectors.\n\ny &lt;- dialga::r2cron(\n minutes = seq(0, 59, 20),\n hours = 15:17,  # 24-hr clock\n days_month = 1,\n months = c(4, 10, 11),\n days_week = c(1, 7)  # Sunday is '1'\n)\n\ny\n\n[1] \"0/20 15-17 1 4,10,11 0,6\"\n\n\nNote that the input to the days_week argument isn’t zero-indexed even though the cron format is zero-indexed; Sunday is 1 in r2cron(), not 0. This is to conform better to the fact that R doesn’t typically zero-index things. r2cron() converts days_week = 1 into 0 for this slot automatically.\nAnd of course, we can express the output of this complicated cron string in English:\n\ndialga::cron2eng(y)\n\nCron string '0/20 15-17 1 4,10,11 0,6' means:\n  - every 20 minute(s) starting from minute(s) 0\n  - hour(s) 3PM to 5PM\n  - day(s) of the month 1\n  - month(s) April, October and November\n  - and day(s) of the week Sunday and Saturday\n\n\n\n\nWarnings\nAs a courtesy, you’ll be warned when unlikely dates arise. Some are impossible, like 31 September and others are rare, like 29 February. It’s important that these are warnings and not errors though, since you might legitimately want the job to run on 31sts when available, or the 29 February only (i.e. every four years).\nThis example hits all the warnings:\n\ndialga::r2cron(days_month = 28:31, months = 2)\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? There's no 31st in Feb, Apr, Jun, Sept nor Nov.\n\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? There's no 30th in Feb.\n\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? 29 Feb is only in leap years.\n\n\n[1] \"* * 28-31 2 *\""
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#rs-scheduling-tools",
    "href": "posts/2021-04-10-dialga/index.html#rs-scheduling-tools",
    "title": "Convert R to cron to English with {dialga}",
    "section": "R’s scheduling tools",
    "text": "R’s scheduling tools\nOf course, {dialga} just handles strings and doesn’t help you set up schedules. If on Unix/Linux, you can use the {cronR} package to schedule tasks from R. The Windows alternative is the {taskscheduleR} package. These have their own tools, including a Shiny app, to help you with scheduling.\nAs for {dialga}, I’ll probably use it every now and again to help set up a scheduled GitHub Action. Whatever its use, {dialga} is really just another exercise in package writing and another classic example of PDD (I hope you haven’t forgotten that acronym already)."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#environment",
    "href": "posts/2021-04-10-dialga/index.html#environment",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:46:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 dialga_0.1.1  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[13] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#footnotes",
    "href": "posts/2021-04-10-dialga/index.html#footnotes",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n© 1995-2021 Nintendo/Creatures Inc./GAME FREAK inc. Pokémon character names are trademarks of Nintendo.↩︎"
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html",
    "href": "posts/2022-05-01-dungeon/index.html",
    "title": "Simple procedural dungeons in R",
    "section": "",
    "text": "Three iterations to expand four randomly-placed floor tiles into a cavern."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#tldr",
    "href": "posts/2022-05-01-dungeon/index.html#tldr",
    "title": "Simple procedural dungeons in R",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a (very!) basic procedure to generate randomised ASCII-character tile-based dungeons for {r.oguelike}, an in-development roguelike-game-in-a-package for R."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#generate-to-accumulate",
    "href": "posts/2022-05-01-dungeon/index.html#generate-to-accumulate",
    "title": "Simple procedural dungeons in R",
    "section": "Generate to accumulate",
    "text": "Generate to accumulate\nI wrote recently about the {r.oguelike} R package, which contains the beginnings of a roguelike game written entirely in R.\n\nA key element of roguelike games is that the dungeons should be procedurally generated1 so that the player gets a different one each time they play.\nThere are many algorithmic systems for dungeon creation, like wave function collapse, perlin noise, binary space partitioning, cellular automata, etc.2 See the talk by Herbert Wolverson at Roguelike Celebration, for example.\nI plan to take a look at these approaches in future, but I wanted to start with something a bit more… naïve. I just want a simple interconnected space that spawns with randomised rooms, corridors and galleries."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#excavations",
    "href": "posts/2022-05-01-dungeon/index.html#excavations",
    "title": "Simple procedural dungeons in R",
    "section": "Excavations",
    "text": "Excavations\n\n Note\nThe {r.oguelike} package is a work in progress and is developing at pace. Many things explained below may have been superseded or changed by the time you read this.\n\n\nInstall/launch\nYou can install the (currently work-in-progress) {r.oguelike} package from GitHub, via {remotes}.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r.oguelike\")\n\nYou can also launch RStudio in the browser with {r.oguelike} preinstalled, thanks to Binder3 (may take a couple of minutes to load):\n\n\n\n\n\n\n\nPrepare\nBefore we begin, note that we can talk about generative ‘dungeons’ in the context of connected rooms, like in The Binding of Isaac, or more freeform structures, like world maps in Dwarf Fortress. We’re going for the latter, which amounts to interconnected caverns.\nThe function we’ll be using is called generate_dungeon(), which prints to the console a cavern that differs each time you run it.4 You can alter the output using the arguments:\n\niterations is the number of times to ‘grow’ the caverns\nn_row and n_col give the map dimensions\nn_rooms is the number of rooms to spawn\nis_snake for a cavern that is continuous from left to right and wiggly\nis_organic for a more freeform vs ‘square’ look to the caverns\ncolour to print the output in colour\n\nYou can always run set.seed() before generate_dungeon() to create the same dungeon every time you run the function with the same parameters.\n\n\nDemo\nSo here’s a smallish dungeon with 3 growth iterations for 4 starting rooms, on a map with tile dimensions of 20 rows by 30 columns.\n\ndungeon &lt;- r.oguelike::generate_dungeon(3, 20, 30, 4)\n\nHere’s a screenshot of the output so you can see it in colour.\n\n\n\nClick for the actual console output.\n\n| - - - - - - - - - - - - - - - - - - - - - - - - - - - - | \n| # # # # # # . # # # # # # # # # # # # # # # # # # # # # | \n| # # . # . . . . # # # # # . # # # # # # # # # # # # # # | \n| # . . . . # . . # # # . . . . # # # # # # # # # # # # # | \n| # . . . . . . . . . . . . . . . # # # # # # # # # # # # | \n| . . . # . . # . . # # . . . . . # # # # # # # # # # # # | \n| . . . . # # # . # # # # # . . # # # # # # # # # # # # # | \n| . . # # # # # # # # # # # . # # # # # # # # # # # # # # | \n| . . . . # # # # # # # # . . . # # # # # # # # # # # # # | \n| . . . . # # # # # # # # # . . # # # # # # # # # # # # # | \n| . . . # # # # # # # . # . . . # # # # # # # # # # # # # | \n| . . . # # # # # # . . . . . . . # # # # # # # # # # # # | \n| . . . # # . . # . . # . . . . . . . . . # . . . # # # # | \n| . . . . . . . . . . . . . . . . . . . . . . . . # # # # | \n| . . # # . . . # . # . . . # . . . # # . . # . . # # # # | \n| # # # # . . . # . # # # # # . # . # # # # . . . # # # # | \n| # # # # # # # # # # # # # # # # # # # # . . . . # # # # | \n| # # # # # # # # # # # # # # # # # # # # . . . # # # # # | \n| # # # # # # # # # # # # # # # # # # # # # # . # # # # # | \n| - - - - - - - - - - - - - - - - - - - - - - - - - - - - | \n\nSo, in this example you can see we have a little cavern with some interconnected areas and a dead-end in the lower right. The tiles represent:\n\ncavern-floor tiles (black periods), which is where the character can traverse\ncave wall tiles (red hashmarks, which can’t be passed through)\na boundary around the edge (yellow hyphens and pipe symbols)\n\nNote that the actual output from the function—a matrix that represents the dungeon tiles—is returned invisibly.\n\n\nClick for a preview of the returned matrix.\n\n\n# Preview first 10 rows and columns\ndungeon[1:10, 1:10]\n\n[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,] \"|\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \n[2,] \"|\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \".\"  \"#\"  \"#\"  \n[3,] \"|\"  \"#\"  \"#\"  \".\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \n[4,] \"|\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \"#\"  \n[5,] \"|\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \n[6,] \"|\"  \".\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \n[7,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \".\"  \"#\"  \n[8,] \"|\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n[9,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n[10,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n\n\n\nMore examples\nI think this process works best with a larger map grid (i.e. higher n_row and n_col values), more randomly-selected room start-points (higher n_rooms) and more growth steps (higher iterations).\nHere’s a larger maze-like dungeon:\n\nThis one came out more like a doughnut, with a central ‘pillar’ of rock-wall tiles:\n\nAnd this one is the result of using is_snake = TRUE, which creates a single, long snaking cavern:\n\nHere’s what happens if we set is_organic = FALSE and is_snake = TRUE. You get much obvious ‘rooms’ connected by small corridors:\n\nAnd if we set is_organic = FALSE and is_snake = FALSE we get something interconnected, but looks more ‘artificial’ or manmade with its mostly square walls:\n\nYou can see how the shape of these dungeons can be used as part of the storytelling. Is the player in a big cavern, hollowed out long ago by natural processes? Or perhaps in an underground city, chiselled-out by dwarves?"
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#proceed-the-procedure",
    "href": "posts/2022-05-01-dungeon/index.html#proceed-the-procedure",
    "title": "Simple procedural dungeons in R",
    "section": "Proceed the procedure",
    "text": "Proceed the procedure\nWhat’s the actual process for generating these maps? The procedure is very simple: lay a map made entirely of wall tiles; select random sites for rooms5 and replace with floor tiles; connect them with floor-tile corridors; expand the floor tiles generatively.\nThe corridors are particularly important. Laying corridors is a cheap way of making all areas of the dungeon accessible, which maximises the opportunity for exploration. Vanilla implementations of some other approaches, like using perlin noise, would need post-processing to make sure isolated caves are connected up.\n\n Note\nAfter publishing this post, I had a quick play around with perlin noise for seeding dungeons. I put code and an example output in a small GitHub Gist. It uses noise_perlin() from the {ambient} package.\n\n\nFunctions\nThese steps are handled in the generate_dungeon() function by a few sub-functions, which looks a bit like this:\n\nm &lt;- .create_dungeon(n_row, n_col, n_rooms)\n\nm &lt;- .connect_dungeon(m, is_snake)\n\ni &lt;- 0\n\nwhile (i &lt; iterations) {\n  m &lt;- .grow_dungeon(m)\n  i &lt;- i + 1\n}\n\n.draw_dungeon(m, colour)\n\nNot much right? But what’s actually happening?\n\nFirst, .create_dungeon():\n\nprepares a matrix with dimensions n_row and n_col\nfills the matrix with tiles that represent non-traversable rocky cave walls (#)\nselects randomly an n_rooms number of non-edge tiles in that map and replaces them with traversable cavern-floor tiles (.)\n\nThen .connect_dungeon() (this function is run now if is_organic = TRUE, otherwise after .grow_dungeon() in the next step):\n\nconnects rooms with straight, right-angled corridors made of floor tiles (connected from lowest to highest if is_snake = TRUE, otherwise randomly)\n\nNow the iterative bit, .grow_dungeon(), which happens in a while-loop whose iterations are determined, which:\n\nspawns randomly with sample() a new cavern-floor tile to the north, south, east or west or current floor tiles\nperforms one round of spawning for the number of iterations provided\n\nFinally, .draw_dungeon():\n\nprints to the console, using cat(), each line of the matrix in turn\ncolours the output with the {crayon} package, if requested\n\n\nAnd we can look at the output at each step to see what’s going on:\n\nSo, the map started with four randomly-selected floor tiles; these were joined with straight, right-angled corridors; then three iterations expanded out the floor space from the existing floor tiles.\n\n\nSampling\nWhat does it mean to ‘expand out the floor space’? Let’s focus on the little bit of the .grow_dungeon() function that actually does this.\nHere’s a tiny example matrix of wall tiles with a floor tile in the middle:\n\nm &lt;- matrix(\"#\", 3, 3)  # wall tiles\nm[2, 2] &lt;- \".\"  # floor tiles\nm\n\n     [,1] [,2] [,3]\n[1,] \"#\"  \"#\"  \"#\" \n[2,] \"#\"  \".\"  \"#\" \n[3,] \"#\"  \"#\"  \"#\" \n\n\nNow we find the adjacent tiles and sample a random number of them to also become floor tiles.\n\nstart_tile &lt;- which(m == \".\")\n\nadjacent_tiles &lt;- c(\n  start_tile - 1,        # north\n  start_tile + 1,        # south\n  start_tile - ncol(m),  # east \n  start_tile + ncol(m)   # west \n)\n\nchange_to_floor &lt;- sample(\n  adjacent_tiles,\n  sample(1:length(adjacent_tiles), 1)\n)\n\nm[change_to_floor] &lt;- \".\"\n\nm\n\n     [,1] [,2] [,3]\n[1,] \"#\"  \"#\"  \"#\" \n[2,] \".\"  \".\"  \"#\" \n[3,] \"#\"  \".\"  \"#\" \n\n\nSo one, two, three, or all of the adjacent tiles could be turned to a floor tile.\nThis is then repeated for the number of iterations provided by the user."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#going-deeper",
    "href": "posts/2022-05-01-dungeon/index.html#going-deeper",
    "title": "Simple procedural dungeons in R",
    "section": "Going deeper",
    "text": "Going deeper\nSo! I encourage you to play with this. Mess around with the arguments and see what you can come up with.\nWhat now for developing the package? Well, the {r.oguelike} package already has the rudiments of gameplay in the start_game() function, so the next step is to place the player, enemies and items into these dungeon spaces and let the player explore them.\nIdeally we can also create a system to place certain objects in certain spaces, like treasure in the far reaches of a dead-end, or a monster that’s in a narrow corridor and must be defeated to advance. Stuff like locked doors would be great too.\nThat’s much more roguelike-like, like, amirite?\n\n Note\nJust after writing this post, I added code from generate_dungeon() into start_game(), so new games will now start with a procedural dungeon. It seems to work pretty well."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#environment",
    "href": "posts/2022-05-01-dungeon/index.html#environment",
    "title": "Simple procedural dungeons in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:15:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] r.oguelike_0.1.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#footnotes",
    "href": "posts/2022-05-01-dungeon/index.html#footnotes",
    "title": "Simple procedural dungeons in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m not a computer scientist, but Wikipedia says ‘procedural’ involves ‘creating data algorithmically as opposed to manually, typically through a combination of human-generated assets and algorithms coupled with computer-generated randomness and processing power’. The page specifically points out roguelikes as having these properties, so I assume what I’ve done can be described as ‘procedural’?↩︎\nDefinitely one of these should be the name for your new band.↩︎\nThere’s no such thing as a free launch, unless it’s with Binder (why have I not thought of this incredible wordplay before and how much should I charge the Binder team for its use?).↩︎\nIn future, this function will be integrated into the start_game() function, but I may still export it so people (i.e. me) can use it for fun.↩︎\nAkshually, it’s not just a case of choosing a random set of four points within the length of the matrix. The 1D matrix is split n_rooms times and we sample from within each of those chunks. This, hopefully, should keep the dungeons relatively-well spread out.↩︎"
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html",
    "href": "posts/2018-10-13-sessioninfo/index.html",
    "title": "R session info info",
    "section": "",
    "text": "US Attorney-General Jeff Sessions-Info."
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#tldr",
    "href": "posts/2018-10-13-sessioninfo/index.html#tldr",
    "title": "R session info info",
    "section": "tl;dr",
    "text": "tl;dr\nYou can get information about your R session using several different functions."
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#session-info",
    "href": "posts/2018-10-13-sessioninfo/index.html#session-info",
    "title": "R session info info",
    "section": "Session info?",
    "text": "Session info?\n\nWhat\nSession info is just some details about your working environment like your version of R, the locale it’s running from and any loaded packages.\nIt gives a snapshot to help people reproduce what you’ve done or spot any anomalies. You might get asked for this if someone is diagnosing your R problem. You may also see it at the end of blog posts or reports.\nYou might typically print this to the console with the base function sessionInfo(), but it gives a lot of information by default. Other functions have been created to make the output more friendly.\n\n\nThis post\nI’ve been using sessionInfo(), but read about Yihui’s session_info() function in his {xfun} package and saw Mat at machinegurning.com using session_info() from {devtools}.\nI want to see the outputs side-by-side for my own curiosity."
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#load-packages",
    "href": "posts/2018-10-13-sessioninfo/index.html#load-packages",
    "title": "R session info info",
    "section": "Load packages",
    "text": "Load packages\nLet’s grab some packages from different sources to see how they’re represented in the output of each session info function.\n\n\nClick to expand package-installation details\n\n\n# From CRAN\n# install.packages(\"package-name\")\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyxl)\n\n# Dev versions of packages from rOpenSci\n# remotes::install_github(\"ropensci/packagename\")\nlibrary(rfishbase)\nlibrary(rgbif)\nlibrary(helminthR)\n\n# Bioconductor\n# Install instructions here: https://bioconductor.org/install/\n# BiocManager::install(c(\"GenomicFeatures\", \"AnnotationDbi\"))\nlibrary(GenomicFeatures)\nlibrary(AnnotationDbi)\n\n\nFor a bit of diversity, I’ve grabbed some packages from:\n\nCRAN – the typical source for R packages\nGitHub – for packages in development or that haven’t had a release anywhere else\nBioconductor – an open-dev project for packages ‘for the analysis and comprehension of high-throughput genomic data’"
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#functions-demo",
    "href": "posts/2018-10-13-sessioninfo/index.html#functions-demo",
    "title": "R session info info",
    "section": "Functions demo",
    "text": "Functions demo\nWe’ll be looking at:\n\n{utils}\n{devtools}\n{sessioninfo}\n{xfun}\n\nClick the package name to jump to that section.\n\n Note\nI later re-rendered this post, so the output from each function will show a date after the initial publication date of this post\n\n\n\n1. Using {utils}\nFrom the documentation for the function:\n\nPrint version information about R, the OS and attached or loaded packages.\n\nWhat do you get? Loads of stuff:\n\nR version, platform and OS\nmatrix products, BLAS and LAPACK\nlocale (where you’re running R from)\npackages – attached base packages, other attached packages, and loaded packages via namespace (but not attached) in separate sections with their version numbers\n\nMaybe that’s too much stuff. Also I don’t really know what the BLAS and LAPACK stuff is; something to do with linear algebra. There’s also no notation to say where the packages came from (CRAN, GitHub or Bioconductor). But it’s pretty human-readable.\n\n\nClick to expand the output from this function\n\n\nutils::sessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] GenomicFeatures_1.52.1 AnnotationDbi_1.62.2   Biobase_2.60.0        \n [4] GenomicRanges_1.52.0   GenomeInfoDb_1.36.1    IRanges_2.34.1        \n [7] S4Vectors_0.38.1       BiocGenerics_0.46.0    helminthR_1.0.10      \n[10] rgbif_3.7.7.2          rfishbase_4.1.2        tidyxl_1.0.8          \n[13] purrr_1.0.1            dplyr_1.1.2           \n\nloaded via a namespace (and not attached):\n [1] DBI_1.1.3                   bitops_1.0-7               \n [3] biomaRt_2.56.1              rlang_1.1.1                \n [5] magrittr_2.0.3              matrixStats_1.0.0          \n [7] compiler_4.3.1              RSQLite_2.3.1              \n [9] png_0.1-8                   vctrs_0.6.3                \n[11] rvest_1.0.3                 stringr_1.5.0              \n[13] pkgconfig_2.0.3             crayon_1.5.2               \n[15] fastmap_1.1.1               dbplyr_2.3.3               \n[17] XVector_0.40.0              fontawesome_0.5.1          \n[19] utf8_1.2.3                  Rsamtools_2.16.0           \n[21] rmarkdown_2.23              tzdb_0.4.0                 \n[23] bit_4.0.5                   xfun_0.39                  \n[25] zlibbioc_1.46.0             cachem_1.0.8               \n[27] jsonlite_1.8.7              progress_1.2.2             \n[29] blob_1.2.4                  DelayedArray_0.26.7        \n[31] BiocParallel_1.34.2         parallel_4.3.1             \n[33] prettyunits_1.1.1           R6_2.5.1                   \n[35] stringi_1.7.12              rtracklayer_1.60.0         \n[37] Rcpp_1.0.11                 SummarizedExperiment_1.30.2\n[39] knitr_1.43.1                readr_2.1.4                \n[41] Matrix_1.6-0                tidyselect_1.2.0           \n[43] rstudioapi_0.15.0           abind_1.4-5                \n[45] yaml_2.3.7                  codetools_0.2-19           \n[47] curl_5.0.1                  lattice_0.21-8             \n[49] tibble_3.2.1                plyr_1.8.8                 \n[51] KEGGREST_1.40.0             evaluate_0.21              \n[53] BiocFileCache_2.8.0         xml2_1.3.5                 \n[55] Biostrings_2.68.1           pillar_1.9.0               \n[57] filelock_1.0.2              MatrixGenerics_1.12.3      \n[59] whisker_0.4.1               generics_0.1.3             \n[61] RCurl_1.98-1.12             hms_1.1.3                  \n[63] ggplot2_3.4.2               munsell_0.5.0              \n[65] scales_1.2.1                glue_1.6.2                 \n[67] lazyeval_0.2.2              tools_4.3.1                \n[69] BiocIO_1.10.0               data.table_1.14.8          \n[71] GenomicAlignments_1.36.0    fs_1.6.3                   \n[73] XML_3.99-0.14               grid_4.3.1                 \n[75] colorspace_2.1-0            GenomeInfoDbData_1.2.10    \n[77] restfulr_0.0.15             cli_3.6.1                  \n[79] rappdirs_0.3.3              fansi_1.0.4                \n[81] S4Arrays_1.0.5              gtable_0.3.3               \n[83] oai_0.4.0                   digest_0.6.33              \n[85] rjson_0.2.21                htmlwidgets_1.6.2          \n[87] memoise_2.0.1               htmltools_0.5.5            \n[89] lifecycle_1.0.3             httr_1.4.6                 \n[91] bit64_4.0.5                \n\n\n\n\n\n2. Using {devtools}\nFrom the documentation for the function:\n\nThis is sessionInfo() re-written from scratch to both exclude data that’s rarely useful (e.g., the full collate string or base packages loaded) and include stuff you’d like to know (e.g., where a package was installed from).\n\nWhat do you get? You get basically what’s in sessionInfo()\n\nsections split into ‘session info’ and ‘packages’\nversion, system, UI, language, locale, timezone and date\npackage names with version number, date and source (CRAN, Bioconductor, GitHub, local)\n\nIt’s even more human-readable in the packages section, where the output is in table format and in alphabetical order. In particular, there’s a column to tell you where the package came from. For example, see how the {helminthR} package is from github (ropensci/helminthR@549957a) (i.e. the development version with a specific Git ref hash) and there’s an asterisk in the row to show you it was attached in the session.\n\n\nClick to expand the output from this function\n\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       macOS Ventura 13.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2023-08-08\n pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package              * version   date (UTC) lib source\n abind                  1.4-5     2016-07-21 [1] CRAN (R 4.3.0)\n AnnotationDbi        * 1.62.2    2023-07-02 [1] Bioconductor\n Biobase              * 2.60.0    2023-05-08 [1] Bioconductor\n BiocFileCache          2.8.0     2023-05-08 [1] Bioconductor\n BiocGenerics         * 0.46.0    2023-06-04 [1] Bioconductor\n BiocIO                 1.10.0    2023-05-08 [1] Bioconductor\n BiocParallel           1.34.2    2023-05-28 [1] Bioconductor\n biomaRt                2.56.1    2023-06-11 [1] Bioconductor\n Biostrings             2.68.1    2023-05-21 [1] Bioconductor\n bit                    4.0.5     2022-11-15 [1] CRAN (R 4.3.0)\n bit64                  4.0.5     2020-08-30 [1] CRAN (R 4.3.0)\n bitops                 1.0-7     2021-04-24 [1] CRAN (R 4.3.0)\n blob                   1.2.4     2023-03-17 [1] CRAN (R 4.3.0)\n cachem                 1.0.8     2023-05-01 [1] CRAN (R 4.3.0)\n callr                  3.7.3     2022-11-02 [1] CRAN (R 4.3.0)\n cli                    3.6.1     2023-03-23 [1] CRAN (R 4.3.0)\n codetools              0.2-19    2023-02-01 [1] CRAN (R 4.3.1)\n colorspace             2.1-0     2023-01-23 [1] CRAN (R 4.3.0)\n crayon                 1.5.2     2022-09-29 [1] CRAN (R 4.3.0)\n curl                   5.0.1     2023-06-07 [1] CRAN (R 4.3.0)\n data.table             1.14.8    2023-02-17 [1] CRAN (R 4.3.0)\n DBI                    1.1.3     2022-06-18 [1] CRAN (R 4.3.0)\n dbplyr                 2.3.3     2023-07-07 [1] CRAN (R 4.3.0)\n DelayedArray           0.26.7    2023-07-30 [1] Bioconductor\n devtools               2.4.5     2022-10-11 [1] CRAN (R 4.3.0)\n digest                 0.6.33    2023-07-07 [1] CRAN (R 4.3.0)\n dplyr                * 1.1.2     2023-04-20 [1] CRAN (R 4.3.0)\n ellipsis               0.3.2     2021-04-29 [1] CRAN (R 4.3.0)\n evaluate               0.21      2023-05-05 [1] CRAN (R 4.3.0)\n fansi                  1.0.4     2023-01-22 [1] CRAN (R 4.3.0)\n fastmap                1.1.1     2023-02-24 [1] CRAN (R 4.3.0)\n filelock               1.0.2     2018-10-05 [1] CRAN (R 4.3.0)\n fontawesome            0.5.1     2023-04-18 [1] CRAN (R 4.3.0)\n fs                     1.6.3     2023-07-20 [1] CRAN (R 4.3.0)\n generics               0.1.3     2022-07-05 [1] CRAN (R 4.3.0)\n GenomeInfoDb         * 1.36.1    2023-07-02 [1] Bioconductor\n GenomeInfoDbData       1.2.10    2023-08-08 [1] Bioconductor\n GenomicAlignments      1.36.0    2023-05-08 [1] Bioconductor\n GenomicFeatures      * 1.52.1    2023-07-02 [1] Bioconductor\n GenomicRanges        * 1.52.0    2023-05-08 [1] Bioconductor\n ggplot2                3.4.2     2023-04-03 [1] CRAN (R 4.3.0)\n glue                   1.6.2     2022-02-24 [1] CRAN (R 4.3.0)\n gtable                 0.3.3     2023-03-21 [1] CRAN (R 4.3.0)\n helminthR            * 1.0.10    2023-08-08 [1] Github (ropensci/helminthR@549957a)\n hms                    1.1.3     2023-03-21 [1] CRAN (R 4.3.0)\n htmltools              0.5.5     2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets            1.6.2     2023-03-17 [1] CRAN (R 4.3.0)\n httpuv                 1.6.11    2023-05-11 [1] CRAN (R 4.3.0)\n httr                   1.4.6     2023-05-08 [1] CRAN (R 4.3.0)\n IRanges              * 2.34.1    2023-07-02 [1] Bioconductor\n jsonlite               1.8.7     2023-06-29 [1] CRAN (R 4.3.0)\n KEGGREST               1.40.0    2023-05-08 [1] Bioconductor\n knitr                  1.43.1    2023-06-21 [1] https://yihui.r-universe.dev (R 4.3.1)\n later                  1.3.1     2023-05-02 [1] CRAN (R 4.3.0)\n lattice                0.21-8    2023-04-05 [1] CRAN (R 4.3.1)\n lazyeval               0.2.2     2019-03-15 [1] CRAN (R 4.3.0)\n lifecycle              1.0.3     2022-10-07 [1] CRAN (R 4.3.0)\n magrittr               2.0.3     2022-03-30 [1] CRAN (R 4.3.0)\n Matrix                 1.6-0     2023-07-08 [1] CRAN (R 4.3.0)\n MatrixGenerics         1.12.3    2023-07-30 [1] Bioconductor\n matrixStats            1.0.0     2023-06-02 [1] CRAN (R 4.3.0)\n memoise                2.0.1     2021-11-26 [1] CRAN (R 4.3.0)\n mime                   0.12      2021-09-28 [1] CRAN (R 4.3.0)\n miniUI                 0.1.1.1   2018-05-18 [1] CRAN (R 4.3.0)\n munsell                0.5.0     2018-06-12 [1] CRAN (R 4.3.0)\n oai                    0.4.0     2022-11-10 [1] CRAN (R 4.3.0)\n pillar                 1.9.0     2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild               1.4.2     2023-06-26 [1] CRAN (R 4.3.0)\n pkgconfig              2.0.3     2019-09-22 [1] CRAN (R 4.3.0)\n pkgload                1.3.2.1   2023-07-08 [1] CRAN (R 4.3.0)\n plyr                   1.8.8     2022-11-11 [1] CRAN (R 4.3.0)\n png                    0.1-8     2022-11-29 [1] CRAN (R 4.3.0)\n prettyunits            1.1.1     2020-01-24 [1] CRAN (R 4.3.0)\n processx               3.8.2     2023-06-30 [1] CRAN (R 4.3.0)\n profvis                0.3.8     2023-05-02 [1] CRAN (R 4.3.0)\n progress               1.2.2     2019-05-16 [1] CRAN (R 4.3.0)\n promises               1.2.0.1   2021-02-11 [1] CRAN (R 4.3.0)\n ps                     1.7.5     2023-04-18 [1] CRAN (R 4.3.0)\n purrr                * 1.0.1     2023-01-10 [1] CRAN (R 4.3.0)\n R6                     2.5.1     2021-08-19 [1] CRAN (R 4.3.0)\n rappdirs               0.3.3     2021-01-31 [1] CRAN (R 4.3.0)\n Rcpp                   1.0.11    2023-07-06 [1] CRAN (R 4.3.0)\n RCurl                  1.98-1.12 2023-03-27 [1] CRAN (R 4.3.0)\n readr                  2.1.4     2023-02-10 [1] CRAN (R 4.3.0)\n remotes                2.4.2.1   2023-07-18 [1] CRAN (R 4.3.0)\n restfulr               0.0.15    2022-06-16 [1] CRAN (R 4.3.0)\n rfishbase            * 4.1.2     2023-06-02 [1] CRAN (R 4.3.0)\n rgbif                * 3.7.7.2   2023-08-08 [1] Github (ropensci/rgbif@3bdfdb2)\n rjson                  0.2.21    2022-01-09 [1] CRAN (R 4.3.0)\n rlang                  1.1.1     2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown              2.23      2023-07-01 [1] CRAN (R 4.3.0)\n Rsamtools              2.16.0    2023-06-04 [1] Bioconductor\n RSQLite                2.3.1     2023-04-03 [1] CRAN (R 4.3.0)\n rstudioapi             0.15.0    2023-07-07 [1] CRAN (R 4.3.0)\n rtracklayer            1.60.0    2023-05-08 [1] Bioconductor\n rvest                  1.0.3     2022-08-19 [1] CRAN (R 4.3.0)\n S4Arrays               1.0.5     2023-07-30 [1] Bioconductor\n S4Vectors            * 0.38.1    2023-05-08 [1] Bioconductor\n scales                 1.2.1     2022-08-20 [1] CRAN (R 4.3.0)\n sessioninfo            1.2.2     2021-12-06 [1] CRAN (R 4.3.0)\n shiny                  1.7.4.1   2023-07-06 [1] CRAN (R 4.3.0)\n stringi                1.7.12    2023-01-11 [1] CRAN (R 4.3.0)\n stringr                1.5.0     2022-12-02 [1] CRAN (R 4.3.0)\n SummarizedExperiment   1.30.2    2023-06-11 [1] Bioconductor\n tibble                 3.2.1     2023-03-20 [1] CRAN (R 4.3.0)\n tidyselect             1.2.0     2022-10-10 [1] CRAN (R 4.3.0)\n tidyxl               * 1.0.8     2022-09-01 [1] CRAN (R 4.3.0)\n tzdb                   0.4.0     2023-05-12 [1] CRAN (R 4.3.0)\n urlchecker             1.0.1     2021-11-30 [1] CRAN (R 4.3.0)\n usethis                2.2.2     2023-07-06 [1] CRAN (R 4.3.0)\n utf8                   1.2.3     2023-01-31 [1] CRAN (R 4.3.0)\n vctrs                  0.6.3     2023-06-14 [1] CRAN (R 4.3.0)\n whisker                0.4.1     2022-12-05 [1] CRAN (R 4.3.0)\n xfun                   0.39      2023-04-20 [1] CRAN (R 4.3.0)\n XML                    3.99-0.14 2023-03-19 [1] CRAN (R 4.3.0)\n xml2                   1.3.5     2023-07-06 [1] CRAN (R 4.3.0)\n xtable                 1.8-4     2019-04-21 [1] CRAN (R 4.3.0)\n XVector                0.40.0    2023-05-08 [1] Bioconductor\n yaml                   2.3.7     2023-01-23 [1] CRAN (R 4.3.0)\n zlibbioc               1.46.0    2023-05-08 [1] Bioconductor\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n3. Using {sessioninfo}\nFrom the CRAN page for the package:\n\nIt is similar to utils::sessionInfo(), but includes more information about packages, and where they were installed from.\n\nWhat do you get? Basically the same as utils::sessionInfo(). Note that the final column of output – the source column is wrapped below.\n\n\nClick to expand the output from this function\n\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       macOS Ventura 13.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2023-08-08\n pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package              * version   date (UTC) lib source\n abind                  1.4-5     2016-07-21 [1] CRAN (R 4.3.0)\n AnnotationDbi        * 1.62.2    2023-07-02 [1] Bioconductor\n Biobase              * 2.60.0    2023-05-08 [1] Bioconductor\n BiocFileCache          2.8.0     2023-05-08 [1] Bioconductor\n BiocGenerics         * 0.46.0    2023-06-04 [1] Bioconductor\n BiocIO                 1.10.0    2023-05-08 [1] Bioconductor\n BiocParallel           1.34.2    2023-05-28 [1] Bioconductor\n biomaRt                2.56.1    2023-06-11 [1] Bioconductor\n Biostrings             2.68.1    2023-05-21 [1] Bioconductor\n bit                    4.0.5     2022-11-15 [1] CRAN (R 4.3.0)\n bit64                  4.0.5     2020-08-30 [1] CRAN (R 4.3.0)\n bitops                 1.0-7     2021-04-24 [1] CRAN (R 4.3.0)\n blob                   1.2.4     2023-03-17 [1] CRAN (R 4.3.0)\n cachem                 1.0.8     2023-05-01 [1] CRAN (R 4.3.0)\n callr                  3.7.3     2022-11-02 [1] CRAN (R 4.3.0)\n cli                    3.6.1     2023-03-23 [1] CRAN (R 4.3.0)\n codetools              0.2-19    2023-02-01 [1] CRAN (R 4.3.1)\n colorspace             2.1-0     2023-01-23 [1] CRAN (R 4.3.0)\n crayon                 1.5.2     2022-09-29 [1] CRAN (R 4.3.0)\n curl                   5.0.1     2023-06-07 [1] CRAN (R 4.3.0)\n data.table             1.14.8    2023-02-17 [1] CRAN (R 4.3.0)\n DBI                    1.1.3     2022-06-18 [1] CRAN (R 4.3.0)\n dbplyr                 2.3.3     2023-07-07 [1] CRAN (R 4.3.0)\n DelayedArray           0.26.7    2023-07-30 [1] Bioconductor\n devtools               2.4.5     2022-10-11 [1] CRAN (R 4.3.0)\n digest                 0.6.33    2023-07-07 [1] CRAN (R 4.3.0)\n dplyr                * 1.1.2     2023-04-20 [1] CRAN (R 4.3.0)\n ellipsis               0.3.2     2021-04-29 [1] CRAN (R 4.3.0)\n evaluate               0.21      2023-05-05 [1] CRAN (R 4.3.0)\n fansi                  1.0.4     2023-01-22 [1] CRAN (R 4.3.0)\n fastmap                1.1.1     2023-02-24 [1] CRAN (R 4.3.0)\n filelock               1.0.2     2018-10-05 [1] CRAN (R 4.3.0)\n fontawesome            0.5.1     2023-04-18 [1] CRAN (R 4.3.0)\n fs                     1.6.3     2023-07-20 [1] CRAN (R 4.3.0)\n generics               0.1.3     2022-07-05 [1] CRAN (R 4.3.0)\n GenomeInfoDb         * 1.36.1    2023-07-02 [1] Bioconductor\n GenomeInfoDbData       1.2.10    2023-08-08 [1] Bioconductor\n GenomicAlignments      1.36.0    2023-05-08 [1] Bioconductor\n GenomicFeatures      * 1.52.1    2023-07-02 [1] Bioconductor\n GenomicRanges        * 1.52.0    2023-05-08 [1] Bioconductor\n ggplot2                3.4.2     2023-04-03 [1] CRAN (R 4.3.0)\n glue                   1.6.2     2022-02-24 [1] CRAN (R 4.3.0)\n gtable                 0.3.3     2023-03-21 [1] CRAN (R 4.3.0)\n helminthR            * 1.0.10    2023-08-08 [1] Github (ropensci/helminthR@549957a)\n hms                    1.1.3     2023-03-21 [1] CRAN (R 4.3.0)\n htmltools              0.5.5     2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets            1.6.2     2023-03-17 [1] CRAN (R 4.3.0)\n httpuv                 1.6.11    2023-05-11 [1] CRAN (R 4.3.0)\n httr                   1.4.6     2023-05-08 [1] CRAN (R 4.3.0)\n IRanges              * 2.34.1    2023-07-02 [1] Bioconductor\n jsonlite               1.8.7     2023-06-29 [1] CRAN (R 4.3.0)\n KEGGREST               1.40.0    2023-05-08 [1] Bioconductor\n knitr                  1.43.1    2023-06-21 [1] https://yihui.r-universe.dev (R 4.3.1)\n later                  1.3.1     2023-05-02 [1] CRAN (R 4.3.0)\n lattice                0.21-8    2023-04-05 [1] CRAN (R 4.3.1)\n lazyeval               0.2.2     2019-03-15 [1] CRAN (R 4.3.0)\n lifecycle              1.0.3     2022-10-07 [1] CRAN (R 4.3.0)\n magrittr               2.0.3     2022-03-30 [1] CRAN (R 4.3.0)\n Matrix                 1.6-0     2023-07-08 [1] CRAN (R 4.3.0)\n MatrixGenerics         1.12.3    2023-07-30 [1] Bioconductor\n matrixStats            1.0.0     2023-06-02 [1] CRAN (R 4.3.0)\n memoise                2.0.1     2021-11-26 [1] CRAN (R 4.3.0)\n mime                   0.12      2021-09-28 [1] CRAN (R 4.3.0)\n miniUI                 0.1.1.1   2018-05-18 [1] CRAN (R 4.3.0)\n munsell                0.5.0     2018-06-12 [1] CRAN (R 4.3.0)\n oai                    0.4.0     2022-11-10 [1] CRAN (R 4.3.0)\n pillar                 1.9.0     2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild               1.4.2     2023-06-26 [1] CRAN (R 4.3.0)\n pkgconfig              2.0.3     2019-09-22 [1] CRAN (R 4.3.0)\n pkgload                1.3.2.1   2023-07-08 [1] CRAN (R 4.3.0)\n plyr                   1.8.8     2022-11-11 [1] CRAN (R 4.3.0)\n png                    0.1-8     2022-11-29 [1] CRAN (R 4.3.0)\n prettyunits            1.1.1     2020-01-24 [1] CRAN (R 4.3.0)\n processx               3.8.2     2023-06-30 [1] CRAN (R 4.3.0)\n profvis                0.3.8     2023-05-02 [1] CRAN (R 4.3.0)\n progress               1.2.2     2019-05-16 [1] CRAN (R 4.3.0)\n promises               1.2.0.1   2021-02-11 [1] CRAN (R 4.3.0)\n ps                     1.7.5     2023-04-18 [1] CRAN (R 4.3.0)\n purrr                * 1.0.1     2023-01-10 [1] CRAN (R 4.3.0)\n R6                     2.5.1     2021-08-19 [1] CRAN (R 4.3.0)\n rappdirs               0.3.3     2021-01-31 [1] CRAN (R 4.3.0)\n Rcpp                   1.0.11    2023-07-06 [1] CRAN (R 4.3.0)\n RCurl                  1.98-1.12 2023-03-27 [1] CRAN (R 4.3.0)\n readr                  2.1.4     2023-02-10 [1] CRAN (R 4.3.0)\n remotes                2.4.2.1   2023-07-18 [1] CRAN (R 4.3.0)\n restfulr               0.0.15    2022-06-16 [1] CRAN (R 4.3.0)\n rfishbase            * 4.1.2     2023-06-02 [1] CRAN (R 4.3.0)\n rgbif                * 3.7.7.2   2023-08-08 [1] Github (ropensci/rgbif@3bdfdb2)\n rjson                  0.2.21    2022-01-09 [1] CRAN (R 4.3.0)\n rlang                  1.1.1     2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown              2.23      2023-07-01 [1] CRAN (R 4.3.0)\n Rsamtools              2.16.0    2023-06-04 [1] Bioconductor\n RSQLite                2.3.1     2023-04-03 [1] CRAN (R 4.3.0)\n rstudioapi             0.15.0    2023-07-07 [1] CRAN (R 4.3.0)\n rtracklayer            1.60.0    2023-05-08 [1] Bioconductor\n rvest                  1.0.3     2022-08-19 [1] CRAN (R 4.3.0)\n S4Arrays               1.0.5     2023-07-30 [1] Bioconductor\n S4Vectors            * 0.38.1    2023-05-08 [1] Bioconductor\n scales                 1.2.1     2022-08-20 [1] CRAN (R 4.3.0)\n sessioninfo            1.2.2     2021-12-06 [1] CRAN (R 4.3.0)\n shiny                  1.7.4.1   2023-07-06 [1] CRAN (R 4.3.0)\n stringi                1.7.12    2023-01-11 [1] CRAN (R 4.3.0)\n stringr                1.5.0     2022-12-02 [1] CRAN (R 4.3.0)\n SummarizedExperiment   1.30.2    2023-06-11 [1] Bioconductor\n tibble                 3.2.1     2023-03-20 [1] CRAN (R 4.3.0)\n tidyselect             1.2.0     2022-10-10 [1] CRAN (R 4.3.0)\n tidyxl               * 1.0.8     2022-09-01 [1] CRAN (R 4.3.0)\n tzdb                   0.4.0     2023-05-12 [1] CRAN (R 4.3.0)\n urlchecker             1.0.1     2021-11-30 [1] CRAN (R 4.3.0)\n usethis                2.2.2     2023-07-06 [1] CRAN (R 4.3.0)\n utf8                   1.2.3     2023-01-31 [1] CRAN (R 4.3.0)\n vctrs                  0.6.3     2023-06-14 [1] CRAN (R 4.3.0)\n whisker                0.4.1     2022-12-05 [1] CRAN (R 4.3.0)\n xfun                   0.39      2023-04-20 [1] CRAN (R 4.3.0)\n XML                    3.99-0.14 2023-03-19 [1] CRAN (R 4.3.0)\n xml2                   1.3.5     2023-07-06 [1] CRAN (R 4.3.0)\n xtable                 1.8-4     2019-04-21 [1] CRAN (R 4.3.0)\n XVector                0.40.0    2023-05-08 [1] Bioconductor\n yaml                   2.3.7     2023-01-23 [1] CRAN (R 4.3.0)\n zlibbioc               1.46.0    2023-05-08 [1] Bioconductor\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n4. Using {xfun}\nFrom Yihui Xie’s Introduction to {xfun} page:\n\n…it is rarely useful to print out the names of base R packages, or information about the matrix products / BLAS / LAPACK. Often times I want additional information in the session information, such as the Pandoc version when rmarkdown is used.\n\nWhat do you get? Basically utils::sessionInfo() but no matrix products, BLAS or LAPACK info, plus all the packages are listed together with their version numbers. You also can’t see where the package came from (CRAN, GitHub or Bioconductor). It lacks some human-readability compared to the functions in {devtools} and {sessioninfo}, but is clearly enough for Yihui – his package contains ‘miscellaneous functions that [he] use[s] by [him]self from time to time’.\n\n\nClick to expand the output from this function\n\n\nxfun::session_info()\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\n\nLocale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nPackage version:\n  abind_1.4-5                 AnnotationDbi_1.62.2       \n  ape_5.7.1                   askpass_1.1                \n  assertthat_0.2.1            backports_1.4.1            \n  base64enc_0.1.3             BH_1.81.0.1                \n  Biobase_2.60.0              BiocFileCache_2.8.0        \n  BiocGenerics_0.46.0         BiocIO_1.10.0              \n  BiocParallel_1.34.2         biomaRt_2.56.1             \n  Biostrings_2.68.1           bit_4.0.5                  \n  bit64_4.0.5                 bitops_1.0-7               \n  blob_1.2.4                  bold_1.3.0                 \n  brew_1.0.8                  brio_1.1.3                 \n  bslib_0.5.0                 cachem_1.0.8               \n  callr_3.7.3                 checkmate_2.2.0            \n  cli_3.6.1                   clipr_0.8.0                \n  cluster_2.1.4               codetools_0.2-19           \n  colorspace_2.1-0            commonmark_1.9.0           \n  compiler_4.3.1              conditionz_0.1.0           \n  contentid_0.0.17            cpp11_0.4.5                \n  crayon_1.5.2                credentials_1.3.2          \n  crul_1.4.0                  curl_5.0.1                 \n  data.table_1.14.8           DBI_1.1.3                  \n  dbplyr_2.3.3                DelayedArray_0.26.7        \n  desc_1.4.2                  devtools_2.4.5             \n  diffobj_0.3.5               digest_0.6.33              \n  downlit_0.4.3               dplyr_1.1.2                \n  duckdb_0.8.1.1              ellipsis_0.3.2             \n  evaluate_0.21               fansi_1.0.4                \n  farver_2.1.1                fastmap_1.1.1              \n  fastmatch_1.1.3             filelock_1.0.2             \n  fontawesome_0.5.1           foreach_1.5.2              \n  foreign_0.8.84              formatR_1.14               \n  Formula_1.2.5               fs_1.6.3                   \n  futile.logger_1.4.3         futile.options_1.0.1       \n  generics_0.1.3              GenomeInfoDb_1.36.1        \n  GenomeInfoDbData_1.2.10     GenomicAlignments_1.36.0   \n  GenomicFeatures_1.52.1      GenomicRanges_1.52.0       \n  gert_1.9.3                  ggplot2_3.4.2              \n  gh_1.4.0                    gitcreds_0.1.2             \n  glue_1.6.2                  graphics_4.3.1             \n  grDevices_4.3.1             grid_4.3.1                 \n  gridExtra_2.3               gtable_0.3.3               \n  helminthR_1.0.10            highr_0.10                 \n  Hmisc_5.1.0                 hms_1.1.3                  \n  htmlTable_2.4.1             htmltools_0.5.5            \n  htmlwidgets_1.6.2           httpcode_0.3.0             \n  httpuv_1.6.11               httr_1.4.6                 \n  httr2_0.2.3                 igraph_1.5.0.1             \n  ini_0.3.1                   IRanges_2.34.1             \n  isoband_0.2.7               iterators_1.0.14           \n  jquerylib_0.1.4             jsonlite_1.8.7             \n  KEGGREST_1.40.0             knitr_1.43.1               \n  labeling_0.4.2              lambda.r_1.2.4             \n  later_1.3.1                 lattice_0.21-8             \n  lazyeval_0.2.2              lifecycle_1.0.3            \n  magrittr_2.0.3              MASS_7.3.60                \n  Matrix_1.6-0                MatrixGenerics_1.12.3      \n  matrixStats_1.0.0           memoise_2.0.1              \n  methods_4.3.1               mgcv_1.9.0                 \n  mime_0.12                   miniUI_0.1.1.1             \n  munsell_0.5.0               natserv_1.0.0              \n  nlme_3.1.162                nnet_7.3.19                \n  oai_0.4.0                   openssl_2.1.0              \n  parallel_4.3.1              pbapply_1.7.2              \n  phangorn_2.11.1             pillar_1.9.0               \n  piton_1.0.0                 pkgbuild_1.4.2             \n  pkgconfig_2.0.3             pkgdown_2.0.7              \n  pkgload_1.3.2.1             plogr_0.2.0                \n  plyr_1.8.8                  png_0.1-8                  \n  praise_1.0.0                prettyunits_1.1.1          \n  processx_3.8.2              profvis_0.3.8              \n  progress_1.2.2              promises_1.2.0.1           \n  ps_1.7.5                    purrr_1.0.1                \n  quadprog_1.5.8              R6_2.5.1                   \n  ragg_1.2.5                  rappdirs_0.3.3             \n  ratelimitr_0.4.1            rcmdcheck_1.4.0            \n  RColorBrewer_1.1.3          Rcpp_1.0.11                \n  RCurl_1.98-1.12             readr_2.1.4                \n  rematch2_2.1.2              remotes_2.4.2.1            \n  rentrez_1.2.3               restfulr_0.0.15            \n  rex_1.2.1                   rfishbase_4.1.2            \n  rgbif_3.7.7.2               Rhtslib_2.2.0              \n  ritis_1.0.0                 rjson_0.2.21               \n  rlang_1.1.1                 rmarkdown_2.23             \n  rncl_0.8.7                  rotl_3.1.0                 \n  roxygen2_7.2.3              rpart_4.1.19               \n  rprojroot_2.0.3             rredlist_0.7.1             \n  Rsamtools_2.16.0            RSQLite_2.3.1              \n  rstudioapi_0.15.0           rtracklayer_1.60.0         \n  rversions_2.1.2             rvest_1.0.3                \n  S4Arrays_1.0.5              S4Vectors_0.38.1           \n  sass_0.4.7                  scales_1.2.1               \n  selectr_0.4.2               sessioninfo_1.2.2          \n  shiny_1.7.4.1               snow_0.4.4                 \n  solrium_1.2.0               sourcetools_0.1.7.1        \n  splines_4.3.1               stats_4.3.1                \n  stats4_4.3.1                stringi_1.7.12             \n  stringr_1.5.0               SummarizedExperiment_1.30.2\n  sys_3.4.2                   systemfonts_1.0.4          \n  taxize_0.9.100              testthat_3.1.10            \n  textshaping_0.3.6           tibble_3.2.1               \n  tidyr_1.3.0                 tidyselect_1.2.0           \n  tidyxl_1.0.8                tinytex_0.45               \n  tools_4.3.1                 triebeard_0.4.1            \n  tzdb_0.4.0                  urlchecker_1.0.1           \n  urltools_1.7.3              usethis_2.2.2              \n  utf8_1.2.3                  utils_4.3.1                \n  uuid_1.1.0                  vctrs_0.6.3                \n  viridis_0.6.4               viridisLite_0.4.2          \n  vroom_1.6.3                 waldo_0.5.1                \n  whisker_0.4.1               WikidataQueryServiceR_1.0.0\n  WikidataR_2.3.3             WikipediR_1.5.0            \n  wikitaxa_0.4.0              withr_2.5.0                \n  wk_0.7.3                    worrms_0.4.3               \n  xfun_0.39                   XML_3.99-0.14              \n  xml2_1.3.5                  xopen_1.0.0                \n  xtable_1.8-4                XVector_0.40.0             \n  yaml_2.3.7                  zip_2.3.0                  \n  zlibbioc_1.46.0             zoo_1.8.12"
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#conclusion",
    "href": "posts/2018-10-13-sessioninfo/index.html#conclusion",
    "title": "R session info info",
    "section": "Conclusion",
    "text": "Conclusion\nYep, they basically do the same thing with slight differences. I personally like the idea of having some kind of table-like output for easy readability, so I’ll probably go with {devtools} as I often have it loaded anyway."
  },
  {
    "objectID": "posts/2018-10-13-sessioninfo/index.html#environment",
    "href": "posts/2018-10-13-sessioninfo/index.html#environment",
    "title": "R session info info",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 12:48:07 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] GenomicFeatures_1.52.1 AnnotationDbi_1.62.2   Biobase_2.60.0        \n [4] GenomicRanges_1.52.0   GenomeInfoDb_1.36.1    IRanges_2.34.1        \n [7] S4Vectors_0.38.1       BiocGenerics_0.46.0    helminthR_1.0.10      \n[10] rgbif_3.7.7.2          rfishbase_4.1.2        tidyxl_1.0.8          \n[13] purrr_1.0.1            dplyr_1.1.2           \n\nloaded via a namespace (and not attached):\n  [1] DBI_1.1.3                   bitops_1.0-7               \n  [3] remotes_2.4.2.1             biomaRt_2.56.1             \n  [5] rlang_1.1.1                 magrittr_2.0.3             \n  [7] matrixStats_1.0.0           compiler_4.3.1             \n  [9] RSQLite_2.3.1               callr_3.7.3                \n [11] png_0.1-8                   vctrs_0.6.3                \n [13] profvis_0.3.8               rvest_1.0.3                \n [15] stringr_1.5.0               pkgconfig_2.0.3            \n [17] crayon_1.5.2                fastmap_1.1.1              \n [19] ellipsis_0.3.2              dbplyr_2.3.3               \n [21] XVector_0.40.0              fontawesome_0.5.1          \n [23] utf8_1.2.3                  promises_1.2.0.1           \n [25] Rsamtools_2.16.0            rmarkdown_2.23             \n [27] sessioninfo_1.2.2           tzdb_0.4.0                 \n [29] ps_1.7.5                    bit_4.0.5                  \n [31] xfun_0.39                   zlibbioc_1.46.0            \n [33] cachem_1.0.8                jsonlite_1.8.7             \n [35] progress_1.2.2              blob_1.2.4                 \n [37] later_1.3.1                 DelayedArray_0.26.7        \n [39] BiocParallel_1.34.2         parallel_4.3.1             \n [41] prettyunits_1.1.1           R6_2.5.1                   \n [43] stringi_1.7.12              rtracklayer_1.60.0         \n [45] pkgload_1.3.2.1             Rcpp_1.0.11                \n [47] SummarizedExperiment_1.30.2 knitr_1.43.1               \n [49] usethis_2.2.2               readr_2.1.4                \n [51] httpuv_1.6.11               Matrix_1.6-0               \n [53] tidyselect_1.2.0            rstudioapi_0.15.0          \n [55] abind_1.4-5                 yaml_2.3.7                 \n [57] miniUI_0.1.1.1              codetools_0.2-19           \n [59] processx_3.8.2              curl_5.0.1                 \n [61] pkgbuild_1.4.2              lattice_0.21-8             \n [63] tibble_3.2.1                plyr_1.8.8                 \n [65] shiny_1.7.4.1               KEGGREST_1.40.0            \n [67] evaluate_0.21               urlchecker_1.0.1           \n [69] BiocFileCache_2.8.0         xml2_1.3.5                 \n [71] Biostrings_2.68.1           pillar_1.9.0               \n [73] filelock_1.0.2              MatrixGenerics_1.12.3      \n [75] whisker_0.4.1               generics_0.1.3             \n [77] RCurl_1.98-1.12             hms_1.1.3                  \n [79] ggplot2_3.4.2               munsell_0.5.0              \n [81] scales_1.2.1                xtable_1.8-4               \n [83] glue_1.6.2                  lazyeval_0.2.2             \n [85] tools_4.3.1                 BiocIO_1.10.0              \n [87] data.table_1.14.8           GenomicAlignments_1.36.0   \n [89] fs_1.6.3                    XML_3.99-0.14              \n [91] grid_4.3.1                  devtools_2.4.5             \n [93] colorspace_2.1-0            GenomeInfoDbData_1.2.10    \n [95] restfulr_0.0.15             cli_3.6.1                  \n [97] rappdirs_0.3.3              fansi_1.0.4                \n [99] S4Arrays_1.0.5              gtable_0.3.3               \n[101] oai_0.4.0                   digest_0.6.33              \n[103] rjson_0.2.21                htmlwidgets_1.6.2          \n[105] memoise_2.0.1               htmltools_0.5.5            \n[107] lifecycle_1.0.3             httr_1.4.6                 \n[109] mime_0.12                   bit64_4.0.5"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#tldr",
    "href": "posts/2021-08-27-zzz/index.html#tldr",
    "title": "Exploring R package startup messages",
    "section": "tl;dr",
    "text": "tl;dr\nI got curious about R package startup messages, so I grabbed all the special zzz.R files from R packages that are on CRAN and sourced on GitHub. You can jump to the table of results."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#start-me-up",
    "href": "posts/2021-08-27-zzz/index.html#start-me-up",
    "title": "Exploring R package startup messages",
    "section": "Start me up",
    "text": "Start me up\nI learnt recently from Hernando Cortina that his and Amanda Dobbyn’s {multicolor} package prints to the console some multicoloured ASCII-art text of the package’s name when you call it with library(multicolor).\nIt gave me an itch to scratch: how often are these sorts of startup messages used by R packages? What do people put in them? Is there anything funny in them? Anything nefarious?"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#a-strong-attachment",
    "href": "posts/2021-08-27-zzz/index.html#a-strong-attachment",
    "title": "Exploring R package startup messages",
    "section": "A strong attachment",
    "text": "A strong attachment\nA package may need to run additional code before its functions can work, like maybe some options() need to be set.\nThere are two times this kind of code can be run: when the package is loaded, including namespace calls like dplyr::select(), or more specifically when the package is attached with library().\nTo prepare code for running on-load or on-attach, you create the special functions .onLoad() and .onAttach(). These go in a zzz.R file in the R/ directory of your package, because… convention?\nThe on-attach option is useful for printing messages for the user to see in the console, like the {multicolor} example above. You want this to happen on-attach and not on-load, since you wouldn’t want to print a message every single your script uses the :: namespace qualifier.\nTo specify a message in the body of your .onAttach() function, you use packageStartupMessage(). Why not just cat() or message()? Because it allows the user to quell startup messages using suppressPackageStartupMessages().\nYou can learn more in Hadley Wickham’s R Packages book.\nAs an example, consider the {tidyverse} package, which has some verbose output on attach:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nBut you can shush it with the suppressPackageStartupMessages() function:1\n\ndetach(\"package:tidyverse\")  # first detach it\nsuppressPackageStartupMessages(library(tidyverse))\n\nPeace.\nSo the startup messages of {multicolor} and {tidyverse} do two completely different things: one is fun and frivolous and the other is informative. Isn’t it possible that someone could put ads in the startup message or use it in evil ways? Well, perhaps.\nLet’s find out what R package developers put in their startup messages. How many packages even have a zzz.R file and how many of those even contain a packageStartupMessage() call?"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#catching-some-zs",
    "href": "posts/2021-08-27-zzz/index.html#catching-some-zs",
    "title": "Exploring R package startup messages",
    "section": "Catching some Zs",
    "text": "Catching some Zs\nI understand if all this talk of zzz.R causes you to… zzz. In short, if you want to get all the zzz.R files, you can:\n\nGet a list of R packages on CRAN\nIdentify which ones have an associated GitHub repo\nGet the default branch name of each one and construct the possible URL to their zzz.R file\nContact the possible zzz.R file to see if it exists\nIf it exists, download it\nFilter for zzz.R files that contain packageStartupMessage()\n\nWe’ve already attached the tidyverse packages, but we’ll also need two more packages:\n\nlibrary(gh)    # interact with GitHub API\nlibrary(httr)  # requests via the internet \n\n\n Note\nIf you’re thinking this approach is a bit long-winded, you’re right. As Tim pointed out, we could just extract the info via METACRAN, an unofficial CRAN mirror hosted on GitHub. It even has its own API. I’ll leave that as an exercise for the reader.\n\n\nPackages\nLuckily you can grab info for all current CRAN packages with the very handy CRAN_package_db() function.2\n\ncran_pkgs &lt;- as_tibble(tools::CRAN_package_db())\n\nThis returns a dataframe containing 19865 rows, where each one is a package, along with 67 variables. We get information like the stuff that’s found in package DESCRIPTION files, but it doesn’t tell us whether a package has a zzz.R file.\nOne way to do this is to visit the GitHub repo associated with the package, if it has one, and see if a zzz.R exists. Of course, many packages are not on GitHub, but we’re going to ignore those for simplicity.\n\n Note\nI re-rendered this post in July 2023, so the output no longer reflects CRAN as it was when this post was published (August 2021).\n\n\n\n\nGithub repos\nA quick way of discovering if a package has a GitHub repo is to check for ‘github.com’ in the BugReports section of it DESCRIPTION file.3 Again, this doesn’t capture all the possible repos, but is fine for now.\n\nhas_repo &lt;- cran_pkgs %&gt;% \n  select(Package, BugReports) %&gt;% \n  filter(str_detect(BugReports, \"github\")) %&gt;% \n  transmute(\n    Package,\n    owner_repo = str_extract(\n      str_replace_all(paste0(BugReports, \"/x\"), \"//\", \"/\"),\n      \"(?&lt;=github.com/).*(?=/[a-zA-Z])\"\n    )\n  ) %&gt;% \n  separate(owner_repo, c(\"owner\", \"repo\"), \"/\") %&gt;% \n  filter(!is.na(Package), !is.na(owner), !is.na(repo)) %&gt;% \n  distinct(Package, owner, repo) %&gt;% \n  arrange(Package) \n\nsample_n(has_repo, 5)\n\n# A tibble: 5 × 3\n  Package     owner          repo       \n  &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;      \n1 MatrixEQTL  andreyshabalin MatrixEQTL \n2 mitre       motherhack3r   mitre      \n3 path.chain  krzjoa         path.chain \n4 shinyXYpad  stla           shinyXYpad \n5 netdiffuseR USCCANA        netdiffuseR\n\n\nThere were 19865 CRAN packages total and now we have 8152 (41%) that appear to have a GitHub repo.\nIf you’re wondering why we didn’t just use the package name as the repo name, it’s because they sometimes don’t match, e.g. {baseballDBR} is in a repo called ‘moneyball’.\nNow we can use the repo details to build a URL to a potential zzz.R URL. This comes in the form https://raw.githubusercontent.com/&lt;owner&gt;/&lt;repo&gt;/&lt;defaultbranch&gt;/R/zzz.R\".\n\n\nDefault branch\nYou’ll notice we don’t yet know the default branch of the package’s GitHub repo. Historically, we could probably have just hard-coded ‘master’, but the automatic default is now ‘main’. And of course, the default branch could be something else entirely.\nWe can grab the default branch for each repo from the GitHub API using the excellent {gh} package by Gábor Csárdi, Jenny Bryan and Hadley Wickham. You’ll need to do some setup to use it yourself.\nThe key function is gh(), to which you can pass a GET request for the information we want: GET /repos/{owner}/{repo}. We can iterate for each repo by passing each owner and repo name in turn. It returns a list object with lots of information about the repo.\nI’ve created ‘possibly’ function variants with {purrr} so that any errors in the process are handled by returning NA, rather than breaking the loop, which would kill the process.\n\n# Create 'try' function versions\nmap2_possibly &lt;- possibly(map2, NA_real_)\ngh_possibly &lt;- possibly(gh, NA_real_)\n\n# Function: fetch repo details, print message on action\nget_repo &lt;- function(owner, repo) {\n  cat(paste0(\"[\", Sys.time(), \"]\"), paste0(owner, \"/\", repo), \"\\n\")\n  gh_possibly(\"GET /repos/{owner}/{repo}\", owner = owner, repo = repo) \n}\n\nmaybe_zzz &lt;- has_repo %&gt;%\n  mutate(\n    repo_deets =  map2_possibly(\n      has_repo$owner, has_repo$repo, get_repo\n    )\n  ) %&gt;% \n  mutate(\n    default_branch = map(\n      repo_deets, ~pluck(.x, \"default_branch\")\n    ),\n    default_branch = pluck(default_branch, 1),\n    zzz_url = paste0(\n      \"https://raw.githubusercontent.com/\",\n      owner, \"/\", repo, \"/\", default_branch, \"/R/zzz.R\"\n    )\n  )\n\nSo now we have a column with the returned repo information, the extracted default branch name and a URL that points to a potential zzz.R file in that repo.\n\nhead(maybe_zzz)\n\n# A tibble: 6 × 6\n  Package      owner           repo         repo_deets default_branch zzz_url   \n  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;        &lt;list&gt;     &lt;chr&gt;          &lt;chr&gt;     \n1 AATtools     Spiritspeak     AATtools     &lt;gh_rspns&gt; master         https://r…\n2 ABHgenotypeR StefanReuscher  ABHgenotypeR &lt;gh_rspns&gt; master         https://r…\n3 ABM          junlingm        ABM          &lt;gh_rspns&gt; master         https://r…\n4 ACEP         agusnieto77     ACEP         &lt;gh_rspns&gt; master         https://r…\n5 ACNE         HenrikBengtsson ACNE         &lt;gh_rspns&gt; master         https://r…\n6 ACWR         JorgeDelro      ACWR         &lt;gh_rspns&gt; master         https://r…\n\n\n\n\nStatus codes\nNow we can check the status code for each of the URLs we’ve built. A return of 200 tells us that the file exists and 404 means it doesn’t.4 Again, we can prevent the loop breaking on error by creating a ‘possibly’ version of map().\n\nlibrary(httr)  # for status_code()\n\nmap_possibly &lt;- possibly(map, NA_character_)\n\nmaybe_zzz_status &lt;- maybe_zzz %&gt;% \n  mutate(\n    status = map_possibly(\n      zzz_url, ~status_code(GET(.x))\n    )\n  ) %&gt;% \n  unnest(status)\n\ncount(maybe_zzz_status, status)\n\n# A tibble: 2 × 2\n  status     n\n   &lt;int&gt; &lt;int&gt;\n1    200  1519\n2    404  6631\n\n\nOkay, great, we’ve got over a thousand zzz.R files.\n\n\nRead content\nNow we know which packages have a zzz.R file, we can use readLines() to grab their content from their URL, which again we can protect from errors with purrr::possibly().\nNote that I’ve created a special version of readLines() that reports to the user the path being checked, but also has a random delay. This is to dampen the impact on GitHub’s servers.\n\n# Function: readLines() but with a pause and message\nreadLines_delay &lt;- function(path) {\n  sample(1:3, 1)\n  cat(paste0(\"[\", Sys.time(), \"]\"), path, \"\\n\")\n  readLines(path, warn = FALSE)\n}\n\nreadLines_delay_possibly &lt;- possibly(readLines_delay, NA_character_)\n\nfosho_zzz &lt;- maybe_zzz_status %&gt;% \n  select(-repo_deets) %&gt;% \n  filter(status == 200) %&gt;%  # just the \n  mutate(lines = map_possibly(zzz_url, readLines_delay_possibly))\n\ndim(fosho_zzz)\n\nSo now we have a dataframe with a row per package and a list-column containing the R code in the zzz.R file.\n\n\nStartup messages\nFinally, we can find out which packages have a packageStartupMessage() call inside their zzz.R.\n\nhas_psm &lt;- fosho_zzz %&gt;% \n  select(Package, lines) %&gt;%\n  unnest(lines) %&gt;%\n  filter(str_detect(lines, \"packageStartupMessage\")) %&gt;% \n  mutate(lines = str_remove_all(lines, \" \")) %&gt;%\n  distinct(Package) %&gt;% \n  pull()\n\nfosho_psm &lt;- filter(fosho_zzz, Package %in% has_psm)\n\nSo we started with 19865 CRAN packages and have winnowed it to down to 579 (3%) that have a call to packageStartupMessage() in their zzz.R.\n\n\nTable of results\nI could provide a table with all the zzz.R content, but I don’t want to break any licenses by reproducing them all here. Instead, here’s an interactive table that links to the GitHub page for each zzz.R file that appears to have a package startup message.\n\n\nClick for table code\n\n\nlibrary(reactable)\n\nreactable(\n  data = fosho_psm %&gt;% \n    select(package = Package, owner, url = zzz_url),\n  searchable = TRUE,\n  paginationType = \"jump\",\n  defaultPageSize = 10,\n  columns = list(\n    url = colDef(cell = function(value) {\n      htmltools::tags$a(href = value, target = \"_blank\", \"zzz.R\")\n    })\n  )\n)\n\n\n\n\n\n\n\n\n\n\n Note\nI re-rendered this post in July 2023, so the table above may contain different packages to when it was first published. The section below relates to the originally-published post and may no longer reflect the content of the zzz.R files listed in the table above.\n\n\n\nPatterns\nI had a scan through the scripts and found some frequent uses of packageStartupMessages() to:\n\nshow a basic salutation (e.g. {afex})\nshow the version number, a check to see if the user has the latest version, sometimes a prompt to download the latest version for them (e.g. {vistributions}), sometimes a note that the package has been superseded by another (e.g. {drake})\nlinks to guidance, examples, documentation (e.g. {bayesplot})\nprovide a citation or author names (e.g. {unvotes})\nlink to issue tracking or bug reporting (e.g. {timeperiodsR})\ncheck for required supplementary software (e.g. {DALY})\nremind of the need for credentials or keys for packages that access APIS, for example (e.g. {trainR})\nprovide terms of use, warranties, licenses, etc (e.g. {emmeans})\n\nI was also interested to see:\n\na random tip, so you get something new each time you attach the package (e.g. {shinyjs})\nappeals for GitHub stars (e.g. {sigminer})\nlinks to purchasable course materials (e.g. {anomalise})\n\nAnd perhaps the most self-aware were several packages that reminded the user that they can turn off startup messages with suppressPackageStartupMessages() if the messages get too annoying (e.g. {dendextend}).\nA few interesting specifics (possible spoiler alerts!):\n\n{bayestestR} and {sjmisc} have displays a special Star Wars message on a certain day of the year…\n{SHT} and {symengine} load ASCII art, as does {BetaBit}, which also prompts the user for a game they’d like to play\n{depigner} says ‘Welcome to depigner: we are here to un-stress you!’\n{mde} has a friendly ‘Happy Exploration :)’ salutation and {manymodelr} says ‘Happy Modelling! :)’\n{sjPLot} says ‘#refugeeswelcome’\n\nYou can use the interactive table above to reach each of the zzz.R files for these packages, or have a sift through yourself to see what you can find."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#buy-my-stuff",
    "href": "posts/2021-08-27-zzz/index.html#buy-my-stuff",
    "title": "Exploring R package startup messages",
    "section": "Buy my stuff?",
    "text": "Buy my stuff?\nIs there a line somewhere? Is it okay to advertise something? You could argue that someone has gone out of their way to release a package for free, so what harm is it in trying to get something back? or does this approach undermine the whole ‘open’ process?\nI know some people find startup messages a bit annoying, but I think it’s easy enough for users to opt out of seeing them with a call to suppressPackageStartupMessages().\nMostly I’m kind of surprised by the lack of abuse of packageStartupMessage() in this sample. Let me know of any cheeky business you might have come across."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#environment",
    "href": "posts/2021-08-27-zzz/index.html#environment",
    "title": "Exploring R package startup messages",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:29:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reactable_0.4.4 httr_1.4.6      gh_1.4.0        tidyverse_2.0.0\n [5] lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.2    \n [9] purrr_1.0.1     readr_2.1.4     tidyr_1.3.0     tibble_3.2.1   \n[13] ggplot2_3.4.2  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    compiler_4.3.1    tidyselect_1.2.0 \n [5] scales_1.2.1      yaml_2.3.7        fastmap_1.1.1     R6_2.5.1         \n [9] generics_0.1.3    knitr_1.43.1      htmlwidgets_1.6.2 munsell_0.5.0    \n[13] pillar_1.9.0      tzdb_0.4.0        rlang_1.1.1       utf8_1.2.3       \n[17] stringi_1.7.12    reactR_0.4.4      xfun_0.39         timechange_0.2.0 \n[21] cli_3.6.1         withr_2.5.0       magrittr_2.0.3    crosstalk_1.2.0  \n[25] digest_0.6.31     grid_4.3.1        fontawesome_0.5.1 rstudioapi_0.15.0\n[29] hms_1.1.3         lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21    \n[33] glue_1.6.2        fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[37] ellipsis_0.3.2    tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#footnotes",
    "href": "posts/2021-08-27-zzz/index.html#footnotes",
    "title": "Exploring R package startup messages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhich makes me wonder what the longest R function name is.↩︎\nI made use of this for the {kevinbacran} package and the associated ‘What’s your Hadley Number?’ app.↩︎\nI chose the BugReports field rather the URL field because people put all sorts of things in the latter, like links to websites, etc. BugReports (I think) tends to point to the source on GitHub.↩︎\nI wrote about status codes as part of the post on my {linkrot} package.↩︎"
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html",
    "href": "posts/2020-05-08-badgr/index.html",
    "title": "Make a README badge with {badgr}",
    "section": "",
    "text": "The {badgr} package is no bodge, I assure you!"
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html#tldr",
    "href": "posts/2020-05-08-badgr/index.html#tldr",
    "title": "Make a README badge with {badgr}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve written {badgr}, a very simple package with a single very simple function—get_badge()—that generates a URL for a shields.io badge, which can then be placed in a repo’s README. For example, here’s one for this blog:\n\n\n\n\n\n\nℹ️ Note\nSomehow I missed the existence of the {badger} package by Guangchuang Yu on CRAN, which also uses shields.io.\nAs of 2023, there’s also {badgen} by Jeroen Ooms, which is based on the badgen library and lets you make badges without an internet connection."
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html#whats-a-badge",
    "href": "posts/2020-05-08-badgr/index.html#whats-a-badge",
    "title": "Make a README badge with {badgr}",
    "section": "What’s a badge?",
    "text": "What’s a badge?\nYou’ll see badges in the README files of code repositories on sites like GitHub and GitLab. They communicate something about the code at-a-glance and usually contain metadata or a link to further information.\n\n\n\nExamples of badges in the repo README for {data.table}.\n\n\nDynamic metadata badges help you judge the status of the repo. For example, a common badge is one that indicates whether the code has passed testing via a continuous integration service like Travis. So ‘build passing’ means that the code in the latest update is working. Clicking the badge will take you to the associated site to get more information.\nOther badges are static and can act as a handy link. For example, some repos have badges for services like Ko-Fi for donations, or perhaps to open the repo in a cloud-based instance of Binder.1"
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html#roll-your-own",
    "href": "posts/2020-05-08-badgr/index.html#roll-your-own",
    "title": "Make a README badge with {badgr}",
    "section": "Roll your own",
    "text": "Roll your own\nYou can create your own badges for whatever purpose.\nI want people to know if one of my GitHub repositories is related to a post on this blog so they can find out more. I could just link to the post in the README—I often do—but the badge sits at the top of the README and is eye-catching. It’s also a useful at-a-glance reminder for me when I’m looking over my repos.\nThe rest of this post lays out how you can build one for yourself.\n\nshields.io\nFortunately, There’s a service called shields.io that makes it easy to create a simple badge. It works by exposing a badge with parameters you provide in a URL string.\nYou can generate a simple static badge by modifying a URL string in the form https://img.shields.io/badge/&lt;LABEL&gt;-&lt;MESSAGE&gt;-&lt;COLOR&gt;.\nSo ![](https://img.shields.io/badge/label-message-red) results in this:\n\n\n\n\n\nYou could build on this by providing an alternative style and an image from Simple Icons.\nFor example, ![](https://img.shields.io/badge/label-message-181717?style=for-the-badge&logo=github) results in this:\n\n\n\n\n\n\nSo you can see that additional ‘arguments’ to the basic call are added after a ? and then additional parts added with an &.\n\n\n{badgr}\nThis got me thinking about a quick R function to build up a badge URL. This became the get_badge() function in the {badgr} package. This is currently a bit janky and untested, but so far it does what I want it to do.\nYou can install it with:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_githb(\"matt-dray/badgr\")\n\nget_badge() builds up the components of a shields.io-valid URL given the arguments you provide. For example, you can specify the text (label and message arguments) and background colour to go on either side of the badge (label_color and color). You can also include a logo from simpleicons.org (logo_simple) or a custom icon of your choosing (logo_path).\nThe most complex part is that the path to the custom logo has to be base64-encoded, which is done with base64enc::base64encode(). The output from that is then passed into the shields.io URL.\nBy default, the function wraps your badge in Markdown in the form [![](&lt;shields.io URL&gt;)](&lt;provided link&gt;) and copies it to your clipboard, ready for you to paste it into a README somewhere. It also sends the URL to your browser for a preview.\n\n\nA rostrum.blog badge\nSo, I made a badge that has:\n\n‘rostrum.blog’ on the left side, with a black background\n‘post’ on the right side with a green background (to match the green used on this site)\nthe rostrum.blog ‘bug’ logo gif (used as the favicon for the site)2\n\nI achieved that with the following code:\n\n# Set path to custom logo (a gif in this case)\nlogo &lt;- \"https://raw.githubusercontent.com/matt-dray/rostrum-blog/master/static/images/favicon.gif\"\n\n# Set underlying badge link (where the badge-click will take you)\nlink &lt;- \"https://www.rostrum.blog/\"\n\nblog_badge &lt;- badgr::get_badge(\n  label = \"rostrum.blog\",   # left-side text\n  message = \"post\",         # right-side text\n  color = \"008900\",         # left-side colour (green)\n  label_color = \"black\",    # right_side colour\n  md_link = link,           # where to go when clicked\n  logo_path = logo,         # path to my logo\n  browser_preview = FALSE,  # don't open preview\n  to_clipboard = FALSE      # don't copy to clipboard\n)\n\nThat results in the following string output:\n\nblog_badge\n\n[1] \"[![](https://img.shields.io/badge/rostrum.blog-post-008900?style=flat&labelColor=black&logo=data:image/gif;base64,R0lGODlhEAAQAPEAAAAAABWCBAAAAAAAACH5BAlkAAIAIf8LTkVUU0NBUEUyLjADAQAAACwAAAAAEAAQAAAC55QkISIiEoQQQgghRBBCiCAIgiAIgiAIQiAIgSAIgiAIQiAIgRAEQiAQBAQCgUAQEAQEgYAgIAgIBAKBQBAQCAKBQEAgCAgEAoFAIAgEBAKBIBAQCAQCgUAgEAgCgUBAICAgICAgIBAgEBAgEBAgEBAgECAgICAgECAQIBAQIBAgECAgICAgICAgECAQECAQICAgICAgICAgEBAgEBAgEBAgICAgICAgECAQIBAQIBAgECAgICAgIBAgECAQECAQIBAgICAgIBAgIBAgEBAgECAgECAgICAgICAgECAgECAgQIAAAQIKAAAh+QQJZAACACwAAAAAEAAQAAAC55QkIiESIoQQQgghhAhCBCEIgiAIgiAIQiAIgSAIgiAIQiAIgRAEQiAQBAQCgUAQEAQEgYAgIAgIBAKBQBAQCAKBQEAgCAgEAoFAIAgEBAKBIBAQCAQCgUAgEAgCgUBAICAgICAgIBAgEBAgEBAgEBAgECAgICAgECAQIBAQIBAgECAgICAgICAgECAQECAQICAgICAgICAgEBAgEBAgEBAgICAgICAgECAQIBAQIBAgECAgICAgIBAgECAQECAQIBAgICAgIBAgIBAgEBAgECAgECAgICAgICAgECAgECAgQIAAAQIKAAA7)](https://www.rostrum.blog/)\"\n\n\nThis is a shields.io-valid URL encased in some Markdown that allows it to be pasted directly into a GitHub README, for example. See how the Markdown contains the ![]() image declaration, which itself is wrapped in the []() link declaration. This means that clicking the link will take you to the URL specified by the md_link argument to get_badge().\nIt looks like this when rendered:\n\n\nNote that the icon is subtly animated (the bug antennae open and close) because the source image was a gif.\n\n Note\nWhen I re-rendered this post with Quarto in 2023, the logos in the rostrum.blog badge and the GitHub ‘label message’ badge were inexplicably missing (but not in the Shiny badge below). I’ve temporarily replaced these badges with screenshots until I can understand and fix the problem.\n\n\n\n Note\nMore recently I’ve realised that it would be handy to have a README badge to indicate that one of my repos contains a Shiny app and whether it’s available on the internet. The right-hand side of the badge can point out whether the app is live (e.g. on shinyapps.io) or ‘not hosted’. For example:"
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html#environment",
    "href": "posts/2020-05-08-badgr/index.html#environment",
    "title": "Make a README badge with {badgr}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-24 21:35:50 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2      vctrs_0.6.3       cli_3.6.1         knitr_1.43.1     \n [5] rlang_1.1.1       xfun_0.39         stringi_1.7.12    purrr_1.0.1      \n [9] generics_0.1.3    assertthat_0.2.1  jsonlite_1.8.7    glue_1.6.2       \n[13] badgr_0.1.1       clipr_0.8.0       htmltools_0.5.5   rmarkdown_2.23   \n[17] emo_0.0.0.9000    evaluate_0.21     fontawesome_0.5.1 fastmap_1.1.1    \n[21] base64enc_0.1-3   yaml_2.3.7        lifecycle_1.0.3   stringr_1.5.0    \n[25] compiler_4.3.1    htmlwidgets_1.6.2 timechange_0.2.0  rstudioapi_0.15.0\n[29] digest_0.6.33     magrittr_2.0.3    tools_4.3.1       lubridate_1.9.2"
  },
  {
    "objectID": "posts/2020-05-08-badgr/index.html#footnotes",
    "href": "posts/2020-05-08-badgr/index.html#footnotes",
    "title": "Make a README badge with {badgr}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd others are just for fun. I was particularly amused to see a ‘cool | useless’ badge in repos by mikefc (@coolbutuseless).↩︎\nBear in mind that a very large image might not be that effective when squashed down to fit into the badge. The icon I’ve used is only 16x16, so is already small and looks fine in the badge.↩︎"
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#tldr",
    "href": "posts/2021-10-05-gorilla/index.html#tldr",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can convert a line drawing to datapoints with a sprinkle of {magick}."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#ape-escape",
    "href": "posts/2021-10-05-gorilla/index.html#ape-escape",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Ape escape",
    "text": "Ape escape\nHave you seen that video where you’re so focused on counting basketball passes that you fail to see the gorilla moving across the screen?\nThis kind of selective attention was studied by two researchers, Yanai and Lercher, who provided subjects with a dataset that looked like a gorilla when plotted. The gorilla was found less often if the subjects were also given a hypothesis to investigate.\nThe study got some attention on Twitter last week. As a result, Isabella Velásquez wrote a great blogpost where she recreated the dataset using R and Python in tandem via the {reticulate} package.\nI had a go at creating the dataset with base R and the excellent {magick} package for image manipulation."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#point-it-out",
    "href": "posts/2021-10-05-gorilla/index.html#point-it-out",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Point it out",
    "text": "Point it out\nThe jpeg image file used in the original paper can be downloaded from classroomclipart.com to a temporary location on your machine.\n\ndownload.file(\n  paste0(\n    \"https://classroomclipart.com/images/gallery/\",\n    \"Clipart/Black_and_White_Clipart/Animals/\",\n    \"gorilla-waving-cartoon-black-white-outline-clipart-914.jpg\" \n  ),\n  tempfile(fileext = \".jpg\")\n)\n\nWe can read the file into R with {magick}.\n\nimg &lt;- \n  list.files(tempdir(), pattern = \".jpg$\", full.names = TRUE) |&gt;\n  magick::image_read()\n\nimg\n\n\n\n\nWith other {magick} functions we can:\n\nreduce to two distinct colours only (i.e. for the lines and background), which makes it easier to filter the data later\nconvert from an image to point data\n\n\ngo &lt;- img |&gt;\n  magick::image_quantize(2) |&gt;  # colour reduction\n  magick::image_raster() |&gt;     # as x-y data\n  as.data.frame()\n\nhead(go)\n\n  x y       col\n1 1 1 #fefefeff\n2 2 1 #fefefeff\n3 3 1 #fefefeff\n4 4 1 #fefefeff\n5 5 1 #fefefeff\n6 6 1 #fefefeff\n\n\nAnd to prove we only have two colours (off-white for the background, grey for the lines):\n\nunique(go$col)\n\n[1] \"#fefefeff\" \"#555555ff\"\n\n\nNow we can:\n\nreverse the order of the y values so the gorilla is right-side up\nfilter to retain only the datapoints that represent lines\nrescale the x and y to create ‘Body Mass Index’ (BMI)1 and ‘steps’ variables\n\n\ngo$y     &lt;- rev(go$y)\ngo       &lt;- go[go$col != \"#fefefeff\", ]\ngo$bmi   &lt;- go$y / max(go$y) * 17 + 15\ngo$steps &lt;- 15000 - go$x * 15000 / max(go$x)\n\nhead(go)\n\n      x   y       col bmi    steps\n174 174 550 #555555ff  32 8665.049\n175 175 550 #555555ff  32 8628.641\n176 176 550 #555555ff  32 8592.233\n196 196 550 #555555ff  32 7864.078\n198 198 550 #555555ff  32 7791.262\n199 199 550 #555555ff  32 7754.854\n\n\nYou may have noticed that the image has a watermark. We could have removed it earlier with {magick}, but can do it now by filtering out the datapoints in that corner.\n\ngo$logo &lt;- ifelse(go$bmi &lt; 16 & go$steps &lt; 5500, TRUE, FALSE)\ngo      &lt;- go[!go$logo, ]\n\nThis leaves us with 16865 datapoints. We can follow the original study by taking a sample and splitting the results into ‘female’ and ‘male’ groups, weighted so that the female group has higher step counts.\n\ngo_smp       &lt;- go[sample(nrow(go), 1768), ]\ngo_smp$rnorm &lt;- rnorm(nrow(go_smp), mean = 0, sd = 10)\ngo_smp$index &lt;- go_smp$steps * (1 + go_smp$rnorm)\ngo_smp$group &lt;- \n  ifelse(go_smp$index &lt; median(go_smp$steps), \"F\", \"M\") |&gt;\n  as.factor()\n\nhead(go_smp[, c(\"bmi\", \"steps\", \"group\")])\n\n            bmi       steps group\n135597 21.83091 13216.01942     F\n85694  25.60182    72.81553     F\n199825 17.00909 14817.96117     F\n43530  28.75455  5169.90291     M\n200308 16.97818 12233.00971     F\n55403  27.85818  7900.48544     F\n\n\nNow finally to plot the datasets side-by-side.\n\npar(mfrow = c(1, 2))\n\nwith(\n  go_smp[go_smp$group == \"F\", ],\n  plot(\n    steps, bmi,\n    xlim = c(0, 15000),\n    pch = 16, cex = 0.5, col = \"blue\",\n    xlab = \"Steps\", ylab = \"BMI\", \n  )\n)\n\nwith(\n  go_smp[go_smp$group == \"M\", ],\n  plot(\n    steps, bmi, \n    xlim = c(0, 15000),\n    pch = 16, cex = 0.5, col = \"red\",\n    xlab = \"Steps\", ylab = \"BMI\"\n  )\n)\n\n\n\n\nI see them!\nThis has been a bit overengineered and could be generalised, but it gives a gist of how you might go about converting an image to a dataframe of x and y positions.\nAt worst, this is a reminder not to trust researchers and to always check for unexpected gorillas."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#environment",
    "href": "posts/2021-10-05-gorilla/index.html#environment",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-07 21:11:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         magrittr_2.0.3   \n [5] knitr_1.43.1      htmltools_0.5.5   png_0.1-8         rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.14   tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.10       yaml_2.3.7        magick_2.7.4     \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#footnotes",
    "href": "posts/2021-10-05-gorilla/index.html#footnotes",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCheck out a recent episode of the Maintenance Phase podcast (dated 2021-08-03) about the troublesome history and development of BMI as a metric.↩︎"
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html",
    "href": "posts/2020-09-12-herring-units/index.html",
    "title": "{units} of uncleaned herring",
    "section": "",
    "text": "The hex sticker is better than the package."
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html#tldr",
    "href": "posts/2020-09-12-herring-units/index.html#tldr",
    "title": "{units} of uncleaned herring",
    "section": "tl;dr",
    "text": "tl;dr\nI made the tiny R package {cran} to convert volumes to an antiquated measurement of fish. Why? To test out the {units} package and to resolve a joke about the Comprehensive R Archive Network (CRAN)."
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html#units",
    "href": "posts/2020-09-12-herring-units/index.html#units",
    "title": "{units} of uncleaned herring",
    "section": "{units}",
    "text": "{units}\nThe {units} package by Edzer Pebesma, Thomas Mailund and James Hiebert (site, source, R Journal) helps you set and create units, convert between them and raise an error where that isn’t possible.\nI’ve used the package to solve a trivial unit conversion question and to create my own units. This post shows how.\n\nA 12 gallon hat?\nHere’s a really simple example of the {units} package in action.\nA colleague bought a 1 gallon water bottle, only to realise later that it was US gallons rather than UK gallons (viva litres!). What’s the relationship between the two gallon units?\nFirst install and attach the {units} package, which is available on CRAN. It will print the location where the units dataset is stored. These units are derived from the comprehensive UNIDATA udunits database, which has all the relevant SI units and some that are a little more… nonstandard.\n\n# install.packages(\"units\")  # install if you haven't already\nlibrary(units)\n\nudunits database from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/units/share/udunits/udunits2.xml\n\n\nI’ll also load a few other packages for the purposes of this post.\n\nsuppressPackageStartupMessages({\n  library(dplyr)\n  library(stringr)\n  library(purrr)\n})\n\nYou can inspect the valid_units() dataframe to find out what units you can work with. Here’s five random units from the dataframe:\n\nvalid_udunits() %&gt;% \n  filter(symbol != \"\" & name_singular != \"\") %&gt;% \n  sample_n(5) %&gt;% \n  select(symbol, name_singular, definition)\n\n# A tibble: 5 × 3\n  symbol name_singular      definition                                          \n  &lt;chr&gt;  &lt;chr&gt;              &lt;chr&gt;                                               \n1 H      henry              unit of inductance; where a circuit's current chang…\n2 L      liter              unit of capacity equal to 1000 cubic centimeters    \n3 in     international_inch unit of length equal to 25.4 mm by definition, used…\n4 °F     fahrenheit         unit of thermodynamic temperature                   \n5 '      arc_minute         measurement of a plane angle equal to 1/60 arc degr…\n\n\nWe can filter the name_singular column to find the available gallon units.\n\ndplyr::filter(\n  valid_udunits(),\n  str_detect(name_singular, \"gallon\")\n) %&gt;% \n  select(name_singular)\n\n# A tibble: 4 × 1\n  name_singular         \n  &lt;chr&gt;                 \n1 Canadian_liquid_gallon\n2 US_dry_gallon         \n3 US_liquid_gallon      \n4 UK_liquid_gallon      \n\n\nWe’re interested in UK_liquid_gallon and US_liquid_gallon, but wow, there’s two more, including a ‘dry’ one.\nWe can supply a unit to a value with as_units(), so we can create 1 UK gallon with the following:\n\nuk_gal &lt;- as_units(1, \"UK_liquid_gallon\")\n\nThat gives us an object with class units and the print method adds the unit in square brackets:\n\nclass(uk_gal)\n\n[1] \"units\"\n\nuk_gal\n\n1 [UK_liquid_gallon]\n\n\nWe can also do maths with these objects:\n\nuk_gal + uk_gal\n\n2 [UK_liquid_gallon]\n\n\nAnd to convert it, we can take set the units of our unit-class object and specify a different unit. The units need to be compatible though, so you can’t convert a gallon to a parsec, for example.\n\n# Using purrr::safely() to capture the error\nsafe_set_units &lt;- safely(set_units)\nsafe_set_units(uk_gal, \"parsec\")$error\n\n&lt;simpleError: cannot convert UK_liquid_gallon into parsec&gt;\n\n\nThis prevents you from combining non-compatible units, which is a real danger if your data is stored as bare numeric values with no unit information.\nAnd now we’ll set the new units for the gallon-to-gallon conversion.\n\nus_gal &lt;- set_units(uk_gal, \"US_liquid_gallon\")\nus_gal\n\n1.20095 [US_liquid_gallon]\n\n\nSo a UK liquid gallon is about 20% larger than a US one. But I thought everything was meant to be larger in the US!"
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html#herring-aid",
    "href": "posts/2020-09-12-herring-units/index.html#herring-aid",
    "title": "{units} of uncleaned herring",
    "section": "Herring aid",
    "text": "Herring aid\nWho doesn’t like getting lost in the Wikipedia rabbithole? I came upon the page for ‘cran’ and found it amusing that the Comprehensive R Archive Network (CRAN) package database had a rival.\nWhat’s a cran, then? Well, an antiquated legal unit for measuring the volume of landed, uncleaned herring in the North Sea fishing industry. Also used as the name for a basket that could carry that volume.1\nIt sounds like the initial 18th-century measurement was volumetric and inexact, equalling something like 1200 fish. Later this was made official in terms of ‘wine gallons’, with Wikipedia pegging it to 170.5 litres in more modern units. For confirmation, simply read the Second Report of the Commissioners Appointed by His Majesty to Consider the Subject of Weights and Measures, 1820:\n\nNaturally, I checked valid_udunits()… and cran isn’t in there. So obviously I needed to make it.\nYou can basically do this in three steps with {units}: define a new unit based on known units; create a unit object; convert it to the newly-defined unit.\nSo, you can ‘install’ a new unit with reference to another unit by multiplying or offsetting by some constant. In our case, our new unit is equal to 170.5 litres.\n\ninstall_unit(\"cran\", \"170.5 L\")\n\nNow we can work with the cran unit. Let’s first create a unit-class object to convert. For example, we can confirm that 170.5 litres is equal to one cran.\n\none_litre &lt;- as_units(170.5, \"L\")\none_litre\n\n170.5 [L]\n\n\nWe can supply this to the set_units() function and specify we want it converted to cran.\n\nset_units(one_litre, \"cran\")\n\n1 [cran]\n\n\n\nCRAN… no, {cran}\nSo I created a package called {cran} that contains this conversion. You can install it from GitHub using the {remotes} package. Except, you know, don’t, because you have no need for it unless you’re an 18th century fisherman.\n\nremotes::install_github(\"matt-dray/cran\")\n\nAnd then when you load the package it asks if you want to create the cran unit. Answering ‘yes’ results in the cran unit being available in your session.\n\nlibrary(cran)\n\nCreate the 'cran' unit of measurement for this session? yes/no: yes\nYou're ready to measure uncleaned herring.\nNow you can use cran for setting and converting units. So we can revisit our check that 170.5 litres equals 1 cran:\n\ncran::cran_convert(170.5, \"L\")\n\n1 [cran]\n\n\n…And that’s it, basically. You can remove and reinstall the unit at any point with cran_remove() and cran_install().\n\ncran::cran_remove()\n\nRemove the 'cran' unit of measurement for this session? yes/no: yes\nYou're done measuring uncleaned herring."
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html#environment",
    "href": "posts/2020-09-12-herring-units/index.html#environment",
    "title": "{units} of uncleaned herring",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1   stringr_1.5.0 dplyr_1.1.2   units_0.8-2  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         stringi_1.7.12    generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7       \n[17] lifecycle_1.0.3   compiler_4.3.1    htmlwidgets_1.6.2 Rcpp_1.0.11      \n[21] pkgconfig_2.0.3   cran_0.0.0.9001   rstudioapi_0.15.0 digest_0.6.33    \n[25] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0     \n[29] magrittr_2.0.3    withr_2.5.0       tools_4.3.1       xml2_1.3.5"
  },
  {
    "objectID": "posts/2020-09-12-herring-units/index.html#footnotes",
    "href": "posts/2020-09-12-herring-units/index.html#footnotes",
    "title": "{units} of uncleaned herring",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can still buy one today.↩︎"
  },
  {
    "objectID": "posts/2019-12-08-altcheckr/index.html#tldr",
    "href": "posts/2019-12-08-altcheckr/index.html#tldr",
    "title": "{altcheckr}: check image alt text from R",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve made a small concept R package called {altcheckr} that checks the accessibility of images on web pages. It has functions that (1) scrape attributes from HTML  elements on a web page and (2) apply simple rules to indicate the suitability of the alt text provided."
  },
  {
    "objectID": "posts/2019-12-08-altcheckr/index.html#accessibility",
    "href": "posts/2019-12-08-altcheckr/index.html#accessibility",
    "title": "{altcheckr}: check image alt text from R",
    "section": "Accessibility",
    "text": "Accessibility\nA web site is accessible if everyone can engage with its content. There are Web Content Accessibility Guidelines (WCAG) from the World Wide Web Consortium (W3C) to help achieve this and many (often free) tools for checking accessibility issues. It’s pressing because the law in the UK has recently changed to ensure that all public sector websites publish an accessibility statement.\nOne obvious target for improvement is accessibility of images.\n\nScreen readers\nScreen readers are a technology that parse text on a web page and output it as speech audio. They’re particularly helpful for blind and partially-sighted people.\nImages are declared in the HTML code of a website with the &lt;img&gt; element. Like other HTML tags, it can have many ‘attributes’: the source of the image (where the image is actually hosted), the height and width of the image, and so on.\nThe ‘alt’ attribute provides alternative text that describes the image. This text won’t be visible to people visiting the page (unless you right-click and ‘inspect’ the HTML for the page), but will be picked up screen readers.\n\n\nWhen and what to write\nWhat should you actually write as alternative text for an image? It depends on the type of image. To summarise the alt decision tree by W3C:\n\n\n\n\n\n\n\nImage type\nAlt text suggestion\n\n\n\n\nInformative\nA short, complete, descriptive sentence.\n\n\nDecorative\nNone required (alt = \"\").\n\n\nFunctional\nA short description of the purpose served (if it’s a button, for example).\n\n\nContains text\nText should be repeated unless in the main body text.\n\n\nComplex\nDescribe in the main body text or provide a longdesc attribute that links to a page containing a longer description."
  },
  {
    "objectID": "posts/2019-12-08-altcheckr/index.html#chancellor-of-the-altcheckr",
    "href": "posts/2019-12-08-altcheckr/index.html#chancellor-of-the-altcheckr",
    "title": "{altcheckr}: check image alt text from R",
    "section": "Chancellor of the {altcheckr}",
    "text": "Chancellor of the {altcheckr}\nI’ve been writing different sorts of R packages recently (see posts on {usethis}, {kevinbacran}, {blogsnip} and {gdstheme}) and I’ve have also written briefly on accessibility and some related tools.\nTo this end, I’ve written a small R package called {altcheckr} to help assess alt text programmatically. Go to the source on GitHub or see the site built with {pkgdown}.\nNote that {altcheckr} isn’t intended to provide a definitive evaluation of alt text. It uses simple heuristics and doesn’t contain everything that could be checked. I’m not an expert and the package isn’t user tested.\nIt has only two functions for now:\n\nalt_get() scrapes the web page at a URL provided by the user and outputs a data frame where each row is an image and each column is an HTML attribute\nalt_check() takes the output from alt_get() and adds a series of columns that assess features of the alt text, like its length\n\nIt also contains the example_get data set, which is a dummy output from alt_get() to be used to experiment with alt_check().\n\nExample\nLet’s walk through how you can get the package, fetch alt text from a webpage and then assess it.\n\nInstall\nYou can get the package from GitHub with:\n\ninstall.packages(\"remotes\")  # if not yet installed\ninstall_github(\"matt-dray/altcheckr\")\nlibrary(altcheckr)\n\n\n\nalt_get()\nThe alt_get() function makes use of {polite}, {xml2} and {rvest} to scrape a web page and isolate attributes from its &lt;img&gt; elements. If {polite} determines that it’s okay to scrape, alt_get() returns a tibble after some {purrr} wrangling, where each row is an image. You can choose to retain all scraped attributes as columns, or it defaults to returning just src and alt (longdesc too if it exists).\nWe’ll use the BBC News home page as our example. A popular site with constantly-updating content that you would expect to have good alt text.\n\n\n\nBBC News sports section. How would you describe these images in alt text?\n\n\nPass the web page’s URL to alt_get() to return a tibble where each row is an image from the page and there are columns for the image source (src) and alt text (alt).\n\nbbc_get &lt;- alt_get(\"https://www.bbc.co.uk/news\")\nstr(bbc_get)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':    105 obs. of  2 variables:\n$ src: chr  \"https://a1.api.bbc.co.uk/hit.xiti?&col=1&from=p&ptag=js&s=598253&p=unknown&x1=[urn:bbc:cps:b5c53243-a695-e059-e\"| __truncated__ \"https://ichef.bbci.co.uk/news/320/cpsprodpb/14E0/production/_98244350_pa.jpg\" \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" \"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" ...\n$ alt: chr  \"\" \"The Irish border\" \"Airman Mohammad Sameh Haitham (left) and ensign Joshua Kaleb Watson\" \"Crowds\" ...\nA whopping 105 images! Let’s take a look at the first few alt text entries.\n\nhead(bbc_get$alt)\n\n[1] \"\"                                                                                            \n[2] \"The Irish border\"                                                                            \n[3] \"Airman Mohammad Sameh Haitham (left) and ensign Joshua Kaleb Watson\"                         \n[4] \"Crowds\"                                                                                      \n[5] \"Wellingborough Road, Rushden\"                                                                \n[6] \"Juice Wrld, real name Jarad Anthony Higgins, was considered to be a rising star of rap music\"\nSome of these seem quite short and aren’t particularly descriptive; even without having seen the images that they relate to. Let’s do a simple assessment of the alt text using the alt_check() function to provide a bit more information.\n\n\nalt_check()\nThe alt_check() function takes the output from alt_get() and generates some new variables based on the alt text.\n\nbbc_check &lt;- alt_check(bbc_get)\n\npackagelibrary(dplyr)\nglimpse(bbc_check)\n\nObservations: 105\nVariables: 10\n$ src            &lt;chr&gt; \"https://a1.api.bbc.co.uk/hit.xiti?&col=1&from=p&…\n$ alt            &lt;chr&gt; \"\", \"The Irish border\", \"Airman Mohammad Sameh Ha…\n$ alt_exists     &lt;chr&gt; \"Empty\", \"Exists\", \"Exists\", \"Exists\", \"Exists\", …\n$ nchar_count    &lt;int&gt; NA, 16, 67, 6, 28, 92, 37, 16, 14, 38, 4, 10, 26,…\n$ nchar_assess   &lt;chr&gt; NA, \"Short\", \"OK\", \"Short\", \"OK\", \"OK\", \"OK\", \"Sh…\n$ file_ext       &lt;lgl&gt; NA, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ self_evident   &lt;lgl&gt; NA, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ terminal_punct &lt;lgl&gt; NA, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ spellcheck     &lt;list&gt; [&lt;&gt;, &lt;&gt;, &lt;\"Sameh\", \"Haitham\", \"Kaleb\"&gt;, &lt;&gt;, &lt;\"We…\n$ not_basic      &lt;list&gt; [&lt;&gt;, &lt;\"irish\", \"border\"&gt;, &lt;\"airman\", \"mohammad\",…\nYou can see a number of new columns in addition to src and alt that were output from alt_get(). These are as follows, with reasoning:\n\n\n\nColumn name\nWhat\nWhy\n\n\n\n\nalt_exists\nHas alt text been provided?\nA lack of alt text could be a problem, though it’s acceptable if the image is decorative.\n\n\nnchar_count\nNumber of characters in the alt text.\nUsed in nchar_assess\n\n\nnchar_assess\nCategorical. Whether the alt text is ‘short’ (defaults to 20 characters), ‘long’ (125) or ‘okay’.\nShort alt text might not describe the image well, but is acceptable for things like buttons, for example. Long alt text might be too verbose and should probably put in a longdesc attribute.\n\n\nfile_ext\nLogical. Does the alt text appear to be a file name?\nAlt text shouldn’t contain a file name.\n\n\nself_evident\nLogical. Does the alt text contain redundant phrases?\nIt doesn’t need to say ‘a picture showing…’ or similar.\n\n\nterminal_punct\nLogical. Does the alt text end in terminal punctuation?\nThe alt text should end in a sentence terminator, like a full stop. This means the screen reader will parse it as a proper sentence.\n\n\nspellcheck\nA listcol of character vectors detailing misspelled words according to hunspell from the {hunspell} package.\nErrors in spelling may result in the screen reader misreading a word.\n\n\nnot_basic\nA listcol of character vectors that aren’t in Charles Kay Ogden’s Basic English list.\nText is more accessible in general if it uses simple English.\n\n\n\nI’d like to hear your thoughts on these variables and if you’d like to suggest others. Contributions to the GitHub repository are very welcome.\n\n\n\nInterpret the data\nYou can take the output from alt_check() and investigate further. Here’s two very simple and plainly-presented examples.\nLet’s look first at the length of the alt text. This histogram shows the distribution of character counts coloured by the nchar_assess variable, giving different colours to alt text that’s under 20 (‘short’) or over 125 (‘long’) characters.\n\nlibrary(ggplot2)\n\nbbc_check %&gt;%\n  ggplot(aes(nchar_count)) +\n  geom_histogram(\n    aes(fill = nchar_assess),\n    binwidth = 5, \n    na.rm = TRUE\n  ) +\n  labs(\n    title = \"Distribution of character lengths in image alt text\",\n    subtitle = paste(\"BBC News home page,\", Sys.Date()),\n    caption = \"Source: https://www.bbc.co.uk/news via the {altcheckr} package\",\n    x = \"Character count\", y = \"Count\"\n  ) + theme_classic() + theme(legend.title = element_blank())\n\n\nSo you can there’s see a lot of short alt text that might need looking at if the images are meant to be informative. For example, here’s the 10 shortest:\n\nbbc_check %&gt;%\n  filter(nchar_count &lt; 20) %&gt;%\n  arrange(nchar_count) %&gt;%\n  distinct(alt, nchar_count) %&gt;%\n  slice(1:10)\n\n# A tibble: 10 x 2\nalt          nchar_count\n&lt;chr&gt;              &lt;int&gt;\n1 Fred                   4\n2 Santa                  5\n3 Crowds                 6\n4 Celeste                7\n5 Pork pie               8\n6 Liam Payne            10\n7 quiz promo            10\n8 Tie fighter           11\n9 Jamie Vardy           11\n10 Emma Spencer          12\nNext: how does the alt text of images make use of terminal punctuation (period, exclamation point or question mark)?\n\nbbc_check %&gt;%\n  group_by(terminal_punct) %&gt;%\n  summarise(Count = n()) %&gt;%  # count within the variable\n  ggplot(aes(x = terminal_punct, y = Count)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Existence of terminal punctuation (., !, ?) in alt text\",\n    subtitle = paste(\"BBC News home page,\", Sys.Date()),\n    caption = \"Source: https://www.bbc.co.uk/news via the {altcheckr} package\",\n    x = \"Terminal punctuation exists\", \n    y = \"Count\"\n  ) + theme_classic() +\n  coord_flip() + \n  theme_classic()\n\n\nSo most of the alt text does not end in terminal punctuation (FALSE), which is a bit disappointing. This means a screen reader might not fully parse the image as a complete sentence.\nNote that the findings here aren’t definitive and each case would need to be looked further into. However, these very shallow analyses imply that there are some improvements to make.\n\n\nNext steps\nThere’s a number of alt_check() additions that could be developed. For example:\n\noptical character recognition (OCR) to decide whether an image has text in it, and to possibly extract it\nguess the type of image based on its attributes and derived variables (a functional image might have relatively small height and width attributes, for example)\nassess the text in the link provided by the longdesc attribute, if it exists\ndetect ‘link stuffing’, where alt text is filed with keywords for purposes of search engine optimisation\n\nAnd of course: better unit testing and test coverage, simplifying the dependencies (there’s lots) and making the code more efficient. Tell me about other things that can be improved.\nUltimately, my call to action for R users is to explore the wealth of materials for package development1 and for everyone to take a moment to think about your users and the accessibility of whatever you’re producing."
  },
  {
    "objectID": "posts/2019-12-08-altcheckr/index.html#environment",
    "href": "posts/2019-12-08-altcheckr/index.html#environment",
    "title": "{altcheckr}: check image alt text from R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-23 11:06:21 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] altcheckr_0.1.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-12-08-altcheckr/index.html#footnotes",
    "href": "posts/2019-12-08-altcheckr/index.html#footnotes",
    "title": "{altcheckr}: check image alt text from R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nParticularly from Emil Hvitfeldt, Karl Broman and Hadley Wickham.↩︎"
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#tldr",
    "href": "posts/2023-09-10-lifecycle/index.html#tldr",
    "title": "The life and death of the tidyverse",
    "section": "tl;dr",
    "text": "tl;dr\nIn which I try to work out what functions and arguments in the tidyverse are badged as ‘experimental’, ‘deprecated’, ‘superseded’, etc. You can jump to the results table."
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#birth",
    "href": "posts/2023-09-10-lifecycle/index.html#birth",
    "title": "The life and death of the tidyverse",
    "section": "Birth",
    "text": "Birth\nThe tidyverse suite of packages develops quickly and there have been many API changes over the years. For example, gather() and spread() were superseded by pivot_longer() and pivot_wider() in {tidyr}, and there was a recent introduction of experimental .by/by arguments in several {dplyr} functions1.\nThe tidyverse uses the {lifecycle} package to advertise to users the current state of a function or argument, via a badge in the help files (e.g. ?tidyr::gather). There’s a good explanatory vignette about lifecycles if you want to learn more. The badges look like this: \nWith this in mind, wouldn’t it be fun—haha, I mean ‘informative’—to try and extract lifecycle information from tidyverse packages?2."
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#life",
    "href": "posts/2023-09-10-lifecycle/index.html#life",
    "title": "The life and death of the tidyverse",
    "section": "Life",
    "text": "Life\n\nFunctions\nFirst, we get the names of tidyverse packages from within {tidyverse} itself. Preparing these as e.g. package:tidyr will help us later to ls() (list functions) and detach() (remove the package from the search path).\n\n# Package names in the tidyverse\npkg_names &lt;- tidyverse::tidyverse_packages(include_self = FALSE)\npkg_envs &lt;- paste0(\"package:\", pkg_names)\npkg_names\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"         \n\n\n\n\nBadges\nThen we need the badge strings and some regular expression versions that will help with string handling later. ‘Stable’ shouldn’t need to be indicated, but I thought I’d add it for completeness. ‘Maturing’ and ‘Questioning’ have been superseded (lol, so meta), but there might still be some badges in the wild, maybe. I found at least one instance of ‘Soft-deprecated’ as well, which isn’t part of the r-lib lifecycle, so I included it too.\n\n# Badge strings in Rd\nlife_names &lt;- c(\n  \"Deprecated\", \"Experimental\", \"Superseded\",\n  \"Stable\",\n  \"Maturing\", \"Questioning\",\n  \"Soft-deprecated\"\n)\n\n# Regex to help detect lifecycle stages\nlife_names_rx &lt;- paste(life_names, collapse = \"|\")\n\n# Regex to help detect lifecycle badge format: '*[Experimental]*'\nbadges_rx &lt;-\n  paste0(\"\\\\*\\\\[(\", life_names_rx, \")\\\\]\\\\*\")\n\n\n\nHelp files\nI went down rabbitholes trying to extract help files for each function, but a Stackoverflow solution by MrFlick is exactly what I was looking for. It grabs a function’s underlying Rd (‘R documentation’) help file and outputs it to a vector with one element per string, thanks to a couple of functions from {tools}: the most underrated R package (prove me wrong).\n\n# Function to extract function help file from Rd\nget_help_text &lt;- function(fn, pkg) {\n  \n  # Prepare paths to package directory\n  file &lt;- help(fn, (pkg))\n  path &lt;- dirname(file)\n  dirpath &lt;- dirname(path)\n  rd_db &lt;- file.path(path, pkg)\n  \n  # Read rendered function docs (Rd)\n  rd &lt;- tools:::fetchRdDB(rd_db, basename(file))  # unexported function (':::')\n  \n  # Convert raw Rd to text and capture it as strings\n  capture.output(\n    tools::Rd2txt(rd, out = \"\", options = list(underline_titles = FALSE))\n  )\n  \n}\n\nHere’s a demo showing the description block of the function documentation for tidyr::gather(), which was superseded by tidyr::pivot_longer(). You can see how the ‘Superseded’ badge is represented: surrounded by square brackets and asterisks. That’s the pattern what we’ll need to search for.\n\nget_help_text(\"gather\", \"tidyr\")[3:13]\n\n [1] \"Description:\"                                                             \n [2] \"\"                                                                         \n [3] \"     *[Superseded]*\"                                                      \n [4] \"\"                                                                         \n [5] \"     Development on 'gather()' is complete, and for new code we\"          \n [6] \"     recommend switching to 'pivot_longer()', which is easier to use,\"    \n [7] \"     more featureful, and still under active development. 'df %&gt;%\"        \n [8] \"     gather(\\\"key\\\", \\\"value\\\", x, y, z)' is equivalent to 'df %&gt;%\"       \n [9] \"     pivot_longer(c(x, y, z), names_to = \\\"key\\\", values_to = \\\"value\\\")'\"\n[10] \"\"                                                                         \n[11] \"     See more details in 'vignette(\\\"pivot\\\")'.\"                          \n\n\nAnd here’s how the text is laid out for an argument:\n\nget_help_text(\"mutate\", \"dplyr\")[46:50]\n\n[1] \"     .by: *[Experimental]*\"                                            \n[2] \"\"                                                                      \n[3] \"          &lt;'tidy-select'&gt; Optionally, a selection of columns to group\" \n[4] \"          by for just this operation, functioning as an alternative to\"\n[5] \"          'group_by()'. For details and examples, see ?dplyr_by.\"      \n\n\n\n\nLoop-de-loop\nSo, the premise is to iterate over each package and, within each one, iterate through the functions to read their help pages and find any lifecycle badges. This’ll output a list (with an element per package) of lists (an element per function).\nNote that I’m retrieving help files from my local computer, having already downloaded the tidyverse packages with install.packages(\"tidyverse\").\nThere’s always discourse in the R community about for loops. So, as a special surprise, I decided to put a for loop in a for loop (yo dawg)3. I even pre-allocated my vectors, which is for nerds.\n\n# Prepare 'outer' list, where each element is a package\npkg_badges &lt;- vector(mode = \"list\", length = length(pkg_names))\nnames(pkg_badges) &lt;- pkg_names\n\n# Iterate over each package to get lifecycle badge usage\nfor (pkg in pkg_names) {\n  \n  # Extract package function names\n  library(pkg, character.only = TRUE)\n  pkg_env &lt;- paste0(\"package:\", pkg)\n  fn_names &lt;- ls(pkg_env)\n  \n  # Ignore these particular functions, which caused errors, lol\n  if (pkg == \"lubridate\") {\n    fn_names &lt;- fn_names[!fn_names %in% c(\"Arith\", \"Compare\", \"show\")]\n  }\n  \n  # Prepare 'inner' list, where each element is a function\n  fn_badges &lt;- vector(mode = \"list\", length = length(fn_names))\n  names(fn_badges) &lt;- fn_names\n  \n  # Iterate over each function to get lifecycle badge usage\n  for (fn in fn_names) {\n    \n    message(pkg, \"::\",  fn)\n    \n    txt &lt;- get_help_text(fn, pkg)  # fetch help file\n    lines_with_badges &lt;- grep(badges_rx, txt)  # find rows that contain badges\n    \n    badge_lines &lt;- NA  # default to no badges\n    \n    # If lines with badges exist, then extract the text\n    if (length(badge_lines) &gt; 0) {\n      badge_lines &lt;- trimws(txt[lines_with_badges])\n      badge_lines &lt;- sub(\"\\\\*[^\\\\*]+$\", \"\", badge_lines)\n    }\n    \n    fn_badges[[fn]] &lt;- badge_lines  # add to inner list of functions\n    \n  }\n  \n  pkg_badges[[pkg]] &lt;- fn_badges  # add to outer list of packages\n  \n  detach(pkg_env, character.only = TRUE)  # unclutter the search path\n  \n}\n\nSo here’s gather() again, with that ‘Superseded’ badge extracted, as expected. The list element will be empty if there’s no badge.\n\npkg_badges$tidyr$gather\n\n[1] \"*[Superseded]*\"\n\n\nAnd here’s how the badge for an argument looks in that .by example:\n\npkg_badges$dplyr$mutate\n\n[1] \".by: *[Experimental]*\""
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#entabulate",
    "href": "posts/2023-09-10-lifecycle/index.html#entabulate",
    "title": "The life and death of the tidyverse",
    "section": "Entabulate",
    "text": "Entabulate\nWe can convert this to a dataframe for presentational and manipulational purposes. I’m choosing to do that with stack(unlist()), mostly because I haven’t had a chance to use stack() in this blog yet. Handily, this approach also removes all the empty list elements for us.\n\nlife_df &lt;- stack(unlist(pkg_badges))  # stack is a nice function\nhead(life_df)\n\n                values                      ind\n1     *[Experimental]* dbplyr.get_returned_rows\n2     *[Experimental]* dbplyr.has_returned_rows\n3  vars: *[Deprecated]      dbplyr.partial_eval\n4 cte: *[Experimental]        dbplyr.remote_con\n5 cte: *[Experimental]       dbplyr.remote_name\n6 cte: *[Experimental]      dbplyr.remote_query\n\n\nThen we can do a bit of awkward string manipulation to get each package name, function name, argument names (if relevant) and the associated lifecycle badge(s).\n\n# Uncouple 'tidyr.gather' to 'tidyr' and 'gather'\nlife_df$Package &lt;- sub(\"\\\\..*\", \"\", life_df$ind)\nlife_df$Function &lt;- sub(\".*\\\\.\", \"\", life_df$ind)\n\n# Clean off the '*[]*' from the lifecycle badge text\nlife_df$values &lt;- gsub(\"(\\\\[|\\\\]|\\\\*)\", \"\", life_df$values)\n\n# Arg names are captured as a string before the lifecycle badge\nlife_df$Args &lt;- gsub(life_names_rx, \"\", life_df$values)\nlife_df$Args &lt;- trimws(gsub(\":\", \"\", life_df$Args))\nlife_df$Args[life_df$Args == \"\"] &lt;- NA\n\n# Badges appear after args (if any)\nlife_df$Badges &lt;- trimws(sub(\".*\\\\:\", \"\", life_df$values))\nlife_df$Badges &lt;- gsub(\" \", \", \", life_df$Badges)\n\n# Select and reorder\nlife_df &lt;- life_df[, c(\"Package\", \"Function\", \"Args\", \"Badges\")]\n\nSo now we have a table with one row per package and function:\n\nhead(life_df)\n\n  Package          Function Args       Badges\n1  dbplyr get_returned_rows &lt;NA&gt; Experimental\n2  dbplyr has_returned_rows &lt;NA&gt; Experimental\n3  dbplyr      partial_eval vars   Deprecated\n4  dbplyr        remote_con  cte Experimental\n5  dbplyr       remote_name  cte Experimental\n6  dbplyr      remote_query  cte Experimental\n\n\n\nResults\nHere’s an interactive table of the results. You can click the function name to be taken to the rdrr.io website, which hosts package help files in HTML on the web. Note that this won’t always resolve to a functioning URL for various reasons! If you’ve installed the tidyverse packages, you can of course see a function’s help page by running e.g. ?tidyr::gather.\n\n# Factors allow dropdown search in {DT}\nlife_df[names(life_df)] &lt;- lapply(life_df[names(life_df)], as.factor)\n\n# Build URL path to rdrr.io docs\nlife_df$Function &lt;- paste0(\n  \"&lt;a href='https://rdrr.io/cran/\", \n  life_df$Package, \"/man/\", life_df$Function, \".html'&gt;\",\n  life_df$Function, \"&lt;/a&gt;\"\n)\n\n# Build interactive table\nDT::datatable(\n  life_df, \n  filter = \"top\",\n  options = list(autoWidth = TRUE, dom = \"tp\"),\n  esc = FALSE\n)"
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#death",
    "href": "posts/2023-09-10-lifecycle/index.html#death",
    "title": "The life and death of the tidyverse",
    "section": "Death",
    "text": "Death\nYou can see a few patterns. For example:\n\nsome packages are not represented here at all, while others appear a lot (e.g. {googledrive} has a large number of deprecated functions, maybe due to a change to the API, or overhaul of package design?)\n‘Questioning’ is still being used in {rlang}, despite not being part of the {lifecycle} system\n{rlang} curiously has functions that are both ‘Experimental’ and ‘Soft-deprecated’ (perhaps an example of trying something and realising it wasn’t the right fit?)\nsometimes it’s more than one argument that gets a badge, which can happen when the same help page is being used by multiple functions (e.g. slice() and family’s help page has ‘Experimental’ for .by, by4, use of which differ depending on the exact function)\n\nPlus some other stuff I’m sure you can fathom out yourself.\nOf course, this all assumes that the badges are used consistently by developers across the suite of tidyverse packages. The method I used may also miss badges I’m not aware of, like the ‘Soft-deprecated’ example mentioned earlier.\nRegardless, the general approach outlined in this post might be useful for exploring other aspects of help pages, like the use of certain terms, grammar or writing styles. Documentation was a theme of the recent R Project Sprint 2023, after all.\nOf course, it helps to keep badged functions around so that people’s code remains reproducible. The downside is the potential for clutter and confusion, though the tidyverse packages sometimes warn you when something is old hat and suggest the preferred new method5.\nBut I think it’s an even better idea to keep these vestiges around to remind us that we all make mistakes. Oh, and, of course, that ✨ nothing is permanent ✨."
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#environment",
    "href": "posts/2023-09-10-lifecycle/index.html#environment",
    "title": "The life and death of the tidyverse",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-09-11 14:19:57 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3        bslib_0.5.0         xfun_0.39          \n [4] ggplot2_3.4.2       htmlwidgets_1.6.2   gargle_1.5.2       \n [7] tzdb_0.4.0          crosstalk_1.2.0     vctrs_0.6.3        \n[10] tools_4.3.1         generics_0.1.3      tibble_3.2.1       \n[13] fansi_1.0.4         pkgconfig_2.0.3     data.table_1.14.8  \n[16] tidyverse_2.0.0     dbplyr_2.3.3        readxl_1.4.3       \n[19] lifecycle_1.0.3     compiler_4.3.1      stringr_1.5.0      \n[22] textshaping_0.3.6   munsell_0.5.0       sass_0.4.7         \n[25] htmltools_0.5.5     yaml_2.3.7          jquerylib_0.1.4    \n[28] pillar_1.9.0        tidyr_1.3.0         ellipsis_0.3.2     \n[31] DT_0.28             googlesheets4_1.1.1 cachem_1.0.8       \n[34] tidyselect_1.2.0    rvest_1.0.3         conflicted_1.2.0   \n[37] digest_0.6.33       stringi_1.7.12      dplyr_1.1.2        \n[40] purrr_1.0.1         forcats_1.0.0       fastmap_1.1.1      \n[43] grid_4.3.1          colorspace_2.1-0    cli_3.6.1          \n[46] magrittr_2.0.3      utf8_1.2.3          broom_1.0.5        \n[49] readr_2.1.4         withr_2.5.0         scales_1.2.1       \n[52] backports_1.4.1     lubridate_1.9.2     googledrive_2.1.1  \n[55] timechange_0.2.0    rmarkdown_2.23      modelr_0.1.11      \n[58] httr_1.4.6          cellranger_1.1.0    ragg_1.2.5         \n[61] hms_1.1.3           memoise_2.0.1       evaluate_0.21      \n[64] knitr_1.43.1        haven_2.5.3         dtplyr_1.3.1       \n[67] rlang_1.1.1         glue_1.6.2          DBI_1.1.3          \n[70] xml2_1.3.5          reprex_2.0.2        rstudioapi_0.15.0  \n[73] jsonlite_1.8.7      R6_2.5.1            systemfonts_1.0.4  \n[76] fs_1.6.3"
  },
  {
    "objectID": "posts/2023-09-10-lifecycle/index.html#footnotes",
    "href": "posts/2023-09-10-lifecycle/index.html#footnotes",
    "title": "The life and death of the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEthan White wondered aloud recently if people are teaching learners to ungroup() then summarise(), or to use the ‘experimental’ .by argument within summarise() itself. Opinion: typically I prefer to avoid ‘deprecated’ or ‘superseded’ functions when teaching, like the mutate_*() suite that became mutate(across()). I’m a little wary of anything ‘experimental’ for teaching, for similarish reasons. But I do personally use them.↩︎\nI assume a running list of these functions/args must already exist, or this has already been explored by a third party. But forget them; we’re here to have fun!↩︎\nYeah, this approach is pretty awkward. Basically I was noodling around with some code and then realised I don’t really care to refactor it. That could be a nice treat for you instead.↩︎\nHaving mentioned teaching earlier, could this be awkward for learners? How do you teach that sometimes it’s by and sometimes its .by, especially when the same family of functions (like slice()) is inconsistent? You should teach people to look at help files, sure, but it would be nice if it was always predictable.↩︎\nI’ll leave the grumbling to you about whether all this chopping and changing of functions and arguments is A Good Thing or not; that’s not what this post is about.↩︎"
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html",
    "href": "posts/2020-02-27-get-blogging/index.html",
    "title": "Dear past self: blog",
    "section": "",
    "text": "I’m pretty sure that {blogdown} is a bit easier than {printingpressdown}1."
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html#tldr",
    "href": "posts/2020-02-27-get-blogging/index.html#tldr",
    "title": "Dear past self: blog",
    "section": "tl;dr",
    "text": "tl;dr\nThere are many reasons to start that R blog you’ve been thinking about. First and foremost, do it for you."
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html#why-blog",
    "href": "posts/2020-02-27-get-blogging/index.html#why-blog",
    "title": "Dear past self: blog",
    "section": "Why blog?",
    "text": "Why blog?\nI’ve stumbled into writing 50 posts on this blog. There was no plan. I have no strategy. It’s working so far.\nMy only regret was not starting sooner. How would I convince me-from-the-past?\n\nIt’s your reference library\nIt only has to be good enough\nThere are others like you\n\nI’ll explain.\n\n1. It’s your reference library\nI forget everything. That’s especially true for code.\nKeeping a written record of what you’ve learnt is a good way of storing that information outside of your head.\nWriting a narrative will help explain the code and make sure you understand it in your own words. That’ll make it easier to pick up later.\nIt helps if what you write is available to you everywhere all the time as well. It needs to be open and on the internet.\nProof is in the pudding: I’ve lost count of the number of times I’ve referred back to my own posts on creating an R package, web scraping and fixing leaky pipes, for example.\nFor me, ‘blog or it didn’t happen’ is probably a good mantra.\n\n\n2. It only has to be good enough\nPerfectionism is cruel and returns are diminishing. I sat on a thesis for months longer than I should have. Did it improve in that time? Marginally. Did it affect the outcome? Not really.\nThe spell was broken when someone told me that ‘it only has to be good enough’.\nYou have finite time and too much stuff to do, so maybe efficiency should be the focus. There’s a real, obtainable, minimum level of effort that will get you to a thing that works.\nConsider that in the context of writing blog posts for yourself. They only have to be good enough to remind you of what you did so you can redo the thing at some point in the future.\nThis will also encourage you to keep it short and simple. You’re far more likely to finish it that way. Write a follow-up later if you want to.\n\n\n3. There are others like you\nR solves so many problems efficiently and reproducibly. It’s particularly needed in the public sector, where I work, to build trust, reduce costs and do things quicker. I think there are plenty of people in this boat; why else are you reading this?\nI’m not a ‘programmer’, however. I wasn’t specifically trained in statistics. I definitely didn’t ‘get’ R at first and I’m probably never going to be an ‘expert’. So I might as well keep learning and sharing.\nBeing visible with your learning means that others can help you and give you ideas. Being open might even encourage other learners to get involved, too.\nConsider people like Sharla Gelfand and David Keyes (of R for the Rest of Us), who are visible on Twitter and unafraid of asking questions. One of R’s unique selling points is its friendly community. Make the most of it.\nUltimately, you don’t owe anything to anyone. But there are other people like you. Why not learn in the open and help lower the barrier to entry?"
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html#more-reasons",
    "href": "posts/2020-02-27-get-blogging/index.html#more-reasons",
    "title": "Dear past self: blog",
    "section": "More reasons",
    "text": "More reasons\nI think this would be enough to convince me-from-the-past, but maybe it’s not enough for you.\nAfter I started writing this I came across Rebecca Barter’s nice talk on Becoming an R Blogger at the recent RStudio Conference. Rebecca has also written a supporting blog post with some helpful information.\nIn particular, Rebecca mentions some reasons beyond ‘doing it for yourself’, like building up a portfolio of work, gaining exposure and squeezing some productivity into your procrastination. All extremely valid.\nTry it and let me know how it goes."
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html#environment",
    "href": "posts/2020-02-27-get-blogging/index.html#environment",
    "title": "Dear past self: blog",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 16:10:55 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-02-27-get-blogging/index.html#footnotes",
    "href": "posts/2020-02-27-get-blogging/index.html#footnotes",
    "title": "Dear past self: blog",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPublic Domain.↩︎"
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html",
    "href": "posts/2021-08-27-dehex-app/index.html",
    "title": "Adding a Shiny app to {dehex}",
    "section": "",
    "text": "Use the {dehex} app to generate a random hex code and learn how to interpret it by eye."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#tldr",
    "href": "posts/2021-08-27-dehex-app/index.html#tldr",
    "title": "Adding a Shiny app to {dehex}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {dehex} package now contains a Shiny app that you can use to walk through the process of reading a colour hex code, as per David DeSandro’s method."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#dehexcellent",
    "href": "posts/2021-08-27-dehex-app/index.html#dehexcellent",
    "title": "Adding a Shiny app to {dehex}",
    "section": "{dehex}cellent",
    "text": "{dehex}cellent\nIn the last post I introduced the R package {dehex}. Its purpose is to help me (you?) look at a colour hex code and be able to ‘read’ roughly what colour it is without resorting to a lookup.\n\n\n\nI promise this is a hex sticker, but it’s background is white, whoops.\n\n\nSo, the computer-friendly code ‘#C68738’ can be interpreted by your brain as the human-friendly phrase ‘middle washed orange’.\nThe package only exists because of a mind-melting talk by David DeSandro and his recommendation of the approach due to his colourblindness. I’m also colourblind and would prefer to ‘solve’ a colour than try and guess what it is from a sample."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#an-apportunity",
    "href": "posts/2021-08-27-dehex-app/index.html#an-apportunity",
    "title": "Adding a Shiny app to {dehex}",
    "section": "An apportunity",
    "text": "An apportunity\nThe {dehex} package uses a number of functions to help you through the steps of DeSandro’s method. It prints things to the R console to help you.1\nThere’s dh_shorten() to simplify the code to three digits; dh_graph() to make an RGB chart of your shortened hex code; dh_guide() to preview hue, saturation and lightness profiles to match against your shortened hex code; and dh_solve() to provide you with ‘the answer’, along with RGB charts for the nearest hue, saturation and lightness (HSL) profiles.\n\n\n\nAn RGB bar chart printed by {dehex} to the console, with guides for hue, saturation and lightness.\n\n\nThe trouble is that you have to know what order to run these functions. The documentation, README and blog post provide this information, as well as DeSandro’s resources, but it would be ideal to have an option to showcase {dehex} and learn stuff without needing to type any functions yourself.\nSo, I’ve created a simple Shiny app and made it available as the dh_app() function in {dehex}.2 I consider it ‘in development’ (this absolves me of liability if I say this, yes?).\nThe app depends on two packages: {shiny} and {bslib}. You’ll have to install these separately to {dehex} by using install.packages(c(\"shiny\", \"bslib\")) (if you haven’t already installed them on your machine).\nThese aren’t dependencies3 because you shouldn’t be forced to install them if you have no plans on using the app.4\nAside: what’s fun is I get to make further use of the Shiny app README badge I invented (?) with my {badgr} package, like so:"
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#lolwat",
    "href": "posts/2021-08-27-dehex-app/index.html#lolwat",
    "title": "Adding a Shiny app to {dehex}",
    "section": "lolwat?",
    "text": "lolwat?\nThe app is pretty simple.\nThere’s a big blue button labelled ‘Generate’. Click it and a random six-digit colour hex code is generated.\n\n\n\n‘That is the question.’\n\n\nYour then proceed through the numbered tabs to learn about each step, get some quick bullets of explanation, and then have the option to reveal help via some outputs from functions in the {dehex} package. There’s also a link to the relevant slide of David DeSandro’s talk.\nAs a beginner, you’ll want to reveal the tips to get maximum help. As you get better, you may not need to reveal them anymore.\nThe final tab provides the solution. You should have the answer by the time you get to this tab, but it reveals to you the hue, saturation and lightness RGB profiles that best match the generated hex code, along with the answer as a string, and a sample of the colour itself.\nThe app is purposefully low on interactivity. It’s just a little sidequest that bundles the steps and relevant {dehex} functions, in case you don’t want to run the functions from R itself.5\nOriginally I was going to just create an app to go on the web for anyone to use, but why would they want to see outputs from {dehex}? I also think that it’s worth reading DeSandro’s blog and watching or reading his talk in the first instance.\nAs ever, send suggestions, issues and pull requests in the GitHub repo for the package."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#environment",
    "href": "posts/2021-08-27-dehex-app/index.html#environment",
    "title": "Adding a Shiny app to {dehex}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-08 19:08:45 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#footnotes",
    "href": "posts/2021-08-27-dehex-app/index.html#footnotes",
    "title": "Adding a Shiny app to {dehex}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, but the quality of printing Unicode blocks in the app depends on what browser you’re using to view it. On macOS, Firefox seems fine. Other browsers don’t line up the little Unicode blocks nicely when outputting from dh_graph(). Ah well.↩︎\nYou can read about how to do this in Hadley Wickham’s ‘Mastering Shiny’ book.↩︎\nIn other words, they’re listed as Imports rather than Suggests in the DESCRIPTION file.↩︎\nUsing {bslib} is a bit lazy on my part because it makes it really easy to customise the style of a Shiny app, while forcing the user to have to install yet another package. This is not the tinyverse way, so I may refactor one day.↩︎\nThe ‘thought-of-a-thing-and-then-did-it-sort-of’ approach is very befitting of this blog and very apt given this is post number 100. 🎈↩︎"
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html",
    "href": "posts/2021-05-07-encrypted-rmd/index.html",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "",
    "text": "An attempted knitting/padlock visual pun with stitch markers."
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#tldr",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#tldr",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "tl;dr",
    "text": "tl;dr\nYou can knit an R Markdown file to an encrypted HTML with {encryptedRmd} and put it online with GitHub Pages. Users must enter the decryption key to download and view the content."
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#tinkr-tailr",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#tinkr-tailr",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "TinkR TailR",
    "text": "TinkR TailR\nI’m working on a personal project that outputs an HTML document rendered from an R Markdown file. I want to password-protect and share it with a specific person somehow. Also, sharing a hard copy by email is tedious; I’d rather they always had the latest version from a URL.\nMore importantly, I watched Tinker Tailor Soldier Spy1 over the weekend and I wanted to feign top-secret document handling."
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#invest-in-encrypto",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#invest-in-encrypto",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "Invest in encrypto",
    "text": "Invest in encrypto\nI’m a simple fellow. I don’t want to download or handle any extra software; I don’t want to configure anything; I like ‘free’ as in ‘I don’t have to pay for it’; I want minimal friction for the person accessing the content; I want the file to be standalone and self-contained.\nThere’s probably many ways to achieve this with R, but I decided to try out Dirk Schumacher’s {encryptedRmd} package, which I starred on GitHub a while ago and then forgot about.2 I’ve used GitHub Pages for hosting a bunch of stuff at no cost; might as well pop it there.\n\nExample\nI made a simple GitHub repo containing a demo of this approach. The encrypted HTML output is available online. I’ve embedded it below as well.\nYou’ll be asked for a key to decrypt it. For this demo, the key is: 9ebf5d40b061c59330b9fce16703e4c2fb2fbf90a773996e43e49d562ea17039.\n\n\nYour browser will prompt you to save and view the decrypted document if you enter the correct key. Prepare to see some extremely top secret information when you open that file.\n\n\nHow to\nHow was this created? In short, you knit an R Markdown as usual, but replace the output type in the YAML header. Here’s the steps:\n\nInstall {encryptedRmd} from CRAN if you haven’t already, using install.packages(\"encryptedRmd\")\nWrite an R Markdown file (i.e. extension .Rmd) where the output: field in the YAML header is set to encryptedRmd::encrypted_html_document\nKnit the file to render (i) an unencrypted ‘normal’ version HTML, (ii) an encrypted HTML version, and (iii) a text file containing a randomised decryption key, all of which are generated by default in the same folder that the Rmd is in\nTo serve, commit and push only the encrypted file to GitHub and then activate GitHub Pages for the repo (go to ‘Settings’ &gt; ‘Pages’)\n\nOf course, you should add the R Markdown file, the unencrypted HTML and the decryption key to your .gitignore file, otherwise the content will be available for people to see.\nI’ve retained all the output files in the demo repo so you can see them all. You can find them in the docs/ folder:\ndocs/\n├── encrypt-test.Rmd\n├── encrypt-test.html\n├── encrypt-test.enc.html\n└── encrypt-test.enc.html.key\nI told GitHub Pages to serve this docs/ folder from the main branch, so that the URL ends up as https://matt-dray.github.io/encrypt-rmd-test/encrypt-test.html.enc.html.3\nNow I can share the URL with someone and send them the key via a separate means of communication, like via a fax or a pigeon."
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#get-a-job-in-cyber",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#get-a-job-in-cyber",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "‘Get a job in cyber’",
    "text": "‘Get a job in cyber’\nSurprise, I am not a cyber security expert. You can read more about the libsodium encryption method underlying {encryptedRmd} if you’re wondering how it works, etc.\nAs noted by Dirk in the {encryptedRmd} README: use at your own risk.\nFor me, the outlined approach does what I need and does it painlessly. I have no intention to share actually-sensitive information via this method, so I have little to worry about. I’m Smiley as George Smiley in Tinker Tailor Soldier Spy.4"
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#environment",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#environment",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:35 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-05-07-encrypted-rmd/index.html#footnotes",
    "href": "posts/2021-05-07-encrypted-rmd/index.html#footnotes",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nStarring the adjective-name actors Strong Mark, Hurt John and Oldman Gary.↩︎\nAll too often I ‘discover’ a cool-sounding project on GitHub only to find I’ve already starred it. Partly I’m forgetful. Partly it’s because I’ve starred so many things. (I think this phenomenon should have a word. Possibly a compound German word. Or like ‘brown dwarf’, because it’s a celestial object that had potential to begin fusion but didn’t quite make it? Rubbish analogy.) The {encryptedRmd} case is especially amusing because apparently I gave a thumbs-up to an issue in the repo posted by my colleague Duncan.↩︎\nYou could simplify this by renaming your encrypted output file to index.html, which means you can refer to it with a shortened URL in the form user.github.io/repo-name/.↩︎\nSpoiler: he didn’t actually smile very much.↩︎"
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html",
    "href": "posts/2019-09-12-live-code/index.html",
    "title": "The Carpentries: teach with live coding",
    "section": "",
    "text": "An example of hardware carpentry, lol (Wikimedia Commons, CC BY-SA 2.0)."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#tldr",
    "href": "posts/2019-09-12-live-code/index.html#tldr",
    "title": "The Carpentries: teach with live coding",
    "section": "tl;dr",
    "text": "tl;dr\nI learnt a lot about how to teach live coding by becoming a Carpentries instructor.\n\n Note\nThis post was cross-posted to The Carpentries blog on 30 September 2019."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#carving-new-coders",
    "href": "posts/2019-09-12-live-code/index.html#carving-new-coders",
    "title": "The Carpentries: teach with live coding",
    "section": "Carving new coders",
    "text": "Carving new coders\nThe Carpentries is a global non-profit initiative to help build foundational skills in coding and data science. For example, Software Carpentry contains lessons about the shell, git, R and Python, while Data Carpentry and Library Carpentry teach more domain-specific knowledge.\nI took part in a two-day remote workshop to learn how to become a badged Carpentries instructor. There was a strong focus on understanding how people learn and how best to teach them to maintain motivation.\nThe schedule and materials from the workshop are available openly online. I encourage you to take a look and consider becoming an instructor yourself."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#whittling-down-the-complexity",
    "href": "posts/2019-09-12-live-code/index.html#whittling-down-the-complexity",
    "title": "The Carpentries: teach with live coding",
    "section": "Whittling down the complexity",
    "text": "Whittling down the complexity\nI learnt a lot from the part of the workshop about live coding and wanted to share the experience.\nThe Carpentries use a specific workshop format with an emphasis on using participatory live coding. This means people follow along with the instructor who is sharing their code on a screen at the front of the room. There are no slideshows to sit through, so no ‘death by PowerPoint’.\nThere are some features of live coding that make it conducive to learning:\n\nit slows down the pace so all learners can keep up\ninstructors must explain what they’re doing with every line, encouraging detailed explanation\nlearners become familiarised with running code given the particulars of their machine and software\nit’s beneficial for learners to see the instructor make mistakes and correct them\n\nI recommend looking at The Carpentries top ten tips for participatory live coding, which is a short but excellent resource to make sure people get the most out of your session."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#say-what-you-saw",
    "href": "posts/2019-09-12-live-code/index.html#say-what-you-saw",
    "title": "The Carpentries: teach with live coding",
    "section": "Say what you saw",
    "text": "Say what you saw\nYou can probably remember a workshop that you enjoyed and learnt a lot from. Maybe you can think of one that didn’t go so well. What was the difference? How can you, as an instructor, engage with participants and motivate learning?\nIn the ‘live coding is a skill’ lesson we watched two contrasting videos staged by Lex Nederbragt1 that show an instructor live-coding in front of a class.\nThese videos are linked in the sections below. Pay attention to whether they follow the top tips for live coding in particular.\n\nClamp down on negative behaviours\nFirst, take a look at this video of an instructor who has room to improve.\n\n \n\nWhat did you notice? What would make it difficult for you to engage?\nFor example, the instructor didn’t:\n\ncheck if everyone could see the small white-on-black text on the screen\nexplain each line as it was executed\nturn off notifications on their computer and phone\nnotice a participant’s sticky note (which signals that help is needed)\n\nThese are all behaviours that can be improved upon given feedback and reflection.\n\n\nMake it plane\nThe second video demonstrated more positive behaviours.\n\n \n\nFor example, the instructor:\n\nexplained each line as it was being typed\nre-sized the shell so people will always see the last-typed line\nphysically pointed out things on the projector screen to reinforce what was happening in the code\nmade an error, but talked it through\n\nThis time the instructor considered the needs of the audience and kept them engaged."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#hammer-it-home",
    "href": "posts/2019-09-12-live-code/index.html#hammer-it-home",
    "title": "The Carpentries: teach with live coding",
    "section": "Hammer it home",
    "text": "Hammer it home\nWe then did short, three-minute, live-coding demos of Carpentries materials in small groups. We provided feedback to help each other improve and engage better with learners.\nWe ran the demo twice each: the first time was relatively cold with little preparation, but for the second attempt we had a chance to react to the feedback and to think about the teaching demo assessment rubric.\n\nSanding the rough edges\nI chose to do the ‘exploring data frames’ episode of the R for Reproducible Scientific Research lesson of Software Carpentry.\nPositive feedback from my first attempt included that I:\n\nmade sure everyone could see what was on my screen and it was at a sufficient zoom level (I had reset RStudio to its defaults because this is what beginners would see)\ngave the learning objectives and recap of the previous session to remind people what we were doing and what we had done already\nexecuted code line by line at an appropriate speed with clear instructions\n\nSome points to improve upon where that I:\n\ndidn’t say out loud the keyboard shortcut that I was using to execute the lines\nsaid that the c() function was for ‘concatenating’ elements into vectors, which is a word that some people may not be familiar with\nused the word ‘simply’ when describing how to do something, a phrase that could undermine a learner’s progress if they aren’t able to complete that task (a case of an ‘expert blind spot’, as discussed in the ‘expertise and instruction’ lesson of the workshop)\n\n\n\nNailing it\nI reacted to the feedback to help improve things for my second live-coding demo. For example, I:\n\nsaid out-loud every action I was doing, including physical key presses when necessary (e.g. “and run this line with the command and enter shortcut”)\navoided phrases like ‘simply do this’ and ‘just do that’\nsaid that the ‘c’ in the c() function means to ‘combine’ rather than to ‘concatenate’2\n\nI also did a couple of extra things:\n\nadded three lines of comments at the top of the file to explain the objectives and goals\npre-loaded an object into the environment (they learnt how to do this in the previous session) to avoid a slightly awkward explanation at the beginning\nexpanded my RStudio window so more code be seen at once\n\nThe second attempt was well-received, thanks to feedback and a greater appreciation of the audience’s needs."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#i-axe-one-thing-of-you",
    "href": "posts/2019-09-12-live-code/index.html#i-axe-one-thing-of-you",
    "title": "The Carpentries: teach with live coding",
    "section": "I axe one thing of you",
    "text": "I axe one thing of you\nI got a lot out of the workshop and will be continuing the checkout process to get badged as a Carpentries instructor.\nDo take a look at the workshop materials, particularly the top ten tips for participatory live coding, and consider becoming an instructor yourself."
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#environment",
    "href": "posts/2019-09-12-live-code/index.html#environment",
    "title": "The Carpentries: teach with live coding",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-24 20:25:27 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2019-09-12-live-code/index.html#footnotes",
    "href": "posts/2019-09-12-live-code/index.html#footnotes",
    "title": "The Carpentries: teach with live coding",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLex Nederbragt is an instructor with many contributions to The Carpentries. I also recommend you check out the ‘good enough practices in scientific computing’ paper, of which he is an author.↩︎\nTo explain: the help page for c() actually says ‘combine’ in the title—‘Combine Values into a Vector or List’—but also says that the elements passed to it are ‘the objects to be concatenated’.↩︎"
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#tldr",
    "href": "posts/2020-05-02-aguerooooo/index.html#tldr",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "tl;dr",
    "text": "tl;dr\nI used R to animate the goal that won Manchester City the 2011/12 Premier League title in breathtaking fashion.\nInspired by Ryo Nakagawara, who makes awesome R-related soccer content that you can find on his site and on Twitter.1"
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#the-problem",
    "href": "posts/2020-05-02-aguerooooo/index.html#the-problem",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "The ‘problem’",
    "text": "The ‘problem’\nSoccer has run dry.\nLeagues have been cancelled or decided on a contentious points-per-game basis given that there’s no precedent. The fate of the 2019/20 English Premier League season is still unknown.2\nI figured it would be a good time to revisit a season that finished in the most emphatic fashion; one that was decided in the final minute of the final game.\n\nThe game\nCity and United were level on points at the top of the Premier League as they entered their final matches of the 2011/12 season. Only goal difference separated them.\n\n\n\nPos\nTeam\nPlayed\nGD\nPoints\n\n\n\n\n1\nManchester City\n37\n+63\n86\n\n\n2\nManchester United\n37\n+55\n86\n\n\n\nAs the game entered the closing stages, a dominant City somehow found themselves 2-1 down to a lacklustre Queens Park Rangers side.\nAfter sustained pressure, Edin Dzeko scored a towering header from a corner after 92 minutes. The game was level at 2-2, but it wouldn’t be enough to win the title; one more goal was needed.\nMeanwhile, Manchester United had won their concurrent game at Sunderland and had every right to think the title was theirs.\n\n\n\nPos\nTeam\nPlayed\nGD\nPoints\n\n\n\n\n1\nManchester United\n38\n+56\n89\n\n\n2\nManchester City\n38\n+63\n87\n\n\n\nBut after 93 minutes, City’s Nigel De Jong burst into QPR’s half. Sergio stepped forward, received the ball and beat his man. He passed to Mario Balotelli and continued his run into the box. Super Mario slid to the ground and pushed the ball into Agüero’s path.\nThe rest is history: Sergio received the ball, beat a slide tackle and smashed the ball into the goal. Cue commentator Martin Tyler screaming ‘AGÜEROOOOO!’.\n\n\n\nPos\nTeam\nPlayed\nGD\nPoints\n\n\n\n\n1\nManchester City\n37\n+64\n89\n\n\n2\nManchester United\n37\n+56\n89\n\n\n\nCity had done the impossible to win their first Premier League trophy and first top-flight title in 44 years."
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#reliving-the-moment",
    "href": "posts/2020-05-02-aguerooooo/index.html#reliving-the-moment",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "Reliving the moment",
    "text": "Reliving the moment\nSo the sensible thing to do is to use R to make a gif of the player movements in the build-up to the goal.\nYou may have seen something like this before from Ryo Nakagawara and others. I took a slightly different approach to Ryo, but the result is basically the same.\nYou need three packages:3\n\n{ggplot2}, created by Hadley Wickham, to provide the plotting framework\n{ggsoccer}, by Ben Torvaney, for the grid and pitch theme\n{gganimate}, by Thomas Lin Pedersen, for animating each step and interpolating between them\n\n\n# Load packages\nlibrary(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggsoccer) # Plot Soccer Event Data\nlibrary(gganimate) # A Grammar of Animated Graphics\nlibrary(tibble) # Simple Data Frames\n\nI also used {tibble} to create data frames with tribble(), but this isn’t a requirement."
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#set-coordinates",
    "href": "posts/2020-05-02-aguerooooo/index.html#set-coordinates",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "Set coordinates",
    "text": "Set coordinates\nYou need to start with coordinate data for the players and ball. {ggsoccer} defaults to a 100- by 100-unit pitch on which to plot these data. But where do you get it from?\nYou could use Opta’s premium service for accessing player-tracking data. My approach was more… artisanal. I just watched some grainy YouTube videos and roughly guessed where the players were.\nA really nice interactive tool that makes the process easier is the soccer event logger by Ben Torvaney, creator of {ggsoccer}.\n\nPlayers\nThe first data frame contains each player’s coordinates, with a row for each frame of the final animation. I added the player name so it could be used as a label.\nI chose to focus on the three active players in the build-up to the goal. This made the final graphic clearer, yes, but more importantly it meant I had fewer data points to input.\nI created the data frame using tribble() from the {tibble} package because I found it easier to input the data in a row-wise fashion. It’s also easy to write a comment per line to explain what’s happening.\n\n# Player position data\nplayers &lt;- tribble(\n  \n  ~frame, ~name, ~x, ~y,  # column names\n  \n  1, \"De Jong\", 50, 50,  # advances from own half\n  2, \"De Jong\", 56, 50,  # advances into oppo half\n  3, \"De Jong\", 64, 50,  # passes to Agüero\n  4, \"De Jong\", 64, 50,  # off the ball\n  5, \"De Jong\", 64, 50,  # off the ball\n  6, \"De Jong\", 64, 50,  # off the ball\n  7, \"De Jong\", 64, 50,  # off the ball\n  8, \"De Jong\", 64, 50,  # off the ball\n  \n  1, \"Agüero\", 85, 70, # diagonal run to meet ball from De Jong\n  2, \"Agüero\", 80, 65, # diagonal run to meet ball from De Jong\n  3, \"Agüero\", 75, 60, # receives pass from De Jong\n  4, \"Agüero\", 76, 63, # beats defender, passes to Balotelli\n  5, \"Agüero\", 80, 50, # advances to edge of box\n  6, \"Agüero\", 87, 38, # receives pass from Balotelli\n  7, \"Agüero\", 93, 36, # shot\n  8, \"Agüero\", 94, 33, # goal\n  \n  1, \"Balotelli\", 83, 61, # waiting on edge of box\n  2, \"Balotelli\", 83, 61, # waiting on edge of box\n  3, \"Balotelli\", 83, 61, # waiting on edge of box\n  4, \"Balotelli\", 83, 57, # waiting on edge of box\n  5, \"Balotelli\", 83, 55, # recieves pass from Agüero\n  6, \"Balotelli\", 83, 55, # passes to Agüero\n  7, \"Balotelli\", 83, 54, # off the ball\n  8, \"Balotelli\", 83, 54, # off the ball\n  \n)\n\nSo each player has coordinates for each time step.\n\n# Preview the data frame\nhead(players[order(players$frame), ])\n\n# A tibble: 6 × 4\n  frame name          x     y\n  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1 De Jong      50    50\n2     1 Agüero       85    70\n3     1 Balotelli    83    61\n4     2 De Jong      56    50\n5     2 Agüero       80    65\n6     2 Balotelli    83    61\n\n\n\n\nBall\nI put the coordinate data for the ball in a separate data frame. This made it easier to specify and modify separately the ball and player data.\n\n# Ball position data\nball &lt;- tribble(\n  \n  ~frame, ~x, ~y,\n  \n  1,  51, 50,  # De Jong possession\n  2,  57, 50,  # De Jong pass\n  3,  74, 60,  # receievd by Agüero\n  4,  77, 63,  # Agüero pass\n  5,  83, 54,  # received by Balotelli\n  6,  88, 38,  # received by Agüero\n  7,  94, 36,  # Agüero shot\n  8, 100, 46   # goal \n\n)"
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#graphics",
    "href": "posts/2020-05-02-aguerooooo/index.html#graphics",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "Graphics",
    "text": "Graphics\nThe first step in producing the animation is to create a single plot object that contains all the points. {gganimate} takes the object and animates it frame by frame, interpolating the data points between each time step.\n\nStatic plot\nTo produce the plot object:\n\nPlot the pitch area\nAdd ball data first so the points will appear ‘under’ the player points\nAdd player points and labels\nAdd a title\n\n\n# Plot all the data\nplot &lt;- \n  ggplot() +       # blank canvas\n  annotate_pitch(  # plot 100 * 100 unit pitch \n    colour = \"white\", fill = \"#7fc47f\", limits = FALSE\n  ) +\n  theme_pitch() +  # theme removes plotting elements\n  coord_flip(      # rotate and crop pitch\n    xlim = c(49, 101), ylim = c(-12, 112)\n  ) +\n  geom_point(      # add ball data\n    data = ball,\n    aes(x = x, y = 100 - y),\n    colour = \"black\", fill = \"white\", pch = 21, size = 2\n  ) +\n  geom_point(      # add player data\n    data = players, \n    aes(x = x, y = 100 - y), \n    colour = \"black\", fill = \"skyblue\", pch = 21, size = 4\n  ) +\n  geom_text(       # add player labels\n    data = players, aes(x = x, y = 100 - y, label = name),\n    hjust = -0.2, nudge_x = 1\n  ) +\n  ggtitle(         # add title\n    label = \"MCY [3]-2 QPR\",\n    subtitle = \"93:20 GOAL Sergio Agüero\"\n  )\n\nI’ve chosen to rotate the plot and crop it because we only need to see one half of the pitch. Note that this means the y-aesthetic for the points is set to 100 - y.\nThe output plot object is composed of all the frames that we set out in the player and ball data sets. You wouldn’t plot this object as-is, but here’s what it looks like:\n\nplot\n\n\n\n\n{gganimate} will take each time-step—specified by the frame variable—to render the animation. Here’s each of those frames from the player data.\n\nplot + facet_wrap(~ frame) + ggtitle(NULL, NULL)\n\n\n\n\n\n\nAnimated plots\n{gganimate} turns the static plot into an animation in one step.\nThe transition_states() function builds on top of the plot object. I specified the time-step variable; the durations for showing the frame and the interpolated frames between; and whether or not the animation should loop back to the start.\n\n# Animate the plot\nanimation &lt;-\n  plot +                   # the plot object\n  transition_states(\n    frame,                 # time-step variable\n    state_length = 0.01,   # duration of frame\n    transition_length = 1, # duration between frames\n    wrap = FALSE           # restart, don't loop\n  )\n\nYou can use the animate() function to render it.\n\nanimate(animation)\n\n\n\n\nAGÜEROOOOO!\nYou can save the result as a gif with anim_save(), which works like ggsave() from {ggplot2}: the default is to save the latest animation to your working directory.\n\nanim_save(\"9320.gif\")\n\nLuckily the gif keeps looping so you can keep watching until a decision is made on how the current Premier League season will end."
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#environment",
    "href": "posts/2020-05-02-aguerooooo/index.html#environment",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 11:39:13 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tibble_3.2.1    gganimate_1.0.8 ggsoccer_0.1.7  ggplot2_3.4.2  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    dplyr_1.1.2       compiler_4.3.1   \n [5] crayon_1.5.2      Rcpp_1.0.11       tidyselect_1.2.0  magick_2.7.4     \n [9] progress_1.2.2    scales_1.2.1      yaml_2.3.7        fastmap_1.1.1    \n[13] R6_2.5.1          labeling_0.4.2    generics_0.1.3    knitr_1.43.1     \n[17] htmlwidgets_1.6.2 munsell_0.5.0     pillar_1.9.0      rlang_1.1.1      \n[21] utf8_1.2.3        stringi_1.7.12    xfun_0.39         cli_3.6.1        \n[25] withr_2.5.0       magrittr_2.0.3    tweenr_2.0.2      digest_0.6.33    \n[29] grid_4.3.1        rstudioapi_0.15.0 hms_1.1.3         lifecycle_1.0.3  \n[33] prettyunits_1.1.1 vctrs_0.6.3       evaluate_0.21     glue_1.6.2       \n[37] farver_2.1.1      fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[41] tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2020-05-02-aguerooooo/index.html#footnotes",
    "href": "posts/2020-05-02-aguerooooo/index.html#footnotes",
    "title": "AGÜEROOOOO with {ggsoccer} and {gganimate}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlso a fellow builder of {brickr} soccer players.↩︎\nBut do check out posts by Ben Torvaney and Robert Hickman on predicting Premier League outcomes with R.↩︎\nAn aside: I used the {annotater} RStudio Addin by Luis D Verde to annotate these library calls.↩︎"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html",
    "href": "posts/2020-07-11-raspberry/index.html",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "",
    "text": "Raspberry Pi 2 Model B (rostrum.blog limited edition)"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#tldr",
    "href": "posts/2020-07-11-raspberry/index.html#tldr",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "tl;dr",
    "text": "tl;dr\nI installed R on a Raspberry Pi and set it up to use {blogdown}. This post was written from my Pi.\n\n Note\nSince I wrote this post it’s become much easier to get started with R on the Raspberry Pi with r4pi.org by Mark Sellors, along with VS Code. Read on for a more terminal-based experience."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#a-delicious-raspberry-pi",
    "href": "posts/2020-07-11-raspberry/index.html#a-delicious-raspberry-pi",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "A delicious Raspberry Pi",
    "text": "A delicious Raspberry Pi\n\nThe hardware\nThe Raspberry Pi is a small, inexpensive, single-board computer designed to make computing and coding accessible to all. It’s also popular in the maker community given its support for various peripherals like cameras and sensors.\nThe Pi was first released in 2012 and is now in its fourth generation of hardware. I was gifted a Pi 2 Model B in 2015 and have used it intermittently as a secondary computer and a video game emulation machine.\nI decided to pull my Pi out of retirement to explore how well it could run R, and more specifically, be used as a machine for blogging.\n\n\nRaspberry Pi OS\nThe Raspberry Pi is capable of running a large number of operating systems. The go-to is Raspberry Pi OS (formerly Raspbian), built on the open-source Debian Linux distribution.\nYou need to install the OS onto a micro-SD card1 via a second computer and then insert it into your Pi. Installing the Raspberry Pi Imager to your second computer will help you format (clean) the card and install the OS. At the time of writing, this was the May 2020 release.\nThere’s a full walkthrough for setting up your machine on the Raspberry Pi website."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#installing-software",
    "href": "posts/2020-07-11-raspberry/index.html#installing-software",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Installing software",
    "text": "Installing software\nWith the Pi set up, we can get on with installing the software we need to get blogging. Things may change over time, but the sections below describe what worked at time of writing. I’ve added software version numbers below for posterity.\nYou can click to jump to each section:\n\n1. Install R and an IDE\n\n1a. Install R\n1b. Install Neovim\n1c. Install Nvim-R\n\n2. Install blogging requirements\n\n2a. Install {blogdown}\n2b. Install Pandoc\n2c. Install Hugo\n\n\nIn each case, we’ll be running commands from the Terminal to install what we need.2\nBefore installing things, it’s a good idea to run the update command so that the latest package versions are installed\n\nsudo apt-get update\n\n\n1. Install R and an IDE\nIt’s not too tricky to get hold of R, but what coding environment can we use?\nI typically use the RStudio integrated development environment (IDE), but it isn’t available on this platform3. You could just run R from the Terminal, but it’s tedious to work entirely from the command line or copy-paste commands to it from a text editor.\nThis is where Nvim-R comes in. It turns your Terminal into an IDE.4\n\n1a. Install R\nR can be installed from the command line with:\n\nsudo apt-get install r-base r-base-core r-base-dev\n\nThis grabs the latest R version that’s available for the platform, which is 3.5. At time of writing, version 4.0 has been released on other platforms, so we’ll miss out on the latest advancements like stringsAsFactors=FALSE by default, sadly.\n\n\n1b. Install Neovim\nA prerequisite for Nvim-R is either Vim or Neovim. Nvim-R is a plugin for these tools.\nBut what are they, actually? Vim is a powerful text editor for the command line and Neovim is effectively a more extensible version of it.\nI’ve been using Neovim, which can be installed with:\n\nsudo apt install neovim\n\nAt time of writing, this installs version 0.3.4. You can enter Neovim by opening a terminal and running nvim. This puts you into a text editor interface.\n\n\n1c. Install Nvim-R\n\n\n\nNvim-R running in Terminal. Script up top, console below.\n\n\nThere are a whole bunch of plugins available for Neovim to help extend it. You can see these at the VimAwesome site.\nNvim-R by Jakson Alves de Aquino is one such plugin.\nAt the simplest level, Nvim-R turns your terminal into an R IDE by allowing for a concurrent script editor and console (along with many other features). This means you can write R code and send it to the console without having to copy-paste or write directly into the console. This is analagous to something like RStudio without the point-and-click features.\n\nvim-plug and Nvim-R\nWe can install a plugin manager to help install and manage Nvim-R and other Neovim extensions: vim-plug by Junegunn Choi.\nHaving installed Neovim, you can get vim-plug by running this via Terminal:\n\nsh -c 'curl -fLo \"${XDG_DATA_HOME:-$HOME/.local/share}\"/nvim/site/autoload/plug.vim --create-dirs \\\n       https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim'\n\nYou specify your plugins in a special init.vim file. Run the following line to create the file and open it in Neovim in the Terminal so you can begin editing:\n\nnvim ~/.config/nvim/init.vim\n\nYou can then toggle into Neovim’s ‘insert’ mode (press i) and paste (ctrl + shift + V) this in:\n\n\" Specify a directory for plugins\n\" - Avoid using standard Vim directory names like 'plugin'\ncall plug#begin('~/.vim/plugged')\n\n\" List of plugins.\n\" Make sure you use single quotes\n\n\" Shorthand notation\nPlug 'jalvesaq/Nvim-R', {'branch': 'stable'}\n\n\" Initialize plugin system\ncall plug#end()\n\nWhere Plug 'jalvesaq/Nvim-R' is the part where the Nvim-R plugin is specified.\nThis is a super minimal init.vim example. You can add a whole bunch of other plugins to this list that will allow for things like code autocompletion and themes. You can also add lines to this file to modify various settings within Neovim.\nEnter ‘normal’ mode (press Esc) and then type the following and hit Enter:\n\n:PluginInstall\n\nThis triggers the installation of the plugins you specified in the init.vim file. For me, this installed the latest Nvim-R version, 0.9.14.\nI found a YouTube video and a GitHub gist by Rohit Farmer really useful for doing these steps. Rohit provides some good examples of additional plugins that will improve your experience of Nvim-R.\n\n\nUsing Nvim-R\nA full run-through of how to use Neovim and Nvim-R are out of scope for this post, but it’s worth a quick aside here.\nTo open an .R or .Rmd script for editing in Nvim-R, you can:\n\ntype nvim and the path to your file, like nvim ~/path/to/file.R, from a Terminal\nright-click the file in the explorer and select ‘Nvim-R’, which will open that file in Nvim-R in a Terminal window\n\nThe important thing to know is that Neovim and Nvim-R are keyboard-driven; there’s no pointing-and-clicking like in RStudio. You’ll need to remember a bunch of non-obvious key presses to get around, although these are all configurable.\nSee Neovim’s docs for its key bindings (i.e. key presses that result in something happening), but here’s some useful ones:\n\ni to enter ‘insert’ mode and begin typing text\nEsc to exit insert mode and enter ‘normal’ mode\n:w and Enter to write (save)\n:q and Enter to quit (the most searched-for command in history?) or :q! to quit without saving\n:wq and Enter to save and quit\n^W and one of l, k, j or h to move focus around the ‘panes’ (e.g. script to console)\n\nAs for Nvim-R, see Section 4 of the docs for a full set of key bindings. Here’s some important default ones:\n\n\\rf opens a console\n\\l sends the current line to the console\n\\cc to send the current R Markdown chunk\n\\ro to open and close the object browser\n\n\n\n\n\n2. Install blogging requirements\nNow we’ve got everything we need to use R on the Raspberry Pi. My use case involves blogging, so now to install the requirements for that.\n\n2a. Install {blogdown}\nI used Yihui Xie’s {blogdown} package to build this blog and post to it.\nYou can install the package (currently v0.20) from CRAN. I found that I had to install {httpuv} separately first to prevent errors.\nYou can run this from Nvim-R or you can run R to start R from a Terminal window.\n\ninstall.packages(c(\"httpuv\", \"blogdown\"))\n\nOf course, you can go ahead and install any other packages you might need to write your posts.\nBut we also need two further things that aren’t R packages: Pandoc and Hugo.\n\n\n2b. Install Pandoc\n{blogdown} is based on turning R Markdown files into HTML files to be served as a website. A crucial element of this conversion process is a document converter called Pandoc. It can be installed via the Terminal with:\n\nsudo apt-get install pandoc\n\nThis installed version 2.2.1 at time of writing.\n\n\n2c. Install Hugo\nHugo is a static-site generator that builds your posts into a website, like the one you’re looking at now.\nYou can install Hugo from within R with blogdown::install_hugo(), but this failed for me because it tries to install a 64-bit version and Raspberry Pi OS is 32-bit.\nInstead, I used snapcraft, which describes itself as ‘the app store for Linux’. It bundles up everything you need for a given installation, including dependencies. This is great for a noob like me.\nTo enable the installation of ‘snaps’, you first need to run:\n\nsudo apt install snapd\n\nAfter a reboot, install the Hugo snap:\n\nsudo snap install hugo\n\nThis installed version 0.73.0 for me at time of writing."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#a-blogging-workflow",
    "href": "posts/2020-07-11-raspberry/index.html#a-blogging-workflow",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "A blogging workflow",
    "text": "A blogging workflow\nSo now we have everything installed, what’s the workflow for blogging?\nSetting up a blog is out of scope for this post, but you can find instructions for this in the blogdown companion book by Yihui Xie, Amber Thomas and Alison Presmanes Hill.\nThe flow could be something like:\n\nCreate a new YYYY-MM-DD-post-name.Rmd file for the post in content/post/\nOpen this file with Neovim-R and begin writing, including the YAML metadata and R Markdown chunks as usual (remembering that you can send R Markdown chunks to the console with the \\\\cc default key binding)\nUse blogdown::serve_site() from the console to render the site and serve it locally (it’ll open in your browser)\nCommit and push your changes to GitHub as normal (Git is preinstalled with Raspberry Pi OS5)\n\nFor images or other files you wan to embed in your post, create static/post/YYYY-MM-DD-post-name_files and refer to it from your post in the form /post/2020-07-07-post-name_files/image.jpg.\nTypically I would use the {blogdown} RStudio addin to help set up the YAML and put the files in the right place, but it isn’t a big deal to do this ‘manually’.\nThis approach works for me: you’re currently looking at a post made from my Raspberry Pi!"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#blow-a-raspberry",
    "href": "posts/2020-07-11-raspberry/index.html#blow-a-raspberry",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Blow a raspberry",
    "text": "Blow a raspberry\nI set up my Pi before thinking about writing a post about it, so I may have missed or misremembered a step here or there. Let me know if I’ve made an obvious error or if you run into problems if you’re following along.\nBear in mind that I have very little experience of Linux and Vim, but eager to learn. I’d also be grateful for any useful plugins or anything else you’d like to share.\nUltimately I’ve written this post so I can remember what to do when the time comes to upgrade to a newer, more delicious Raspberry Pi."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#environment",
    "href": "posts/2020-07-11-raspberry/index.html#environment",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 15:18:27 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#footnotes",
    "href": "posts/2020-07-11-raspberry/index.html#footnotes",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m using a spare card that’s only 16 GB. The OS will take up something like 2.5 GB.↩︎\nYou can open the Terminal from the taskbar (the icon with ’&gt;_’ on it) or via the Pi start menu under Accessories.↩︎\nThough you could use RStudio Cloud via the browser.↩︎\nNot Nevadans for Informed Marijuana Regulation (NVIMR).↩︎\nI recommend you introduce yourself to Git and set up keys for SSH to make this process seamless (these links go to Happy Git With R by Jenny Bryan, the STAT 545 TAs and Jim Hester).↩︎"
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#tldr",
    "href": "posts/2023-02-02-trapinch/index.html#tldr",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve used the {httr2} R package to create {trapinch}, a package that wraps PokéAPI for fetching Pokémon data.\n\n Note\nI had found a couple of older, non-{httr2} PokéAPI wrappers for R (see footnotes), but had somehow missed one that already uses {httr2}: see Ash Baldry’s {pokeapi} package, which he wrote months ago!"
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#httr-me-baby-one-more-time",
    "href": "posts/2023-02-02-trapinch/index.html#httr-me-baby-one-more-time",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "{httr} me baby one more time",
    "text": "{httr} me baby one more time\nThe {httr2} package lets you talk to the internet. Or, if you’re fancy, it ‘helps you deal programmatically with HTTP requests and responses’ so you can use it to fetch data from Application Programming Interfaces (APIs).\n{httr2} has functions that are prefixed consistently (req_*(), resp_*(), etc), are narrow in scope, pipeable (|&gt;) and which return nice errors and messages. These are neat improvements on the original {httr} package.\nI’ve used {httr} before to explore R package startup messages and detect linkrot. It’s time to try out {httr2}. What simple API can I wrap into an R package?1"
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#poke-an-api",
    "href": "posts/2023-02-02-trapinch/index.html#poke-an-api",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Poke an API",
    "text": "Poke an API\nRegular readers will be unsurprised that I’ve chosen the PokéAPI API for fetching all sorts of information related to the Pokémon game franchise.2\nPokéAPI provides a relatively simple API. You don’t need to sign-up or use API tokens, you can only read (‘GET’) data from it’s not rate-limited.\nURL paths for fetching data are also straightforward: you append an endpoint and a resource of interest to the base URL in the form https://pokeapi.co/api/v2/{endpoint}/{resource}.3\nIn other words, you could type https://pokeapi.co/api/v2/pokemon/lotad in your browser and the API would respond with a JSON file containing data about Lotad, the best Pokémon.\n{httr2} lets us do this programmatically and can return a more R-friendly list object."
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#its-a-trapinch",
    "href": "posts/2023-02-02-trapinch/index.html#its-a-trapinch",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "It’s a trapinch",
    "text": "It’s a trapinch\nSo, I’ve created the {trapinch} package.\nIt’s a proof of concept; a work in progress. There’s probably bugs. I’m sharing it in case I don’t take it any further, or if you want to contribute an issue or pull request.\nYou can download it from GitHub. It depends on {httr2} (obviously), {rcurl} and R version 4.1 or higher4 and can be downloaded from GitHub:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/trapinch\")  # v0.0.1 in this post\nlibrary(trapinch)\n\nDon’t be surprised if function names or general functionality change in future. In particular, I’d like to look at throttling (limiting the number of API calls to prevent misuse) and to provide sensible errors for timeouts or if the service is down.\n\nGotta GET ’em all\nThere’s a generic low-level function, get_pokeapi(), to which you pass the endpoint and resource ID (numeric) or name (character) of interest. Each endpoint also has its own dedicated function, like get_item() or get_move() that calls get_pokeapi() under the hood.\nYou can look at the inbuilt resource_lookups list to get a dataframe of resource IDs and names for each endpoint, as well as the full URL needed to query the API. Here’s the first few:\n\nhead(names(resource_lookups))\n\n[1] \"ability\"        \"berry\"          \"berry-firmness\" \"berry-flavor\"  \n[5] \"characteristic\" \"contest-effect\"\nSo here’s the first few rows of the resource dataframe for the ‘pokemon’ endpoint:\n\nhead(resource_lookups[[\"pokemon\"]])\n\n  id       name                                  url\n1  1  bulbasaur https://pokeapi.co/api/v2/pokemon/1/\n2  2    ivysaur https://pokeapi.co/api/v2/pokemon/2/\n3  3   venusaur https://pokeapi.co/api/v2/pokemon/3/\n4  4 charmander https://pokeapi.co/api/v2/pokemon/4/\n5  5 charmeleon https://pokeapi.co/api/v2/pokemon/5/\n6  6  charizard https://pokeapi.co/api/v2/pokemon/6/\nOne of these resource names is ‘mew’, the legendary first-generation Pokémon.5 You could use get_pokeapi(\"pokemon\", \"mew\") to retrieve its data, or more simply:\n\nmew &lt;- get_pokemon(\"mew\")\n\nThe function returns a list of lists, which is parsed from the JSON response returned by the API. So for the ‘pokemon’ endpoint we get 18 different elements of various classes:\n\nstr(mew, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nI’ve shown only the top level structure to hide some of the complexity. For example, the ‘moves’ item contains all the moves a Pokémon can learn, at what level it can learn them, in which game it learns them, and so on. Grabbing the first of the 363 ‘moves’ items (!) listed for Mew looks like this (oof):\n\nmew[[\"moves\"]][[1]][[\"move\"]][[\"name\"]]\n\n[1] \"pound\"\nA future task might be to simplify some of this complexity by collapsing deep lists into dataframes where possible.\n\n\nThumbing the Pokédex\nThe API responses are ‘paged’, meaning that you must make successive requests of a set size to retrieve all the data for a given endpoint. The get_*() functions automatically expand the request to ask for all the items in one go.\nWe know the maximum number of items to be returned from an endpoint because the stored in the resource_lookups object, so this can be appended automatically to the request string.\n\n\nBILL’s PC\nResponses are cached, which means that the data is saved on your computer. If you make the same request, the data will be retrieved first from the cache rather than calling the API again. That means there’s one less request for the API to deal with.\nThe cache is the path resolved by R_user_dir(\"trapinch\", \"cache\"). This function was introduced in R v4.0 for platform-independent storage of package-related data on a user’s machine.6 You can delete everything from the cache with clear_cache().\n\n\nSubstitute\n{httptest2} is a handy package that lets you test code written with {httr2}, specifically.\nWhy would you need special testing for API calls? The idea is that you should be able to test your package without the need for an active internet connection. {httptest2} ‘records’ the calls you make when you run your tests, then chooses when testing between this ‘mock’ response and a ‘live’ response.\nThe approach is pretty simple if you’ve tested before with {testthat}: you wrap your normal test_that() call with httr2::with_mock_dir(). Here’s an example of a test that make sure we get a list back from the API when we use get_pokeapi():\n\nwith_mock_dir(\"endpoint\", {\n  test_that(\"a list is returned\", {\n    expect_type(get_pokeapi(\"move-battle-style\"), \"list\")\n  })\n})\n\nBy wrapping the test in with_mock_dir(), {httptest2} creates the directory tests/endpoint/ that stores a copy of the JSON returned for this call when an internet connection was live.\nAs an aside, I learnt about curl::has_internet() in Colin’s blogpost, which can stop() the get_*() functions if there’s no internet connection. But has_internet() will trigger if you’re offline when you test, defeating the purpose of {httptest2}! Luckily, I saw a timely post by Maëlle about integrating this type of check into an ‘escape hatch’ so your unit tests can be run successfully in this scenario.\nThe rOpenSci HTTP Testing book is a good general port of call as well."
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#inside-the-poké-ball",
    "href": "posts/2023-02-02-trapinch/index.html#inside-the-poké-ball",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Inside the Poké Ball",
    "text": "Inside the Poké Ball\nThe user-facing functions of {trapinch} are therefore pretty simple. I could leave it at that.\nBut how daunting does the underlying {httr2} code look in the back-end? Turns out that it’s not that scary, thanks to those friendly and modular functions of {httr2}.\nWe can walk through that earlier get_pokemon(\"mew\") call using bare {httr2} functions by:\n\nStarting with the base API URL\nAppending the endpoint and resource as extensions (i.e. in the form /pokemon/mew)\nAdding a query for the maximum number of items in this endpoint-resource combo (i.e. ?limit=1279)\nAnnouncing to the API, as courtesy, who has made the call (i.e. who is the ‘user agent’)\nSpecifying the cache location for results to be saved\n\nFirst some variables:\n\nendpoint &lt;- \"pokemon\"\nresource &lt;- \"mew\"\nbase_url &lt;- \"https://pokeapi.co/api/v2/\"\nuser_agent &lt;- \"trapinch (http://github.com/matt-dray/trapinch)\"\nresource_count &lt;- nrow(trapinch::resource_lookups[[endpoint]])\ncache_dir &lt;- tools::R_user_dir(\"trapinch\", which = \"cache\")\n\nAnd now we can build our request with {httr2} functions prefixed with req:\n\nlibrary(httr2)\n\nmew_request &lt;- request(base_url) |&gt;\n  req_url_path_append(endpoint, resource) |&gt;\n  req_url_query(limit = resource_count) |&gt;\n  req_user_agent(user_agent) |&gt;\n  req_cache(cache_dir)\n\nPrinting the object summarises the request:\n\nmew_request\n\n&lt;httr2_request&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nBody: empty\nOptions:\n• useragent: 'trapinch (http://github.com/matt-dray/trapinch)'\nPolicies:\n• cache_path: '/Users/mattdray/Library/Caches/org.R-project.R/R/trapinch'\n• cache_use_on_error: FALSE\n• cache_debug: FALSE\nThen we can actually execute the request:\n\nmew_perform &lt;- req_perform(mew_request)\n\nAgain, we can peek at the object to get some extra information about the processing of the request:\n\nmew_perform\n\n&lt;httr2_response&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nStatus: 200 OK\nContent-Type: application/json\nBody: In memory (561317 bytes)\nWe can see the request was successful, since the HTTP status was 200 OK. Other status values are possible and may require us to try again later, for example.\nA couple of functions to mention here are last_request() and last_response(), which will also (surprise!) spit out info about the last request you made and the response received.\nFinally we can parse the JSON returned by the API. Again, I’m presenting the top-level structure only, given its complexity:\n\nmew_response &lt;- resp_body_json(mew_perform)\nstr(mew_response, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nBoom: this matches the information we retrieved earlier with get_pokemon(\"mew\")."
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#whos-that-pokémon",
    "href": "posts/2023-02-02-trapinch/index.html#whos-that-pokémon",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Who’s that Pokémon?",
    "text": "Who’s that Pokémon?\nI know you’re thinking ‘why trapinch?’ In short, it’s the name of a Pokémon that contains the letters ‘R API’, which is cute. It also makes for an easy hex sticker with the Pokémon’s characteristic zigzag mouth and colour palette of orange and grey.\nSo why not ‘rapidash’, which starts with ‘R API’? Easy, lol: trapinch isn’t taken yet on Repokémon, a page by Chee Aun that lists GitHub repositories that are named after Pokémon.7\n\nJoin me next time as I continue my quest to write (sometimes) useful R packages that help me squat all the remaining spots on Repokémon (I call this ‘RDD’).8"
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#environment",
    "href": "posts/2023-02-02-trapinch/index.html#environment",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 15:02:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-02-trapinch/index.html#footnotes",
    "href": "posts/2023-02-02-trapinch/index.html#footnotes",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere’s a GitHub repo with a big long list of free APIs that you can try out.↩︎\nThe PokéAPI website notes several wrappers in various languages. There exist R wrappers like UBC-MDS’s {pokedex} and Eva Nguyen’s {pokeWrapper}, but these appear smaller in scope and haven’t been updated for a while. (Edit: as noted at the top of this post, see also Ash Baldry’s {httr2}-powered {pokeapi} package, which I had somehow missed!)↩︎\nThere’s one exception: for Pokémon encounters you need the form /pokemon/{resource}/encounters. The get_pokeapi() function handles this extension with a third argument, ext, which is pre-filled with the string \"encounters\" in the get_pokemon_location_areas() function, so you don’t have to think about it.↩︎\nThis is entirely because I wanted to use tools::R_user_dir() for caching, which was introduced in v4.0. And if we’re depending on v4.0, why not bump to v4.1 and use the base pipe, |&gt;?↩︎\nI’ll say it: the original Japanese Red/Green Mew sprite was baller. Battle me.↩︎\nI made a mockery of R_user_dir’s functionality in my toy package {tamRgo}, which uses the location to store data for a persistent cyberpet (like a Tamagotchi) that you can interact with in the R console.↩︎\nI have history with this: my {dialga} package is named for the legendary ‘temporal’ Pokémon from the Diamond and Pearl games, which is fitting because the package converts between R code, cron strings and English.↩︎\nRepokémon-Driven Development.↩︎"
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html",
    "href": "posts/2022-11-13-tamRgo/index.html",
    "title": "Tamagotchi in R?",
    "section": "",
    "text": "Development of a {tamRgo} digital pet."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#tldr",
    "href": "posts/2022-11-13-tamRgo/index.html#tldr",
    "title": "Tamagotchi in R?",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve written the concept R package {tamRgo} to simulate a persistent digital pet in your R console, lol."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#had-an-oeuf",
    "href": "posts/2022-11-13-tamRgo/index.html#had-an-oeuf",
    "title": "Tamagotchi in R?",
    "section": "Had an oeuf?",
    "text": "Had an oeuf?\nR is a game engine1. Don’t @ me2.\nTurns out that R can keep a ‘save state’: developers can write a persistent file to the platform-independent path on a user’s machine resolved by tools::R_user_dir()3.\nOf course, I’ve used this to make a concept R package. {tamRgo} saves locally a ‘blueprint’ for a Tamgotchi-like digital pet4, which is read and updated when you interact with it in the R console.\nTamago (egg) + uotchi (‘watch’) = Tamagotchi. Tamago + R = {tamRgo}."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#nuovo-uovo",
    "href": "posts/2022-11-13-tamRgo/index.html#nuovo-uovo",
    "title": "Tamagotchi in R?",
    "section": "Nuovo uovo",
    "text": "Nuovo uovo\n\nInstall\nUse {remotes} to install the package from GitHub. There’s also an accompanying documentation website.\n\n# install.packages(\"tamRgo\")  # if not yet installed\nremotes::install_github(\"matt-dray/tamRgo\")\nlibrary(tamRgo)\n\nWelcome to {tamRgo}, a digital pet in the R console!\n - Docs: &lt;https://matt-dray.github.io/tamRgo&gt;\n - New pet: lay_egg()\n - Then: get_stats(), see_pet(), play(), feed(), clean()\nIt has no package dependencies, but you’ll need to be running a version of R greater than 4.0.\nOf course, it’s just a toy to demonstrate a concept. I’ve built out a bit of a ‘game loop’, but it’s just for fun and the code is not optimised. Bugs guaranteed, so suggestions and code contributions are always welcome.\n\n\nNew pet\nTo begin, you’ll need to generate you new cyberpet5 by laying an egg. You’ll be asked to confirm it’s okay to save a blueprint file onto your computer, which is just a small list object stored as an RDS file.\n\nlay_egg(pet_name = \"KEVIN\")\n\nSave pet blueprint? y/n: y\nSaved pet blueprint.\nYou have a new egg... it hatched!\nYou can get_stats(), see_pet(), play(), feed(), clean().\nThe blueprint will be saved at the location resolved by tools::R_user_dir(\"tamRgo\", \"data\"). You can always release() your pet into the wild, which will delete the blueprint file.\nSo, you have a new pet. Now what? The hint suggests to check the stats, so let’s do that.\n\nget_stats()\n\nCharacteristics\n Name:    KEVIN\n Species: Z\n Age:     0\n Level:   0 (newborn)\n Alive:   TRUE\nStatus\n Happy:   ■■■□□  \n Hungry:  ■■■□□  \n Dirty:   □□□□□  \nYou can see some characteristics: the name you provided, the pet’s species (X, Y or Z) and their age (days since ‘birth’). You can see the pet’s level (whatever that means) and whether they are currently alive. There’s also status values, which are followed by five-point gauges, some of which are filled.\nLet’s quickly check what our pet looks like with see_pet(). Its appearance depends on the species and the level; newborns are pretty much a blob, but your pet will grow and develop as it levels.\nThe rendering of the sprite, which is built with unicode block elements, will depend on the settings in your console. Your browser may also bork the the sprites as they appear in this post. See the package’s hex logo at the top of the page to get truer examples of the intended designs.\n\nsee_pet()\n\n░░░░░░░\n░░███░░\n░█░█░█░\n░█████░\n░██░██░\n░░███░░\n░░░░░░░\nCongratulations! KEVIN is a beautiful little chap.\n\n\nFeed\nHaving just been born, KEVIN is a bit peckish. You can tell because the ‘Hungry’ gauge is partially filled. Let’s lower the value by using feed().\n\nfeed()\n\n'Hungry' status value is now 2/5\nSee how the ‘Hungry’ counter decreased by 1 to 2?\n\nget_stats()\n\nCharacteristics\n  Name:    KEVIN\n  Species: Z\n  Age:     0\n  Level:   0 (newborn)\n  Alive:   TRUE\nStatus\n  Happy:   ■■■□□  \n  Hungry:  ■■□□□  \n  Dirty:   □□□□□  \n\n\nPlay\nYou can increase the ‘Happy’ value, which is currently 0, with play(). This begins a game of ‘higher or lower’ with user input. Yes, it’s not much of a skill-based game, but there’s a rumour that it’s easier under some circumstances and that a higher score is better for your pet’s wellbeing.\n\nplay()\n\nHigher or lower than 4? Type h or l: h\nWrong! It was 1. Score: 0/5.\nHigher or lower than 1? Type h or l: h\nCorrect! It was 8. Score: 1/5.\nHigher or lower than 4? Type h or l: h\nCorrect! It was 6. Score: 2/5.\nHigher or lower than 6? Type h or l: l\nCorrect! It was 5. Score: 3/5.\nHigher or lower than 7? Type h or l: l\nWrong! It was 10. Score: 3/5.\nResult: you scored 3/5!\n'Happy' status value is now 4/5\n\n\nClean\nAfter some time, your pet will become ‘dirty’, represented by a small pile of filth underneath their sprite.\n\nsee_pet()\n\n░░░░░░░\n░░███░░\n░█░█░█░\n░█████░\n░██░██░\n░░███░░\n░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\nWhich is almost as big as KEVIN himself, wow. You’ll just need to clean() it away.\n\nclean()\n\n'Dirty' status value is now 0/5\n\n\nPersistence\nPerhaps the most important thing to know is that you can end your R session and come back later and your pet will still be available. In fact, it will continue to live and grow on your computer while you’re away.\nMaybe you come back five days later. Here’s what you might see if you check your pet’s stats from any R session on your computer.\n\nget_stats()\n\nCharacteristics\n  Name:    KEVIN\n  Species: Z\n  Age:     5\n  Level:   2 (youngling)\n  Alive:   TRUE\nStatus\n  Happy:   □□□□□ !\n  Hungry:  ■■■■■ !\n  Dirty:   ■■■■■ !\nAha, so KEVIN’s age and level have increased since you’ve been away, even though you haven’t interacted with him for a while. But uh-oh, looks like his status values are at their worst.\nPay attention to these status values. Look after your pet! Apparently there’s a chance it might become… ‘unalive’. Rumour has it that good owners have longer-living pets…\nAnyway, let’s quickly check KEVIN’s appearance now he’s level 2.\n\nsee_pet()\n\n░░░░░░░░░░\n░░█░░░░█░░\n░░░█░░█░░░\n░░██████░░\n░░█░██░█░░\n░░██████░░\n░███░░███░\n░░██████░░\n░░█░░░░█░░\n░░░░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\n░░░░░░░\n░░░█░░░\n░░███░░  \n░█████░ \n░░░░░░░\nErm, well, cool antennae, bro. Totally distracts from the mess. Might need to clean() him."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#under-the-shell",
    "href": "posts/2022-11-13-tamRgo/index.html#under-the-shell",
    "title": "Tamagotchi in R?",
    "section": "Under the shell",
    "text": "Under the shell\nThe underlying logic is pretty simple. I don’t want to give away too many spoilers, but it’s worth explaining some of the main components a bit.\n\nBlueprint\nThe whole system is dependent on a ‘blueprint’ file, which is what gets stored at the tools::R_user_dir() location. It’s a list object with elements like the pet’s name, species (randomly generated), ‘date of birth’, accumulated XP, status values (happy, hungry, dirty) and some other things.\nThe blueprint is read and updated whenever you use a function from {tamRgo}. The current datetime is compared to the datetime of last interaction (stored in the blueprint) and the difference is used to calculate things like the pet’s age, XP accumulation and level and status values.\nThis gives the impression that the pet has been ‘alive’ on the player’s machine while they’ve been away. A trick6!\n\n\nExperience\nThe main goal is to accumulate XP and keep your pet alive. XP:\n\nis accumulated passively every hour\nis gained from the minigame in play(), where a higher score means more XP\nwill result in the pet levelling up when certain thresholds have been met, which alters their appearance\n\nAt a certain point, the pet will become ‘unalive’7. The chance of this happening is based on the pet’s accumulated XP. Basically:\n\nXP is ‘frozen’ at a certain age and the value is stored in the blueprint\nthe chance of becoming unalive is tied to the frozen XP value, where more XP means a lower chance\nthe number of days since the XP was frozen is used as a multiplier, so the chance of becoming unalive increases with time\n\nThe current XP count is stored in the blueprint, but is hidden from the user. This moves focus away from tracking and improving a single number and hopefully towards a more general goal of keeping your pet happy, well-fed and clean.\n\n\nSprites\nThere are character ‘sprites’ that change with age and species (see the image at the top of this post). The sprite for a newborn, mature and unalive pet are the same regardless of species, but the other levels are dependent on whether the pet is species X, Y or Z. Of course, these are pixellated to mimic the original Tamagotchi style.\nThe sprites are called by see_pet() as binary matrices of filled and unfilled ‘pixels’. I wrote the package {pixeltrix}, which I wrote about in my last blog post for a simple interactive way to design sprites by turning pixels ‘on’ and ‘off’ in a plotting window. Here’s a preview of a totally original little cyberfriend being incepted."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#practical-yolk",
    "href": "posts/2022-11-13-tamRgo/index.html#practical-yolk",
    "title": "Tamagotchi in R?",
    "section": "Practical yolk",
    "text": "Practical yolk\nThe package is not feature complete, lol8. To improve it, I could maybe9:\n\nanimate the pixel graphics\nallow blueprints to be transferred between machines, so your pet can live across multiple devices10\nadd a battle system like Digimon\nmake the play() minigame actually fun and so it grants more XP for greater skill\nmake more meaningful use of ‘hungry’ and ‘dirty’ statuses, perhaps include a hidden HP gauge that is reduced when these statuses are at their maximum for an extended period\n\nThe main point of this toy was for me to work out how to store data on a user’s machine. Should you actually do that? It depends. Can you use it in a silly R package for purposes of fun? Well, yes, if you ask me.\nYou can probably think of other ways to use tools::R_user_dir() for games in R, particularly for save states. Let me know when you’ve made a new triple-A game for R and I’ll add it to the list."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#environment",
    "href": "posts/2022-11-13-tamRgo/index.html#environment",
    "title": "Tamagotchi in R?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:05 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tamRgo_0.1.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#footnotes",
    "href": "posts/2022-11-13-tamRgo/index.html#footnotes",
    "title": "Tamagotchi in R?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOh, wait, I have to explain myself? Look no further than Mike Cheng’s rstudio::conf22 talk or the awesome-r-games list. I’ve written toys like {ActionSquirrel}, {safar6}, {potato} and {r.oguelike}.↩︎\nIf you do try and @ me, then you can now do it over at @mattdray@fosstodon.org.↩︎\nYou may be familiar with {rappdirs}, a package that helps you find directories. tools::R_user_dir() is nice because it’s built into R, so no dependency is required.↩︎\nFor the benefit of youths, a Tamagotchi was (is!) a little physical device that contains a ‘digital pet’, made popular in the late 90s. They have a little screen and physical buttons so you can see your pet and interact with it. Play with it, feed it, even reprimand it.↩︎\nThere are few terms that evoke the same wave of late-90s nostalgia.↩︎\nIllusions, Michael.↩︎\nA euphemism to protect the sensitive.↩︎\nMeanwhile, VS Code users can check out Anthony Shaw’s VS Code Pets to have a little cat or dog (or Clippy!) in their IDE. There’s also a lot of digital-pet implementations on various blogs and YouTube, but it was SquidGodDev’s Pocket Pets for the Playdate that really egged me on.↩︎\nHahaha, as if I’d finish a side project.↩︎\nIn fact, my initial approach to {tamRgo} was to store blueprints remotely in GitHub gists. The plus-side is that this could (in theory) let you battle other pets by reading their blueprints from a URL. The downside is the overhead of requiring a GitHub account and API access. If you want, you can peruse the {tamRgo} GitHub repo just before I moved from Gist-based to local blueprints.↩︎"
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html",
    "title": "Engifification in R with {gifski}",
    "section": "",
    "text": "I personally don’t evolve Lotad, because it’s already perfect."
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#tldr",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#tldr",
    "title": "Engifification in R with {gifski}",
    "section": "tl;dr",
    "text": "tl;dr\nUse {gifski} to make gifs—real quickly!—using R."
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#intergalactic-pizza-sloths",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#intergalactic-pizza-sloths",
    "title": "Engifification in R with {gifski}",
    "section": "Intergalactic pizza sloths",
    "text": "Intergalactic pizza sloths\nYou and I both know that the world needs more gifs of sloths riding through space on a slice of pizza, for example.\nGreat news: ‘the fastest gif encoder in the universe’ has come to R via the {gifski} package built by Jeroen Ooms for rOpenSci. It’s built on Gifski package for Rust, hence the speed.\nThe obvious analytical application is for creating gifs from plots, as in the following example from the rOpenSci announcement, which shows life expectancy by GDP per capita with a different year for each frame of the gif.\n\nBut no-one can stop us having fun with it too."
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#engifification-proclamation",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#engifification-proclamation",
    "title": "Engifification in R with {gifski}",
    "section": "Engifification proclamation",
    "text": "Engifification proclamation\nSo I’ve made a quick function that takes a folder of PNGs and stitches them into a gif using the gifski::gifski() function. I’ve called it make_gif() because it… makes gifs. It’s not optimised because it’s just for fun, okay?\n\nmake_gif &lt;- function(png_dir, gif_path, ...) {\n  \n  png_dir_is_char  &lt;- inherits(png_dir, \"character\")\n  gif_path_is_char &lt;- inherits(gif_path, \"character\")\n  \n  if (!png_dir_is_char | !gif_dir_exists) {\n    stop(\"png_dir and gif_path must be character class.\", call. = FALSE)\n  }\n  \n  png_dir_exists &lt;- dir.exists(png_dir)\n  gif_dir_exists &lt;- dir.exists(dirname(gif_path))\n  \n  \n  if (!png_dir_exists | !gif_path_is_char) {\n    stop(\"png_dir and gif_path directories must exist.\", call. = FALSE)\n  }\n  \n  path_is_gif &lt;- tools::file_ext(gif_path) == \"gif\"\n  \n  if (!path_is_gif) {\n    stop(\"gif_path must be a file path ending with .gif.\", call. = FALSE)\n  }\n  \n  files &lt;- list.files(\n    path = png_folder,\n    pattern = \".png$|.PNG$\",\n    full.names = TRUE\n  )\n  \n  if (length(files) &lt; 2) {\n    stop(\"You need two or more PNGs to make a gif.\", call. = FALSE)\n  }\n  \n  png(\"frame%03d.png\")\n  \n  par(ask = FALSE)\n  \n  dev.off()\n  \n  gifski::gifski(png_files = files, gif_file = gif_path)\n  \n}\n\nBasically, you must supply two things:\n\nA path to a folder containing the images (.png or .PNG only).\nA path for where the gif should be written (including the ‘.gif’ extension).\n\nOptionally you can provide a third: use the dots (...) to pass further arguments to gifski::gifski() (see ?gifski for details).\nNote that you should make sure your PNGs are ordered alphabetically or numerically in the named directory so that they’re engiffed1 in the desired sequence. Don’t worry if your folder has other filetypes; make_gif() only extracts PNGs."
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#hexapod-lilypad-frog-evolution",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#hexapod-lilypad-frog-evolution",
    "title": "Engifification in R with {gifski}",
    "section": "Hexapod lilypad-frog evolution",
    "text": "Hexapod lilypad-frog evolution\nI used the make_gif() function to create the important gif at the top of this post, featuring the evolution chain of Lotad, the best and most special Pokémon.\n\nmake_gif(\n  png_folder = \"~/Documents/pokemon/lotad/images\",  # folder of images\n  gif_path   = \"~/Desktop/lotad.gif\"                # path to save gif\n)\n\nMaybe you’ll find the function useful too. So get out there and get engiffing!2"
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#environment",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#environment",
    "title": "Engifification in R with {gifski}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 22:14:03 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#footnotes",
    "href": "posts/2018-07-26-engifification-in-r-with-gifski/index.html#footnotes",
    "title": "Engifification in R with {gifski}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI am endorsing the phrase ‘to engif’, as in ‘I am engiffing a bunch of PNGs’. There’s no way this doesn’t take off.↩︎\nActually, it doesn’t sound right does it?↩︎"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html",
    "href": "posts/2021-07-15-dollar-dollar/index.html",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "",
    "text": "Kiwi by Georgiana Ionescu. Laser embellishment in honour of Lucy Gray’s flag."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#tldr",
    "href": "posts/2021-07-15-dollar-dollar/index.html#tldr",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "tl;dr",
    "text": "tl;dr\nR’s $ data accessor symbol is part of an international ruse. I wrote a function so you can use your local currency symbol instead."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#pull-the-wool-from-your-eyes",
    "href": "posts/2021-07-15-dollar-dollar/index.html#pull-the-wool-from-your-eyes",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Pull the wool from your eyes",
    "text": "Pull the wool from your eyes\nYou’re an R user, so you’ll know how to access the contents of a quoted column name from a dataframe with square-bracket notation.\n\nmtcars[[\"cyl\"]]\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nThe dollar symbol ($) does the same thing, of course, in the form dataframe$column.\n\nmtcars$cyl\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nBut, like basically everything in R, it’s just a function.\nSo you can also use it in the ‘traditional way’ by passing the dataframe and column name to it as arguments inside brackets. You’ll need to use backticks (```) though, because function names can’t start with symbols or numbers.\n\n`$`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#wake-up-sheeple",
    "href": "posts/2021-07-15-dollar-dollar/index.html#wake-up-sheeple",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Wake up sheeple",
    "text": "Wake up sheeple\nBut why the dollar symbol? Something something ‘compatability with S’.\nOr perhaps a more sinister ploy by R’s original developers, Ihaka and Gentleman?\nLike a KIWI CONSPIRACY to raise awareness of the NEW ZEALAND DOLLAR (NZD) and INFLUENCE currency markets? I’m just asking the question.1\nSo, I’m giving you the FREEDOM to assign the functionality of the dollar symbol to another currency symbol, like, oh, I don’t know, the pound sterling symbol (£), as a completely random example.\n\n`£` &lt;- `$`\n`£`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nYou can’t use it in the dataframe$column form, however. That kind of behaviour is reserved for special symbols in R.2\n\nmtcars£cyl\n\nError: &lt;text&gt;:1:7: unexpected input\n1: mtcars£\n          ^\n\n\nShame. R has a little quirk that will make this work though. Sort of.\nYou can make a function do this by putting it between percentage symbols (%). This is called an ‘infix operator’ and you may have seen the {magrittr} pipe (%&gt;%) as one example.\n\n`%£%` &lt;- `$`\nmtcars %£% cyl\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nAs a complete coincidence, I live in Great Britain (GB) where we use pound sterling (£, or ‘GBP’).\nR also knows where I live (another conspiracy?).\n\nSys.getlocale()\n\n[1] \"en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\"\n\n\nThis string is R’s way of keeping track of the location-specific information that influences stuff like the language of error messages.\nYou can specify different locales for different things. Here’s my locale for ‘monetary’ parameters, for example.\n\nSys.getlocale(category = \"LC_MONETARY\")\n\n[1] \"en_GB.UTF-8\"\n\n\nThat particular value impacts parameters like the punctuation mark used for decimals and, wouldn’t you know it, the symbol used for currency.\n\nSys.localeconv()\n\n    decimal_point     thousands_sep          grouping   int_curr_symbol \n              \".\"                \"\"                \"\"            \"GBP \" \n  currency_symbol mon_decimal_point mon_thousands_sep      mon_grouping \n              \"£\"               \".\"               \",\"        \"\\003\\003\" \n    positive_sign     negative_sign   int_frac_digits       frac_digits \n               \"\"               \"-\"               \"2\"               \"2\" \n    p_cs_precedes    p_sep_by_space     n_cs_precedes    n_sep_by_space \n              \"1\"               \"0\"               \"1\"               \"0\" \n      p_sign_posn       n_sign_posn \n              \"1\"               \"1\""
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#mutton-dressed-as-lamb",
    "href": "posts/2021-07-15-dollar-dollar/index.html#mutton-dressed-as-lamb",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Mutton dressed as lamb",
    "text": "Mutton dressed as lamb\nSo, that means I can write you a function that gets the currency symbol for your locale and assigns to it the functionality of the dollar symbol, naturally.\n\ncopy_dollar &lt;- function() {\n  \n  # Get currency symbol for locale\n  currency &lt;- Sys.localeconv()[[\"currency_symbol\"]]\n  \n  # Report the locale\n  if (currency == \"$\") stop(\"KIWI CONSPIRATOR!\")\n  locale &lt;- Sys.getlocale(category = \"LC_MONETARY\")\n  cat(paste0(\"Your monetary locale is '\", locale, \"'\\n\"))\n  \n  # Generate and evaluate strings\n  expr_fn &lt;- paste0(\"`\", currency, \"` &lt;&lt;- `$`\")\n  expr_in &lt;- paste0(\"`%\", currency, \"%` &lt;&lt;- `$`\")\n  eval(rlang::parse_expr(expr_fn))  # function form\n  eval(rlang::parse_expr(expr_in))  # infix form\n  \n  # Report to user\n  cat(\n    paste0(\"Try `\", currency, \"`(df, col) and df%\", currency, \"%col\\n\")\n  )\n  \n}\n\nI used a bit of a trick3 there. You can’t use a string on the left-hand side of the assignment operator, but you can build an R expression as a string and eval()uate a parsed version of it (with some help from {rlang} in my example).\nI also used a special double-headed assignment arrow, &lt;&lt;-, that makes the objects available in the global environment.4 That means we can use the new functions outside the scope of the copy_dollar() function.\nAnd now: freeeedooooom.\n\ncopy_dollar()\n\nYour monetary locale is 'en_GB.UTF-8'\nTry `£`(df, col) and df%£%col\n\n\nWe got a couple of messages5 to confirm our location and let us know how we can use the new currency-symbol functions.\nAnd we can see these in the global environment.\n\nls()\n\n[1] \"%£%\"             \"£\"               \"copy_dollar\"     \"has_annotations\"\n\n\nAnd we can prove that GBP equals NZD, at least as a function for accessing columns of a dataframe.\n\nall(\n  mtcars %£% cyl == mtcars$cyl,\n  `£`(mtcars, cyl) == `$`(mtcars, cyl)\n)\n\n[1] TRUE\n\n\nOkay, works for my location. What about when I’m competing in Japan at the Olympics?6 Well, I can change the monetary locale.\n\nSys.setlocale(\"LC_MONETARY\", \"ja_JP.UTF-8\")\n\n[1] \"ja_JP.UTF-8\"\n\nSys.localeconv()\n\n    decimal_point     thousands_sep          grouping   int_curr_symbol \n              \".\"                \"\"                \"\"            \"JPY \" \n  currency_symbol mon_decimal_point mon_thousands_sep      mon_grouping \n              \"¥\"               \".\"               \",\"        \"\\003\\003\" \n    positive_sign     negative_sign   int_frac_digits       frac_digits \n               \"\"               \"-\"               \"0\"               \"0\" \n    p_cs_precedes    p_sep_by_space     n_cs_precedes    n_sep_by_space \n              \"1\"               \"0\"               \"1\"               \"0\" \n      p_sign_posn       n_sign_posn \n              \"1\"               \"4\" \n\n\nSo now you can see the yen symbol (¥) as the named currency value for this locale. And you can use the function to activate it for use as a data accessor.\n\ncopy_dollar()\n\nYour monetary locale is 'ja_JP.UTF-8'\nTry `¥`(df, col) and df%¥%col\n\n`¥`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nOh, and there’s no point trying to do this if your locale already uses the dollar for currency. I know you want as many dollars as possible, but don’t be greedy.\n\nSys.setlocale(\"LC_MONETARY\", locale = \"en_NZ.UTF-8\")\n\n[1] \"en_NZ.UTF-8\"\n\ncopy_dollar()\n\nError in copy_dollar(): KIWI CONSPIRATOR!\n\n\nI’ll reset my settings to the motherland to prevent any accidental borking.\n\nSys.setlocale(locale = \"en_GB.UTF-8\")\n\n[1] \"en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\"\n\n\nNothing ever goes wrong in Britain, after all."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#separate-your-sheep-from-your-goats",
    "href": "posts/2021-07-15-dollar-dollar/index.html#separate-your-sheep-from-your-goats",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Separate your sheep from your goats",
    "text": "Separate your sheep from your goats\nWhile you go and adjust your locale in an act of defiance, be on the lookout for the next New Zealander conspiracy.\nI heard that they want to replace the ampersand (&) symbol in R version 5 with NEWZEAL&, so stay on your toes.\nHang on…\nI think I used sheep-related phrases in all the section titles of this post. And aren’t there like 10 sheep per person in New Zealand?\nThey’ve got to me already!"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#environment",
    "href": "posts/2021-07-15-dollar-dollar/index.html#environment",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-20 22:50:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#footnotes",
    "href": "posts/2021-07-15-dollar-dollar/index.html#footnotes",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWith apologies to all the lovely people of New Zealand.↩︎\nYep, you could probably change this in the R source code and recompile it, but… effort.↩︎\n‘Illusions, Michael.’↩︎\nIn other words, assign like the single-headed ‘gets’ operator, &lt;-, but more so! You may know that I have strong feelings about assigment operators, lol.↩︎\nYes, I’m aware I’ve written the messages in English only. I can only break down one international barrier at once, pal.↩︎\nI heard that code golf is one of the new sports on display this year?↩︎"
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#tldr",
    "href": "posts/2021-07-25-faxcrayon/index.html#tldr",
    "title": "Make an art gallery with {bs4cards}",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {bs4cards} package by Danielle Navarro to create an effortless online ‘gallery’ of ‘art’ on a single R Markdown page: faxcrayon.art.\n\n Note\nI may decide to shutdown this site at some point. The code will always be available on GitHub, but the site may disappear. C’est la vie."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#art-is-a-lie",
    "href": "posts/2021-07-25-faxcrayon/index.html#art-is-a-lie",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Art is a lie",
    "text": "Art is a lie\nTurns out you can just put up some pictures on the internet and call it a gallery. No one is stopping you.\nHere is a foolproof approach: R Markdown with {bs4cards} to write the content, GitHub Pages to serve it, and a totally rad URL to convince people you’re legit."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#bs4cards",
    "href": "posts/2021-07-25-faxcrayon/index.html#bs4cards",
    "title": "Make an art gallery with {bs4cards}",
    "section": "{bs4cards}",
    "text": "{bs4cards}\nThe {bs4cards} package (available on CRAN) is great because it lets you create customisable ‘cards’ that you can tile on an R Markdown page.\nTo create a card, you use the card() function with arguments for title, image,1 text, link, etc. You can put these in a list and pass that to card_grid() to make a grid. Of cards. A card grid.\nSo, this format could work well to bring disparate information together in one central location, like a blog’s landing page, where a card’s content gives you a preview of post that you can click to visit it.\nSo I did just that: I made a single page2 where each card displays an art piece I created with R code for #RecreationThursday, or whatever.\nThe cards contain the creation date in the header; the ‘name’ of the piece as the card title, which links out to where the code is hosted for recreating it; and in the card body it states whether the image is a recreation, a remix or something original.\n\nYou can find the source on GitHub.\n\nGitHub Pages\nOne of the easiest ways to serve an R Markdown file on the internet is to store it in a GitHub repository, knit it to HTML and then enable GitHub Pages.\nYou go to the ‘Pages’ in your repository’s settings to enable it and then your HTML is served so that it’s available to anyone on the internet in the form &lt;username.github.io/repository-name/file.html&gt;.3\n\n\nDomain\nBut that doesn’t make for a terribly exciting URL. Since I’m going to be an internationally-famous and extremely financially-successful artist, it makes sense to improve my online brand with a rad URL.\nWhere to get inspiration? I’ve tweeted images for #RecreationThursday using the fax4 📠 and crayon 🖍️ emojis because I was using my rudimentary skills to create facsimile copies of original artworks. So… fax crayon? Like a wax crayon, but, like, fax?\nAnd the &lt;faxcrayon.art&gt; URL only cost two dollars to buy, so.\nThere’s a small dance you have to do to make GitHub Pages link to your domain, while your domain provider may themselves require a particular set of settings.\nIt took half an hour or so for the domain dance to complete, but now the site is available at faxcrayon.art."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#nothing-is-real",
    "href": "posts/2021-07-25-faxcrayon/index.html#nothing-is-real",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Nothing is real",
    "text": "Nothing is real\nSo: {bs4cards}, GitHub Pages and a totally hip URL.\nNow I just need to work out how to integrate NFT5 functionality to the site and quit my day job."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#environment",
    "href": "posts/2021-07-25-faxcrayon/index.html#environment",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:32:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#footnotes",
    "href": "posts/2021-07-25-faxcrayon/index.html#footnotes",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can pass card_image(\"&lt;path to image&gt;\", alt = \"Descriptive alt text.\") to the image argument of card() to help improve accessibility.↩︎\nIf you were less lazy than me you could turn this into a fully-blown R Markdown website, so that a card click takes you to a separate page for that piece.↩︎\nIf you’re feeling fancy, you can call your file ‘index.Rmd’, which knits to ‘index.html’, which GitHub Pages serves with the slightly more succinct URL &lt;username.github.io/repository-name&gt;.↩︎\nYounglings, the fax machine is an ancient and possibly imaginary piece of technology that’s a mash-up of a telephone, photocopier and printer. All in one!↩︎\nNon-Fungible Tokens are Not For ’Thew.↩︎"
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html",
    "title": "Pokéballs in Super Smash Bros",
    "section": "",
    "text": "My special edition Nintendo 64 playing Super Smash Bros."
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#tldr",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#tldr",
    "title": "Pokéballs in Super Smash Bros",
    "section": "tl;dr",
    "text": "tl;dr\nPokémon emerge at different rates from the pokéball item in Super Smash Bros (N64). Also {Rokemon} can make fun Pokémon-themed plots."
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#smash",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#smash",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Smash!",
    "text": "Smash!\nSuper Smash Bros (SSB) is a series of beat ’em up videogames featuring characters from various Nintendo franchises and beyond. The twist is that your health doesn’t deplete; instead you build damage so that subsequent hits knock you back further.\nThe series first featured on Nintendo 64 (Super Smash Bros, 1998).\nYou can fight characters directly but you can also make use of items and weapons from games across the Nintendo universe, such as the mushroom (the Super Mario series), the heart container (Zelda) and the home run bat (EarthBound).\nOne of the more interesting items in SSB is the pokéball. This item is used in the Pokémon series of games to capture and store Pokémon. When a player picks up and throws a pokéball in SSB, it opens to release 1 of a possible 13 Pokémon. The SSB wiki says that all of them are ‘common’, except for ‘uncommon’ Snorlax and ‘rare’ Mew (apparently only once every 151 releases, which is related to the number of Pokémon in the original game).\nSo how frequently in practice does each Pokémon emerge from a pokéball in SSB on N64?\nThis is a short post to sate my curiosity. I’ve used R code throughout. The post will update as I gather more data."
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#data",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#data",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Data",
    "text": "Data\nI’m a recovering ecologist, so data collection by observation is very important to me. I watched four computer-controlled players face-off in versus mode (it’s a weekend and I’m old enough to do whatever I want (after I’ve done my chores)). Pokéballs were the only items set to ‘on’ and frequency was set to ‘very high’. I saved the file as a CSV on GitHub.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(readr)\n\ncsv_path &lt;-\n  \"https://raw.githubusercontent.com/matt-dray/draytasets/master/ssb_pokeballs.csv\"\n\nballs &lt;- read_csv(csv_path, show_col_types = FALSE) %&gt;% \n  mutate(pokemon = tools::toTitleCase(pokemon))\n\nballs %&gt;% sample_n(25) %&gt;% pull()\n\n [1] \"Hitmonlee\" \"Hitmonlee\" \"Chansey\"   \"Beedrill\"  \"Charizard\" \"Chansey\"  \n [7] \"Beedrill\"  \"Koffing\"   \"Hitmonlee\" \"Hitmonlee\" \"Starmie\"   \"Beedrill\" \n[13] \"Onix\"      \"Chansey\"   \"Snorlax\"   \"Clefairy\"  \"Blastoise\" \"Starmie\"  \n[19] \"Charizard\" \"Snorlax\"   \"Charizard\" \"Koffing\"   \"Clefairy\"  \"Starmie\"  \n[25] \"Snorlax\""
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#frequencies",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#frequencies",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s take a look at some very basic presentation of the data.\nFirst, We can make use of the tabyl() function from the {janitor} package to get the count and percentage of each Pokémon.\n\nlibrary(janitor, warn.conflicts = FALSE)\n\nballs_summary &lt;- balls %&gt;%\n  tabyl(pokemon) %&gt;% \n  arrange(desc(n)) %&gt;% \n  mutate(Percent = round(percent * 100, 1)) %&gt;% \n  select(Pokemon = pokemon, Count = n, Percent)\n  \nknitr::kable(balls_summary)\n\n\n\n\nPokemon\nCount\nPercent\n\n\n\n\nBeedrill\n26\n9.0\n\n\nChansey\n26\n9.0\n\n\nGoldeen\n26\n9.0\n\n\nSnorlax\n26\n9.0\n\n\nBlastoise\n25\n8.6\n\n\nHitmonlee\n25\n8.6\n\n\nOnix\n25\n8.6\n\n\nKoffing\n24\n8.3\n\n\nCharizard\n23\n7.9\n\n\nStarmie\n23\n7.9\n\n\nMeowth\n20\n6.9\n\n\nClefairy\n18\n6.2\n\n\nMew\n3\n1.0\n\n\n\n\n\nOf course we can plot these data a well. It seems fitting to have a Pokémon theme, so we can use the gghealth() function from the {Rokemon} package by David Schoch. This creates a bar chart where the bars look like the health point (HP) meter from the original Pokémon games on the Nintendo Game Boy.1\n\nlibrary(ggplot2)\nlibrary(Rokemon)  # remotes::install_github(\"schochastics/Rokemon\")\n\n{Rokemon} has a function that imports the Pokémon font to use in its plots. Run import_pokefont() to install the pokemon-font.ttf font file to your machine. The path will be printed in your console. I’m running macOS, so I can copy this file into Font Book to make it available for use.\nAnd now we can plot.\n\nballs %&gt;% \n  count(pokemon) %&gt;% \n  gghealth(\"pokemon\", \"n\") +\n  labs(\n    x = \"\", \n    y = \"Count\",\n    title = \"Pokeball release frequencies\",\n    subtitle = \"Super Smash Bros on Nintendo 64\"\n  )"
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#revelation",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#revelation",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Revelation",
    "text": "Revelation\nSo it looks like the ‘common’ Pokémon according to the SSB wiki are indeed more common, though Snorlax appears equal first on this list, despite being labelled as ‘uncommon’. Clefairy also appeared less than expected, given it was labelled as ‘common’.\nMew appeared 3 times out of 290, which is once every 96.7 releases; less than the once every 151 releases I mentioned above.\nBear in mind that this is only based on a sample of 290 so far. I might collect more data at a later point.\nI hope this inside information will help you win your next Smash tournament. You are welcome."
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#environment",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#environment",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 09:28:16 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] Rokemon_0.0.1 ggplot2_3.4.2 janitor_2.2.0 readr_2.1.4   dplyr_1.1.2  \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    tidyr_1.3.0       stringi_1.7.12   \n [5] extrafontdb_1.0   hms_1.1.3         digest_0.6.33     magrittr_2.0.3   \n [9] evaluate_0.21     grid_4.3.1        timechange_0.2.0  fastmap_1.1.1    \n[13] jsonlite_1.8.7    purrr_1.0.1       fansi_1.0.4       scales_1.2.1     \n[17] cli_3.6.1         rlang_1.1.1       crayon_1.5.2      bit64_4.0.5      \n[21] munsell_0.5.0     withr_2.5.0       yaml_2.3.7        tools_4.3.1      \n[25] parallel_4.3.1    tzdb_0.4.0        colorspace_2.1-0  curl_5.0.1       \n[29] vctrs_0.6.3       R6_2.5.1          lifecycle_1.0.3   lubridate_1.9.2  \n[33] snakecase_0.11.0  stringr_1.5.0     htmlwidgets_1.6.2 bit_4.0.5        \n[37] vroom_1.6.3       pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.3     \n[41] glue_1.6.2        xfun_0.39         tibble_3.2.1      tidyselect_1.2.0 \n[45] rstudioapi_0.15.0 knitr_1.43.1      farver_2.1.1      extrafont_0.19   \n[49] htmltools_0.5.5   labeling_0.4.2    rmarkdown_2.23    Rttf2pt1_1.3.12  \n[53] compiler_4.3.1"
  },
  {
    "objectID": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#footnotes",
    "href": "posts/2018-05-19-pokeballs-in-super-smash-bros/index.html#footnotes",
    "title": "Pokéballs in Super Smash Bros",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlso check out the geom_pokemon() function in the ggimage package by Guangchuang Yu, which plots points as Pokémon sprites.↩︎"
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html",
    "href": "posts/2020-03-22-ninja-scaffold/index.html",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "",
    "text": "Example of modified Ninjutsu for ‘scaffolding’ a {xaringan} slide."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#tldr",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#tldr",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "tl;dr",
    "text": "tl;dr\nEmi Tanaka’s Ninjutsu CSS for {xaringan} breaks slides into ‘cells’, which are useful for arranging plots, tables, etc. I’ve been experimenting with Emi’s CSS to create my own layouts."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#slide-themes",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#slide-themes",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Slide themes",
    "text": "Slide themes\nThe {xaringan} package by Yihui Xie – an implementation of remark.js – lets you create reproducible slides with R.\nYou can create your own themes for {xaringan} by supplying some CSS. Yihui has encouraged users to add their themes to the package itself.\nTip: if you don’t know CSS, Garrick Aden-Buie’s {xaringanthemer} package lets you write R code and will generate the corresponding CSS for you."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#slide-layouts",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#slide-layouts",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Slide layouts",
    "text": "Slide layouts\nI was given a brief to create slides with a particular layout of page elements (plots, tables, text). How could I create a ‘scaffold’ in {xaringan} into which I could place the page elements?\nFortunately, Emi Tanaka1 created Ninjutsu2: CSS classes for splitting your page into columns and rows. This is now built into {xaringan} along with her Kunoichi theme3.\nFor example, the split-1-2-1 class from Ninjutsu splits the slide into three columns that are 25%, 50% and 25% of the total page width (hence ‘1-2-1’).\n\n.split-1-2-1&gt;.column:first-of-type {\n  width: 25%; height: 100%; position: absolute; top: 0; left: 0; \n}\n.split-1-2-1&gt;.column:nth-of-type(2) {\n  width: 50%; height: 100%; position: absolute; top: 0; left: 25%;\n}\n.split-1-2-1&gt;.column:nth-of-type(3) {\n  width: 25%; height: 100%; position: absolute; top: 0; right: 0;\n}\n\nThere’s one line of CSS for each of the three columns that the slide will be split into. In this example, the first column (first-of-type) starts from the extreme left (left: 0;), the middle column (nth-of-type(2)) starts where the first one ends (left: 25%;) and the third one (nth-of-type(3)) starts from the extreme right (right: 0;)."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#demo-ninja-scaffold",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#demo-ninja-scaffold",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Demo: ninja scaffold",
    "text": "Demo: ninja scaffold\nI adapted Emi’s CSS to create the layouts I wanted. You can:\n\nfind the source on GitHub\ninspect the relevant custom CSS\nsee a demo slideshow, or view it embedded below\n\n\n\n\n\n\n\n\n\nRead the rest of this post for an explanation of how I did it."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#adapting-the-layout",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#adapting-the-layout",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Adapting the layout",
    "text": "Adapting the layout\nSpecifically, I wanted to define title, body and footer-bar sections for:\n\na title page\na main, generic content page\na content page that could show a table and plot next to each other, with a wider table underneath\n\nThis means I could colour them and/or fill them with content according to some additional CSS formatting.\nTo do this, I tweaked Emi’s split-1-2-1 class to create classes with rows (rather than columns) split into the sections I wanted.\nBelow are some simplified examples of what I did. You can see the original CSS in the source code of the demo I’ve put on GitHub.\n\nDefining the classes\nThe title page has two rows, one is a large header area to hold a logo and the other is where the talk metadata goes (see demo):\n\n.split-title&gt;.row:first-of-type {\n  height: 35%; width: 100%; position: absolute; top: 0; left: 0;\n}\n.split-title&gt;.row:nth-of-type(2) {\n  height: 65%; width: 100%; position: absolute; left: 0; top: 35%;\n}\n\nThe main slide class has a title and footer section and the content goes in the large section between (see demo):\n\n.split-main1&gt;.row:first-of-type {\n  height: 15%; width: 100%; position: absolute; top: 0; left: 0;\n}\n.split-main1&gt;.row:nth-of-type(2) {\n  height: 80%; width: 100%; position: absolute; left: 0; bottom: 5%;\n}\n.split-main1&gt;.row:nth-of-type(3) {\n  height: 5%; width: 100%; position: absolute; bottom: 0; left: 0;\n}\n\nI modified slightly this class so the large blank area is split once more (see demo):\n\n.split-main2&gt;.row:first-of-type { \n  height: 15%; width: 100%; position: absolute; top: 0; left: 0;\n}\n.split-main2&gt;.row:nth-of-type(2) { \n  height: 40%; width: 100%; position: absolute; left: 0; top: 15%;\n}\n.split-main2&gt;.row:nth-of-type(3) { \n  height: 40%; width: 100%; position: absolute; left: 0; bottom: 5%;\n}\n.split-main2&gt;.row:nth-of-type(4) { \n  height: 5%; width: 100%; position: absolute; bottom: 0; left: 0;\n}\n\n\n\nUsing the classes\nHaving defined the CSS, how do we use it?\nLet’s say I’d saved this CSS into a file called custom.CSS, along with some font specifications in custom-fonts.CSS. Here’s a simplified YAML header showing how to declare these CSS files in your {xaringan} .Rmd file:\n---\ntitle: \"Example Title\"\noutput:\n  xaringan::moon_reader:\n    css: [default, ninjutsu, custom.css, custom-fonts.css]\n---\nThe CSS files are listed in this order so that the later-listed files take precedence if there’s any clashes. Remember also that in-built themes don’t need the .css file extension, but you need to provide the full path for any custom CSS.\nWith {xaringan} you name the class at the top of a slide to actually apply it, where slides are defined by three hyphens ---.\nYou can see an example in the source code of the demo I put on GitHub.\n\nClass split-main1\nSo, the split-main1 could be used like this:\n---\nclass: split-main1\n\n.row[.content[\nThis Is A Title\n]]\n\n.row[.content[\nThis is the main body area of the slide.\n]]\nRemember that the split-main1 class is split into three separate rows for the title, main body and footer sections. We can define what’s in each row with .row[] and then define the content inside a call to .content[].\nThe first .row[] call will take the style from .split-main1&gt;.row:first-of-type in our CSS, the second will take the CSS information from .split-main1&gt;.row:nth-of-type(2), and so on.\nNote that Ninjutsu also lets you adjust the content of classes by chaining calls like .content.vmiddle[], which will make the content vertically centred in this case.\n\n\nClass split-main2\nThe split-main2 class has an additional .row[] to define because the main body area is composed of two rows rather than one.\nHere I’ve added a split-two[] call inside the second .row[] call and declared .column[] twice within it. This results the main body area containing one row the width of the page and one row split into two columns (see demo).\n---\nclass: split-main2\n\n.row[.content[\nThis Is A Title\n]]\n\n.row[.content[\nThis is the second row of the page. It's full-width.\n]]\n\n.row[.content[\n.split-two[\n.column[.content[\nThis is the third row, which is split in two. This is the left column.\n]]\n.column[.content[\nThis is the right-hand column of the third row.\n]]\n]\n]]\n\n.row[\n]"
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#what-now",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#what-now",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "What now?",
    "text": "What now?\nI think there’s a lot of promise in this approach for making bespoke page layouts.\nI’ve already used this approach at work to design a {xaringan} template to a specification, which I used to help automate the generation of a large number of reports. In particular, I used the split-main2 class to arrange a small table in the top-left, a plot in the top-right, and a full-width wide table below them.\nIt’s possible to create these kinds of layouts in other ways – like in {pagedown} or with fancier CSS skills. For now I’m most comfortable with {xaringan} and the features it offers, like presenter notes and presenter view. But this is probably less important if your goal is to output to PDF.\nI look forward to seeing how Ninjutsu and other {xaringan} themes develop to help with page layouts for reproducible presentations."
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#environment",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#environment",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 15:54:05 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-03-22-ninja-scaffold/index.html#footnotes",
    "href": "posts/2020-03-22-ninja-scaffold/index.html#footnotes",
    "title": "Ninja scaffolding for {xaringan}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA certified great hacker.↩︎\nWikipedia: ‘the strategy and tactics of unconventional warfare, guerrilla warfare and espionage purportedly practiced by the ninja’.↩︎\nWikipedia: ‘a female ninja or practitioner of ninjutsu’.↩︎"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#tldr",
    "href": "posts/2021-04-18-pico-pkg/index.html#tldr",
    "title": "Make the simplest R package with {pico}",
    "section": "tl;dr",
    "text": "tl;dr\nI made {pico}, an R package for creating tiny R packages with the absolute minimum structure and content. The goal: to demystify package making."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#function-in-a-haystack",
    "href": "posts/2021-04-18-pico-pkg/index.html#function-in-a-haystack",
    "title": "Make the simplest R package with {pico}",
    "section": "Function in a haystack",
    "text": "Function in a haystack\nI saw a @WeAreRLadies tweet from last week’s curator, @ShreyaLouis. The gist was ‘how can you be more organised when recalling and reusing your own R code?’\nSee the thread for ideas, but I had the same thought as Fabio: create a personal package of your frequently-used functions so you can invoke them whenever you want.1"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#whats-the-problem",
    "href": "posts/2021-04-18-pico-pkg/index.html#whats-the-problem",
    "title": "Make the simplest R package with {pico}",
    "section": "What’s the problem?",
    "text": "What’s the problem?\nPackages are daunting, particularly if you haven’t made one before. I’ve written a number of packages for fun and learning, but none have been submitted to CRAN and I’m never quite sure if I’m doing everything ‘correctly’.\nFrom personal experience, I think the esoteric structure and content of R packages are a barrier to beginners. Like, what is the man/ folder and what’s an .Rd file? It’s easy to look at a chonky package repo on GitHub, like the popular {dplyr}, and despair.\nYes, you could RTFM (‘Read the Hecking Manual’) about R packages, but have you looked at it before? And it’s not even necessary to follow all of these steps if you don’t have dreams of submitting it to CRAN.\nWhat if—for teaching purposes—we strip back to the absolute barest of requirements with the goal of demystifying packages and to make it easier to get started?"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#minimalism",
    "href": "posts/2021-04-18-pico-pkg/index.html#minimalism",
    "title": "Make the simplest R package with {pico}",
    "section": "Minimalism",
    "text": "Minimalism\nWhat’s the least we need for a functioning package? Well, following Karl Broman’s book, all you need is two files and a subfolder. That is all.\nHere’s how it looks for an imaginary package called {mypkg}:\nmypkg/\n├── R/\n│   └── functions.R\n└── DESCRIPTION\nThe mypkg/R/functions.R file is a normal R script where you put your function definitions, like:\n\nsay_hi &lt;- function(name = \"buddy\") {\n  paste0(\"Ahoy-hoy \", name, \"!\")\n}\n\nThe DESCRIPTION file (which has no file extension) might not be as familiar, but it’s basically a text file with only two lines: the package name and a version number (typically 0.0.0.9000 indicates a package under development, whereas 0.1 might be a minor release).2\nPackage: mypkg\nVersion: 0.0.0.9000\nThe DESCRIPTION file is like a magic flag that identifies that this folder is special and contains an R package; it isn’t just a boring folder with some R scripts in it.\n…And that’s all you need."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#introducing-pico",
    "href": "posts/2021-04-18-pico-pkg/index.html#introducing-pico",
    "title": "Make the simplest R package with {pico}",
    "section": "Introducing {pico}",
    "text": "Introducing {pico}\nSo, you could point-and-click to create a folder with the structure and content outlined above, but I’ve also created the {pico} package to make the setup even easier.3\nThe basic process for using {pico} is:\n\nInstall {pico} with remotes::install_github(\"matt-dray/pico\")\nCreate your package with e.g. pico::create(\"mypkg\", \"~/Documents/\") (the second argument is a filepath for where to put the package folder)\nAdd new function definitions to the mypkg/R/functions.R script file\nInstall the package to your computer with remotes::install_local(\"~/Documents/mypkg\") and attach it like a normal package with library(mypkg)\n\nLater you can add more functions to R/functions.R (or add more script files to the R/ folder) and can reinstall the package with install_local(), using the force = TRUE argument to overwrite the old version.\nLet’s take a look at those steps in a bit more depth.\n\nInstall {pico}\nFirst, you can install {pico} from GitHub with help from the {remotes} package.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/pico\")\n\nYou can look up the help files with ?pico::create() at any time.\nIt’s a really small package, but let me know if you find any bugs or you want to contribute.\n\n\nCreate your package\nThere’s only one function in {pico}: create(). It generates a folder with the minimum required content, as outlined above. You supply a package name and a directory (folder on your computer) where you want your package to be generated.\nAs a demonstration, here’s how to create a pico package called {mypkg} in a temporary folder. You should put yours somewhere more permanent and convenient like ~/Documents on macOS, for example.\n\ntmp &lt;- tempdir()\npico::create(name = \"mypkg\", dir = tmp)\n\nPico package {mypkg} written to:\n  /var/folders/cg/5x7y2f0x6tqb9mqrc13pd8_40000gn/T//RtmpRGhTOc/mypkg\n\n\nThis will output some lines in the R console that confirm your new package has been written to the location you specified (my example path here is convoluted because it’s just a temporary folder).\nThe name will be checked against R-package naming standards: it should contain alphanumeric characters or periods only, must have at least two characters, and can’t start with a number nor end with a period. The provided directory also will be checked for existence and, if it already contains a folder with the proposed name of your package, you’ll be asked interactively if you want to overwrite it.\n\n\nInstall your package\nSo, the package now exists on your computer inside a folder. Now how do you use its functions in an R session?\nNormally, you would use install.packages() to fetch a package from CRAN and install it to your computer’s R package library. We can do something similar, but instead of fetching from CRAN, we can fetch the package ‘locally’, i.e. from your computer.\nTo do this, we can use the {remotes} package, which we installed earlier. It contains an install_local() function to which you pass the package’s filepath on your computer.\n\nremotes::install_local(\n  path = file.path(tmp, \"mypkg\")  # change to your packages filepath\n)\n\n\n\n✓  checking for file  ‘private/var/folders/cg/5x7y2f0x6tqb9mqrc13pd8_40000gn/T//RtmpRGhTOc/mypkg ’ ...\n ─  preparing ‘mypkg’:\n ✓  checking DESCRIPTION meta-information\n ─  checking for LF line-endings in source and make files and shell scripts\n ─  checking for empty or unneeded directories\n ─  creating default NAMESPACE file\n ─  building ‘mypkg_0.0.9000.tar.gz’\n \n * installing *source* package ‘mypkg’ ...\n ** using staged installation\n ** R\n ** byte-compile and prepare package for lazy loading\n ** help\n No man pages found in package  ‘mypkg’ \n *** installing help indices\n ** building package indices\n ** testing if installed package can be loaded from temporary location\n ** testing if installed package can be loaded from final location\n ** testing if installed package keeps a record of temporary installation path\n * DONE (mypkg)\n\n\nYou’ll see some output that describes the installation process, ending with DONE.\nThe package is now installed into your R package library and can be attached like any other package.\n\nlibrary(mypkg)\n\nNow the functions from the package are available for use. By default, create() added a dummy function called say_hi() to R/functions.R, which we can use now:\n\nsay_hi(\"chums\")\n\n[1] \"Ahoy-hoy chums!\"\n\n\nSo, we created an R package, installed it and used it."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#add-new-functions",
    "href": "posts/2021-04-18-pico-pkg/index.html#add-new-functions",
    "title": "Make the simplest R package with {pico}",
    "section": "Add new functions",
    "text": "Add new functions\nOf course, you’ll want to add your own functions to your package. The basic steps are:\n\nOpen the R/functions.R script\nPaste in your function definitions and save the file\nRerun remotes::install_local() with the argument force = TRUE\nRestart R, so the updated package is recognised\n\nHere’s what this might look like for our example package. First, you might add the function say_bye() by adding these lines to the functions.R file:\n\nsay_bye &lt;- function(name = \"folks\") {\n  paste0(\"Cheerio \", name, \"!\")\n}\n\nAfter you saved the updated file, you can re-run install_local() with the file path and force = TRUE, which will overwrite the old version in the package library.\n\nremotes::install_local(\n path = file.path(tmp, \"mypkg\"),\n force = TRUE\n)\n\nYou must restart R after you’ve done this.\nYour new functions will then be available from your package, much like the dummy say_hi() function was. Here’s say_bye():\n\nlibrary(mypkg)\nsay_bye(\"friends\")\n\n[1] \"Cheerio friends!\"\n\n\nSo, that means that all those functions you keep forgetting, or that are stored across multiple locations, can be made available to you from one package. And ultimately, all it required was install_github(), create() and install_local().\nNote that it can get unwieldy to add all your functions to the functions.R file provided by {pico}, but you can group them up into several R scripts in the R/ subfolder if you like."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#huge-limitations",
    "href": "posts/2021-04-18-pico-pkg/index.html#huge-limitations",
    "title": "Make the simplest R package with {pico}",
    "section": "Huge limitations",
    "text": "Huge limitations\nSo, I think {pico} is a quick way to get you from ‘no-package’ to ‘package’ quickly, but more importantly it has none of the esoteric, daunting structure and content of a ‘normal’ package.\nHowever.\nA pico package doesn’t encourage best practice, nor is it very useful for sharing. That’s why I think the only practical applications are for learning the basics of package structure, or for building a small package of functions that you might personally want to use again in future.\nI would absolutely advocate for learning how to make a ‘real’ package, because that additional structure and content is really powerful and exists for a reason. For example, we haven’t documented any of our functions. What if you add a function to your package but you can’t remember how to use it? We also haven’t tested anything. What if something breaks?\nI’ve written before about the wonders of {usethis}, a package made specifically to help develop your own R packages without thinking too hard. I believe it provides the perfect starting point for developing your own package without worrying about exactly what files are needed and where.\nThere’s a vast array of free web-based resources out there for package building. For example, some that I’ve found useful are:\n\nHilary Parker’s Writing an R Package from Scratch post\nTom Westlake’s update to Hilary’s post\nFabio Votta’s fun slides\nEmil Hvitfeldt’s {usethis} workflow\nKarl Broman’s R Package Primer site, a primer for package development\nHadley Wickham’s R Packages book\n\nYou should make use of those resources, for sure. Do not use {pico} for any serious work. {pico}’s purpose here is to think about how we might demystify package development. At worst I think it’s an interesting curiosity."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#environment",
    "href": "posts/2021-04-18-pico-pkg/index.html#environment",
    "title": "Make the simplest R package with {pico}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 13:41:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] mypkg_0.0.9000\n\nloaded via a namespace (and not attached):\n [1] desc_1.4.2        digest_0.6.31     R6_2.5.1          fastmap_1.1.1    \n [5] xfun_0.39         remotes_2.4.2     knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    ps_1.7.5          cli_3.6.1         processx_3.8.1   \n[13] callr_3.7.3       pico_0.0.0.9000   compiler_4.3.1    rprojroot_2.0.3  \n[17] prettyunits_1.1.1 rstudioapi_0.15.0 tools_4.3.1       pkgbuild_1.4.1   \n[21] evaluate_0.21     yaml_2.3.7        crayon_1.5.2      rlang_1.1.1      \n[25] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#footnotes",
    "href": "posts/2021-04-18-pico-pkg/index.html#footnotes",
    "title": "Make the simplest R package with {pico}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMy initial thought was to try and respond—in a single tweet—with the code required to build a package. That might help show how little code is required, especially with shortcuts like usethis::create_package() and usethis::use_r(). But I think there’s a little too much extra explanation required for this to be a viable, helpful response.↩︎\nYou don’t need to worry too much about the version number for now, especially if you aren’t releasing the package to the world. You can read more in Hadley’s book, though.↩︎\nYo, I heard you like packages that make packages, so I wrote you a package to make a package.↩︎"
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html",
    "href": "posts/2021-03-02-randoflag/index.html",
    "title": "A tiny {shiny} flag challenge",
    "section": "",
    "text": "The gif loops; I promise there’s more flags than this."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#tldr",
    "href": "posts/2021-03-02-randoflag/index.html#tldr",
    "title": "A tiny {shiny} flag challenge",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a teeny-weeny R Shiny app to serve me a flag challenge whenever I open a new browser tab."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#a-vexatious-request",
    "href": "posts/2021-03-02-randoflag/index.html#a-vexatious-request",
    "title": "A tiny {shiny} flag challenge",
    "section": "A vexatious request",
    "text": "A vexatious request\nI thought it would be fun to set my browser tabs to open with thiscatdoesnotexist.com, which serves a random ersatz ‘cat’ as hallucinated by StyleGAN.1 It’s kind of terrifying and time for a change.\nWe probably accumulate hours of time looking at fresh browser tabs, so why not exploit that for fun and learning? I wanted something visual, quick and low stakes, so… world flags?\nMy needs were simple: show a mystery flag; reveal who it belongs to; refresh.2 So I built a little {shiny} app, put it in a GitHub repo and served it.\nOn the front-end you’re presented one of over 250 (!) emoji flags3 at random. There’s a button to reveal the country it represents and another button to refresh the page via {shinyjs}. The back-end just samples a flag from the {emo} package and waits for you to hit refresh. The {bslib} package made it easy to generate a theme that keeps focus on the flag.\nSo now I’ve set my new tabs to open at https://mattdray.shinyapps.io/randoflag/ (tested on Firefox, Chrome and Safari on iOS 14) and I know what the Guadeloupe flag looks like now."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#hoisting-the-app",
    "href": "posts/2021-03-02-randoflag/index.html#hoisting-the-app",
    "title": "A tiny {shiny} flag challenge",
    "section": "Hoisting the app",
    "text": "Hoisting the app\nThe app is currently hosted online via shinyapps.io and I’ve embedded it below. It’s highly likely I’ll take it down at some point.\n\n\nIf it does get yoinked from the internet, you can install and run the app from your R session:\n\nshiny::runGitHub(\"randoflag\", \"matt-dray\", \"main\")\n\nYou’ll need {shiny}, {bslib} and {shinyjs} installed from CRAN and you can get {emo} using remotes::install_github(\"hadley/emo\")."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#half-mastery",
    "href": "posts/2021-03-02-randoflag/index.html#half-mastery",
    "title": "A tiny {shiny} flag challenge",
    "section": "Half-mastery",
    "text": "Half-mastery\nBeware: some emoji flags are shared by more than one geographic entity…\n\n\n\nBof!"
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#environment",
    "href": "posts/2021-03-02-randoflag/index.html#environment",
    "title": "A tiny {shiny} flag challenge",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 21:10:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#footnotes",
    "href": "posts/2021-03-02-randoflag/index.html#footnotes",
    "title": "A tiny {shiny} flag challenge",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYeah, but thispersondoesnotexist.com is even creepier.↩︎\nSee Sporcle if you want an actual quiz.↩︎\nWhy emoji flags? I don’t have to store hundreds of flags as images in the app’s files and {emo} exists to make things very easy. Also I want to practice for when Emojli inevitably returns.↩︎"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#tldr",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#tldr",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve updated the {pixeltrix} package so you can create animated sprite gifs with a simple, interactive pixel editor from within R’s plot window."
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#pix-all-the-right-boxes",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#pix-all-the-right-boxes",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Pix all the right boxes",
    "text": "Pix all the right boxes\nThe {pixeltrix} package—which I’ve written about before—lets you open an interactive R plot that you can click to turn ‘pixels’ on and off.\nI created it for one purpose: to quickly create simple, blocky sprites for my {tamRgo} package, which lets you keep a persistent cyberpet on your computer (yes, really).\nBut wouldn’t it be nice if {pixeltrix} were more… general? Read on for a couple of improvements to the package that might help.\n\n Note\nThe package has been updated again since this post. From version 0.2 you:\n\ncan provide colours as input to click_pixels() and frame_pixels()\nreceive a colours attribute with the output matrices, which encodes the state and colour values"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#pixellate-to-accumulate",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#pixellate-to-accumulate",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Pixellate to accumulate",
    "text": "Pixellate to accumulate\nFirst, you can install the updated package from GitHub:\n\nremotes::install_github(\"matt-dray/pixeltrix\")  # v0.1.2 in this post\nlibrary(pixeltrix)\n\nNow the improvements: plotting with colour, and creating gif animations.\n\n1. Plot\nThe click_pixel() function opens an interactive plot. If n_state = 3, for example, then each pixel will cycle through three states as you keep clicking it. You’re returned a matrix of these values when you hit Esc.\nThat was enough for {tamRgo}: I turned a binary matrix into a 1-bit sprite. But wouldn’t it be good—fundamental!—to be able to plot the matrix as an image with user-specified colours? So I made draw_pixels().\nI’ve added a three-state matrix, blue, into the package as an example dataset. Let’s plot it with simple colours:\n\ndraw_pixels(\n  m = pixeltrix::blue, \n  colours = c(\"white\", \"#879afb\", \"gray20\")\n)\n\n\nOf course, it’s the subtly-coloured player character from Pokémon Blue (1996) as seen on the Nintendo Game Boy Color.\n\n\n2. Animate\nNaturally, you could use click_pixels() and draw_pixels() to generate several images and combine them as ‘frames’ of an animation. Why not have a function that does this automatically?\nSo that’s what I did:\n\nframe_pixels() calls click_pixels() and adds the output as the first element of a list, then it passes that matrix into edit_pixels() as the template for the next frame (and so on until you choose to stop making frames)\ngif_pixels() takes the list of matrices created by frame_pixels() and draws, combines and writes them to a gif\n\nI’ve prepared pixeltrix::mario as an example of an output from frame_pixels(). It contains each of three frames that comprise Mario’s walk cycle from Super Mario Bros on the NES.\nHere’s what the console output looked like when I made mario:\n\nmario &lt;- frame_pixels(\n  n_rows   = 16,\n  n_cols   = 16,\n  n_states = 4  # background + 3 colours\n)\n\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nAdd a frame? y/n: y\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nCurrent frame count: 2\nAdd a frame? y/n: y\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nCurrent frame count: 3\nAdd a frame? y/n: n\nFinal frame count: 3\nYou can see there’s interactivity; the user is prompted to add another frame with Add a frame? y/n:, where y will let you create a new frame and n will stop the process and return the list of matrices.\nAnd so you can see it’s a list of three matrices:\n\nstr(mario)\n\nList of 3\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 1 1 ...\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 0 0 ...\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 0 0 ...\n\n\nYou can then convert the list to a gif with gif_pixels(), which engifs the frames using {gifski}.1\n\ngif_pixels(\n  frames = mario,\n  colours = c(\n    \"white\",    # background\n    \"#FDA428\",  # skin (yellowish)\n    \"#FC0D1B\",  # overalls/hat (red)\n    \"#A32B2E\"   # hair, eyes, shirt, boots (brown)\n  ),\n  file = \"mario.gif\",\n  delay = 0.15  # passed via dots to gifski::save_gif()\n)\n\nInserting image 3 at 0.30s (100%)...\nEncoding to gif... done!\n[1] \"mario.gif\"\nAnd if we open that file:\n\nYahoooooo, created entirely with R. Noice.\n\n\nPix n mix\nSo {pixeltrix} finally got a couple of nice-to-have (well, must-have) functions. This is enough for me to continue just messing around with it as a novelty2.\nI mean, come on: animated pixelart created in an interactive R plot window? Why? I mean, er… wow!"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#environment",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#environment",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:10:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] pixeltrix_0.2.1.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#footnotes",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#footnotes",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe {pixeltrix} package has no dependencies and I didn’t want to force a user to install {gifski} if they weren’t going to use gif_pixels(). It’s therefore up to the user to install it. I also wonder if I should provide an argument for the user to name a ‘gif engine’ of choice, e.g. {gifski} or {magick}, depending on what they’ve got installed on their machine.↩︎\nIt’s never, ever going to have the features and quality of a premium pixel-art program like Aseprite, obviously.↩︎"
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#tldr",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#tldr",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "tl;dr",
    "text": "tl;dr\nHere you go, the customary ‘i PoRtEd My R bLoG’ meta-post."
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#quartoh-no",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#quartoh-no",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "Quartoh-no",
    "text": "Quartoh-no\nYes, wow, porting {blogdown} to Quarto, such bravery.\nThe old source code is now archived on GitHub. The new source code is in a separate repo. There’s still some issues to sort out, but the site is now live on the worldwide web at doubleyoo double-doubleyoo full-stop rostrum full-stop blog1.\nThis post is not a tutorial and is not exhaustive; it’s just a grab-bag of notes for when I (absolutely inevitably) forget how I did certain things. I may add some other things later if there’s teething issues I haven’t uncovered yet."
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#the-struggle-is-real",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#the-struggle-is-real",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "The struggle is real",
    "text": "The struggle is real\nThings went pretty well, basically. It was just boring and slow2 to go through over 150 posts and perform (mostly) little corrections here and there. Herefollows some minor struggles.\n\nLoad-bearing posts\nYou could copy-paste your old {blogdown} source code into the structure and style required by Quarto. But why spend 10 minutes doing that when I could spend many more minutes creating a package to do it?3 This is a little manoeuvre I call ‘procrastination-driven development’. The outcome was my helper package {bd2q}, which I wrote about before. It was useful for some big structural changes and also some specific line edits to the large number of posts I wanted to port and re-render.\n\n\nTw*tter’s ex-API\nI have some posts that used the Twitter API, like one about Wordle and a bunch about londonmapbot. I ended up hardcoding the outputs in these posts because Twitter is utterly borked. One bunglesome post used API data for an interactive leaflet map, but I had failed to save the intermediate data set. To retrieve the data, I had to extract it from the rendered leaflet HTML (!) with some garish string manipulation. Never again.\n\n\nGitHub (In)Actions\nI have a dynamic, stats-laden README for the blog that re-renders when I push to the repo. Famously, GitHub Actions never works first time. This time it was because you have to go into Settings &gt; Actions &gt; General on GitHub and set ‘Workflow permissions’ to ‘Read and write permissions’. For some reason.\n\n\nTrough of a WAV\nI have some little HTML audio whatsits on some pages, like the one about sonifying covid data. Despite putting .wav files in the appropriate directory, the sounds simply wouldn’t play. It’s because you need to specify resources: in your YAML header and then list the path to each one (for me this would be like - resources/roblox-oof.wav). The file is then correctly copied over to the _site/ folder for deployment.\n\n\nEnvironmental disaster\nTo appease nerds, each post on the old blog had a record of the R and package versions used to render it. I did this by calling the session info in an expandable &lt;details&gt; block after a page divider (---). This looked a bit awkward when I tried it in Quarto.\nTook me a while to realise: you can add arbitrary sections to each post’s appendix section with {.appendix} next to its heading. By default, my Quarto appendices have license information and footnotes, but I added an ‘environment’ section with the clickable session info in it. It’s written like this4:\n## Environment {.appendix}\n\n&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\n```{r sessioninfo, eval=TRUE, echo=FALSE}\ncat(\"Last rendered:\", format(Sys.time(), usetz = TRUE)); sessionInfo()\n```\n&lt;/details&gt;\nI also introduced a ‘last rendered’ time before the session info. You can add this to the top of the post along with the author and publish date, but I didn’t want to put so much emphasis on it.\nYou can see an example of this at the bottom of this post, of course.\n\n\nMisdirection\nThe old blog had URLs in the form rostrum.blog/YYYY/MM/DD/postname. Quarto does it like rostrum.blog/posts/YYYY-MM-DD-postname. I thought each Quarto post might need to be placed in a folder structure like /YYYY/MM/DD/postname.qmd to achieve the old URL style. This would be awkward to work with.\nAha, actually you can write a little _redirects text file with a line for each old-to-new path. Given the number of posts, I wrote a little script to generate this file5:\n\nredirect_to &lt;- paste0(\"/\", list.dirs(\"posts\", recursive = FALSE))\n\ndate_rx &lt;- \"\\\\d{4}-\\\\d{2}-\\\\d{2}\"  # YYYY-MM-DD format\n\n# Extract date from path to Quarto post\ndate_portion &lt;- regexpr(date_rx, redirect_to) |&gt; \n  regmatches(redirect_to, m = _) |&gt; \n  gsub(\"/\", \"-\", x = _)\n\nname_portion &lt;- gsub(paste0(\"posts/\", date_rx, \"-\"), \"\", redirect_to)\n\nredirect_from &lt;- paste0(\"/\", date_portion, name_portion)\n\n# 'From' and 'to' paths on same line, separated by a space\nmapping &lt;- paste0(\n  paste(redirect_from, redirect_to, sep = \" \"),\n  collapse = \"\\n\"\n)\n\ncat(mapping, file = \"_redirects\")  # dyk cat() can save files?\n\nOriginally I failed to include the leading slash in the redirect_from string, which would result in trying to redirect from the nonsense rostrum.blogYYYY/MM/DD/postname instead of rostrum.blog/YYYY/MM/DD/postname. Subtle.\nIn the new site’s index.qmd I also added a snippet to copy over the _redirects file into the _site/ folder on render, ready for deployment.\n\n\nCat egg or rice?\nAs I went through each old post, I removed all the ‘tags’ from the YAML and consolidated some of them into ‘categories’. I am still not happy with these categories. How can I extract them all for review? I’m sure there’s an easier way than regexing6 them out, but this hacky thing works:\n\nposts &lt;- \n  list.files(\"posts\", pattern = \".qmd\", recursive = TRUE, full.names = TRUE)\n\nget_categories &lt;- function(post_path, ignore_rx = \"resources\") {\n  \n  post_lines &lt;- readLines(post_path, warn = FALSE)\n  \n  # Extract between the 'categories' YAML section and closing fence\n  cats_start &lt;- which(post_lines == \"categories:\") + 1\n  cats_end &lt;- which(post_lines == \"---\")[2] - 1\n  \n  cats &lt;- NULL\n  \n  # Ignore other YAML sections and content after the categories\n  if (length(cats_start) == 1 & length(cats_end) == 1) {\n    cats &lt;- gsub(\"  - \", \"\", post_lines[cats_start:cats_end])\n    cats &lt;- cats[!grepl(ignore_rx, cats)]\n  }\n  \n  return(cats)\n  \n}\n\ncats_list &lt;- lapply(posts, \\(post) get_categories(post)) |&gt; \n  setNames(dirname(post_names))\n\nall_cats &lt;- unlist(cats_list)\n\ntable(all_cats) |&gt; sort(decreasing = TRUE)\n\nOof, mostly just an excuse to use ‘cats’ as a variable name I think, but maybe this would be easier with some Quarto command or with the {yaml} package or something?\n\n Note\nIndeed. In a more recent blogpost I ended up using {yaml} for extracting a Quarto doc’s format from its YAML.\n\n\n\nGoated Netlify\nI remember struggling a bit when setting up Netlify to deploy the blog five years ago, but it seemed easier when I later set up my personal page. I dithered a little before setting up this new Quarto version of the blog, though. What if I click the wrong thing and the site disappears forever? Ah well.\nBut actually it was straightforward. The old and new blog are separate sites in my Netlify account and I just had to remove the ‘rostrum.blog’ domain from the old one and activate it on the new, which is under Site configuration &gt; Domain management &gt; Domains.\nIt was also easy to re-add Goatcounter—which counts but doesn’t track visitors—under Site configuration &gt; Build and deploy &gt; Post processing &gt; Snippet injection. I pasted in a Goatcounter-provided snippet so it’s injected before &lt;/body&gt;."
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#selling-out",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#selling-out",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "Selling out",
    "text": "Selling out\nI picked up a lot of miscellaneous tips and tricks from Danielle Navarro, Albert Rapp and the Quarto docs themselves. Do check those out.\nAbove all, thank you Yihui and contributors for {blogdown}. It felt cool to be a hipster {blogdown} user7. I held out for over five years, but the time has come and I have become… mainstream. The horror.\nBut how can I complain? A mid-life crisis precipitated by a blog transition is exactly where I saw this going, to be honest.\nHopefully I won’t be changing platforms again any time soon. But the posts are always ported first from my brain to the blog, so I could simplify the process by just… keeping them in my head? You’re preemptively welcome."
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#environment",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#environment",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-09-04 11:59:19 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-08-26-cheerio-blogdown/index.html#footnotes",
    "href": "posts/2023-08-26-cheerio-blogdown/index.html#footnotes",
    "title": "Conscious uncoupling with {blogdown}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCALL NOW.↩︎\nI began in April 2023. I took my sweet time because I knew it would be dull, but also because I recently fell down an Action Button YouTube rabbit hole. I also got into the geocaching scene, both IRL (9 caches found, legend) and digitally, in the form of Zelda TOTK (‘YA-HA!’).↩︎\nAlso check out Antoine’s {editor} package that can reach into a file and make alterations. I wish I’d had this before I bodged together some similar functionality in {bd2q}.↩︎\nIf you’re wondering how to show a verbatim chunk in a Quarto doc without rendering it, there’s some documentation.↩︎\nI like the ‘modern base’ aesthetic of the date_portion object here. Holdup, brb, just going to add ‘Modern Base Core’ to the Aesthetics Wiki.↩︎\nI desperately wanted to spell this ‘regexxing’, but ‘x’ appearing twice makes it look illicit.↩︎\nAt least that’s how I felt. Please don’t shatter my precious illusions.↩︎"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#tldr",
    "href": "posts/2021-11-04-kanto-locator/index.html#tldr",
    "title": "Get coordinates from fictitious maps",
    "section": "tl;dr",
    "text": "tl;dr\nUse the locator() function in R to interactively extract arbitrary coordinates from images of imaginary maps. I extracted points of interest from Kanto in the original Pokémon games."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#on-the-road-to-viridian-city",
    "href": "posts/2021-11-04-kanto-locator/index.html#on-the-road-to-viridian-city",
    "title": "Get coordinates from fictitious maps",
    "section": "On the road to Viridian City",
    "text": "On the road to Viridian City\nThere are lots of interesting fictitious maps. For example, Middle Earth from Lord of the Rings, Hyrule from The Legend of Zelda and Sodor from Thomas the Tank Engine.\nThis is excellent fodder for fan-made recreations. I’ve thought before about how I would do this programmatically, but there’s one particularly awkward thing: how can you grab location coordinates from an image of your chosen map?\nThis post outlines a pretty low-effort method for doing this in R. Basically there’s two steps: (1) read and plot an image of a map and (2) click locations interactively to record their coordinates. I’m going to do this with a Pokémon example for simplicity, but also because have you ever visited this blog before?"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#get-map",
    "href": "posts/2021-11-04-kanto-locator/index.html#get-map",
    "title": "Get coordinates from fictitious maps",
    "section": "Get map",
    "text": "Get map\nFor my own convenience, I’ve written a function that downloads a PNG of a map from the web and plots it. This requires {png} and {grid} packages.\n\nplot_map &lt;- function(png_path) {\n  \n  # Return to user's par settings once done\n  original_par &lt;- par()[\"mar\"]\n  on.exit(par(original_par))\n  \n  # Download and read image\n  tmp &lt;- tempfile(fileext = \".png\")\n  download.file(png_path, tmp, quiet = TRUE)\n  img &lt;- png::readPNG(tmp)\n  unlink(tmp)  # clean up\n  \n  # Set up canvas and plot\n  par(mar = rep(0, 4))  # remove margins\n  plot.new()  # start new plot frame\n  grid::grid.raster(img, x = 0.5, y = 0.5)\n  \n}\n\nTo be specific, I’m using the in-game ‘town map’ of the fictitious Kanto region from the first generation of Pokémon Red and Blue for the Nintendo GameBoy,1 downloaded from Bulbapedia. This is good for a demo: the locations are pretty discrete, obvious and clickable.\n\nkanto_path &lt;- \n  \"https://cdn2.bulbagarden.net/upload/8/86/Kanto_Town_Map_RBY.png\"\n\nplot_map(kanto_path)\n\n\n\n\nYou might be thinking that it looks like a schematic map—an abstraction of actual geography—like the London underground map. In fact, the town map is pretty similar to the actual in-game world layout, as demonstrated by folks who have stitched together all the overworld screens."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#get-points",
    "href": "posts/2021-11-04-kanto-locator/index.html#get-points",
    "title": "Get coordinates from fictitious maps",
    "section": "Get points",
    "text": "Get points\nWith the Kanto map drawn in our active plot window, we can run a function to prompt the user to click on points and record their coordinates.\n\nlocate_points &lt;- function(places) {\n  \n  places_list &lt;- vector(\"list\", length(places)) |&gt; \n    setNames(places)\n  \n  for (i in places) {\n    cat(paste0(\"Click on \", i, \"... \"))\n    places_list[[i]] &lt;- locator(1, type = \"p\")\n    cat(\"found.\\n\")\n  }\n  \n  places_df &lt;- do.call(rbind, places_list) |&gt;\n    data.frame()\n  \n}\n\nThis is not magic. It is merely powered by the locator() function, which records the x and y location of a point clicked on a plot by the user.2\nHere’s a simplified version of what’s going on when you use locator(). If you make a plot and call the function, then the top of the plotting window in RStudio says ‘locator active’ and your cursor becomes crosshairs. Clicking on the plot returns a list of the x and y coordinates within the plotting space. The first argument is the number of clicks to collect before the locator is deactivated automatically.\n\nFor our bespoke locate_points() function, we can pass a character vector of place names. For this demo, that’ll be Kanto’s towns, cities and other places of interest. The function loops through the locations and requests you to click the corresponding point on the map. The console will read like Click on Pallet Town... and then found once you’ve clicked it.\n\nkanto_names &lt;- c(\n  \"Pallet Town\", \"Viridian City\", \"Viridian Forest\", \"Pewter City\", \n  \"Mt Moon\", \"Cerulean City\", \"Rock Tunnel\", \"Vermilion City\", \n  \"Lavender Town\", \"Celadon City\", \"Fuchsia City\", \"Saffron City\", \n  \"Seafoam Islands\", \"Cinnabar Island\", \"Victory Road\",\n  \"Indigo Plateau\"\n)\n\nkanto_pts &lt;- locate_points(kanto_names)  # initiates clicking prompts\n\nClick on Pallet Town...\nDuring the clickfest, the locate_points() function has assembled the points lists into a data.frame with one row per location. The locations vector was passed as the rownames of the dataframe as well. Here’s the full list of collected coordindates.\n\nkanto_pts\n\n                        x          y\nPallet Town     0.2470187 0.30648777\nViridian City   0.2451179 0.50103940\nViridian Forest 0.2451179 0.75868886\nPewter City     0.2470187 0.81652853\nMt Moon         0.4275933 0.88225543\nCerulean City   0.6100688 0.87962636\nRock Tunnel     0.7944450 0.81915761\nVermilion City  0.6100688 0.43794158\nLavender Town   0.7963458 0.69296196\nCeladon City    0.4751130 0.69296196\nFuchsia City    0.5207318 0.18292120\nSaffron City    0.6100688 0.69559103\nSeafoam Islands 0.3838752 0.05672554\nCinnabar Island 0.2451179 0.05672554\nVictory Road    0.1538802 0.75343071\nIndigo Plateau  0.1519794 0.87962636\n\n\nThe coordinate values are between 0 to 1 because those are the default x- and y-axis limits that were set up in plot_map(). They’re remarkably precise, but the resolution on the image wasn’t great and my hand-eye coordination is bad, so take these with a grain of salt."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#plot",
    "href": "posts/2021-11-04-kanto-locator/index.html#plot",
    "title": "Get coordinates from fictitious maps",
    "section": "Plot",
    "text": "Plot\nSo! You can now plot the coordinates independently. To demonstrate, I’ve plotted the points and added a label whose style is dependent on the type of location. I’ve added lines to join the locations in the order they appear in a normal playthrough.\n\nkanto_pts$city &lt;- ifelse(\n  grepl(\"Town|City|Island$\", rownames(kanto_pts)), \n  TRUE, FALSE\n)\n\npar(mar = rep(0, 4))\nwith(kanto_pts, plot(x, y, axes = FALSE))\nwith(kanto_pts, lines(x, y, col = \"grey95\", lwd = 5))\n\npoints(\n  kanto_pts$x, kanto_pts$y,\n  pch = 16,\n  cex = ifelse(kanto_pts$city, 2, 1),\n  col = ifelse(kanto_pts$city, \"red\", \"blue\")\n)\n\ntext(\n  kanto_pts$x, kanto_pts$y,\n  gsub(\" \", \"\\n\", row.names(kanto_pts)),\n  cex = ifelse(kanto_pts$city, 0.7, 0.4),\n  pos = c(1, 1, 1, 4, 1, 1, 2, 1, 2, 1, 1, 1, 3, 3, 1, 1),\n  family = \"Press Start 2P\"  # installed locally from Google Fonts\n)\n\n\n\n\nIt might also be fun to do a minimal map of the cities where the points are coloured according to the name of the city. You may have noticed that the city names are all fancy colour names (viridian, fuchsia, etc), so let’s use them. Well, except Pallet, for which can just use a mix of all colours, i.e. white.\n\nkanto_colour &lt;- \n  kanto_pts[kanto_pts$city | \n              rownames(kanto_pts) == \"Indigo Plateau\", ]\n\nkanto_colour$city_col &lt;- c(  # close-enough named R colours\n  \"white\", \"aquamarine4\", \"grey57\", \"royalblue3 \",\n  \"red3 \", \"lavender\", \"darkseagreen2\", \"magenta\",\n  \"tomato2\", \"orangered2\", \"blue\"\n) \npar(mar = rep(0, 4))\nwith(kanto_colour, plot(x, y, axes = FALSE))\nwith(kanto_colour, points(x, y, pch = 22, cex = 4, bg = city_col))\n\n\n\n\nI’ll admit I struggled to make this given my colourblindness, but also because I had no prior notions of what colours like ‘vermilion’ and ‘celadon’ are. Actually they kind of sound more like Pokémon names.\nAnyway, these ‘maps’ are the first steps to create something more exciting. For now they demonstrate the point (literally, lol). Plus they fulfil my belated submission for day one of the #30DayMapChallenge (‘points’)."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#distances",
    "href": "posts/2021-11-04-kanto-locator/index.html#distances",
    "title": "Get coordinates from fictitious maps",
    "section": "Distances",
    "text": "Distances\nBut wait, there’s more.\nSo, obviously, why not work out the distances between towns? Not in arbitrary units, but in actual metres. There’s a few ways we could do this, but basically I’m going to peg a pixel to a known length.3\nFirst, we can create a lookup table of the straight-line ‘distances’ between locations, given our arbitrary 0 to 1 dimensions. We want to avoid being precise with these values (they’re only as good as my ability to click a tiny square on a computer screen), so I’m multiplying and rounding them.\n\nkanto_dist &lt;- raster::pointDistance(\n  kanto_pts[, c(\"x\", \"y\")],\n  lonlat = FALSE\n) |&gt;\n  as.data.frame() |&gt;\n  round(2) * 100\n\nThe legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\nwhich was just loaded, will retire in October 2023.\nPlease refer to R-spatial evolution reports for details, especially\nhttps://r-spatial.org/r/2023/05/15/evolution4.html.\nIt may be desirable to make the sf package available;\npackage maintainers should consider adding sf to Suggests:.\nThe sp package is now running under evolution status 2\n     (status 2 uses the sf package in place of rgdal)\n\nnames(kanto_dist) &lt;- kanto_names\nrownames(kanto_dist) &lt;- kanto_names\n\nkanto_dist[1:3, 1:3]  # first few\n\n                Pallet Town Viridian City Viridian Forest\nPallet Town               0            19              45\nViridian City            19             0              26\nViridian Forest          45            26               0\n\n\nThese values are the number of arbitrary distance units between pairs of locations, which are given by the row and column headers. So, Pallet Town to Viridian City is 19 arbitrary units.\nBased on my own measurements, the centre of Pallet to the centre of Viridian is 64 in-game ‘blocks’, where a block is a 16- by 16-pixel square.4\nIt just so happens that the player-character sprite fills a single block5 and we know that the character is probably about 140 cm tall.6\nThat means Pallet to Viridian is about 64 * 140 cm = 8960 cm. So, one of our arbitrary units equals 8960 cm / 19 = 472 cm. Now we can correct our distance lookup.\n\nkanto_dist_m &lt;- round(kanto_dist * 472 / 100)\nkanto_dist_m[1:3, 1:3]  # first few\n\n                Pallet Town Viridian City Viridian Forest\nPallet Town               0            90             212\nViridian City            90             0             123\nViridian Forest         212           123               0\n\n\nOnce again I’ve removed some precision by calculating the result as a rounded distance in metres. Coward.\n\nSo this means we can now say some really profound things like it’s about 90 m from Pallet Town to Viridian City. Maybe that’s true in the context of the game’s dimensions, but it’s… underwhelming.\nWas this scuffed distance-conversion exercise worthwhile? No. \nBut it might strengthen my belated submission to day two of the #30DayMapChallenge (‘lines’)?"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#environment",
    "href": "posts/2021-11-04-kanto-locator/index.html#environment",
    "title": "Get coordinates from fictitious maps",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     codetools_0.2-19  fastmap_1.1.1     xfun_0.39        \n [5] lattice_0.21-8    knitr_1.43.1      raster_3.6-20     htmltools_0.5.5  \n [9] png_0.1-8         rmarkdown_2.23    cli_3.6.1         terra_1.7-39     \n[13] grid_4.3.1        compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[17] sp_2.0-0          evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7       \n[21] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locator/index.html#footnotes",
    "href": "posts/2021-11-04-kanto-locator/index.html#footnotes",
    "title": "Get coordinates from fictitious maps",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes: I recreated the ‘Safari Zone’ from this game as a playable text adventure in R and even threw in an RStudio theme to mimic the original puke-green GameBoy screen.↩︎\nI was thinking about this function recently because I remember being taught to use it to help place labels on a plot. Then I saw it appeared in Tomaz’s post for creating interactive, self-updating Voronoi maps and I took it as a sign to make something with it too.↩︎\nAs it happens, in-game Kanto is based on the real-life Kanto region of Japan. That means another approach might be to measure approximate distances by overlaying the in-game map over real-life Japan.↩︎\nOf course, the relative in-game scales are a bit weird. For example, some single-storey houses are only twice the height of the player. It also implies the whole of Kanto is only a few kilometres wide. But, y’know, it’s a retro videogame, so.↩︎\nYou can make little animated sprites in R, don’t you know?↩︎\n4 feet 7 inches, if you prefer. This does seems quite short, although he is meant to be 10 years old.↩︎"
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html",
    "href": "posts/2023-12-03-eyedrop/index.html",
    "title": "No tears over missed eyedrops",
    "section": "",
    "text": "Lotad: best Pokémon. No contest."
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#tldr",
    "href": "posts/2023-12-03-eyedrop/index.html#tldr",
    "title": "No tears over missed eyedrops",
    "section": "tl;dr",
    "text": "tl;dr\nUse the {eyedroppeR} package by Dan Oehm if you want to sample a colour from an image using R. You don’t need to use my hastily-created function."
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#top-of-the-drops",
    "href": "posts/2023-12-03-eyedrop/index.html#top-of-the-drops",
    "title": "No tears over missed eyedrops",
    "section": "Top of the drops",
    "text": "Top of the drops\nA colleague on Slack asked about ‘eyedropper’ tools; where you can click a point on an image and have its colour returned. Very handy.\nI couldn’t recall seeing an eyedrop tool built with R. How hard could it be to make one?\nI thought immediately of the locator() function from base R, which lets you click a plot and have its coordinates returned1. So I went ahead and made a little demo function.\nBut I figured someone must have done this before, so I asked on Mastodon. And lol, of course: the {eyedroppeR} package by Dan Oehm already does this (and more).\n\n Note\nYou may also enjoy Dan’s {traceR} package, which lets you interactively click points in the plot window to trace around an image, then use the resulting dot-to-dot in a new plot."
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#eye-eye",
    "href": "posts/2023-12-03-eyedrop/index.html#eye-eye",
    "title": "No tears over missed eyedrops",
    "section": "Eye, eye",
    "text": "Eye, eye\nSo this is a good lesson about avoiding duplication and wasted effort. I’m glad I asked about it!\nBut I still had fun. For posterity, here’s the sketch I came up with:\n\neyedrop &lt;- function(file, swatch = TRUE) {\n  \n  # Check file exists\n  if (!file.exists(file)) stop(\"File doesn't exist.\")\n  \n  # Check file extension\n  file_ext &lt;- tools::file_ext(file)\n  if (!file_ext %in% c(\"png\", \"jpeg\")) stop(\"File must be .png or .jpeg.\")\n  \n  # Read from path\n  if (file_ext == \"png\") img &lt;- png::readPNG(file)\n  if (file_ext == \"jpeg\") img &lt;- jpeg::readJPEG(file)\n  \n  # Plot the image\n  grDevices::dev.new()\n  grid::grid.raster(img)\n  main_dev &lt;- grDevices::dev.cur()\n  \n  # Get the size of the plot window\n  grid_size &lt;- setNames(dev.size(\"cm\"), c(\"x\", \"y\"))\n  \n  message(\"Select points on the image to identify colours. Press &lt;Esc&gt; to quit.\")\n  \n  # Keep allowing user to click points until they refuse\n  repeat {\n    \n    clicked_point &lt;- grid::grid.locator(\"cm\")  # xy in cm\n    \n    if (is.null(clicked_point)) break  # exit if user is finished\n    \n    # Standardise xy as 0 to 1\n    grid_coords &lt;- unlist(clicked_point)\n    grid_ratios &lt;- grid_coords / grid_size\n    \n    # Find the 'pixel' coords given the image's resolution\n    grid_dim &lt;- setNames(dim(img)[1:2], c(\"y\", \"x\"))[2:1]\n    pixels &lt;- round(grid_dim * grid_ratios)\n    pixels[\"y\"] &lt;- grid_dim[\"y\"] - pixels[\"y\"]\n    \n    # Extract RGB for given pixel, convert to hex\n    rgb_vals &lt;- img[pixels[\"y\"], pixels[\"x\"], ]\n    hex &lt;- rgb(rgb_vals[1], rgb_vals[2], rgb_vals[3])\n    \n    # Open a window filled with the provided hex colour\n    if (swatch) {\n      dev.new(width = 2, height = 2)\n      par(mar = c(rep(0, 4)))  # remove plot margins\n      image(matrix(1), col = hex)\n      grDevices::dev.set(main_dev)  # return focus to original plot window\n    }\n    \n    message(hex)\n    \n  }\n  \n}\n\nYou can see an example of this in action in the gif at the top of this page.\nOf course, this is a minimum viable product and has many deficiencies; it is not optimised in any way. I may even have misunderstood some concepts from {grid} graphics.\nAlso, importantly, there is some kind of issue with RStudio where grid units are converted incorrectly. Hence why the example shown at the top of this post uses R’s vanilla graphical use interface. Given that  of people are using RStudio, that isn’t ideal.\nTo explain the basic steps of the function:\n\nWe get the plot window dimensions with dev.size() and coordinates for our clicked point with grid.locator(). We can use that to work out how far along each axis that our point is, as a percentage.\nWe can then check the dim()ensions of the image (i.e. its resolution) and locate the ‘pixel’ that is x% and y% along each axis.\nThe image is an array object with red, green and blue ‘channels’, so we can retrieve each one for our pixel and convert to a hex value.\n\nOf course, I welcome your thoughts on how to improve the function. But yeah, y’know, just use {eyedroppeR}."
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#dry-your-eyes-mate",
    "href": "posts/2023-12-03-eyedrop/index.html#dry-your-eyes-mate",
    "title": "No tears over missed eyedrops",
    "section": "Dry your eyes, mate",
    "text": "Dry your eyes, mate\nI’m a big believer in sharing failure. I’m a big believer in recognising when to stop2. Regardless of ‘success’, I’m also a big believer in sharing your ideas and documenting your thought processes.\nI’m also a big believer in having a nice time and coding for fun."
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#environment",
    "href": "posts/2023-12-03-eyedrop/index.html#environment",
    "title": "No tears over missed eyedrops",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 10:03:39 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       fontawesome_0.5.2 evaluate_0.23"
  },
  {
    "objectID": "posts/2023-12-03-eyedrop/index.html#footnotes",
    "href": "posts/2023-12-03-eyedrop/index.html#footnotes",
    "title": "No tears over missed eyedrops",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI used locator() for the {pixeltrix} ‘pixel-art editor’ package and in a previous post about getting coordinates from fictitious maps.↩︎\nI’ve definitely created things in the past that I didn’t realise already existed, such as my {badgr} package and the pre-existing {badger} package.↩︎"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "tl;dr",
    "text": "tl;dr\n{officer} is an R package that lets you extract elements of a Word document, including tables, into a tidy dataframe. I’ve written a function to ‘re-rectangularise’ extracted Word tables into a list of R dataframes.\n\n Note\nTurns out that Eli Pousson has written the {officerExtras} package (install it from GitHub), which already contains this functionality in the officer_tables() and officer_table() functions. At least this proves my idea wasn’t too far-fetched!\nAlso you can just use docxtractr::docx_extract_all_tbls() by Bob Rudis to extract all the tables in one go, lol."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "href": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "What’s the officer, problem?",
    "text": "What’s the officer, problem?\nSomeone on Slack asked about some difficulty with scraping a table from a Word document. We’ve all been there.\nMy mind immediately went to {officer} by David Gohel, which is part of the ‘officeverse’ for reading, creating and manipulating common Microsoft documents with R1.\nIn particular, the function officer::docx_summary() extracts all the elements of a Word doc into a tidy dataframe2. Each row of that dataframe is a heading, or a paragraph, or the contents of a table cell3.\nThis means tables are ‘unstacked’, with a row per ‘cell’ of the original Word table. How could you convert these tidy Word tables into dataframes for further use in R? There’s a suggestion in the docs, but I drew the rest of the heckin’ owl by creating a slightly overengineered function to do it4."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "href": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "’Allo ’allo",
    "text": "’Allo ’allo\nFirst, you can download the {officer} package from CRAN:\n\ninstall.packages(\"officer\") # if not yet installed\nlibrary(officer)\n\nLet’s create a Word document to test with and save it to a temporary location:\n\n# Create a test docx file\ndoc_test &lt;- read_docx() |&gt;\n  body_add_par(\"This is a test\", style = \"heading 1\") |&gt;\n  body_add_par(\"Below is a table.\", style = \"Normal\") |&gt;\n  body_add_table(mtcars[1:3, 1:5]) |&gt; \n  body_add_par(\"Below is another table\", style = \"Normal\") |&gt;\n  body_add_table(airquality[1:3, 1:5])\n\n# Save docx to temp location\ntemp_docx &lt;- tempfile(fileext = \".docx\")\nprint(doc_test, target = temp_docx)\n\nThe package has a nice system of pipeable functions for building up document. This code created a file with a heading, followed by two tables that each have a line of text above them.\nWe can read the document with read_docx() and extract the contents into a tidy dataframe:\n\n# Read the file from temp path\ndoc_path &lt;- list.files(tempdir(), pattern = \".docx$\", full.names = TRUE)\ndoc_in &lt;- read_docx(doc_path)\n\n# Get the content of the document as a dataframe\ndoc_tidy &lt;- docx_summary(doc_in)\nstr(doc_tidy)\n\n'data.frame':   43 obs. of  11 variables:\n $ doc_index   : int  1 2 3 3 3 3 3 3 3 3 ...\n $ content_type: chr  \"paragraph\" \"paragraph\" \"table cell\" \"table cell\" ...\n $ style_name  : chr  \"heading 1\" \"Normal\" NA NA ...\n $ text        : chr  \"This is a test\" \"Below is a table.\" \"mpg\" \"21.0\" ...\n $ level       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ num_id      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ row_id      : int  NA NA 1 2 3 4 1 2 3 4 ...\n $ is_header   : logi  NA NA TRUE FALSE FALSE FALSE ...\n $ cell_id     : num  NA NA 1 1 1 1 2 2 2 2 ...\n $ col_span    : num  NA NA 1 1 1 1 1 1 1 1 ...\n $ row_span    : int  NA NA 1 1 1 1 1 1 1 1 ...\n\n\nThe doc_in object has ‘rdocx’ class that carries the extracted elements and associated style information. Running docx_summary() converts this to the single tidy dataframe that we’re after.\nYou can see we have information here about the content of our doc. For purposes of this post, we care about:\n\ntext, which is the actual written content\ncontent_type, which can tell us if we’re looking at table cells\ndoc_index, which assigns an ID value so document elements stay together (e.g. cells of a table will all carry the same doc_index)\ncell_id and row_id, which tell us the x and y cell locations in tables\nis_header, which can tell us if the row contains a table header.\n\nNow to extract the table elements and ‘re-rectangularise’ back into a dataframe."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "href": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Cop a load of this",
    "text": "Cop a load of this\nI’ve made two functions using base R:\n\nrectangularise_tables() (note the plural) takes the dataframe provided by docx_summary() and outputs a list of dataframes, one per table in the original Word file\n.rectangularise_table() (not pluralised and starts with a dot for disambiguation), which runs inside rectangularise_tables() to reformat the tidy representation of a single Word table into an R dataframe\n\nYou’ll need to copy both of these into your session and run them. For convenience, I’ve added them to a GitHub gist. I’ve added commentary so you can see what’s happening in each bit.\n\n\nClick to expand the rectangularise_tables() definition.\n\n\nrectangularise_tables &lt;- function(\n    docx_summary,  # output dataframe from docx_summary\n    assume_headers = TRUE,  # assume headers in first row?\n    type_convert = TRUE  # try to coerce columns to most likely data type?\n) {\n  \n  # Check inputs\n  \n  is_data.frame &lt;- inherits(docx_summary, \"data.frame\")\n  \n  docx_summary_names &lt;- c(\n    \"doc_index\", \"content_type\", \"style_name\", \"text\", \"level\", \"num_id\", \n    \"row_id\", \"is_header\", \"cell_id\", \"col_span\", \"row_span\"\n  )  # column names we can expect in the output from docx_summary\n  \n  is_docx_summary &lt;- all(names(docx_summary) %in% docx_summary_names)\n  \n  if (!is_data.frame | !is_docx_summary) {\n    stop(\n      paste(\n        \"Argument 'docx_summary' must be a data.frame created with\",\n        \"'officer::docx_summary'.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Get only the rows that relate to Word tables\n  docx_summary_tables &lt;- \n    docx_summary[docx_summary[[\"content_type\"]] %in% \"table cell\", ]\n  \n  # Get the ID value for each Word table\n  doc_indices &lt;- unique(docx_summary_tables[[\"doc_index\"]])\n  \n  # Initiate an empty list to hold dataframe representations of the Word tables\n  tables_out &lt;- vector(mode = \"list\", length = length(doc_indices))\n  names(tables_out) &lt;- paste0(\"doc_index_\", doc_indices)\n  \n  # For each Word table, 'rectangularise' into a dataframe and add to the list\n  for (doc_index in doc_indices) {\n    \n    docx_summary_table &lt;- \n      docx_summary_tables[docx_summary_tables[[\"doc_index\"]] == doc_index, ]\n    \n    extracted_table &lt;- .rectangularise_table(docx_summary_table, assume_headers)\n    \n    list_element_name &lt;- paste0(\"doc_index_\", doc_index)\n    tables_out[[list_element_name]] &lt;- extracted_table\n    \n  }\n  \n  # Optionally convert columns to appropriate type (integer, etc)\n  if (type_convert) {\n    tables_out &lt;- lapply(tables_out, type.convert, as.is = TRUE)\n  }\n  \n  return(tables_out)\n  \n}\n\n\n\n\nClick to expand the .rectangularise_table() definition.\n\n\n.rectangularise_table &lt;- function(\n    table_cells,  # docx_summary output filtered for 'table cells' only\n    assume_headers = TRUE  # assume headers in first row?\n) {\n  \n  # Check inputs\n  \n  is_table_cells &lt;- all(table_cells[[\"content_type\"]] == \"table cell\")\n  is_one_table &lt;- length(unique(table_cells[[\"doc_index\"]])) == 1\n  \n  if (!is_table_cells | !is_one_table) {\n    stop(\n      paste(\n        \"Argument 'table_cells' must be a dataframe created with\",\n        \"'officer::docx_summary' where 'content_type' is filtered for\",\n        \"'table cell' only.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Split each Word table into a list element, isolate headers and cell contents\n  cell_id_split &lt;- split(table_cells, table_cells[[\"cell_id\"]])\n  headers &lt;- lapply(cell_id_split, function(x) x[x[[\"is_header\"]], \"text\"])\n  content &lt;- lapply(cell_id_split, function(x) x[!x[[\"is_header\"]], \"text\"])\n  table_out &lt;- as.data.frame(content)\n  \n  # Column headers are identified by TRUE in the is_header column, but may not\n  # be marked up as such. Use them as dataframe headers if they exist.\n  has_headers &lt;- length(unlist(headers)) &gt; 0\n  if (has_headers) {\n    names(table_out) &lt;- headers\n  }\n  \n  # If headers are not identified by is_header, assume that the first row of the\n  # Word table contains the headers. The user can control this behaviour with\n  # the argument assume_headers.\n  if (!has_headers & assume_headers) {\n    headers &lt;- table_out[1, ]  # assume first row is headers\n    table_out &lt;- table_out[2:nrow(table_out), ]  # rest of table is content\n    names(table_out) &lt;- headers\n  }\n  \n  return(table_out)\n  \n}\n\n\nYou’ll notice the assume_headers argument. The headers for a Word table are marked by TRUE in the is_header column of the output from docx_summary(). Except when they aren’t. It’s possible that you’ll read a Word doc where the table headers aren’t identified. Set assume_headers to TRUE (the default) to allow rectangularise_table() to instead use the first row of the table as headers. The setting will apply to all tables; I reckon that it’s all or nothing whether table headers will be marked up in a given Word document.\nYou may also have seen the type_convert argument5. By default, the text column in the output from docx_summary() will be character class, but the actual data might be integers, for example. As explained in a recent blog post, the type.convert() function attempts to coerce a column to the appropriate data type if possible.\nAnd now we can see that the dataset works using our test document:\n\ndf_list &lt;- rectangularise_tables(doc_tidy)\nstr(df_list)\n\nList of 2\n $ doc_index_3:'data.frame':    3 obs. of  5 variables:\n  ..$ mpg : num [1:3] 21 21 22.8\n  ..$ cyl : int [1:3] 6 6 4\n  ..$ disp: int [1:3] 160 160 108\n  ..$ hp  : int [1:3] 110 110 93\n  ..$ drat: num [1:3] 3.9 3.9 3.85\n $ doc_index_5:'data.frame':    3 obs. of  5 variables:\n  ..$ Ozone  : int [1:3] 41 36 12\n  ..$ Solar.R: int [1:3] 190 118 149\n  ..$ Wind   : num [1:3] 7.4 8 12.6\n  ..$ Temp   : int [1:3] 67 72 74\n  ..$ Month  : int [1:3] 5 5 5\n\n\nSmashing. We have a list of two dataframes: one for each of the tables in the test document. I took the liberty of naming the list elements like doc_index_* so you can trace which doc_index they were in the original output from docx_summary()."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "PrisonR",
    "text": "PrisonR\nTo summarise, this is absolutely not the worst code-related crime I’ve committed on this blog. Sorry guv! I’ll definitely be sentenced to the most severe punishment if caught and tried: several minutes of hard labour, or ‘refactoring’ as they call it on the inside.\nAt worst I’ll build an Andy-Dufresne-style tunnel out of my prison cell and hide the entrance behind years of accumulated hex stickers.\n\n Note\nAs a bonus, I later wrote a quick reproducible example that part-solves the original reason for this post. Here I’ve used {docxtractr} to extract tables from docx files in separate subfolders and then combine them.\n\n\nClick to expand code.\n\n\n# Attach packages (all are available from CRAN)\nlibrary(docxtractr)  # to extract tables from docx files\nlibrary(officer)  # to create dummy docx files\nlibrary(charlatan)  # to generate fake data\n\n# Create multiple dummy docx files in separate temporary folders\n\nmy_folder &lt;- tempdir()  # temporary locations to store the files\nn_files &lt;- 5  # the number of dummy files to generate\n\nfor (i in seq(n_files)) {\n  \n  # Create subfolders\n  subfolder_name &lt;- paste0(\"subfolder_\", i)\n  dir.create(file.path(my_folder, subfolder_name))\n  \n  # Create dummy dataframe\n  \n  n_fake &lt;- 10  # number of fake data items to generate\n  \n  temp_df &lt;- data.frame(\n    name = ch_name(n_fake),\n    job = ch_job(n_fake),\n    phone = ch_phone_number(n_fake)\n  )\n  \n  # Add dummy dataframe to a docx file and save it\n  path &lt;- file.path(my_folder, subfolder_name, paste0(\"df_\", i, \".docx\"))\n  officer::read_docx() |&gt; body_add_table(temp_df) |&gt; print(target = path)\n  \n}\n\n# Get the file paths to all the docx files\ndocx_paths &lt;- list.files(\n  my_folder,\n  pattern = \".docx$\",\n  full.names = TRUE,  # return full filepaths\n  recursive = TRUE  # look in all subfolders\n)\n\n# Preallocate a list to be filled with extracted tables, one element per file\nextracted_tables &lt;- vector(\"list\", n_files)\n\n# Extract tables and add to the list (not tested: I think that read_docx will\n# read .doc files, but only if you have LibreOffice installed.\nfor (i in docx_paths) {\n  tables &lt;- docxtractr::read_docx(i) |&gt; docx_extract_all_tbls()\n  extracted_tables[basename(i)] &lt;- tables\n}\n\n# In this simple demo, the dataframes in each list element can be appended\n# because they all have the same column names and types.\ndo.call(rbind, extracted_tables)"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "href": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:05:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] officer_0.6.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] xml2_1.3.5        cli_3.6.1         zip_2.3.0         askpass_1.1      \n[13] openssl_2.1.0     textshaping_0.3.6 systemfonts_1.0.4 compiler_4.3.1   \n[17] rstudioapi_0.15.0 tools_4.3.1       ragg_1.2.5        evaluate_0.21    \n[21] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[25] uuid_1.1-0"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#footnotes",
    "href": "posts/2023-06-07-rectangular-officer/index.html#footnotes",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRelated: I have some experience with R-to-Excel: my {a11ytables} package generates best-practice spreadsheets using {openxlsx}.↩︎\nIt would be wrong for me not to point out that you can extract Excel and ODS cells into ‘tidy’ dataframes with Duncan Garmonsway’s {tidyxl} and Matt Kerlogue’s {tidyods}. No, they haven’t sponsored this post (invoices in the mail, chaps).↩︎\nMerged cells in the table end up being unmerged, with the upper- and left-most cells holding the content and the remianing cells being assigned NA.↩︎\nI did this for my own curiosity, really. Just like everything else on this blog! As mentioned, check out {docxtractr} and {officerExtras} for better implementations.↩︎\nWhat a handy function. This was useful enough that Eli has now added it to {officerExtras}.↩︎"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#tldr",
    "href": "posts/2022-04-27-tide/index.html#tldr",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "tl;dr",
    "text": "tl;dr\nR has an interactive spreadsheet editor for dataframes that you can access with edit(). I made the function tide::tide() to generate automatically some code that will reproduce the changes you made manually with edit()."
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#edit",
    "href": "posts/2022-04-27-tide/index.html#edit",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "Edit",
    "text": "Edit\nR’s edit() function invokes a text editor so you can amend an R object.1\nSomething special happens If you edit() a data.frame object: a somewhat-janky interactive spreadsheet-like editor appears in a new window.2\nClick in a cell to amend a value, or click in the header for a menu that lets you change the column name, or switch between real and character classes. There are even buttons to copy and paste values.\nClick the ‘quit’ button to confirm your changes. The edited data is returned to you back in the console.\nBut that’s not very reproducible. How can anyone recreate the amended dataframe from the original if your clicks and keypresses weren’t recorded?\nCan we make edit() more reproducible?"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#tide",
    "href": "posts/2022-04-27-tide/index.html#tide",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "Tide",
    "text": "Tide\nBasic premise: create a function that accepts a dataframe as input, opens the edit menu, observes the updated values and generates code to reproduce the new object from the old.\nI’ve created the concept package, {tide}, to do this.3 It has only one, eponymous function: tide().\nWhy ‘tide’? Well, it’s ‘edit’ backwards. And we’re ‘turning the tide’ on the edit() function to make it reproducible, geddit?4\nYou can install {tide} from GitHub. The {clipr} package, which can copy text to your clipboard, will also be installed.\n\nif (!require(remotes)) install.packages(\"remotes\")\ninstall_github(\"matt-dray/tide\")\n\nSo let’s get our feet wet with an example. Here’s a thematically-related data.frame of the tide table for London Bridge for May 1 2022.\n\ntide_table &lt;- data.frame(\n  type = c(\"High\", \"Low\", NA_character_, \"Low\"),\n  time_bst = c(\"02:58\", \"09:42\", \"15:20\", \"21:58\"),\n  height_m = c(7.0, 0.5, 6.9, 70)\n)\n\ntide_table\n\n  type time_bst height_m\n1 High    02:58      7.0\n2  Low    09:42      0.5\n3 &lt;NA&gt;    15:20      6.9\n4  Low    21:58     70.0\n\n\nBut whoops: the missing value should be ‘High’ and the height is wrong by two orders of magnitude for the 21:58 low tide.\nSo, let’s use tide::tide() on the dataframe to edit those values.\n\nlibrary(tide)\ntide(tide_table)\n\nThis opens a separate data-editor window. Here’s how it looks when it opens:5\n\nAnd once I’ve made the adjustments manually:\n\nAnd here’s what’s returned to the console once I’ve clicked the ‘Quit’ button:\nWrote code to clipboard\n##   type time_bst height_m\n## 1 High    02:58      7.0\n## 2  Low    09:42      0.5\n## 3 High    15:20      6.9\n## 4  Low    21:58      0.7\nYou can see the edits have been successfully returned. This is also what you’d see if you just used edit().\nThe extra feature from tide() is evident in the message Wrote code to clipboard: the function generated some lines of code that will take you from the original to the edited object.\nSo if we now paste from the clipboard we get:\n\ntide_table[3, 1] &lt;- \"High\"\ntide_table[4, 3] &lt;- 0.7\n\nIn other words, ‘replace the value in row 3, column 1 of the tide_table object with the string value \"High\"’, for example.\nAnd if we actually run those lines, we can recreate the amended data.frame from the original:\n\ntide_table\n\n  type time_bst height_m\n1 High    02:58      7.0\n2  Low    09:42      0.5\n3 High    15:20      6.9\n4  Low    21:58      0.7\n\n\nSo, hurrah, we now have a method of manually editing the table and getting some code back that can reproduce it."
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#diet",
    "href": "posts/2022-04-27-tide/index.html#diet",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "Diet",
    "text": "Diet\nTo borrow another anagram of ‘edit’ the capability of the package is quite… lightweight. Some issues are that:\n\nthe function currently only works if you amend individual values (cells), not if you change headers, or add rows and columns\nthe returned code will operate on a cell-by-cell basis, so you might get x[1, 1] &lt;- \"A\" and x[2, 1] &lt;- \"B\" where actually it could have been the more convenient to get x[1:2, 1] &lt;- c(\"A\", \"B\")\nthe returned code refers to columns by index, even though it’s more explicit to refer to them by name, like x[1, \"col1\"] &lt;- \"A\"\nthe returned code will be written in base R and will edit in place by index (i.e. [&lt;-), it doesn’t return {data.table}- or tidyverse-compliant code\nyou only get the code in your clipboard, it isn’t returned from the function\n\nI might update the package to handle this stuff in future, or you can do it for me with a pull request in the GitHub repo.\nBut to be honest, the data editor is probably a bit too clunky and simple to be useful for most use cases. So there’s not much point expanding this package beyond a concept.\nOr maybe the approach will pick up pace like the Severn Estuary tidal bore, who knows? Or maybe you think this post is a bore.6"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#environment",
    "href": "posts/2022-04-27-tide/index.html#environment",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:36:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#footnotes",
    "href": "posts/2022-04-27-tide/index.html#footnotes",
    "title": "Turn the {tide} on R’s secret spreadsheet editor",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI think this was new to quite a lot of people, based on a recent tweet I wrote about it. The edit() function feels like another one of those ‘hidden’ base functions. There’s not really a good reason for you to know about it unless someone told you about it. I got it from an old-school textbook when first learning R, just like the locator() function for retrieving interactively the coordinates from a plot, which I wrote about in a previous post.↩︎\nNote that the help for ?dataentry, which underlies edit(), says ‘the data entry editor is only available on some platforms and GUIs’ and ‘the details of interface to the data grid may differ by platform and GUI’.↩︎\n‘Concept’ means I can put it out there without any guarantees or polish, and I don’t even have to complete it if I don’t want to!↩︎\nAlso consider the allusion to King Canute trying to turn back the tide. It can be pretty hard to stop people writing non-reproducible code. And this package isn’t going to change that.↩︎\nNote that the help for ?dataentry, which underlies edit(), says ‘the data entry editor is only available on some platforms and GUIs’ and ‘the details of interface to the data grid may differ by platform and GUI’.↩︎\nYou came here for the wordplay anyway, right?↩︎"
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#tldr",
    "href": "posts/2023-09-16-chunktop/index.html#tldr",
    "title": "Dear John, I’m sorry",
    "section": "tl;dr",
    "text": "tl;dr\nI developed a convenience function for parsing chunk options out of an R Markdown document for collaborators to edit. But it doesn’t work in reverse, which is the whole point. Some notes on failure.\n\n Note\nSince this was posted, the folks at ThinkR have a pretty good solution with the {lightparser} package: ‘From Rmd And Qmd To Tibble And Back’. The ‘And Back’ being the crucial part."
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#a-very-simple-problem",
    "href": "posts/2023-09-16-chunktop/index.html#a-very-simple-problem",
    "title": "Dear John, I’m sorry",
    "section": "A very simple problem (?)",
    "text": "A very simple problem (?)\nJohn asked about parsing chunk options from R Markdown files (Rmd), passing the content to editors, then reincorporating the edited text back into the chunk whence it came.\nWell, John, have I got the solution for you. Oh wait, I absolutely don’t. Rather I’ve looked into {parsermd}, messed around and… gave up. C’est la vie.\nIn my hubris, I began the package {chunktop} to solve John’s problem. Goal: parse Rmd chunk options, write them to file, allow for edits, read them back in and reintegrate the strings into the chunks they came from. Then re-write the Rmd with the changes. Boom.\nSpoiler: I was naïve."
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#a-good-start",
    "href": "posts/2023-09-16-chunktop/index.html#a-good-start",
    "title": "Dear John, I’m sorry",
    "section": "A good start",
    "text": "A good start\nMy advice: don’t install {chunktop}; it’s already archived on GitHub.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/chunktop\")\n\nIt steals functionality from the excellent {parsermd} package to grab Rmd chunk options using the very appropriate rmd_get_options() function.\nThe package contains a demo Rmd for testing purposes.\n\npath &lt;- system.file(\"extdata/demo1.Rmd\", package = \"chunktop\")\n\nYou can read in this demo Rmd with parsermd::parse_rmd(), which is actually a little abstract syntax tree (AST) that demonstrates the hierarchy of the page and contains all the data.\n\nif (!require(\"parsermd\")) install.packages(parsermd)\n\nLoading required package: parsermd\n\n(rmd &lt;- parse_rmd(path))\n\n├── YAML [1 lines]\n└── Heading [h1] - A header\n    ├── Chunk [r, 1 opt, 1 lines] - chunk1\n    └── Heading [h2] - A subheader\n        ├── Chunk [r, 2 opts, 1 lines] - chunk2\n        ├── Markdown [2 lines]\n        ├── Chunk [r, 1 lines] - chunk3\n        └── Chunk [r, 2 opts, 1 lines] - chunk4\n\n\nAnd we can take a look at the lines in the Rmd doc.\n\n(rmd_doc &lt;- parsermd::as_document(rmd))\n\n [1] \"---\"                                                                \n [2] \"title: Test\"                                                        \n [3] \"---\"                                                                \n [4] \"\"                                                                   \n [5] \"# A header\"                                                         \n [6] \"\"                                                                   \n [7] \"```{r chunk1, eval = FALSE}\"                                        \n [8] \"1 + 1\"                                                              \n [9] \"```\"                                                                \n[10] \"\"                                                                   \n[11] \"## A subheader\"                                                     \n[12] \"\"                                                                   \n[13] \"```{r chunk2, fig.cap = \\\"I am a fig caption.\\\", fig.height = 4}\"   \n[14] \"plot(mtcars$mpg, mtcars$cyl)\"                                       \n[15] \"```\"                                                                \n[16] \"\"                                                                   \n[17] \"Some text.\"                                                         \n[18] \"\"                                                                   \n[19] \"\"                                                                   \n[20] \"```{r chunk3}\"                                                      \n[21] \"plot(mtcars$mpg, mtcars$disp\"                                       \n[22] \"```\"                                                                \n[23] \"\"                                                                   \n[24] \"```{r chunk4, fig.cap = \\\"I am another fig caption.\\\", eval = TRUE}\"\n[25] \"plot(mtcars$mpg, mtcars$drat)\"                                      \n[26] \"```\"                                                                \n[27] \"\"                                                                   \n\n\nSo it contains a bunch of chunks with various options.\nSo, here’s as far as I got. First off, given our Rmd file, we can use get_chunktop() to read the chunk options of interest using {parsermd} and stick them a nice little list. Trivially.\n\nlibrary(chunktop)\n(chunktop_list &lt;- get_chunktop(rmd_file = path, opts = c(\"fig.cap\", \"eval\")))\n\n$chunk1\n$chunk1$eval\n[1] \"FALSE\"\n\n\n$chunk2\n$chunk2$fig.cap\n[1] \"\\\"I am a fig caption.\\\"\"\n\n\n$chunk4\n$chunk4$fig.cap\n[1] \"\\\"I am another fig caption.\\\"\"\n\n$chunk4$eval\n[1] \"TRUE\"\n\n\nWhich is trivially massaged into a data.frame.\n\n(chunktop_df &lt;- chunktop_to_df(chunktop_list))\n\n  chunk_name option_name                option_value\n1     chunk1        eval                       FALSE\n2     chunk2     fig.cap       \"I am a fig caption.\"\n3     chunk4     fig.cap \"I am another fig caption.\"\n4     chunk4        eval                        TRUE\n\n\nWhich is trivially written to a CSV to share with your colleagues for editing.\n\ncsv_file &lt;- tempfile(fileext = \".csv\")\nwrite.csv(chunktop_df, csv_file, row.names = FALSE)\n\nWhich is trivially read back into R.\n\n(chunktop_df2 &lt;- read.csv(csv_file))\n\n  chunk_name option_name                option_value\n1     chunk1        eval                       FALSE\n2     chunk2     fig.cap       \"I am a fig caption.\"\n3     chunk4     fig.cap \"I am another fig caption.\"\n4     chunk4        eval                        TRUE\n\n\nWhich is trivially converted back into a list.\n\n(chunktop_list2 &lt;- df_to_chunktop(chunktop_df2))\n\n$chunk1\n$chunk1$eval\n[1] \"FALSE\"\n\n\n$chunk2\n$chunk2$fig.cap\n[1] \"\\\"I am a fig caption.\\\"\"\n\n\n$chunk4\n$chunk4$fig.cap\n[1] \"\\\"I am another fig caption.\\\"\"\n\n$chunk4$eval\n[1] \"TRUE\"\n\n\nAnd then we trivially, um, well, I don’t know, actually. I just assumed there would be an elegant way to convert the listed options back into the chunk options.\nThe function parsermd::rmd_set_options() exists, but appears to set options for all chunks, not selected options. Maybe I misunderstood, let me know.\nFor sure you could do a thing where you parse the strings out of the Rmd and replace them with the new option values. You are welcome to do that, friend."
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#descent-into-masochism",
    "href": "posts/2023-09-16-chunktop/index.html#descent-into-masochism",
    "title": "Dear John, I’m sorry",
    "section": "Descent into masochism",
    "text": "Descent into masochism\nAnyway, having implied that I am too lazy to do that, I actually tried something much more procastinatory when I hit a brick wall. Enjoy this bonus content.\nI wondered if I could just… extract the chunk options from the original Rmd myself, dependency-free. For ‘fun’.\nBut I turned I into a sort of unhinged code golf. Well, maybe ‘code wild-goose-chase’. The challenge: is it possible to extract chunk options from an arbitrary Rmd using only base R in a single base-R pipe (|&gt;) chain? Haha, of course.\nFirst, I’ve got a few input checks that I’ve put into a .check_inputs() so that it causes less clutter in the main function.\n\n\nClick for function to check inputs\n\n\n.check_inputs &lt;- function(rmd_lines, engine, yaml_out) {\n  \n  if (!inherits(rmd_lines, \"character\")) {\n    stop(\"Argument 'rmd_lines' must be a character vector.\", call. = FALSE)\n  }\n  \n  if (engine != \"r\") {\n    stop(\"For now, argument 'engine' must be 'r'.\", call. = FALSE)\n  }\n  \n  if (!is.null(yaml_out) & !inherits(yaml_out, \"character\")) {\n    stop(\"Argument 'yaml_out' must be NULL or character.\", call. = FALSE)\n  }\n  \n  if (!is.null(yaml_out)) {\n    \n    if (tools::file_ext(yaml_out) != \"yaml\") {\n      stop(\"Argument 'yaml_out' must have extension '.yaml'.\", call. = FALSE)\n    }\n    \n    if (!dir.exists(dirname(yaml_out))) {\n      stop(\"The directory in 'yaml_out' does not exist.\", call. = FALSE)\n    }\n    \n  }\n  \n}\n\n\nSo here’s an overengineered grab_chunktop() function that extracts Rmd chunk options.\n\ngrab_chunktop &lt;- function(rmd_lines, engine = \"r\", yaml_out = NULL) {\n  \n  .check_inputs(rmd_lines, engine, yaml_out)\n  \n  rmd_lines[grep(\"```\\\\{\", rmd_lines)] |&gt;  # isolate Rmd chunks\n    gsub(paste0(\"```\\\\{\", engine , \" |\\\\}$\"), \"\", x = _) |&gt;  # retain options\n    strsplit(\", \") |&gt;  # list of chunks, split by commas\n    (\\(chunk_str) {\n      setNames(object = chunk_str, sapply(chunk_str, \"[[\", 1))  # name-value\n    })() |&gt;  # name the list elements after chunks\n    sapply(\"[\", -1) |&gt;  # forget first element (engine)\n    lapply(  # split options/values into nested list under named chunk\n      \\(opt_str) {\n        strsplit(opt_str, \"=\") |&gt;  # \"eval=TRUE\" to \"eval\" and \"TRUE\"\n          (\\(opt_str) {  # first element to name\n            setNames(object = opt_str, trimws(sapply(opt_str, \"[[\", 1)))}\n          )() |&gt;\n          sapply(\"[\", -1) |&gt;  # now remove first element\n          trimws() |&gt; \n          as.list() |&gt;\n          type.convert(as.is = TRUE)  # make sure \"1\" becomes 1\n      }\n    )\n  \n}\n\nAbsolutely disgusting. But it works!\n\ngrab_chunktop(rmd_doc)\n\n$chunk1\n$chunk1$eval\n[1] FALSE\n\n\n$chunk2\n$chunk2$fig.cap\n[1] \"\\\"I am a fig caption.\\\"\"\n\n$chunk2$fig.height\n[1] 4\n\n\n$chunk3\nlist()\n\n$chunk4\n$chunk4$fig.cap\n[1] \"\\\"I am another fig caption.\\\"\"\n\n$chunk4$eval\n[1] TRUE\n\n\nNote the exclusive use of |&gt; base pipe, _ placeholder, \\() anonymous function and ()() ‘dog’s balls’. Welcome to base R circa 2023.\nI’m telling you this works and you can see that’s the case. But gosh bless you if you actually try to grok that code by eye."
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#brief-grief",
    "href": "posts/2023-09-16-chunktop/index.html#brief-grief",
    "title": "Dear John, I’m sorry",
    "section": "Brief grief",
    "text": "Brief grief\nNothing good has come of this. I just have more respect for {parsermd}. But here’s a brief timeline of my activites on this task:\n\nthere’s no way this isn’t trivial (denial)\nI can’t believe I can’t batter {parsermd} into doing this (anger)\nI’ll start a package and see where we get (bargaining)\nwhat if I simply ignore the package and lark about with base R instead (depression)\nI’ll just write a blog post and move on (acceptance)\n\nDon’t worry, you only lost a few braincells reading this. I lost an afternoon, woe is me."
  },
  {
    "objectID": "posts/2023-09-16-chunktop/index.html#environment",
    "href": "posts/2023-09-16-chunktop/index.html#environment",
    "title": "Dear John, I’m sorry",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 09:55:00 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] chunktop_0.0.0.9000 parsermd_0.1.2     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       cli_3.6.2         knitr_1.45        rlang_1.1.3      \n [5] xfun_0.41         purrr_1.0.2       jsonlite_1.8.7    glue_1.7.0       \n [9] backports_1.4.1   htmltools_0.5.6.1 hms_1.1.3         fansi_1.0.6      \n[13] rmarkdown_2.25    evaluate_0.23     tibble_3.2.1      tzdb_0.4.0       \n[17] fontawesome_0.5.2 fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4  \n[21] compiler_4.3.1    htmlwidgets_1.6.2 Rcpp_1.0.11       pkgconfig_2.0.3  \n[25] rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1          tidyselect_1.2.0 \n[29] readr_2.1.4       utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3   \n[33] checkmate_2.2.0   withr_2.5.2       tools_4.3.1"
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#tldr",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#tldr",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "tl;dr",
    "text": "tl;dr\nI presented slides at an R conference about {crosstalk}."
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#earl-2018",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#earl-2018",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "EARL 2018",
    "text": "EARL 2018\nI gave a talk called ‘Crosstalk: Shiny-like without Shiny’1 at the 2018 EARL conference in London.\nThe {crosstalk} package by Joe Cheng allows htmlwidgets—JavaScript visualisations wrapped in R code—to interact with each other. Filtering the data in widget causes all widgets to be filtered. This can be done inside an R Markdown document (including Flexdashboard) for easy server-less sharing in HTML format."
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#crosstalk-in-action",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#crosstalk-in-action",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "{crosstalk} in action",
    "text": "{crosstalk} in action\nBelow is a very simple example from the {crosstalk} documentation site. Click and drag to highlight points in the interactive plot ({d3scatter} package) and ‘brush’ the map markers (button in upper left) on the interactive map ({leaflet} package) and see how selections in each impact each other. Without {crosstalk}, selections in one of these widgets would not impact the others.\n\n\n\n\n\n\n\n\n\n\nYou can find a more advanced example of {crosstalk} in action using Gapminder data. It links HTML widgets from three packages – {leaflet}, {d3scatter} and {DT} – and includes a couple of sliders for filtering. All of this in less than 80 lines of code.\nRemember all this is happening in the browser and without Shiny. And all you need to do is give each of your widgets a ‘shared data’ object. So instead of this:\n\ndata &lt;- readRDS(\"data/some_data.RDS\")  # get data\ndatatable(data)  # interactive table\nleaflet(data) %&gt;% addTiles() %&gt;% addMarkers()  # map\n\nWe can just add one extra line to create the shared data object and pass that to our widgets instead:\n\ndata &lt;- readRDS(\"data/some_data.RDS\")\nshared &lt;- SharedData$new(data)  # just add this line\ndatatable(shared)  # now refer to the shared data object\nleaflet(shared) %&gt;% addTiles() %&gt;% addMarkers()"
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#slides",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#slides",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "Slides",
    "text": "Slides\nMy task: I had to create a very simple app for our users to explore schools data. My problem: I didn’t have a server for hosting such an app. In other words, Shiny wasn’t really feasible in this case.\nI’ve embedded the slides below. Click inside the frame and use the left and right arrow keys to navigate. Press P to see the presenter notes.\n\n\n\n\n\n\n\n\nYou can also view the slides in a dedicated browser tab.\nOn GitHub you can find code for the presentation, written with the {xaringan} package, and code for the dummy examples in it."
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#memestravaganza",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#memestravaganza",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "Memestravaganza",
    "text": "Memestravaganza\nSince it’s 2018, the only way to publicise such a presentation is to exploit the power of memes and social media; the only method for communicating with millenials and younglings these days.\nBut why stop at one meme? Why not a meme advent calendar counting down the week in advance of the conference?2 You can find them all (plus bonuses) in my earl18-presentation GitHub repo\nI’ve reproduced them here with a bit more context.\n\nDay one\n\n\n\n\n\nYeah, so I figured that Shiny was the only way to make interactive apps with R. But I had a problem: no server access for hosting the app. {crosstalk} is worth considering in this instance because you can share outputs as HTML files, which will open in the user’s browser.\n\n\nDay two\n\n\n\n\n\nR users can probably recognise an interactive app made with Shiny3. Probably a Flexdashboard is easy to recognise too; these are typically used for non-interactive dashboard displays, but {crosstalk} can be used to blur this line by making the elements interact with each other.\n\n\nDay three\n\n\n\n\n\nSelf-explanatory, really. A small app can be made using {crosstalk} and shared freely. Try it!\n\n\nDay four\n\n\n\n\n\nIt’s 2018. You’ve got to exploit Trump for personal gain at some point. One potential drawback of Shiny is the need to host the app on a server. Not ideal if you don’t have access to one. This is not a problem with {crosstalk}-enabled tools, which you can share as HTML files.\nBonus:\n\n\n\n\n\n\n\nDay five\n\n\n\n\n\nYeah, so there’s a false equivalency here. {crosstalk} doesn’t necessarily help provide a direct replacement for Shiny. You still need Shiny to make ‘proper’ apps. But hey, the picture that the little girl has drawn still looks like a cat, right?\n\n\n\n\n\nSince everything is rendered in-browser with {crosstalk}, you’re limited by your browser’s power. This means that the number of points on your interactive map, for example, is limited. In practice it’s maybe a couple of hundred. You can get around this by controlling point layers that can be switched on and off so fewer points are rendered at any one point But that’s a pain.\n\n\nDay six\n\n\n\n\n\nLet’s say you’ve read your data into the object data. Ordinarily you would do leaflet::leaflet(data), DT::datatable(data), etc, to create HTML widgets containing the data. To get the widgets to talk to each other with {crosstalk}, you make a shared data object: shared &lt;- SharedData$new(data). Now you can do leaflet::leaflet(shared), DT::datatable(shared), etc, to get widget interactivity. Only one extra line of code is needed.\n\n\nDay seven\n\n\n\n\n\nYou can use both frameworks to do cool stuff! Just consider the context and the limitations of {crosstalk} when you do this.\nAlso, turns out I punked you: my talk was called ‘Crosstalk: Shiny-like without Shiny’ but you can actually put Shiny in your {crosstalk}. Why? Your brushing and filtering with {crosstalk} can be used to generate Shiny outputs and vice versa. For simplicity, my talk focuses only on {crosstalk}"
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#environment",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#environment",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 18:23:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] d3scatter_0.1.0 leaflet_2.1.2   crosstalk_1.2.0\n\nloaded via a namespace (and not attached):\n [1] cli_3.6.1           knitr_1.43.1        rlang_1.1.1        \n [4] xfun_0.39           promises_1.2.0.1    shiny_1.7.4.1      \n [7] jsonlite_1.8.7      xtable_1.8-4        htmltools_0.5.5    \n[10] httpuv_1.6.11       xaringanExtra_0.7.0 rmarkdown_2.23     \n[13] evaluate_0.21       ellipsis_0.3.2      fastmap_1.1.1      \n[16] yaml_2.3.7          lifecycle_1.0.3     compiler_4.3.1     \n[19] htmlwidgets_1.6.2   Rcpp_1.0.11         rstudioapi_0.15.0  \n[22] later_1.3.1         digest_0.6.33       R6_2.5.1           \n[25] magrittr_2.0.3      tools_4.3.1         lazyeval_0.2.2     \n[28] mime_0.12"
  },
  {
    "objectID": "posts/2018-09-12-crosstalk-memes/index.html#footnotes",
    "href": "posts/2018-09-12-crosstalk-memes/index.html#footnotes",
    "title": "EARL 2018: {crosstalk} in memes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRunning joke: Shiny without Shiny? Sounds like a dull talk lol.↩︎\nAnswer: because you have better things to do.↩︎\nYeah, but have you seen The New Zealand tourism dashboard?↩︎"
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html",
    "href": "posts/2023-03-15-in-a-dungeon/index.html",
    "title": "Fun and learning. In a dungeon!",
    "section": "",
    "text": "Learn hard and you too can be a mobile gamedev like me."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#tldr",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#tldr",
    "title": "Fun and learning. In a dungeon!",
    "section": "tl;dr",
    "text": "tl;dr\nToday I spoke at a public sector1 event for data scientists2. I said that learning is best when focused into little projects that are fun."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#to-the-point",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#to-the-point",
    "title": "Fun and learning. In a dungeon!",
    "section": "To the point",
    "text": "To the point\nThe abstract sums it up, obviously:\n\nEver done a technical training module and then immediately forgot what you learnt? Do you sometimes feel like you’re ticking boxes instead of actually developing your skills? Yeah, me too. Luckily, more active styles of learning are available. Maybe you can try working on a small, focused project where you can make mistakes and have fun. I’ve had success with this and, as a bonus, accidentally learnt more than I had planned to. I’ll give you an example of my experience and some ideas for how you might be able to do it yourself. The talk will involve a detour to an underground cave, but you won’t need any extra equipment.3\n\nYes, a cheeky teaser there to pique the interest. But everyone came to my talk anyway because it was the only one at that timeslot.\nYou can just look at the slides below if you want (direct link, source). Press ‘s’ to pop out the speaker notes.\n\n\n\n\n\n\n\n\nThese were made with Revealjs via Quarto, of course."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#on-my-soapbox",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#on-my-soapbox",
    "title": "Fun and learning. In a dungeon!",
    "section": "On my soapbox",
    "text": "On my soapbox\nSo what incredible insight did I bring to the event?\nBasically, I think ‘module-based’ learning—often passive video walkthroughs with comprehension exercises—are too generic and I usually struggle to remember anything from them.\nI think ‘project-based’ learning is preferable. Think about what you actually want to learn and develop a small-scope, discrete project around it. Make the subject matter fun. Fail meaningfully by be being open, recording what you’ve found, and involving your community.\nMy contrived soundbite is that module-based is done to you and project-based is done by you.\nIs this a new thought technology? No. Is it always true and applicable to everyone in every conceivable scenario and with every learning need? No. What’s my expertise? None, really. I’ve just spent a long time in lots of different departments and I can tell you what has worked for me4 as someone who entered the public sector with little computing or coding ability.\nAm I all too aware of how self-indulgent this all sounds? Yes. Did I need a whole talk to explain this? No, probably not. I’m happy if just one person stops to think about this next time they want to learn something. I’m also content if one person panicked slightly when they realised that R is a game engine now."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#environment",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#environment",
    "title": "Fun and learning. In a dungeon!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:26:56 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#footnotes",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#footnotes",
    "title": "Fun and learning. In a dungeon!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOn the same day as train and public sector strikes, oof.↩︎\nI’m becoming more convinced that I don’t know what ‘data scientist’ means anymore. ‘Old man yells at cloud (computing)’, etc.↩︎\nA reference of, course, to my little toy {r.oguelike} project. This is an R package I wrote to achieve some learning goals and also to have some fun; it contains a novelty tile- and turn-based game that the player interacts with in the console. This also fit the themes of the conference—connectivity and patterns—because it contains a procedural dungeon generator and enemy pathfinding.↩︎\nWould’ve been smarter to bring, y’know, actual evidence rather than anecdotes to a data science conference, eh?↩︎"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\n\n\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n\nConsiderations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.\nConsiderations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor’s permission is not necessary for any reason–for example, because of any applicable exception or limitation to copyright–then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.\n\n\n\n\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#tldr",
    "href": "posts/2023-02-26-nook-s7/index.html#tldr",
    "title": "Repaying Tom Nook with {S7}",
    "section": "tl;dr",
    "text": "tl;dr\nThe R7 S7 object-oriented system is coming to R. I’ve done a little R6-to-S7 translation on an old project to get a very cursory feel for it, featuring Animal Crossing New Horizons.\n\n Note\nThe S7 system and package are under development and could change at any time, rendering everything in this post useless.1 Heck, last time I checked, the system was called ‘R7’. There’s also a chance that S7 elements may have been integrated into base R itself by the time you read this."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#again-oh-no",
    "href": "posts/2023-02-26-nook-s7/index.html#again-oh-no",
    "title": "Repaying Tom Nook with {S7}",
    "section": "2020 again, oh no",
    "text": "2020 again, oh no\nAnimal Crossing New Horizons (ACNH) was the perfect pandemic game. And the pandemic was the perfect time to build an ersatz version of the ACNH in-game banking system to solve an exercise in the Advanced R book using the {R6} package for object-oriented programming (OOP) in R.\nThe exercise helped me fantasize about defeating the game’s main boss, the predatory loanshark (loanraccoon?) Tom Nook, via endless wire transfers of hard-earned in-game currency, called ‘Bells’.\nOf course, a lot has changed since 2020. Most importantly, a new OOP system for R is being developed. Conversely, Tom Nook has not changed. He is still a scourge.\nAnyway, maybe this is a chance to twitch my OOP muscles with this new system."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#oop-they-did-it-again",
    "href": "posts/2023-02-26-nook-s7/index.html#oop-they-did-it-again",
    "title": "Repaying Tom Nook with {S7}",
    "section": "OOP they did it again",
    "text": "OOP they did it again\nThe R Consortium’s OOP working group has been beavering (raccooning?) away to develop a new OOP system from the ground up: S72 (S3 + S4, geddit?).\nThe idea is to take the best elements of the existing and in-built S3 and S4 systems, interface with them and improve on them.\nYou can read various design docs and meeting minutes on their documentation site, which is housed in their ‘OOP-WG’ GitHub repo, and try out the current iteration of the associated package, fittingly called {S7}.\nYou should refer to their docs in the first instance, or a useful third party review. For example, Jumping Rivers have… jumped the river on this one and produced a handy intro."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#a-new-horizon-for-oop",
    "href": "posts/2023-02-26-nook-s7/index.html#a-new-horizon-for-oop",
    "title": "Repaying Tom Nook with {S7}",
    "section": "A new horizon for OOP",
    "text": "A new horizon for OOP\nNaturally, I should revisit my post on Repaying Tom Nook with {R6} by replicating it with {S7}. Naturally.\nAha, but actually the {S7} package is more like a development of S3 and S4 objects, and is not a ‘new version’ of {R6}! Ah well. I’m noodling around with {S7} for my own devices and thought I’d post it here so I can refer back to it later.\nBasically I’m recycling content from a previous post to get a feel for the new system. But only in the most superficial, basic way. I spent about 15 minutes on this. Look elsewhere for actually-usefully material. You have been warned."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#install",
    "href": "posts/2023-02-26-nook-s7/index.html#install",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Install",
    "text": "Install\nFor now, the {S7} package is in the R Consortium’s OOP-WG GitHub repo.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"RConsortium/OOP-WG\")\n\nAnd for some glamour we’ll also use the quintessential {emoji} package3\n\ninstall.packages(\"emoji\")  # if not yet installed\nlibrary(emoji)"
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#that-is-class",
    "href": "posts/2023-02-26-nook-s7/index.html#that-is-class",
    "title": "Repaying Tom Nook with {S7}",
    "section": "That is class",
    "text": "That is class\nA new class is constructed with… new_class()\nWe can give it a name. We can also give it properties: fields that contain data and can be provided a type check and default value. It’s possible to build validators for these as well, which ensure that certain conditions are met when the properties are adjusted. I’ll keep this simple for now: I just want the values to remain equal or greater than zero.\n\nABD &lt;- new_class(\n  name = \"ABD\",\n  properties = list(\n    savings = new_property(class_integer, default = 0L),\n    loan = new_property(class_integer, default = 2498000L)\n  ),\n  validator = function(self) {\n    if (self@savings &lt; 0L) {\n      \"@savings must be zero or more\"\n    } else if (self@loan &lt; 0L) {\n      \"@loan must be zero or more\"\n    }\n  }\n)\n\nFor new methods, you can create a new ‘generic’ and define a function for it. For example, the ‘deposit’ method is pretty straightforward: it just adds an amount to the current savings value.\n\ndeposit &lt;- new_generic(\"deposit\", \"x\")\n\nmethod(deposit, ABD) &lt;- function(x, amount) {\n  x@savings &lt;- x@savings + amount\n  x\n}\n\nI specified some other methods, but I hid them because they’re not much more complicated.\n\n\nClick for more methods\n\nThe ‘withdraw’ method subtracts a specified amount from the savings property. You’re warned if you specify an amount greater than the amount available.\n\nwithdraw &lt;- new_generic(\"withdraw\", \"x\")\n\nmethod(withdraw, ABD) &lt;- function(x, amount) {\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Withdrew all savings: \", x@savings, \" Bells.\\n\", \n      call. = FALSE\n    )\n    x@savings &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n  }\n  \n  x\n  \n}\n\nThe ‘pay’ method moves funds from savings to loan. You’re warned if the loan is already paid, if you specify a greater amount than there are savings, or if you pay a greater amount than the loan remaining. You’ll get a victory message if you pay off the whole loan.\n\npay &lt;- new_generic(\"pay\", \"x\")\n\nmethod(pay, ABD) &lt;- function(x, amount) {\n  \n  if (x@loan == 0L) {\n    stop(\"You already finished paying your loan!\\n\", call. = FALSE)\n  }\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Paid total amount from savings instead: \", x@savings, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@loan &lt;- x@loan - x@savings\n    x@savings &lt;- 0L\n  } else if (x@loan - amount &lt; 0L) {\n    warning(\n      \"Paid total remaining loan instead: \", x@loan, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@savings &lt;- x@savings - x@loan \n    x@loan &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n    x@loan &lt;- x@loan - amount\n  }\n  \n  if (x@loan == 0L) {\n    cat(\n      emoji(\"smiley\"),\n      \"Sweet! I finally finished paying off my very last home loan!\",\n      emoji(\"tada\"), \"\\n\\n\"\n    )\n  }\n  \n  x\n  \n}\n\nThe check method is basically a print method. It reports the loan and savings amounts currently stored in the bank.\n\ncheck &lt;- new_generic(\"check\", \"x\")\n\nmethod(check, ABD) &lt;- function(x) {\n\n  loan_formatted &lt;- format(x@loan, big.mark = \",\", scientific = FALSE)\n\n  savings_formatted &lt;- format(x@savings, big.mark = \",\", scientific = FALSE)\n\n  cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")\n  cat(emoji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n  cat(emoji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n  cat(\n    \"Please make a selection from the menu below\\n\\n\",\n    emoji(\"house\"), \"pay()\\n\",\n    emoji(\"arrow_up\"), \"deposit()\\n\",\n    emoji(\"arrow_down\"), \"withdraw()\"\n  )\n\n}\n\n\nYou can start a new instance of the ABD class by, y’know, calling it.\n\nbank &lt;- ABD()\n\nWhen you check the class of this object, you’ll see both the custom class name and a reminder that it has the ‘S7’ class.\n\nclass(bank)\n\n[1] \"ABD\"       \"S7_object\"\n\n\nThe vanilla print method exposes the properties and their startup values:\n\nbank\n\n&lt;ABD&gt;\n @ savings: int 0\n @ loan   : int 2498000\n\n\nNote that the properties are prepended with @. This indicates that we can use the ‘at’ symbol to access these ‘slots’ (like S4) from the object, like:\n\nbank@loan\n\n[1] 2498000\n\n\nWhile we’re printing stuff, we can use the check() method (that I’ve pre-specified) to see the properties in a manner that more closely resembles the game.\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,498,000 Bells\n🐖 Savings Balance: 0 Bells\n\nPlease make a selection from the menu below\n\n 🏠 pay()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nYou can easily and directly change the properties. To add 10 Bells:\n\nbank@savings &lt;- 9.99\n\nError: &lt;ABD&gt;@savings must be &lt;integer&gt;, not &lt;double&gt;\nHaha, whoops. Remember I specified that the property can only be an integer, so we need to provide an integer value instead of a double value. In other words, we can only provide whole numbers of Bells. Remember that the L suffix is used in R to signify an integer.4\n\nbank@savings &lt;- 10L\n\nIs there an overdraft? Tom Nook would probably love that and would ask for massive overdraft fees, but it’s not programmed into the game. This is where our validator comes in handy. We specified that you can’t have a negative amount of savings, so this causes an error:\n\nbank@savings &lt;- -11L\n\nError: &lt;ABD&gt; object is invalid:\n- @savings must be zero or more\nThat’s fine, but I have sometimes I have extra logic I want to evaluate when I adjust the properties. That’s why I created new methods earlier on. It means I can use a function to add to the savings property instead, for example.\n\nbank &lt;- deposit(bank, 10L)\nbank@savings\n\n[1] 10\n\n\nWe can retrieve Bells in this fashion too:\n\nbank &lt;- withdraw(bank, 10L)\nbank@savings\n\n[1] 0\n\n\nWhat if we deposit enough Bells to pay the loan?\n\nbank &lt;- deposit(bank, 2500000L)\nbank &lt;- pay(bank, 2500000L)\n\nWarning: Paid total remaining loan instead: 2498000 Bells.\n\n\n😃 Sweet! I finally finished paying off my very last home loan! 🎉 \n\n\nThe method warns us when we try to pay off a value greater than the remaining loan and prints a nice congratulatory message if we’ve cleared the whole debt.\nAnd so we end up with this view:\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 0 Bells\n🐖 Savings Balance: 2,000 Bells\n\nPlease make a selection from the menu below\n\n 🏠 pay()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nHuzzah. Get rekt, raccoon dog. More like Tom Crook amirite."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#environment",
    "href": "posts/2023-02-26-nook-s7/index.html#environment",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-20 22:31:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emoji_15.0    S7_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    glue_1.6.2        stringr_1.5.0     knitr_1.43.1     \n [9] htmltools_0.5.5   rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1        \n[13] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[17] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[21] stringi_1.7.12"
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#footnotes",
    "href": "posts/2023-02-26-nook-s7/index.html#footnotes",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n‘Useless’ is an extremely relative term with regard to this blog.↩︎\n95% certain that ‘S7’ is pronounced how a snake might say ‘seven’: like ‘sseven’.↩︎\n{emo} is dead, long live {emoji}. Haha, joke’s on you, emo will never die. I know this because ‘emo’ was in my top 5 genres on Spotify Wrapped 2022, lololol.↩︎\nWhy L? Shrug. Just take the L.↩︎"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#tldr",
    "href": "posts/2021-07-10-linkrot/index.html#tldr",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a little function to check web pages for link rot and put it in the tiny R package {linkrot} in case you want to use or improve it."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#page-not-found",
    "href": "posts/2021-07-10-linkrot/index.html#page-not-found",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Page not found",
    "text": "Page not found\nYou’ve clicked a link before and been taken somewhere you weren’t expecting. Sometimes it’s because you’ve been rickrolled,1 sure, but content on the internet is constantly being moved or removed and links break all the time.\nA hyperlink that no longer resolves can be considered to have ‘rotted’. As time marches on, the ‘rottenness’ of the internet increases. This can be frustrating.\nThis blog is getting on for a hundred posts over three years. It would not be a surprise if link rot has taken hold. How big is the problem?"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#rising-damp",
    "href": "posts/2021-07-10-linkrot/index.html#rising-damp",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Rising damp",
    "text": "Rising damp\nSo, basically I want to visit every link in every post on this blog and see if it’s still working.2\nI’ve written the function detect_rot() to do this for any given web page and I’ve put it in the {linkrot} package on GitHub. To install:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/linkrot\")\nlibrary(linkrot)\n\nIn short, the detect_rot() function takes the URL of a web page and returns a tibble with details of each link from that page and whether it can be reached.\nI’ve basically built it for my own amusement, so there’s no guarantees. Feel free to suggest or amend things in the GitHub repo.\n\nCheck one post\nLet’s feed in the first post on this blog, from April 2018:\n\ntrek_url &lt;- \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\"\ntrek_rot &lt;- detect_rot(trek_url)\n\nChecking &lt;https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/&gt; ..............................\nIt can take a short while for the function to visit every link. To let us know it’s working, the URL is printed to the console and then a period (.) is printed for every link that’s been successfully visited (a bit like a progress bar).\nWe’re returned an object with a bunch of information.\n\nstr(trek_rot)\n\ntibble [30 × 6] (S3: tbl_df/tbl/data.frame)\n $ page             : chr [1:30] \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" ...\n $ link_url         : chr [1:30] \"https://www.r-project.org/about.html\" \"https://en.wikipedia.org/wiki/Star_Trek:_The_Next_Generation\" \"http://www.st-minutiae.com/resources/scripts/#thenextgeneration\" \"https://github.com/zeeshanu/learn-regex/blob/master/README.md\" ...\n $ link_text        : chr [1:30] \"R statistical software\" \"Star Trek: The Next Generation\" \"Star Trek Minutiae\" \"regex\" ...\n $ response_code    : num [1:30] 200 200 200 200 200 200 200 404 200 200 ...\n $ response_category: chr [1:30] \"Success\" \"Success\" \"Success\" \"Success\" ...\n $ response_success : logi [1:30] TRUE TRUE TRUE TRUE TRUE TRUE ...\nSo, it’s a tibble with six columns and a row for each link on that page that’s been checked. Basically, the output tells us the URL and text of each link and also whether the page was reachable or not.\nThe tibble includes a special officially-standardised three-digit ‘status code’ in the response_code column. These indicate whether contact was successful, with a specific reason. For example, 200 represents a typical success (‘OK’), but you may be familiar with 404 (‘not found’) if you’ve visited a broken link before.\nWe can extract any broken links using the logical response_success column.\n\ntrek_rot[!trek_rot$response_success, c(4, 5, 2)]\n\n# A tibble: 1 x 3\n  response_code response_category link_url                                      \n          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;                                         \n1           404 Client error      https://cran.r-project.org/web/packages/rvest…\nSo, at time of writing, that post has one broken link: an {rvest} package vignette for SelectorGadget that’s no longer active on the CRAN site. It has status code 404 (‘client error’), which basically means the thing couldn’t be found.\nWe can confirm this by visiting the URL, but you could also use the {webshot} package to go and retrieve an screenshot of the page3.\n\nlibrary(webshot)\ncran_404 &lt;- trek_rot$link_url[!trek_rot$response_success]\nwebshot(cran_404, vheight = 250)\n\n\nSo that’s CRAN’s 404 page to tell us that the page couldn’t be fetched.\n\n\nCheck whole blog\nNow we know how it works for one page, we can apply the function over every post of this blog and see how many links have rotted.\nFirst we need all the post URLs, which are all available from the blog’s homepage. The links returned are internal (like 2021/06/28/pixel-art/), so we need to add on the https://www.rostrum.blog/ bit. We also need to filter out any links that aren’t posts (like the ‘About’ page).\n\n# Load packages\nsuppressPackageStartupMessages({\n  library(xml2)\n  library(rvest)\n  library(dplyr)\n  library(purrr)\n})\n\n# The URL of this blog's homepage\nblog_url &lt;- \"https://www.rostrum.blog\"\n\n# Fetch all the links from the blog home page\nblog_hrefs &lt;- \n  read_html(blog_url) %&gt;%  # get full homepage HTML\n  html_nodes(\"a\") %&gt;%      # nodes with links, &lt;a&gt;\n  html_attr(\"href\")        # the URL attribute\n\n# Only links to posts\nposts &lt;- paste0(blog_url, blog_hrefs[grepl(\"^/20\", blog_hrefs)])\ntail(posts)  # preview\n\n[1] \"https://www.rostrum.blog/2018/06/05/tid-ye-text/\"                             \n[2] \"https://www.rostrum.blog/2018/05/25/cloud-pie/\"                               \n[3] \"https://www.rostrum.blog/2018/05/19/pokeballs-in-super-smash-bros/\"           \n[4] \"https://www.rostrum.blog/2018/05/12/accessibility-workshop-at-sprint18/\"      \n[5] \"https://www.rostrum.blog/2018/04/27/two-dogs-in-toilet-elderly-lady-involved/\"\n[6] \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\"\nNow we can use {purrr} to iterate the detect_rot() function over the pages. By using map_df() we can get a data frame as output rather than a list. I’ve hidden the printed output from detect_rot() this time because there would be nearly 100 lines of output (one per post).\n\nresults &lt;- map_df(posts, detect_rot)\n\nSo, this results tibble has 23311 links from 95 posts, or about 25 links per post.\nAgain, we can filter the logical response_success column to see which links weren’t successfully resolved.\n\nrotten &lt;- filter(results, !response_success)\nnrow(rotten)\n\n[1] 61\nSo in total there were 61 links out of 2331 that did not return a ‘success’, which works out to about 3% being unreachable.\nWe can count the reasons for these failures by looking at the status codes.\n\ncount(rotten, response_code, sort = TRUE)\n\n# A tibble: 6 x 2\n  response_code     n\n          &lt;dbl&gt; &lt;int&gt;\n1           404    53\n2           400     4\n3           403     1\n4           406     1\n5           410     1\n6           502     1\nYou can see most of these status codes are in the 4xx range, which is the group of codes that mean ‘client error’. Usually this is a problem with the link you’ve provided, like 404 is ‘not found’, 403 is ‘forbidden’ and 406 is ‘not acceptable’.\nIt’s hard to tell whether this level of link rot is good or bad, but remember that these are links that have failed within the past three years. Imagine how bad this might look in another 10 years. By comparison, a quarter of links on the New York Times website were completely inaccessible, stretching back to 1996.\nI’d be interested to know whether this is comparable to your blog or website."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#surveying-for-rot",
    "href": "posts/2021-07-10-linkrot/index.html#surveying-for-rot",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Surveying for rot",
    "text": "Surveying for rot\nWe’ve seen it in action, but how does the function work? I’m not claiming the approach is optimal, but it obviously worked for my needs. You’ll probably find the approach naive if you have any experience in dealing with HTTP requests from R.\n\nValidate, fetch, check\nYou can find the function definition for detect_rot() in the {linkrot} source code. It has three underlying steps, each of which has a helper function:\n\nCheck that the provided URL is valid with .validate_page()\nScrape the links from the page with .fetch_links()\nVisit each link and check its response code with .check_links()\n\nSo, the URL provided by the user is first checked with help from the {httr} package. We GET() the page and then extract the status_code() and check for an http_error(). If all is well (i.e. no error), then we can continue.\nTo get the links from the URL, we first scrape the page with xml2::read_html() and then use {rvest} functions: html_nodes() to grab all the nodes with links, then html_attr() and html_text() to extract the URLs and link text from each.\nFinally, each of the URLs is visited with GET() and the http_status() is extracted. The final data frame is converted to tibble (for ease of reading) and returned to the user.\n\n\nLimitations\nOf course, it’s possible that GET() will fail to reach a page for reasons other than it being missing. Sometimes there can be a momentary blip, but detect_rot() is simple and never retries a link.\nAdditionally, there are some links that {httr} struggles to contact. I wrapped functions internal to detect_rot() inside tryCatch() so any failures appear as NA in the response_code column. The printed output for detect_rot() also displays an exclamation point (!) instead of a period (.) when being run. For example, there were 8 links that had this problem for this blog.\nI welcome any thoughts or suggestions, particularly around testing. I’d like to use this package as a way to learn proper HTTP testing and have found rOpenSci’s HTTP Testing in R book useful so far. Eventually I might convert detect_rot() to use the {httr2} package when it’s released."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#now-what",
    "href": "posts/2021-07-10-linkrot/index.html#now-what",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Now what?",
    "text": "Now what?\nI could go back and fix the broken links, but maybe it’s not that big a deal. I don’t have any data on what people click on, so I can’t really tell if it’s worth it.\nBut anyway, didn’t I say ‘decay is inevitable’? I can fix things, but more things will break.\nI wasn’t expecting this to get quite so existential.4"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#environment",
    "href": "posts/2021-07-10-linkrot/index.html#environment",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 19:23:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#footnotes",
    "href": "posts/2021-07-10-linkrot/index.html#footnotes",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t worry, you can see from the URL that this doesn’t go to the YouTube video! it goes to the excellent pudding.cool site, which has some great analysis of the rise and rise (and rise) of Rickrolling.↩︎\nThat’s links to other pages on the internet, because links also exist to take you to these footnotes, or point elsewhere internally to this website.↩︎\nIf not already installed, you’ll be prompted by {webshot} to install phantomjs with webshot::install_phantomjs().↩︎\nActually yes, dear reader, he was; he really was.↩︎"
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#tldr",
    "href": "posts/2021-11-27-long-fns/index.html#tldr",
    "title": "R has obscenely long function names",
    "section": "tl;dr",
    "text": "tl;dr\nUse ls() on a package name in the form \"package:base\" to see all the objects it contains. I’ve done this to find the longest (and shortest) function names in base R and the {tidyverse} suite."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#naming-things",
    "href": "posts/2021-11-27-long-fns/index.html#naming-things",
    "title": "R has obscenely long function names",
    "section": "Naming things",
    "text": "Naming things\nI try to keep to a few rules when creating function names, like:\n\nuse a verb to make clear the intended action, like get_badge() from {badgr}\nstart functions with a prefix to make autocomplete easier, like the dh_*() functions from {dehex}\ntry to be descriptive but succinct, like r2cron() from {dialga}\n\nIt can be tricky to be succinct. Consider the base R function suppressPackageStartupMessages()1: it’s a whopping 30 characters, but all the words are important. Something shortened, like suppPkgStartMsg(), wouldn’t be so clear.\nIt made me wonder: what’s the longest function name in R?2\nBut! It seems tricky and time consuming to find the longest function name from all R packages. CRAN alone has over 18,000 at time of writing.\nA much easier (lazier) approach is to focus on some package subsets. I’ll look at base R and the {tidyverse}."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#the-long-and-the-short-of-it",
    "href": "posts/2021-11-27-long-fns/index.html#the-long-and-the-short-of-it",
    "title": "R has obscenely long function names",
    "section": "The long and the short of it",
    "text": "The long and the short of it\n\nBase R\nCertain R packages are built-in and attached by default on startup.\n\nbase_names &lt;- sessionInfo()$basePkgs\nbase_names\n\n[1] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[7] \"base\"     \n\n\nHow can we fetch all the functions from these packages? We can use ls() to list all their objects, supplying the package name in the format \"package:base\", for example. Note that I said ‘objects’, not ‘functions’, since it will also return names that refer to things like datasets.\nFor fun, we can use this as an excuse to demo ‘lambda’ syntax and the dog’s balls approach to function-writing, both introduced in R v4.1.3\n\nbase_pkgs &lt;- paste0(\"package:\", base_names)\n\nbase_fns &lt;- lapply(base_pkgs, ls) |&gt;\n  setNames(base_names) |&gt; \n  lapply(\\(object) as.data.frame(object)) |&gt; \n  (\\(x) do.call(rbind, x))()  # the balls ()()\n\nbase_fns$package &lt;- gsub(\"\\\\.\\\\d{,4}$\", \"\", row.names(base_fns))\nrow.names(base_fns) &lt;- NULL\nbase_fns$nchar &lt;- nchar(base_fns$object)\n\nbase_fns &lt;- base_fns[order(-base_fns$nchar), ]\n\nOf the 2465 objects across these packages, a quick histogram shows that the most frequent character length is under 10, with a tail stretching out to over 30.\n\nhist(\n  base_fns$nchar,\n  main = \"Character length of base-object names\",\n  xlab = \"Number of characters\",\n  las = 1\n)\n\n\n\n\nHere’s the top 10 by character length.\n\nbase_fns_top &lt;- base_fns[order(-base_fns$nchar), ]\nrownames(base_fns_top) &lt;- seq(length = nrow(base_fns_top))\nhead(base_fns_top, 10)\n\n                                  object package nchar\n1  aspell_write_personal_dictionary_file   utils    37\n2     getDLLRegisteredRoutines.character    base    34\n3       getDLLRegisteredRoutines.DLLInfo    base    32\n4        reconcilePropertiesAndPrototype methods    31\n5         suppressPackageStartupMessages    base    30\n6          as.data.frame.numeric_version    base    29\n7           as.character.numeric_version    base    28\n8            print.DLLRegisteredRoutines    base    27\n9             as.data.frame.model.matrix    base    26\n10            conditionMessage.condition    base    26\n\n\nSo there are four objects with names longer than suppressPackageStartupMessages(), though they are rarely used as far as I can tell. The longest is aspell_write_personal_dictionary_file(), which has 37(!) characters. It’s part of the spellcheck functions in {utils}.\nIt’s interesting to me that it follows some of those rules for function naming that I mentioned earlier. It has a verb, is descriptive and uses a prefix for easier autocomplete; ‘aspell’ refers to the GNU open-source Aspell spellchecker on which it’s based.\nI’m intrigued that the function uses snake_case rather than camelCase or dot.case, which seem more prevalent in base functions. You could argue then that the underscores have ‘inflated’ the length by four characters. Similarly, the prefix adds another six characters. So maybe the function could be simplified to writePersonalDictionaryFile(), which is merely 27 characters.\nWhat about shortest functions? There are many one-character functions in base R.\n\nsort(base_fns[base_fns$nchar == 1, ][[\"object\"]])\n\n [1] \"-\" \":\" \"!\" \"?\" \"(\" \"[\" \"{\" \"@\" \"*\" \"/\" \"&\" \"^\" \"+\" \"&lt;\" \"=\" \"&gt;\" \"|\" \"~\" \"$\"\n[20] \"c\" \"C\" \"D\" \"F\" \"I\" \"q\" \"t\" \"T\"\n\n\nSome of these will be familiar, like c() to concatenate and t() to transpose. You might wonder why operators and brackets are in here. Remember: everything in R is a function, so `[`(mtcars, \"hp\") is the same as mtcars[\"hp\"]. I have to admit that stats::C() and stats::D() were new to me.\n\n\nTidyverse\nHow about object names from the {tidyverse}?\nTo start, we need to attach the packages. Running library(tidyverse) only loads the core packages of the tidyverse, so we need another approach to attach them all.\nOne method is to get the a vector of the package names with the tidyverse_packages() function and pass it to p_load() from {pacman}, which prevents the need for a separate library() call for each one.4\nFirst, here’s the tidyverse packages.\n\n Note\nI updated this post in July 2023. The {lubridate} package is now installed as part of the tidyverse and many new functions have appeared across the multitude of packages in the metapackage.\n\n\n# install.packages(\"tidyverse\")  # if not installed\nsuppressPackageStartupMessages(  # in action!\n  library(tidyverse)\n)\ntidy_names &lt;- tidyverse_packages()\ntidy_names\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nAnd now to load them all.\n\n# install.packages(\"pacman\")  # if not installed\nlibrary(pacman)\np_load(char = tidy_names)\n\nOnce again we can ls() over packages in the form \"package:dplyr\". Now the {tidyverse} is loaded, we might as well use it to run the same pipeline as we did for the base packages.\n\ntidy_pkgs &lt;- paste0(\"package:\", tidy_names)\n\ntidy_fns &lt;- map(tidy_pkgs, ls) |&gt;\n  set_names(tidy_names) |&gt; \n  enframe(name = \"package\", value = \"object\") |&gt;\n  unnest(object) |&gt; \n  mutate(nchar = nchar(object))\n\nSo we’re looking at even more packages this time, since the whole tidyverse contains 3071 of them.\nThe histogram is not too dissimilar to the one for base packages, though the tail is shorter, it’s arguably more normal-looking and the peak is perhaps slightly closer to 10. The latter could be because of more liberal use of snake_case.\n\nhist(\n  tidy_fns$nchar,\n  main = \"Character length of {tidyverse} object names\",\n  xlab = \"Number of characters\",\n  las = 1\n)\n\n\n\n\nHere’s the top 10 by character length.\n\nslice_max(tidy_fns, nchar, n = 10)\n\n# A tibble: 11 × 3\n   package       object                            nchar\n   &lt;chr&gt;         &lt;chr&gt;                             &lt;int&gt;\n 1 rlang         ffi_standalone_check_number_1.0.7    33\n 2 googlesheets4 vec_ptype2.googlesheets4_formula     32\n 3 googlesheets4 vec_cast.googlesheets4_formula       30\n 4 cli           cli_progress_builtin_handlers        29\n 5 rstudioapi    getRStudioPackageDependencies        29\n 6 rstudioapi    registerCommandStreamCallback        29\n 7 rlang         ffi_standalone_is_bool_1.0.7         28\n 8 dbplyr        supports_star_without_alias          27\n 9 rstudioapi    launcherPlacementConstraint          27\n10 cli           ansi_has_hyperlink_support           26\n11 ggplot2       scale_linewidth_continuous           26\n\n\nWell there you are: ffi_standalone_check_number_1.0.7() from {rlang} wins the prize with 33 characters. What does it do? The full documentation is literally ‘Internal API for standalone-types-check’. Okey doke.\nIntriguingly, the next two are both from {googlesheets4}. The help pages say they’re ‘internal {vctrs} methods’. The names of these are long because of the construction: the first part tells us the method name, e.g. vec_ptype2, and the second part tells us that they apply to the googlesheets4_formula S3 class.\nSo maybe these don’t really count because they would be executed as as vec_ptype2() and vec_cast()? And they’re inflated because they contain the package name, {googlesheets4}, which is quite a long one (13 characters). That would leave cli::cli_progress_builtin_handlers() and rstudioapi::getRStudioPackageDependencies() as the next longest (29 characters). The latter uses camelCase—which is typical of the {rstudioapi} package—so isn’t bulked out by underscores.\nOn the other end of the spectrum, there’s only one function with one character: dplyr::n(). I think it makes sense to avoid single-character functions in non-base packages, because they aren’t terribly descriptive. n() can at least be understood to mean ‘number’.\nInstead, here’s all the two-letter functions from the {tidyverse}. Note that many of these are from {lubridate} and are shorthand expressions that make sense in context, like hm() for hour-minute. You can also see some of {rlang}’s operators creep in here, like bang-bang (!!) and the walrus (:=).5\n\ndplyr::filter(tidy_fns, nchar == 2)\n\n# A tibble: 16 × 3\n   package   object nchar\n   &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n 1 cli       no         2\n 2 dplyr     do         2\n 3 dplyr     id         2\n 4 lubridate am         2\n 5 lubridate hm         2\n 6 lubridate ms         2\n 7 lubridate my         2\n 8 lubridate pm         2\n 9 lubridate tz         2\n10 lubridate ym         2\n11 lubridate yq         2\n12 magrittr  or         2\n13 rlang     :=         2\n14 rlang     !!         2\n15 rlang     ll         2\n16 rlang     UQ         2\n\n\nMany of these are due to {lubridate} using single letters to represent time periods, like hm is ‘hour minute’. You can also see some symbols from {rlang}, like the good ol’ :=, or ‘walrus’ operator.\nBoth the {dplyr} functions here are no longer intended for use. I’m sad especially for dplyr::do(): the help page says it ‘never really felt like it belong[ed] with the rest of dplyr’. Sad.\n\nIn memoriam: do()."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#environment",
    "href": "posts/2021-11-27-long-fns/index.html#environment",
    "title": "R has obscenely long function names",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:19:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] xml2_1.3.5          rvest_1.0.3         rstudioapi_0.15.0  \n [4] rlang_1.1.1         reprex_2.0.2        readxl_1.4.2       \n [7] ragg_1.2.5          pillar_1.9.0        modelr_0.1.11      \n[10] magrittr_2.0.3      jsonlite_1.8.7      httr_1.4.6         \n[13] hms_1.1.3           haven_2.5.2         googlesheets4_1.1.1\n[16] googledrive_2.1.1   dtplyr_1.3.1        dbplyr_2.3.2       \n[19] cli_3.6.1           conflicted_1.2.0    broom_1.0.5        \n[22] pacman_0.5.1        lubridate_1.9.2     forcats_1.0.0      \n[25] stringr_1.5.0       dplyr_1.1.2         purrr_1.0.1        \n[28] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1       \n[31] ggplot2_3.4.2       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      xfun_0.39         htmlwidgets_1.6.2 gargle_1.5.1     \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.1       generics_0.1.3   \n [9] fansi_1.0.4       pkgconfig_2.0.3   data.table_1.14.8 lifecycle_1.0.3  \n[13] compiler_4.3.1    textshaping_0.3.6 munsell_0.5.0     fontawesome_0.5.1\n[17] htmltools_0.5.5   yaml_2.3.7        cachem_1.0.8      tidyselect_1.2.0 \n[21] digest_0.6.31     stringi_1.7.12    fastmap_1.1.1     grid_4.3.1       \n[25] colorspace_2.1-0  utf8_1.2.3        withr_2.5.0       scales_1.2.1     \n[29] backports_1.4.1   timechange_0.2.0  rmarkdown_2.23    cellranger_1.1.0 \n[33] memoise_2.0.1     evaluate_0.21     knitr_1.43.1      glue_1.6.2       \n[37] DBI_1.1.3         R6_2.5.1          systemfonts_1.0.4 fs_1.6.2"
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#footnotes",
    "href": "posts/2021-11-27-long-fns/index.html#footnotes",
    "title": "R has obscenely long function names",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI wrote recently a whole post about package startup messages.↩︎\nLuke was curious too, so that’s at least two of us. (Luke also noticed that a link to my {linkrot} package was itself rotten, lol.)↩︎\nMy understanding is that a future version of R will allow an underscore as the left-hand-side placeholder, in a similar manner to how the {tidyverse} allows a dot. That will do away with the need for ()(). Also ignore my badly-written base code; I’m trying to re-learn.↩︎\nIn fact, p_load() will attempt installation if the package can’t be found in your library. Arguably, this is poor behaviour; you should always ask the user before installing something on their machine.↩︎\nBang-Bang and the Walrus, touring Spring 2022.↩︎"
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html",
    "href": "posts/2019-02-01-git-going-cl/index.html",
    "title": "Git going: the command line",
    "section": "",
    "text": "Examples of inputs and outputs at the command line"
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html#tldr",
    "href": "posts/2019-02-01-git-going-cl/index.html#tldr",
    "title": "Git going: the command line",
    "section": "tl;dr",
    "text": "tl;dr\nThis post is a basic introduction to the command line, focusing on macOS’s Terminal. Here are some commonly-used commands:\n\n\n\n\n\n\n\n\nCommand\nExample\nShort explanation\n\n\n\n\npwd\npwd\nPrint working directory\n\n\ncd\ncd &lt;filepath&gt;\nChange directory\n\n\nls\nls\nList folder contents\n\n\nmkdir\nmkdir &lt;folder name&gt;\nMake directory (folder)\n\n\ntouch\ntouch &lt;filename&gt;\nCreate a file\n\n\nnano\nnano &lt;filename&gt;\nOpen Nano editor\n\n\nopen\nopen &lt;filename&gt;\nOpen a file in its default program\n\n\nmv\nmv &lt;filename&gt; &lt;filepath&gt;\nMove a file\n\n\nrm\nrm &lt;filename&gt;\nRemove (delete) a file\n\n\nman\nman &lt;command name&gt;\nManual for a command"
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html#new-years-r-solution",
    "href": "posts/2019-02-01-git-going-cl/index.html#new-years-r-solution",
    "title": "Git going: the command line",
    "section": "New Year’s R-solution",
    "text": "New Year’s R-solution\nPeople shared recently on Twitter their R goals for 2019 (see Maëlle Salmon’s post). Some of them referenced the use of Git and GitHub (see Jason Baik’s scraped dataset) for version-control of their projects.\nIt wasn’t that long ago that I began working with the command line, Git and GitHub. Now seems a good time to record what I learnt and maybe someone else will find it useful, or suggest better approaches.\nI’m splitting this into two posts: one introducing the basics of the command line and one about a basic Git workflow.\nIn these posts I assume that you:\n\nhave little-to-no understanding of the command line and Git commands, but some experience of coding\nwant to version control your R project\nintend to store your version-controlled files in the cloud with GitHub\nwant to interact with Git via the command line, rather than with a Graphical User Interface (GUI)\nare using a Mac and will access the command line via the Terminal application\n\nThese are relatively narrow constraints, but there will likely be some overlap with your particular configuration."
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html#the-command-line",
    "href": "posts/2019-02-01-git-going-cl/index.html#the-command-line",
    "title": "Git going: the command line",
    "section": "The command line",
    "text": "The command line\nOur goal is to start writing Git commands at the command line. Before we get to Git, we need to know what the command line is and get some experience of working there.\nYou probably interact with your computer primarily via a Graphical User Interface (GUI) composed of windows and visual representations of files and folders, and probably use a mouse to do this.\nBut there’s another way: you can write text commands directly to your computer to manipulate files and folders. One benefit is that you can save and re-execute commands in a script, which is much more reproducible than an unknown series of mouse-based interactions.\nWhat language are we going to use to communicate? We’ll be writing in our computer’s default scripting language, called bash. In this post we’ll be looking at a few basic commands.\n\nTerminal\nOpen the Terminal application (tap command and space to search for it). Terminal acts as a Command Line Interface (CLI): a place where you can chat with your machine.\nTerminal is a simple application where you type commands and execute them. You’re presented with the prompt, which is the form &lt;computer name&gt;:&lt;current directory&gt; &lt;user&gt;$. For example:\n\nbros:~ luigi$\n\nThe prompt will appear each time your computer is awaiting an instruction. You just need to write your command after the $ and hit Enter.\n\n\nWhere are we?\nThe commands we input are going to affect the current folder we’re in, or other files and folders relative to it.\nWhere are you when you start Terminal? The prompt helps you orient yourself: see the &lt;current directory&gt; bit of &lt;computer name&gt;:&lt;current directory&gt; &lt;user&gt;$.\nWhen you start, the prompt will show the tilde ~ by default. This is a shortcut symbol for your ‘home’ directory, which on a Mac will be set to the path /Users/&lt;your-username&gt;.\nWe can prove this by typing pwd at the prompt and hitting the Enter key.\n\nbros:~ luigi$ pwd\n/Users/luigi\n\nThis command prints the path for the current working directory. The folder we’re working in at any given moment is called ‘the working directory’.\n\n\nLook around with ls\nWe can look at the contents of our current working directory with ls, which means ‘list the files’.\n\nbros:~ luigi$ ls\nApplications  Desktop               Documents\nDownloads     Movies                Music\nPictures      plumbing-invoice.txt  \n\nIt holds some folders and a text file. This command is analogous to double-clicking a folder to open it and look inside.\n\n\nFlags\nWe can go one better: we can add ‘flags’ to the command. These are arguments prefixed with a hyphen that change the command’s default behaviour. We’re going to ask for all the files and folders (some are hidden!) with -a and also we’ll use -p to append the folders with a forward slash to make them more obvious.\n\nbros:~ luigi$ ls -a -p\n./\n../\n.luigi-profile\n.gameboy-horror-token\n.poltergust-key\nApplications/\nDesktop/\nDocuments/\nDownloads/\nMovies/\nMusic/\nPictures/\nplumbing-invoice.txt\n\nSo now can see all the files, including the hidden ones. Hidden files are often settings or profiles for various programs, or tokens stored for API access. One example of a hidden file for R is an .Rprofile.\nYou can see a description of the command and the list of available flags using the man command. For example, try man ls to learn about the list command. Sometimes the contents of the man file don’t fit the screen; keep hitting return until the bottom, or tap q to quit.\n\n\nNavigation with cd\nKnowing what’s in our working directory is useful because it helps us navigate. We can switch to another folder with the change directory command cd. We don’t have to type the full path, just the path relative to where we are. So instead of /Users/luigi/Documents, we can just type Documents. In fact, you can start typing and hit the tab key for autocompletion, assuming there’s no conflicts.\n\nbros:~ luigi$ cd Documents\nbros:Documents luigi$ pwd\n/Users/luigi/Documents\n\nSee how the prompt changed to say ‘Documents’? This is a handy reference in case we forget where we are. To return to the parent folder (i.e. back where we were), we can use cd .. to go up the file structure by one level.\n\n\nCreate/edit a file with touch/nano\nLet’s create a file in our current working directory with the touch command and then convince ourselves it’s there by listing the folder contents. I’m choosing to write a Markdown file with the .md extension, but you could just as easily have specified a .txt text file, for example.\n\nbros:Documents luigi$ touch  mushroom-top3.md\nbros:Documents luigi$ ls -p\ncoin-balance/         mushroom-top3.md  monty-mole-fanfic.txt\nmoustache-wiggle.gif  plumbing/         star-locations/\n\nOkay great, but the file is empty. How do we write something in it? Well, you could use open characters.md at the prompt to open the file in your default text editor (TextEdit or something), but we can also write text from within Terminal itself. Perhaps the simplest way is to use the Nano editor, which you can think of as a text editor built into Terminal.\nYou just need to type nano &lt;file name&gt;.\n\nbros:important-notes luigi$ nano mushroom-top3.md\n\nThe prompt will disappear and you’ll see a header saying File: characters.md. You’re now editing this file with Nano. Start typing.\n\n\n\nThe Nano text editor running from the command line\n\n\nNotice the options at the bottom of the window. We can exit Nano with ^ and x (‘control’ and ‘x’ keys). You’ll be asked if you want to save; hit Y for yes. Then you’ll be asked for a File name to write: characters.md. You can edit the name or hit Enter to confirm. The content is now saved.\n\n\nCreate a folder with mkdir\nAs well as files, the command mkdir &lt;folder name&gt; will create a new folder in our current working directory. We can switch to the new folder with cd and can again convince ourselves by looking at the  bit of the prompt, or by executing pwd to print our working directory.\n\nbros:Documents luigi$ mkdir new-games-starring-luigi\nbros:Documents luigi$ cd \nbros:new-games-starring-luigi luigi$ pwd\n/Users/luigi/Documents/important-notes\nbros:new-games-starring-luigi luigi$ ls\nbros:new-games-starring-luigi luigi$\n\nNote that ls on an empty directory will return nothing.\n\n\nMove your files with mv\nLet’s say we have a rogue text file in our home directory (remember this is denoted with the tilde, ~) that should really be in a subfolder of Documents/. The command mv allows us to move it. It’s like dragging and dropping a file from one folder into another.\nYou can specify this in the form mv &lt;filepath&gt; &lt;filepath&gt; to move files to and from any path, or navigate with cd to the folder containing the file and use the form mv &lt;file&gt; &lt;filepath&gt;. The code below does the latter, using cd and ls to move between folders and show where the file is.\n\nbros:Documents luigi$ cd ~\nbros:~ luigi$ ls\nApplications  Desktop               Documents\nDownloads     Movies                Music\nPictures      plumbing-invoice.txt\nbros:~ luigi$ mv plumbing-invoice.txt ~/Documents/important-notes/plumbing\nbros:~ luigi$ ls\nApplications  Desktop               Documents\nDownloads     Movies                Music\nPictures\nbros:~ luigi$ cd /Documents/plumbing/important-notes/plumbing\nbros:plumbing luigi$ ls\noveralls.jpg  plumbing-invoice.txt  tighten-warp-pipes.txt\n\n\n\nDelete with rm\nWhile we’re in this folder, we might want to prune our files a bit. You can remove files with the rm command.\n\nbros:plumbing luigi$ ls\noveralls.jpg  plumbing-invoice.txt  tighten-warp-pipes.txt\nbros:plumbing luigi$ rm tighten-warp-pipes.txt\nbros:plumbing luigi$ ls\noveralls.jpg  plumbing-invoice.txt"
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html#next-steps",
    "href": "posts/2019-02-01-git-going-cl/index.html#next-steps",
    "title": "Git going: the command line",
    "section": "Next steps",
    "text": "Next steps\nSo we should have enough knowledge now to navigate and manipulate folders. This will be extremely helpful when we start using Git commands at the command line in part two of the ‘Git going’ series."
  },
  {
    "objectID": "posts/2019-02-01-git-going-cl/index.html#environment",
    "href": "posts/2019-02-01-git-going-cl/index.html#environment",
    "title": "Git going: the command line",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-04 08:37:50 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-11-04-r-train-pkmn/index.html#tldr",
    "href": "posts/2018-11-04-r-train-pkmn/index.html#tldr",
    "title": "Teaching R with Pokémon Go data",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote and delivered a basic intro to R and RStudio for some colleagues of mine."
  },
  {
    "objectID": "posts/2018-11-04-r-train-pkmn/index.html#you-teach-me-and-ill-teach-you",
    "href": "posts/2018-11-04-r-train-pkmn/index.html#you-teach-me-and-ill-teach-you",
    "title": "Teaching R with Pokémon Go data",
    "section": "You teach me and I’ll teach you",
    "text": "You teach me and I’ll teach you\nI wrote in a recent post about some training materials I wrote for teaching R Markdown.\nNow I’m sharing another thing I made: Beginner R and RStudio Training (featuring Pokémon!). It’s an introduction to R, RStudio, R Projects, directory structure and the tidyverse. It uses Pokémon Go1 data that I collected myself.2\nYou can:\n\nvisit the page where the training is hosted\nlook at the source on GitHub\naccess a ‘follow along’ R script prepared by a colleague\n\nIt’s pretty rudimentary in content and design but it got the job done. I’m unlikely to update it any time soon. Feel free to use all of it, parts of it, or even fork it on GitHub and improve it."
  },
  {
    "objectID": "posts/2018-11-04-r-train-pkmn/index.html#other-materials",
    "href": "posts/2018-11-04-r-train-pkmn/index.html#other-materials",
    "title": "Teaching R with Pokémon Go data",
    "section": "Other materials",
    "text": "Other materials\nWhy didn’t I just use materials that are already out there? Well, I find it easier to teach material that I know well and that’s particularly true for things I’ve written myself. Also I couldn’t find any Pokémon-themed guides, so it was obviously inevitable.\nBelow are some other training materials to consider. I’m certain some of these will be out of date over time, or better things will emerge, but I’m unlikely to come back and update this post in the meantime.\n\nStarting with R and RStudio\n\nSoftware Carpentry’s Programming with R\nSwirl teaches you R interactively, from within RStudio itself\nFurther information about R Projects is available from the RStudio Support pages\nStarting data analysis/wrangling with R: Things I wish I’d been told by Stian Håklev\nBasics of ‘tidy’ data and the ‘tidyverse’ of packages\n\n\n\nGoing further\n\nData wrangling, exploration, and analysis with R from STAT 545 at the Uni of British Columbia\nOnline learning from RStudio: R Programming, Shiny, R Markdown and Data Science\nAn exhaustive Quora question with links to resources\n\n\n\nData Science in R\n\nAn Introduction to Statistical and Data Sciences via R by ModernDive\nR for Data Science and exercise solutions\n\n\n\nGetting help\n\nRStudio cheat sheets, including help with {readr}, {dplyr} and {ggplot2}\nOften it helps to produce a small reproducible example (a ‘reprex’) of your code if you run into trouble\nGetting help with R page of resources from RStudio\nExplore questions and answers tagged as r on StackOverflow"
  },
  {
    "objectID": "posts/2018-11-04-r-train-pkmn/index.html#environment",
    "href": "posts/2018-11-04-r-train-pkmn/index.html#environment",
    "title": "Teaching R with Pokémon Go data",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-07 23:00:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-11-04-r-train-pkmn/index.html#footnotes",
    "href": "posts/2018-11-04-r-train-pkmn/index.html#footnotes",
    "title": "Teaching R with Pokémon Go data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdd me as a friend on Pokémon Go. Friend code: 9572 6464 0472.↩︎\nThe data are available in my ‘draytasets’ GitHub repository and in the pkmn_go function in my {dray} package.↩︎"
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#tldr",
    "href": "posts/2021-08-10-dehex/index.html#tldr",
    "title": "Read a hex colour code with {dehex}",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote an R package, {dehex}, that helps you learn to ‘read’ a hex colour code by eye according to David DeSandro’s method. Check out his mindblowing talk."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#hue-are-you",
    "href": "posts/2021-08-10-dehex/index.html#hue-are-you",
    "title": "Read a hex colour code with {dehex}",
    "section": "Hue are you?",
    "text": "Hue are you?\nHex codes are used in computing to encode a colour as a succinct six-digit alphanumeric string, like #F4D82A.\nThese codes are written in hexadecimal (hence ‘hex’): they can take the characters 0 to 9 and A to F, which encodes 16 possible values. This encodes 16 million colours total, which are easy for computers to store and interpret.\nEach pair of characters basically encodes red, green and blue. For example, the code #FF000 is ‘red’. It uses the highest of these hex values, ‘F’, in both of the ‘red’ positions, while the green and blue pairs are zero.\nThat’s easy enough to decipher, but what about #8ACD52 or #C0FFEE?1 You could copy these into a tool that returns colour information (many search engines can do this now) but they often return a sample and not the colour’s name.\nI’m red-green colourblind and have difficulty identifying and talking about colours, so that’s not always helpful."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#the-desandro-method",
    "href": "posts/2021-08-10-dehex/index.html#the-desandro-method",
    "title": "Read a hex colour code with {dehex}",
    "section": "The DeSandro Method",
    "text": "The DeSandro Method\nDavid DeSandro of Metafizzy gave a talk at the dotCSS conference in 2018 about his superpower: ‘reading’ a hex colour code by eye.2\nHis talk is comprehensive and has excellent visuals. I strongly recommend that you watch his explanation if you find this topic interesting. You can also find the slides and a great written explanation on his blog. I cannot do justice here to such a powerful thought technology.\nIn short, it’s possible to look at a hex code like #F2D359 and get the rough hue, saturation and lightness of the colour it encodes, which you can speak as an English phrase like ‘light washed yellow’. David, too, is colourblind and has found success with his method.\nThis post isn’t about colour theory and I’m definitely not an expert, but the point of the method is that you don’t need to be one."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#introducing-dehex",
    "href": "posts/2021-08-10-dehex/index.html#introducing-dehex",
    "title": "Read a hex colour code with {dehex}",
    "section": "Introducing {dehex}",
    "text": "Introducing {dehex}\n\n\n\nThis is a hex logo, but it has a white background.\n\n\nRight, so I’ve made a small R package called {dehex} that you can use to:\n\nTrain yourself to read hex codes with the DeSandro Method\nReturn a rough English phrase for a given hex code\n\nAll from your R console.\nThe package is on GitHub and you can install with the help of {remotes}.\n\nremotes::install_github(\"matt-dray/dehex\")\n\nThe reason for the name should be obvious: you’re ‘dehexing’, i.e. converting from hex. But also I like the connotation of removing a ‘hex’ as in a spell. The colour is cursed; it’s trapped behind a code.\nUsual warnings: the package needs a refactor, there’s probably some bugs, but it works for me. Drop an issue or PR in the GitHub repo with any ideas or suggestions.\n\nCheat codes\nYou are thinking:\n\nUgh, this sounds like effort, just tell me what colour my hex code is\n\nSo I’m going to show you immediately how to retrieve an English phrase and a colour sample for a given hex code. Probably this is the most useful bit of the package for users who don’t want to become a hex mentat.3\nSince we’re ‘solving’ the hex code, the function is called dh_solve().4 It outputs a text string.\n\ndehex::dh_solve(\"#F2D359\")\n\n[1] \"light washed yellow\"\n\n\nIf you set swatch to TRUE, then you’ll get a plot filled with that colour as well.\n\ndehex::dh_solve(\"#F2D359\", swatch = TRUE)\n\n\n\n\n[1] \"light washed yellow\"\n\n\nHow lovely.\n\n Note\nI later noticed that the package {ColorNameR} exists, which has the express purpose of taking a colour code and returning a name for that colour.\n\n\n\nLearning is fun\nFor the more adventurous, you can use {dehex} to learn how to read a hex code with DeSandro’s method from your R console.\nThere’s five steps:\n\nSimplify from a six- to a three-digit hex code\nCreate a bar chart from the RGB values encoded by the short hex\nAssess hue (red, orange, violet, etc) from the chart’s ‘shape’\nAssess saturation (‘saturated’, ‘washed’, etc) from the range of the RGB values\nAssess lightness (‘dark’, ‘middle’, ‘light’) from the total of the RGB values\n\nI’ve incorporated each of these into {dehex}, plus a method for getting the answer.\n\n1. Three-digit code\nTurns out that the first value of each pair is the important one when determining colour, so you can shorten the standard six-digit hex code to just three digits.\nThat’s easy enough to do in your head, but the function dh_shorten() does it for you:\n\nhex_code &lt;- \"#F2D359\"\nshort_code &lt;- dehex::dh_shorten(hex_code)\nshort_code\n\n[1] \"#FD5\"\n\n\nAs it happens, the short code is still recognised by interpreters, but it’s often expanded double up each value to get back to six. So #FD5 is technically #FFDD55 rather than the original #F2D359, but that doesn’t really matter for our purposes.\n\n\n2. RGB graph\nThe values in the shortcode encode an ‘amount’ of red, green and blue. The lowest value is 0 and the highest is F, which is hexadecimal for 15. The higher the value, the more that’s ‘mixed’ into the final colour.\nYou can use dh_graph() to create this for you automatically. Rather than generate a plot though, we can just print a cute bar graph to the console. We’re only using it for reference, after all.\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = FALSE, adorn_l = FALSE\n)\n\n#FD5\nR ████████████████\nG ██████████████░░\nB ██████░░░░░░░░░░\n\n\nFor whatever reason, certain browsers struggle to render these graph outputs correctly in this blog post (seems fine in Firefox). In your console, the graphs will appear with neat ‘continuous’ bars instead of as individual blocks. Example in a dark theme editor:\n\nThe output is a horizontal chart showing the values of red (R), green (G) and blue (B) encoded by the hex short code. Each bar is made from 16 unicode block elements (i.e. 0 to 15), which are ‘filled’ to represent the amount of each colour.\nIf you’re using RStudio, this will print in colour, thanks to the {crayon} package (although you can turn it off with the argument crayon = FALSE). That looks like this using RStudio’s default light theme:\n\nOr, using a dark theme:\n\nPerhaps you’re wondering what the adorn_* arguments do in dh_graph(). They add extra information to the output that will help us in steps 3 to 5. I’ll switch these on as we go through those next steps.\n\n\n3. Hue\nFor our purposes, hue is basically a name we give a colour, like ‘orange’. We’re going to compare the ‘profile’ or ‘shape’ of our RGB graph to a number of others to determine which one most closely resembles ours.\nFor simplicity, we stick only to the primary, secondary and tertiary colours in the RGB colour system: red, green and blue; yellow, cyan, magenta; orange, chartreuse, aquamarine, azure, violet and rose. We also include a special case: grey.5\nThe {dehex} package has a built in guide that will print RGB graphs for each of these colours. Since this is a guide for hue, you pass the argument \"H\". I’ve hidden the output, since there are 13 graphs.\n\ndehex::dh_guide(\"H\")\n\n\n\nClick to expand the hue guides\n\n\n\nred\nR ████████████████ H 3\nG █░░░░░░░░░░░░░░░ H 1.5\nB █░░░░░░░░░░░░░░░ H 1.5\n\ngreen\nR █░░░░░░░░░░░░░░░ H 1.5\nG ████████████████ H 3\nB █░░░░░░░░░░░░░░░ H 1.5\n\nblue\nR █░░░░░░░░░░░░░░░ H 1.5\nG █░░░░░░░░░░░░░░░ H 1.5\nB ████████████████ H 3\n\nyellow\nR ████████████████ H 2.5\nG ████████████████ H 2.5\nB █░░░░░░░░░░░░░░░ H 1\n\ncyan\nR █░░░░░░░░░░░░░░░ H 1\nG ████████████████ H 2.5\nB ████████████████ H 2.5\n\nmagenta\nR ████████████████ H 2.5\nG █░░░░░░░░░░░░░░░ H 1\nB ████████████████ H 2.5\n\norange\nR ████████████████ H 3\nG █████████░░░░░░░ H 2\nB █░░░░░░░░░░░░░░░ H 1\n\nchartreuse\nR █████████░░░░░░░ H 2\nG ████████████████ H 3\nB █░░░░░░░░░░░░░░░ H 1\n\naquamarine\nR █░░░░░░░░░░░░░░░ H 1\nG ████████████████ H 3\nB █████████░░░░░░░ H 2\n\nazure\nR █░░░░░░░░░░░░░░░ H 1\nG █████████░░░░░░░ H 2\nB ████████████████ H 3\n\nviolet\nR █████████░░░░░░░ H 2\nG █░░░░░░░░░░░░░░░ H 1\nB ████████████████ H 3\n\nrose\nR ████████████████ H 3\nG █░░░░░░░░░░░░░░░ H 1\nB █████████░░░░░░░ H 2\n\ngrey\nR █████████░░░░░░░ H 2\nG █████████░░░░░░░ H 2\nB █████████░░░░░░░ H 2\n\n\n\nYou can see that I’ve added a value to the end of each bar, which represents the ranking of the RGB values. This follows the logic of the rank() function in base R: 1 is smallest, 3 is largest and ties are the average of the shared ranks. However, I’ve increased the tolerance for ties.6\nWhich of the graphs in the hue guide most closely resemble our colour?\nYou might be able to see by eye that it’s probably yellow, but we look at our graph again but this time with adorn_h set to TRUE (the default).\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = TRUE, adorn_s = FALSE, adorn_l = FALSE\n)\n\n#FD5\nR ████████████████ H 2.5\nG ██████████████░░ H 2.5\nB ██████░░░░░░░░░░ H 1\n\n\nSo, we have an RGB hue ranking of 2.5-2.5-1, which indeed matches the ‘yellow’ ranks in the guide, even if the RGB values are not exactly the same.\nI admit this step is quite clunky and it doesn’t help that there’s so many plots to compare against. It’s easier I think when you have a colour wheel arrangement to look at, like in DeSandro’s talk. Remember: with {dehex}’s help, you just need to look at the ranking values at the end of each bar.\n\n\n4. Saturation\nNow we repeat the process for saturation. This time we’re going to compare the range of RGB values. This is easier because there’s only three (‘saturated’, ‘washed’ and ‘muted’) plus grey (i.e. zero range).\nThis time we pass \"S\" for the saturation guide:\n\ndehex::dh_guide(\"S\")\n\n\n\nClick to expand the saturation guides\n\n\n\nsaturated\nR ████████████████\nG █████████░░░░░░░\nB █░░░░░░░░░░░░░░░\nS ████████████████\n\nwashed\nR █████████████░░░\nG █████████░░░░░░░\nB ████░░░░░░░░░░░░\nS ░░░██████████░░░\n\nmuted\nR ██████████░░░░░░\nG █████████░░░░░░░\nB ███████░░░░░░░░░\nS ░░░░░░████░░░░░░\n\ngrey\nR █████████░░░░░░░\nG █████████░░░░░░░\nB █████████░░░░░░░\nS ░░░░░░░░█░░░░░░░\n\n\n\nThis time there’s an additional bar for saturation, labelled ‘S’, that indicates the range of RGB values covered by each level of saturation. We can compare the saturation of our colour with the adorn_s argument set to TRUE.\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = TRUE, adorn_l = FALSE\n)\n\n#FD5\nR ████████████████\nG ██████████████░░\nB ██████░░░░░░░░░░\nS ░░░░░███████████\n\n\nSo, that’s roughly the range of the ‘washed’ category of saturation.\n\n\n5. Lightness\nFinally, we do the same for the lightness of the colour (‘light’, ‘middle’ and ‘dark’. You can total up the values, where higher values are lighter, but I’ve chosen to mark the mean value in {dehex} because I think it’s easier to interpret from the graph format.\nProvide \"L\" for lightness to the dh_guide() function:\n\ndehex::dh_guide(\"L\")\n\n\n\nClick to expand the lightness guides\n\n\n\nlight\nR ████████████████\nG ███████████████░\nB ██████████████░░\nL ░░░░░░░░░░░░░░█░\n\nmiddle\nR ██████████░░░░░░\nG █████████░░░░░░░\nB ████████░░░░░░░░\nL ░░░░░░░░█░░░░░░░\n\ndark\nR ████░░░░░░░░░░░░\nG ███░░░░░░░░░░░░░\nB ██░░░░░░░░░░░░░░\nL ░░█░░░░░░░░░░░░░\n\n\n\nAnd again, here’s the chart for our colour showing a column for lightness:\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = FALSE, adorn_l = TRUE\n)\n\n#FD5\nR ████████████████\nG ██████████████░░\nB ██████░░░░░░░░░░\nL ░░░░░░░░░░░█░░░░\n\n\nYep, slightly on the higher end, so it’s a lighter colour.\n\n\nSolution\nIf you followed these steps, you’ll have seen that #F2D359 is roughly ‘light washed yellow’.\nSo, {dehex} can therefore be used as a ‘training device’ to guide you through this process.\nThe idea is that you remember the hue shapes (relatively hard because there’s lots), the saturation ranges (i.e. wider range means more saturated) and lightness averages (i.e. higher is lighter) from the guides and compare your colour to those.\nYou can check your answer (or cheat, of course) by using dh_solve(). I showed this earlier in the post, but it also has the option to see all the matching charts for hue, saturation and lightness:\n\ndehex::dh_solve(hex_code, graphs = TRUE)\n\ninput code: #FD5\nR ████████████████ H 2.5\nG ██████████████░░ H 2.5\nB ██████░░░░░░░░░░ H 1\nS ░░░░░███████████\nL ░░░░░░░░░░░█░░░░\n\nhue: yellow\nR ████████████████ H 2.5\nG ████████████████ H 2.5\nB █░░░░░░░░░░░░░░░ H 1\n\nsaturation: washed\nR █████████████░░░\nG █████████░░░░░░░\nB ████░░░░░░░░░░░░\nS ░░░██████████░░░\n\nlightness: light\nR ████████████████\nG ███████████████░\nB ██████████████░░\nL ░░░░░░░░░░░░░░█░\n\n\n[1] \"light washed yellow\"\n\n\nHere you can see the selected guides that best matched the input.\n\n\n\nTest yourself\nIf you’re really serious about this, you’ll want to practice with random hex codes, of course. Lucky for you I’ve included a function that will generate them.\nSee if you can work out what this colour is using the guides and method above and then check your answer in the details block below.\n\nset.seed(2021)\nrando_hex &lt;- dehex::dh_random()\nrando_hex\n\n[1] \"#76EA7C\"\n\n\n\n\nClick here for the solution\n\n\ndehex::dh_solve(rando_hex, swatch = TRUE, graphs = TRUE)\n\n\n\n\ninput code: #7E7\nR ████████░░░░░░░░ H 1.5\nG ███████████████░ H 3\nB ████████░░░░░░░░ H 1.5\nS ░░░░░░░████████░\nL ░░░░░░░░░█░░░░░░\n\nhue: green\nR █░░░░░░░░░░░░░░░ H 1.5\nG ████████████████ H 3\nB █░░░░░░░░░░░░░░░ H 1.5\n\nsaturation: washed\nR █████████████░░░\nG █████████░░░░░░░\nB ████░░░░░░░░░░░░\nS ░░░██████████░░░\n\nlightness: middle\nR ██████████░░░░░░\nG █████████░░░░░░░\nB ████████░░░░░░░░\nL ░░░░░░░░█░░░░░░░\n\n\n[1] \"middle washed green\"\n\n\n\nDid you get it right?"
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#dream-of-colourfornication",
    "href": "posts/2021-08-10-dehex/index.html#dream-of-colourfornication",
    "title": "Read a hex colour code with {dehex}",
    "section": "Dream of colourfornication",
    "text": "Dream of colourfornication\nAs ever, this package and post are a Showerthought That Became Real (possible tagline for this blog); something to fill my free time.\nAt very least I’ve got a better idea of identifying hex-encoded colours without looking them up and getting confused when presented with an unnamed block of colour that my deuteronopic eyes can’t understand.\nI’m developing a Shiny app to make this more of an interactive tool that you can use without even needing access to R. I can’t promise it’ll be ready any time soon.\nAnyway, go and watch/read David DeSandro’s materials and do drop an issue or PR in the {dehex} GitHub repo if you have any contributions."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#environment",
    "href": "posts/2021-08-10-dehex/index.html#environment",
    "title": "Read a hex colour code with {dehex}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 10:05:44 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.41         fontawesome_0.5.2\n [5] magrittr_2.0.3    knitr_1.45        htmltools_0.5.6.1 rmarkdown_2.25   \n [9] lifecycle_1.0.4   cli_3.6.2         grid_4.3.1        vctrs_0.6.5      \n[13] compiler_4.3.1    purrr_1.0.2       rstudioapi_0.15.0 tools_4.3.1      \n[17] evaluate_0.23     yaml_2.3.8        dehex_0.1.2       crayon_1.5.2     \n[21] rlang_1.1.3       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#footnotes",
    "href": "posts/2021-08-10-dehex/index.html#footnotes",
    "title": "Read a hex colour code with {dehex}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYep, if you have 1 to 9 and A to F, you can ‘spell’ words with hex codes. See mikefc’s {colourmebad} package and Michael Sumner’s {hexwords}.↩︎\nI only found about this talk because of a tweet from Maëlle.↩︎\nI’m still waiting for the release of Villeneuve’s Dune.↩︎\nAll the functions in the package are prefixed with dh_, as in ‘dehex’, for easier autocomplete.↩︎\nAt time of writing, black and white will actually be returned as ‘dark’ and ‘light’ versions of grey.↩︎\nThere’s just too few combinations of RGB that result in selection of the hues that contain a tie, like red. I’ve considered RGB values within two units of each other as being a tie. I haven’t tested this thoroughly.↩︎"
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html",
    "href": "posts/2018-11-29-fontface-lithium/index.html",
    "title": "Change your {blogdown} fonts",
    "section": "",
    "text": "Lithium by Nirvana (via Giphy)"
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#tldr",
    "href": "posts/2018-11-29-fontface-lithium/index.html#tldr",
    "title": "Change your {blogdown} fonts",
    "section": "tl;dr",
    "text": "tl;dr\nWant to change the font for your {blogdown} site? I’ve been using this workflow:\n\nFind a font on the Google Fonts site\nSearch for the font name on the independent Google Web Fonts Helper\nDownload the zip file from the Helper, then copy all the files to static/fonts/ folder\nCopy the CSS from the Helper into your static/css/fonts.css file"
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#not-my-type",
    "href": "posts/2018-11-29-fontface-lithium/index.html#not-my-type",
    "title": "Change your {blogdown} fonts",
    "section": "Not my type",
    "text": "Not my type\nYou can change the default font face for your {blogdown} blog with freely-available files from Google Fonts.1\nIn this post I’ll show how you can do this with a bit of help from the Google Web Fonts Helper) by Mario Ranftl and by copy-pasting a small amount of CSS.\nI know this approach works for this blog’s base theme: Lithium for Hugo by Jonathan Rutheiser and edited for use with {blogdown} by Yihui Xie. Your mileage may vary.\nImportant note: do not adjust your site’s themes/ folder. We’ll be changing things in the static/ folder only.2"
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#storefont-window",
    "href": "posts/2018-11-29-fontface-lithium/index.html#storefont-window",
    "title": "Change your {blogdown} fonts",
    "section": "Storefont window",
    "text": "Storefont window\nThe Google Fonts catalog has nearly a thousand open-source fonts that you can use for your site. You can filter by categories (serif, sans-serif, monspace, etc), language and font properties (thickness, slant, etc) to find what you’re looking for. You can type a sentence and see how it looks in each font.\n\nClick a font name to go to a specimen page (example: Open Sans). Here you can see who designed it and a bit of information about the font itself. Of course, you also get a preview of the characters and styles. There’s even some suggestions for popular pairings.\n\nClicking the ‘select this font’ button will add a font to a ‘tray’ in the bottom right of the page, which is a bit like a shopping basket on a retail site. You can compare your selected fonts by clicking the ‘preview and share’ button in the upper right of the tray."
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#fontastic-helper",
    "href": "posts/2018-11-29-fontface-lithium/index.html#fontastic-helper",
    "title": "Change your {blogdown} fonts",
    "section": "Fontastic helper",
    "text": "Fontastic helper\nYou will hopefully have selected a font after countless hours perusing Google Fonts.\nRather than use Google Fonts to get the files, I recommend you use Google Web Fonts Helper). Why? It has a simple interface and gives you what you need in one screen (example: Open Sans).\nUse the search in the upper right and select your font. Sections 1 and 2 let you select character sets (cyrillic, latin, etc) and styles (regular, italic, etc). The default for many fonts is latin and regular, which is often what you want.\n\nNow we’re going to (1) get the font files and (2) make your site recognise them.\n\n1. Get fonts\n\nTo make the font files available to your site:\n\nGo to ‘4. Download files’ on the Helper font page\nClick the big blue button that says &lt;font-name&gt;.zip to download a zipped folder of the font files\nUnzip the file and copy all the files to the static/fonts/ folder of your site\n\nBy default, you’ll be copying across multiple file types (eot, svg, ttf, woff, woff2), which will give the best possible coverage for users of your site visitng from different browsers. You can, in theory, get away with using just the woff and woff2 files for modern browsers. Except there’s always an IE6 user somewhere.\n\n\n2. Recognise fonts\n\nIt’s not enough to just host the font files; we need to adjust some CSS. CSS files are basically style instructions that inform how HTML files (like our blog posts) should be rendered. You don’t need to be a CSS expert for this part.\nHere’s the steps in short:\n\nGo to ‘3. Copy CSS’ on the Helper font page\nCopy the CSS code\nPaste it into static/css/fonts/ (you can overwrite the CSS for any other fonts that you aren’t using)\nAdjust the font specifications for the body and title text, overwriting the font you’re replacing\n\nIt’s worth explaining those last couple of steps a bit more. The default static/css/fonts.css file for the Lithium theme looks like this:\n\n@font-face {\n  font-family: 'Merriweather';\n  font-style: normal;\n  font-weight: 400;\n  src: local('Merriweather'), local('Merriweather-Regular'),\n       url('../fonts/merriweather-v13-latin-regular.woff2') format('woff2'),\n       url('../fonts/merriweather-v13-latin-regular.woff') format('woff');\n}\n@font-face {\n  font-family: 'Lato';\n  font-style: normal;\n  font-weight: 400;\n  src: local('Lato Regular'), local('Lato-Regular'),\n       url('../fonts/lato-v11-latin-regular.woff2') format('woff2'),\n       url('../fonts/lato-v11-latin-regular.woff') format('woff');\n}\nbody {\n  font-family: 'Merriweather', serif;\n}\nh1, h2, h3, h4, h5, h6, .nav, .article-duration, .archive-item-link, .footer {\n  font-family: 'Lato', sans-serif;\n}\n\nThe @font-face sections declare the fonts and where the files are stored. There are two: Merriweather and Lato.\nThe last two sections (that don’t start with @) point out which fonts should be used in the main body text and for a number of other elements of the site, like headers (h1, etc) and the .footer. Other elements can be added.\nYou can also name more than one font for each site element. For example, the font-family: 'Merriweather', serif; of the the body {} section says that body text should be ‘Merriweather’ but should default to the host computer’s generic serif file if there’s a problem displaying Merriweather.\nSo, you can copy-paste over the @font-face sections with the CSS you copied from the Helper and then adjust the font-family names with your selections."
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#just-my-type",
    "href": "posts/2018-11-29-fontface-lithium/index.html#just-my-type",
    "title": "Change your {blogdown} fonts",
    "section": "Just my type",
    "text": "Just my type\nAs examples, you can see rostrum.blog’s static/fonts/ folder and static/css/fonts.css.\nCompare the CSS file for this site to the Lithium default above:\n\n/* roboto-regular - latin */\n@font-face {\n  font-family: 'Roboto';\n  font-style: normal;\n  font-weight: 400;\n  src: url('../fonts/roboto-v20-latin-regular.eot'); /* IE9 Compat Modes */\n  src: local('Roboto'), local('Roboto-Regular'),\n       url('../fonts/roboto-v20-latin-regular.eot?#iefix') format('embedded-opentype'), /* IE6-IE8 */\n       url('../fonts/roboto-v20-latin-regular.woff2') format('woff2'), /* Super Modern Browsers */\n       url('../fonts/roboto-v20-latin-regular.woff') format('woff'), /* Modern Browsers */\n       url('../fonts/roboto-v20-latin-regular.ttf') format('truetype'), /* Safari, Android, iOS */\n       url('../fonts/roboto-v20-latin-regular.svg#Roboto') format('svg'); /* Legacy iOS */\n}\n/* lekton-regular - latin */\n@font-face {\n  font-family: 'Lekton';\n  font-style: normal;\n  font-weight: 400;\n  src: url('../fonts/lekton-v10-latin-regular.eot'); /* IE9 Compat Modes */\n  src: local('Lekton'), local('Lekton-Regular'),\n       url('../fonts/lekton-v10-latin-regular.eot?#iefix') format('embedded-opentype'), /* IE6-IE8 */\n       url('../fonts/lekton-v10-latin-regular.woff2') format('woff2'), /* Super Modern Browsers */\n       url('../fonts/lekton-v10-latin-regular.woff') format('woff'), /* Modern Browsers */\n       url('../fonts/lekton-v10-latin-regular.ttf') format('truetype'), /* Safari, Android, iOS */\n       url('../fonts/lekton-v10-latin-regular.svg#Lekton') format('svg'); /* Legacy iOS */\n}\nbody {\n  font-family: 'Roboto', serif;\n}\nh1, h2, h3, h4, h5, h6, .nav, .article-duration, .archive-item-link, .article-meta, .footer {\n  font-family: 'Lekton', monospace;\n}\ncode {\n  font-family: 'Lekton', monospace;\n  font-size: 100%;\n}\n\nI chose the monospace Lekton for code and headers and the serif Roboto for the body. I like Lekton’s relative narrowness especially, along with its almost-square {braces}. Roboto is clean and clear, if ubiquitous.\nAs ever with these decisions, I may well change my mind again at some point."
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#environment",
    "href": "posts/2018-11-29-fontface-lithium/index.html#environment",
    "title": "Change your {blogdown} fonts",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-05 16:56:13 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-11-29-fontface-lithium/index.html#footnotes",
    "href": "posts/2018-11-29-fontface-lithium/index.html#footnotes",
    "title": "Change your {blogdown} fonts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee also sections 2.5.1 and 2.7 of the Blogdown book.↩︎\nJust ask Alison.↩︎"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html",
    "href": "posts/2023-01-06-remorse/index.html",
    "title": ".-././–/—/.-./…/.",
    "section": "",
    "text": "You may not believe it, but I am releasing this art under CC0."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#tldr",
    "href": "posts/2023-01-06-remorse/index.html#tldr",
    "title": ".-././–/—/.-./…/.",
    "section": "tl;dr",
    "text": "tl;dr\nOn a whim, I’ve written {remorse}: a tiny R package that converts text to Morse Code to audio."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "href": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "title": ".-././–/—/.-./…/.",
    "section": "Beat a dead morse",
    "text": "Beat a dead morse\nIn the last post I mentioned {sonify} for making R do little audible beeps and boops.\nIt reminded me of one (of many) unwritten micro-projects I’ve got kicking around in my brain: obviously you could use {sonify} to communicate Morse Code. And why not translate from text to Morse (and back) while you’re at it?1\nTo be honest this was a classic case of name-driven development (NDD): I thought {remorse} was a funny name for a package and worked backwards from there.\nObviously it says ‘Morse’ in the name, but also ‘remorse’ is usually what I feel after putting together a small pointless package; pointless-package existentialism (PPE) is something I have a track history with.\nBut of course, the true remorse is that I didn’t find the better package-name pun: {morseinspector}. But maybe that’s too long of a name and maybe non-Brits wouldn’t understand the reference. Maybe I’m thinking too hard.2"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "href": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "title": ".-././–/—/.-./…/.",
    "section": "Oh dit-dit-dahling",
    "text": "Oh dit-dit-dahling\nConsider this highly plausible scenario: it’s 20XX, the apocalypse has come, and the remaining humans on planet Earth communicate by Morse Code. For some reason.3\nWow, wouldn’t it be handy to have a text-to-Morse translator?\nWell friend, if you’ve managed to find an electronic thinking box in the apocalyptic barren wastelands (assuming electricity is still available (and the machine has R installed (and the {remorse} package was downloaded before the world’s internet cut out (and you know how to use R (and you don’t own a simpler, more portable Morse Code translation pamphlet))))), then you will have this incredible power at your fingertips.\nOr maybe you’d rather risk it? Pfft."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "href": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "title": ".-././–/—/.-./…/.",
    "section": "Use the Morse…",
    "text": "Use the Morse…\nThat’s an awful lot of build-up for a very simple package. Let’s take a look at what little it does.\nAs usual, {remorse} lives on GitHub4, so it can be downloaded with a little help from the typographically-adjacent {remotes} package:\n\ninstall.github(\"remotes\")\nremotes::install_github(\"matt-dray/remorse\")  # v0.1.1 here\n\nThat’ll install {sonify} as well, which is needed for the audio.\nRight so: text to Morse Code.\n\ntext_in &lt;- \"Ahoy pal!\"\nmorse &lt;- remorse::txt2morse(text_in)\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nSo each letter has been translated to the relevant string of ‘dits and dahs’ (‘dots’ and ‘dashes’) that make up Morse Code. I’ve used a period (.) and hyphen (-) to represent these in {remorse}, with forward slashes (/) between Morse groups that represent individual characters, and a space for the spaces between words.\nNote that not all characters can be converted to Morse Code. I did some research (Wikipedia) to discover the mappings from letters, numbers and punctuation to Morse Code. This information is used internally as a lookup, but is also exported in morse_lookup:\n\nremorse::morse_lookup\n\n       A        B        C        D        E        F        G        H \n    \".-\"   \"-...\"   \"-.-.\"    \"-..\"      \".\"   \"..-.\"    \"--.\"   \"....\" \n       I        J        K        L        M        N        O        P \n    \"..\"   \".---\"    \"-.-\"   \".-..\"     \"--\"     \"-.\"    \"---\"   \".--.\" \n       Q        R        S        T        U        V        W        X \n  \"--.-\"    \".-.\"    \"...\"      \"-\"    \"..-\"   \"...-\"    \".--\"   \"-..-\" \n       Y        Z        0        1        2        3        4        5 \n  \"-.--\"   \"--..\"  \"-----\"  \".----\"  \"..---\"  \"...--\"  \"....-\"  \".....\" \n       6        7        8        9        &        '        @        ) \n \"-....\"  \"--...\"  \"---..\"  \"----.\"  \".-...\" \".----.\" \".--.-.\" \"-.--.-\" \n       (        :        ,        =        !        .        -        * \n \"-.--.\" \"---...\" \"--..--\"  \"-...-\" \"-.-.--\" \".-.-.-\" \"-....-\"   \"-..-\" \n       +        \"        ?        /          \n \".-.-.\" \".-..-.\" \"..--..\"  \"-..-.\"      \" \" \n\n\nOf course, this means we can map backwards from Morse Code to letters, numbers and punctuation:\n\ntext_out &lt;- remorse::morse2txt(morse)\ntext_out\n\n[1] \"AHOY PAL!\"\n\n\nMorse Code has no sense of case, so it just converts it all to uppercase. Like you’re shouting; the most clear form of communication.\nSo, you can argue justifiably that txt2morse(\"yo\") |&gt; morse2txt() is just a worse version of toupper() that strips out certain unmappable characters.\nBut of course it does so much more. Well, one thing more. Let’s go from Morse to audio.\nFirst a reminder of the code from earlier:\n\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nAnd to generate audio you just:\n\nremorse::morse2sfx(morse)\n\nThe output sounds like this:\n\n\n\n\n\nWow. It plays audible dits (one ‘time unit’, default is dit_length = 0.05 in seconds), dahs (three), spaces between dits and dahs (one), spaces between Morse character groupings (three) and spaces between words (seven). Tell all your friends.\nSo, do I still feel remorse for writing {remorse}, even after demonstrating its incredible power? Yes. All I ask is that you think of me in those apocalyptic wastelands.\n\n Note\nI just realised you can turn Morse Code into… Morse Code. Mind blown.\n\nremorse::txt2morse(\"hi\") |&gt;\n  remorse::txt2morse()\n\n[1] \".-.-.-/.-.-.-/.-.-.-/.-.-.-/-..-./.-.-.-/.-.-.-\"\n\n\n‘Morsest Code’. Why? Absolutely.\nMaybe I’ve been watching too much Tom7 recently."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#environment",
    "href": "posts/2023-01-06-remorse/index.html#environment",
    "title": ".-././–/—/.-./…/.",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-13 14:07:22 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   remorse_0.1.1     rstudioapi_0.15.0\n [9] yaml_2.3.7        rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7   \n[13] xfun_0.39         digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1\n[17] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#footnotes",
    "href": "posts/2023-01-06-remorse/index.html#footnotes",
    "title": ".-././–/—/.-./…/.",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhich completes my hattrick of ‘R translation’ packages, I suppose. The {r2eng} package attempts to translate R code to spoken English and have your computer speak it out loud. The {dialga} package takes R code and translates it to cron strings and those cron strings to English.↩︎\nNot to mention that it’s a bad pun: the package doesn’t ‘inspect’ Morse; it translates it. Yep, definitely I’m thinking too hard about this.↩︎\nPersonally I’d rather see telegraphy make a comeback.↩︎\nWow, how edgy, maybe he’s had a bad run in with the CRAN maintainers, or perhaps he’s read the bit of the CRAN repository policy that says ‘a package’s contribution has to be non-trivial’ (whatever that means). Or he’s just lazy.↩︎"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html",
    "href": "posts/2023-03-03-getparsedata/index.html",
    "title": "I can’t be parsed, mate",
    "section": "",
    "text": "Image by Keith Johnston from Pixabay. Deep fried by Matt Dray.1"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#tldr",
    "href": "posts/2023-03-03-getparsedata/index.html#tldr",
    "title": "I can’t be parsed, mate",
    "section": "tl;dr",
    "text": "tl;dr\nR is capable of reading R code. Obviously. You can use getParseData(parse()) to see what’s going on. A very naive intro."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#at-an-imparse",
    "href": "posts/2023-03-03-getparsedata/index.html#at-an-imparse",
    "title": "I can’t be parsed, mate",
    "section": "At an imparse",
    "text": "At an imparse\nThere’s many things that delight me about R coding.2 One meta thing I like is the idea that R has to recognise the code that you give it as… R code.\nFor example, does x&lt;-1 mean ‘x is less than minus-one’? Hm, actually R recognises &lt;- as a ‘left-assignment operator’—a special ‘token’—that gives the name x the value of 1. Subtle, but important.\nAnother example: the tokens &lt;- and = have an equivalent role in x &lt;- 1 and x = 1. For style reasons, you’ll probably want to replace = with &lt;-.3 But don’t just ‘find and replace’ because = is context dependent. Consider:\n\nx = subset(mtcars, subset = carb == 8)\n\nHere, = is used to assign (=), to set a function argument (=) and as part of the equivalence operator (==). Oof.\nHow can a mere human understand this better?"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parsed-tense",
    "href": "posts/2023-03-03-getparsedata/index.html#parsed-tense",
    "title": "I can’t be parsed, mate",
    "section": "Parsed tense",
    "text": "Parsed tense\nThe cool (‘cool’) thing is that R gives you tools to be able to see the world as R sees it.\nThis is sometimes called ‘static code analysis’, in that you can interrogate the code for syntax errors before it executes. Packages like {lintr} can even help tidy up (‘lint’) your code by adjusting or replacing the tokens.4\nI’ve used this approach before to:\n\ncreate the {r2eng} package, which matches tokens against words so an expression can be translated to English (e.g. &lt;- is matched to the word ‘gets’)\nwrite an RStudio addin that auto-labels closing parentheses with the name of the function they belong to (known cutely as a ‘biscuit’)\nidentify and destroy files that contain equals assignment (x = 1), rather than the superior assignment arrow (x &lt;- 1)\n\nHow might you tinker about with this yourself? Read on for a quickstart."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parse-the-parcel",
    "href": "posts/2023-03-03-getparsedata/index.html#parse-the-parcel",
    "title": "I can’t be parsed, mate",
    "section": "Parse the parcel",
    "text": "Parse the parcel\nI’ll talk about two main functions: parse() and getParseData(), which are both part of base R.\nYou can pass a string of R code to parse() for it to be recognised as an ‘expression’. Let’s use the equals-rich subset() example from above.\n\ncode_str &lt;- \"x = subset(mtcars, subset = carb == 8)\"\ncode_expr &lt;- parse(text = code_str)\ncode_expr\n\nexpression(x = subset(mtcars, subset = carb == 8))\n\nclass(code_expr)\n\n[1] \"expression\"\n\n\nSo the string is recognised as R code at this point, which will allow us to break it down into its individual tokens. You could jump ahead here and just eval()uate this expression object.\n\neval(code_expr)\nx\n\n              mpg cyl disp  hp drat   wt qsec vs am gear carb\nMaserati Bora  15   8  301 335 3.54 3.57 14.6  0  1    5    8\n\n\nAs a result, the dataframe x is now in our environment and, as expected, contains only rows of the mtcars that have 8 carburetors.5\nSo we have the power to delay code execution, like some kind of wizard. Jeepers! That’s great, but now lets pick apart the frozen expression into its constituent tokens. This is where getParseData() comes in.\nThe function takes an expression object as the input and returns a dataframe with one token per row and several columns of handy information related to positioning and the relatedness between the tokens.\nFor now I’m going to simplify the output to show only the units of text that have been recognised as tokens, along with the name that R gives to each token under the hood (e.g. &lt;- is recognised as LEFT_ASSIGN).6\n\ncode_parsed &lt;- getParseData(parse(text = code_str, keep.source = TRUE))\ncode_parsed[code_parsed$text != \"\", c(\"text\", \"token\")]\n\n     text                token\n1       x               SYMBOL\n2       =            EQ_ASSIGN\n5  subset SYMBOL_FUNCTION_CALL\n6       (                  '('\n8  mtcars               SYMBOL\n9       ,                  ','\n14 subset           SYMBOL_SUB\n15      =               EQ_SUB\n16   carb               SYMBOL\n17     ==                   EQ\n19      8            NUM_CONST\n21      )                  ')'\n\n\nOh neato, so you can see = is indeed recognised as the token EQ_ASSIGN (‘equals assign’), = as EQ_SUB (equals in the context of supplying function arguments) and == as in EQ (the equivalence operator).\nIf you’re wondering, the keep.source = TRUE bit was needed to encourage parse() to return its output, which is a necessary step within this non-interactive blog post."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parseltongue",
    "href": "posts/2023-03-03-getparsedata/index.html#parseltongue",
    "title": "I can’t be parsed, mate",
    "section": "Parseltongue",
    "text": "Parseltongue\nWant to take a look at the tokens in a given string of R code yourself? You can use this little function that contains parse() and getParseData() and returns you the simplified dataframe I showed above if simplify = TRUE, otherwise it gives the full read out.7\n\nparse_out &lt;- function(string, simplify = TRUE) {\n  p &lt;- parse(text = string, keep.source = TRUE)\n  pd &lt;- getParseData(p)\n  if (simplify) {\n    keep_cols &lt;- c(\"token\", \"text\")\n    pd &lt;- pd[pd$text != \"\", keep_cols]\n  }\n  pd\n}\n\nSo you could use it like:\n\nparse_out(\n  \"mean(CO2[CO2$Plant == 'Qn1', CO2$uptake]) -&gt; mean_uptake\"\n)\n\n                  token        text\n1  SYMBOL_FUNCTION_CALL        mean\n2                   '('           (\n4                SYMBOL         CO2\n5                   '['           [\n7                SYMBOL         CO2\n8                   '$'           $\n10               SYMBOL       Plant\n12                   EQ          ==\n13            STR_CONST       'Qn1'\n14                  ','           ,\n20               SYMBOL         CO2\n21                  '$'           $\n23               SYMBOL      uptake\n25                  ']'           ]\n30                  ')'           )\n35         RIGHT_ASSIGN          -&gt;\n36               SYMBOL mean_uptake\n\n\n\n Note\nSince I wrote this post, it’s become possible to include editable R blocks in a rendered Quarto document, which can be run in the browser thanks to WebR(!). I’ve made a quick demo and post so you can play around with a simplified version of the parsing function above."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#lateral-parse",
    "href": "posts/2023-03-03-getparsedata/index.html#lateral-parse",
    "title": "I can’t be parsed, mate",
    "section": "Lateral parse",
    "text": "Lateral parse\nI’ll leave you with another interesting thing that shows you the inner workings of R, which you might not realise as you run your code. We can look at how the code is actually executed, not just the tokens that it’s composed of.\nConsider how the {magrittr} pipe %&gt;% is used. Here I’ve slightly adjusted the input to filter for 6 and 8 carburetors; you’ll see why in a second.\n\nparse_out(\"mtcars %&gt;% subset(carb %in% c(6, 8))\")\n\n                  token   text\n1                SYMBOL mtcars\n2               SPECIAL    %&gt;%\n4  SYMBOL_FUNCTION_CALL subset\n5                   '('      (\n7                SYMBOL   carb\n8               SPECIAL   %in%\n10 SYMBOL_FUNCTION_CALL      c\n11                  '('      (\n13            NUM_CONST      6\n15                  ','      ,\n19            NUM_CONST      8\n21                  ')'      )\n26                  ')'      )\n\n\nOkay yeah, %&gt;% is recognised as a token called SPECIAL between the left-hand side of mtcars and the right-hand side of subset(carb %in% c(6, 8)). Notice also that %in% is also recognised as SPECIAL.\nIn fact, this is how R recognises ‘infix operators’ that are bound by percent symbols. This is some special syntactical magic that lets you put the function name between two arguments. So x %&gt;% head is equivalent to `%&gt;%`(mtcars, head). Perhaps SPECIAL instead of a more specific name because infix operators can be created on the fly?\nIf %&gt;% is SPECIAL, how do you think the base pipe is recognised in this simpler example?\n\nparse_out(\"mtcars |&gt; head()\")\n\n                 token   text\n1               SYMBOL mtcars\n2                 PIPE     |&gt;\n4 SYMBOL_FUNCTION_CALL   head\n5                  '('      (\n7                  ')'      )\n\n\nNot that surprising: it’s recognised as PIPE and not a SPECIAL, since it’s a proper base R token in its own right (as of R v4.1) .\nOkay, so we’ve seen how R parses these tokens, what about how it actually executes the code? One way to see this is to look at an ‘abstract syntax tree’ with the {lobstr} package.8 A ‘tree’ to show the nested structure of code and variables and so on.\n\nlibrary(lobstr)    # install from CRAN\nlibrary(magrittr)  # install from CRAN\nast(mtcars %&gt;% head())\n\n█─`%&gt;%` \n├─mtcars \n└─█─head \n\n\nYeah, like I said: x %&gt;% head() is ultimately executed by R like a normal function (block symbol in the output from ast() above), in the form `%&gt;%`(mtcars, head). You can see how the `%&gt;%` is a parent to mtcars and head() below it.\nSo the same happens for the base pipe, right?\n\nast(mtcars |&gt; head())\n\n█─head \n└─mtcars \n\n\nSurprise! mtcars |&gt; head is not executed like `|&gt;`(mtcars, head). It’s literally executed like head(mtcars). The base pipe is so special because it’s baked right into the R source code as a separate type of token that is recognised to have a job distinct from a basic SPECIAL. This should make it a little faster to run compared to %&gt;% as well."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parse-away",
    "href": "posts/2023-03-03-getparsedata/index.html#parse-away",
    "title": "I can’t be parsed, mate",
    "section": "Parse away",
    "text": "Parse away\nWell, ‘cool’ I guess. Now it’s up to you: you can either parse on this knowledge, or leave it in the parsed.9"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#environment",
    "href": "posts/2023-03-03-getparsedata/index.html#environment",
    "title": "I can’t be parsed, mate",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:08:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 lobstr_1.1.2  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[13] yaml_2.3.7        crayon_1.5.2      rlang_1.1.1       jsonlite_1.8.7   \n[17] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#footnotes",
    "href": "posts/2023-03-03-getparsedata/index.html#footnotes",
    "title": "I can’t be parsed, mate",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou too can use R to deep fry a meme.↩︎\nThings that I’m sure are quite trivial to gatekeepers. I learnt minimal amounts of R to help me wrangle ecological data and ‘do statistics’. I’m not a computer scientist, nor was I trained as a programmer.↩︎\nOf course, I’m not mentioning right assignment (-&gt;) here, nor the plucky upstart of down-asignment, which is certain to be the future for assignment in R.↩︎\nYou may also enjoy a post by Kun Ren about how this approach is useful for static analysis in the {languageserver} package, which is a handy download for using R in VS Code.↩︎\nNot carbohydrates. ‘Non-car people’ should take a look at the ‘Format’ section of ?mtcars. I mean, drat means ‘rear axle ratio’, what?↩︎\nYou can see a list of these with English translations in Winston Chang’s GitHub copy of R’s source code. So NUM_CONST is ‘numeric constant’, for example.↩︎\nAn exercise for the reader is to alter this function to accept an R script file rather than a string (hint: parse() takes a file argument).↩︎\nA package with one of my favourite names and hex logos. The ‘str’ is from ‘structure’, as in ‘the structure of code’. The logo is a lobster snipping apart the ‘lob’ from ‘str’ text. I mean, *(lobster) chef’s kiss* on that one. 🦞↩︎\nYeah, I’m hoping you didn’t read this far. Obviously I didn’t know how to end the post, sorry.↩︎"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve (finally) ported the londonmapbot Twitter bot to Mastodon. Like a mammoth rising from the ashes."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "TOOOOOOOT",
    "text": "TOOOOOOOT\nTwitter is burning to the ground, yada yada.\nFor example, it appears that the free API tier will disappear soon. Soon like… today. Oh wait, maybe not yet?1 Cool customer communication, brah.\nAnyway, this news will obviously devastate contributors and fans of the mapbotverse Twitter list.\nYou don’t know what the mapbotverse is? Oof. It’s a collection of 25 bot accounts that take some inspiration from my londonmapbot account, which uses GitHub Actions and the {rtweet} package to tweet on schedule a picture of a random spot in Greater London via MapBox.\nAnd so it’s time to update the code behind londonmapbot so that it continues to post to Twitter for as long as it survives. But also so that it lives on by posting to Mastodon via the {rtoot} package as well.\nMastowhat? Something something federated Twitter-replacement sort of thing. Tooooooot tooooooot.\n\n Note\nI finally turned off londonmapbot on Twitter in May 2023."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Masto-do or masto-do-not",
    "text": "Masto-do or masto-do-not\nI’m slightly behind the curve on this: Matt Kerlogue has already ported his narrowbotR (‘narrow boater’) bot from Twitter to Mastodon and written about it.\nThe fix was fairly rudimentary in the end, thanks to standing on the shoulder of mammoths. Particularly the creators of the {rtoot} R package.\n{rtoot} lets you interact with the Mastodon API. It’s a sort-of analogue to the {rtweet} package for the Twitter API. {rtoot} was stood up very quickly by David Schoch (with co-author Chung-hong Chan and contributor Johannes Gruber) when it became clear that Mastodon was becoming the platform-du-jour for nerds.\n\nSet up Mastodon\nIt’s easier to set yourself up with API access for Mastodon compared to Twitter:\n\nSet up a Mastodon account on the dedicated bot server botsin.space (londonmapbot is @londonmapbot@botsin.space).2\nInstall the {rtoot} package.\nAuthorise yourself with Mastodon and get an API token.\n???\nAbsolutely do not profit whatsoever.\n\nSteps 2 and 3 look like this:\n\ninstall.packages(\"rtoot\")  # on CRAN\n\nrtoot::auth_setup(\n  instance  = \"botsin.space\",  # the Mastodon server the account is on\n  type      = \"user\",          # i.e. for posting from R\n  name      = \"londonmapbot\",  # name the token file\n  clipboard = TRUE             # copy to clipboard\n)\n\nThis process interrupts you to interactively authorise the {rtoot} package in a browser window and copy a big long code to a dialogue box that appears in your R session.\n\nIt’ll then return:\nToken of type \"user\" for instance botsin.space is valid\nToken (in environment variable format) has been copied to clipboard.\n&lt;mastodon bearer token&gt; for instance: botsin.space of type: user \nI pasted this API token to a safe place and also stored it as a GitHub repo secret in the londonmapbot GitHub repo so it could be referred to while the GitHub Action was running.\n\n\nPost to Mastodon\nNow we can use the post_toot() function to… toot a post. Publish a toot? Entoot a noote. It requires a token argument that takes a special ‘bearer token’ with a particular structure that’s not too dissimilar from what the rtweet package expects of the object passed to its own token function.\nAside: token setup is made easy in {rtweet} thanks to the rtweet_bot() function, to which you can pass your API keys and secrets. It’s a little less obvious in {rtoot}, which was initially built with the intention of running API calls from your personal machine, so you could just store your keys in your .Renviron file or whatever.\nBut actually you can just mimic how {rtweet} accepts the token. To do this, I did not use my brain at all and simply ripped-off Matt Kerlogue’s post.3 My updated R script now contains this:4\n\nmastodon_token &lt;- structure(\n  list(  # it's just a list\n    bearer   = Sys.getenv(\"RTOOT_DEFAULT_TOKEN\"),\n    type     = \"user\",  # i.e. to post from R\n    instance = \"botsin.space\"  # the server\n  ),\n  class = \"rtoot_bearer\"  # special token class\n)\n\nWhere RTOOT_DEFAULT_TOKEN is that API token from earlier, which is required for accessing Mastodon. As mentioned, it’s stored as a GitHub repo secret and called into the GitHub Action environment thanks to the ${{ secrets.RTOOT_DEFAULT_TOKEN }} call in the YAML file.\nThis object can be passed quite happily to the post_toot() function.\n\nrtoot::post_toot(\n  status   = latlon_details,\n  media    = temp_file,\n  alt_text = alt_text,\n  token    = mastodon_token\n)\n\nWhere the status (body text), media (image file) and alt_text (alternative text for the image) objects have been generated already (see the R script for details).\nThis is then executed on schedule according to the cron string5 specified in the YAML file (currently twice a day at 0914 and 1714) to publish stuff like this:\n\n\n\nAwait Twitter implosion\nI want the bot to keep posting to Twitter for as long as I’m allowed to. In other words, we should try to post a tweet and catch any error silently, without disrupting the GitHub Action. So naturally I wrapped post_tweet() in a tryCatch() statement, yes? No, actually I used purrr::possibly() instead.\nWhy? Basically because the syntax is easy to remember, lol. And what difference does it make to have one extra dependency for this task? To use it, you wrap your function of interest in possibly() and then it can fail without erroring-out the whole function.\n\npossibly_post_tweet &lt;- purrr::possibly(rtweet::post_tweet)\n\npossibly_post_tweet(\n  status         = latlon_details,\n  media          = temp_file,\n  media_alt_text = alt_text,\n  token          = twitter_token\n)\n\n\n\nFiddle while Frisco burns\nWhile I was messing about with the londonmapbot code, I made a few things in the repo a bit more generic. For example, I altered the name of the GitHub Actions YAML file and the R script to be called ‘post-image’. This is more descriptive and it removes the need for someone forking the repo to have to manually change the name away from ‘londonmapbot’. You are so welcome."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Parp",
    "text": "Parp\nFarewell, until the next time we have to port londonmapot to another API-enabled microblogging site. We’ve had bird- and mammal-themed sites; my prediction is that the next site will be called ‘Seacucumber’ and we won’t ‘tweet’ or ‘toot’, we’ll ‘eviscerate’.6\nI mean, inverting one’s stomach is a daily reaction on Twitter anyway, amirite?"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:09:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#footnotes",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#footnotes",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHappy Valentine’s to all my fellow monetisable users.↩︎\nDuring this process you have to explain why you want to set up the account. Don’t forget to say the magic word in your application, wink wink.↩︎\n‘Matt hivemind prerogative’, this is called.↩︎\nKerlogue influenced the {rtoot} team to update the package to handle environmental variables, but I could not get this to work, alas.↩︎\nDid I mention I made the R package {dialga} to convert R to cron to English, lol?↩︎\nI fact-checked myself on Wikipedia and read this brand new sentence: ‘[evisceration] causes the wall of the cloaca to tear and the anus to gape.’↩︎"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html",
    "href": "posts/2021-01-04-safar6/index.html",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "",
    "text": "An original Nintendo Game Boy playing Pokémon… if you squint."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#tldr",
    "href": "posts/2021-01-04-safar6/index.html#tldr",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "tl;dr",
    "text": "tl;dr\nI created the R package {safar6}, which contains an R6-class object to simulate a simplified, text-based version of the Safari Zone sub-area from Pokémon Blue.\nI also made the ‘gamelad’ RStudio theme to mimic the screen of a pukey-green original Game Boy. Pair with a blocky monospace font like VT323 for that 8-bit experience.1"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#kangaskhan-you-believe-it",
    "href": "posts/2021-01-04-safar6/index.html#kangaskhan-you-believe-it",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Kangaskhan you believe it?",
    "text": "Kangaskhan you believe it?\nDid you know you can play games in R?\nI particularly like the text adventures The Secret of Landusia by Peter Prevos and Castle of R by Giora Simchoni\nThe latter uses object-oriented programming (OOP) for handling game elements, thanks to the {R6} package. So, a room in the castle is an R6-class object with specific fields (variables), like whether the door is open, and methods (functions) like openDoor() that can change the door state.\nThis is interesting because R is better known for being a function- rather than an object-oriented language. You can learn more about OOP in R from Hadley Wickham’s Advanced R book and more about the R6-class from the {R6} website."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#a-chansey-to-learn",
    "href": "posts/2021-01-04-safar6/index.html#a-chansey-to-learn",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "A Chansey to learn",
    "text": "A Chansey to learn\nI wrote a post about using {R6} to simulate an Automatic Bell Dispenser (an ATM, basically) from Nintendo’s Animal Crossing: New Horizons (2020) game. Fields include savings and methods include withdraw(), for example.\nObviously my next step was to use {R6} for a game, but I wanted to start small. The original Pokémon2 games were effectively text adventures with some random-number generation and simple calculations going on in the background. Would it be possible to simulate some aspects of it?\n\n\n\nWould you like to join the hunt?’ Via bulbapedia.bulbagarden.net.\n\n\nLuckily, there’s an in-game sub-area that’s self-contained and much simpler than the mechanics in the rest of the world. In the The Safari Zone you’re only allowed to take 500 steps, you can only use a special type of ball to capture wild Pokémon (of which you only have 30) and you can’t reduce a wild Pokémon’s health (hit points, HP).\nSo I went ahead and wrote an R6-class object to mimic the Safari Zone and bundled it in the {safar6} R package.3"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#a-quick-tauros-of-the-game",
    "href": "posts/2021-01-04-safar6/index.html#a-quick-tauros-of-the-game",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "A quick Tauros of the game",
    "text": "A quick Tauros of the game\nYou can install the package from GitHub. Loading the package provides a reminder of how to play.\n\n# Install first the the {remotes} package\nremotes::install_github(\"matt-dray/safar6\")\n\nlibrary(safar6)\n\n# {safar6}\n# Start game: x &lt;- safari_zone$new()\n# Take a step: x$step()\nBasically, the package contains an R6-class object SafariZone, which you initialise like safari_zone$new(). Make sure to assign a name to it (x in these examples). This starts a routine with some text from the game and some interactive elements. Sometimes you’ll be prompted for a response; type a value and hit enter to make a choice.\nHere’s the opening sequence, which asks for your name and invites you to play:\n\nx &lt;- safari_zone$new()\n\nFirst, what is your name?\n------------------------\nNEW NAME (1)\nBLUE (2)\nGARY (3)\nJOHN (4)\n------------------------\nSelect 1, 2, 3 or 4:\n&gt; 1\nYour name: \n&gt; THEW\nWelcome to the SAFARI ZONE!\nFor just P500, you can catch all the\nPokemon you want in the park!\nWould you like to join the hunt?\n------------------------\nMONEY: P500\nYES (1) or NO (2)\n------------------------\nSelect 1 or 2: \n&gt; 1\nThat'll be P500 please!\n------------------------\nMONEY: P0\n------------------------\nWe only use a special POKe BALL here.\nTHEW received 30 SAFARI BALLs!\nWe'll call you on the PA when you run out of time or SAFARI BALLs!\nYou can then ‘move around’ by using the step() method on your SafariZone object. This method does most of the hard work in {safar6}, since it contains all the logic required for a wild Pokémon encounter.\nThe underlying values and calculations in step() are all true to the original game. That includes the encounter rate, which is less than 1, so you’ll likely have to step() a number of times before you find a Pokémon.\nFor convenience, the step method prints the number of steps remaining:\n\nx$step()\n\n499/500\nEach step is treated as though you’re walking through the tall grass, which is where you find wild Pokémon. There’s a weighted chance of encountering certain Pokémon at certain levels, but each wild Pokémon also has (hidden) randomised individual variation in its stats (HP, speed, etc) that impact your ability to catch it.\nHere’s an encounter:\n\nx$step()\n\n497/500\nWild VENONAT L22 appeared!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \nAt the prompt, you can throw a Safari ball straight away to attempt a catch, or you can run away from the encounter. You can also influence the Pokémon’s state: throw a rock to raise the catch chance (but you’ll also increase the flee chance) or throw bait to reduce the chance of fleeing (but that’ll also decrease the catch chance).\nWild VENONAT L22 appeared!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 3\nTHEW threw a ROCK.\nWild VENONAT is angry!\nThe Pokémon will be angry or eating for one to five turns.\nWhen you throw a ball, the success of a capture attempt is determined by several factors, like the Pokémon’s HP, its level and its catch rate (possibly modified by rocks and bait). It may also run away given factors like its speed.\nTHEW threw a ROCK.\nWild VENONAT is angry!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 1\nTHEW used SAFARI BALL!\nWobble...\nDarn! The POKeMON broke free!\nYou may want to change your strategy. More rocks, or some bait? While it’s still angry, you could take advantage of its heightened catch rate by throwing another ball.\nWild VENONAT is angry!\n------------------------\nBALLx29 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 1\nTHEW used SAFARI BALL!\nWobble... Wobble... Wobble...\nAll right!\nVENONAT was caught!\nSuccess! You can choose to give your ‘captured friend’ a nickname.\n------------------------\nDo you want to give a nickname to VENONAT?\nYES (1) or NO (2)\n------------------------\nSelect 1 or 2:\n&gt; 1\nNickname: \n&gt; Tajiri\nTajiri was transferred to BILL's PC!\nTry to catch as many as you can before you run out of steps or balls. You can x$pause() the game at any point to see your remaining stats and you can check out x$bills_pc to see what you’ve captured4.\n\nx$pause()\n\n497/500\nBALLx28\nBILL's PC: 1\n\nx$bills_pc\n\n  nickname species level\n1   Tajiri VENONAT    22\nWhen the game is over, you’ll see an endscreen with your results.\n------------------------\nPA: Ding-dong!\nTime's up!\nPA: Your SAFARI GAME is over!\nDid you get a good haul?\nCome again!\n------------------------\nResult: 1 transferred to BILL's PC\n  nickname species level\n1   Tajiri VENONAT    22\nThe Safari Zone in the original game was pretty tricky. The Pokémon were flighty and it was especially hard to trap rare encounters like Chansey, Pinsir and Scyther.\nThe most captures I’ve made on a playthrough of {safar6} is three (!), so use that as a yardstick."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#exeggcute-ing-the-class",
    "href": "posts/2021-01-04-safar6/index.html#exeggcute-ing-the-class",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Exeggcute-ing the class",
    "text": "Exeggcute-ing the class\nI tried to keep things simple, so there’s a number of omissions compared to the original game. For example, there’s no visuals or sounds; I’ve simulated only the ‘Center’ hub area of the Safari Zone; you walk around as though you’re always in tall grass; you can’t fish or use different rod types; you’re restricted to the catch rates and Pokémon identities of the Blue game (not Red or Yellow, which are different).\nOn the flipside, I tried to maintain some subtle true-to-the-original elements. For example, you’ll be prompted to enter your name; you can nickname your Pokémon; there’s ‘wobble logic’ for deciding how many times the ball should shake before a capture; and the majority of the text is as it appears in the game. I’ve also made it so the text is progressively revealed, character by character.\n\n\n\nProgressive text reveal. Takes longer to print but is more authentic.\n\n\nIn particular, I’ve tried to keep the various hidden and non-hidden Pokémon stats and calculations true to Pokémon Blue. For example, I built in:\n\noriginal encounter rates, both for the Safari Zone and the wild Pokémon in it\nwild Pokémon base statistics and calculation of randomised individual values\ncatch rates based on factors like ball type and HP, and any modifications during the encounter\ntracking of ‘eating’ and ‘anger’ statuses and the effects on catch rates\nthe calculation for whether a wild Pokémon will flee\n\nThere’s no guarantee I’ve got these things completely right, but the gameplay appears similar to the original, so I think it’s close enough."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#disen-tangela-ing-game-mechanics",
    "href": "posts/2021-01-04-safar6/index.html#disen-tangela-ing-game-mechanics",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Disen-Tangela-ing game mechanics",
    "text": "Disen-Tangela-ing game mechanics\nInformation about game mechanics and values were relatively tricky to come by. The following resources were really important:\n\nBulbapedia is the Bible of Pokémon and hosts various stats and formulae\nThe Cave of Dragonflies has some excellent breakdowns of game mechanics, particularly in capture and Safari Zone logic\nthe Pokémon Slots website is a convenient lookup for base encounter rates for wild Pokémon by area\nthe pret/pokered GitHub repo contains a disassembly of the games, where you can see the raw game mechanics and stats5\n\nI later saw on YouTube some interesting attempts at building small text-based Pokémon games like {safar6}. For example, one in Python by Rylan Fowers6 and one for the TI-84 calculator (of course) by Aeri."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#dont-marowak-living-creatures",
    "href": "posts/2021-01-04-safar6/index.html#dont-marowak-living-creatures",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Don’t Marowak living creatures",
    "text": "Don’t Marowak living creatures\nObviously this is for fun and learning. Play at your own risk. Feel free to report any bugs (as in code problems, not bug-type Pokémon) as GitHub issues.\nAnd do not, I repeat, do not throw rocks at animals IRL."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#environment",
    "href": "posts/2021-01-04-safar6/index.html#environment",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 22:01:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] safar6_0.1.1\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#footnotes",
    "href": "posts/2021-01-04-safar6/index.html#footnotes",
    "title": "Play Pokémon’s Safari Zone in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRStudio only accepts monospace fonts, so the Press Start 2P font—which mimics Namco’s fonts of the 80s—sadly misses out because it’s a ‘display’ font.↩︎\nThe first generation of Pokémon games were developed for the Nintendo Game Boy by Game Freak and published by Nintendo. Pokémon as a property is owned by The Pokémon Company.↩︎\nYou know, like ‘safari’ and ‘R6’ mashed together?↩︎\n‘Bill’s PC’ is the original game’s in-game Pokémon-storage system. Yes, they’re stored on a computer. In particular, Bill’s computer. Don’t think about it too hard.↩︎\nIt’s interesting to see how the game actually worked. There’s a few investigations of this on YouTube: Shane Lee demonstrates how it works by editing the code (like making Mew a starter Pokémon) and booting it and TheHappieCat explains how Red and Blue were written in Assembly and maximised memory to an extreme degree.↩︎\nThis is what prompted me to include safar6:::cat_tw(), a function for progressive text reveal, in {safar6}.↩︎"
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#tldr",
    "href": "posts/2022-09-13-potato/index.html#tldr",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "tl;dr",
    "text": "tl;dr\nPlay an interactive version of ‘Potato’—a one-page halfling-themed role-playing game (RPG) by Oliver Darkshire (Twitter, Patreon)—in your R console with the {potato} package."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato",
    "href": "posts/2022-09-13-potato/index.html#potato",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato?",
    "text": "Potato?\nI’ve recently put together a GitHub repo to collect together a bunch of neat games that you can play. The twist? They were built using R.\nYes, R: ‘a FrEe SoFtWaRe EnViRoNmEnT fOr StAtIsTiCaL cOmPuTiNg AnD gRaPhIcS’.\nI think R is best suited to either text-based user-input games on the R console, or via a more dedicated interface, like Shiny.1\nIn this vein, Oliver Darkshire wrote an excellent ‘one-page role-playing game’ called Potato that seems ripe for plucking (well, I guess you ‘pull’ potatoes?) into an R implementation. A simple text interface; updating and tracking variables; clear win conditions. The basic desire to avoid action and simply tend to vegetables.\nSo… {potato}."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato-1",
    "href": "posts/2022-09-13-potato/index.html#potato-1",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato!",
    "text": "Potato!\nYou can install the {potato} package from GitHub thanks to {remotes}:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/potato\")\n\nYou start a game with:2\n\npotato::potato()\n\n--- POTATO ---\n\nA (one-page) RPG by Oliver Darkshire (@deathbybadger)\nThese and more at https://www.patreon.com/deathbybadger\n\nYou are a halfling, just trying to exist.\nMeanwhile, the dark lord rampages across the world.\nYou do not care about this. You are trying to farm potatoes.\nBecause what could a halfling possibly do about it anyway?\n\nKeep rolling until DESTINY, POTATO or ORC reach 10/10.\n\n- DESTINY: 0/10\n- POTATO:  0/10\n- ORC:     0/10\n- PAY:     1 POTATO to remove 1 ORC\n\nPress [ENTER] to roll... \nThe console will prompt you for input as you play. It’s basically luck-based die rolls, though you will have the chance to intervene with an option to hurl a certain number of precious potatoes at an orc to make it clear off.\nYou win when POTATO reaches 10. You lose when ORC reaches 10. You also… ‘don’t lose’… if DESTINY reaches 10.\nPlease see the one-page RPG that David put together and/or support him on Patreon if you like it or any of the other hilarious one-page RPGs that he’s made.\nI cannot stress enough that this is his work and all I’ve done is put it into an obscure format that literally three people might look at for a laugh."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato-2",
    "href": "posts/2022-09-13-potato/index.html#potato-2",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato…",
    "text": "Potato…\nI could just leave it there, but I think the interesting thing for R users are the various little methods required to make the ‘game’ function.\nTo display text to the user in the console, we can use cat() or message(). I kinda prefer message() because the user has more control over it in general, like suppressMessages() (which does what you think it does).\n\nmessage(\"Hello world!\")\n\nHello world!\nThere’s a subtlety in presentation too, which is that the two functions return text in different colours.\nThe game loop itself runs inside a repeat, which is maybe uncommon for some R users. We’re mostly used to for or while loops for iteration with a known set of things to iterate over, whereas repeat will keep going until we specify a break.\n\nrepeat {\n  \n  if (keep_going) {\n    do_something()\n  }\n  \n  if (!keep_going) {\n    break\n  }\n  \n}\n\nYou can imagine a scenario where keep_going is set to TRUE and some actions happen as a result; and that if it becomes FALSE then the game loop ends. In {potato}, we make sure to first print the current values of DESTINY, POTATO and ORC so the user sees them before the game continues or ends.\nWhat are DESTINY, POTATO and ORC? Before we initiate that repeat loop we can specify a bunch of starting values for some important scoring variables. Stylistically, it makes sense to use ALL CAPS for these (that’s how they were written in the original game, after all), but there’s also an old-school rule-of-thumb to specify variables this way in R code so you can more easily spot them in your code.\n\nDESTINY &lt;- 0L\nPOTATO  &lt;- 0L\nORC     &lt;- 0L\n\nin addition, we clearly need user input to decide what to do during the game. Most of the time, a user’s hand is forced and they need to roll. But sometimes they have the choice to remove an orc at the cost of one or more potatoes (depending on how the die falls).\nThis is a logical variable that we can keep track of, i.e. can the user pay (TRUE or FALSE)?\n\ncan_pay &lt;- FALSE\n\nif (COST &lt;= POTATO) {\n  can_pay &lt;- TRUE\n} else if (COST &gt; POTATO) {\n  can_pay &lt;- FALSE\n}\n\nIf the cost to yeet an orc is equal-to or less-than the number of potatoes, we can elect to make the payment. This is expressed in the options provided to the user on the command line.\nGiven the can_pay value, the user will get the option to either roll the die (FALSE):\n\nevent &lt;- readline(\n  \"Press [ENTER] to roll... \"\n)\n\nOr choose to roll the die or make the payment (TRUE):\n\nevent &lt;- readline(\n  \"Press [ENTER] to roll or [p] to pay 1 POTATO to remove 1 ORC... \"\n)\n\nBoth of which require user input that results in a value stored in the event object. Note that hitting Enter results in an empty string (\"\").\nDie-roll values pass through a series of if statements that are activated based on the number rolled. So if you roll 1 or 2, you’re In the garden...; if 3 or 4, you’ll get A knock on the door...; else the potato cost per orc-yeet increases by 1).\nA second roll is made automatically when in the garden or when a knock is heard. Here’s what happens if a 1 is rolled when in the garden:\n\nif (rolled_garden == 1L) {\n  \n  message(\n    paste(\n      rolled_garden_msg,\n      \"You happily root about all day in your garden.\"\n    )\n  )\n  \n  message(\"- Result: +1 POTATO\")\n  \n  POTATO &lt;- POTATO + 1L\n  \n}\n\nExcellent, the POTATO variable counter is increased by 1 in this case and confirmed to the user in a message(). The latest DESTINY, POTATO and ORC scores are then printed back to the user at the start of the next repeat loop.\nAnd then you just… keep potatoing."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato.",
    "href": "posts/2022-09-13-potato/index.html#potato.",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato.",
    "text": "Potato.\nOnce again, you can visit Oliver Darkshire on Twitter as @deathbybadger and support him on Patreon.\nYou can find the source code for {potato} on GitHub. Issues and pull requests welcome. Just make sure you can afford the charge of one potato to submit."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#environment",
    "href": "posts/2022-09-13-potato/index.html#environment",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-24 21:29:41 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#footnotes",
    "href": "posts/2022-09-13-potato/index.html#footnotes",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYeah, but have you seen the mind-boggling extent to which Mike Cheng (AKA mikefc, AKA coolbutuseless, AKA R legend) has gone to turn R into a proper game engine?↩︎\nPotayto, potahto, let’s call the whole thing off.↩︎"
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html",
    "href": "posts/2019-09-06-lithium-metadata/index.html",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "",
    "text": "Modifying lithium metal with heat (via Giphy)."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#tldr",
    "href": "posts/2019-09-06-lithium-metadata/index.html#tldr",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "tl;dr",
    "text": "tl;dr\nAdd author name, categories and tags to the posts of your Lithium-themed {blogdown} site. Might work for other themes.\n\n Note\nThis blog is no longer made with {blogdown}. It uses Quarto instead."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#lithium",
    "href": "posts/2019-09-06-lithium-metadata/index.html#lithium",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "Lithium",
    "text": "Lithium\nThis blog is generated using Yihui Xie’s {blogdown}, which is built on the Hugo framework.\nA number of site-wide themes have been ported for use with {blogdown}. This site uses the clean and simple Lithium theme by Jonathan Rutheiser, modified for {blogdown} by Yihui.\nThe Lithium template doesn’t display author names, categories and tags by default. I’ve been adding author names manually and the number of posts is large enough now that exploring categories and tags is worthwhile.\nI initially found it tricky to add these bits of metadata to each post, so I’m recording it here."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#yaml",
    "href": "posts/2019-09-06-lithium-metadata/index.html#yaml",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "YAML",
    "text": "YAML\nYou provide metadata for your posts in the YAML header (YAML is just some human-readable code often used for configuration). The information can then be extracted and presented on the front-end. The ‘Update Metadata’ option from the {blogdown} RStudio addin is useful for making changes to the YAML.\nHere’s the YAML for the post you’re reading currently:\n---\ntitle: '{blogdown}: add metadata to Lithium-themed posts'\nauthor: Matt Dray\ndate: 2019-09-06\ncategories:\n  - blog-meta\n  - code\nslug: lithium-metadata\ntags:\n  - blogdown\n  - hugo\n  - lithium\n  - r\n  - yihui\n---\nYou need to make sure the author, categories and tags elements are completed before they can be extracted and displayed on your posts.\nYou need to update the files that specify the layout of your site, but where are they? And how do you translate these YAML elements into parameters that are understood in those files?\n\nWhat’s missing where?\nThe basics of what you need to do is all laid out in the excellent blogdown: Creating Websites with R Markdown book by Yihui, Amber Thomas, Alison Hill.\nThe file describing the layout of your posts—the one you need to edit—is on this path: layouts/_default/single.html (see the default template).\nIt’s an HTML file, so has lots of things like &lt;h1 class=\"article-title\"&gt;. This is pretty classic HTML that declares a top-level header and a class that can be styled with CSS.\nBut what we really care about are the things that look like {{ .Title }}. The parameter names embraced in double-curly brackets refer to our YAML elements, but they don’t necessarily have the same name (title in YAML and .Title here, for example).\nSo &lt;h1 class=\"article-title\"&gt;{{ .Title }}&lt;/h1&gt; will return the title of the post as an HTML header that will be styled as the article-title class.\n\n\nModifications\nI hadn’t added the author name in the past because I wasn’t sure what the right parameter was. I found it in section 2.5.1 of the blogdown book: .Params.author.\nThis meant I could arrange some metadata at the top of my posts in the form Firstname Lastname / DD Mon YYY / X min read with the line {{ .Params.author }} / {{ .Date.Format \"02 Jan 2006\" }} / {{ .ReadingTime }} min read to get what I wanted.\nDisplaying categories and tags is trickier. It’s not just about finding the right parameters, but also involves looping through the categories and tags specified in each post’s YAML. Fortunately, the code is provided in section 2.5.2 of the blogdown book, under the bullet ‘Display categories and tags in a post if provided in its YAML’. It looks like this:\n&lt;p class=\"terms\"&gt;\n  {{ range $i := (slice \"categories\" \"tags\") }}\n  {{ with ($.Param $i) }}\n  {{ $i | title }}:\n  {{ range $k := . }}\n  &lt;a href='{{ relURL (print \"/\" $i \"/\" $k | urlize) }}'&gt;{{$k}}&lt;/a&gt;\n  {{ end }}\n  {{ end }}\n  {{ end }}\n&lt;/p&gt;\nI slid this into my single.html file with some trial and error, using a &lt;br&gt; linebreak tag to split the categories and tags onto two separate lines."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#side-by-side",
    "href": "posts/2019-09-06-lithium-metadata/index.html#side-by-side",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "Side by side",
    "text": "Side by side\n\nThe default\n\nThe default output for a Lithium-themed post is produced with the following single.html file:\n{{ partial \"header.html\" . }}\n\n&lt;main class=\"content\" role=\"main\"&gt;\n\n  &lt;article class=\"article\"&gt;\n    {{ if eq .Section \"post\" }}\n    &lt;span class=\"article-duration\"&gt;{{ .ReadingTime }} min read&lt;/span&gt;\n    {{ end }}\n\n    &lt;h1 class=\"article-title\"&gt;{{ .Title }}&lt;/h1&gt;\n\n    {{ if eq .Section \"post\" }}\n    &lt;span class=\"article-date\"&gt;{{ .Date.Format \"2006-01-02\" }}&lt;/span&gt;\n    {{ end }}\n\n    &lt;div class=\"article-content\"&gt;\n      {{ .Content }}\n    &lt;/div&gt;\n  &lt;/article&gt;\n\n  {{ partial \"disqus.html\" .}}\n\n&lt;/main&gt;\n\n{{ partial \"footer.html\" . }}\n\n\nModified\nBelow is what the updated posts look like. Note that I’ve also updated the styles and fonts as well as the layout. You can read a previous post about how to update the typeface.\n\nMy modifications to the Lithium layout in the layouts/_default/single.html file:\n{{ partial \"header.html\" . }}\n\n&lt;main class=\"content\" role=\"main\"&gt;\n\n    &lt;h1 class=\"article-title\"&gt;{{ .Title }}&lt;/h1&gt;\n\n    {{ if eq .Section \"post\" }}\n    &lt;span class=\"article-meta\"&gt;\n      {{ .Params.author }} / {{ .Date.Format \"02 Jan 2006\" }} / {{ .ReadingTime }} min read &lt;br&gt;\n      {{ range $i := (slice \"categories\" \"tags\") }}\n      {{ with ($.Param $i) }}\n      {{ $i | title }}:\n      {{ range $k := . }}\n      &lt;a href='{{ relURL (print \"/\" $i \"/\" $k | urlize) }}'&gt;{{ $k }}&lt;/a&gt;\n      {{ end }}&lt;br&gt;\n      {{ end }}\n      {{ end }}&lt;br&gt;\n    &lt;/span&gt;\n    \n    {{ end }}\n    \n    &lt;div class=\"article-content\"&gt;\n      {{ .Content }}\n    &lt;/div&gt;\n\n  {{ partial \"disqus.html\" .}}\n\n&lt;/main&gt;\n\n{{ partial \"footer.html\" . }}\nNote that I created the new class article-meta to control the styles for this metadata block."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#improvements",
    "href": "posts/2019-09-06-lithium-metadata/index.html#improvements",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "Improvements",
    "text": "Improvements\nLet me know if this is worth optimising. Like I say: it was trial and error, really.\nThanks to Maëlle Salmon for pointing out the correct filepath at which to edit the single.html file. I also recommend you check out Alison Hill’s tweet reminder of which {blogdown} folders you should and shouldn’t modify within."
  },
  {
    "objectID": "posts/2019-09-06-lithium-metadata/index.html#environment",
    "href": "posts/2019-09-06-lithium-metadata/index.html#environment",
    "title": "{blogdown}: add metadata to Lithium-themed posts",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-24 20:33:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html",
    "href": "posts/2022-09-07-earl22/index.html",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "",
    "text": "Please don’t sue me for my fan art, Microsoft."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#tldr",
    "href": "posts/2022-09-07-earl22/index.html#tldr",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "tl;dr",
    "text": "tl;dr\nI presented some slides at the EARL 2022 conference about {a11ytables}: an R package that helps automate the production of reproducible and accessible spreadsheets, with a focus on publication of government statistics."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#counting-sheets",
    "href": "posts/2022-09-07-earl22/index.html#counting-sheets",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Counting sheets",
    "text": "Counting sheets\nThe UK government publishes a lot of spreadsheets that contain statistical tables. Compared to each other—and to themselves over time—these files are often:\n\ninconsistent in structure (e.g. cover or contents sheets are missing)\ninconsistent in style (e.g. different fonts, different shorthand codes for suppressed values)\ninaccessible to users of assistive technology (e.g. they contain blank columns or unannounced footnotes)\n\nLuckily, the government’s Analysis Function released some excellent guidance for releasing statistics in spreadsheets, with particular attention to accessibility.\nThe government’s grassroots Reproducible Analytical Pipelines (RAP) movement is also growing at pace. RAP’s purpose is to overcome a legacy of fragmented point-and-click processes into code-driven end-to-end pipelines that improve speed, accuracy and reproducibility; including workflows that generate statistical spreadsheets for publication.\nIt will take time for these approaches to become 100% embedded across government, due to factors like the inevitable inertia that comes with trying to leave legacy processes behind.1\nHow can we grease the wheels?"
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#spreadsheet-socialism",
    "href": "posts/2022-09-07-earl22/index.html#spreadsheet-socialism",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Spreadsheet socialism",
    "text": "Spreadsheet socialism\nI work in a government team that publishes data2 and I wanted to make it easier for us to:\n\ngenerate spreadsheets via R (the most commonly used language here)\nbe able to reproduce outputs in future (i.e. we produce files monthly, quarterly, annually)\napply accessible styles and structure (so we don’t have to spend ages with checklists and point-and-click interfaces)\n\nFirst I looked for existing code-based solutions and found the Python package gptables, written by the Analysis Function Core Team. At the time, the package created spreadsheets in accordance with an older version of the best-practice guidance. There was no R-native solution either, though gptables could be accessed in R via {reticulate}.\nAs a result, I created {a11ytables}: an R package to generate spreadsheets that meet the latest best-practice guidance for releasing statistics in spreadsheets.\n\nIt can be downloaded from GitHub (currently v0.1), which also installs {openxlsx} (which does all the hard work of building a workbook) and {pillar} (for prettier printing).\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"co-analysis/a11ytables\")\nlibrary(a11ytables)\n\nDo submit issues or pull requests to the repo if you have ideas or solutions."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#easy-does-it",
    "href": "posts/2022-09-07-earl22/index.html#easy-does-it",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Easy does it",
    "text": "Easy does it\nA major aim of {a11ytables} is to make it easy for stats producers to more easily complete the last mile of their ‘data-in to spreadsheet-out’ pipeline. As such, the workflow is relatively simple and is composed of only three functions (arguments ignored for brevity):\n\ncreate_a11ytable() |&gt; \n  generate_workbook() |&gt;\n  openxlsx::saveWorkbook()\n\nBasically:\n\nPass information and data as arguments to create_a11ytable(), which creates a special a11ytables-class dataframe representation of your spreadsheet content\nPass that object to generate_workbook() to convert it to a Workbook-class object that applies the required structure and styling\nUse saveWorkbook() from the {openxlsx} package to write the spreadsheet output to an xlsx file\n\nI recommend that you read the vignettes and function documentation on the package website to better understand how to use {a11ytables} and to learn about its caveats3; I won’t go into depth in this post."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#over-easy-does-it",
    "href": "posts/2022-09-07-earl22/index.html#over-easy-does-it",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Over-easy does it",
    "text": "Over-easy does it\nI wrote some slides about the package and presented it at the EARL 2022 conference4 in London. Yes, to expose the package, but also to make a wider point about the general importance of reproducibility, accessibility and the power of reusable tools.\nYou can access the slides for my talk on the web, or find the source on GitHub.\nThe slides show an example of some tables published by the UK government—the latest UK egg statistics5—and walks through how they might be developed using {a11ytables}.\n\n\n\n\n\n\n\n\nI wrote the slides in Quarto and made heavy use of {quartostamp}—my package of Quarto helpers exposed as an RStudio Addin—which I wrote about recently. Click ‘settings’ in the hamburger menu (lower left) to go fullscreen, see presenter notes, or get a slide overview."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#environment",
    "href": "posts/2022-09-07-earl22/index.html#environment",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#footnotes",
    "href": "posts/2022-09-07-earl22/index.html#footnotes",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCheck out the excellent RAP strategy and Goldacre Review for how this might be achieved.↩︎\nThis blog and everything on it is personal and doesn’t represent government policy in any possible shape or form. Unless the Geospatial Commission needs me for drawing procedural dungeon maps, or whatever.↩︎\nNote that the package is not intended for creating perfectly accessible spreadsheets but will help with the bulk of the work needed. Users of the package should refer back to the main spreadsheet guidance or the spreadsheet accessibility checklist after using it to make sure nothing has been missed. Please email analysis.function@ons.gov.uk if you use the package so they can monitor its use and the outputs produced.↩︎\n‘Enterprise Applications of the R Language’. Long-time readers may remember that I spoke at EARL in 2018 about the {crosstalk} package, largely through the medium of memes.↩︎\nLong-time readers may remember that I’ve used this publication before to demonstrate the {drake} package for workflow reproducibility.↩︎"
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#tldr",
    "href": "posts/2021-12-30-gpx3d/index.html#tldr",
    "title": "Your workout route (in three dimensions!)",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R to extract coordinate and elevation data from a GPX file and then plot it as an interactive 3D object. I put some functions in the tiny R package {gpx3d} to help do this."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#elevate-to-accumulate",
    "href": "posts/2021-12-30-gpx3d/index.html#elevate-to-accumulate",
    "title": "Your workout route (in three dimensions!)",
    "section": "Elevate to accumulate",
    "text": "Elevate to accumulate\nI’ve seen recently on Twitter some people using Marcus Volz’s {strava} R package to create pleasing visualisations of their running routes as small-multiples.\nI don’t use Strava, but I downloaded my Apple Health data this week and it contained a folder of GPX files; one for each ‘workout’ activity recorded via my Apple Watch.1 GPX files are basically just a type of XML used for storing GPS-related activity.\nBut rather than try to emulate {strava}, I thought it might be ‘fun’ to incorporate the elevation data from a GPX as a third dimension. I’ve also had mikefc’s {ggrgl} package—‘a 3D extension to ggplot’—on my to-do list for a while now."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#an-alternate-dimension",
    "href": "posts/2021-12-30-gpx3d/index.html#an-alternate-dimension",
    "title": "Your workout route (in three dimensions!)",
    "section": "An alternate dimension",
    "text": "An alternate dimension\nCut to the chase: I made a tiny package called {gpx3d}. For now it does what I want it to do and it works on my machine.\nYou can download it from GitHub with help from the {remotes} package.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/gpx3d\")\n\nThere are a number of dependencies, including many that are not available on CRAN; see the README for {ggrgl} for details. You must also install XQuartz, if you haven’t already.\nThe package does two things and has two exported functions:\n\nextract_gpx3d() gets the data out of a GPX file (i.e. it reads a GPX file; parses the XML; extracts datetime, latitude, longitude and elevation; converts to sf-class; and calculates the distance covered)\nplot_gpx3d() plots the data as an interactive 3D object (i.e. it takes the output from extract_gpx3d(), generates a ‘3D ggplot’ using {ggrgl} and renders it as an interactive object to an external device)\n\nThere are also two demo datasets:\n\nsegment.gpx, a GPX file containing a shorter, edited version of the route used in this blogpost, which you can access with system.file(\"extdata\", \"segment.gpx\", package = \"gpx3d\") after installing the package\ngpx_segment, an sf-class data.frame that’s the result of using the extract_gpx3d() on the built-in segment.gpx file\n\nRead on for an explanation and examples.\n\nExtract\nThere are already functions that can help read GPX files into R, like gpx::read_gpx() and plotKML::readGPX(), but I decided to do it by hand with {xml2} to get a custom output format (and to practice handling XML).\nIn short, the extract_gpx3d() function uses read_xml() to read the GPX file, then as_list() to convert it to a deeply nested list. A little wrangling is then required to create a data.frame: datetime and elevation can be hoisted out of the list okay, but the longitude and latitude are actually extracted from the attributes.\nAfter this, the data.frame is converted to the ‘geography-aware’ sf-class.2 I’ve done this for two reasons: (1) the output object can be taken away and will play nicely with various {sf} functions, letting you create various maps and perform further processing, and (2) it allowed me to calculate the distance between each recorded point, which could be summed for total distance.\nTo use extract_gpx3d(), simply pass a path to a GPX file. I’ve chosen a 10 km run I took on Christmas morning,3 which I downloaded from Apple Health and stored locally.4\n\nfile &lt;- \"~/Documents/data/apple_health_export/workout-routes/route_2021-12-25_10.31am.gpx\"\nroute &lt;- gpx3d::extract_gpx3d(file)\nroute[2000:2004, ]\n\nSimple feature collection with 5 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0.559015 ymin: 50.85109 xmax: 0.559273 ymax: 50.85109\nGeodetic CRS:  WGS 84\n                    time      ele      lon      lat                  geometry\n2000 2021-12-25 09:13:29 8.406136 0.559273 50.85109 POINT (0.559273 50.85109)\n2001 2021-12-25 09:13:30 8.498508 0.559209 50.85109 POINT (0.559209 50.85109)\n2002 2021-12-25 09:13:31 8.599027 0.559144 50.85109 POINT (0.559144 50.85109)\n2003 2021-12-25 09:13:32 8.721706 0.559079 50.85109 POINT (0.559079 50.85109)\n2004 2021-12-25 09:13:34 8.858613 0.559015 50.85109 POINT (0.559015 50.85109)\n         distance\n2000 4.564465 [m]\n2001 4.494285 [m]\n2002 4.564465 [m]\n2003 4.564465 [m]\n2004 4.492909 [m]\n\n\nYou can see the rows are basically a measurement per second (time) of the coordinates (lon and lat) and elevation (ele), and that the sf-class metadata and geometry column are present, along with the distance in metres from the previous to current point.\nYou can take this dataset away and do other stuff with it, like create a lat-long plot of the route (below left), or the elevation over time (below right).\n\npar(mfrow = c(1, 2), mar = rep(0, 4))\nwith(route, plot(lon, lat, type = \"l\", axes = FALSE))\nwith(route, plot(time, ele, type = \"l\", axes = FALSE))\n\n\n\n\nIf you’re wondering about the little ‘tail’ in the bottom right of the route, I accidentally joined the back of a Parkrun, so quickly did a hairpin turn to escape. Except the Parkrun route is a ‘there-and-back’ course, so the confused stewards thought I was now in the lead with a pace of about two minutes per kilometre. Whoops!\nThe elevation plot is pretty dramatic: roughly, it goes downhill to a small plateau, down again to a flatter plateau, then the inevitable (steep!) climb. The lowest plateau is along the seafront, so basically sea level.\nBut boo! Only two dimensions? You can instead use the plotting function built in to {gpx3d} for something a bit more exciting.\n\n\nPlot\nAll the hard work of plotting is done primarily by {ggplot2} and {ggrgl}. The former is probably well-known to readers; the latter is an extension written by mikefc to introduce a third dimension to ggplot objects. In other words, you can extrude your plot along some third variable to generate a z-axis.\nThere’s a whole bunch of specialised 3D geoms in {ggrgl}. For my purposes, I wanted to extend a geom_path() line plot into the third dimension. This is achieved by adding a z argument to the aes() call of the geom_path_3d() function, where z is our elevation data.\nAnd so the plot_gpx3d() function in {gpx3d} renders the plot as an interactive 3D object with {rgl} to an external devoutrgl::rgldev() graphics device.5 You can then click and drag it with your mouse and use the scrollwheel to zoom. I’ve embedded a gif of the output at the top of this thread.6\n\ngpx3d::plot_gpx3d(route)\n\nYou can see why I chose this particular route for the demo; it really shows off the power of the elevation data. I ran anti-clockwise downhill to the seafront, where it was almost entirely flat, before running back up a relatively sharp ascent.\nMight have made a nice print if I’d been gifted a 3D printer for Christmas!\n\n Note\nI was originally able to embed the interactive 3D graphic in this post, but it failed to work when I ported this blog over to Quarto in 2023. Maybe I’ll try to fix it one day."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#a-romance-of-many-dimensions",
    "href": "posts/2021-12-30-gpx3d/index.html#a-romance-of-many-dimensions",
    "title": "Your workout route (in three dimensions!)",
    "section": "A romance of many dimensions",
    "text": "A romance of many dimensions\nI’ve made {gpx3d} entirely for my own amusement, so your kilometreage may vary. At this point I can’t make any guarantees about whether it will even work on your machine, but hopefully I’ll find time in future to make sure it does. It might also be nice to include more user options for adjusting the output so you aren’t stuck with ‘ggplot grey’ and the same defaults mikefc used in a vignette showing a {ggrgl} version of Minard’s famous visulisation of Napoleon’s march.7\nI’ll also be thinking about developing {gpx4d} and functions like geom_tesseract(), but I might need physics to catch up first."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#environment",
    "href": "posts/2021-12-30-gpx3d/index.html#environment",
    "title": "Your workout route (in three dimensions!)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-20 22:39:35 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] jsonlite_1.8.7     dplyr_1.1.2        compiler_4.3.1     tidyselect_1.2.0  \n [5] Rcpp_1.0.11        xml2_1.3.5         gpx3d_0.0.0.9002   yaml_2.3.7        \n [9] fastmap_1.1.1      R6_2.5.1           generics_0.1.3     classInt_0.4-9    \n[13] s2_1.1.4           sf_1.0-14          knitr_1.43.1       htmlwidgets_1.6.2 \n[17] tibble_3.2.1       units_0.8-2        DBI_1.1.3          pillar_1.9.0      \n[21] rlang_1.1.1        utf8_1.2.3         xfun_0.39          cli_3.6.1         \n[25] magrittr_2.0.3     class_7.3-22       wk_0.7.3           digest_0.6.33     \n[29] grid_4.3.1         rstudioapi_0.15.0  fontawesome_0.5.1  lifecycle_1.0.3   \n[33] vctrs_0.6.3        KernSmooth_2.23-22 proxy_0.4-27       evaluate_0.21     \n[37] glue_1.6.2         fansi_1.0.4        e1071_1.7-13       rmarkdown_2.23    \n[41] tools_4.3.1        pkgconfig_2.0.3    htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#footnotes",
    "href": "posts/2021-12-30-gpx3d/index.html#footnotes",
    "title": "Your workout route (in three dimensions!)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI wrote earlier in the year about wrangling my Nike Run Club data via Apple Health. It seems as though NRC doesn’t pass geographic information to Health, but now I also record my runs via the Workout app on the watch, which does regurgitate the geo-related data.↩︎\nOr you can return a simpler data.frame without the sf-class by passing sf_out = FALSE to extract_gpx3d().↩︎\nIn a place I do not live, so minimal opsec-leaking here.↩︎\nYou could try using the demo GPX file that’s included in the package, using file &lt;- system.file(\"extdata\", \"segment.gpx\", package = \"gpx3d\")↩︎\nNote that you can also set the argument route_only to TRUE to get rid of all the chart elements and leave behind the path only.↩︎\nI originally managed to embed the interactive object in the blog itself after peeking at mikefc’s vignettes for {ggrgl}, but this seemed to fail when I later tried to re-render the post. I’ve left the code I used to do this in the source of this post (in the hidden chunks labelled ‘plot-unused’ and ‘rglwidget-unused’) if you want to check it out yourself.↩︎\nI also realised later that Tyler Morgan-Wall already did something like this with {rayshader}. I should have guessed.↩︎"
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#tldr",
    "href": "posts/2021-10-03-squirrel/index.html#tldr",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "tl;dr",
    "text": "tl;dr\nI created the {ActionSquirrel} package. It contains an {R6}-powered playable game for the R console, which includes images (well, emoji) and sounds (thanks to the {sonify} package)."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#gamers",
    "href": "posts/2021-10-03-squirrel/index.html#gamers",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "GameRs",
    "text": "GameRs\nI’ve written before about the idea of games that you can play in R. For example, I replicated a text-based version of Pokemon Blue’s Safari Zone. This was made possible by using the {R6} package by Winston Chang, which provides an implementation of object-oriented programming (OOP) in R.\nAn R6 class has ‘fields’ (variables) and ‘methods’ (functions) that can adjust the field values. This means you can manipulate the state of the object over time. You can read more in the {R6} documentation or in Hadley Wickham’s Advanced R book.\nSo you could create a class with a field that provides the location of a character, then let the user apply a method to overwrite that location. If you print the ‘before’ and ‘after’ states, you’ll get the impression of movement for the character."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#winter-is-coming",
    "href": "posts/2021-10-03-squirrel/index.html#winter-is-coming",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Winter is coming",
    "text": "Winter is coming\nWith this in mind, I made a game and put it in the {ActionSquirrel} package. It’s pretty simple; consider it a concept.\nYou play as a squirrel in a woodland, hoarding nuts before winter sets in. You have to collect 8 nuts in 30 moves or you won’t survive. To make matters worse, there’s an owl on patrol that wants to eat you.\nThe package contains a single ‘ActionSquirrel’ class. It has fields for the location of game objects—emojis for a tree, a squirrel, an owl and a nut—on a grid.1 It has a method to move the squirrel around the grid, which also executes code to assesses and change other field states. For example, it can check how many moves have happened, can adjust the owl’s position and spawn a new nut after the last one was collected."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#demo",
    "href": "posts/2021-10-03-squirrel/index.html#demo",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Demo",
    "text": "Demo\nYou can install from GitHub.\n\ninstall.packages(\"remotes\")  # if not installed already\nremotes::install_github(\"matt-dray/ActionSquirrel\")\n\nNote that I’ve developed and tested this only in RStudio v1.4.1717 with R v4.1.1 running on macOS Big Sur. I think emoji rendering, console-clearing and the sound effects may not work on all platforms and setups.\nBasic instructions are printed when the package is attached.\n\nlibrary(ActionSquirrel)\n\nWelcome to {ActionSquirrel}!\n* New game: x &lt;- ActionSquirrel$new()\n* Move:     e.g. x$move('up')\n* Info:     x$pause()\n\n\n\nStart\nInitiate an object with the ActionSquirrel class by assigning ActionSquirrel$new() to a name (I’ll use x for demo purposes). This clears the console and generates a forest grid that contains the squirrel, a nut and an owl, along with tallies for moves and nuts collected.\n\nx &lt;- ActionSquirrel$new()\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌰 🌳 🌳 \n🌳 🌳 🌳 🐿 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 0 \nNuts: 0\n\n\nMethods are applied to your object with the dollar symbol accessor2 in the form object$method(). We can use the pause() method to get game instructions, for example.\n\nx$pause()\n\nP A U S E\n * Aim:       get eight nuts before winter (30 moves)\n * Move:      e.g. x$move('up')\n * Chain:     e.g. x$move('u')$move('r')\n * New game:  x &lt;- ActionSquirrel$new()\n * Info:      x$pause()\n * Source:    github.com/matt-dray/ActionSquirrel\n\n\n\n\nState\nTo understand a little more the mechanics of R6-classes, you could take a peek at the current state of the fields and methods by printing your ActionSquirrel-class object.\nIt isn’t necessary for gameplay purposes to see this information, but for learning purposes it provides a sort-of ‘meta’ view of the current game state. (It will also help you ‘hack’ the game, more on that later!)\n\nx\n\n&lt;ActionSquirrel&gt;\n  Public:\n    active: TRUE\n    clone: function (deep = FALSE) \n    initialize: function () \n    move: function (where = c(\"up\", \"down\", \"left\", \"right\")) \n    moves: 0\n    n_loc: 8\n    nuts: 0\n    o_loc: 17\n    overworld: 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌰 🌳 🌳 🌳 🌳 🌳 🐿 🌳 🌳 🦉 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳\n    pause: function () \n    s_loc: 14\n\n\nThe most relevant of these are the moves and nuts counts; the *_loc values that specify the location of the squirrel, owl and nut in the overworld vector; and the move() method for controlling the player.\n\n\nMove\nYou move the squirrel through the forest with the move() method. It has one argument, where, that takes the directions \"up\", \"down\", \"left\" and \"right\" (you can also just supply the first letter of the direction).\n\nx$move(\"up\")\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌰 🐿️ 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 1 \nNuts: 0\n\n\nCongratulations: your move tally has increased by one. You may also have noticed that the owl moved up one space as well; it moves one space vertically or horizontally, or stays still, with equal probability.\nI built in collision detection, so you can’t exceed the limits of the grid by trying to go left if you’re already on the leftmost edge, for example.\nNote that you can also take more than one move at a time (elite gamer tech) by ‘chaining’ methods, like x$move(\"up\")$move(\"left\"), but this is risky because you might collide with the owl.\nImportantly, the whole R console is cleared before the updated grid is printed. This gives an impression of animated graphics, since the console overwrites the previous state with the current state.\nNow to collect the nut.\n\nx$move(\"left\")\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🐿️ 🌳 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌰 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 2 \nNuts: 1\n\n\nCongratulations, your nut tally has increased by one and a new nut has spawned in a random location. Collect at least eight nuts, or you won’t survive winter.\n\n\nOwl\nYou’ll get a game over if the owl eats you (i.e. you occupy the same spot). So if you move left and the owl happens to move up…\n\nx$move(\"left\")\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 💀 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \n🌰 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 3 \nNuts: 1\nY O U   D I E D ! \nThe owl ate you.\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nThe location of your death is marked with a skull and you’ll get a game over with information about what happened. At this point, the active field of the class is set to FALSE, which prevents you from moving again.\n\n\n\nDefinitely it’s harder than Dark Souls.\n\n\n\n\nWinter\nAfter 30 turns the game will end because you’ve reached winter. You’ll get a victory screen if you collected 8 nuts, otherwise a failure screen.\nAside: {R6} allows for ‘public’ and ‘private’ fields and methods. I’ve used public methods for the ActionSquirrel class, so that users can see the contents and state of the class and manipulate them. I think this is good for learning purposes.\nIt also means that we can ‘hack’ the game to the end state by overwriting the number of nuts and moves remaining! First, a victory after having collected eight nuts or more:\n\nx &lt;- ActionSquirrel$new()\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌰 🌳 🌳 \n🌳 🌳 🌳 🐿 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 0 \nNuts: 0\n\nx$moves &lt;- 29\nx$nuts &lt;- 10\nx$move()\n\n\f🐿️ 💤 🌰 🌰 🌰 \n🌰 🌰 🌰 🌰 🌰 \n🌰 🌰 🎄 ⛄ 🎄 \n🌨 ⛄ 🎄 ⛄ 🎄 \n⛄ ⛄ 🌨 🎄 🌨 \nMoves: 30 \nNuts: 10\nY O U   S U R V I V E D ! \nSufficient winter nut cache!\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nOur little squirrel friend is hibernating with the nut cache nearby. Meanwhile, the signs of winter fill the rest of the grid. Your success is confirmed in a printed statement.\nAnd what if we end the game with an insufficient nut cache?\n\nx &lt;- ActionSquirrel$new()  # start new game\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌰 🌳 🌳 \n🌳 🌳 🌳 🐿 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 0 \nNuts: 0\n\nx$moves &lt;- 29\nx$nuts &lt;- 4\nx$move()\n\n\f🐿️ 💀 🌰 🌰 🌰 \n🌰 ❌ ❌ ❌ ❌ \n🎄 🎄 🌨 🎄 ⛄ \n🎄 ⛄ 🎄 ⛄ 🎄 \n⛄ 🎄 🌨 ⛄ ⛄ \nMoves: 30 \nNuts: 4\nY O U   D I E D ! \nInsufficient winter nut cache!\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nOh dear.\n\n\nSFX\nSo we’ve got a player character, an enemy, collectibles, a goal and ‘animated’ visuals. The only thing missing is audio.\nLuckily, you can force your computer to make noise with the {sonify} package. I’ve used it before in this blog to represent COVID-19 data in audio form. For {ActionSquirrel}, I used it to make short, simple beeps to indicate a move, nut capture, collision with the edge of the grid, a win and a death. Here’s what those sound like, respectively:\n\n\n\n\n\nThe death sound is a flatline, because of course it is."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#r6-7-8",
    "href": "posts/2021-10-03-squirrel/index.html#r6-7-8",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "R6, 7, 8",
    "text": "R6, 7, 8\nSo, give it a go. What’s your high score? How guilty did you feel when the squirrel died?\nThere’s lots of ways this could be improved. Maybe the owl could have ‘AI’ that encourages it to move towards the player or nut. Maybe there could be another enemy with different movement patterns. I welcome any bug reports or suggestions in the GitHub repo for {ActionSquirrel}, or maybe you can fork it and make it better.\nThis post completes my R6 OOP hattrick alongside posts on Animal Crossing and Pokémon. Next time I might move onto {R7}, a new package for OOP in R that’s being coordinated and developed in the open by the R Consortium."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#environment",
    "href": "posts/2021-10-03-squirrel/index.html#environment",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-11 23:43:35 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ActionSquirrel_0.1.0\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     R6_2.5.1          signal_0.7-7      fastmap_1.1.1    \n [5] sonify_0.0-1      xfun_0.39         knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    tuneR_1.4.4       cli_3.6.1         compiler_4.3.1   \n[13] rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2 MASS_7.3-60"
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#footnotes",
    "href": "posts/2021-10-03-squirrel/index.html#footnotes",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’ve posted previously about my {emojiscape} package for printing little emoji grids to the console that represent different scenes. You may recognise the components from emojiscape::generate(\"woods\") in {ActionSquirrel}.↩︎\nBut beware of the conspiracy behind the use of this operator.↩︎"
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html",
    "href": "posts/2020-06-14-ghdump/index.html",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "",
    "text": "My garbage GitHub repos being dumped onto my local machine."
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#tldr",
    "href": "posts/2020-06-14-ghdump/index.html#tldr",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "tl;dr",
    "text": "tl;dr\nRun ghd_copy() from the {ghdump} package to either clone or download all the GitHub repositories for a given user. Intended for archival purposes or setting up a new computer.\nThe package comes with no guarantees and will likely be in a perpetual work-in-progress state. Please submit issues or pull requests."
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#clone-army",
    "href": "posts/2020-06-14-ghdump/index.html#clone-army",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Clone army",
    "text": "Clone army\nSituation:\n\nSometimes I get a new computer and want to clone all my repos to it\nSometimes I want to be able to archive my repos so I’m not dependent on GitHub nor any given computer\nit would be tedious to download or clone the repos one-by-one from the GitHub interface\n\nWants:\n\nTo clone (with HTTPS or SSH) or download all of my repos with one command\nBe able to unzip downloaded repos en masse if I want to\nDo all this from within R, mostly for the learning experience, but also to allow for user interactivity\n\nObservations:\n\nI don’t know of a specific R function that automates mass-downloading or mass-cloning of GitHub repos\nthe {gh} package provides a lightweight GitHub API wrapper for R that’s likely to be helpful\nR has many file-handling functions that will be helpful"
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#ghdump",
    "href": "posts/2020-06-14-ghdump/index.html#ghdump",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "{ghdump}",
    "text": "{ghdump}\nThe result is that I wrote a function, ghd_copy(), that copies (clones or downloads) all the repos for a given user to a specified location. You can get it in the tiny {ghdump} package.\nThe function interacts with the GitHub API thanks to the {gh} package by Gábor Csárdi, Jenny Bryan and Hadley Wickham, while iterating over repos comes thanks to the {purrr} package by Lionel Henry and Hadley Wickham.\n\n Update\nAs of May 2022 there’s also a handy rOpenSci package called {gitcellar}, by Maëlle Salmon and Jeroen Ooms, which is for downloading an organisation’s repos for archival purposes.\n\n\nGet and use\nInstall with:\n\nremotes::install_github(\"matt-dray/ghdump\")\nlibrary(ghdump)\n\nTo use the package, you’ll need a GitHub account and a GitHub Personal Access Token (PAT) stored in your .Renviron file. You can do this with the following steps:\n\nusethis::browse_github_pat()  # opens browser to generate token\nusethis::edit_r_environ()     # add your token to the .Renviron\n# then restart R\n\nYou can use {ghdump} to download the repos for a specified user:\n\nghd_copy(\n  gh_user = \"matt-dray\",           # download repos for this user\n  dest_dir = \"~/Documents/repos\",  # full local file path to copy to\n  copy_type = \"download\"           # \"download\" or \"clone\" the repos\n)\n\nOr clone them:\n\nghd_copy(\n  gh_user = \"matt-dray\",\n  dest_dir = \"~/Documents/repos\",\n  copy_type = \"clone\",\n  protocol = \"https\" # specify \"https\" or \"ssh\"\n)\n\nIf you want to use the SSH protocol when cloning, you need to make sure that you’ve set up your keys.\n\n\nInteractivity\nMy expectation is to use ghd_copy() infrequently and in a non-programmatic way, so I’ve made it quite interactive. This means user input is required; you’ll get some yes/no questions in the console that will affect how the function runs.\nHere’s an imaginary demo of the output from ghd_copy() when copy_type = \"download\":\n\nghd_copy(\"made-up-user\", \"~/Desktop/test-download\", \"download\")\n\nFetching GitHub repos for user made-up-user... 3 repos found\nCreate new directory at path ~/Desktop/test-download? y/n: y\nDefinitely download all 3 repos? y/n: y\nDownloading zipped repositories to ~/Desktop/test-download\n\ntrying URL 'https://github.com/made-up-user/fake-repo-1/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\ntrying URL 'https://github.com/made-up-user/fake-repo-2/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\ntrying URL 'https://github.com/made-up-user/fake-repo-3/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\nUnzip all folders? y/n: y\nUnzipping repositories\nRetain the zip files? y/n: y\nKeeping zipped folders.\nRemove '-master' suffix from unzipped directory names? y/n: y\nRenaming files to remove '-master' suffix\nFinished downloading\nAnd now imaginary demo of the output from ghd_copy() when copy_type = \"clone\":\n\nghd_copy(\"made-up-user\", \"~/Desktop/test-clone\", \"clone\", \"ssh\")\n\nFetching GitHub repos for user made-up-user... 3 repos found\nCreate new directory at path ~/Desktop/test-clone? y/n: y\nDefinitely clone all 3 repos? y/n: y\nCloning repositories to ~/Desktop/test-clone \nCloning into 'fake-repo-1'...\nCloning into 'fake-repo-2'...\nCloning into 'fake-repo-3'...\nFinished cloning\nNote that cloning has only been tested on my own Mac OS machine at this point (June 2020) and is not guaranteed to work elsewhere yet. Please submit issues or pull requests to help improve this.\n\n\nUnder the hood\nWhat are the steps to downloading repos with ghdump::ghd_copy()? Each of the functions in this section are not exported from the package, but you can access them by prefacing with ghdump::: (the rare triple-colon operator) if you want to see their code.\nFirst, to get repo info:\n\nghd_get_repos() passes a GitHub username to gh::gh(), which contacts the GitHub API to return a gh_response object that contains info about each of that user’s repos\nghd_extract_names() takes the gh_response object from ghd_get_repos() and extracts the names into a character vector\n\nThen to download (if copy_type = \"download\"):\n\nghd_enframe_urls() turns the character vector of repo names into a data.frame, with a corresponding column that contains the URL to a zip file for that repo\nghd_copy_zips() takes each zip file URL from that data frame and downloads them to the file path provided by the user\nghd_unzip() unzips the zipped repos\n\nYou can, of course, use these intermediate functions if you have slightly different needs. Maybe you want to limit the repos that are downloaded; do this by filtering the vector output from ghd_extract_names() for example.\nOr to clone (if copy_type = \"clone\"):\n\nghd_clone_multi() that iterates cloning over the repos, itself calling ghd_clone_one()"
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#why-bother",
    "href": "posts/2020-06-14-ghdump/index.html#why-bother",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Why bother?",
    "text": "Why bother?\nWhat did I learn from doing this? As if I have to explain myuself to you, lol.\n\n1. Iteration\nAside from {gh}, the package also depends on {purrr} for iterative programming.\nFor example, the gh_response object output from ghdump:::ghd_get_repos() is passed to map() with the pluck() function to extract the repo names.\nAnother example is the use of walk(), which is like map(), except we use it when the output is some ‘side effect’. By ‘side effect’, we mean that it doesn’t return an R object. For example, we can walk() the unzip() function over the path to each zip file. This doesn’t return anything in R; it results in some local files being manipulated.\n\n\n2. File manipulation\nR can be used to interact with files on your computer. There’s a number of these base R functions in the package:\n\ndir.create() to create a new folder\nfile.remove() to remove a file or folder\nlist.files() and list.dirs() to return a character vector files and folders at some path\nfile.rename to change the name of a file or folder\nunzip() to unpack a zipped folder\n\n\n\n3. User input\nHow do you ask questions of your user and get answers? This interactivity is made possible by readline(). You pass it a string to prompt the user, whose return value can be stored.\nFor example, this is how it looks in the console:\n\nanswer &lt;- readline(\"Do you like pizza? \") \n\nDo you like pizza? yes\n\nanswer\n\n[1] \"yes\"\nWhere a user has written yes after the prompt on the second line.\n\n\n4. Stickers\nI’ve designed a few hex stickers with the {hexSticker} package; you can see them in my ‘stickers’ GitHub repo. This time I made the sticker for {ghdump} using Dmytro Perepolkin’s {bunny} package, which is a helper for the {magick} package from Jeroen Ooms. It’s a very smooth process with much flexibility."
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#this-belongs-in-a-dump",
    "href": "posts/2020-06-14-ghdump/index.html#this-belongs-in-a-dump",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "This belongs in a dump",
    "text": "This belongs in a dump\nYeah, maybe. It’s not sophisticated, but I’ve found it useful for my own specific purposes."
  },
  {
    "objectID": "posts/2020-06-14-ghdump/index.html#environment",
    "href": "posts/2020-06-14-ghdump/index.html#environment",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:31 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#tldr",
    "href": "posts/2023-03-16-webr-quarto/index.html#tldr",
    "title": "Playgrounds with WebR and Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nWebR lets you run R in the browser(!). Now you can make WebR chunks in Quarto that render to editable, executable blocks(!)."
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#sliding-into-tedium",
    "href": "posts/2023-03-16-webr-quarto/index.html#sliding-into-tedium",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Sliding into tedium",
    "text": "Sliding into tedium\nI wrote recently a simple introduction to how R parses code. I provided a function that I said the reader could go away and run themselves.\nAs in… copy-paste it into an instance of R running on their machine. Gross.\nWouldn’t it be better if people could just tinker with the code right there in the post? This kind of ‘playground’ could be great for explaining concepts and teaching.1"
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#i-seesaw-a-solution",
    "href": "posts/2023-03-16-webr-quarto/index.html#i-seesaw-a-solution",
    "title": "Playgrounds with WebR and Quarto",
    "section": "I seesaw a solution",
    "text": "I seesaw a solution\nWebR lets you run R in the browser. Read that again! This is a landmark piece of work from George Stagg and Lionel Henry.\nI won’t go into technicals and limitations here. For more information, see:\n\nthe docs\nthe v0.1 launch post\nan ‘awesome’ list of resources\n\nCrucially for my needs, you can now run WebR chunks in a Quarto document, thanks to James J Balamuta. This renders interactive blocks of R code that the reader can adjust and execute with button-click:\n\n\n\nBeware: this is a gif, not an embedded demo!\n\n\nCheck out James’s coatless/quarto-webr GitHub repo for the source. There’s also a live demo and its source."
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#swinging-into-action",
    "href": "posts/2023-03-16-webr-quarto/index.html#swinging-into-action",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Swinging into action",
    "text": "Swinging into action\nTo have a go yourself, do follow the setup steps in James’s quarto-webr README and look at the source of his demo.\nUltimately you can:\n\nInstall the extension to your project folder by running quarto add coatless/quarto-webr in the terminal\nSet filter: webr in the YAML of your qmd file2\nWrite code chunks in the qmd using the {webr} engine\n\nThis made it straightforward to prepare a little Quarto doc with chunks powered by the ‘webr’ engine, which I deployed to the web via Netlify.3\nYou can visit that live page or see the underlying source on GitHub.4\nSo now you can tinker with the example I gave in the original blogpost about parsing R code. Unfortunately I can’t add this directly to the post, since this blog is not made with Quarto."
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#a-blog-platform-merry-go-round",
    "href": "posts/2023-03-16-webr-quarto/index.html#a-blog-platform-merry-go-round",
    "title": "Playgrounds with WebR and Quarto",
    "section": "A blog-platform merry-go-round",
    "text": "A blog-platform merry-go-round\nI’ve written this quick demo and post because I was excited about what George & Lionel and James have put together. There’s so many system-independent applications of this approach that could help with teaching and learning, or explaining simple ideas in a blog post.\nIn fact, this blog may eventually switch from {blogdown} to Quarto to take advantage of WebR. It’ll be a pain to convert old posts, but luckily I already missed the earlier {blogdown}-to-{distill} bandwagon, lol.5"
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#environment",
    "href": "posts/2023-03-16-webr-quarto/index.html#environment",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:33 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-16-webr-quarto/index.html#footnotes",
    "href": "posts/2023-03-16-webr-quarto/index.html#footnotes",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA nice example of this in a teaching context is W3 Schools, who have a ‘Try It Yourself’ space that lets you take code from the lessons and tinker with it yourself in the browser.↩︎\nSet also engine: knitr in the YAML to use {knitr} instead of Jupyter to handle the conversion. You can add format: html to ensure that the output is rendered to HTML.↩︎\nSelf-deployment and Netlify are viable for now, GitHub Pages is coming later. Netlify is how this blog is deployed.↩︎\nOriginally I tried to embed the Quarto demo in an iframe, but WebR failed to load inside it when the blog was rendered. That’s interesting.↩︎\nBut came close when I thought I’d found a system for making individual posts reproducible.↩︎"
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#tldr",
    "href": "posts/2020-01-22-repro-three-things/index.html#tldr",
    "title": "Reproducibility in R: three things",
    "section": "tl;dr",
    "text": "tl;dr\nThree tips for reproducibility in R: centralise everything; report with code; manage your workflows."
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#reproducevangelism",
    "href": "posts/2020-01-22-repro-three-things/index.html#reproducevangelism",
    "title": "Reproducibility in R: three things",
    "section": "Reproducevangelism",
    "text": "Reproducevangelism\nI spoke at the Department for Education’s Data Science Week. I wanted everyone – newer and more experienced users alike – to learn at least one new thing about reproduciblity with R and RStudio.\nThe slides are embedded below and you can also get them fullscreen online (press ‘F’ for fullscreen and ‘P’ for presenter notes) and find the source on GitHub."
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#three-things",
    "href": "posts/2020-01-22-repro-three-things/index.html#three-things",
    "title": "Reproducibility in R: three things",
    "section": "Three things",
    "text": "Three things\nThe three things to achieve reproducibility were very broad. I focused on R and some specific packages that could be helpful, but the ideas are transferable and there’s lots of ways to achieve the same thing.\nThe things were:\n\n1. Centralise everything\nGet code, functions, data, documentation in one place. Use R Projects in RStudio and write packages. This makes code more shareable and improves the chance that others can recreate things on their machine.\n\n\n2. Report with code\nPut code inside your report so that updates to data and code will be reflected instantly. Use R Markdown and other formats like Yihui Xie’s {xaringan} for reproducible slides and {bookdown} by for reproducible books.\n\n\n3. Manage workflows\nDon’t use your brain to store information about the dependencies within your analysis. Use {drake} by Will Landau instead. It remembers all the relationships between the files, objects and fcuntions in your analysis and only re-runs what needs to be re-run following changes."
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#acknowledgements",
    "href": "posts/2020-01-22-repro-three-things/index.html#acknowledgements",
    "title": "Reproducibility in R: three things",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI keep referring to the same resources about reproducibility. Take a look at:\n\nReproducible Analytical Pipelines (RAP), a UK government initiative to make publications more reproducible\nThe Turing Way, a book about reproducibility from the Alan Turing Institute\nPutting the R into reproducible research, some excellent and comprehensive slides by Anna Krystalli"
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#on-this-blog",
    "href": "posts/2020-01-22-repro-three-things/index.html#on-this-blog",
    "title": "Reproducibility in R: three things",
    "section": "On this blog",
    "text": "On this blog\nRelevant rostrum.blog reproduciblity-related writings:\n\nBuild an R package with {usethis}\nGit going: Git and GitHub\nCan {drake} RAP?\nA GitHub repo template for R analysis\nKnitting Club: R Markdown for beginners"
  },
  {
    "objectID": "posts/2020-01-22-repro-three-things/index.html#environment",
    "href": "posts/2020-01-22-repro-three-things/index.html#environment",
    "title": "Reproducibility in R: three things",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 16:29:14 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#tldr",
    "href": "posts/2023-08-19-find-bad-names/index.html#tldr",
    "title": "Object of type closure can shut up",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote an R function to help identify variable names that already exist as function names, like in c &lt;- 1 or head &lt;- \"x\"."
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#naming-and-shaming",
    "href": "posts/2023-08-19-find-bad-names/index.html#naming-and-shaming",
    "title": "Object of type closure can shut up",
    "section": "Naming and shaming",
    "text": "Naming and shaming\nNaming things is hard, yes, but data is a short and sensible choice for a dataframe, right?\n\ndata[data$column == 1, ]\n\nError in data$column: object of type 'closure' is not subsettable\n\n\nOh, silly me, I tried to subset a dataframe called data without actually, y’know, creating it first.\nThis is a classic stumbling block in R. In short, there’s already a function in base R called data() (!) and I ended up trying subset it. But you can’t subset a function, hence the error.\nHere’s what happens if you subset a non-existent object that has a name that’s different to any existing functions:\n\nx[x$column == 1, ]\n\nError in eval(expr, envir, enclos): object 'x' not found\n\n\n‘Object not found’ is a much more helpful error message."
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#whats-in-a-name",
    "href": "posts/2023-08-19-find-bad-names/index.html#whats-in-a-name",
    "title": "Object of type closure can shut up",
    "section": "What’s in a name?",
    "text": "What’s in a name?\nSo it’s not a big deal, but using existing function names as variable names is a code smell. Especially if they’re frequently used functions from base R like head(), str(), paste(), etc1.\nBut R doesn’t stop you from using these names. In general, R is pretty loose with variable naming, though you can’t use a small set of reserved words like TRUE, if or NA 2.\nFor example, here we can call the c() function to see its (very short) definition. But using it as a variable name obscures the function definition.\n\nc  # this refers to the function\n\nfunction (...)  .Primitive(\"c\")\n\nc &lt;- 1\nc  # this now refers to the variable!\n\n[1] 1\n\nrm(c)  # tidy up by removing variable\n\nCan we write a generic function to identify if some code contains ‘bad’ variable names in this way?"
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#symbolic-gesture",
    "href": "posts/2023-08-19-find-bad-names/index.html#symbolic-gesture",
    "title": "Object of type closure can shut up",
    "section": "Symbolic gesture",
    "text": "Symbolic gesture\nOf course. I’ve made a function called find_var_names(). I’m certain the functionality already exists; consider this a thought experiment.\nYou provide (a) a string of code to evaluate3 and (b) a vector of names to avoid. The code is parsed with getparsedata(parse()) to identify variable names4. It checks for a SYMBOL token followed by the assignment operators &lt;- or =5, or preceded by an assignment operator in the case of -&gt;6 (i.e. *_ASSIGN tokens). These variable names are then compared to the set of names provided.\n\nfind_var_names &lt;- function(code_string, names_to_find) {\n  \n  # Parse the string of code to identify R 'tokens'\n  parsed &lt;- getParseData(parse(text = code_string, keep.source = TRUE))\n  parsed &lt;- parsed[parsed$text != \"\", ]\n  \n  # Identify subsequent tokens (to help find 'x' in x &lt;- 1 and x = 1)\n  parsed$next_token &lt;- \n    c(parsed$token[2:nrow(parsed)], NA_character_)\n  \n  # Identify prior token (to help find 'x' in 1 -&gt; x)\n  parsed$last_token &lt;- \n    c(NA_character_, parsed$token[1:nrow(parsed) - 1])\n  \n  # Identify variable names with left-assignment\n  lassign &lt;- \n    parsed[parsed$token == \"SYMBOL\" & grepl(\"ASSIGN\", parsed$next_token), ]\n  \n  # Identify row index for variable names following right-assignment\n  rassign_i &lt;- \n    which(parsed$token == \"RIGHT_ASSIGN\" & parsed$next_token == \"SYMBOL\") + 1\n  \n  # Filter for right-assigned variable names\n  rassign &lt;- parsed[rassign_i, ]\n  \n  # Combine the results and sort by location\n  var_names &lt;- rbind(lassign, rassign)\n  var_names &lt;- var_names[sort(row.names(var_names)), ]\n  \n  # Filter for variable names that are in the provided names list\n  var_names[var_names$text %in% names_to_find, !grepl(\"_token\", names(var_names))]\n  \n}\n\nSo, let’s say we have this snippet of R code7 below. It uses some variable names that are already function names, as well as each flavour of assignment.\n\ndemo_code &lt;- r\"{\ndata &lt;- \"x\"\nhead = head(chickwts)\n\"y\" -&gt; df\na &lt;- beaver1[1:3]\nb &lt;- 2 -&gt; c\n}\"\n\nAnd here’s a function that grabs the base packages and the function names within. This is what we’ll use as our ‘no-go’ variable names. You could expand this to include other names, like function names from the tidyverse, for example.\n\nget_base_functions &lt;- function() {\n  base_names &lt;- sessionInfo()$basePkgs\n  base_pkgs &lt;- paste0(\"package:\", base_names)\n  lapply(base_pkgs, ls) |&gt; unlist() |&gt; unique() |&gt; sort()\n}\n\ntail(get_base_functions())\n\n[1] \"xyTable\"    \"xyz.coords\" \"xzfile\"     \"yinch\"      \"zapsmall\"  \n[6] \"zip\"       \n\n\nAside: this function uses a little hack. It specifically grabs the attached base packages from the sessionInfo() listing. There are other base and ‘recommended’ packages that are actually not attached from the start of your session; see the Priority value from the output of installed.packages().\nNow we can run the function to check the code for the list of function names.\n\nnaughty_words &lt;- find_var_names(\n  code_string = demo_code,\n  names_to_find = get_base_functions()\n)\n\nnaughty_words\n\n   line1 col1 line2 col2 id parent  token terminal text\n12     3    1     3    4 12     14 SYMBOL     TRUE head\n3      2    1     2    4  3      5 SYMBOL     TRUE data\n33     4    8     4    9 33     35 SYMBOL     TRUE   df\n66     6   11     6   11 66     68 SYMBOL     TRUE    c\n\n\nThe output is what you normally get from getparsedata(parse()), filtered for the illegal names. Helpfully it shows you the exact row and column indices for where the string exists in the code you provided.\nAnd of course you can just isolate the offenders.\n\nnaughty_words$text |&gt; unique() |&gt; sort()\n\n[1] \"c\"    \"data\" \"df\"   \"head\"\n\n\nSo the variable names a and b in demo_code were ignored because they’re not function names in base R. And the in-built data sets beaver1 and chickwts were also ignored, because they’re not being used as variable names. And yes, df—a commonly-used variable name for dataframes—is also a function!"
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#seeking-closure",
    "href": "posts/2023-08-19-find-bad-names/index.html#seeking-closure",
    "title": "Object of type closure can shut up",
    "section": "Seeking closure",
    "text": "Seeking closure\nI probably won’t use this function in real life, but maybe the concepts are interesting to you or you can tell me about a linter that does this already.\nAt least for now, object of type ‘Matthew’ is not upsettable."
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#environment",
    "href": "posts/2023-08-19-find-bad-names/index.html#environment",
    "title": "Object of type closure can shut up",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-22 20:39:44 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-08-19-find-bad-names/index.html#footnotes",
    "href": "posts/2023-08-19-find-bad-names/index.html#footnotes",
    "title": "Object of type closure can shut up",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlease note that this post is not a subtweet. I’ve read a bunch of code recently—including my own!—that uses variable names in this way.↩︎\nAlthough the more nefarious among you will know you can put just about anything in backticks and it can be a legit variable name. So `TRUE` &lt;- FALSE will work, but you’ll have to supply `TRUE` with the backticks to use it.↩︎\nExercise for the reader: have the function accept script files from a connection, not just as a string. I didn’t bother for this silly demo.↩︎\nIf you can be parsed, I’ve written about this before.↩︎\nIf you haven’t already expunged any files containing equals assignment.↩︎\nI’ll have to update this in future to work with down-assignment arrows.↩︎\nThis is an ‘R string’, introduced in R version 4.0.0. It deals with escaping certain characters and quotes within quotes so that you don’t have to. So \"x &lt;- \"y\"\" will error but r\"(x &lt;- \"y\")\" will return \"x &lt;- \\\"y\\\"\". You can use symbols other than parentheses, such as curly braces, if your expression already contains parentheses itself.↩︎"
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#tldr",
    "href": "posts/2022-06-01-try-r/index.html#tldr",
    "title": "Try R v4.2 in your browser",
    "section": "tl;dr",
    "text": "tl;dr\nI made it so you can launch RStudio in the browser with R v4.2 installed—thanks to the Binder service—so you can try out the new pipe |&gt; and anonymous-function \\() syntax."
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#just-browsering",
    "href": "posts/2022-06-01-try-r/index.html#just-browsering",
    "title": "Try R v4.2 in your browser",
    "section": "Just browsering",
    "text": "Just browsering\nWant to try R v4.2 from the safety of your browser without installing any software?\nMaybe your organisation hasn’t yet moved to version 4.1 or higher, but you want a chance to noodle around with its cool new syntax that all the hip young trendsetters are yakking about.\nClick the ‘launch binder’ badge below to launch R v4.2 and RStudio in your browser, thanks to the Binder project and {holepunch} package.1 You may need to wait a few moments for it to build.\n\n\n\n\n\nOnce loaded, click on the get-started.R file in the ‘files’ pane for a very simple introductory script with some basic introductions to the new syntax.\nTwo packages are also installed with the Binder instance:\n\nThe {dplyr} package, authored by Hadley Wickham, Romain François, Lionel Henry and Kirill Müller, so you can compare the base pipe against the {magrittr} pipe (%&gt;%), which was created by Stefan Milton-Bache and made popular by the tidyverse.\nThe {pipebind} package by Brenton Wiernik, so you can explore some methods for extending the functionality of the base pipe"
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#untaxing-syntax",
    "href": "posts/2022-06-01-try-r/index.html#untaxing-syntax",
    "title": "Try R v4.2 in your browser",
    "section": "Untaxing syntax",
    "text": "Untaxing syntax\nThere are two major new features to try: the base pipe |&gt; and anonymous-function syntax \\() (sometimes referred to as ‘lambdas’), which were both introduced in R v4.1 (May 2021). From R news:\n\nR now provides a simple native forward pipe syntax |&gt;. The simple form of the forward pipe inserts the left-hand side as the first argument in the right-hand side call. The pipe implementation as a syntax transformation was motivated by suggestions from Jim Hester and Lionel Henry.\n\n\nR now provides a shorthand notation for creating functions, e.g. (x) x + 1 is parsed as function(x) x + 1.\n\nAn underscore placeholder _ for the right-hand side of a base pipe was introduced in R v4.2 (April 2022). From R news:\n\nIn a forward pipe |&gt; expression it is now possible to use a named argument with the placeholder _ in the rhs [right-hand side] call to specify where the lhs [left-hand side] is to be inserted. The placeholder can only appear once on the rhs."
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#whos-been-piping-up",
    "href": "posts/2022-06-01-try-r/index.html#whos-been-piping-up",
    "title": "Try R v4.2 in your browser",
    "section": "Who’s been piping up?",
    "text": "Who’s been piping up?\nThis post isn’t about how to use the new syntax or the motivation behind it.\nThis post exists, at best, to help you play with R v4.2 and the latest features without installing anything. At worst, it might make you aware that the base pipe exists, or that Binder is magic.\nI suggest you take a look at the following materials for more information:\n\nHadley Wickham’s ‘Pipes’ chapter in the work-in-progress second edition of R for Data Science (R4DS), which talks about why to use it and how it compares to %&gt;%\nMichael Barrowman’s post about the speed of the new base pipe and what it’s doing under the hood\nSharon Machlis’s post that provides an introduction and also points to materials for running different R versions in a Docker container\nIsabella Velásquez’s post, with a story about solving a plotting problem with the base pipe\nElio Campitelli’s post that covers a number of things, including implications for {data.table}\nMiles McBain’s post on the awkward ‘dog balls’ syntax for constructing anonymous functions on the right-hand side of a base pipe, which is partially fixed by the introduction of the underscore placeholder in R v4.22\nBrenton Wiernik’s Twitter thread about the {pipebind} package to help address some of the base pipe’s shortcomings, including use of the placeholder multiple times on the right-hand side\nAdolfo Álvarez’s charming post on the history of pipes in R, including the inception of the base pipe\n\nAnd there’s probably loads more I’m missing. Let me know about them.\nRegardless, this all very exciting for me because I have strong feelings about symbols in R. Do read my theory about how $ notation is an INTERNATIONAL CONSPIRACY and YOU ARE COMPLICIT. Or my method for avoiding scripts that use the equals symbol for assignment, yuck!"
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#environment",
    "href": "posts/2022-06-01-try-r/index.html#environment",
    "title": "Try R v4.2 in your browser",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-01-try-r/index.html#footnotes",
    "href": "posts/2022-06-01-try-r/index.html#footnotes",
    "title": "Try R v4.2 in your browser",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you’re interested in the source, it’s on GitHub.↩︎\nBasically, you couldn’t pipe into an anonymous function like this: mtcars |&gt; \\(x) lm(hp ~ cyl, data = x). You had to use ‘dog balls’ or ‘eyes’, ()(), like this: mtcars |&gt; (\\(x) lm(hp ~ cyl, data = x))(). Not pleasing. As of R v4.2, you can use the placeholder to do this: mtcars |&gt; lm(hp ~ cyl, data = _). However, you will still need the balls if you want to use the placeholder more than once on the right-hand side (or you could use Brenton’s {pipebind} package).↩︎"
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#tldr",
    "href": "posts/2019-05-24-xaringan-template/index.html#tldr",
    "title": "Package a {xaringan} template",
    "section": "tl;dr",
    "text": "tl;dr\nYou can make themes for reproducible {xaringan} presentations. I made one for my organisation, the Government Digital Service."
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#a-remarkable-ninja",
    "href": "posts/2019-05-24-xaringan-template/index.html#a-remarkable-ninja",
    "title": "Package a {xaringan} template",
    "section": "A remarkable ninja",
    "text": "A remarkable ninja\nThe {xaringan} package by Yihui Xie implements remark.js1 in R Markdown so you can create exciting presentations that contain reproducible R content.2\nYihui has encouraged people to submit styles—like the RLadies theme—to enrich {xaringan}.\nThis post is about a specific theme I recreated for {xaringan} and shared in the {gdstheme} package along with an R Markdown template.\nClick on the slides embedded below and cycle through with your arrow keys, or you can open them fullscreen in a dedicated browser tab."
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#create-a-theme",
    "href": "posts/2019-05-24-xaringan-template/index.html#create-a-theme",
    "title": "Package a {xaringan} template",
    "section": "Create a theme",
    "text": "Create a theme\nThe organisation I work for uses a Google Slides template with pre-set styles and slide layouts. The template was designed with a particular philosophy in mind.\nThe downside is that any R outputs have to be copy-pasted in, which isn’t very reproducible.\nTo overcome this, I recreated their theme for {xaringan} in three steps (click to jump):\n\nCreate styles with CSS\nMake an R Markdown template\nPut these into an R package\n\n\nDo it in style\nCSS lets you define the style of HTML documents, which is the default output for {xaringan}.\nFor {xaringan} you’ll typically need two CSS files:\n\ntheme.css to define the style for each broad slide class (e.g. a heading-slide class) and for general things like table design and hyperlink colours\ntheme-fonts.css to set the typefaces, which you can define separately for the body text, headers, etc\n\nYou reference these files in the YAML header of your {xaringan} R Markdown and the style is enacted when you render it to HTML.\nI tweaked the default {xaringan} CSS files to create my own, which you can see in the the GitHub repo.\nYou can check out the {xaringan} wiki for help and ideas.\n\nGet to class\nI overwrote the default .remark-slide-content class for regular text slides. In other words, failing to specify a class in your {xaringan} slide will result in a text slide by default. I also created title-slide and heading-slide classes.\nHere’s the CSS for defining and styling the very simple heading-slide class:\n\n.heading-slide {\n  background-color: #2372b6;  /* blue background */\n  color: #fff;                /* white text*/\n  text-shadow: 0 0 0;         /* no text shadow */\n  border-bottom: 0;           /* no border */\n  font-size: 90px;            /* large text size */\n  font-weight: bold;          /* headings are bold */\n}\n\n\nAnd here’s how it looks:\n\nYou use it by specifying class: heading-slide in the R Markdown for a {xaringan} slide. You also ass the middle class to make the text vertically centred. This will overwrite the default styles to give you the ‘heading’ slide instead.\n\n\nTag team\nAs well as specifying classes, I’ve added some additional CSS tags that can be used for some minor text modifications:\n\n.black { color: #000; }      /* black text for heading slides */\n.bold { font-weight: bold; } /* embolden name on title/end slides */\n\n\nThese can be used to define different styling for a small part of a slide class. For example, the .black tag is intended for use on heading slides so the default white text can be made darker to contrast with light-coloured backgrounds.\n\n\n\nFace the font\nThe fonts.css is much simpler; it just imports and declares fonts. These can be the default system fonts or can be imported from Google Fonts\n\nMy organisation uses the proprietary Helvetica for its body type. Fortunately the default system sans-serif is Helvetica on a Mac and the close-enough Arial on Windows machines.\nFor the monospace font—used for displaying script—I’ve chosen Fira Mono, which I think is more readable than the default system monospace.\nThe fonts.css file starts by importing from Google Fonts and then describes where they’ll be used. The order of dictates which font will be shown first and then which will be next if there’s a problem.\n\n@import url('https://fonts.googleapis.com/css?family=Roboto');\n@import url('https://fonts.googleapis.com/css?family=Fira+Mono');\n\nbody { font-family: sans-serif, 'Roboto'; }\n.remark-code, .remark-inline-code { font-family: 'Fira Mono', monospace; }\n\n\nI’ve written a bit before about how to access Google Fonts for Blogdown’s Lithium theme.\n\n\n\nLay down a template\nThe style is not the only important part of recreating my organisation’s presentations. I also need to create an R Markdown template to demonstrate a restricted set of accepted slide designs. The design philosophy is important to the organisation.\nThe template itself is just a pre-filled R Markdown that shows the approved slide types and some example content. For example, the first slide of my organisation’s template doesn’t actually contain a ‘title’. Instead it’s an introduction slide that contains the speaker’s name, job, affiliation and Twitter handle.\nFor example, the user may not know to set class: title-slide and add seal: false in the YAML to override the creation of a default title slide. This is instead pre-specified for the user in the template:\n\n---\noutput:\n  xaringan::moon_reader:\n    css: [\"default\", \"gds.css\", \"gds-fonts.css\"]\n    seal: false\n    lib_dir: libs\n    nature:\n      highlightStyle: github\n      highlightLines: true\n      countIncrementalSlides: false\n---\n\nclass: title-slide, middle\n\n.bold[Firstname Surname]\n\nJob title\n\nGovernment Digital Service\n\n@username\n\n---\n\nThe top half of the code is the YAML that provides metadata for the R Markdown file. Note the reference to the CSS files and seal: false as mentioned.\nThe bottom half is the pre-filled opening slide with the speaker’s details; the user needs only to modify the filler text. Note the use of the title-slide class and the middle class for vertical alignment. There’s also the .bold[] tag mentioned earlier in this post.\n\n\nDeliver your package\nSo how can the CSS and R Markdown template be delivered to people in one bundle? In a package of course.\nYou need a specific repo structure to provide your template. This is all explained in the Document Templates chapter of the ‘R Markdown: a Definitive Guide’ book by Yihui Xie, JJ Allaire and Garrett Grolemund.\nAt the very least, your repo will need to contain the path inst/rmarkdown/templates/your-theme/skeleton/, which will typically contain three files:\n\ntheme.css for the slide styles\ntheme-fonts.css for the font face specifications\nskeleton.Rmd for the template you created\n\nI’ve also included an img/ folder to hold stock images I’ve used in the template, but this isn’t strictly necessary.\nYou’ll also need a template.yaml file one level up in inst/rmarkdown/templates/your-theme/. This contains information about the template so users know which one they’re selecting. For example:\n\nname: \"Organisation X template\"\ndescription: Internal slide style for Organisation X\ncreate_dir: false\n\nA user can now install the package and get access to your styles and template.\n\n\nShow the thing\nYou’ve written your code and packaged it, so how do you actually use it?\nIf hosted on GitHub, like my package, you can install it with:\n\n# install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/gdstheme\")\n\nAfter installation the template will appear in the ‘from template’ section of the new R Markdown window. Selecting it will open the R Markdown template.\n\n\n\n\n\nThe CSS files referenced in the YAML are used to render the style provided when you knit the document."
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#all-hands-on-deck",
    "href": "posts/2019-05-24-xaringan-template/index.html#all-hands-on-deck",
    "title": "Package a {xaringan} template",
    "section": "All hands on deck",
    "text": "All hands on deck\nMy package is a success if the outputs are reproducible and can fool my colleagues. There’s definitely improvements that can be made, but the number of users for this package is very small and it’s probably not worth the effort for now. Feel free to make a pull request to make it better.\nConsider creating your own theme and submitting it to {xaringan} so that more possibilities are available out of the box. Also take a look at Garrick Aden-Buie’s helpful {xaringanthemer} package for a simple way to tweak styles."
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#environment",
    "href": "posts/2019-05-24-xaringan-template/index.html#environment",
    "title": "Package a {xaringan} template",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-01 19:37:45 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2019-05-24-xaringan-template/index.html#footnotes",
    "href": "posts/2019-05-24-xaringan-template/index.html#footnotes",
    "title": "Package a {xaringan} template",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYihui has commented on why he loves remark.js.↩︎\nYou can learn more about the basics of {xaringan} from Alison Hill’s excellent slideshow.↩︎"
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#tldr",
    "href": "posts/2021-06-26-emojiscape/index.html#tldr",
    "title": "Generate an {emojiscape}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can print a little emoji scene to your R console with the {emojiscape} package."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#really",
    "href": "posts/2021-06-26-emojiscape/index.html#really",
    "title": "Generate an {emojiscape}",
    "section": "Really?",
    "text": "Really?\nRegular readers will know that this blog is where I implement whimsical R daydreams. Today is no exception: I’ve made a tiny package to print a little randomised emoji scene to my console.\nWhy? I’ve seen people make cute emoji-based bots, which I’ve been interested in after making the @londonmapbot Twitter bot (post, source, BotWiki). I also enjoyed the fun of mild randomisation in my last post about #RecreationThursday.\nI’ve made this completely for my own amusement, so no guarantees whatsoever."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#play-god",
    "href": "posts/2021-06-26-emojiscape/index.html#play-god",
    "title": "Generate an {emojiscape}",
    "section": "Play god",
    "text": "Play god\n\nInstall\nYou can install {emojiscape} from GitHub.\n\n## remotes::install_github(\"matt-dray/emojiscape\")\nlibrary(emojiscape)\n\nThe package has one dependency: the GitHub-hosted {emo} package1 by Hadley Wickham. It implements emoji in R like emo::ji(\"sauropod\") 🦕.\nThere’s no guarantee that these particular emoji will display correctly on your device and they may have different designs if you’re using another operating system.\n\n\nGenerate\nLet’s generate() a scene.\nThe first one is nuts, lol: a classic deciduous woods.2\n\ngenerate(\"woods\")\n\n🌳 🐿 🌰 🌰 🌳 🐿 🌰 🌳 🐿 🌰 \n🌳 🐿 🌳 🌳 🌰 🌳 🌳 🌰 🌰 🌳 \n🌳 🌰 🌳 🌳 🌳 🌳 🌰 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 🌳 🌰 🌳 🌳 🌳 \n🌳 🐿 🌳 🌰 🌳 🌰 🌳 🌳 🌳 🌳 \n🌳 🌳 🐿 🌳 🌳 🌳 🌳 🌳 🌰 🌳 \n🌰 🐿 🌰 🐿 🌳 🌳 🐿 🌳 🌳 🌳 \n🌳 🌰 🌰 🌳 🌳 🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🐿 🌳 🌳 🌳 🌳 🌳 🌰 🐿 \n\n\nHold your breath, we’re going to space. You can resize the output, but space is basically infinite and my console is not.\n\ngenerate(\n  terrain = \"space\",\n  grid_size = 7  # i.e. a 7x7 grid\n)\n\n⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ \n⭐ ⬛ ⬛ ⬛ ⭐ ⬛ ⬛ \n⭐ ⭐ ⬛ ⭐ ⬛ ⬛ ⬛ \n⬛ ⬛ ⭐ ⬛ ⭐ ⬛ ⬛ \n⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ \n⬛ ⬛ ⬛ ⭐ 🛰 ⬛ ⬛ \n⬛ ⬛ ⭐ ⭐ ⬛ ⬛ ⭐ \n\n\nHere’s a little raccoon city. Perhaps the residents are evil. (That is a gamer joke, gg.)\n\ngenerate(\"city\", 5)\n\n🏬 🏢 🏢 🏢 🏢 \n🏢 🏬 🏬 🏢 🏢 \n🏢 🏢 🏬 🏢 🏢 \n🏢 🏢 🏢 🏬 🏢 \n🏢 🏢 🦝 🏢 🏢 \n\n\nI have a PhD in dead leaves, so I had to add undergrowth. Ant you glad I included it?\n\ngenerate(\"undergrowth\", 5)\n\n🍂 🐜 🍂 🐜 🍂 \n🐜 🍄 🍂 🍂 🍂 \n🍂 🍂 🍂 🍂 🍂 \n🍂 🍂 🐜 🍂 🐜 \n🍂 🍂 🍂 🍂 🍂 \n\n\nHere endeth the puns.\n\n\nTerrains\nSo what are all the available terrain options?\n\npaste(as.list(args(generate))$terrain)[-1]\n\n [1] \"arable\"      \"city\"        \"desert\"      \"forest\"      \"garden\"     \n [6] \"liminal\"     \"mountains\"   \"ocean\"       \"pastoral\"    \"polar\"      \n[11] \"rainforest\"  \"sky\"         \"space\"       \"suburbs\"     \"traffic\"    \n[16] \"undergrowth\" \"woods\"      \n\n\nThis list may go out of date if more options are added in future.\nExpand the sections below to see each terrain’s emoji set and previews of the output for each one.\n\n\nClick for all emoji sets\n\n\n\n\nterrain = \"arable\"\n  terrain        name emoji     freq\n1  arable ear_of_corn    🌽   common\n2  arable     tractor    🚜 uncommon\n3  arable       mouse    🐭     rare\n\nterrain = \"city\"\n  terrain             name emoji     freq\n1    city  office_building    🏢   common\n2    city department_store    🏬 uncommon\n3    city          raccoon    🦝     rare\n\nterrain = \"desert\"\n  terrain   name emoji     freq\n1  desert desert     🏜   common\n2  desert cactus    🌵 uncommon\n3  desert  camel    🐫     rare\n\nterrain = \"forest\"\n  terrain           name emoji     freq\n1  forest evergreen_tree    🌲   common\n2  forest       squirrel     🐿 uncommon\n3  forest christmas_tree    🎄     rare\n\nterrain = \"garden\"\n  terrain          name emoji     freq\n1  garden          rose    🌹   common\n2  garden      seedling    🌱 uncommon\n3  garden wilted_flower    🥀     rare\n\nterrain = \"liminal\"\n  terrain               name emoji     freq\n1 liminal white_large_square    ⬜   common\n2 liminal               door    🚪 uncommon\n3 liminal         light_bulb    💡     rare\n\nterrain = \"mountains\"\n    terrain                 name emoji     freq\n1 mountains             mountain     ⛰   common\n2 mountains snow_capped_mountain     🏔️ uncommon\n3 mountains                 goat    🐐     rare\n\nterrain = \"ocean\"\n  terrain          name emoji     freq\n1   ocean    water_wave    🌊   common\n2   ocean desert_island     🏝 uncommon\n3   ocean       dolphin    🐬     rare\n\nterrain = \"pastoral\"\n   terrain           name emoji     freq\n1 pastoral        rooster    🐓   common\n2 pastoral            egg    🥚 uncommon\n3 pastoral hatching_chick    🐣     rare\n\nterrain = \"polar\"\n  terrain            name emoji     freq\n1   polar cloud_with_snow     🌨   common\n2   polar       snowflake     ❄️ uncommon\n3   polar         penguin    🐧     rare\n\nterrain = \"rainforest\"\n     terrain           name emoji     freq\n1 rainforest deciduous_tree    🌳   common\n2 rainforest          snake    🐍 uncommon\n3 rainforest        gorilla    🦍     rare\n\nterrain = \"sky\"\n  terrain            name emoji     freq\n1     sky cloud_with_rain     🌧   common\n2     sky         rainbow    🌈 uncommon\n3     sky        airplane     ✈️     rare\n\nterrain = \"space\"\n  terrain               name emoji     freq\n1   space black_large_square    ⬛   common\n2   space               star    ⭐ uncommon\n3   space              orbit     🛰     rare\n\nterrain = \"suburbs\"\n  terrain              name emoji     freq\n1 suburbs    deciduous_tree    🌳   common\n2 suburbs house_with_garden    🏡 uncommon\n3 suburbs     person_biking    🚴     rare\n\nterrain = \"traffic\"\n  terrain       name emoji     freq\n1 traffic automobile    🚗   common\n2 traffic       taxi    🚕 uncommon\n3 traffic      truck    🚚     rare\n\nterrain = \"undergrowth\"\n      terrain        name emoji     freq\n1 undergrowth fallen_leaf    🍂   common\n2 undergrowth         ant    🐜 uncommon\n3 undergrowth    mushroom    🍄     rare\n\nterrain = \"woods\"\n  terrain           name emoji     freq\n1   woods deciduous_tree    🌳   common\n2   woods       chestnut    🌰 uncommon\n3   woods       chipmunk     🐿     rare\n\n\n\n\n\nClick for all previews\n\n\n\n\nterrain = \"arable\"\n🌽 🌽 🌽 🌽 🌽 🌽 🌽 🚜 🌽 🌽 \n🌽 🌽 🌽 🌽 🌽 🚜 🚜 🌽 🌽 🌽 \n🚜 🌽 🌽 🌽 🌽 🌽 🌽 🚜 🌽 🚜 \n🌽 🐭 🌽 🌽 🌽 🌽 🐭 🌽 🚜 🌽 \n🌽 🌽 🚜 🌽 🌽 🌽 🌽 🐭 🌽 🌽 \n🌽 🌽 🚜 🌽 🚜 🌽 🚜 🌽 🌽 🚜 \n🌽 🌽 🌽 🚜 🌽 🌽 🐭 🌽 🌽 🐭 \n🚜 🌽 🌽 🌽 🌽 🌽 🌽 🌽 🌽 🌽 \n🌽 🌽 🌽 🌽 🚜 🌽 🌽 🌽 🌽 🌽 \n🌽 🐭 🌽 🚜 🌽 🌽 🌽 🌽 🌽 🌽 \n\nterrain = \"city\"\n🏢 🏢 🏢 🏢 🏢 🏢 🏢 🏬 🏢 🏢 \n🏢 🏢 🏢 🏢 🏢 🏢 🏢 🏢 🏢 🏢 \n🏢 🏢 🏢 🏢 🏬 🏬 🏢 🏢 🏢 🏢 \n🏢 🏢 🏢 🏢 🏢 🏢 🏬 🏢 🏬 🏢 \n🏢 🏢 🏬 🏢 🏢 🏢 🏢 🏢 🦝 🏢 \n🏢 🏢 🦝 🏬 🏢 🦝 🏢 🏬 🏢 🏢 \n🏬 🏢 🏢 🏬 🏢 🏬 🏢 🏢 🏢 🦝 \n🏢 🏢 🏢 🏬 🏢 🏢 🏬 🏬 🏢 🏢 \n🏢 🏢 🏢 🏬 🏢 🏢 🏢 🏢 🦝 🏬 \n🏢 🏬 🏬 🏢 🏢 🏢 🏢 🏢 🏢 🏢 \n\nterrain = \"desert\"\n🏜 🏜 🏜 🏜 🏜 🌵 🏜 🏜 🏜 🌵 \n🏜 🏜 🏜 🏜 🏜 🏜 🌵 🏜 🏜 🏜 \n🏜 🏜 🏜 🏜 🏜 🏜 🏜 🏜 🌵 🏜 \n🏜 🌵 🏜 🏜 🌵 🏜 🏜 🏜 🌵 🏜 \n🏜 🏜 🏜 🏜 🏜 🏜 🌵 🐫 🏜 🏜 \n🌵 🏜 🏜 🏜 🏜 🏜 🏜 🏜 🌵 🏜 \n🏜 🏜 🏜 🏜 🏜 🌵 🏜 🏜 🏜 🏜 \n🏜 🏜 🏜 🏜 🏜 🏜 🏜 🏜 🏜 🏜 \n🏜 🏜 🏜 🐫 🏜 🌵 🌵 🏜 🌵 🏜 \n🏜 🏜 🏜 🐫 🐫 🏜 🏜 🌵 🌵 🐫 \n\nterrain = \"forest\"\n🌲 🌲 🌲 🐿 🌲 🌲 🌲 🌲 🎄 🌲 \n🌲 🌲 🌲 🌲 🌲 🌲 🐿 🌲 🌲 🌲 \n🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 \n🌲 🌲 🐿 🌲 🌲 🌲 🐿 🌲 🌲 🌲 \n🐿 🌲 🌲 🌲 🎄 🌲 🐿 🌲 🌲 🎄 \n🌲 🌲 🌲 🌲 🐿 🌲 🌲 🎄 🌲 🌲 \n🐿 🌲 🐿 🌲 🎄 🌲 🐿 🌲 🐿 🌲 \n🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🐿 \n🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 \n🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🐿 🌲 \n\nterrain = \"garden\"\n🌱 🌹 🌹 🌹 🌱 🌹 🌹 🌹 🌹 🌱 \n🌹 🌹 🌹 🌹 🌱 🌹 🌹 🌱 🥀 🌹 \n🌹 🌱 🌹 🌹 🌹 🌹 🌹 🌹 🥀 🌱 \n🥀 🌱 🌹 🌱 🌹 🌹 🌹 🌹 🌹 🌹 \n🌱 🥀 🌹 🌹 🌹 🥀 🌹 🌹 🌱 🌹 \n🌹 🌹 🌱 🌹 🌹 🌹 🥀 🌹 🌹 🌹 \n🌱 🌱 🌹 🌹 🌹 🌹 🌹 🌱 🌹 🌹 \n🌹 🌹 🌱 🌹 🌹 🌹 🌹 🌹 🌱 🌹 \n🌹 🌹 🌹 🌱 🌹 🌹 🌹 🌹 🌹 🌹 \n🌱 🌹 🌱 🌹 🌹 🌹 🌹 🌹 🌹 🌱 \n\nterrain = \"liminal\"\n⬜ ⬜ ⬜ ⬜ ⬜ 🚪 ⬜ ⬜ ⬜ 🚪 \n⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚪 ⬜ ⬜ ⬜ \n⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚪 ⬜ \n⬜ ⬜ ⬜ ⬜ 🚪 ⬜ ⬜ ⬜ ⬜ ⬜ \n⬜ 🚪 ⬜ ⬜ 🚪 🚪 ⬜ 🚪 ⬜ ⬜ \n⬜ 🚪 ⬜ ⬜ 💡 ⬜ ⬜ 🚪 ⬜ ⬜ \n⬜ 🚪 🚪 🚪 ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ \n⬜ ⬜ ⬜ ⬜ ⬜ ⬜ ⬜ 🚪 ⬜ ⬜ \n⬜ ⬜ 🚪 ⬜ 🚪 ⬜ 🚪 ⬜ ⬜ ⬜ \n⬜ 🚪 🚪 ⬜ 🚪 ⬜ ⬜ ⬜ ⬜ ⬜ \n\nterrain = \"mountains\"\n⛰ ⛰ ⛰ 🐐 ⛰ ⛰ 🏔️ ⛰ ⛰ ⛰ \n⛰ ⛰ ⛰ 🏔️ ⛰ ⛰ 🏔️ ⛰ ⛰ ⛰ \n⛰ 🏔️ ⛰ ⛰ 🏔️ ⛰ ⛰ ⛰ ⛰ ⛰ \n⛰ ⛰ ⛰ ⛰ ⛰ ⛰ ⛰ ⛰ 🏔️ ⛰ \n⛰ ⛰ ⛰ ⛰ ⛰ ⛰ 🐐 ⛰ ⛰ 🐐 \n⛰ 🐐 🏔️ ⛰ ⛰ ⛰ ⛰ ⛰ 🏔️ 🏔️ \n⛰ ⛰ ⛰ 🏔️ 🐐 ⛰ 🏔️ 🏔️ ⛰ ⛰ \n⛰ 🏔️ 🐐 ⛰ ⛰ ⛰ ⛰ ⛰ ⛰ ⛰ \n🏔️ ⛰ ⛰ ⛰ ⛰ 🏔️ 🏔️ ⛰ 🏔️ 🐐 \n🐐 🏔️ ⛰ ⛰ ⛰ ⛰ ⛰ 🏔️ ⛰ 🏔️ \n\nterrain = \"ocean\"\n🐬 🌊 🏝 🏝 🌊 🌊 🌊 🌊 🌊 🌊 \n🐬 🌊 🌊 🌊 🌊 🌊 🐬 🌊 🌊 🌊 \n🌊 🌊 🌊 🌊 🌊 🌊 🏝 🏝 🌊 🌊 \n🌊 🏝 🌊 🌊 🌊 🌊 🌊 🌊 🐬 🌊 \n🌊 🌊 🌊 🏝 🌊 🌊 🌊 🌊 🌊 🌊 \n🌊 🌊 🐬 🌊 🐬 🌊 🌊 🌊 🏝 🌊 \n🌊 🏝 🏝 🌊 🌊 🏝 🌊 🌊 🌊 🌊 \n🌊 🌊 🏝 🌊 🌊 🌊 🌊 🐬 🌊 🌊 \n🏝 🌊 🌊 🏝 🌊 🐬 🌊 🌊 🏝 🌊 \n🌊 🌊 🌊 🌊 🏝 🌊 🌊 🏝 🏝 🌊 \n\nterrain = \"pastoral\"\n🐓 🥚 🥚 🥚 🐓 🐓 🐓 🐓 🐓 🐓 \n🐓 🐓 🐓 🐓 🐣 🐓 🥚 🐓 🐓 🐣 \n🐓 🐓 🐓 🐓 🐓 🐓 🐓 🐓 🐣 🐓 \n🐓 🐓 🥚 🐓 🐓 🐓 🐓 🐓 🐓 🐣 \n🐓 🐣 🐓 🐓 🐓 🐓 🐓 🐓 🐓 🐓 \n🥚 🐓 🥚 🐓 🐓 🐓 🐓 🐓 🐣 🐣 \n🐓 🐓 🐓 🐓 🐓 🥚 🥚 🐓 🐣 🐓 \n🐓 🐓 🐓 🥚 🐓 🐓 🐓 🐓 🐓 🐓 \n🥚 🐓 🐓 🐓 🥚 🥚 🥚 🐓 🐓 🐓 \n🥚 🐓 🥚 🥚 🥚 🐣 🐓 🥚 🐓 🥚 \n\nterrain = \"polar\"\n🌨 ❄️ ❄️ 🌨 ❄️ 🌨 🌨 🌨 ❄️ 🌨 \n🌨 🌨 🌨 🌨 🌨 🌨 ❄️ 🌨 🌨 🌨 \n🌨 🌨 🐧 🌨 ❄️ 🐧 🌨 ❄️ ❄️ 🌨 \n❄️ 🌨 🌨 🌨 🌨 🌨 ❄️ 🌨 ❄️ 🌨 \n🌨 🌨 ❄️ 🐧 ❄️ ❄️ ❄️ 🌨 🌨 ❄️ \n🌨 🌨 🌨 🌨 🌨 ❄️ 🌨 🌨 🌨 ❄️ \n🌨 ❄️ 🌨 🌨 🌨 ❄️ 🌨 🌨 🌨 🌨 \n🌨 🌨 🐧 ❄️ 🌨 ❄️ 🌨 🌨 ❄️ 🌨 \n🌨 🌨 🌨 🌨 ❄️ 🌨 🌨 🌨 🌨 🌨 \n🌨 ❄️ 🌨 🌨 🌨 🌨 🌨 🐧 ❄️ 🌨 \n\nterrain = \"rainforest\"\n🌳 🌳 🌳 🌳 🌳 🌳 🦍 🌳 🌳 🌳 \n🌳 🐍 🐍 🐍 🌳 🦍 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🦍 🌳 🦍 🌳 🌳 🐍 \n🌳 🌳 🌳 🌳 🌳 🌳 🌳 🐍 🌳 🌳 \n🌳 🌳 🐍 🦍 🌳 🌳 🌳 🐍 🌳 🐍 \n🌳 🌳 🐍 🌳 🐍 🌳 🐍 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🐍 🌳 🌳 🌳 🌳 🌳 \n🐍 🌳 🌳 🌳 🦍 🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🦍 🌳 🌳 🌳 🌳 🐍 🌳 🐍 \n🐍 🌳 🌳 🐍 🌳 🌳 🐍 🌳 🌳 🌳 \n\nterrain = \"sky\"\n🌧 🌧 🌧 🌧 🌧 🌧 🌧 🌧 🌈 🌈 \n🌧 🌧 🌧 🌧 🌧 🌈 🌧 🌧 🌈 🌧 \n🌧 🌧 🌈 🌧 ✈️ 🌧 🌧 🌧 🌧 ✈️ \n🌧 🌧 🌧 ✈️ 🌧 🌧 🌧 🌧 🌧 🌈 \n🌧 🌧 🌧 🌧 🌈 🌧 🌧 🌧 🌧 🌧 \n🌈 🌧 🌧 🌧 🌧 🌧 🌧 🌈 🌧 🌧 \n🌧 🌈 🌧 🌧 🌧 🌧 🌧 🌧 🌧 🌧 \n🌧 🌧 🌧 🌧 🌈 🌧 🌧 ✈️ 🌈 🌈 \n✈️ 🌧 🌧 🌧 🌧 🌧 🌧 🌧 🌈 🌈 \n🌈 🌧 🌧 🌧 🌧 🌧 🌈 🌧 🌈 🌧 \n\nterrain = \"space\"\n⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⭐ \n⬛ ⬛ ⭐ ⬛ ⬛ ⬛ ⬛ ⭐ ⬛ ⬛ \n⬛ ⬛ ⬛ ⭐ ⭐ ⬛ ⭐ ⭐ ⬛ ⬛ \n⭐ ⬛ ⬛ ⭐ ⬛ 🛰 ⬛ 🛰 ⬛ ⭐ \n⬛ ⬛ ⬛ 🛰 ⭐ ⬛ ⬛ 🛰 ⬛ ⭐ \n⭐ ⬛ ⭐ ⬛ ⬛ ⬛ ⬛ ⬛ ⭐ ⬛ \n⬛ ⬛ ⭐ ⬛ ⬛ ⬛ ⬛ ⬛ ⬛ ⭐ \n⭐ ⭐ ⬛ ⬛ ⭐ ⬛ ⬛ ⬛ ⭐ ⬛ \n⬛ ⬛ ⬛ ⬛ ⭐ ⬛ ⬛ ⬛ ⭐ ⭐ \n⭐ ⬛ ⭐ ⬛ 🛰 ⬛ ⬛ ⬛ ⬛ ⬛ \n\nterrain = \"suburbs\"\n🌳 🌳 🏡 🌳 🌳 🌳 🌳 🌳 🌳 🌳 \n🌳 🏡 🌳 🌳 🏡 🌳 🏡 🌳 🚴 🏡 \n🌳 🌳 🏡 🌳 🌳 🏡 🌳 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🏡 🌳 🌳 🚴 🌳 🌳 \n🌳 🌳 🏡 🏡 🌳 🏡 🌳 🏡 🌳 🌳 \n🌳 🌳 🏡 🌳 🌳 🏡 🌳 🏡 🌳 🏡 \n🌳 🏡 🌳 🏡 🌳 🌳 🏡 🏡 🌳 🏡 \n🌳 🌳 🌳 🌳 🌳 🚴 🏡 🌳 🏡 🌳 \n🌳 🌳 🌳 🚴 🌳 🌳 🌳 🏡 🌳 🌳 \n🌳 🏡 🌳 🏡 🌳 🌳 🏡 🏡 🌳 🌳 \n\nterrain = \"traffic\"\n🚗 🚗 🚗 🚗 🚕 🚗 🚗 🚕 🚗 🚕 \n🚗 🚗 🚗 🚗 🚕 🚗 🚗 🚚 🚗 🚗 \n🚗 🚕 🚗 🚗 🚗 🚗 🚗 🚗 🚗 🚗 \n🚗 🚗 🚚 🚗 🚗 🚗 🚗 🚗 🚕 🚗 \n🚗 🚗 🚗 🚗 🚕 🚗 🚗 🚗 🚗 🚗 \n🚗 🚗 🚚 🚗 🚗 🚗 🚕 🚗 🚕 🚗 \n🚕 🚗 🚕 🚗 🚗 🚗 🚗 🚕 🚗 🚕 \n🚕 🚕 🚕 🚕 🚗 🚗 🚕 🚗 🚗 🚗 \n🚕 🚕 🚗 🚗 🚚 🚗 🚗 🚗 🚕 🚗 \n🚗 🚗 🚗 🚗 🚗 🚗 🚗 🚗 🚗 🚚 \n\nterrain = \"undergrowth\"\n🍂 🐜 🐜 🐜 🍂 🍂 🐜 🍂 🍂 🍂 \n🍂 🍂 🍂 🍂 🍂 🐜 🍂 🍂 🍂 🍂 \n🍂 🐜 🍂 🍂 🍂 🐜 🍂 🍂 🍂 🐜 \n🍂 🐜 🐜 🍂 🍂 🍂 🐜 🍂 🍂 🍂 \n🍂 🍂 🍂 🍂 🍂 🍂 🍂 🐜 🍂 🍂 \n🍂 🍂 🍂 🍂 🍂 🐜 🍂 🐜 🍄 🍂 \n🍂 🍄 🍂 🍂 🍂 🍂 🐜 🍂 🍂 🍂 \n🍂 🍂 🐜 🍂 🐜 🍂 🍂 🍂 🍂 🍂 \n🍂 🍂 🍂 🐜 🍄 🍂 🍂 🍂 🍂 🐜 \n🐜 🍂 🍂 🍂 🍂 🍂 🍂 🍂 🍂 🍂 \n\nterrain = \"woods\"\n🌳 🌳 🌳 🌰 🌰 🌳 🌳 🌳 🌳 🌳 \n🌳 🌰 🌳 🌰 🌳 🌰 🌳 🌳 🌳 🌳 \n🌳 🌰 🌰 🌳 🌳 🐿 🌳 🌳 🐿 🌳 \n🌰 🌳 🌳 🌳 🌳 🌰 🌳 🌳 🌰 🌳 \n🌰 🌳 🌰 🌳 🌳 🌳 🌳 🌳 🌳 🌰 \n🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌰 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 🌳 🐿 🌰 🌳 🌳 \n🌳 🌳 🌰 🌰 🌰 🌳 🌰 🌳 🌳 🌰 \n🌳 🌳 🌰 🌰 🌳 🌳 🌳 🌳 🌳 🌰 \n🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 🌳 \n\n\n\n\n\nFrequencies\nUse get_set() to see each terrain’s emoji set and their ‘suggested frequency’ slot. In general, the most common emoji is the one that defines the background or vegetation and the rarer ones are creatures or whatever.\n\nget_set(\"mountains\")\n\n    terrain                 name emoji     freq\n1 mountains             mountain     ⛰   common\n2 mountains snow_capped_mountain     🏔️ uncommon\n3 mountains                 goat    🐐     rare\n\n\nBut you can totally mess with these emoji sampling probabilities in generate().\nAny The Mountain Goats fans?\n\ngenerate(\n  terrain = \"mountains\",\n  prob_common = 0.1,\n  prob_uncommon = 0.2,\n  prob_rare = 0.7  # INCREASE GOAT FREQUENCY\n)\n\n🐐 🏔️ 🐐 ⛰ 🐐 🐐 🐐 🏔️ 🐐 🐐 \n🏔️ 🐐 ⛰ 🐐 🐐 🐐 🐐 🏔️ 🐐 🐐 \n🐐 🐐 🏔️ 🐐 🐐 🐐 ⛰ 🐐 🐐 🐐 \n🐐 🐐 🐐 🐐 ⛰ 🐐 🐐 🏔️ 🐐 🐐 \n🐐 🐐 🐐 🐐 🏔️ 🐐 🐐 🐐 ⛰ 🐐 \n🐐 🐐 🐐 🐐 🏔️ 🐐 🏔️ 🐐 🐐 🐐 \n🏔️ 🐐 ⛰ 🏔️ 🐐 🐐 ⛰ 🐐 ⛰ 🐐 \n🐐 🐐 🐐 ⛰ 🐐 ⛰ 🐐 🏔️ 🐐 🏔️ \n🏔️ 🐐 🐐 🐐 🐐 🐐 🏔️ 🏔️ 🏔️ 🏔️ \n🏔️ 🏔️ ⛰ 🐐 🐐 🏔️ 🐐 🐐 🏔️ 🐐"
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#approach",
    "href": "posts/2021-06-26-emojiscape/index.html#approach",
    "title": "Generate an {emojiscape}",
    "section": "Approach",
    "text": "Approach\nThe generate() function is pretty simple. What it does is:\n\nCreates a vector of emojis with a length of grid_size() squared, sampled from the specified terrain set with frequencies from the prob_* arguments\nCoerces this vector to a matrix of length and width grid_size() (i.e. a square)\nLoops over each row of the matrix with cat() to print the output to the console\n\nIt works."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#expansion",
    "href": "posts/2021-06-26-emojiscape/index.html#expansion",
    "title": "Generate an {emojiscape}",
    "section": "Expansion",
    "text": "Expansion\nIf you really want, you can add a terrain option by raising a new issue or pull request in the {emojiscape} GitHub repo. These are specified in the .get_emoji() function in the /R/utils.R script."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#environment",
    "href": "posts/2021-06-26-emojiscape/index.html#environment",
    "title": "Generate an {emojiscape}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:35:09 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emojiscape_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     assertthat_0.2.1  lubridate_1.9.2   fastmap_1.1.1    \n [5] xfun_0.39         magrittr_2.0.3    glue_1.6.2        stringr_1.5.0    \n [9] knitr_1.43.1      htmltools_0.5.5   timechange_0.2.0  generics_0.1.3   \n[13] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3      \n[17] compiler_4.3.1    purrr_1.0.1       emo_0.0.0.9000    rstudioapi_0.15.0\n[21] tools_4.3.1       evaluate_0.21     yaml_2.3.7        crayon_1.5.2     \n[25] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2 stringi_1.7.12"
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#footnotes",
    "href": "posts/2021-06-26-emojiscape/index.html#footnotes",
    "title": "Generate an {emojiscape}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn turn, {emo} is built on emojilib, which is where I got the emoji names in the form ‘some_emoji’ for {emojiscape}.↩︎\nNot to scale. Or, y’know, use your imagination.↩︎"
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html",
    "href": "posts/2019-10-22-blogsnip/index.html",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "",
    "text": "Inserting a details block with the {blogsnip} addin."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#tldr",
    "href": "posts/2019-10-22-blogsnip/index.html#tldr",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "tl;dr",
    "text": "tl;dr\nOn my commute home I made {blogsnip}: a tiny package of RStudio addins that add snippets of R code to help me write blog posts."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#the-problem",
    "href": "posts/2019-10-22-blogsnip/index.html#the-problem",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "The problem",
    "text": "The problem\nI’m lazy.\nThere’s some bits of code I often want to put in my blog posts (written in R Markdown) but I can’t remember them.\nIn particular:\n\nan expandable ‘details’ section1, which sometimes contains R session information and the date of the post’s last update (see examples throughout this previous post)\na way to add an image with a caption and alt text that differ (like the gif at the top of this post), something that makes the images more accessible for users of screen readers, for example\na link that opens in a new tab, rather than in the tab where you’re reading a post (as per this tweet by Albert Y Kim)\n\nOriginally I stored them in a GitHub Gist, but this is sub-optimal: the internet connection on my commute can be patchy. I needed an offline solution."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#the-answer",
    "href": "posts/2019-10-22-blogsnip/index.html#the-answer",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "The answer",
    "text": "The answer\nI use RStudio and {blogdown} to write my blog posts. RStudio has a feature that lets you execute functions from an ‘addins’ menu.\nLots of of addins are available (see this RStudio Community thread). Some simple ones are {datapasta} for copy-pasting stuff into R, {reprex} for generating reproducible examples and even {blogdown} itself, which has addins for creating new posts and inserting images, for example.\nSo I wrote my snippets into a package that, when installed, adds some functions to RStudio’s addins menu.\nThe package is called {blogsnip}. Visit the site or source. Install with:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/blogsnip\")\n\nOnce installed, the functions are available under ‘BLOGSNIP’ in RStudio’s ‘addins’ dropdown (see the gif at the top of this post). You could also use them like regular functions by calling blogsnip::addin_details(), for example."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#how-to",
    "href": "posts/2019-10-22-blogsnip/index.html#how-to",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "How to",
    "text": "How to\nYou can follow RStudio’s guidance on creating addins, which even incldues some fancy stuff like invoking Shiny-powered interfaces for addins.\nBut perhaps, like me, you just want to create some simple shareable addins that insert some snippets of text. In which case, the (simplified) steps are:\n\nCreate an R package structure with usethis::create_package()\nAdd an R script to house your functions with usethis::use_r()\nEdit the script so you have functions in the form fun_name &lt;- function() {rstudioapi::insertText(\"Text\")}, where the insertText() function does exactly that (see example)\nAdd a special file at inst/rstudio/addins.dcf that declares your functions as addins (see example)\nDocument and build your package and host it for others to use\n\nSo you’re writing an R package as usual2, making use of {rstudioapi} functions and adding that special .dcf file.\nSee what this looks like in the full source code for {blogsnip} (note that I’ve added some other stuff there, like a license, readme and files to generate a {pkgdown} site)."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#next",
    "href": "posts/2019-10-22-blogsnip/index.html#next",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "Next",
    "text": "Next\nAdd more useful snippets to {blogsnip} for writing posts with {blogdown}. Maybe this can include ‘find-and-replace’ rather than ‘insert’ versions of current functions. Maybe you can help?\nOh, and a sticker, probably."
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#environment",
    "href": "posts/2019-10-22-blogsnip/index.html#environment",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 19:11:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-10-22-blogsnip/index.html#footnotes",
    "href": "posts/2019-10-22-blogsnip/index.html#footnotes",
    "title": "{blogsnip}: an RStudio Addins package",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI think I stole this originally from Duncan Garmonsway.↩︎\nI recommend Tomas Westlake’s guide for writing an R package from scratch, Emil Hvitfeldt’s {usethis} workflow for package development, Karl Broman’s R Packages Primer and Hadley Wickham’s R Packages book.↩︎"
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#tldr",
    "href": "posts/2021-03-13-assign/index.html#tldr",
    "title": "Protect yourself from equals assignment!",
    "section": "tl;dr",
    "text": "tl;dr\nI present you a function that warns if an R script contains The Assignment Operator That Shall Not Be Named."
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#assign-of-the-times",
    "href": "posts/2021-03-13-assign/index.html#assign-of-the-times",
    "title": "Protect yourself from equals assignment!",
    "section": "Assign of the times",
    "text": "Assign of the times\nSo, it’s been confirmed with extremely robust and objective evidence: the left-assignment arrow (x &lt;- 1) is better than equals (x = 1) for assignment in R.1\nSo, unless you hate democracy, you should protect yourself from aberrant code that uses the cursed symbol.\nBut what if a nefarious colleague still sends you their scuffed code?"
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#assignment-refinement",
    "href": "posts/2021-03-13-assign/index.html#assignment-refinement",
    "title": "Protect yourself from equals assignment!",
    "section": "Assignment refinement",
    "text": "Assignment refinement\nI’ve created the appraise_assignment() function that will peek at a suspect script and warn you if it contains the foul mark.\n\nappraise_assignment &lt;- function(file, destroy = FALSE) {\n  \n  tokens &lt;- getParseData(parse(file))[[\"token\"]]\n  \n  if (any(tokens == \"EQ_ASSIGN\")) {            # if '='\n    warning(\"\\nme = 'disgusted'\") \n    if (destroy == TRUE) {\n      answer &lt;- readline(\"Destroy file? y/n: \")\n      if (answer == \"y\") cat(\"Have mercy! This time...\")\n    }\n  } else if (any(tokens == \"RIGHT_ASSIGN\")) {  # if '&lt;-'\n    cat(\"'unorthodox' -&gt; you\\n\")\n  } else if (any(tokens == \"LEFT_ASSIGN\")) {   # if '-&gt;'\n    cat(\"you &lt;- 'hero'\\n\")\n  } else {\n    cat(\"anyway(assignment(is(even('what'))))\\n\")\n  }\n  \n}\n\nBasically, we parse() an input file and then the function uses getParseData() to extract ‘tokens’ (i.e. maths symbols, special operators, variables, etc) from the R expressions within.\nIn particular, it spots the token called EQ_ASSIGN, which is when = is used in the context of assignment."
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#i-saw-the-assign",
    "href": "posts/2021-03-13-assign/index.html#i-saw-the-assign",
    "title": "Protect yourself from equals assignment!",
    "section": "I saw the assign",
    "text": "I saw the assign\nFor demonstration purposes, I’ve written four temporary files containing left assign (&lt;-), right assign (-&gt;), equals (=), and no assignment at all.2 Our function will catch even a single deviation in a given file.\n\ntemp &lt;- tempdir()  # temp location to store files\n\npurrr::walk2(\n  c(\"x &lt;- 1\", \"x &lt;- 1; y -&gt; 1\", \"x &lt;- 1; y = 1\", \"x\"),\n  c(\"left\", \"right\", \"equals\", \"none\"),\n  ~writeLines(.x, file.path(temp, paste0(.y, \".R\")))\n)\n\nlist.files(temp, pattern = \".R$\")\n\n[1] \"equals.R\" \"left.R\"   \"none.R\"   \"right.R\" \n\n\nFirst, let’s pass the file containing the unquestionably correct assignment operator.\n\nappraise_assignment(file.path(temp, \"left.R\"))\n\nyou &lt;- 'hero'\n\n\nRight-assignment is left-assignment’s less-handsome sibling.\n\nappraise_assignment(file.path(temp, \"right.R\"))\n\n'unorthodox' -&gt; you\n\n\nHold steady…\n\nappraise_assignment(file.path(temp, \"equals.R\"))\n\nWarning in appraise_assignment(file.path(temp, \"equals.R\")): \nme = 'disgusted'\n\n\nPhew, we got a warning, so we know the file is dangerous and should never be opened.\nIn fact, if you set the argument destroy = TRUE in appraise_assignment(), you’ll be prompted to irrecoverably annihilate the rotten file forever.3\nFor completeness, is it really an R script if it doesn’t contain any assignment at all?\n\nappraise_assignment(file.path(temp, \"none.R\"))\n\nanyway(assignment(is(even('what'))))"
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#assigning-off",
    "href": "posts/2021-03-13-assign/index.html#assigning-off",
    "title": "Protect yourself from equals assignment!",
    "section": "Assigning off",
    "text": "Assigning off\nIn conclusion, some assignment operators were created more equal than others. See Colin Fay’s round-up to learn more about the history and plethora of these symbols (and be happy that the underscore is no longer legitimate).\nAnyway, welcome to the best timeline, where we all recognise &lt;- unequivocally as the champion and = can get absolutely rekt.\nIf I had one wish though, it would be to make the left-assign arrow even more powerful. How about making it really long? 23 hyphens seems sufficiently dominant.\n\nx &lt;----------------------- 1\nx\n\n[1] 1\n\n\nIt’s a really long arrow, so I call it ‘the spear’.4 I look forward to its adoption by R Core."
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#environment",
    "href": "posts/2021-03-13-assign/index.html#environment",
    "title": "Protect yourself from equals assignment!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 23:40:11 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2       vctrs_0.6.3        cli_3.6.1          knitr_1.43.1      \n [5] rlang_1.1.1        xfun_0.39          rex_1.2.1          processx_3.8.2    \n [9] purrr_1.0.1        xmlparsedata_1.0.5 data.table_1.14.8  jsonlite_1.8.7    \n[13] glue_1.6.2         backports_1.4.1    rprojroot_2.0.3    htmltools_0.5.5   \n[17] ps_1.7.5           fansi_1.0.4        rmarkdown_2.23     tibble_3.2.1      \n[21] evaluate_0.21      fastmap_1.1.1      yaml_2.3.7         lifecycle_1.0.3   \n[25] cyclocomp_1.1.0    compiler_4.3.1     lintr_3.1.0        pkgconfig_2.0.3   \n[29] htmlwidgets_1.6.2  rstudioapi_0.15.0  digest_0.6.33      R6_2.5.1          \n[33] utf8_1.2.3         pillar_1.9.0       callr_3.7.3        magrittr_2.0.3    \n[37] tools_4.3.1        withr_2.5.0        lazyeval_0.2.2     xml2_1.3.5        \n[41] remotes_2.4.2.1    desc_1.4.2"
  },
  {
    "objectID": "posts/2021-03-13-assign/index.html#footnotes",
    "href": "posts/2021-03-13-assign/index.html#footnotes",
    "title": "Protect yourself from equals assignment!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nActually, I don’t really care which one you use, but that’s less of a funny take. I prefer the left assignment operator because look! It’s a little arrow! Quirky! Esoteric! An extra keystroke to exercise your fingers!↩︎\nWe do not talk about &lt;&lt;-.↩︎\nWell, not really, because I don’t want you to delete any of your files. But rest assured I’ve included file.remove() in my local version of the function and I’m not afraid to use it.↩︎\nIn other words, R evaluates this as an object, x, being assigned a numeric value that has an odd number of ‘negative’ symbols that cancel each other out.↩︎"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html",
    "href": "posts/2021-02-27-typos/index.html",
    "title": "Typo-shaming my Git commits",
    "section": "",
    "text": "The author at work (CC BY-SA 3.0 by KaterBegemot)"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#tldr",
    "href": "posts/2021-02-27-typos/index.html#tldr",
    "title": "Typo-shaming my Git commits",
    "section": "tl;dr",
    "text": "tl;dr\nNearly 10 per cent of the commits to this blog’s source involve typo fixes, according to a function I wrote to search commit messages via the {gh} package.\n\n Note\nGreat news everyone, I improved. I re-rendered this post in July 2023 and the percentage had basically halved to 5%."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#not-my-typo",
    "href": "posts/2021-02-27-typos/index.html#not-my-typo",
    "title": "Typo-shaming my Git commits",
    "section": "Not my typo",
    "text": "Not my typo\nI’m sure you’ve seen consecutive Git commits from jaded developers like ‘fix problem’, ‘actually fix problem?’, ‘the fix broke something else’, ‘burn it all down’. Sometimes a few swear words will be thrown in for good measure (look no further than ‘Developers Swearing’ on Twitter).\nThe more obvious problem from reading the commits for this blog is my incessant keyboard mashing; I think a lot of my commits are there to fix typos.1\nSo I’ve prepared a little R function to grab the commit messages for a specified repo and find the ones that contain a given search term, like ‘typo’.2"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#search-commits",
    "href": "posts/2021-02-27-typos/index.html#search-commits",
    "title": "Typo-shaming my Git commits",
    "section": "Search commits",
    "text": "Search commits\n{gh} is a handy R package from Gábor Csárdi, Jenny Bryan and Hadley Wickham that we can use to interact with GitHub’s REST API.3 We can also use {purrr} for iterating over the returned API object.\n\nlibrary(gh)    # CRAN v1.2.0\nlibrary(purrr) # CRAN v0.3.4\n\nSo, here’s one way of forming a function to search commit messages:\n\nsearch_commits &lt;- function(owner, repo, string = \"typo\") {\n  \n  commits &lt;- gh::gh(\n    \"GET /repos/{owner}/{repo}/commits\",\n    owner = owner, repo = repo,\n    .limit = Inf\n  )\n\n  messages &lt;- purrr::map_chr(\n    commits, ~purrr::pluck(.x, \"commit\", \"message\")\n  )\n  \n  matches &lt;- messages[grepl(string, messages, ignore.case = TRUE)]\n  \n  out &lt;- list(\n    meta = list(owner, repo),\n    counts = list(\n      match_count = length(matches),\n      commit_count = length(messages),\n      match_ratio = length(matches) / length(messages)\n    ),\n    matches = matches,\n    messages = messages\n  )\n  \n  return(out)\n  \n}\n\nFirst we pass a GET request to the GitHub API via gh::gh(). The API documentation tells us the form needed to get commits for a given owner’s repo.\nBeware: the API returns results in batches of some maximum size, but the .limit = Inf argument automatically creates additional requests until everything is returned. That might mean a lot of API calls.\nNext we can use {purrr} to iteratively pluck() out the commit messages from the list returned by gh::gh(). It’s then a case of finding which ones contain a search string of interest (defaulting to the word ‘typo’).\nThe object returned by search_commits() is a list with four elements: meta repeats the user and repo names; counts is a list with the commit count, the count of messages containing the search term, and their ratio; and the messages and matches elements contain all messages and the ones containing the search term, respectively."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#fniding-my-typoes",
    "href": "posts/2021-02-27-typos/index.html#fniding-my-typoes",
    "title": "Typo-shaming my Git commits",
    "section": "Fniding my typoes",
    "text": "Fniding my typoes\nHere’s an example where I look for commit messages to this blog that contain the word ‘typo’. Since the function contains the .limit = Inf argument in gh::gh(), we’ll get an output message for each separate request that’s been made to the API.\n\nblog_typos &lt;- search_commits(\"matt-dray\", \"rostrum-blog\")\n\nℹ Running gh query\n\n\nℹ Running gh query, got 100 records of about 1900\n\n\nℹ Running gh query, got 200 records of about 1900\n\n\nℹ Running gh query, got 300 records of about 1900\n\n\nℹ Running gh query, got 400 records of about 1900\n\n\nℹ Running gh query, got 500 records of about 1900\n\n\nℹ Running gh query, got 600 records of about 1900\n\n\nℹ Running gh query, got 700 records of about 1900\n\n\nℹ Running gh query, got 800 records of about 1900\n\n\nℹ Running gh query, got 900 records of about 1900\n\n\nℹ Running gh query, got 1000 records of about 1900\n\n\nℹ Running gh query, got 1100 records of about 1900\n\n\nℹ Running gh query, got 1200 records of about 1900\n\n\nℹ Running gh query, got 1300 records of about 1900\n\n\nℹ Running gh query, got 1400 records of about 1900\n\n\nℹ Running gh query, got 1500 records of about 1900\n\n\nℹ Running gh query, got 1600 records of about 1900\n\n\nℹ Running gh query, got 1700 records of about 1900\n\n\nℹ Running gh query, got 1800 records of about 1900\n\n\nHere’s a preview of the structure of the returned object. You can see how it’s a list that contains the values and other list elements that we expected.\n\nstr(blog_typos)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"matt-dray\"\n  ..$ : chr \"rostrum-blog\"\n $ counts  :List of 3\n  ..$ match_count : int 95\n  ..$ commit_count: int 1870\n  ..$ match_ratio : num 0.0508\n $ matches : chr [1:95] \"Improve text, correct typos, add cheatcode to hiscore post\" \"Fix typo that also made it into a Mastodon post, lol\" \"Correct typo in games post\" \"Improve readability of parse post, add renkun post, fix typos\" ...\n $ messages: chr [1:1870] \"Re-build README.Rmd\" \"Remove non-existent anchor from hiscore post\" \"Improve text, correct typos, add cheatcode to hiscore post\" \"Re-build README.Rmd\" ...\n\n\nYou can see there were 1870 commit messages returned, of which 95 contained the string ‘typo’. That’s 5 per cent.\nHere’s a sample4 of those commit messages that contained the word ‘typo’:\n\nset.seed(1337)\nsample(blog_typos$matches, 5)\n\n[1] \"Fix potatypos\"                                         \n[2] \"Merge pull request #72 from maelle/patch-1\\n\\ntypo fix\"\n[3] \"Correct typos\"                                         \n[4] \"Correct typo\"                                          \n[5] \"add gapminder example, fix typo\"                       \n\n\nIt seems the typos are often corrected with general improvements to a post’s copy. This usually happens when I read the post the next day with fresh eyes and groan at my ineptitude.5"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#exposing-others",
    "href": "posts/2021-02-27-typos/index.html#exposing-others",
    "title": "Typo-shaming my Git commits",
    "section": "Exposing others",
    "text": "Exposing others\nI think typos are probably most often referenced in repos that involve a lot of documentation, or a book or something.\nTo make myself feel better, I had a quick look at the repo for the {bookdown} project R for Data Science by Hadley Wickham and Garrett Grolemund.\n\ntypos_r4ds &lt;- search_commits(\"hadley\", \"r4ds\")\n\nThe result:\n\nstr(typos_r4ds)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"hadley\"\n  ..$ : chr \"r4ds\"\n $ counts  :List of 3\n  ..$ match_count : int 450\n  ..$ commit_count: int 2137\n  ..$ match_ratio : num 0.211\n $ matches : chr [1:450] \"fix: typo (add missing `to`) (#1529)\" \"Fix typos in subsection \\\"6.3.2 How does pivoting work?\\\" (#1534)\\n\\n* Add missing word\\r\\n\\r\\n* Fix typo\" \"typo fix in communication.qmd (#1523)\" \"Typo: \\\"a new\\\" instead of \\\"an new\\\" (#1515)\" ...\n $ messages: chr [1:2137] \"Small format for column (#1522)\\n\\nspecies column name is missing back ticks in this reference\" \"fix: typo (add missing `to`) (#1529)\" \"Use dplyr 1.1 'default' parameter in 'case_when()' (#1525)\\n\\n* Use dplyr 1.1 'default' parameter in 'case_when\"| __truncated__ \"Update arrow chapter code to avoid errors (#1517)\\n\\n* Add in `col_types` to specify schema\\r\\n\\r\\n* Just use open_dataset()\" ...\n\n\nSurprise: typos happen to all of us. I’m guessing the percentage is quite high because the book has a lot of readers scouring it, finding small issues and providing quick fixes."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#in-other-words",
    "href": "posts/2021-02-27-typos/index.html#in-other-words",
    "title": "Typo-shaming my Git commits",
    "section": "In other words",
    "text": "In other words\nOf course, you can change the string argument of search_commits() to find terms other than the default ‘typo’. Use your imagination.\nHere’s a meta example: messages containing emoji in the commits to the {emo} package by Hadley Wickham, Romain François and Lucy D’Agostino McGowan.\nEmoji are expressed in commit messages like :dog:, so we can capture them with a relatively simple regular expression like \":.*:\" (match wherever there are two colons with anything in between).\n\nemo_emoji &lt;- search_commits(\"hadley\", \"emo\", \":.*:\")\n\nℹ Running gh query\n\n\nℹ Running gh query, got 100 records of about 200\n\nstr(emo_emoji)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"hadley\"\n  ..$ : chr \"emo\"\n $ counts  :List of 3\n  ..$ match_count : int 21\n  ..$ commit_count: int 112\n  ..$ match_ratio : num 0.188\n $ matches : chr [1:21] \"need emo:: prefix in that case, bc ji_glue might be called without emo being attached. ping @batpigandme\" \"rm emoji keyboard (saved in separate branch) but eventually might just go in a separate :package:\" \"emo::ji_rx a meta regex to catch all emojis. closes #14\" \"bring in some extra modules (for emo::ji_rx)\" ...\n $ messages: chr [1:112] \"Imports CRAN glue (#54)\" \"no longer importing dplyr. #24\" \"less dependency on dplyr\" \"clock no longer depends on dplyr\" ...\n\n\nOnly 19 per cent? Son, I am disappoint."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#environment",
    "href": "posts/2021-02-27-typos/index.html#environment",
    "title": "Typo-shaming my Git commits",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 22:22:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1 gh_1.4.0   \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 magrittr_2.0.3    rappdirs_0.3.3    glue_1.6.2       \n [9] knitr_1.43.1      gitcreds_0.1.2    htmltools_0.5.5   rmarkdown_2.23   \n[13] lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3       compiler_4.3.1   \n[17] rstudioapi_0.15.0 tools_4.3.1       curl_5.0.1        evaluate_0.21    \n[21] httr2_0.2.3       yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7   \n[25] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#footnotes",
    "href": "posts/2021-02-27-typos/index.html#footnotes",
    "title": "Typo-shaming my Git commits",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, I’m aware of Git hooks and various GitHub Actions that could prevent this.↩︎\nThough obviously you’ll miss messages containing the word ‘typo’ if you have a typo in the word ‘typo’ in one of your commits…↩︎\nI used it most recently in my little {ghdump} package for downloading or cloning a user’s repos en masse.↩︎\nVery rarely do I make myself laugh, but I had forgotten that I used the commit message ‘Fix potatypos’ when correcting typos in the post about the {potato} package, lol. Also thank you to Maëlle, who fixed a typo on my behalf!↩︎\nI wonder how many typos I’ll need to correct in this post after publishing. (Edit: turns out I accidentally missed a couple of words, lol.)↩︎"
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#tldr",
    "href": "posts/2020-11-21-president-tilegram/index.html#tldr",
    "title": "The US electoral college with {tilegramsR}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {tilegramsR} package for R contains a geospatial object for mapping the US electoral college. I amended it for states that use the congressional district method and generated a minimalist map of the results for the 2020 US presidential election.1"
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#send-a-cartogram",
    "href": "posts/2020-11-21-president-tilegram/index.html#send-a-cartogram",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Send a cartogram",
    "text": "Send a cartogram\nIt’s usually best to scale subnational divisions by voter count when visualising election results. This is because election outcomes are decided by people, not land area. Cartograms are a good choice for this: they’re maps where geographic units are resized according to something other than area.\nOne format of the cartogram is the tilegram. Tilegrams disregard the shape of the geographic units entirely and represent them with uniformly-shaped ‘tiles’ instead. Squares are often used, but hexagons give you a bit more freedom to pack the units and approximate geographic location. Hexagons are the bestagons, after all.\nA tilegram may end up looking strange if you’re used to looking at Mercator-projected maps, but it’s a better reflection of relative voter contribution."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#back-to-college",
    "href": "posts/2020-11-21-president-tilegram/index.html#back-to-college",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Back to college",
    "text": "Back to college\nSo we could make a tilegram of the recent US presidential election with a separate shape for each state. Right? Well, yeah, but there’s a better way.\nThe US presidential election is special because the total vote count doesn’t directly elect the leader. Instead there’s an ‘electoral college’ system. Put extremely simply, each state has a number of representatives (‘electors’) that are sent to vote for the candidate that got the majority vote share in their state. The winning national candidate has the majority of state electors declaring for them (270 of 538).\nSo it’s electors, not states, that should be represented by each unit in a tilegram of US presidential election results."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#tile-style",
    "href": "posts/2020-11-21-president-tilegram/index.html#tile-style",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Tile style",
    "text": "Tile style\nFortunately for us, the {tilegramsR} package by Bhaskar V. Karambelkar has an sf_FiveThirtyEightElectoralCollege2 object that contains tilegram data for the US where each elector is represented by one hexagon.\nIt’s an sf-class object, which means it contains tidy geospatial information: each row is an elector, with a column for the state abbreviation and a column for the hexagon geometries.\nBefore we take a look, let’s load the packages used in this post.\n\nsuppressPackageStartupMessages({\n  # Data wrangling\n  library(dplyr)       # data manipulation\n  library(stringr)     # string manipulation\n  # Mapping\n  library(tilegramsR)  # tilegram objects\n  library(ggplot2)     # plotting\n  library(ggtext)      # text rendering in plots\n  library(ggthemes)    # has a map theme\n  library(patchwork)   # organise plots\n})\n\nThe default print method for sf-class objects shows us a few things. We can see there are 538 two-dimensional shapes: one for each elector. Note that this map is built in arbitrary space: the bounding box doesn’t reflect actual geography and there’s no coordinate reference system (CRS). The preview of the features shows us each row of the dataset with each state labelled with its abbreviation (CA is California, for example).\n\nsf_FiveThirtyEightElectoralCollege\n\nSimple feature collection with 538 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 293.6239 ymin: 16.95238 xmax: 2495.803 ymax: 1661.333\nCRS:           NA\nFirst 10 features:\n   FID state tilegramVa                       geometry\n1   02    AK          3 POLYGON ((293.6239 237.3333...\n2   06    CA         55 POLYGON ((352.3486 847.619,...\n3   06    CA         55 POLYGON ((322.9862 796.7619...\n4   06    CA         55 POLYGON ((352.3486 745.9048...\n5   06    CA         55 POLYGON ((322.9862 695.0476...\n6   06    CA         55 POLYGON ((352.3486 644.1905...\n7   02    AK          3 POLYGON ((322.9862 288.1905...\n8   02    AK          3 POLYGON ((352.3486 237.3333...\n9   06    CA         55 POLYGON ((411.0734 949.3333...\n10  06    CA         55 POLYGON ((381.711 898.4762,...\n\n\nSimilarly, there’s an object called sf_FiveThirtyEightElectoralCollege.states that contains geometry to delineate state boundaries in the sf_FiveThirtyEightElectoralCollege object. We can combine these and look at a quick tilegram of the US electoral college using {ggplot2} and the special geom_sf() geom for visualising geospatial data stored in sf format.\n\nggplot() + \n  geom_sf(data = sf_FiveThirtyEightElectoralCollege) + \n  geom_sf(\n    data = sf_FiveThirtyEightElectoralCollege.states,\n    color = \"black\", alpha = 0, size = 1\n  ) + \n  theme_map()\n\n\n\n\nYou can see that each elector is represented by a single hexagon and groups of hexagons are combined into states (thick outlines). Hexagons are placed roughly in the familiar shape of the US despite the change to the apparent area of each one. The non-contiguous regions in the lower left are Alaska (three electors) and Hawaii (four)."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#district-structure-strictures",
    "href": "posts/2020-11-21-president-tilegram/index.html#district-structure-strictures",
    "title": "The US electoral college with {tilegramsR}",
    "section": "District-structure strictures",
    "text": "District-structure strictures\nIn general, the winner of the popular vote within a state gains all the electors for that state. There are two exceptions: Nebraska (NE) and Maine (ME). These states use the ‘congressional district method’.\nThe popular-vote winner gets two electors by default and the remaining electors are won by the winner of the popular vote in each district (three in Nebraska and two in Maine). In other words, the electors from these states could be from more than one party.\nThis is sometimes represented in electoral college maps by colouring Nebraska and Maine with stripes of with each party’s colour. We can avoid that suboptimal representation with a tilegram because we can individually colour our tiles.\nUnfortunately, the sf_FiveThirtyEightElectoralCollege doesn’t account for the congressional district method, so we’ll have to build this in ourselves. We can isolate rows for Nebraska and Maine and then generate a new column to create distinct names for the districts, which we’ll number sequentially.\n\n# Isolate/update states with the congressional district method\ncdm_sf &lt;- sf_FiveThirtyEightElectoralCollege %&gt;% \n  filter(state %in% c(\"NE\", \"ME\")) %&gt;% \n  mutate(\n    state_cdm = c(\n      \"NE\", \"NE\", \"NE1\", \"NE2\", \"NE3\", \n      \"ME\", \"ME\", \"ME1\", \"ME2\"\n    )\n  ) %&gt;% \n  select(state, state_cdm, everything())\n\n# Preview\ncdm_sf\n\nSimple feature collection with 9 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 851.5092 ymin: 932.381 xmax: 2407.716 ymax: 1661.333\nCRS:           NA\n  state state_cdm FID tilegramVa                       geometry\n1    NE        NE  31          5 POLYGON ((851.5092 1000.19,...\n2    NE        NE  31          5 POLYGON ((910.2339 1000.19,...\n3    NE       NE1  31          5 POLYGON ((939.5963 949.3333...\n4    NE       NE2  31          5 POLYGON ((968.9587 1000.19,...\n5    NE       NE3  31          5 POLYGON ((998.3211 949.3333...\n6    ME        ME  23          4 POLYGON ((2290.266 1559.619...\n7    ME        ME  23          4 POLYGON ((2319.628 1610.476...\n8    ME       ME1  23          4 POLYGON ((2348.991 1559.619...\n9    ME       ME2  23          4 POLYGON ((2319.628 1508.762...\n\n\nYou can see that we’ve retained the original state column and now also have a state_cdm column that contains tiles named by district.\nNow we can replace the data for these states in our original sf-class object.\n\n# Update the original object with the new information\nf38_cdm_sf &lt;- sf_FiveThirtyEightElectoralCollege %&gt;% \n  mutate(state_cdm = state) %&gt;%  # generate column\n  filter(!state %in% c(\"ME\", \"NE\")) %&gt;%  # remove old NE and ME\n  bind_rows(cdm_sf) %&gt;% # bind updated NE and ME \n  select(state, state_cdm, everything())  # relocate cols"
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#party-time",
    "href": "posts/2020-11-21-president-tilegram/index.html#party-time",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Party time",
    "text": "Party time\nWe have our geospatial information sorted; now to create vectors of the states won by each candidate as declared by the Associated Press (AP) at time of writing.\n\n# Vector of states/districts won by Democrat candidate\nd_states &lt;- c(\n  \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"GA\", \"HI\",\n  \"IL\", \"MA\", \"MD\", \"ME\", \"ME1\", \"MI\", \"MN\", \"NE2\",\n  \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OR\", \"PA\", \"RI\",\n  \"VA\", \"VT\", \"WA\", \"WI\"\n)\n\n# Vector of states/districts won by Republican candidate\nr_states &lt;- c(\n  \"AK\", \"AL\", \"AR\", \"FL\", \"IA\", \"ID\", \"IN\", \"KS\",\n  \"KY\", \"LA\", \"ME2\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\",\n  \"NE\", \"NE1\", \"NE3\", \"OH\", \"OK\", \"SC\", \"SD\", \"TN\",\n  \"TX\", \"UT\", \"WV\", \"WY\"\n)\n\nWith this information we can add a couple of columns to our geospatial object: result to indicate a Democrat or Republican winner, and the symbolic colour of the party (blue for Democrat and red for Republican). We’ll refer to this colour column in the plot so we can colour the tiles correctly.\n\n# Mark districts with winning party and provide colour\nresults_sf &lt;- f38_cdm_sf %&gt;% \n  mutate(\n    result = case_when(\n      state_cdm %in% d_states ~ \"D\",  # Democrat\n      state_cdm %in% r_states ~ \"R\"   # Republican\n    ),\n    colour = case_when(\n      result == \"D\" ~ \"#0000FF\",  # blue\n      result == \"R\" ~ \"#FF0000\"   # red\n    )\n  ) %&gt;% \n  select(state, state_cdm, result, colour, everything())\n\n# Preview\nresults_sf\n\nSimple feature collection with 538 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 293.6239 ymin: 16.95238 xmax: 2495.803 ymax: 1661.333\nCRS:           NA\nFirst 10 features:\n   state state_cdm result  colour FID tilegramVa                       geometry\n1     AK        AK      R #FF0000  02          3 POLYGON ((293.6239 237.3333...\n2     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 847.619,...\n3     CA        CA      D #0000FF  06         55 POLYGON ((322.9862 796.7619...\n4     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 745.9048...\n5     CA        CA      D #0000FF  06         55 POLYGON ((322.9862 695.0476...\n6     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 644.1905...\n7     AK        AK      R #FF0000  02          3 POLYGON ((322.9862 288.1905...\n8     AK        AK      R #FF0000  02          3 POLYGON ((352.3486 237.3333...\n9     CA        CA      D #0000FF  06         55 POLYGON ((411.0734 949.3333...\n10    CA        CA      D #0000FF  06         55 POLYGON ((381.711 898.4762,..."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#gram-them-tiles",
    "href": "posts/2020-11-21-president-tilegram/index.html#gram-them-tiles",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Gram them tiles",
    "text": "Gram them tiles\nThe plot will be built from our sf-class object that has been edited for the congressional district method and contains the results; the state boundaries from sf_FiveThirtyEightElectoralCollege.states; and the title with coloured as a key matching the candidate’s party.\nNote that Nebraska (centre-left) and Maine (upper-right) are indeed coloured to represent more than one party, given the share of votes in their congressional district systems.\n\n# Build plot object\np &lt;- ggplot() +\n  geom_sf(  # layer containing district hexagons\n    data = results_sf,\n    fill = results_sf$colour,  # hex interiors\n    color = results_sf$colour  # hex outlines\n  ) + \n  geom_sf(  # layer containing state hexagons\n    data = sf_FiveThirtyEightElectoralCollege.states,\n    color = \"white\",  # state boundaries\n    alpha = 0,  # transparent\n    size = 1  # thickness\n  ) +\n  theme_map() # remove non-data plot elements\n\np\n\n\n\n\nI think that’s quite pleasing.\nWe can add some more contextual information with titles. In particular, we can use the text rendering of {ggtext} to create a subtitle with the candidates’ names coloured as a key to the map.\n\np +  # the original plot object\n  labs(  # {ggtext} to colour names by party\n    title = \"&lt;span style='font-size:15pt'&gt;\n    US Presidential Election 2020\",\n    subtitle = \"&lt;span style='font-size:10pt'&gt;Electoral college votes for\n    &lt;span style='color:#0000FF;'&gt;Joe Biden&lt;/span&gt; (306) and \n    &lt;span style='color:#FF0000;'&gt;Donald Trump&lt;/span&gt; (232)\n    &lt;/span&gt;\",\n    caption = \"Made with {ggplot2}, {tilemapsR} and {ggtext}\"\n  ) +\n  theme(\n    plot.title = element_markdown(lineheight = 1.1),\n    plot.subtitle = element_markdown(lineheight = 1.1)\n  )"
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#zoom-enhance",
    "href": "posts/2020-11-21-president-tilegram/index.html#zoom-enhance",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Zoom! Enhance!",
    "text": "Zoom! Enhance!\nIn case you didn’t spot Nebraska and Maine, we can plot these two alone and label them by state_cdm to expose the district names.\n\n# Quick and dirty function to plot each state\nplot_state &lt;- function(state_abbrev) {\n  \n  # Isolate state data\n  state_sf &lt;- results_sf %&gt;% \n    filter(str_detect(state, paste0(\"^\", state_abbrev)))\n  \n  # Build plot\n  p &lt;- ggplot() +\n    geom_sf(\n      data = state_sf,\n      fill = state_sf$colour, color = state_sf$colour\n    ) +\n    geom_sf_text(  # overlay state abbrev\n      data = state_sf, aes(label = state_cdm),\n      size = 5, color = \"white\"\n    ) +\n    theme_map()\n  \n  # Provide a \n  if (state_abbrev == \"NE\") {\n    p &lt;- p + labs(title = \"Nebraska\")\n  } else if (state_abbrev == \"ME\"){\n    p &lt;- p + labs(title = \"Maine\")\n  }\n  \n  return(p)\n  \n}\n\n# Arrange plots side-by-side with {patchwork}\nplot_state(\"NE\") + plot_state(\"ME\")\n\n\n\n\nNote that the districts aren’t necessarily placed in geographically-accurate locations within each state, relatively speaking. But that’s okay, because the tilegram is not an accurate representation of geography anyway."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#development",
    "href": "posts/2020-11-21-president-tilegram/index.html#development",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Development",
    "text": "Development\nI’ve chosen to keep these maps very simple, partly for the aesthetics, but also because the purpose is to communicate the share of electoral college votes with minimal distraction.\nYou could do a number of other things to provide further information, like label states with geom_sf_text(), colour the tiles by vote share rather than outright winner, or make it interactive with the {leaflet} package and include mouseovers to show a full breakdown of results."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#other-solutions",
    "href": "posts/2020-11-21-president-tilegram/index.html#other-solutions",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Other solutions",
    "text": "Other solutions\nYou can find many, many examples of cartograms or other map types used to display the presidential election results. For example, check out:\n\nThe Wall Street Journal has a square version of the hexagonal map in this post\nThe Financial Times shows a regular map with each state’s electoral college contribution overlaid as squares\nThe BBC and Reuters have a regular map with the option to switch to a cartogram with one square per state\n\nLet me know if you seen any particularly good examples."
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#environment",
    "href": "posts/2020-11-21-president-tilegram/index.html#environment",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 18:39:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] patchwork_1.1.2  ggthemes_4.2.4   ggtext_0.1.2     ggplot2_3.4.2   \n[5] tilegramsR_0.2.0 sf_1.0-14        stringr_1.5.0    dplyr_1.1.2     \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3         generics_0.1.3     class_7.3-22       xml2_1.3.5        \n [5] KernSmooth_2.23-21 stringi_1.7.12     digest_0.6.33      magrittr_2.0.3    \n [9] evaluate_0.21      grid_4.3.1         fastmap_1.1.1      jsonlite_1.8.7    \n[13] e1071_1.7-13       DBI_1.1.3          purrr_1.0.1        fansi_1.0.4       \n[17] scales_1.2.1       cli_3.6.1          rlang_1.1.1        units_0.8-2       \n[21] commonmark_1.9.0   munsell_0.5.0      withr_2.5.0        yaml_2.3.7        \n[25] tools_4.3.1        colorspace_2.1-0   vctrs_0.6.3        R6_2.5.1          \n[29] proxy_0.4-27       lifecycle_1.0.3    classInt_0.4-9     htmlwidgets_1.6.2 \n[33] pkgconfig_2.0.3    pillar_1.9.0       gtable_0.3.3       glue_1.6.2        \n[37] Rcpp_1.0.11        xfun_0.39          tibble_3.2.1       tidyselect_1.2.0  \n[41] rstudioapi_0.15.0  knitr_1.43.1       farver_2.1.1       htmltools_0.5.5   \n[45] rmarkdown_2.23     compiler_4.3.1     markdown_1.7       gridtext_0.1.5"
  },
  {
    "objectID": "posts/2020-11-21-president-tilegram/index.html#footnotes",
    "href": "posts/2020-11-21-president-tilegram/index.html#footnotes",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDisclaimer: I am not a US citizen.↩︎\nThe object was created and named for the tilegrams by fivethirtyeight, a company named after the total count of electors in the US electoral college.↩︎"
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "",
    "text": "A pigeon does not belong inside a chimney."
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#tldr",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#tldr",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "tl;dr",
    "text": "tl;dr\nAnimals get stuck in weird places, just ask the London Fire Brigade. I used the {sf} package to handling some animal rescue spatial data prior to interactive mapping with {leaflet}."
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#the-problem",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#the-problem",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "The problem",
    "text": "The problem\nSometimes I need to convert coordinate data to latitude and longitude for interactive mapping using the {leaflet} package in R.\nI’m going to demo the {sf} package, show how to reproject coordinates, work with points and polygon data, make an interactive map with {leaflet} and do a bonus bit of webscraping."
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#special-features",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#special-features",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Special features",
    "text": "Special features\nThe {sf} (‘simple features’) package from Edzer Pebesma has a series of classes and methods for spatial data. The package is becoming popular because simple feature access is a widely-used multi-platform ISO standard and the package supports the popular tidy data paradigm and can be integrated with tidyverse operations. This and more was spelled out by Pebesma in a post from UseR! 2017.\nYou can read more about anlyses with {sf} in Geocomputation with R by Robin Lovelace, Jakub Nowosad and Jannes Muenchow."
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-animal-rescues",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-animal-rescues",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Data: animal rescues",
    "text": "Data: animal rescues\nI’ve found an interesting example dataset that contains eastings and northings: animal rescue incidents attended by the London Fire Brigade from the excellent London Data Store. In their words:\n\nThe London Fire Brigade attends a range of non-fire incidents (which we call ‘special services’). These ‘special services’ include assistance to animals that may be trapped or in distress.\n\nThis is close to my heart because a pigeon fell down our chimney recently. After a brave rescue mission (putting on some rubber gloves and contorting my arms through a tiny vent hole) I think I’m now qualified to join an elite search and rescue team.\n\nClean\nWe can read the data directly from the datastore as a CSV file.\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(janitor, warn.conflicts = FALSE)\n\ncsv_path &lt;- \"https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/01007433-55c2-4b8a-b799-626d9e3bc284/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv\"\n\nrescue &lt;- read_csv(csv_path, show_col_types = FALSE)\n\n# A sample of the rows and columns\nrescue %&gt;%\n  select(DateTimeOfCall, `IncidentNotionalCost(£)`, AnimalGroupParent, Borough) %&gt;%\n  slice_sample(n = 5)\n\n# A tibble: 5 × 4\n  DateTimeOfCall      `IncidentNotionalCost(£)` AnimalGroupParent     Borough   \n  &lt;dttm&gt;              &lt;chr&gt;                     &lt;chr&gt;                 &lt;chr&gt;     \n1 2020-06-14 12:05:00 346                       Bird                  WESTMINST…\n2 2022-12-31 18:53:00 728                       Cat                   BRENT     \n3 2017-06-16 21:19:00 328                       Cat                   SOUTHWARK \n4 2022-07-17 12:41:00 728                       Unknown - Wild Animal HARROW    \n5 2018-04-08 10:36:00 333                       Cat                   WALTHAM F…\n\n\nSo each row is an ‘incident’ to which the brigade were called and there’s 9728 of them recorded in the dataset. There are 31 columns for variables relating to incident, including when it was, what it was and where it was.\n\n Note\nThis post was first written in April 2018, but was re-rendered with the latest rescue data as of August 2023.\n\n\n\n\nExplore\nThis post isn’t about the dataset, but it’s worth having a closer look at it. I’ve added an interactive table below so you can search for incidents, creatures, locations and the notional cost of the callout.\n\n\n\n\n\n\n\nObviously there are plenty of cats up trees, but there’s so much more. Some of the more unique entries are:\n\nDOG WITH JAW TRAPPED IN MAGAZINE RACK\n\n\nSWAN IN DISTRESS\n\n\nFERRET STUCK IN LIFT SHAFT\n\nAnd of course:\n\nTWO DOGS IN TOILET ELDERLY LADY INVOLVED"
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-points",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-points",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Data: points",
    "text": "Data: points\nEach incident in our data is a point in space with an X and Y coordinate. It’s currently eastings and northings, but we want to transform it to latitude and longitude.\n\nThe sf class and reprojection\nA Coordinate Reference System (CRS) is required to project geographic entities – points, polygons, etc – onto a surface. There are many systems for doing this, from local to global, each with its own CRS code. This isn’t a post about geography and projections, but you can read more in the CRS chapter of rspatial.org.\nFirst we convert the our dataframe-class object an ‘sf’ class object using the st_as_sf function, which readies it for spatial analysis. We simply provide arguments that point to the columns containing the coordinates and the CRS code for that projection system.\nWe can then use the st_transform() function to convert our projection system from eastings and northings to to latitude and longitude.\n\nlibrary(sf, quietly = TRUE)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nrescue_sf &lt;- rescue %&gt;% \n  st_as_sf(\n    coords = c(\"Easting_rounded\", \"Northing_rounded\"),\n    crs = 27700  # coordinate reference system code for eastings/northings\n  ) %&gt;% \n  st_transform(crs = 4326)  # the coord ref system code for latlong\n\nSo what happened more specifically? Our eastings and northings were combined with st_as_sf() into a two element list-column called geometry with data type sfc_POINT. Our new sf-class object also contains some metadata detailing the geometry type – POINTS in our case – and the projection system of the coordinate data, which we converted to latlong with the st_transform() function.\n\n\nTidyverse manipulation\nAs mentioned, one advantage of using {sf} is that sf-class objects use the tidy data paradigm that allows for use of the tidyverse. Some users may prefer this relative to the ‘Spatial Points Data Frame’ (SPDF) class that is produced by the {sp} package for points data. SPDFs are an S4 class, which means they have ‘slots’ of data, coordinates, etc.\nIn the code chunk above I used pipes to pass the rescue dataframe to st_as_sf() and then to st_transform(). You can also use {dplyr} functions like filter() on your sf-class object.\n\nfiltered_rescue_sf &lt;- rescue_sf %&gt;%\n  filter(\n    AnimalGroupParent %in% c(\"Dog\", \"Cat\", \"Bird\"),  # just these animals\n    DateTimeOfCall &gt; ymd(\"2017-01-01\") &\n      DateTimeOfCall &lt; ymd(\"2017-12-31\")  # 2017 only\n  )\n\nWe can also use the st_coordinates() function to extract the XY (latitude and longitude) coordinates from the column containing our {sf} point geometry. This means we can have separate columns for the latitude and longitude, as well as our list-column.\n\nrescue_coords &lt;- as.data.frame(st_coordinates(filtered_rescue_sf))\nfiltered_rescue_sf &lt;- bind_cols(filtered_rescue_sf, rescue_coords)"
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-polygons",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#data-polygons",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Data: polygons",
    "text": "Data: polygons\n\nRead and convert GeoJSON\nWhile we’re messing around with the {sf} package we can investigate polygons by adding in the borders for each of the London boroughs from a GeoJSON file.\nFirst, read Local Authority District (LADs) data directly from the Open Geography Portal and then use the st_as_sf() function to make the conversion from the sp class to the sf class.\n\nsuppressPackageStartupMessages(library(geojsonio))\n\n# Download boundary data to temporary location\ngeojson_path &lt;- \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_May_2023_UK_BUC_V2/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\ntemp_geojson &lt;- tempfile(fileext = \".geojson\")\ndownload.file(geojson_path, temp_geojson, quiet = TRUE)\n\n# Read the geojson and convert to sf class\nlad_sf &lt;- temp_geojson %&gt;%\n  geojson_read(what = \"sp\") %&gt;% \n  st_as_sf()\n\nunlink(temp_geojson)  # discard temporary file\n\nThis means our polygon dataset is a tidy dataframe with the polygon information stored as MULTIPOLYGON type in a list-column with as many elements as required to draw each polygon (e.g. a square requires four sets of XY points that can be joined together). The outcome is very similar to what we had for our points data.\n\n\nScrape London boroughs\nBut which of these LADs are London boroughs? We can extract a vector of the boroughs from Wikipedia using the {rvest} package and use it to filter our data. The CSS selector used in the html_nodes() function below can be extracted using the very handy SelectorGadget tool.\n\nlibrary(rvest, warn.conflicts = FALSE)\nlibrary(xml2)\n\nwiki_page &lt;- \"https://en.wikipedia.org/wiki/List_of_London_boroughs\"\n\nboroughs &lt;- wiki_page %&gt;%\n  read_html() %&gt;% \n  html_nodes(css = \"td:nth-child(1) &gt; a\") %&gt;%\n  html_text() %&gt;% \n  tolower()\n\nboroughs_sf &lt;- lad_sf %&gt;% \n  mutate(LAD23NM = tolower(LAD23NM)) %&gt;% \n  filter(LAD23NM %in% boroughs)\n\nhead(boroughs_sf$LAD23NM)\n\n[1] \"city of london\"       \"barking and dagenham\" \"barnet\"              \n[4] \"bexley\"               \"brent\"                \"bromley\""
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#map-it",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#map-it",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Map it",
    "text": "Map it\nSo now we can plot the data. The addPolygons() function accepts each MULTIPOLYGON in the list-column of our London boroughs dataset. The addMarkers() function accepts the POINTS-type list-column to plot each point at the latitude and longitude specified.\nThis is a very simple map for now. You can:\n\nzoom with the + and - buttons or scroll with your mouse wheel\nclick and drag to move the map\nclick the points to get a pop-up showing more information\nhover over a borough to highlight it and show a label\n\n\nlibrary(leaflet)  # for interactive mapping\n\n# put the map together\nleaflet(boroughs_sf) %&gt;% \n  addProviderTiles(providers$Wikimedia) %&gt;%\n  addPolygons(  # add London borough boundaries\n    label = ~tools::toTitleCase(LAD23NM),  # label on hover\n    color = \"black\",  # boundary colour\n    weight = 2,  # boundary thickness\n    opacity = 1,  # fully opaque lines\n    fillOpacity = 0.2,  # mostly transparent\n    highlightOptions = highlightOptions(\n      color = \"white\",  # turn boundary white on hover\n      weight = 2,  # same as polygon boundary\n      bringToFront = TRUE  # overlay the highglight\n    )\n  ) %&gt;% \n  addAwesomeMarkers( # add incident points\n    lng = filtered_rescue_sf$X, lat = filtered_rescue_sf$Y,\n    icon = awesomeIcons(\n      library = \"ion\",  # from this icon library\n      icon = \"ion-android-alert\",  # use this icon\n      iconColor = \"white\",  # colour it white\n      # colour by animal\n      markerColor = case_when(  # different colours for each\n        filtered_rescue_sf$AnimalGroupParent == \"Dog\" ~ \"red\",\n        filtered_rescue_sf$AnimalGroupParent == \"Cat\" ~ \"blue\",\n        filtered_rescue_sf$AnimalGroupParent == \"Bird\" ~ \"black\"\n      )\n    ),\n    popup = ~paste0(  # display this information on click\n      \"&lt;b&gt;Animal&lt;/b&gt;: \", filtered_rescue_sf$AnimalGroupParent, \"&lt;br&gt;\",\n      \"&lt;b&gt;Incident&lt;/b&gt;: \", filtered_rescue_sf$FinalDescription, \"&lt;br&gt;\",\n      \"&lt;b&gt;Date&lt;/b&gt;: \", filtered_rescue_sf$DateTimeOfCall, \"&lt;br&gt;\",\n      \"&lt;b&gt;Borough&lt;/b&gt;: \", filtered_rescue_sf$Borough, \"&lt;br&gt;\",\n      \"&lt;b&gt;Notional cost&lt;/b&gt;: £\", filtered_rescue_sf$`IncidentNotionalCost(£)`\n    )\n  )\n\n\n\n\n\n Okay cool, we get a simple map of London with borough boundaries and markers showing incidents in 2017, with a different colour for each of three selected animal groups (red = dog, blue = cat, black = bird).\nMy main advice? Keep an eye on your pets. And consider covering your chimney."
  },
  {
    "objectID": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#environment",
    "href": "posts/2018-04-27-two-dogs-in-toilet-elderly-lady-involved/index.html#environment",
    "title": "TWO DOGS IN TOILET ELDERLY LADY INVOLVED",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 23:31:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] leaflet_2.1.2    xml2_1.3.5       rvest_1.0.3      geojsonio_0.11.1\n [5] sf_1.0-14        DT_0.28          janitor_2.2.0    lubridate_1.9.2 \n [9] forcats_1.0.0    stringr_1.5.0    dplyr_1.1.2      purrr_1.0.1     \n[13] readr_2.1.4      tidyr_1.3.0      tibble_3.2.1     ggplot2_3.4.2   \n[17] tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            xfun_0.39               bslib_0.5.0            \n [4] htmlwidgets_1.6.2       lattice_0.21-8          tzdb_0.4.0             \n [7] leaflet.providers_1.9.0 vctrs_0.6.3             tools_4.3.1            \n[10] crosstalk_1.2.0         generics_0.1.3          curl_5.0.1             \n[13] parallel_4.3.1          proxy_0.4-27            fansi_1.0.4            \n[16] pkgconfig_2.0.3         KernSmooth_2.23-22      lifecycle_1.0.3        \n[19] compiler_4.3.1          munsell_0.5.0           fontawesome_0.5.1      \n[22] snakecase_0.11.0        jqr_1.2.3               htmltools_0.5.5        \n[25] class_7.3-22            sass_0.4.7              lazyeval_0.2.2         \n[28] yaml_2.3.7              pillar_1.9.0            crayon_1.5.2           \n[31] jquerylib_0.1.4         ellipsis_0.3.2          classInt_0.4-9         \n[34] cachem_1.0.8            tidyselect_1.2.0        digest_0.6.33          \n[37] stringi_1.7.12          fastmap_1.1.1           grid_4.3.1             \n[40] colorspace_2.1-0        cli_3.6.1               magrittr_2.0.3         \n[43] crul_1.4.0              utf8_1.2.3              e1071_1.7-13           \n[46] withr_2.5.0             scales_1.2.1            sp_2.0-0               \n[49] bit64_4.0.5             timechange_0.2.0        httr_1.4.6             \n[52] rmarkdown_2.23          bit_4.0.5               hms_1.1.3              \n[55] evaluate_0.21           knitr_1.43.1            V8_4.3.3               \n[58] geojson_0.3.4           rlang_1.1.1             Rcpp_1.0.11            \n[61] httpcode_0.3.0          glue_1.6.2              DBI_1.1.3              \n[64] selectr_0.4-2           geojsonsf_2.0.3         rstudioapi_0.15.0      \n[67] vroom_1.6.3             jsonlite_1.8.7          R6_2.5.1               \n[70] units_0.8-2"
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html",
    "href": "posts/2019-09-20-say-package/index.html",
    "title": "How do you pronounce {dplyr}?",
    "section": "",
    "text": "Public Domain via wpclipart.com."
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html#tldr",
    "href": "posts/2019-09-20-say-package/index.html#tldr",
    "title": "How do you pronounce {dplyr}?",
    "section": "tl;dr",
    "text": "tl;dr\nIt’s ‘d-ply-r’ according to Hadley himself… maybe.\nWhat does it sound like when your computer tries to pronounce R package names? Is this an accessibility issue?"
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html#deep-liar",
    "href": "posts/2019-09-20-say-package/index.html#deep-liar",
    "title": "How do you pronounce {dplyr}?",
    "section": "Deep liar",
    "text": "Deep liar\nSometimes I hear a word being spoken and think ‘oh wait, is that how it’s actually pronounced?’\nI know people struggle with pronouncing R package names. They’re often hard to parse.\nIs {dplyr} ‘dee-ply-arr’ or ‘d’plier’? Is {data.table} ‘data table’ or ‘data-dot-table’?"
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html#speak-the-truth",
    "href": "posts/2019-09-20-say-package/index.html#speak-the-truth",
    "title": "How do you pronounce {dplyr}?",
    "section": "Speak the truth",
    "text": "Speak the truth\nHow does this affect users of assitive technology? VoiceOver is a macOS accessibility tool that helps people navigate their computers via audio. It reads text on a page. What happens when VoiceOver reads R package names?\nI used the say command at the command line to test this out. For example, you can type say dplyr to get your machine to interpret and vocalise ‘dplyr’.\nYou can add flags to the command to read text from an input file (-f) and then store the audio output (-o):\n\nsay -f input.txt -o output.wav\n\nI generated some audio of package names being read via say and embedded them in the sections below. These were:\n\nthe tidyverse\nthe top 20 downloads from CRAN\n20 random CRAN packages\n\nYou can download all the text and audio files as a zip file (note that the audio is in .wav format).\n\nTidyverse\nYou can get the tidyverse packages with the tidyverse_packages() function from the {tidyverse} package.\n\n\nClick for code\n\n\n# Fetch the packages of the tidyverse\ntidy_pkgs &lt;- tidyverse::tidyverse_packages()\ntidy_pkgs &lt;- gsub(\"\\n\\\\(&gt;=\", \"\", tidy_pkgs)  # replace rogue characters\n\n# Add terminal periods so that 'say' pauses between package names\ntidy_pkgs &lt;- paste0(tidy_pkgs, \".\")\n\n# Write the list to a text file\nwrite.table(\n  tidy_pkgs,\n  file = \"say_tidy.txt\",\n  row.names = FALSE,\n  col.names = FALSE\n)\n\n# Get say command to read from text file and output an audio file\nsystem(\"say -f say_tidy.txt -o say_tidy.wav\")\n\n\n\"broom\" \"cli\" \"crayon\" \"dplyr\" \"dbplyr\" \"forcats\" \"ggplot2\" \"haven\"\n\"hms\" \"httr\" \"jsonlite\" \"lubridate\" \"magrittr\" \"modelr\" \"purrr\" \"readr\"\n\"readxl\" \"reprex\" \"rlang\" \"rstudioapi\" \"rvest\" \"stringr\" \"tibble\"\n\"tidyr\" \"xml2\" \"tidyverse\"\n\n\n\n\n\n\n\nCRAN top 20\nYou can get the top 20 downloads from CRAN in the last month with the cran_top_downloads() function from the {cranlogs} package.\n\n\nClick for code\n\n\n# Fetch the top 20 downloaded packages from CRAN in past month\ncran_top_pkgs &lt;- cranlogs::cran_top_downloads(when = \"last-month\", count = 20)\n\n# Add terminal periods so that 'say' pauses between package names\ncran_top_pkgs$package &lt;- paste0(cran_top_pkgs$package, \".\")\n\n# Write the list to a text file\nwrite.table(\n  cran_top_pkgs$package,\n  file = \"say_cran_top.txt\",\n  row.names = FALSE,\n  col.names = FALSE\n)\n\n# Get say command to read from text file and output an audio file\nsystem(\"say -f say_cran_top.txt -o say_cran_top.wav\")\n\n\n\"magrittr\" \"aws.s3\" \"aws.ec2metadata\" \"rsconnect\" \"rlang\" \"Rcpp\" \"dplyr\"\n\"ggplot2\" \"ellipsis\" \"vctrs\" \"tibble\" \"digest\" \"glue\" \"pillar\" \"zeallot\"\n\"backports\" \"stringr\" \"markdown\" \"fansi\" \"stringi\"\n\n\n\n\n\n\n\nRandom CRAN packages\nYou can get the full list of packages currently on CRAN with the CRAN_package_db() function in the {tools} package (part of base R).\n\n\nClick for code\n\n\n# Fetch and clean CRAN packages\ncran &lt;- tools::CRAN_package_db()\n\n# Select random packages\nset.seed(1337)\ncrandom_pkgs &lt;- sample(cran$Package, size = 20)\n\n# Add terminal periods so that 'say' pauses between package names\ncrandom_pkgs &lt;- paste0(cran_rand_pkgs, \".\")\n\n# Write the list to a text file\nwrite.table(\n  crandom_pkgs,\n  file = \"~/Desktop/say_cran_random.txt\",\n  row.names = FALSE,\n  col.names = FALSE\n)\n\n# Get say command to read from text file and output an audio file\nsystem(\"say -f ~/Desktop/say_cran_random.txt -o ~/Desktop/say_cran_random.wav\")\n\n\n\"NScluster\" \"nlnet\" \"Bivariate.Pareto\" \"lisa\" \"homtest\" \"glarma\" \"ttdo\"\n\"flock\" \"equSA\" \"coreCT\" \"WEE\" \"xtable\" \"shinyKGode\" \"DiffNet\" \"WGCNA\"\n\"aqfig\" \"Voss\" \"tidymv\" \"gogarch\" \"erp.easy\""
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html#results",
    "href": "posts/2019-09-20-say-package/index.html#results",
    "title": "How do you pronounce {dplyr}?",
    "section": "Results",
    "text": "Results\nObviously there’s a lot of subjectivity, but what was strange to your ears? To my southern English ears, it seems like there were a few patterns:\n\nEnglish word pronounced as expected: {haven}, {broom} and {glue}\nAmerican English: {crayon} (‘crain’)\nunexpected English parsing: {lubridate} (‘loobridot’)\nthe trouble with ‘tidy’: {tidyr} (‘tid-ear’ instead of ‘tidy-arr’) and {tidyverse} (‘tid-a-verse’ instead of ‘tidy-verse’)\nthe trouble wirh ‘r’: {rvest}, {rlang} and {rstudioapi} (‘r’ not pronounced as ‘arr’ in any of these)\nthe trouble with ‘read’: {readr} and {readxl} (‘reed’ becomes ‘ree-add’ because the whole thing is being read as one word)\nspelled out: {vctrs} (rather than ‘vectors’ in a New Zealand accent)\nwhat the actual heck: {ttdo} (I think it tries to pronounce the whole thing)\n\nAnd what about {dplyr}? Well, it was something like ‘d’pleur’. I’m pretty sure that’s not quite right.\nOf course, there are other text-to-speech engines, which may interpret and synthesise words differently. For example, espeak vocalises {dplyr} as ‘deepler’ which is definitely not right.\nIf you’re a user of assistive technology, does the way the machine reads the package names impact your pronunciation of the package name?"
  },
  {
    "objectID": "posts/2019-09-20-say-package/index.html#environment",
    "href": "posts/2019-09-20-say-package/index.html#environment",
    "title": "How do you pronounce {dplyr}?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-24 21:21:51 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html",
    "title": "Markov-chaining my PhD thesis II",
    "section": "",
    "text": "This is science, I promise."
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#tldr",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#tldr",
    "title": "Markov-chaining my PhD thesis II",
    "section": "tl;dr",
    "text": "tl;dr\nIn which a Markov chain perfectly summarises my entire PhD thesis:\n\nIn general, litter chemical composition and decomposition."
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#markovifyr",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#markovifyr",
    "title": "Markov-chaining my PhD thesis II",
    "section": "{markovifyR}",
    "text": "{markovifyR}\nI posted a while back about using a Markov chain to generate sentences using my PhD thesis as input. I also posted about the {markovifyR} package for generating lyrics by The Mountain Goats.\nThis is a quick update to that original post, but this time I’m using {markovifyR}."
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#some-code",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#some-code",
    "title": "Markov-chaining my PhD thesis II",
    "section": "Some code",
    "text": "Some code\nThe PhD text is available from my {dray} package on GitHub:\n\nremotes::install_github(\"matt-dray/dray\")\n\nI’ll remove the blank lines and ignore the preamble and references section. As a reminder, the thesis is about the decomposition of tree litter that’s been exposed to environmental stressors like elevated carbon dioxide levels and acidified streams.\n\nphd_text &lt;- dray::phd  # get data\nphd_text &lt;- phd_text[nchar(phd_text) &gt; 0]  # remove blank lines\nphd_text &lt;- phd_text[27:376]  # ignore preamble and references\nphd_text[1:2]\n\n[1] \"Acknowledgements\"                                                                                                   \n[2] \"The study of rotting detritus is not for the faint-hearted. I am indebted to many people for their help and advice.\"\n\n\nNow to prepare the work space. {markovifyR} is a wrapper of the markovify Python module. You first need to install markovify. You can do this from the command line with pip3 install markovify, for example (though this will depend on the version of Python you have). You can also run command-line code from R with a call to system():\n\nsystem(\"pip3 install markovify\")\n\nAnd then ensure you’ve installed {markovifyR} from GitHub and also the dependency {furrr}.\n\nlibrary(markovifyR)   # remotes::install_github(\"abresler/markovifyR\")\nlibrary(furrr)  # install.packages(\"furrr\")\n\nThe function generate_markovify_model() builds the model and markovify_text() generate some sentences based on that model.\n\n# Build model\nmarkov_model &lt;- generate_markovify_model(\n  input_text = phd_text,\n  markov_state_size = 2L,\n  max_overlap_total = 25,\n  max_overlap_ratio = 0.7\n)\n\n# Generate lines\nphd_speak &lt;- markovify_text(\n  markov_model = markov_model,\n  maximum_sentence_length = NULL,\n  output_column_name = \"phd_speak\",\n  count = 50,\n  tries = 50,\n  only_distinct = TRUE,\n  return_message = FALSE\n)\n\nhead(phd_speak)\n\n# A tibble: 6 × 2\n  idRow phd_speak                                                               \n  &lt;int&gt; &lt;chr&gt;                                                                   \n1     1 Initial lignin concentrations after 268 days were compared by pairwise …\n2     2 5.3.1 Leaf litter growth condition on any measure of invertebrate feedi…\n3     3 It is, however, generally patchy in time and space, making it difficult…\n4     4 Specifically, it considers how elevated atmospheric CO2, and rural litt…\n5     5 Conversely to lignin, carbon and nutrient storage in both the aquatic s…\n6     6 Bag positions were randomised within each species were selected to repr…\n\n\nI haven’t spent much time tweaking the arguments in generate_markovify_model(), but the results are pretty amusing anyway."
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#robo-thesis",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#robo-thesis",
    "title": "Markov-chaining my PhD thesis II",
    "section": "Robo-thesis",
    "text": "Robo-thesis\nI ran this a few times and picked some favourites.\n\n\n\n\n\n\n\nOutput\nHot take\n\n\n\n\nIn general, litter chemical composition and decomposition.\nThis is the ultimate summary of my thesis.\n\n\nThis thesis is the total nitrogen content of the North American Benthological Society.\nI’m sure the NABS has more nitrogen in its possession.\n\n\nThis simplicity has allowed for broad underlying principles to be linked to litter chemical composition differently depending on whether it was exposed to a labeled 0.5 m steel rod.\nHoly smokes, who knew that the steel rods were the deciding factor? Were they radioactive or something?\n\n\nDeciduous woodlands are dependent on the parent tree.\nYes, all deciduous woodlands have one central master tree from which all the others are descended.\n\n\nCurrently there is a key ecosystem process in temperate deciduous woodlands and streams.\nYes, but what is it? I must know!\n\n\nCanadian Journal of the laboratory in a randomly-ordered 3 × 3 grid.\nThat is one niche academic journal.\n\n\nI am grateful for the choice test.\nI designed and ran it, so I have only myself to thank.\n\n\nMy parents have never wavered in their responses, suggesting that caution has to be available online in the CEF.\nIt seems the Controlled Environment Facility (CEF) cannot control for the effect of parental input; best to provide some guidance on what to do if parental influence is strong.\n\n\nBonferroni-adjusted critical significance levels were compared by pairwise PERMANOVA.\nThat sure sounds like statistics!\n\n\nThis reduced decomposition rate in the University’s Open Access repository and for inter-library loan, and for inter-library loan, and for inter-library loans.\nAh good, slower-decomposing books will last longer; apparently this is important for inter-library loans?"
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#very-science-much-thesis",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#very-science-much-thesis",
    "title": "Markov-chaining my PhD thesis II",
    "section": "Very science, much thesis",
    "text": "Very science, much thesis\nOnce again, simply copy and paste several of these sentences into your own thesis. The benefit is that you won’t have to grow any trees in a high carbon-dioxide atmosphere; you won’t have to spend months packing leaves into tiny bags; you won’t have to attach those bags to tens of IKEA cutlery holders and dunk them in frozen streams in mid-Wales; you won’t have to grind those leaves into a suspicious-looking powder and transport them cross-country for chemical analyses; you won’t have to imprison any insects against their will. You are welcome.\nGood luck at your viva!"
  },
  {
    "objectID": "posts/2019-04-30-markov-chain-phd-2/index.html#environment",
    "href": "posts/2019-04-30-markov-chain-phd-2/index.html#environment",
    "title": "Markov-chaining my PhD thesis II",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 14:11:58 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1      furrr_0.3.1      future_1.33.0    markovifyR_0.102\n\nloaded via a namespace (and not attached):\n [1] Matrix_1.5-4.1     jsonlite_1.8.7     dplyr_1.1.2        compiler_4.3.1    \n [5] plotrix_3.8-2      tidyselect_1.2.0   Rcpp_1.0.11        stringr_1.5.0     \n [9] parallel_4.3.1     png_0.1-8          globals_0.16.2     yaml_2.3.7        \n[13] fastmap_1.1.1      here_1.0.1         lattice_0.21-8     reticulate_1.30   \n[17] R6_2.5.1           generics_0.1.3     dray_0.0.0.9000    knitr_1.43.1      \n[21] htmlwidgets_1.6.2  tibble_3.2.1       rprojroot_2.0.3    pillar_1.9.0      \n[25] RColorBrewer_1.1-3 rlang_1.1.1        utf8_1.2.3         wordcloud_2.6     \n[29] stringi_1.7.12     xfun_0.39          cli_3.6.1          withr_2.5.0       \n[33] magrittr_2.0.3     grid_4.3.1         digest_0.6.33      rstudioapi_0.15.0 \n[37] lifecycle_1.0.3    vctrs_0.6.3        evaluate_0.21      glue_1.6.2        \n[41] listenv_0.9.0      codetools_0.2-19   parallelly_1.36.0  fansi_1.0.4       \n[45] gifski_1.12.0-1    rmarkdown_2.23     tools_4.3.1        pkgconfig_2.0.3   \n[49] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2023-11-01-qr-enabled-fn/index.html",
    "href": "posts/2023-11-01-qr-enabled-fn/index.html",
    "title": "Unlock R functions with QR codes",
    "section": "",
    "text": "Uh uh uh! (Jurassic Park via BJ22CS)"
  },
  {
    "objectID": "posts/2023-11-01-qr-enabled-fn/index.html#tldr",
    "href": "posts/2023-11-01-qr-enabled-fn/index.html#tldr",
    "title": "Unlock R functions with QR codes",
    "section": "tl;dr",
    "text": "tl;dr\nWhat if (hear me out) you could prevent an R function from operating correctly unless the user presents a specific QR code?"
  },
  {
    "objectID": "posts/2023-11-01-qr-enabled-fn/index.html#qr-you",
    "href": "posts/2023-11-01-qr-enabled-fn/index.html#qr-you",
    "title": "Unlock R functions with QR codes",
    "section": "QR you?",
    "text": "QR you?\nJeroen announced that the latest version of the {opencv} package is capable of detecting and decoding a QR code.\nSo this means we could write a function that only returns an answer when you introduce a QR code that encodes the correct ‘password’.\n\nadd_one &lt;- function(n) {\n  \n  string_in &lt;- opencv::qr_scanner()\n  password &lt;- RCurl::base64Decode(\"b3BlbmN2IHNlc2FtZSE=\")\n  \n  if (string_in == password) {\n    cat(\"🔑 Correct password!\\n\")\n    n + 1\n  } else {\n    stop(\"Wrong password!\", call. = FALSE)\n  }\n  \n}\n\nSo add_one() uses the qr_scanner() function to find and read a QR code from a video image and compare that to a password before giving the answer. You can see in the function body that I’ve only mildly obfuscated the password, using base64 encoding. Maybe you can do something more secure?\nNow to run the function:\n\nadd_one(1)\n\nStarting video window (could be behind this window)\nThis will activate your device’s camera and it will keep looking for a QR code before it runs the rest of the code in the function.\nThe ‘correct’ QR code (made with {qrcode}) is this one:\n\n\n\nMaybe this is a rickroll, who knows?\n\n\nIf you then scan this QR code with your device you’ll get an answer:\nCorrect password!\n[1] 2\nHere’s a gif of the process:\n\n\n\nHalloween special: the QR code appears like a jumpscare\n\n\nThe add_one() function was run, my laptop’s camera opened and then I showed it the QR code on my phone. The code was detected super quickly and the correct answer was returned in the console.\nI think there’s a lot of promise in this approach for helping to monetise your R package!\n\n Note\nAs Jeroen and Dan pointed out: you could use this to create an R-based multi-factor authentication solution by introducing {otp} and {ntfy} into the mix.\nI also wanted to mention Tom’s talk at the recent NHS-R conference. Tom had fun building a conference check-in service with personalised QR codes, making use of {plumber} and {blastula} in the back end."
  },
  {
    "objectID": "posts/2023-11-01-qr-enabled-fn/index.html#environment",
    "href": "posts/2023-11-01-qr-enabled-fn/index.html#environment",
    "title": "Unlock R functions with QR codes",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-11-01 10:23:17 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.25    knitr_1.44        jsonlite_1.8.7    xfun_0.40        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.2 evaluate_0.22"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html",
    "href": "posts/2020-06-06-acnh-swipe/index.html",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "",
    "text": "Lily &lt;3 4eva"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#tldr",
    "href": "posts/2020-06-06-acnh-swipe/index.html#tldr",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "tl;dr",
    "text": "tl;dr\nThe villagers of Animal Crossing: New Horizons are taking part in a popularity contest and you’re the judge.\nI made an R Shiny app where you swipe right if you like a randomly-presented villager and left if you dislike them.\nVisit the app here and help decide the most popular villager! You can also visit the source code."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#tidy-tuesday",
    "href": "posts/2020-06-06-acnh-swipe/index.html#tidy-tuesday",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Tidy Tuesday",
    "text": "Tidy Tuesday\nTidy Tuesday is an open event for the R community. The organisers provide a data set and participants submit their take on wrangling and presenting the data, usually via Twitter with the hashtag #tidytuesday.\nA recent data set (week 19) via VillagerDB includes information about villager non-player characters from the wildly popular Animal Crossing: New Horizons game for the Nintendo Switch. A similar set of data was also uploaded to Kaggle.\nI couldn’t resist, having recently written about learning R6 object-oriented programming with an Animal Crossing example.\nThis was also a good chance to learn more about two packages in particular: {shinysense} and {googlesheets4}.\n\n{shinysense}\nNick Strayer‘s {shinysense} package lets Shiny ’sense the world around it’, with modules for touch, vision, hearing and motion.\nI wanted to try out shinyswipr, which presents a user with a ‘card’ that they can swipe. The direction of swiping can be used to indicate something, like a preference. After swiping, the card content can be updated.\nYou can read Nick’s blog post about its inception.\n\n\n{googlesheets4}\nIn Nick’s shinyswipr example, he presents back to the user their swipe history, but how can we record the information from all users and return the collated results?\nThere’s a number of ways to do persistent storing with Shiny, but a relatively simple one is to write the data to Google Sheets and read the entire sheet back into the app.\nThe {googlesheets4} package by Jenny Bryan helps you do exactly that, with functions like sheet_append() and read_sheet()."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#the-acnh-popularity-contest",
    "href": "posts/2020-06-06-acnh-swipe/index.html#the-acnh-popularity-contest",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "The ACNH Popularity Contest",
    "text": "The ACNH Popularity Contest\nThere’s a lot of articles online about favourite villagers, but they aren’t very democratic. They tend to cite characters like Raymond, Beau, Marshal, Judy and Audie.\nIt’s time to let the people speak."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#how-to-use",
    "href": "posts/2020-06-06-acnh-swipe/index.html#how-to-use",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "How to use",
    "text": "How to use\nIf you visit the app, or look at the image at the top of this post, you’ll see that the user is presented with a card containing a randomly-selected villager and some details (name, species, personality and hobby).\nYou can move the card to the right to indicate you like the character, or to the left if you dislike them. On mobile you can swipe left or right with your finger. On desktop you can click and drag the card.\n\n\n\nNo dates guaranteed. The characters aren’t actually real, y’see.\n\n\nThe swipe event results in the information being written to a Google Sheet and triggers the entirety of the updated data set to be read back to the app. It’s then wrangled lightly and the information is presented as a table of the current top 10 villagers by ‘like’ count. Finally, a new random villager is presented.\nThis is obviously a bit of fun and definitely not polished. Do let me know of any bugs that you find, though. I’m aware that mobiles may not display the fonts correctly, for example.\n\nData and hosting\nNo data about the user is stored. The app records only the date-time, the villager name and the swipe direction.\nThe app is hosted for free on shinyapps.io, so there’s a limited number of uptime hours it can use per month."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#results",
    "href": "posts/2020-06-06-acnh-swipe/index.html#results",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Results",
    "text": "Results\nI hope that enough people cast a vote to make the results interesting… but there’s nearly 400 villagers, so that seems unlikely!\n\n Note\nI’ve written a more recent post where I aggregated the results for the thousands of swipes that people made in the app!"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#environment",
    "href": "posts/2020-06-06-acnh-swipe/index.html#environment",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:47:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#tldr",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#tldr",
    "title": "The most popular Animal Crossing villagers",
    "section": "tl;dr",
    "text": "tl;dr\nI once wrote an R Shiny app to run a popularity contest for Animal Crossing villagers. Surprise: cute ones are favourites."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#swiping-shinyswipe-code",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#swiping-shinyswipe-code",
    "title": "The most popular Animal Crossing villagers",
    "section": "Swiping {shinyswipe} code",
    "text": "Swiping {shinyswipe} code\nA while back I wrote a Shiny app (site, source, blogpost) for TidyTuesday to replicate a Tinder-like experience using villagers from Nintendo’s Animal Crossing New Horizons game. It uses the swipe mechanic from Nick Strayer’s {shinysense} package to gauge popularity: left for a ‘dislike’, right for a ‘like’.\nAfter exceeding 3000 total swipes, it’s time to take a look at the results.\n\n Note\nI re-rendered this post in July 2023 when there were about 6000 swipes(!)."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#oh-sheet",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#oh-sheet",
    "title": "The most popular Animal Crossing villagers",
    "section": "Oh sheet",
    "text": "Oh sheet\nData from each swipe in the app is automatically appended to a public Google Sheets sheet that can be read with {googlesheets4}. Public sheets don’t require authentication to download, so run gs4_deauth() before read_sheet() to prevent it.\n\nlibrary(googlesheets4)\ngs4_deauth()\n\nraw &lt;- read_sheet(\n  ss = \"1kMbmav6XvYqnTO202deyZQh37JeWtTK4ThIXdxGmEbs\",\n  col_types = \"Tcc\"  # datetime, char, char\n)\n\n✔ Reading from \"acnh-swipe_results\".\n\n\n✔ Range 'Sheet1'.\n\n\nFirst thing is to isolate the left and right swipes only. The {shinysense} package also allows for up and down swipes by default and I wasn’t sure how to remove this capability from my app (and was too lazy to work it out).\n\ndat &lt;- raw[raw$swipe %in% c(\"left\", \"right\"), ]\ndat[sample(rownames(dat), 5), ]  # random sample\n\n# A tibble: 5 × 3\n  date                name     swipe\n  &lt;dttm&gt;              &lt;chr&gt;    &lt;chr&gt;\n1 2021-12-01 01:09:52 Wart Jr. left \n2 2022-12-03 00:41:01 Dora     left \n3 2022-01-09 22:38:01 Pango    left \n4 2021-05-14 22:58:52 Bertha   right\n5 2022-12-03 00:41:42 Rosie    left \n\n\nThe data are one row per swipe, with columns for date (datetime of when the swipe happened), name (the villager’s name) and swipe (the swipe direction).\nBut what we’re really after is a grouped table with a row per villager, plus new columns for the total number of swipes, the difference between right and left swipes and the percentage of swipes that were to the right (pc_right). These will let us better rank the characters.\n\ndf &lt;- with(dat, table(name, swipe)) |&gt;  # like dplyr::count()\n  as.data.frame(responseName = \"n\") |&gt;\n  reshape(  # like tidyr::pivot_*()\n    v.names   = \"n\",      # values_from\n    idvar     = \"name\",   # id_cols\n    timevar   = \"swipe\",  # names_from\n    direction = \"wide\",   # i.e. pivot_wider()\n    sep       = \"_\"       # names_sep\n  ) |&gt; \n  transform(  # like dplyr::mutate()\n    total    = n_left + n_right,\n    diff     = n_right - n_left,\n    pc_right = 100 * round(n_right / (n_right + n_left), 2)\n  )\n\nhead(df)\n\n     name n_left n_right total diff pc_right\n1 Admiral     14       4    18  -10       22\n2 Agent S     10       4    14   -6       29\n3   Agnes     14       8    22   -6       36\n4      Al     13       3    16  -10       19\n5 Alfonso      6       7    13    1       54\n6   Alice      8       8    16    0       50\n\n\n\n\nClick to expand code explanation\n\nI think most readers of this blog are probably {tidyverse} users, so I’ll explain some of the base R approach I took here:\n\nI’ve used the base pipe (|&gt;) introduced in R v4.1 to chain the functions, which is analogous to {magrittr}’s pipe (%&gt;%) in this example\nwith() allows the bare column names in table() to be evaluated as columns of dat, which means you only write the name of the data object once\na table() coerced with as.data.frame() is equivalent to dplyr::count(), basically\nreshape() can be used like tidyr::pivot_wider() (I’ve added comments in the code block above to show how the arguments are used)\nturns out that transform() can be used like dplyr::mutate() to create new columns, thought the help files say it should only be used for interactive and that ‘you deserve whatever you get!’\n\n\nWe can also bring in some additional villager data collected for TidyTuesday and join it to the swipe data. This will come in useful later.\n\ntt &lt;- read.csv(\n  paste0(\n    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/\",\n    \"2e9bd5a67e09b14d01f616b00f7f7e0931515d24/data/\",\n    \"2020/2020-05-05/villagers.csv\"\n  )\n)\n\ndf &lt;- merge(df, tt, by = \"name\")"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#new-horizons-scanning",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#new-horizons-scanning",
    "title": "The most popular Animal Crossing villagers",
    "section": "New Horizons scanning",
    "text": "New Horizons scanning\nThere are 391 villagers represented in these data, with a combined total of 5950 legitimate swipes.\nThe total swipes per villager ranged from 7 to 29, with a mean of 15.2±3.9, so some characters didn’t really get enough swipes for proper assessment. You’d better go to the app and add some more swipes, eh?\n\npar(bg = \"lightgreen\")\nhist(\n  df$total,\n  main = \"Distribution of total swipes per villager\",\n  xlab = \"Total swipes\",\n  col = \"lightblue\",\n  las = 1\n)\n\n\n\n\nWhat if we look now at right swipes (i.e. ‘likes’), adjusted for the total swipes per character?\n\npar(bg = \"lightgreen\")\nhist(\n  df$pc_right,\n  main = \"Distribution of right swipes per villager\",\n  xlab = \"Right swipes (%)\",\n  col = \"lightblue\",\n  las = 1\n)\n\n\n\n\nYou can see that the distribution isn’t quite normal. The frequency of swipes below 50% is 297 and above 50% is 83. This implies that the majority of characters were disliked in a binary sense.\nThe bins at 0 and 100% tell you that there were some characters that were met with universal disapproval and approval, while the bin at 50% tells us that same characters split people’s opinions. Which were they?"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#drumroll-please",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#drumroll-please",
    "title": "The most popular Animal Crossing villagers",
    "section": "Drumroll, please",
    "text": "Drumroll, please\nSo, onto the villager rankings.\nI’ve written a little function to output an HTML table where each character’s name links to their profile on the Animal Crossing Wiki and exposes their photo from VillagerDB.\n\nentable &lt;- function(df) {\n  df$url &lt;- paste0(\n    \"&lt;img src='\", df$url, \"' \",\n    \"width=50 \",\n    \"alt='Animal Crossing villager \", df$name,\"'&gt;\"\n  )\n  df$name &lt;- paste0(\n    \"&lt;a href='https://animalcrossing.fandom.com/wiki/\",\n    df$name, \"'&gt;\", df$name, \"&lt;/a&gt;\"\n  )\n  df &lt;- df[, c(\"name\", \"url\", \"pc_right\", \"total\")]\n  names(df) &lt;- c(\"Name\", \"Picture\", \"Right swipes (%)\", \"Total swipes\")\n  rownames(df) &lt;- NULL\n  knitr::kable(df)\n}\n\n\nLeast popular\nTo build tension, we’ll start with the least-liked villagers.\n\nbot &lt;- df[order(df$pc_right, -df$n_left), ] |&gt; head()\nentable(bot)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nPinky\n\n0\n23\n\n\nCashmere\n\n0\n17\n\n\nLeonardo\n\n0\n16\n\n\nWalt\n\n0\n16\n\n\nHarry\n\n0\n14\n\n\nBenedict\n\n0\n13\n\n\n\n\n\nSorry Pinky. You are simply… too pink? Seems harsh.\n\n\nMost polarising\nTo build even more tension, let’s look at the characters who had a 50:50 ratio of likes to dislikes.\n\nmeh &lt;- subset(df[order(-df$total), ], diff == 0) |&gt; head()\nentable(meh)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nAlice\n\n50\n16\n\n\nHopkins\n\n50\n16\n\n\nHornsby\n\n50\n16\n\n\nMelba\n\n50\n16\n\n\nCherry\n\n50\n14\n\n\nGoose\n\n50\n14\n\n\n\n\n\nI’m not sure why these villagers are so controversial Perhaps they’re too ‘plain’ for some people?\n\n\nMost popular\nAnd finally, what you’ve all been waiting for.\n\ntop &lt;- df[order(-df$pc_right, -df$n_right), ] |&gt; head()\nentable(top)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nKiki\n\n89\n9\n\n\nFrobert\n\n85\n20\n\n\nBea\n\n85\n13\n\n\nZell\n\n83\n23\n\n\nJulia\n\n82\n17\n\n\nFauna\n\n80\n15\n\n\n\n\n\nSo: Kiki, the grandad-jumper-wearing black-void cat, has the best ratio of right to left-swipes! The rest of the list are pretty conventionally cute (though Zell looks pretty aloof)."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#speciesism",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#speciesism",
    "title": "The most popular Animal Crossing villagers",
    "section": "Speciesism!",
    "text": "Speciesism!\nI know what you’re thinking: the results are on a villager-by-villager basis, but which species are the most popular? We can aggregate swipes and take a look.\n\nsp_l &lt;- aggregate(n_left ~ species, sum, data = df)\nsp_r &lt;- aggregate(n_right ~ species, sum, data = df)\nsp_n &lt;- with(df, table(species)) |&gt; \n  as.data.frame(responseName = \"n_villagers\")\n\nsp &lt;- sp_n |&gt; \n  merge(sp_l, by = \"species\") |&gt; \n  merge(sp_r, by = \"species\") |&gt; \n  transform(\n    total = n_right + n_left,\n    pc_right = 100 * round(n_right / (n_right + n_left), 2)\n  )\n\n\n\nClick to expand code explanation\n\nA couple more base functions here for those not used to them:\n\naggregate() is like dplyr::group_by() followed by dplyr::summarise() and it allows for compact ‘formula syntax’, so we can say ‘aggregate y by x’ with y ~ x\nmerge() is just like the dplyr::*_join() family\n\n\nSo, firstly, the species ranked by lowest proportion of right swipes.\n\nsp_bot &lt;- sp[order(sp$pc_right, -sp$n_left), ]\nrownames(sp_bot) &lt;- NULL\nhead(sp_bot)\n\n   species n_villagers n_left n_right total pc_right\n1    mouse          15    172      24   196       12\n2    hippo           7     86      19   105       18\n3   monkey           8    110      26   136       19\n4 kangaroo           8    114      29   143       20\n5      pig          15    178      46   224       21\n6     bear          15    172      47   219       21\n\n\nI can see how monkeys and hippos might not be that ‘cute’, per se, but what about the mice? Although ‘cute’ is probably not the best term for the cranky mouse Limberg (sorry Limberg).\nWhat about the most liked species?\n\nsp_top &lt;- sp[order(-sp$pc_right, sp$n_right), ]\nrownames(sp_top) &lt;- NULL\nhead(sp_top)\n\n  species n_villagers n_left n_right total pc_right\n1    deer          10     85      96   181       53\n2     dog          16    104     115   219       53\n3 octopus           3     22      24    46       52\n4     cat          23    190     191   381       50\n5 ostrich          10     79      72   151       48\n6     cub          16    133     104   237       44\n\n\nDeer (all-around solid designs) and dogs (generally friend-shaped) top the table.\nOctopuses are up there too, although there’s relatively few octopus villagers. Personally, I like Zucker, an octopus who looks like takoyaki and therefore delicious.\nThis wasn’t meant to be about villager tastiness, was it? We may need a new app to rank by apparent edibility…"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#environment",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#environment",
    "title": "The most popular Animal Crossing villagers",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:18:03 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] googlesheets4_1.1.1\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       httr_1.4.6        cli_3.6.1         knitr_1.43.1     \n [5] rlang_1.1.1       xfun_0.39         purrr_1.0.1       generics_0.1.3   \n [9] jsonlite_1.8.7    glue_1.6.2        gargle_1.5.1      htmltools_0.5.5  \n[13] fansi_1.0.4       rmarkdown_2.23    cellranger_1.1.0  evaluate_0.21    \n[17] tibble_3.2.1      fontawesome_0.5.1 fastmap_1.1.1     yaml_2.3.7       \n[21] lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2       fs_1.6.2         \n[25] pkgconfig_2.0.3   htmlwidgets_1.6.2 rstudioapi_0.15.0 digest_0.6.31    \n[29] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        curl_5.0.1       \n[33] pillar_1.9.0      magrittr_2.0.3    tools_4.3.1       googledrive_2.1.1"
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html",
    "href": "posts/2019-11-01-usethis/index.html",
    "title": "Build an R package with {usethis}",
    "section": "",
    "text": "Ossie, a Cabinet Office cat (via @cabinetofficeuk on Twitter)."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#tldr",
    "href": "posts/2019-11-01-usethis/index.html#tldr",
    "title": "Build an R package with {usethis}",
    "section": "tl;dr",
    "text": "tl;dr\n\nI gave a talk (slides, source) about creating an R package with helper functions from the {usethis} package.\nIn the session I created a new package from scratch called {cabinet} (source, website) for identifying the cats that live in the UK Government’s Cabinet Office."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#coffee-packaging",
    "href": "posts/2019-11-01-usethis/index.html#coffee-packaging",
    "title": "Build an R package with {usethis}",
    "section": "Coffee packaging",
    "text": "Coffee packaging\nI gave a talk at a Cabinet Office Coffee & Coding session about building R packages from scratch. The emphasis was on the {usethis} package, which contains lots of package-setup functions that make your life easier.\nThe focus is on beginners who may never have written a package before.\nClick on the slides embedded below and cycle through with your arrow keys, or you can open them fullscreen in a dedicated browser tab. Press the P button your keyboard to see the presenter notes.\n\n\n\n\n\n\n\n\nI made the slides using Yihui Xie’s {xaringan} implementation of remark.js and I used my own {gdstheme} package for the theme (read the blog or see the source on GitHub)."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#talk-summary",
    "href": "posts/2019-11-01-usethis/index.html#talk-summary",
    "title": "Build an R package with {usethis}",
    "section": "Talk summary",
    "text": "Talk summary\nBasically you can make a minimal R package with only:\n\nusethis::create_package() to set up the minimal package structure\nusethis::create_r() to set up a script for your functions\ndevtools::document() to generate minimal documentation from your files\n\nThe {usethis} package also helps you set up internal and long-form documentation, testing, version control, a GitHub repository and more. {pkgdown} even generates a website from your documentation to make it more user-friendly."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#cat-egorise",
    "href": "posts/2019-11-01-usethis/index.html#cat-egorise",
    "title": "Build an R package with {usethis}",
    "section": "Cat-egorise",
    "text": "Cat-egorise\nIn the session I live-built a package called {cabinet}. You can:\n\nlook at the package’s source code on GitHub\nsee the package’s website, made with {pkgdown}\ninstall the package yourself\n\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/cabinet\")\n\nThe package only has one (very important) function, cabinet_cat(), which checks whether a supplied character string matches the name of either of the Cabinet Office’s cats.\nLike:\n\nlibrary(cabinet)\ncabinet_cat(\"Ossie\")\n\nOssie is a good Cabinet Office kitty.\n\ncabinet_cat(\"Larry\")\n\nLarry isn't a Cabinet Office cat!\n\ncabinet_cat(\"Garfield\")\n\nYou've much to learn about government cats."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#resources",
    "href": "posts/2019-11-01-usethis/index.html#resources",
    "title": "Build an R package with {usethis}",
    "section": "Excellent resources",
    "text": "Excellent resources\nThere are some really good resources out there already. I like the following:\n\nHilary Parker’s post to write a package from scratch (beginner)\nTomas Westlake’s update to Hilary’s post (beginner)\nEmil Hvitfeldt’s post, focusing on {usethis} (beginner/intermediate)\nKarl Broman’s site, a primer for package developement (intermediate)\nHadley Wickham’s book (intermediate/advanced)\n\nTom’s post is probably the best place to start if you want to create a package with {usethis} from scratch as a beginner."
  },
  {
    "objectID": "posts/2019-11-01-usethis/index.html#environment",
    "href": "posts/2019-11-01-usethis/index.html#environment",
    "title": "Build an R package with {usethis}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 19:13:31 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] cabinet_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33       fastmap_1.1.1       xfun_0.39          \n [4] glue_1.6.2          knitr_1.43.1        htmltools_0.5.5    \n [7] rmarkdown_2.23      cli_3.6.1           compiler_4.3.1     \n[10] rstudioapi_0.15.0   tools_4.3.1         xaringanExtra_0.7.0\n[13] evaluate_0.21       yaml_2.3.7          crayon_1.5.2       \n[16] rlang_1.1.1         jsonlite_1.8.7      htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#tldr",
    "href": "posts/2022-06-07-assign-down/index.html#tldr",
    "title": "Down with R’s assignment flamewars!",
    "section": "tl;dr",
    "text": "tl;dr\nAll &lt;- vs = flamewars are nullified forever with the introduction of my new ‘down assign’ operator for the R language:\n\n|\nv\n\n\n Note\nFolks, nerdsniping works:\n\nMatthew Kay has now written the {explodeAssign} package, which lets you use special (weaponised) down-assign arrows in an interactive session\nAntoine Fabri has followed up with a coded implementation for making this possible with a just a v operator (‘vassign’)\n\nAs Matthew says, this is a ‘terrible idea’ and you should use at your own risk, lol."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#get-down",
    "href": "posts/2022-06-07-assign-down/index.html#get-down",
    "title": "Down with R’s assignment flamewars!",
    "section": "Get down",
    "text": "Get down\nI no longer set my calendar by the movement of the Earth around the hottest point in the solar system. I now set it by the recurrent emergence of the hottest take in the solar system: that R’s assignment operator &lt;- is garbage and R users should be ashamed of themselves.\nLast time I spoke about this I made clear that our Strong Pointy Lad was the One True Operator for assignment. In that post, like some kind of modern Prometheus, I gave mortals the power to detect and destroy R scripts containing the weak and mundane equals assignment operator.\nBut with deference, I have come to realise something profound: we shouldn’t fight about this. It’s not worth anyone’s time to debate the relative merits of using &lt;- or =. We should all relax. We can live in harmony.\n…Because I’ve invented a new assignment concept. Folks, say hello to the down assign operator.\n\n|\nv\n\nYes, it’s still an ‘arrow’, but I think everyone will agree that it makes sense this time. Lateral assignment is unnatural and inefficient and is out of the natural order of things.\nNow the the value falls effortlessly down your script, under the weight of gravity, into the name of the object. If it’s good enough Sir Isaac Newton, it’s good enough for me. Or don’t you believe in gravity? Exactly.\nSo x &lt;- 1 (or, shudder, x = 1) translates to:\n\n1\n|\nv\nx\n\nElegant, isn’t it?\nWhile R Core perform the trivial task of cementing this feature into base R, I’ve prepared a small function that will take care of rudimentary usage for now.\nNote that this function won’t work in an interactive session; it takes the filepath to a script as its input. But that’s okay: I think &lt;- haters are often computer-scientist types and 1337 h4x0rz who never sully their code by playing around in filthy IDEs and notebooks anyway. Obviously we should emulate them.\nFirst I’ll write a demo script to a temporary file. It assigns the values of 1 and 2 to x and y, respectively, then adds them together.\n\ndemo_script &lt;- \"\n1\n|\nv\nx\n\n2\n|\nv\ny\n\nx + y\n\"\n\ndemo_file &lt;- tempfile(fileext = \".R\")\nwriteLines(demo_script, demo_file)\n\nNow to define the function. It reads our script file, finds the down arrows, substitutes them, returns them back to the expression from whence they came, then executes the script.\n\npoint_down &lt;- function(file) {\n  \n  content &lt;- readLines(file)\n  \n  for (i in seq(content)) {\n    \n    if (content[i] == \"|\" & content[i + 1] == \"v\") {\n      \n      combos &lt;- paste0(\n        content[i - 1], content[i], content[i + 1], content[i + 2]\n      )\n      \n      rm_index &lt;- c(i - 1, i, i + 1, i + 2)\n      \n      content[rm_index[1]] &lt;- combos\n      content[rm_index[2:4]] &lt;- \"\"\n      content &lt;- gsub(\"\\\\|v\", \"-&gt;\", content)\n      \n    }\n    \n  }\n  \n  path &lt;- tempfile(fileext = \".R\")\n  writeLines(content, path)\n  eval(parse(path))\n  \n}\n\nAnd now we execute.\n\npoint_down(demo_file)\n\n[1] 3\n\n\nSimply: wow."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#down-and-away",
    "href": "posts/2022-06-07-assign-down/index.html#down-and-away",
    "title": "Down with R’s assignment flamewars!",
    "section": "Down and away",
    "text": "Down and away\nMy next step for unifying the community around R operators is the ‘down pipe’:\n\n_\nv\n\nSome use the term ‘down pipe’ to mean the exterior drainage tube that takes wastewater away from their homes. I hope we can use the down pipe operator as a way of siphoning away all the bilge around the %&gt;% vs |&gt; arguments once and for all. You’re welcome."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#environment",
    "href": "posts/2022-06-07-assign-down/index.html#environment",
    "title": "Down with R’s assignment flamewars!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:14:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2018-09-24-knitting-club/index.html#tldr",
    "href": "posts/2018-09-24-knitting-club/index.html#tldr",
    "title": "Knitting Club: R Markdown for beginners",
    "section": "tl;dr",
    "text": "tl;dr\nI made a couple of training resources about R Markdown for reproducibility:\n\nKnitting Club (see the slides or source)\nQuick R Markdown (see the slides or source)."
  },
  {
    "objectID": "posts/2018-09-24-knitting-club/index.html#reproducibility",
    "href": "posts/2018-09-24-knitting-club/index.html#reproducibility",
    "title": "Knitting Club: R Markdown for beginners",
    "section": "Reproducibility",
    "text": "Reproducibility\nIt’s often important to recreate and verify prior work, as well as update it in future as data changes. In government we’re using a code-based approach called Reproducible Analytical Pipelines (RAP) to automate and make reproducible our statistical publications; speeding up our work while reducing error and building confidence.\nR has many packages that help with reproducibility. Take a look at the CRAN Task View for some examples.\nR Markdown is a particularly useful and ubiquitous tool. It allows you to execute R code inside your document and ‘knit’ it into a readable report with the {knitr} package by Yihui Xie. You can re-run the code, or alter the parameters and re-knit it without stress. This is much faster and less error-prone versus a workflow that moves data between a database, spreadsheet and word processor.\nThe R Markdown bible has been released recently by Yihui Xie, JJ Allaire and Garrett Grolemund and is the go-to resource for creating reports, presentations, dashboards, websites, books and blogs in R Markdown."
  },
  {
    "objectID": "posts/2018-09-24-knitting-club/index.html#resources",
    "href": "posts/2018-09-24-knitting-club/index.html#resources",
    "title": "Knitting Club: R Markdown for beginners",
    "section": "Resources",
    "text": "Resources\nI made some short resources earlier in the year to help beginners in my organisation learn about R Markdown. They’re a little rough, but got the job done. I’m unlikely to update them in future, but you can go to the source on GitHub and leave an issue, or make a pull request.\n\n1. Knitting Club\nKnitting Club is a document about R Markdown and {knitr} made with R markdown and {knitr}. It’s freely available on the web and you can find the code on GitHub.\nI presented this document in a cross-department Coffee & Coding session in April 2018. The blurb was:\n\nDo you have woolly knowledge of document creation in R? Needle little help? Matt Dray will drop some purls of wisdom and unravel a yarn about the knitty-gritty of R Markdown and the ‘knitr’ package for one-click document creation. Don’t get the point? If a deadline is looming, you’ll avoid a stitch-up from endless re-running of code and copy-pasting of outputs into a Word document. Come along and have a ball!\n\nHa.\n\n\n2. Quick R Markdown\nIf the Knitting Club document is too long, you can check out this shorter slide-based introduction to R Markdown below. You can also access the slides alone and find the source on GitHub."
  },
  {
    "objectID": "posts/2018-09-24-knitting-club/index.html#environment",
    "href": "posts/2018-09-24-knitting-club/index.html#environment",
    "title": "Knitting Club: R Markdown for beginners",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-08 17:55:32 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html",
    "href": "posts/2020-12-08-postcard/index.html",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "",
    "text": "Sleek. Minimal. Bearded."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#tldr",
    "href": "posts/2020-12-08-postcard/index.html#tldr",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "tl;dr",
    "text": "tl;dr\n\nDearest ma and pa,\nThe food here is okay. Mostly I’ve been setting up a single-page personal site with the {postcards} package for R, deploying it with Netlify and setting up a custom domain with Namecheap. More rain is forecast for tomorrow.\nWish you were here,\nMatthew"
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#domain-driven-development",
    "href": "posts/2020-12-08-postcard/index.html#domain-driven-development",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Domain-driven development",
    "text": "Domain-driven development\nA hobby of mine is to look for funny domain names and to not buy them.\nEventually I realised that matt-dray.com wasn’t taken, so I figured I might as well squat it and do something pseudo-useful with it.1\nYes, I could write some HTML2 and CSS to make a complicated shrine to self-absorption, but why bother trying to center divs when Sean Kross has just announced the {postcards} R package to create nice, minimal landing pages?\nThis post is a short self-reminder of how to:\n\nGenerate a webpage with {postcards}\nDeploy it with Netlify\nPoint to it with a custom domain from Namecheap\n\nThis post isn’t about the tubes and wires of the internet. It’s more the how than the why."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#write-a-postcard",
    "href": "posts/2020-12-08-postcard/index.html#write-a-postcard",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Write a postcard",
    "text": "Write a postcard\n{postcards} provides some R Markdown templates that contain space for a photo, a mini-bio and some buttons to link out to your profiles elsewhere. See the package’s readme for examples.\nYou can install the development version from GitHub:\n\nremotes::install_github(\"seankross/postcards\")\n\nI generated an R Markdown file with the ‘Jolla’ template using the following line:\n\nrmarkdown::draft(\"index.Rmd\", \"Jolla\", package = \"postcards\")\n\nNote that the file is called index.Rmd and will thus render to index.html. This is the default file that gets read when a site is visited.\nIn the YAML header of the template you can specify a title, which is likely to be your name; the output format, which is the name for our chosen {postcards} template; links, where you specify the wording and underlying links for the page’s buttons; image for your bokeh-rich professional headshot and favicon for the little image that will appear alongside your page title in a browser tab. \n---\ntitle: \"Matt Dray\"\nimage: \"matt.jpg\"\nlinks:\n  - Blog: \"https://www.rostrum.blog/\"\n  - Twitter: \"https://twitter.com/mattdray/\"\n  - GitHub: \"https://github.com/matt-dray/\"\noutput:\n  postcards::jolla\nfavicon: favicon.gif\n---\nYou can then write your mini bio in the body text of the document. I garnished mine with emoji via Hadley Wickham’s {emo} package.\nThe {postcards} templates are ready to go out of the box but you can still tinker with the style. I decided to pull in a font, Fantasque Sans Mono by Jany Belluz3, and put a CSS chunk in the R Markdown to specify it.\n\n\n\nA preview of the ‘Jolla’ template. Tobi seems nice.\n\n\nThe content and design of my page may change at any time, but I purposefully want it to be minimal and have a clean and simple appearance. The {postcards} package is also in development, so I look forward to testing out any new features that appear in future."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#pop-it-in-the-post",
    "href": "posts/2020-12-08-postcard/index.html#pop-it-in-the-post",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Pop it in the post",
    "text": "Pop it in the post\nYou could put your site’s files in a GitHub repo and serve it with GitHub Pages. Upside: it’s free. Downside: your URL will be in the form username.github.io/your-postcard-repo, which isn’t particularly sleek.\nInstead you could use a free service like Netlify to deploy a site from a GitHub/GitLab/BitBucket repository and set up a custom domain to point at it. I’ve had prior success with Netlify for this blog, so that’s why I’m using it here.\nA bonus of this approach is continuous deployment: pushing changes to your repo causes Netlify to rebuild and deploy your site automatically, so you don’t need to worry about it.\nTo set up my page, I signed into Netlify and I:\n\nclicked the ‘New site from Git’ button\nclicked ‘GitHub’ in section ‘1. Connect to Git provider’, because that’s where my {postcards} repo is stored\nselected my github.com/matt-dray/postcard/ repo in section ‘2. Pick a repository’ after authorising Netlify to connect to to it\nleft the ‘build command’ empty in section ‘3. Build options and deploy!’ and set the ‘publish directory’ to ‘/’ (because I want to serve index.html from the root of the repo)\nclicked ‘deploy site’\n\nNetlify takes a moment to build and serve the site after you click ‘deploy site’. It’s served automatically from a URL in the form random-name.netlify.app4 but, as mentioned, you can configure a privately-owned domain name instead.\nFor more on these steps, including screenshots, see Netlify’s step-by-step guidance on deploying static and single-page sites.\nIt’s also worth mentioning Netlify Drop: a service that lets you simply drag and drop your site’s files to deploy them, rather than needing to authorise Netlify to connect to your Git-based repo. This is quick and technically easier, but you’ll have to drag and drop each time you want to update the site."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#address-it-properly",
    "href": "posts/2020-12-08-postcard/index.html#address-it-properly",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Address it properly",
    "text": "Address it properly\nThere’s a whole bunch of domain-name providers. I’m focusing here on Namecheap, which is what I used to for this blog. After buying a domain, there’s a little bit of back-and-forth required between Netlify and Namecheap.\nIn brief:\n\nIn your Namecheap account, click the ‘Manage’ button for your domain and set the dropdown in the ‘Nameservers’ section to ‘Custom DNS’\nIn your Namecheap account, click ‘Set up a custom domain’, type it in and confirm\nClick ‘Set up Netlify DNS’ alongside the domain and click through until you’re provided a handful of nameserver strings\nBack on Namecheap, copy-paste each of these into the ‘Nameservers’ section from step 1 and click the check mark to confirm\nWait.\n\nIt’ll take a short while, but there’ll be a sort of high-five between your domain and your site and then it’ll be ready for viewing.\nSee Ezekiel Ekunola’s excellent blog post for a more thorough guide, which includes screenshots.\nNote also that Netlify provides HTTPS for free too, which is good for a number of reasons, though the certificate can take a few hours to generate.\nYou can check your domain settings in Netlify at any time by clicking the site name in your account and then clicking the ‘Domain settings’ button.\n\n\n\nNetlify’s domain settings after successful set-up."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#post-postcard-postscript",
    "href": "posts/2020-12-08-postcard/index.html#post-postcard-postscript",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Post-postcard postscript",
    "text": "Post-postcard postscript\nSo this is a relatively quick way of generating up a single-page site with {postcards}; hosting the source on GitHub; deploying it with Netlify; and serving it via a custom domain bought from from Namecheap.\nThis seems to work fine for me for now. Let me know if you have a better approach to generating and deploying simple single-page sites."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#environment",
    "href": "posts/2020-12-08-postcard/index.html#environment",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 19:03:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#footnotes",
    "href": "posts/2020-12-08-postcard/index.html#footnotes",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDear other-Matt-Drays: you should know that we’re in direct competition and I have to do what it takes to maximise my SEO and become the top Matt Dray globally.↩︎\nFree advice for your personal site: a liberal sprinkling of the &lt;marquee&gt; tag should definitely grab people’s attention.↩︎\nI learnt about this via a GitHub star by Alison Presmanes Hill.↩︎\nYou can change the random element to be more meaningful. For example, I changed it to matt-dray.netlify.app. You could stop there, but the whole point of using Netlify in this example is to set up a custom domain instead.↩︎"
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html",
    "href": "posts/2019-12-27-pkgs-2019/index.html",
    "title": "Packages that Sparked Joy in 2019",
    "section": "",
    "text": "Marie Kondo (Netflix via Giphy)."
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html#thank-you-package-makers",
    "href": "posts/2019-12-27-pkgs-2019/index.html#thank-you-package-makers",
    "title": "Packages that Sparked Joy in 2019",
    "section": "Thank you package-makers",
    "text": "Thank you package-makers\nI’ve used a lot of packages in 2019 and many have brought great joy to my R experience. Thank you to everyone who has created, maintained or contributed to a package this year.\nSome particular packages of note for me have been:\n\n🤖 {usethis} by Hadley Wickham and Jenny Bryan\n🦆 {drake} by Will Landau\n🐈 {purrr} by Lionel Henry and Hadley Wickham\n\nAnd some honourable mentions are:\n\n📝 {blogdown} by Yihui Xie\n⚔️ {xaringan} by Yihui Xie\n🙇 {polite} by Dmytro Perepolkin\n↔︎️ {arsenal} by Ethan Heinzen, Jason Sinnwell, Elizabeth Atkinson, Tina Gunderson and Gregory Dougherty\n\nClick the package name to jump to that section."
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html#packages-of-note",
    "href": "posts/2019-12-27-pkgs-2019/index.html#packages-of-note",
    "title": "Packages that Sparked Joy in 2019",
    "section": "Packages of note",
    "text": "Packages of note\n\n{usethis}\nThe format and content of R packages is objectively odd. What files are necessary? What structure should it have? The {usethis} package from RStudio’s Hadley Wickham and Jenny Bryan makes it far easier for newcomers and experienced useRs alike.\nIn fact, you can make a minimal package in two lines:\n\ncreate_package() to create the necessary package structure\nuse_r() to create in the right place an R script for your functions\n\nBut there’s way more functions to help you set up your package. To name a few more that I use regularly:\n\nuse_vignette() and use_readme_md() for more documentation\nuse_testthat() and use_test() for setting up tests\nuse_package() to add packages to the Imports section of the DESCRIPTION file\nuse_data() and use_data_raw() to add data sets to the package and the code used to create them\nuse_*_license() to add a license\n\nThere are also other flavours of function like git_*() and pr_*() to work with version control and proj_*() for working with RStudio Projects.\nI focused this year on making different types of package. {usethis} made it much easier to develop:\n\n{altcheckr} to read and assess image alt text from web pages\n{oystr} to handle London travel-history data from an Oyster card\n{gdstheme} to use a {xaringan} presentation theme and template\n{blogsnip} to insert blog-related code snippets via an RStudio addin (there’s even a use_addin() function to create the all-important inst/rstudio/addins.dcf file)\n\nFor more package-development info, I recommend Emil Hvitfeldt’s {usethis} workflow, as well as Karl Broman’s R Package Primer and Hadley Wickham’s R Packages book. To help me remember this stuff, I also wrote some slides about developing a package from scratch with {usethis} functions.\n\n\n{drake}\nYour analysis has got 12 input data files. They pass through 15 functions There are some computationally-intensive, long-running processes. Plots and tables are produced and R Markdown files are rendered. How do you keep on top of this? Is it enough to have a set of numbered script files (01_read.R, etc) or a single script file that sources the rest? What if something changes? Do you have to re-run everything from scratch?\nYou need a workflow manager. Save yourself some hassle and use Will Landau‘s {drake} package, backed by rOpenSci’s peer review process. {drake} ’remembers’ all the dependencies between files and only re-runs what needs to be re-run if any errors are found or changes are made. It also provides visualisations of your workflow and allows for high-performance computing.\nIn short, you:\n\nSupply the steps of your analysis as functions to drake_plan(), which generates a data frame of commands (functions) to operate over a set of targets (objects)\nRun make() on your plan to run the steps and generate the outputs\nIf required, make changes anywhere in your workflow and re-make() the plan – {drake} will only re-run things that are dependent on what you changed\n\nBelow is an extreme example from a happy customer. Each point on the graph is an object or function; black ones are out of date and will be updated when make() is next run.\n\n\n\n‘I’m so glad {drake} is tracking those dependencies between #rstats computations for me’\n\n\nIt’s hard to do {drake} justice in just a few paragraphs, but luckily it’s one of the best-documented packages out there. Take a look at:\n\nthe {drake} rOpenSci website\nthe thorough user manual\nthe learndrake GitHub repo, which can be launched in the cloud\nthe drakeplanner Shiny app\nWill’s {drake} examples page\nthis rOpenSci community call\na Journal of Open Source Software (JOSS) paper\nmore things listed in the documentation section of the user manual\n\nI wrote about {drake} earlier in the year and made a demo and some slides. I think it could be useful for reproducibility of statistical publications in particular.\n\n\n{purrr}\nYou want to apply a function over the elements of some list or vector.\nThe map() family of functions from the {purrr} package–by Lionel Henry and Hadley Wickham of RStudio–has a concise and consistent syntax for doing this.\nYou can choose what gets returned from your iterations by selecting the appropriate map_*() variant: map() for a list, map_df() for a data frame, map_chr() for a character vector and so on. Here’s a trivial example that counts the number of Street Fighter characters from selected continents. Here’s a list:\n\n# Create the example list\nstreet_fighter &lt;- list(\n china = \"Chun Li\", japan = c(\"Ryu\", \"E Honda\"),\n usa = c(\"Ken\", \"Guile\", \"Balrog\"), `???` = \"M Bison\"\n)\n\nstreet_fighter  # take a look at the list\n\n$china\n[1] \"Chun Li\"\n\n$japan\n[1] \"Ryu\"     \"E Honda\"\n\n$usa\n[1] \"Ken\"    \"Guile\"  \"Balrog\"\n\n$`???`\n[1] \"M Bison\"\n\n\nNow to map the length() function to each element of the list and return a named integer vector.\n\nlibrary(purrr)  # load the package\n\n# Get the length of each list element\npurrr::map_int(\n  street_fighter,  # list\n  length           # function\n)\n\nchina japan   usa   ??? \n    1     2     3     1 \n\n\nBut what if you want to iterate over two or more elements? You can use map2() or pmap(). And what if you want to get the side effects? walk() and pwalk().\n{purrr} is also great for working with data frames with columns that contain lists (listcols), like the starwars data from the {dplyr} package. Let’s use the length() function again, but in the context of a listcol, to get the characters in the most films.\n\n# Load packages\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(purrr)\n\n# map() a listcol within a mutate() call\nstarwars %&gt;% \n  mutate(films_count = map_int(films, length)) %&gt;% \n  select(name, films, films_count) %&gt;% \n  arrange(desc(films_count)) %&gt;% head()\n\n# A tibble: 6 × 3\n  name           films     films_count\n  &lt;chr&gt;          &lt;list&gt;          &lt;int&gt;\n1 R2-D2          &lt;chr [7]&gt;           7\n2 C-3PO          &lt;chr [6]&gt;           6\n3 Obi-Wan Kenobi &lt;chr [6]&gt;           6\n4 Luke Skywalker &lt;chr [5]&gt;           5\n5 Leia Organa    &lt;chr [5]&gt;           5\n6 Chewbacca      &lt;chr [5]&gt;           5\n\n\nWhy not just write a loop or use the *apply functions? Jenny Bryan has a good {purrr} tutorial that explains why you might consider either choice. Basically, do what you feel; I like the syntax consistency and the ability to predict what function I need based on its name.\nCheck out the excellent {purrr} cheatsheet for some prompts and excellent visual guidance."
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html#honourable-mentions",
    "href": "posts/2019-12-27-pkgs-2019/index.html#honourable-mentions",
    "title": "Packages that Sparked Joy in 2019",
    "section": "Honourable mentions",
    "text": "Honourable mentions\n\n{blogdown}\nThis blog, and I’m sure many others, wouldn’t exist without {blogdown} by Yihui Xie. {blogdown} lets you write and render R Markdown files into blog posts via static site generators like Hugo. This is brilliant if you’re trying to get R output into a blog post with minimal fuss. The {blogdown} book by Yihui, Amber Thomas, Alison Presmanes Hill is particularly helpful.\n\n\n{xaringan}\n{xaringan} is another great package from Yihui Xie that lets you turn R Markdown into a slideshow using remark.js. It’s very customisable via CSS, to the extent that I was able to mimic the house style of my organisation this year. One of my favourite functions1 is inf_mr() (Infinite Moon Reader), which lets you live-preview your outputs as they’re written.\n\n\n{polite}\nWeb scraping is ethically dubious if you fail to respect the terms of the sites you’re visiting. Dmytro Perepolkin has made it easy to be a good citizen of the internet with the {polite} package, which has just hit version 1.0.0 and is on CRAN (congratulations!). First you introduce yourself to the site with a bow() and collect any information about limits and no-go pages from the robots.txt file, then you can modify search paths with a nod() and collect information from them with a scrape(). Very responsible.\n\n\n{arsenal}\nI’ve been using the handy2 {arsenal} package to compare data frames as part of a quality assurance process. First, you supply two data frames to comparedf() to create a ‘compare’ object. Run diffs() on that object to create a new data frame where each row is a mismatch, given a tolerance, with columns for the location and values that are causing problems. We managed to quality assure nearly a million values with this method in next to no time. Check out their vignette on how to do this."
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html#bonus",
    "href": "posts/2019-12-27-pkgs-2019/index.html#bonus",
    "title": "Packages that Sparked Joy in 2019",
    "section": "Bonus!",
    "text": "Bonus!\n\n{govdown}\nAha, well done for reading this far. As a bonus, I’m calling out Duncan Garmonsway’s {govdown} package. Duncan grappled with the complexities of things like Pandoc and Lua filters to build a package that applies the accessibility-friendly GOV.UK design system to R Markdown. This means you can create things like the the Reproducible Analaytical Pipelines (RAP) website in the style of GOV.UK. Endorsed by Yihui Xie himself! Check out Duncan’s {tidyxl} and {unpivotr} packages for handling nightmare Excel files while you’re at it."
  },
  {
    "objectID": "posts/2019-12-27-pkgs-2019/index.html#footnotes",
    "href": "posts/2019-12-27-pkgs-2019/index.html#footnotes",
    "title": "Packages that Sparked Joy in 2019",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlong with yolo: true, of course.↩︎\nUnlike Arsenal FC in 2019, rofl.↩︎"
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#tldr",
    "href": "posts/2020-09-21-londonmapbot/index.html#tldr",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "tl;dr",
    "text": "tl;dr\nI made @londonmapbot: a simple Twitter bot that uses the R package {rtweet}, GitHub Actions and the Mapbox API. Find the source on Github.\n\n Note\nTwitter changed its API terms in 2023. As a result, you probably can’t re-run the code in this blog. Read about how I moved londonmapbot to Mastodon at botsin.space/@londonmapbot because of these changes."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#london-from-socially-distant-space",
    "href": "posts/2020-09-21-londonmapbot/index.html#london-from-socially-distant-space",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "London from (socially-distant) space",
    "text": "London from (socially-distant) space\nI’ve wanted to make a Twitter bot for a while, but it seemed like Hard Work. Spoiler: it’s not.\nSo, I’ve made @londonmapbot: a completely unsophisticated proof-of-concept Twitter bot.\nWhat does it do? It posts a satellite image from random coordinates in Greater London (well, from a bounding box roughly within the M25 motorway) on schedule. Below is an example image from an existing @londonmapbot tweet. Can you guess where it is?1\n\nThe code for this runs remotely. You can set it up, let it run and never think about it again.\nSo how does it work? A scheduled GitHub Action runs R code to generate random latitude and longitude values, which are sent to the Mapbox API to retrieve a satellite picture. The image is then posted via the Twitter API that is accessed using the {rtweet} package. A link to the coordinates on OpenStreetMap is also included so you can find out exactly where the image is from.\nThe main purpose was to learn more about GitHub Actions, building on my previous posts about using actions for continuous integration, but I think incidentally that the tweets are quite pleasing to look at and to guess where they are."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#the-components",
    "href": "posts/2020-09-21-londonmapbot/index.html#the-components",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "The components",
    "text": "The components\nThe source code is quite simple. There’s two files, basically:\n\na single YAML file containing the action2\na single R script that generates the tweet and posts it\n\nLet’s look at the GitHub Actions code in the YAML file and the use of {rtweet} and Mapbox in the R file.\n\nGitHub Actions\nGitHub Actions is a platform for automating workflows remotely. In short, you write a small YAML file in the .github/workflows/ subfolder of your repo, which contains instructions for the code you want to run and when to run it.3 I’ve written before about using GitHub Actions for continuous integration of R packages, for example.\nAn action can be triggered by an event, like a git push to your repo. You can also schedule it with a cron job, to run every hour, once a day, or whatever.\nHere’s what the YAML file looks like for the londonmapbot action:\nname: londonmapbot\n\non:\n  schedule:\n    - cron: '0,30 * * * *'\n\njobs:\n  londonmapbot-post:\n    runs-on: macOS-latest\n    env:\n      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}\n      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}\n      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n      MAPBOX_PUBLIC_ACCESS_TOKEN: ${{ secrets.MAPBOX_PUBLIC_ACCESS_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@master\n      - name: Install rtweet package\n        run: Rscript -e 'install.packages(\"rtweet\", dependencies = TRUE)'\n      - name: Create and post tweet\n        run: Rscript londonmapbot-tweet.R\nIt’s interpreted like so:\n\nthis action is called ‘londonmapbot’\nrun this code at :00 and :30 past each hour4\nthe first (and only) job in this action is called londonmapbot-post\nstart up a remote machine with the latest macOS operating system installed (this is where your code will be run)\nset some environmental variables, in this case keys that will be used to access the Twitter and Mapbox APIs (see the ‘Secrets’ section later in this post)\nthe steps of the job are to:\n\nuse some pre-written code by GitHub to check out the repo\nuse some prewritten code from r-lib that sets up R\ninstall the {rtweet} package and its dependencies\nrun the named R script from the repo\n\n\nI would recommend changing your GitHub notification alerts once the bot is up and running, otherwise you’ll get a message every time the action executes. You can change this under Settings &gt; Notifications &gt; GitHub Actions, where you can uncheck the boxes under ‘Notifications for workflow runs on repositories set up with GitHub Actions’."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#rtweet",
    "href": "posts/2020-09-21-londonmapbot/index.html#rtweet",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "{rtweet}",
    "text": "{rtweet}\nThe action runs an R script that generates content for a tweet and then posts it. This script makes use of the package {rtweet} by Mike Kearney, which lets you interact with the Twitter API with R functions.\nYou need a Twitter account, of course, and also to sign up as a Twitter developer to access the API.\n\n Note\nTwitter has moved to version 2.0 of their API since this post was written. As things stand in February 2022 (hello from the future), you will need to ask for ‘elevated’ access in Twitter’s Developer Portal to ensure you can reach version 1.1 of the API, which is what {rtweet} is set up to communicate with.\nHuge thanks to Oscar Baruffa, who learnt about this hard way when setting up a Twitter bot for the excellent Big Book of R (an index of 250+ free books for R programming).\n\n\nAs a developer, you can create ‘apps’ to obtain keys: private alphanumeric passcodes that grant you access to the API.\nTypically, when working locally, you would either provide these keys as bare strings, or put them in your .Renviron file. With the latter, you can then use Sys.getenv() to call them from your .Renviron, which stops you exposing the raw keys in your code.\nBelow is an example of how you can use {rtweet} to post a tweet from R if you’ve added the keys to your .Renviron.\n\n# Install the package from CRAN\ninstall.packages(\"rtweet\")\n\n# Create a token containing your Twitter keys\nrtweet::rtweet_bot(\n  api_key       = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  api_secret    = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token  = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\n# Example: post a tweet via the API\n# The keys will are in your environment thanks to create_token()\nrtweet::post_tweet(status = \"This is a test tweet.\")\n\n\n Note\n{rtweet} version 1.0 was released with breaking changes in July 2022 and so I’ve changed the code above to use the function rtweet_bot() instead of create_token(). You can read a separate blogpost about these changes.\n\n\nThis is basically what happens in the londonmapbot R script too. When writing an action, the keys aren’t fetched from your .Renviron file, however. Instead, you can encrypt them on GitHub and provide them in the env call of your action’s YAML file. See the ‘Secrets’ section below for more detail on this.\n\nMapbox\nMapbox is a company with services for mapping, geocoding and navigation, which developers can use for integrating into their apps for things like asset tracking, route optimisation or anything that requires a map interface for users.\nAgain, you’ll need to set up a Mapbox account to get a key for using the API. While the target audience is largely commercial, there appears to be a generous free allowance of 1250 requests per minute for the static image API.\nYou can then pass parameters to the Mapbox API via a URL. This is well explained in the Mapbox Documentation, which has an excellent ‘playground’ interface for you to test out your call.\nYou basically modify a particular URL string to ask the API for what you want. For example, you can ask for a 300x200 pixel satellite image of the coordinates of -0.1709 and 51.5065 with zoom level 12, which is Hyde Park:\nhttps://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/-0.1709,51.5065,12,0/300x200?access_token=YOUR_MAPBOX_ACCESS_TOKEN\nVisiting the URL in your browser returns the requested image as a JPEG:\n\n\n\nThe Serpentine is so aptly named.\n\n\nOf course, you’ll need to replace the access-token placeholder (YOUR_MAPBOX_ACCESS_TOKEN) in that URL with your own Mapbox key. Rather than provide this as a bare string, the londonmapbot R script calls it from the environment (like we saw in the {rtweet} code in the last section).\nHere’s the code used by londonmapbot to fetch the satellite image from Mapbox:\n\n# Generate random coordinates\nlon &lt;- round(runif(1, -0.5, 0.27), 4)\nlat &lt;- round(runif(1, 51.3, 51.7), 4)\n\n# Build URL and fetch from Mapbox API\nimg_url &lt;- paste0(\n    \"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/\",\n    paste0(lon, \",\", lat),\n    \",15,0/600x400@2x?access_token=\",\n    Sys.getenv(\"MAPBOX_PUBLIC_ACCESS_TOKEN\")\n)\n\n# Download the image to a temporary location\ntemp_file &lt;- tempfile(fileext = \".jpeg\")\ndownload.file(img_url, temp_file)\n\nThe code shows a paste0() statement that builds the URL with random latitude and longitude and the Mapbox key. The image from that URL is then downloaded into a temporary file, where it can be supplied to the media argument of rtweet::create_tweet() for posting to Twitter."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#secrets",
    "href": "posts/2020-09-21-londonmapbot/index.html#secrets",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "Secrets",
    "text": "Secrets\nI’ve mentioned in this post about keeping your keys secure. You don’t want others to copy and use your keys nefariously, so it’s a good idea not to simply paste them into your code as bare strings for the world to see.\nGithub lets you store secrets securely in the ‘Secrets’ section of the ‘Settings’ tab in your repo. No-one can see these, but they can be called into your code when it runs.\n\n\n\nKeep it secret… keep it safe.\n\n\nLet’s use the londonmapbot Twitter consumer API key as an example. First, I saved the string as a GitHub secret with the name TWITTER_CONSUMER_API_KEY. I then called this in the env section of my YAML file in the form ${{ secrets.TWITTER_CONSUMER_API_KEY }}. Running the action results in the string being pulled from the secrets stash and decrypted, where it’s available in the environment. Then the R code can call it with Sys.getenv() when access to the API is needed."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#it-does-the-job",
    "href": "posts/2020-09-21-londonmapbot/index.html#it-does-the-job",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "It does the job",
    "text": "It does the job\nSo, you can:\n\ntake a look at the @londonmapbot profile\nfind the source on GitHub\ninspect the YAML file that runs the action\nsee the R script that generates and posts the image\n\nThe GitHub README also lists a few other map bots—which I’ve christened the ‘mapbotverse’—that have taken inspiration from londonmapbot; take a look at those too.\nOf course, you should fork the repo, or use it as a template, to create your own bot. Let me know what you get up to.\nDo give me suggestions and pull requests, or tell me how good you are at identifying the granular location in each image."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#environment",
    "href": "posts/2020-09-21-londonmapbot/index.html#environment",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:27:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#footnotes",
    "href": "posts/2020-09-21-londonmapbot/index.html#footnotes",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThose look suspiciously like a large number of tennis courts, including some in stadia. Where could that be? The coordinates are 51.4317, -0.2151.↩︎\nIn the first iteration of the action I passed the R code as a single line in the YAML file, which is suboptimal. I later tidied the code into a separate R script and declared the secrets in the YAML file. I looked at actions by Matt Kerlogue and David Keyes to do this. David’s repo is interesting from a Twitter perspective because it automates tweets provided via a Google Sheet.↩︎\nI should note that there are already actions on the GitHub Marketplace built specifically for tweeting, but they didn’t quite do what I wanted. I also wanted to write the juicy bit with R code, which I’m most familiar with.↩︎\nThere’s a number of sites that can help you build a cron string. I built a toy package, {dialga}, to help convert from R to cron to English. I may change the specific posting frequency for londonmapbot in future.↩︎"
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html",
    "href": "posts/2023-01-04-rogue-sfx/index.html",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "",
    "text": "new wr — r.oguelike any% tenkeyless noglitch"
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#tldr",
    "href": "posts/2023-01-04-rogue-sfx/index.html#tldr",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {r.oguelike} package—a toy roguelike microadventure for the R console—now has little sound effects thanks to {sonify}. Pew pew!"
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#the-adventure-continues",
    "href": "posts/2023-01-04-rogue-sfx/index.html#the-adventure-continues",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "The adventure continues?",
    "text": "The adventure continues?\nApparently this is part 5 of the {r.oguelike} devlog. You can read earlier posts about:\n\nits inception\ncreating simple procedural dungeons\nmaking an enemy chase the player\n3D dungeons and continuous keypress inputs\n\nAlas, this is also probably the last installment.\nYes, the dungeons have been dank (cool, edgy), but also dank (cool, damp, claustrophobic). Time to unspelunk myself.\nThere may be time for a {r.oguelike2} in future. I’d like to try a class-based approach to help limit code spaghetti and make it more extensible. Perhaps it will even have a proper game loop! Call me when you’re ready, Kojima.\nUntil then, one more little feature to tie things up. Beeeeeeep. BOOOOOOOP."
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#hi-sonifi",
    "href": "posts/2023-01-04-rogue-sfx/index.html#hi-sonifi",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Hi-Sonifi",
    "text": "Hi-Sonifi\nSo, yes: {r.oguelike} now has sound effects with quality as high as its graphics and gameplay. See all these in concert in the video embedded at the top of this page.\nI used the {sonify} package to create a few little beeps and toots that I think fit the game’s retro aesthetic.1 These are fired when the player moves and interacts with things in the dungeon.\nI’ve written about {sonify} before when I sonified data about COVID-19 infections and GitHub activity (incredible juxtaposition), which can offer a more interesting and accessible way of presenting data.\nYou can also demean {sonify} by making funny little honks and parps, which is what I’ve done for {r.oguelike}.\nHow did I arrive at the soundscape for {r.oguelike}? I did the bare minimum of fiddling around with the arguments in sonify::sonify() until the noises amused me."
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#demo-cassette",
    "href": "posts/2023-01-04-rogue-sfx/index.html#demo-cassette",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Demo cassette",
    "text": "Demo cassette\nSounds are played in the code of the package via functions after each triggering event. The user can prevent these sounds from playing with the logical has_sfx argument in the start_game() function.\nFor example, here’s the function for the simplest sound effect:\n\n.sfx_move &lt;- function(has_sfx) {\n  if (has_sfx) sonify::sonify(1, 1, duration = 0.001)\n}\n\nThe sonify() outputs are {tuneR} objects. I’ve saved these as wav files with tuneR::writeWav() so they can be embedded in this post.\n\n\nClick for illustrative code to create the wav files.\n\n\nlibrary(sonify)\nlibrary(tuneR)\nlibrary(purrr)\n\nsfx &lt;- list(\n  \n  move = sonify(1, 1, duration = 0.001),\n  \n  bump = sonify(1, 1, duration = 0.01, flim = c(100, 110)),\n  \n  gold = bind(\n    sonify(1, 1, duration = 0.05, flim = c(800, 800)),\n    sonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n  ),\n  \n  apple = sonify(0:1, c(0, 1), duration = 0.05),\n  \n  eat = sonify(0:1, c(1, 0), duration = 0.05),\n  \n  win = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n  ),\n  \n  lose = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))\n  )\n  \n)\n\nwalk2(\n  .x = sfx,\n  .y = names(sfx), \n  ~writeWave(.x, paste0(.y, \".wav\"))\n)\n\n\nIn reality, the sounds play a little slower in the game itself, but it was a bit fiddly to reproduce it for these clips. You’ll get the idea.\n\nMove\nStep onto unoccupied floor tile (.) and you’ll hear the very quick tap of your boot.\nClick to play the sound:\n\n\n\n\n\nAnd here’s the corresponding code to reproduce it:\n\nsonify(1, 1, duration = 0.001)\n\nBut bump into the dungeon wall (#) and you’ll get a dull thud, you absolute clod.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.01, flim = c(100, 110))\n\nYes, flim, as in: ‘this post is absolute flimflam’.\n\n\nFood\nWould you pick up an apple (a) you found on the floor of a cave? Here’s what it might sound like as it pops into your inventory.\n\n\n\n\n\n\nsonify(0:1, c(0, 1), duration = 0.05),\n\nMore importantly, would you eat an apple (a) you found on the floor of a cave? Here’s how it would sound as it rolls down your gullet.\n\n\n\n\n\n\nsonify(0:1, c(1, 0), duration = 0.05)\n\n\n\nGold\nCollecting gold ($) grants you a celebratory chirp of excitement. Although there’s not actually anything in the dungeon to spend it on, sorry.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.05, flim = c(800, 800))\nsonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n\n\n\nDefeat enemy\nA powerful victory ditty after you crush your enemies (E).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n\n\n\nLose\nConversely, a sad lament for being crushed by your enemies (E) or running out of turns (T).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))"
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#echo-echo-echo",
    "href": "posts/2023-01-04-rogue-sfx/index.html#echo-echo-echo",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Echo echo echo",
    "text": "Echo echo echo\nIf you want to try out {r.oguelike}, you can install it from GitHub:\n\ninstall.github(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/r.oguelike\")  # v0.1 currently\nr.oguelike::start_game()\n\nYou can also run {r.oguelike} in an RStudio instance in your browser (!), thanks to the Binder project.\nFree feel to highlight any bugs via the issues, or create a pull request that adds all the things that stop me from calling {r.oguelike} a proper ‘game’.2\n\nMost importantly, don’t forget to wishlist me on Steam and remember that pre-order bonuses will include an apple that’s been left on a dungeon floor for a few months."
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#environment",
    "href": "posts/2023-01-04-rogue-sfx/index.html#environment",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-11 19:25:13 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-01-04-rogue-sfx/index.html#footnotes",
    "href": "posts/2023-01-04-rogue-sfx/index.html#footnotes",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMeanwhile, I’m looking forward to what Mike (coolbutuseless) is up to with audio for games in R.↩︎\nFind some actual real R games in this list I’ve put together.↩︎"
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#tldr",
    "href": "posts/2022-02-19-backtick/index.html#tldr",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a tiny R package called {backtick}, which contains an RStudio Addin with a handful of functions for inserting backticks into your R scripts and R Markdown documents (yes, really)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#plus-one",
    "href": "posts/2022-02-19-backtick/index.html#plus-one",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Plus one",
    "text": "Plus one\nRStudio Addins let you select an R function from a dropdown menu in the RStudio IDE. They’re often functions that you don’t need in your executed script, but can make your life easier by performing some kind of supportive action.\nFor example, you can use the RStudio Addin in the {remedy} package from ThinkR to add Markdown formatting to your text. RStudio’s {reprex} package has a built-in RStudio Addin to create a reproducible example from highlighted code. Or how about Miles McBain’s {datapasta} Addin for pasting conveniently into R scripts from external sources?\nYou can find many more examples in Dean Attali’s {addinslist} package, which itself contains an Addin for… adding more Addins."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#in-addition",
    "href": "posts/2022-02-19-backtick/index.html#in-addition",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "In addition",
    "text": "In addition\nI’ve written about RStudio Addins before.\nI have a GitHub-hosted package called {blogsnip} with an Addin to help me insert code into these blogposts.1 For example, to insert the session-information block at the end of each post, or to insert HTML to create more accessible images.\n{blogsnip} also hosts a concept function to add a comment to each closing bracket with the name of the function being closed. I’ve found it useful for keeping on top of deeply-nested Shiny apps.\nA while back I also wrote an Addin for the {r2eng} package to let your computer speak R code aloud as an English sentence.\nI also recently created the {snorkel} R package, which contains an Addin to help you insert {roxygen2} formatting to your function documentation. Turns out Jozef wrote a detailed series about how you can do something similar.\n\n\n\nYou put a snorkel in your mouth to help you breathe oxygen; you put a {snorkel} in your addins to help you write with {roxygen2}.\n\n\nI wanted to write something about how to quickly set up a package to insert or replace text, which I think is probably the most common (simple) use of RStudio Addins.\nEventually I was nerdsniped (unintentionally) on Twitter by Calum to do something about it."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#the-problem",
    "href": "posts/2022-02-19-backtick/index.html#the-problem",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "The problem",
    "text": "The problem\nProblem: Calum’s backtick key, `, is being used to activate additional software that’s awkward to toggle on and off every time they wanted to use the backtick for R coding.2\nTo solve Calum’s problem (and Italy’s?3), you could try to use a custom keyboard shortcut, or maybe a snippet. And RStudio already has a button and shortcut in its IDE for inserting R Markdown code chunks, which require triple backticks to demarcate the start and end of the chunk.\nBut an RStudio Addin is another viable method that means you can bundle up a set of functions that insert each of the backtick ‘constructions’, from a single backtick to an R Markdown chunk.\nAs a bonus, you can also set the functions of an Addin to custom keyboard shortcuts and quickly access them from the RStudio command palette (just hit Shift + Cmd + P, or Shift + Ctrl + P, then type the word ‘backtick’)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#a-solution",
    "href": "posts/2022-02-19-backtick/index.html#a-solution",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "A solution",
    "text": "A solution\nSo, the (very specific!) user need was clear and I created the {backtick} package with functions to:\n\ninsert a single backtick (i.e. `)\nsurround selected text with single backticks (i.e. selection becomes `selection`)\nsurround selected text with backticks for execution as inline R code in an R Markdown document (as above, but inserts an r and space after the first backtick)\nsurround selected text with backticks for execution as an R code chunk in an R Markdown document (selection is surrounded by ```{r} above and ``` below)\n\nThat last one is especially neat because the in-built RStudio function doesn’t appear to put selected text inside an R Markdown chunk; it simply inserts the skeleton of a chunk.\nCalum notes that this solution worked, and that they were able to set the insert backtick Addin to the keyboard shortcut Alt + `, lol."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#add-your-own",
    "href": "posts/2022-02-19-backtick/index.html#add-your-own",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Add your own",
    "text": "Add your own\nI wanted to record for posterity how you (and me) can create this sort of thing.\n\nFirst, create a new package—I like to use usethis::create_package()—and complete basic things like the DESCRIPTION file (I wrote about this before)\nWrite functions in an R script—I like to use usethis::use_r() to create this script in the package—that insert code or replace selected text using the {rstudioapi} package)\nAdd an inst/rstudio/addins.dcf file4 that declares each of your Addins\n\nPoints 2 and 3 are in scope for this quick post.\n\nUse {rstudioapi}\nWhat do I mean by ‘write functions that insert or replace’ text?\nWell, insertion is straightforward. Here’s the function definition from {backtick} to insert a single backtick:\n\nbt_backtick &lt;- function() {\n  rstudioapi::insertText(\"`\")\n}\n\nIn other words, it’s as simple as a function that contains rstudioapi::insertText(). This fetches information from the IDE to know where the cursor is placed in your script, which is where a supplied text string (a single backtick in this case) will be inserted.\nAnd what about text replacement? A similar story: the {rstudioapi} package is used to detect the selected text, which can then be pasted together with other strings to produce and insert a new compound string. Here’s an example from {backtick} for surrounding selected text with backticks:\n\nbt_backticks &lt;- function() {\n\n  active_doc &lt;- rstudioapi::getSourceEditorContext()\n\n  if (!is.null(active_doc)) {\n\n    selected_text &lt;- active_doc$selection[[1]]$text\n\n    text_replace &lt;- paste0(\"`\", selected_text, \"`\")\n\n    rstudioapi::modifyRange(\n      active_doc$selection[[1]]$range,\n      text_replace\n    )\n\n  }\n\n}\n\nSo, in short, rstudioapi::getSourceEditorContext() fetches information about the script pane, including the current selection. That selection can be pasted with other strings, such as a backtick character at the start and end, and then inserted back into the script pane with rstudioapi::modifyRange() to replace the original selection.\nAnd, well… that’s it for functions. All you need to do now is create a special text file so that the functions can be interpreted as Addins.\n\n\nCreate a dcf\nSo, for example, the bt_bactick() function can be exposed as an Addin function by adding the following to the inst/rstudio/addins.dcf file:\nName: Insert Backtick\nDescription: Insert a single backtick. In R Markdown file, one backtick will be\n    inserted. RStudio automatically adds a second backtick when this function is\n    used in an R script.\nBinding: bt_backtick\nInteractive: false\nThis is pretty straightforward: you provide a name (which will be the name you see in the RStudio Addins dropdown menu) and a description (I just copied the description I wrote for the function documentation), along with the binding (just the function name). There’s also ‘interactive’, which tells RStudio if it needs to wait for the user to do something (no, or false in our example)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#addintional-resources",
    "href": "posts/2022-02-19-backtick/index.html#addintional-resources",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Addintional resources",
    "text": "Addintional resources\nThis was a quick roundup to help you (and me) remember quickly how to create this kind of simple insert/replace type of RStudio Addin.\nI recommend you check out a number of more in-depth resources:\n\nSharon’s excellent video ‘Write your own RStudio addins’\nJozef’s in-depth blog series\nRStudio’s very own introduction\n\nLet me know about other useful Addins or tutorials for making them.\nAnd perhaps begin lobbying the Italian government to a backtick key on their keyboards as a gesture of solidarity with developers."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#environment",
    "href": "posts/2022-02-19-backtick/index.html#environment",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:08:17 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#footnotes",
    "href": "posts/2022-02-19-backtick/index.html#footnotes",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nShout-out to Serdar, who has contributed functions to {blogsnip}!↩︎\nIdeally this would be fixed upstream. Re-map the other software to another key? Easier said than done if it’s a work computer you’re using. Turn off the other software when you’re not using it? But what if you forget to switch it back on? Etc, etc. Relax, this is just a silly blog post. There must be a relevant xkcd though: why fix the real problem when you can write more software to paper the cracks?↩︎\nConfirmed by a real-life Italian (as far as I can tell)!↩︎\n‘Debian Control File’ if you must know, but it doesn’t really matter. A package DESCRIPTION file is also a type of dcf file, I believe.↩︎"
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html",
    "title": "Repaying Tom Nook with {R6}",
    "section": "",
    "text": "I assume the other villagers are happy with my choice of town flag."
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#tldr",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#tldr",
    "title": "Repaying Tom Nook with {R6}",
    "section": "tl;dr",
    "text": "tl;dr\nHow would capitalist raccoon-dog Tom Nook simulate home-loan payments using R?1\nI built a version of Animal Crossing’s Automatic Bell Dispenser (a kind of ATM/cashpoint) using Winston Chang’s {R6} package, inspired by an exercise from Hadley Wickham’s Advanced R book."
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#what-do-those-words-mean",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#what-do-those-words-mean",
    "title": "Repaying Tom Nook with {R6}",
    "section": "What do those words mean?",
    "text": "What do those words mean?\n\nAnimal Crossing\nAnimal Crossing is a wholesome Nintendo videogame franchise in which you arrive on an island and befriend anthropomorphic animal villagers. You can catch insects and fish, design clothes, fill a museum with fossils, develop the infrastructure of the island and interact with other players. It’s pretty chill.2 The latest version, New Horizons, was recently released.3\n\n\nTom Nook\nTom Nook is a tanuki. Depending on who you ask, he’s either a maniacal rip-off merchant,4 or a misunderstood chap who gives you several interest-free home loans with no obligation.\n\n\nAutomatic Bell Dispenser\nThe in-game currency is Bells, which can be gained by selling things, helping residents, hitting rocks with a spade and joining the ‘stalk market’ by buying and flipping turnips. You use an Automatic Bell Dispenser to deposit, withdraw and make loan payments.\n\n\nR6\nR is primarily a function-focused language: mostly you’re writing functions that output objects.\nBut there’s also Object-Oriented Programming (OOP), which is common in many other languages. OOP brings together values (fields) and functions (methods) into classes. You can interact with a class via its methods, which may trigger further internal methods and update the values. You can also create subclasses that add to or amend the logic of its parent.\nYou may have heard of the object-oriented systems S3 and S4 in R; R6 provides another, newer implementation of OOP. There are two important things to know about R6 objects. To simplify, they’re:\n\nencapsulated, meaning that you apply the methods to object directly, like object$some_method()\nmutable, meaning that fields are updated as you apply the methods\n\nI’m not going into depth about OOP and R6 here. For more, I recommend:\n\nthe {R6} introduction vignette by Winston Chang\na chapter in Advanced R by Hadley Wickham5\nthe article ‘How to explain OOP concepts to a 6-year-old’ by Alexander Petkov of freeCodeCamp\n\nA really intriguing and illustrative use-case of R6 is Giora Simonchi‘s Castle of R, which is a text adventure game for R (!). Here, classes are things like ’room’ and ‘door’ that have specific properties and actions you can take on them. As you play, the fields are modified depending on your location, interactions you’ve had, or items you’re carrying."
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#demo",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#demo",
    "title": "Repaying Tom Nook with {R6}",
    "section": "Demo",
    "text": "Demo\nThe R6 chapter of the Advanced R book has an exercise about building a bank account class.\nInspired by this, I’ve built an AutomaticBellDispenser class with certain fields (savings and loan values) and methods (deposit(), withdraw() and loan_payment() functions) that mimic the functionality of an Automatic Bell Dispenser. 6\n\n\n\nThe Automatic Bell Dispenser interface. The grind is real.\n\n\nYou can click below to expand the code, but it may be a lot to take in at once. Skip ahead to the next section to see examples of its use and then some explanations of specific bits of the code.\n\n\nClick to expand the full AutomaticBellDispenser class.\n\n\n# Load packages\nlibrary(R6)  # install.packages(\"R6\")\nlibrary(emo)  # remotes::install_github(\"hadley/emo\")\n\n# Build the class\nAutomaticBellDispenser &lt;- R6Class(\n  \"AutomaticBellDispenser\",  # class name\n  list(\n    \n    # set initial values for fields\n    savings = 0,     # start from zero\n    loan = 2498000,  # loan size\n    \n    # show on startup the account status and options\n    initialize = function(...) {\n      loan_formatted &lt;- format(  # reformat the loan field value\n        self$loan,          # the 'loan' field from this class (i.e. 'itself')\n        big.mark = \",\",     # format as '1,000' rather than '1000'\n        scientific = FALSE  # prevent 12000000 being displayed as '1.2e+07'\n      )\n      savings_formatted &lt;- format(  # reformat the savings field value\n        self$savings, big.mark = \",\", scientific = FALSE\n      )\n      cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")  # cat() prints to console\n      cat(emo::ji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n      cat(emo::ji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n      cat(\n        \"Please make a selection from the menu below\\n\\n\",\n        emo::ji(\"house\"), \"loan_payment()\\n\",\n        emo::ji(\"arrow_up\"), \"deposit()\\n\",\n        emo::ji(\"arrow_down\"), \"withdraw()\"\n      )\n    },\n    \n    # method to deposit an amount into savings\n    deposit = function(amount = 0) {    # function takes an amount to deposit\n      amount_int &lt;- as.integer(amount)  # round to nearest lowest integer\n      if (amount - amount_int &gt; 0) {    # warning if rounding has occurred\n        warning(\n          \"Deposit rounded to \", amount_int, \" Bells.\\n\",\n          call. = FALSE # prevents printing of the error-causing line\n        )\n      } else {\n        self$savings &lt;- self$savings + amount_int  # add amount to savings\n      }\n      invisible(self)  # return but don't print\n    },\n    \n    # function to withdraw an amount from savings\n    withdraw = function(amount = 0) {\n      amount_int &lt;- as.integer(amount)  # round to nearest lowest integer\n      if (amount - amount_int &gt; 0) {  # warning if rounding has occurred\n        warning(\"Withdrawal rounded to \", amount_int, \" Bells.\\n\", call. = FALSE)\n      }\n      if (self$savings - amount_int &lt; 0) {\n        warning(  # can't withdraw more than you have so warn and take max\n          \"Withdrew all savings: \", self$savings, \" Bells.\\n\", call. = FALSE\n        )\n        self$savings &lt;- 0\n      } else {  # otherwise subtract amount from your savings\n        self$savings &lt;- self$savings - amount_int\n      }\n      invisible(self)  # return but don't print\n    },\n    \n    # function to make loan payment from savings\n    loan_payment = function(amount = 0, full_amount = FALSE) {\n      if (self$loan == 0) {  # stop if the loan has already been paid in full\n        stop(\"You already finished paying your loan!\\n\", call. = FALSE)\n      }\n      amount_int &lt;- as.integer(amount)  # round to nearest lowest integer\n      if (amount - amount_int &gt; 0) {  # warning if rounding has occurred\n        warning(\"Payment rounded to \", amount_int, \" Bells.\\n\", call. = FALSE)\n      }\n      if (full_amount == TRUE) {  # choose to pay with everything in savings\n        self$loan &lt;- self$loan - self$savings  # reduce loan by savings amount\n        self$savings &lt;- 0  # remove all savings\n      } else if (self$savings - amount_int &lt; 0) {\n        warning(  # can't pay more than total savings, so warn and pay max\n          \"Paid total amount from savings instead: \", self$savings, \" Bells.\\n\",\n          call. = FALSE\n        )\n        self$loan &lt;- self$loan - self$savings  # subtract total savings\n        self$savings &lt;- 0  # all savings used for this repayment\n      } else if (self$loan - amount_int &lt; 0) {\n        warning(  # can't pay more than remaining loan, warn and pay remaining\n          \"Paid total remaining loan instead: \", self$loan, \" Bells.\\n\",\n          call. = FALSE\n        )\n        self$loan &lt;- 0  # loan paid in full\n        self$savings &lt;- amount_int - self$loan  # excess back into savings\n      } else {  # otherwise just remove the amount from the savings and loan\n        self$savings &lt;- self$savings - amount_int\n        self$loan &lt;- self$loan - amount_int\n      }\n      if (self$loan == 0) {  # when the loan is totally cleared\n        cat(\n          emo::ji(\"smiley\"),\n          \"Sweet! I finally finished paying off my very last home loan!\",\n          emo::ji(\"tada\"), \"\\n\\n\"\n        )\n      }\n      invisible(self)  # return but don't print\n    },\n    \n    # Print method wen calling the name of an object with this class\n    # (Content matches the initialise method)\n    print = function(...) {\n      loan_formatted &lt;- format(self$loan, big.mark = \",\", scientific = FALSE)\n      savings_formatted &lt;- format(\n        self$savings, big.mark = \",\", scientific = FALSE\n      )\n      cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")\n      cat(emo::ji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n      cat(emo::ji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n      cat(\n        \"Please make a selection from the menu below\\n\\n\",\n        emo::ji(\"house\"), \"loan_payment()\\n\",\n        emo::ji(\"arrow_up\"), \"deposit()\\n\",\n        emo::ji(\"arrow_down\"), \"withdraw()\"\n      )\n    }\n      \n  )\n)\n\n\n\nUse the class\nHow can you use this class? I’ll explain below how to:\n\nstart a new instance of the class\nuse the deposit() method to increase the value of the savings field\nuse the withdraw() method to decrease the savings field\nuse the pay_loan() method to decrease the value of the loan field\n\n\nInitialise\nYou can start, or ‘initialise’, an instance of the class by calling new() on the class name and assigning it. I’ve called my object account.\n\naccount &lt;- AutomaticBellDispenser$new()\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,498,000 Bells\n🐖 Savings Balance: 0 Bells\n\nPlease make a selection from the menu below\n\n 🏠 loan_payment()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nInitialising the class also triggers the printing of the current account details and instructions. This mimics the interface you see on the Automatic Bell Dispenser in-game.\nIn this case, you can see that we have zero savings, but a multi-million loan to pay off (!). This value represents the final loan amount that Nook sets you in the game.7\n\n\nMake a deposit\nNow we can make a deposit to our account. Use $ notation to say ‘to the account object apply the deposit method’. In this case, the value supplied to deposit is the amount of Bells.\n\naccount$deposit(1000)\naccount  # check status of account\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,498,000 Bells\n🐖 Savings Balance: 1,000 Bells\n\nPlease make a selection from the menu below\n\n 🏠 loan_payment()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nYou could also access the savings field directly from the account object:\n\naccount$savings\n\n[1] 1000\n\n\nSo we now have savings of 1000 Bells! Of course, I just made up that value. I could add as much as I want. Use your imagination!\nIn the game you have to complete various tasks to add money to your pocket. You can then deposit from your pocket into your savings. I haven’t created the concept of ‘pockets’ in this demo, but you could create a pocket class. You could also, for example, create a fish class with subclasses for each species, including their trade value. You could, in theory, mimic the entirety of Animal Crossing in this way.\n\n\nWithdraw and pay loan\nWe can also withdraw Bells and make loan payments with this class.\nNote that you can chain method calls together with $ between them, so we could withdraw 200 Bells and make a loan payment of 300 Bells at once.\n\naccount$withdraw(200)$loan_payment(300)\naccount\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,497,700 Bells\n🐖 Savings Balance: 500 Bells\n\nPlease make a selection from the menu below\n\n 🏠 loan_payment()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nSo the loan amount was reduced by 300 Bells, but our savings reduced by 500 Bells (200 + 300 Bells).\nImportant point: notice how we didn’t have to overwrite the account object to update the values? Remember that this is because the class is mutable.\nAs in the game, you can also choose to transfer everything in your savings by providing full_amount = TRUE rather than a value amount.\n\naccount$loan_payment(full_amount = TRUE)\naccount\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,497,200 Bells\n🐖 Savings Balance: 0 Bells\n\nPlease make a selection from the menu below\n\n 🏠 loan_payment()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nSo the loan balance has gone down by a further 500 bells, which was the remainder of our savings.\n\n\nMessages\nThere are some limits to the Automatic Bell Dispenser system; there’s no overdraft and the outstanding loan amount can’t be negative, for example. I built a few warnings and errors into the class to handle these situations. For example:\n\nwarning – you can only pay in whole Bells (decimal amounts are rounded down to the nearest whole number)\nwarning – you can’t remove more savings than you have (defaults to removing the maximum amount you have in savings)\nwarning – you can’t pay off more than the total loan amount (defaults to paying total remaining loan)\nerror – once you pay off your loan, you can’t make more payments!\n\nYou’ll also get a celebratory message when the loan reaches zero.\nSo, for example, here’s what happens if you try to pay off the loan with more savings than you have and if you also try to pay in decimal Bells:\n\naccount$deposit(1000)$loan_payment(1001.10)\n\nWarning: Payment rounded to 1001 Bells.\n\n\nWarning: Paid total amount from savings instead: 1000 Bells.\n\n\nWe got two warnings:\n\nThe decimal value was rounded down to the nearest integer\nWe tried to pay off 1001 Bells, but only had a total of 1000 Bells\n\nThe result is that our savings are empty and the loan is 1000 Bells lighter.\n\naccount$savings\n\n[1] 0\n\naccount$loan\n\n[1] 2496200\n\n\nAnd if we add enough Bells to pay off the loan?\n\naccount$deposit(2496200)$loan_payment(full_amount = TRUE)\n\n😃 Sweet! I finally finished paying off my very last home loan! 🎉 \n\n\n\n\n\nBuild the class\nI wanted to point out a few elements of the code that went into building the class. You can refer back to the full code in the expandable section above.\nFirst, the basic structure is a call to R6::R6Class(), which contains the name of the class and a list of values and fields.\n\nAutomaticBellDispenser &lt;- R6Class(  # call the function, assign a name\n  \"AutomaticBellDispenser\",  # class name\n  list(\n    # truncated (fields and methods go here)\n  )\n)\n\nThere are two fields in this class, which are put inside the list() with some starting values:\n\n#...\n  # set initial values for fields\n  savings = 0,     # start from zero\n  loan = 2498000,  # loan size\n#...\n\nThere’s an initialize() method that I’ve used to print the Automatic Bell Dispenser display when a new instance of the class is started. It reformats values and uses emoji for the lols.\n\n#...\n  # show on startup the account status and options\n  initialize = function(...) {\n    loan_formatted &lt;- format(  # reformat the loan field value\n      self$loan,          # the 'loan' field from this class (i.e. 'itself')\n      big.mark = \",\",     # format as '1,000' rather than '1000'\n      scientific = FALSE  # prevent 12000000 being displayed as '1.2e+07'\n    )\n    savings_formatted &lt;- format(  # reformat the savings field value\n      self$savings, big.mark = \",\", scientific = FALSE\n    )\n    cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")  # cat() prints to console\n    cat(emo::ji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n    cat(emo::ji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n    cat(\n      \"Please make a selection from the menu below\\n\\n\",\n      emo::ji(\"house\"), \"loan_payment()\\n\",\n      emo::ji(\"arrow_up\"), \"deposit()\\n\",\n      emo::ji(\"arrow_down\"), \"withdraw()\"\n    )\n  },\n#...\n\nThe same code is used in the print() method too, which means that these details will be printed whenever you call your object.\nThe methods for deposit(), withdraw() and loan_payment() look similar, but have slightly different behaviour. The simplest is deposit(), which makes the input an integer and warns the user if a decimal value has been used, then adds the amount to the savings field.\n\n#...\n  deposit = function(amount = 0) {    # function takes an amount to deposit\n    amount_int &lt;- as.integer(amount)  # round to nearest lowest integer\n    if (amount - amount_int &gt; 0) {    # warning if rounding has occurred\n      warning(\n        \"Deposit rounded to \", amount_int, \" Bells.\\n\",\n        call. = FALSE # prevents printing of the error-causing line\n      )\n    } else {\n      self$savings &lt;- self$savings + amount_int  # add amount to savings\n    }\n    invisible(self)  # return but don't print\n  }\n#...\n\nNote how the field values are accessed with self$field_name. We also return self at the end, but it’s wrapped in invisible() so it updates the field without printing."
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#what-now-squirt",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#what-now-squirt",
    "title": "Repaying Tom Nook with {R6}",
    "section": "What now, squirt?",
    "text": "What now, squirt?\nSo now you know how I’ve been spending my time during this period of enforced isolation: playing Animal Crossing, messing about with R or, most importantly, messing around with Animal Crossing in R.\nWhile this use of {R6} has been totally frivolous, it’s helped me understand OOP a bit better and get more of an insight into how R works.\nI recommend you take a look at the Advanced R book, which is online for free or can be purchased,8 for a better understanding of OOP and its implementations in R.\nI also recommend getting hold of Animal Crossing: New Horizons. Just be wary of that raccoon guy…\n\n\n\nTip: the lucrative Tarantula Island will help you satiate Nook’s thirst for Bells."
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#environment",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#environment",
    "title": "Repaying Tom Nook with {R6}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 15:30:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emo_0.0.0.9000 R6_2.5.1      \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     assertthat_0.2.1  lubridate_1.9.2   fastmap_1.1.1    \n [5] xfun_0.39         magrittr_2.0.3    glue_1.6.2        stringr_1.5.0    \n [9] knitr_1.43.1      htmltools_0.5.5   timechange_0.2.0  generics_0.1.3   \n[13] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3      \n[17] compiler_4.3.1    purrr_1.0.1       rstudioapi_0.15.0 tools_4.3.1      \n[21] evaluate_0.21     yaml_2.3.7        crayon_1.5.2      rlang_1.1.1      \n[25] jsonlite_1.8.7    htmlwidgets_1.6.2 stringi_1.7.12"
  },
  {
    "objectID": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#footnotes",
    "href": "posts/2020-04-04-repaying-tom-nook-with-r6/index.html#footnotes",
    "title": "Repaying Tom Nook with {R6}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLiterally the most important question in 2020.↩︎\nPerhaps a literal life-saver in these times of self-isolation.↩︎\nMy island has peaches and lillies. Current villagers are Biff, Renee, Midge, Al and Patty.↩︎\nTo be fair, tanuki do have a mythical reputation as tricksters. And massive balls.↩︎\nSpoiler alert: there’s an online book of solutions to the questions by Malte Grosser, Henning Bumann and Hadley Wickham.↩︎\nI don’t claim that this is an optimal approach, nor is it fully tested, but it works! Tell me how to improve it.↩︎\nImpressive, bearing in mind that the ubiquitous Sea Bass (no, wait, more like a C+) has a sale price of only 400 Bells.↩︎\nNone of my posts are sponsored, but I will accept payments in the form of Bells.↩︎"
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#tldr",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#tldr",
    "title": "Accessibility workshop at #Sprint18",
    "section": "tl;dr",
    "text": "tl;dr\nI went to a public-sector accessibility workshop. Designing for accessibility can make products and services better for everyone."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#sprinting",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#sprinting",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Sprinting",
    "text": "Sprinting\nSprint events are a chance for the government digital, data, design and technology community to:\n\nlook back on the work we’ve been doing to transform government and to look forward at what we need to do\n\nKevin Cunnington, Director General of the Government Digital Service (GDS), outlined this in a recent blog post.\nThis year’s major themes were transformation, innovation and collaboration. The event was held at the Southbank Centre and Royal Festival Hall in London, with 40 speakers, 19 workshops and over 700 delegates representing 40 departments and agencies.\nThe event was captured in a live blog and with the Twitter hashtag #Sprint18. A round-up video is also available."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#motivation",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#motivation",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Motivation",
    "text": "Motivation\nThe analytical community in my department has been producing a range of self-service tools for colleagues, but we’ve generally got little experience of how to incorporate accessibility into our work. Often we have a small pool of users internally who can tell us their needs directly, but we can’t always know whether our creations will be passed on to users that we aren’t aware of.\nI went to the accessibility workshop at Sprint 18 to get an insight into what’s being done across government and what we can learn. This blog post provides a record of the session and will hopefully help to start a conversation."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#presenters",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#presenters",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Presenters",
    "text": "Presenters\nThe session was presented by:\n\nAlistair Duggin (@dugboticus), head of accessibility at GDS and organiser of The London Accessibility Meetup Group (@a11ylondon)\nJames Buller (@jbuller), Access Needs Lead at Home Office Digital, Data and Technology (@HODigital)"
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#what-is-accessibility",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#what-is-accessibility",
    "title": "Accessibility workshop at #Sprint18",
    "section": "What is accessibility?",
    "text": "What is accessibility?\nAlistair opened by explaining that:\n\naccessibility means making sure there are no barriers that might prevent someone from accessing or using something\n\nUsers may have needs related to vision, hearing, motor skills and cognitive skills, among many others. It’s important to take these into account to maximise inclusivity.\nThis is hugely relevant for governments because their users are all of the citizens in the country. That’s a lot of people with a lot of accessibility needs to consider."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#were-all-only-temporarily-not-disabled",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#were-all-only-temporarily-not-disabled",
    "title": "Accessibility workshop at #Sprint18",
    "section": "We’re all only temporarily not disabled",
    "text": "We’re all only temporarily not disabled\nDesigning for accessibility can improve the user experience for everyone.\nThis is because impairments exist along a scale of permanent to situational. For example, consider the needs of users:\n\nwho are deaf (permanent)\nhave an ear infection (situational)\nare in a noisy location (situational)\n\nDesigning for the permanently deaf could benefit everyone on the continuum. For example, captions on video content make the content accessible for all of these people.\nIt’s worth remembering that the prevalence of disability rises with age and we’re all likely to face impairment at some point. Don’t forget that you’re planning and building services for your future self as well."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#achieving-digital-accessibility",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#achieving-digital-accessibility",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Achieving digital accessibility",
    "text": "Achieving digital accessibility\nSimply putting something online doesn’t make it accessible by default.\nFour things are required to achieve digital accessibility, as outlined in the ‘what we mean when we talk about accessibility’ blog post on GOV.UK. Your content must be:\n\nperceivable to at least one of the user’s senses (a webpage that can be interpreted by a screen reader, for example)\nunderstandable so that it makes sense to the user (it’s not enough for it to be perceived, it must also be interpretable)\noperable so users can interact with it (support for keyboard-only input, for example)\nrobust so that it works as expected with the technology that users have access to\n\nIf any of these are broken, then the thing is probably unusable."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#the-law",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#the-law",
    "title": "Accessibility workshop at #Sprint18",
    "section": "The law",
    "text": "The law\nDesigning for accessibility goes beyond being helpful. The flyer for the workshop stated:\n\nConsidering the needs of a diverse range of people helps us design better services and products. Making services accessible is a also a legal requirement.\n\nThe Equality Act 2010 means government must not discriminate against people. In addition, a new EU directive is being brought into UK law later this year that will create new rules for public sector bodies to abide by when presenting content.\nThis means that government is actually obliged to take steps to reduce barriers and improve inclusivity of its services.\nNote that a consultation on the accessibility of public sector websites and apps is currently open for comment until 28 May 2018."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#we-can-improve",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#we-can-improve",
    "title": "Accessibility workshop at #Sprint18",
    "section": "We can improve",
    "text": "We can improve\nAlistair described some discovery work by GDS to investigate how accessibility was being considered across government departments. In general, experience was low and people were unsure what they should be doing.\nHelp and advice are available. Service designers should:\n\nplan for accessibility early; don’t wait until a project is nearly finished\nget impaired users involved in user research to ensure needs are being met\nconsult the accessibility and assisted digital pages of the Service Manual to help meet the Digital Service Standard\nmake use of the Service Manual’s patterns and reusable elements to help build consistent services (these are currently being consolidated into the upcoming GOV.UK Design System)\ntake a look at the user profiles for understanding disabilities and impairments\nmake use of the assistive technology workbench at GDS’s office"
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#culture-change",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#culture-change",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Culture change",
    "text": "Culture change\nJames acknowledged that it’s not just about having the right tools in place. Departments may need to change their ethos to make sure that accessibility is baked into design from day one.\nThere should be a mentality that’s it’s everyone’s responsibility. Everyone should always ask ‘is this accessible?’ when building something. If not, then why not?\nBut it’s not just about generating interest. Assigning and meeting goals for accessibility will help to make sure that you’re accountable for improving your services.\nA big part of this is getting the support of senior leaders, who can help move things along and help to ensure that emphasis is in the right place."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#posters",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#posters",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Posters",
    "text": "Posters\nOne part of culture change is raising awareness. The Home Office have done this by creating a series of posters on the dos and dont’s of designing for accessibility.\nThese are available for download from GitHub."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#questions-and-answers",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#questions-and-answers",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Questions and answers",
    "text": "Questions and answers\nI’ve paraphrased answers to audience questions.\n\nSometimes accessibility is seen as pass/fail thing. But can you actually make services accessible for everyone?\n\nIt’s hard to make things 100 per cent accessible for everyone. You just need to make progress and remove exclusionary barriers. The goal is to stop accidental exclusion.\nThis is why user research is important; the guidelines might not actually be relevant for your particular users.\nConsider the passports pages of GOV.UK: putting the information on a single page made it difficult for people with Attention Deficit Disorder to focus, but spreading it across multiple pages was an issue for people with memory problems. Two versions were required.\n\nDoes government have a relationship with producers of assistive technology\n\nThere’s not been a relationship historically, but we’re starting to form them with vendors. It would be great for them to help us with issues like browser compatibility and assistive technologies. We also raise bug reports where we can.\n\nWhat things can we focus on immediately?\n\nUse plain language. The text of hyperlinks must make sense on their own, since a screen reader will read the text to users. It’s not enough to write ‘click here’. Images should have good alt-text so that screen readers can describe an image to visually impaired users. Videos should be captioned.\nFollow good practice as usual, but take it to the next level."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#summary",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#summary",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Summary",
    "text": "Summary\nThe workshop made me think about what I can do to make sure that the tools I create are accessible to our users. I’ll certainly be reporting back on this workshop to my team and I hope that others find this summary useful. At very worst, here are three things you can do:\n\nEasy: read the Accessibility blog on GOV.UK.\nReview your practices: consult the Accessibility and assisted digital pages of the Service Manual to help meet the Digital Service Standard.\nGet involved: join the cross-government accessibility community, who share resources and hold meetups.\n\nFinally, Alistair and James finished with three take-away messages:\n\nMake accessibility everyone’s responsibility and get the support of seniors in your department\nCheck your services for accessibility and get plenty of user feedback\nSet targets for fixing the issues and achieving the standards\n\n\nSee you at Sprint 19."
  },
  {
    "objectID": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#environment",
    "href": "posts/2018-05-12-accessibility-workshop-at-sprint18/index.html#environment",
    "title": "Accessibility workshop at #Sprint18",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 21:21:31 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html",
    "href": "posts/2018-06-26-mail-merge/index.html",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "",
    "text": "Dawson’s Creek’s Dawson leaks (via Hulu)."
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#tldr",
    "href": "posts/2018-06-26-mail-merge/index.html#tldr",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "tl;dr",
    "text": "tl;dr\nYou have customer details. You want to send each person a personalised letter from a template. You want to mail merge, basically.1\nThis post shows how you can use R to iteratively produce separate Microsoft Word reports from a common template, each one with slightly different data. Here I use R Markdown and the {knitr} package to render a separate report about each episode of Dawson’s Creek (a classic use case!)."
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#merge-those-mails",
    "href": "posts/2018-06-26-mail-merge/index.html#merge-those-mails",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Merge those mails",
    "text": "Merge those mails\nI remember learning to mail merge in computer class at the turn of the century; autocompleting a Word template letter with details for imaginary customers from some made-up Access database.\nI no longer need to invoice ‘Mr Sonic The-Hedgehog’ for ordering ‘25 chili dogs’, but the general approach of generating the same template multiple times with different information is still pertinent. The difference now is that I don’t want to use proprietary software to do it and I want the process to be more reproducible.\nI’ve helped a few colleagues with this recently so they could avoid hours of copy-pasting. R is a natural choice for automating this kind of task and for maximising reproducibility."
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#who-will-she-choose",
    "href": "posts/2018-06-26-mail-merge/index.html#who-will-she-choose",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Who will she choose?",
    "text": "Who will she choose?\nTo keep to the turn-of-the-millennium theme, this post explains how to autogenerate reports that contain data for each episode of the first season of the hit late-90s-early-2000s-weirdly-articulate-teen-angst-love-triangle masterpiece that is Dawson’s Creek. Data via Wikipedia.\nI’ve created an accompanying GitHub repository where you can download or clone a whole R Project that replicates the approach used in this post."
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#approach",
    "href": "posts/2018-06-26-mail-merge/index.html#approach",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Approach",
    "text": "Approach\nA basic overview of the process is that you:\n\nwrite a template document using R Markdown, with snippets of R code that will pull in the data for each element you’re iterating over (e.g. Dawson’s Creek episodes)\nmake reference to a Word document that contains the style information for your output (i.e. fonts, colours, etc)\nloop over each element (e.g. each episode), supplying data to the template and rendering (‘knitting’) a separate output file for each one\n\n[Update: this approach is quite basic. You may want to read a more recent post on this blog that uses parameterised R Markdown reports and iteration with the {purrr} package, which may suit you better.]\n\nSet up\nI recommend creating an RStudio Project with three files important to this task:\n\nYour document template prepared in R Markdown (file type .Rmd)\nYour style-reference document (.docx) that we’ll put in a style/ subfolder\nA script (.R) file for reading your data and looping through each element\n\nAside from your .Rproj file, your folder should also contain:\n\na subfolder to hold the output files (e.g. output/)\nany additional subfolders you need for input files (e.g. data/ and images/)\nan optional README.md file to explain the purpose of your work\n\n\n\n\nA simple folder setup for your working directory\n\n\nBelow is a more detailed explanation using the Dawson’s Creek example. Click to jump to each section:\n\nthe R Markdown template\nthe Word document used as a style reference\nthe R script for iterating over the template\n\n\n\n1. The template\n\nR Markdown\nYour report template should be an R Markdown file. In short, R Markdown files allow you to write plain text formatted with special symbols and insert R code inline or in ‘chunks’. You can find out more about R Markdown from the RStudio website. I’ve also written a short guide to writing R Markdown documents and created a small set of slides, both with beginners in mind.\nYou can see the full R Markdown file for this demo in the source code on GitHub.\n\n\nSpecify Word output\nThe template itself should start with a YAML header section that states (i) the output type, which is word_document in this example2, and (ii) a path to the Word document that contains the style information (i.e. style/dawson_style.docx in this example). The style document is explained in the next section.\nHere’s what the basic YAML header looks like:\n\n---\noutput:\n  word_document:\n    reference_docx: style/dawson_style.docx\n---\n\n\n\nReference the data\nWe’ll be feeding data into the template via an object called episode. This object is a data frame that contains the variables that we want to put into our template, with one row per episode (more on this in the section below about iterating below).\nWhen it comes to iterating over the data to produce each output file, we’ll be subsetting a row at a time so we only pass one episode’s information to the template.\nThis means the R code in our R Markdown file should refer to the episode object. For example, here’s some inline code that will be rendered into the production code and title (see this in the source repo on GitHub):\n\n`r paste0(episode$production_code, \": '\", episode$title, \"'\")`\n\nAnd here’s an example R Markdown chunk that will get a table containing information about the episodes (see this in the source code):\n\nepisode %&gt;% \n  dplyr::select(  # choose these columns for display\n    Season = season,\n    `Number in season` = number_in_season,\n    `Number in series` = number_in_series,\n    `Original air date` = original_air_date\n  ) %&gt;% \n  knitr::kable()  # print to output table\n\n\n\n\n2. The style\nThe default output when rendering R Markdown to Word is a bit boring. Instead, you can create a separate dummy Word document that contains modified styles to suit your theme.\nYou can read more about creating a style document in Richard Layton’s ‘happy collaboration with Rmd to docx’ on the R Markdown site. Basically you create a dummy document in which you’ve set the formatting for each style element (title, third-level header, paragraph text, etc), store it in your working repository and refer to it from the YAML of your R Markdown report (as mentioned in the section above).\n\n\n\nThe style document\n\n\nYou can download the example style file used in this demo from the GitHub repo.\n\n\n3. Iterate\nSo we have the template (.Rmd) and style (.docx) files in place. Now we need an R script (.R) to orchestrate the iteration of our outputs.\nThis script (i) reads the data and (ii) executes a loop that applies episode data to the template, saving to a specified subfolder with a unique file name. You’ll get one document for each unique element; in this demo we’ll get 13 because there are 13 rows (episodes) in our data set.\nYou can see the script file for this demo in the source code on GitHub.\nAfter reading in the data with something like data &lt;- readr::read_csv(file = \"data/dawsons-creek-season-1.csv\") you can write a loop that looks something like this:\n\nfor (i in data$production_code){  # for each unique episode...\n  \n  # Isolate that episode from the dataset\n  \n  episode &lt;- data[data$production_code == i, ]  \n  \n  # The one-row dataframe object 'episode' we just created will be used as the\n  # source for filling the details in on the template file\n  \n  # Now render ('knit') the R Markdown file to Word format, name it and save it\n  \n  rmarkdown::render(\n    input = \"01_template.Rmd\",  # path to the template\n    output_file = paste0(\"episode_\", i, \".docx\"),  # name the output\n    output_dir = \"output\"  # folder in which to put the output file\n  )\n\n}\n\nSo this code:\n\nloops through episodes given unique values in the production_code column\nsubsets the data object (a data frame of all episodes) to isolate the production code for each episode in turn\nrenders the template document after filling it with the episode data\ngives the file a name that incorporates the production code\nsaves this file to the output/ subfolder in our project directory"
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#execute",
    "href": "posts/2018-06-26-mail-merge/index.html#execute",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Execute",
    "text": "Execute\nRun the R script and the files will be rendered in turn according to the formatting in the style document, and added one by one to the output/ folder. It’s fun to open this folder and watch them pop into existence.\n\n\n\nReport for episode 101 of Dawson’s Creek\n\n\n\n\n\nReport for episode 102 of Dawson’s Creek\n\n\nCongratulations! You now have a separate file that contains the information for each of the episodes in season 1 of Dawson’s Creek! Make sure to share with your friends (assuming you’re not in an awkward love triangle)."
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#environment",
    "href": "posts/2018-06-26-mail-merge/index.html#environment",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\nI don’t wanna wait for this post to be oooover…\n\n\nLast rendered: 2023-08-09 00:06:56 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2018-06-26-mail-merge/index.html#footnotes",
    "href": "posts/2018-06-26-mail-merge/index.html#footnotes",
    "title": "Iterative R Markdown reports for Dawson’s Creek",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee Andrie de Vries’s package {mailmerge} if you actually want to iteratively formulate email content from a template and email to people via {gmailr}.↩︎\nYou don’t have to render to Word. You could render to HTML or PDF instead, using CSS to style your document instead of a .docx style template.↩︎"
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html",
    "href": "posts/2019-11-02-tidyswirl/index.html",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "",
    "text": "Starting Swirl and selecting the tidyverse course."
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#tldr",
    "href": "posts/2019-11-02-tidyswirl/index.html#tldr",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "tl;dr",
    "text": "tl;dr\nContribute to Tidyswirl: a Swirl course that lets people learn the tidyverse from within R.\n\n Note\nI never got around to developing this and so I archived the GitHub repo. You should take a look at swirl-tidy by Seo-young Silvia Kim instead."
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#swirl",
    "href": "posts/2019-11-02-tidyswirl/index.html#swirl",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "Swirl",
    "text": "Swirl\nSwirl is a framework for learning R from within R itself. You can install it with install.packages(\"swirl\"). Swirl courses can be created by anyone and installed from nearly anywhere, though the Swirl course repository is the ‘official’ source.\nI’ve written before about how the {swirlify} package makes it easier to create Swirl packages."
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#tidyswirl",
    "href": "posts/2019-11-02-tidyswirl/index.html#tidyswirl",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "Tidyswirl",
    "text": "Tidyswirl\nI didn’t talk much in my previous Swirl post about a course I started to develop on GitHub: Tidyswirl. Its purpose is to teach the packages of the tidyverse.\n\n\n\nPlaceholder logo with apologies to the tidyverse team.\n\n\nAt the time of publication, there are two useable lessons in Tidyswirl: one for {tibble} and one for {tidyr}. I’ve updated these to correct some errors and to improve the experience. In particular, I’ve updated the gather() and spread() functions to pivot_longer() and pivot_wider(), given the update in {tidyr} 1.0.0.\nI started with these packages because of the relatively limited number of functions compared to other packages and because they’re involved typically in the early stages of a data analysis workflow.\nTry it by installing Swirl and Tidyswirl:\n\n# Install Swirl\ninstall.packages(\"swirl\")\nlibrary(swirl)\n\n# Install the Tidyswirl course\ninstall_course_github(\"matt-dray\", \"tidyswirl\")\n\n# Start Swirl\n# Tidyswirl will be one of the course options\nswirl()"
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#lesson-format",
    "href": "posts/2019-11-02-tidyswirl/index.html#lesson-format",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "Lesson format",
    "text": "Lesson format\nFor each lesson, the focal package is introduced and its roles and relationships in a tidyverse workflow are explained.\nSelected functions are introduced and explained in conceptual groups, before test questions are asked to let the learner try it out and test their understanding.\nLessons end with a reminder of the package’s purpose and with links to useful external materials.\nYou can take a look at the lesson files for the {tibble} and {tidyr} lessons as examples, though I’ve also added a template lesson too."
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#help",
    "href": "posts/2019-11-02-tidyswirl/index.html#help",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "Help!",
    "text": "Help!\nTidyswirl is unlikely to be finished anytime soon but it seems worth letting people know it exists. It’d be great for you to contribute to a lesson—which includes writing a new one for any of the other tidyverse packages—or report any issues or bugs you find when using it."
  },
  {
    "objectID": "posts/2019-11-02-tidyswirl/index.html#environment",
    "href": "posts/2019-11-02-tidyswirl/index.html#environment",
    "title": "Tidyswirl: a tidyverse Swirl course",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-24 19:34:16 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#tldr",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#tldr",
    "title": "OG emoji SVGs",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote code to produce SVG versions of the ‘first-ever’ emoji set. Using R, I scraped Emojipedia with the {polite} package and then handled images with {png}, {magick} and {svglite}."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#important-archival-work",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#important-archival-work",
    "title": "OG emoji SVGs",
    "section": "Important archival work",
    "text": "Important archival work\nI posted recently on creating ‘pixel art’ in R and have since stumbled upon an old post by mikefc on the coolbutuseless blog with a method that makes it easier to convert from an image to its ‘pixels’.\nI’ve also learnt recently of Emil’s development of the {emoji} package for R (superseding Hadley’s GitHub-only {emo} package).\nSpeaking of emoji, Jeremy Burge and colleagues have worked hard to archive and document them on Emojipedia. They posted recently about the discovery that the first emoji set was likely to be from SoftBank in 1997, rather than the NTT DOCOMO set that was acquired by MoMA.\nAs a mash-up of these things, I’ve decided to create SVG versions of the original SoftBank set. This format means that the images can be resized without loss of resolution and can be adapted in other ways, like being recoloured.\nThe approach:\n\nScrape the Emojipedia hub page for SoftBank’s 1997 emojis\nScrape each emoji’s dedicated page to retrieve its image path\nDownload each image (gif format)\nConvert gifs to PNGs to matrices\nConvert matrices to plots to SVGs\n\nThe packages we need are all available from CRAN with install.packages():\n\nsuppressPackageStartupMessages({\n  library(polite)\n  library(rvest)\n  library(purrr)\n  library(svglite)\n  library(png)\n  library(magick)\n})\n\nAll the code here is available in a GitHub repo."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#scrape-politely",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#scrape-politely",
    "title": "OG emoji SVGs",
    "section": "Scrape politely",
    "text": "Scrape politely\nIt’s best to scrape using the {polite} package, which allows you to identify yourself to the target website and observe any requests to delay between scrapes. I’ve written about this before.\nFirst we bow() to the site by providing our information and saying where we want to scrape. The returned object contains information that {polite} uses to decide whether scraping is allowed and whether a crawl delay is required.\n\nep_bow &lt;- bow(\n  url = \"https://emojipedia.org/softbank/1997\",\n  user_agent = \"M Dray &lt;https://www.matt-dray.com&gt;\"\n)\n\nep_bow\n\n&lt;polite session&gt; https://emojipedia.org/softbank/1997\n    User-agent: M Dray &lt;https://www.matt-dray.com&gt;\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nFrom the SoftBank 1997 hub page of Emojipedia we can scrape the URLs that lead to each emoji’s dedicated page. The {rvest} package has some handy functions that help us manipulate the retrieved HTML after scraping with {polite}, which rate-limits us to a retrieval every 5 seconds, given the information returned from our bow().\n\nsb_urls &lt;- scrape(ep_bow) |&gt; html_nodes(\"a\") |&gt; html_attr(\"href\")\nsb97_urls &lt;- sb_urls[grepl(\"/1997/\", sb_urls) & !grepl(\"more\", sb_urls)]\nhead(sb97_urls)\n\n[1] \"/softbank/1997/grinning-face-with-big-eyes/\"   \n[2] \"/softbank/1997/smiling-face-with-smiling-eyes/\"\n[3] \"/softbank/1997/disappointed-face/\"             \n[4] \"/softbank/1997/angry-face/\"                    \n[5] \"/softbank/1997/pile-of-poo/\"                   \n[6] \"/softbank/1997/kiss-mark/\"                     \n\n\nFrom this we can get the full list of 90 emoji names for the 1997 SoftBank set.\n\n\nClick to expand full list of emoji names\n\n\nbasename(sb97_urls)\n\n [1] \"grinning-face-with-big-eyes\"    \"smiling-face-with-smiling-eyes\"\n [3] \"disappointed-face\"              \"angry-face\"                    \n [5] \"pile-of-poo\"                    \"kiss-mark\"                     \n [7] \"broken-heart\"                   \"red-heart\"                     \n [9] \"raised-hand\"                    \"victory-hand\"                  \n[11] \"index-pointing-up\"              \"thumbs-up\"                     \n[13] \"raised-fist\"                    \"oncoming-fist\"                 \n[15] \"boy\"                            \"girl\"                          \n[17] \"man\"                            \"woman\"                         \n[19] \"baby-angel\"                     \"person-surfing\"                \n[21] \"dog-face\"                       \"cat-face\"                      \n[23] \"tiger-face\"                     \"horse-face\"                    \n[25] \"mouse-face\"                     \"bear\"                          \n[27] \"penguin\"                        \"spouting-whale\"                \n[29] \"fish\"                           \"cherry-blossom\"                \n[31] \"rose\"                           \"shortcake\"                     \n[33] \"hot-beverage\"                   \"cocktail-glass\"                \n[35] \"beer-mug\"                       \"fork-and-knife\"                \n[37] \"mount-fuji\"                     \"house\"                         \n[39] \"office-building\"                \"church\"                        \n[41] \"sunrise-over-mountains\"         \"railway-car\"                   \n[43] \"bullet-train\"                   \"station\"                       \n[45] \"automobile\"                     \"fuel-pump\"                     \n[47] \"sailboat\"                       \"airplane\"                      \n[49] \"twelve-oclock\"                  \"one-oclock\"                    \n[51] \"two-oclocktime\"                 \"three-oclock\"                  \n[53] \"four-oclock\"                    \"five-oclock\"                   \n[55] \"six-oclock\"                     \"seven-oclock\"                  \n[57] \"eight-oclock\"                   \"nine-oclock\"                   \n[59] \"ten-oclock\"                     \"eleven-oclock\"                 \n[61] \"crescent-moon\"                  \"sun\"                           \n[63] \"cloud\"                          \"umbrella-with-rain-drops\"      \n[65] \"snowman-without-snow\"           \"christmas-tree\"                \n[67] \"soccer-ball\"                    \"baseball\"                      \n[69] \"tennis\"                         \"flag-in-hole\"                  \n[71] \"skis\"                           \"t-shirt\"                       \n[73] \"running-shoe\"                   \"ring\"                          \n[75] \"gem-stone\"                      \"musical-note\"                  \n[77] \"microphone\"                     \"saxophone\"                     \n[79] \"guitar\"                         \"trumpet\"                       \n[81] \"mobile-phone\"                   \"telephone\"                     \n[83] \"fax-machine\"                    \"laptop\"                        \n[85] \"movie-camera\"                   \"camera\"                        \n[87] \"key\"                            \"question-mark\"                 \n[89] \"exclamation-mark\"               \"trident-emblem\"                \n\n\n\nNow, thanks to the {purrr} package, we can iterate over these pages and extract each emoji image URL.1 You have to update your bow() with a nod() for each new page you want to scrape.\n\nscrape_sb_gif &lt;- function(sb_ext, bow = ep_bow) {\n  session &lt;- nod(ep_bow, sb_ext)\n  images &lt;- scrape(session) |&gt; html_nodes(\"img\") |&gt; html_attr(\"src\")\n  images[grepl(\".gif$\", images)]\n}\n\nsb97_img &lt;- map_chr(sb97_urls, scrape_sb_gif)\n\nhead(sb97_img)\n\n[1] \"https://em-content.zobj.net/thumbs/160/softbank/182/smiling-face-with-open-mouth_1f603.gif\"  \n[2] \"https://em-content.zobj.net/thumbs/160/softbank/182/smiling-face-with-smiling-eyes_1f60a.gif\"\n[3] \"https://em-content.zobj.net/thumbs/160/softbank/182/disappointed-face_1f61e.gif\"             \n[4] \"https://em-content.zobj.net/thumbs/160/softbank/182/angry-face_1f620.gif\"                    \n[5] \"https://em-content.zobj.net/thumbs/160/softbank/182/pile-of-poo_1f4a9.gif\"                   \n[6] \"https://em-content.zobj.net/thumbs/160/softbank/182/kiss-mark_1f48b.gif\"                     \n\n\nSo, looks like these are stored on AWS servers."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#download-and-convert",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#download-and-convert",
    "title": "OG emoji SVGs",
    "section": "Download and convert",
    "text": "Download and convert\nNow we can download the emoji images. Here I’m going to download them to a temporary folder. I’ve also chosen to insert manually a random one- to five-second delay between downloads here to limit the impact on the server.\nNote that the download.file() function prints an output for each downloaded file, but I’ve hidden this because there’s 90 outputs.\n\n# Create temporary folder to write into\ntmp &lt;- tempdir()\n\n# Download each file and give it the emoji name\nwalk2(\n  sb97_img,\n  basename(sb97_urls),\n  ~{ cat(\"Downloading\", .y, \"\\n\")\n    download.file(.x, file.path(tmp, paste0(.y, \".gif\")))\n    Sys.sleep(sample(1:5, 1)) }\n)\n\nWe actually want PNG format for the next step, not gifs. One way to do this is to read in the gifs as {magick} objects and then write them back out to png.\n\ngif_paths &lt;- list.files(tmp, pattern = \".gif\", full.names = TRUE)\npng_paths &lt;- gsub(\"gif\", \"png\", gif_paths)\n\nwalk2(\n  gif_paths,\n  png_paths,\n  ~image_read(.x) |&gt; image_write(.y, format = \"png\")\n)"
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#generate-outputs",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#generate-outputs",
    "title": "OG emoji SVGs",
    "section": "Generate outputs",
    "text": "Generate outputs\n\nPixel plots\nFirst, we need a function to read the PNGs and create a 32 by 32 matrix representing the pixels of the image.\n\npixelate_emoji &lt;- function(path_in) {\n  x &lt;- readPNG(path_in)\n  y &lt;- matrix(as.vector(x), 32)\n  t(y[nrow(y):1, 33:64])\n}\n\nWe can take the matrix output from pixelate_emoji() and create a plot of that emoji’s pixels using the image() function from base R.\n\nplot_emoji &lt;- function(emo_mat, col_px = \"black\", col_bg = \"white\") {\n  image(\n    emo_mat,\n    col = c(col_bg, col_px),\n    useRaster = TRUE,\n    axes = FALSE, xaxs = NULL, yaxs = NULL\n  )\n}\n\nWe can create a grid of them all.\n\npar(mfrow = c(10, 9), mar = rep(1, 4))\nwalk(png_paths, ~pixelate_emoji(.x) |&gt; plot_emoji())\n\n\n\n\nSome are a bit peculiar. The faces look like onions or dumplings, for example. But the vast majority are recognisable as emoji that persist today. Note the poo with a smiley face; this emoji is not recent!\nHere’s three emoji, but closer.\n\npar(mfrow = c(1, 3), mar = rep(1, 4))\nwalk(\n  png_paths[c(82, 19, 55)],\n  ~pixelate_emoji(.x) |&gt; plot_emoji()\n)\n\n\n\n\nOr, in modern parlance: 👍😞💩\n\n\nWrite SVGs\nWe can save each plot into SVG (Scalable Vector Graphics) format using the {svglite} package, which can be put in a function that accepts a matrix that’s output from pixelate_emoji().\n\nsave_emoji &lt;- function(emo_mat, file_out, dimn = 10) {\n  svglite(file_out, width = dimn, height = dimn)\n  par(mar = rep(0, 4), mfrow = c(1, 1))\n  plot_emoji(emo_mat)\n  dev.off()\n}\n\nNow to convert all the PNGs to SVGs.\n\nsvg_paths &lt;- gsub(\"png\", \"svg\", png_paths)\n\nwalk2(\n  png_paths, \n  svg_paths,\n  ~save_emoji(pixelate_emoji(.x), file_out = .y)\n) \n\nWe can demonstrate the benefit of SVGs by plotting a scraped PNG emoji (the excellent ‘spouting whale’) at small, medium and large sizes (25, 100 and 500 pixels square) and then do the same for the SVGs.\nFirst the PNG, which look more fuzzy as the image gets larger:\n  \nNow the SVGs, which look sharp at all sizes:\n  \nThis happens because an SVG is basically a text file of instructions on how to build the image that an interpreter can re-build from scratch at any size. Hence the word ‘scalable’ in ‘SVG’."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#licensing",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#licensing",
    "title": "OG emoji SVGs",
    "section": "Licensing?",
    "text": "Licensing?\nThis was a project to remind me about ‘polite’ scraping and the powers of SVG graphics. But maybe the outputs could be useful for archival purposes or something?\nI can’t be completely certain of licensing for this particular emoji set (even Emojipedia isn’t always sure), but I certainly can’t and don’t condone their use for any commercial activities; they belong to SoftBank. I’ve used a few images in this post for demonstration purposes only.\nI’ve made the code available in a GitHub repo that you can use for personal investigation, but I haven’t included any of the outputs there. Let me know if you find a use for this, lol."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#environment",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#environment",
    "title": "OG emoji SVGs",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 11:20:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.7.4  png_0.1-8     svglite_2.1.1 purrr_1.0.1   rvest_1.0.3  \n[6] polite_0.1.3 \n\nloaded via a namespace (and not attached):\n [1] jsonlite_1.8.7    compiler_4.3.1    selectr_0.4-2     Rcpp_1.0.11      \n [5] xml2_1.3.4        stringr_1.5.0     assertthat_0.2.1  spiderbar_0.2.5  \n [9] systemfonts_1.0.4 yaml_2.3.7        fastmap_1.1.1     mime_0.12        \n[13] R6_2.5.1          curl_5.0.1        knitr_1.43.1      htmlwidgets_1.6.2\n[17] rlang_1.1.1       cachem_1.0.8      stringi_1.7.12    xfun_0.39        \n[21] fs_1.6.2          memoise_2.0.1     cli_3.6.1         magrittr_2.0.3   \n[25] digest_0.6.31     rstudioapi_0.14   lifecycle_1.0.3   ratelimitr_0.4.1 \n[29] vctrs_0.6.3       robotstxt_0.7.13  evaluate_0.21     glue_1.6.2       \n[33] rmarkdown_2.23    httr_1.4.6        tools_4.3.1       usethis_2.2.1    \n[37] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#footnotes",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#footnotes",
    "title": "OG emoji SVGs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that I’m using the new (at time of writing) base R pipe, |&gt;, rather than the {magrittr} pipe, %&gt;%, so you’ll need R v4.1 or higher to run this code.↩︎"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "href": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "title": "R is a game engine, fight me",
    "section": "tl;dr",
    "text": "tl;dr\nR is ‘a free software environment for statistical computing and graphics’. Ahahaha, no it’s not, it’s a game engine. I’ve created a ‘splendid’ list of games you can play—written in R—to prove it. Help expand it."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "title": "R is a game engine, fight me",
    "section": "Stats only!",
    "text": "Stats only!\nR is not a general, multi-purpose programming language. It was written to do statistical analysis and make charts. You are literally not allowed to do anything else with it. You should use &lt;LANGUAGE&gt; instead, which is much more suited to your specific use case. R is a joke language for nerds.\nYou should not read beyond this point if you think, quite rightly, that mirth and frivolity are unsuited to an R session."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "title": "R is a game engine, fight me",
    "section": "Stats only?",
    "text": "Stats only?\nUnity. Unreal. GameMaker. Godot. All of these videogame engines are now obsolete.\nIt is R—humble R!—that represents the future of gaming.\nTo prove it, I’ve created a list of ‘splendid R games’ in a GitHub repo1 that you are welcome to contribute to.2\nYes, R can be used for fun. Do not tell R Core."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "href": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "title": "R is a game engine, fight me",
    "section": "Wait, he’s serious?",
    "text": "Wait, he’s serious?\nI think there’s three kinds of ‘platform’ for games written in R:\n\nFor the console\nIn Shiny\nPorted\n\nGames played in the console are pretty straightforward and probably most common. You can run some code, or a function from a package, to launch some code in the R console that you can interact with. A simple option for this might involve use of readline() to receive user input, for example, like Giora Simchoni’s excellent text-based puzzler, Castle of R.\n\n\n\nGiora’s Castle of R running in the terminal.\n\n\nShiny can give you a little more flexibility when it comes to graphics and user input, at the expense of needing to host the app and maybe some extra JavaScript skills. A great example of this is Pedro Silva’s winning entry (app, source) to the Posit Shiny contest in 2020.\n\n\n\nA still from Pedro’s Shiny Decisions app.\n\n\nThe third category is a little more boundary-pushing. Imagine if R was powerful enough to let you port existing games. Well, surprise, ya boi Mike Cheng (aka coolbutuseless) has pushed hard on expanding the capabilities of R to run fast enough and with realtime user input,3 porting the classic Another World (1991) to R, which was showcased at 2022’s Posit conference (source, video, blog).\n\n\n\nA still from Mike’s rstudio::conf(2022) presentation, featuring Another World.\n\n\nOf course, within these ‘platforms’ are genres like word games, arcade games, puzzle games, etc. Will you be the first to create an MMORPG (a massively-multiplayer online R-powered game)?"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "href": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "title": "R is a game engine, fight me",
    "section": "I am an indie game dev now",
    "text": "I am an indie game dev now\nI’ve always been interested in how videogames are coded,4 wishing that I could do the same myself. Of course I could simply learn ‘real’ programming languages.\nExcept that’s blasphemy. Of course I’d rather break my own mind and spirit in an attempt to make R achieve 0.1% of what might be possible in P*thon.\nCase in point, I’ve made a few R packages containing some little toys (in order of gooddest to baddest):\n\n{r.oguelike} (source, blogs) for a procedural-dungeon explorer with enemy pathfinding and inventory\n{tamRgo} (source, blog) for a cyber pet in your R console that persists between sessions\n{safar6} (source, blog) for a text-based re-make of the Safari Zone from the first generation of Pokémon games\n{ActionSquirrel} (source, blog) for a tile-based, turn-based minigame in the R console\n{hokey} (source, blog) for minigames that use direct keypress inputs with {keypress}\n\n\n\n\nHint when playing {tamRgo}: do not forget about your pet for 138 days. RIP Kevin XVIII.\n\n\nI’ve got something in the pipeline that involves extremely rudimentary physics in the R console. Wow! For release in 2023 (because game launches never go wrong)."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "href": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "title": "R is a game engine, fight me",
    "section": "Ready Player 2",
    "text": "Ready Player 2\nThe splendid list must be missing a bunch of games. Please leave an issue or pull request in the splendid-r-games repo to add more examples.\nNext stop: letting people run R games in the browser without an installed copy of R. This is already possible with a service like Binder, which can spin up an instance of RStudio with packages pre-installed I did this for {r.oguelike}).\n\n\n\nJust like the Nokia N-Gage, amirite?\n\n\nBut soon you might be able to use WebR to play games in the browser without even spinning up RStudio, ooh. So look out for an R version of itch.io in future, lol."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "href": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "title": "R is a game engine, fight me",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-10-11 12:51:08 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.25    knitr_1.44        jsonlite_1.8.7    xfun_0.40        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.22"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#footnotes",
    "href": "posts/2023-04-02-splendid-r-games/index.html#footnotes",
    "title": "R is a game engine, fight me",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI originally labelled the GitHub repo as an ‘awesome’ repo, which I later learned has a very specific meaning. You might have seen awesome lists before, like the awesome-quarto repo by Mickaël, or the new awesome-webr list by Nan Xiao. ‘Splendid’ is much more of a Bri’ish word than ‘awesome’, so it feels more natural anyway.↩︎\nNote that I have carefully released this post just after April fool’s day, which means I am super, super serious. As usual.↩︎\nSee the {nara} and {eventloop} packages in particular.↩︎\nI like YouTube devlogs by folks like Seb Lague, ThinMatrix, SquidGod, Jonas, TanTan and others. R can never achieve what they’re up to, but I like listening through the logic of what they’re doing.↩︎"
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html",
    "href": "posts/2021-02-21-skyphone/index.html",
    "title": "#GithubSkyline but hear me out",
    "section": "",
    "text": "My skyline clearly has a Central Business District with development in the suburbs."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#tldr",
    "href": "posts/2021-02-21-skyphone/index.html#tldr",
    "title": "#GithubSkyline but hear me out",
    "section": "tl;dr",
    "text": "tl;dr\nI made the R package {skyphone} to get GitHub contributions data from GitHub Skyline and sonify it.\n\n Note\nThe GitHub Skyline API–on which the {skyphone} package depends–stopped responding (i.e. it 404s) soon after this post was published. I may fix {skyphone} in future to work via {gh} instead; feel free to contribute."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#reach-for-the-skyline",
    "href": "posts/2021-02-21-skyphone/index.html#reach-for-the-skyline",
    "title": "#GithubSkyline but hear me out",
    "section": "Reach for the skyline",
    "text": "Reach for the skyline\nSkyline is an online curio from GitHub that lets you input a user’s name and get a 3D rendering of that user’s contributions to the platform. You can even download the object to 3D print it, I guess?\nIt’s basically the contributions heatmap from your profile, but with a bonus third dimension. And it’s on a plinth! That spins! And it’s happening inside Tron!\n\n\n\nContributions in only two dimensions? Sad!\n\n\nWhy does it exist? Think Spotify Wrapped—a summary of users’ listening habits at the end of each year1—which results in lots of social-media shares and free marketing.2"
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#sounds-of-the-city",
    "href": "posts/2021-02-21-skyphone/index.html#sounds-of-the-city",
    "title": "#GithubSkyline but hear me out",
    "section": "Sounds of the city",
    "text": "Sounds of the city\nI wrote recently about expressing a year’s worth of COVID-19 data in audio form. This process, called sonification, is made simple in R thanks to the {sonify} package.\nObviously it’s far lower stakes, but there’s no reason we can’t take a user’s GitHub contributions data and sonify that too.3 Is that useful? Maybe. Is it it much effort? Not really.\nIt turns out that Skyline has a simple API. Provide a URL in this form to get a JSON back:\nhttps://skyline.github.com/api/contributions?username=username&year=2020\nThis lends itself nicely to a simple R function that grabs the data for a given user in a given year. The counts over time can then be passed to sonification and plotting functions.\nSo… {skyphone}."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#pick-up-the-skyphone",
    "href": "posts/2021-02-21-skyphone/index.html#pick-up-the-skyphone",
    "title": "#GithubSkyline but hear me out",
    "section": "Pick up the {skyphone}",
    "text": "Pick up the {skyphone}\nYou can install the package from GitHub. It’s never going on CRAN.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/skyphone\")\n\nThere’s three functions: one to get the data, one to sonify it, and one to plot it. All functions are prefaced by sky_ for easy tab completion.\n\nGet a dial tone\nThe sky_get() function takes a username and a year, which are used to generate an API string. The function fetches and tidies the resulting JSON from the call, generating a tidy tibble with a row of contributions per day.\n\nlibrary(skyphone)\nmd &lt;- sky_get(user = \"matt-dray\", year = 2020)\nmd\n\n## # A tibble: 366 x 6\n##    user       year  week   day date       count\n##    &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;int&gt;\n##  1 matt-dray  2020     1     1 2020-01-01     5\n##  2 matt-dray  2020     1     2 2020-01-02     5\n##  3 matt-dray  2020     1     3 2020-01-03     8\n##  4 matt-dray  2020     1     4 2020-01-04     3\n##  5 matt-dray  2020     2     5 2020-01-05     0\n##  6 matt-dray  2020     2     6 2020-01-06     7\n##  7 matt-dray  2020     2     7 2020-01-07    10\n##  8 matt-dray  2020     2     8 2020-01-08     2\n##  9 matt-dray  2020     2     9 2020-01-09     6\n## 10 matt-dray  2020     2    10 2020-01-10     0\n## # … with 356 more rows\nBy itself, this is a useful little function for the casual R user who doesn’t want to handle the JSON.\n\n\nHello?\nThe output from sky_get() can be passed to sky_sonify(), which converts the count of contributions over time to audio form: a WaveMC object.\n\nsky_sonify(md, play = FALSE)\n\n## \n## WaveMC Object\n##  Number of Samples:      220500\n##  Duration (seconds):     5\n##  Samplingrate (Hertz):   44100\n##  Number of channels:     2\n##  PCM (integer format):   TRUE\n##  Bit (8/16/24/32/64):    16\nIf you set the play argument to TRUE then you will hear the sonified result over your speakers. You can also provide a directory path to the out_dir argument to save the audio file as a .wav to a specified location.\nThe data I collected sound like this:\n\n\n\n\n\nFor amusement’s sake, 2016 is the year I joined GitHub and, well, that’s all that happened. We can fetch that year with sky_get() and then pipe that into sky_sonify(). I’ve saved the output file to my dekstop in this example.\n\nlibrary(magrittr)  # to demo pipes in {skyphone}\n\nsky_get(\"matt-dray\", 2016) %&gt;% \n  sky_sonify(play = FALSE, out_dir = \"~/Desktop\")\n\n\n\n\n\n\nDid you hear the momentous day on April 2?\n\n\nVideophone\nWe’ve seen what a 3D skyline plot looks like; what about a good old fashioned 2D chart?\nThere’s a simple, opinionated plotting function in the package that you are welcome to use, called sky_plot(). Again, you can pass the earlier object from sky_get().\n\np &lt;- sky_plot(md)\np\n\n\nSee how this looks like a skyline, but in 2D this time? Admittedly the ‘buildings’ are a little weird. Radio towers? Use your imagination, buddy.\nFor a final flourish, we can apply a ridiculous vaporwave-inspired theme to the plot. This retro aesthetic has been rinsed to death of late, so naturally it was used in the Skyline interface.4\nThe {vapoRwave} package has a number of themes we can choose.\n\n# remotes::install_github(\"moldach/vapoRwave\")\nlibrary(vapoRwave)\np + new_retro()\n\n\nSo… that’s it. But do join me in waiting for the first hospital admission of someone who trod on their 3D-printed skyline. It’s the risk you take."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#environment",
    "href": "posts/2021-02-21-skyphone/index.html#environment",
    "title": "#GithubSkyline but hear me out",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-11 23:18:22 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#footnotes",
    "href": "posts/2021-02-21-skyphone/index.html#footnotes",
    "title": "#GithubSkyline but hear me out",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI prefer The Pudding’s highly judgmental bot.↩︎\nAnd here I am, blogging about it.↩︎\nI promise I have other ideas.↩︎\nHow do you do, fellow kids?↩︎"
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#tldr",
    "href": "posts/2023-08-01-monetize/index.html#tldr",
    "title": "One weird trick to {monetize} your R package",
    "section": "tl;dr",
    "text": "tl;dr\nThe {monetize} R package gives you inspiration for monetising your R package. Developers rise up!"
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#free-as-in-free",
    "href": "posts/2023-08-01-monetize/index.html#free-as-in-free",
    "title": "One weird trick to {monetize} your R package",
    "section": "Free as in free",
    "text": "Free as in free\nThere’s one good reason why SAS, SPSS and Stata1 are such successful and beloved statistical tools: money.\nFor some reason, R remains free and open source. But what if Ihaka & Gentleman originally wanted users to be charged a literal (New Zealand) dollar2 every time they use the $ symbol to access an element from an object? I’m just asking the question!\nUs package developers should seize the initiative and harvest the sweet, sweet bounty of our labour. But how? I will tell you the secret!"
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#free-as-in-not-quite",
    "href": "posts/2023-08-01-monetize/index.html#free-as-in-not-quite",
    "title": "One weird trick to {monetize} your R package",
    "section": "Free as in not quite",
    "text": "Free as in not quite\nIntroducing the {monetize} R package! It will provide the inspiration you seek. Serious entrepreneurs can install from GitHub3.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/monetize\")\nlibrary(monetize)\n\nWelcome to the monetize(TM) package FREE TRIAL version!\nTry our EXCLUSIVE add_one() function!\nTry watch_ad() to gain MEGA COINS and increase your MEMBER LEVEL for REWARDS!\nAnd now a quick message from our sponsor:\n  🧃 IMBIBE ACME(TM)-BRAND FRUIT PULP (7% FEWER INSECT COMPONENTS)! 🪳\nThe package contains the exclusive add_one() function, which surprisingly doesn’t come pre-installed with base R. A gap in the market!\nUsers should speculate to accumulate, so there’s a small cost to use the function. In {monetize}, each use of a function costs 1 MEGA COIN.\nBecause I am so kind, I have chosen for users to receive a 30-day FREE TRIAL of the package and to receive 3 MEGA COINS as an exclusive NEW-MEMBER PERK.\nOne use of the function costs the low, low price of 1 MEGA COIN. Merely a small payment, or ‘micro transaction’, if you will.\n\nadd_one(1)\n\n📅 You have 30 days left of your FREE TRIAL!\n🏅 Your MEMBER LEVEL is 1! Try watch_ad()!\n💰 Your MEGA COIN balance is now 2! Try watch_ad()!\n[1] 2\nAlong with the result, the function helpfully prints the number of days left in your FREE TRIAL, your MEMBER LEVEL and the number of MEGA COINS you have left.\nWhat’s a MEMBER LEVEL? Well, at MEMBER LEVEL 1, the function can’t guarantee a correct result. 20% of the time there’ll be an off-by-one error. But R users index from 1 anyway, so they’ll be used to that.\n\nadd_one(1)\n\n📅 You have 30 days left of your FREE TRIAL!\n🏅 Your MEMBER LEVEL is 1! Try watch_ad()!\n💰 Your MEGA COIN balance is now 1! Try watch_ad()!\n[1] 3\nHow can you get the correct result 100% of the time? That’s an exclusive for MEMBER LEVEL 2. How do you reach MEMBER LEVEL 2? What happens if you run out of MEGA COINS?\n\nadd_one(1)\n\n📅 You have 30 days left of your FREE TRIAL!\n🏅 Your MEMBER LEVEL is 1! Try watch_ad()!\nError: 😭 You'll need more MEGA COINS to re-use this function! Try watch_ad()!\nAnswer: simply watch some ads! I’ve managed to get an ad deal with the famous Acme(TM) Corporation. Maybe you could get a sponsorship deal from a third-party whose interests align with your users’ interests; maybe SAS, SPSS or Stata would be interested?\nAnyway, the user can just watch_ad() in exchange for MEGA COINS: I’ve allowed the user to employ their FREE WILL to watch a \"short\" ad for 1 MEGA COIN or a \"long\" ad for 3 MEGA COINS.\n\nwatch_ad(\"short\")\n\n🌭 CONSUME ACME(TM)-BRAND RECONSTITUTED MEAT-LIKE CYLINDERS! 🐕\n🌭 CONSUME ACME(TM)-BRAND RECONSTITUTED MEAT-LIKE CYLINDERS! 🐕\n🌭 CONSUME ACME(TM)-BRAND RECONSTITUTED MEAT-LIKE CYLINDERS! 🐕\n🌭 CONSUME ACME(TM)-BRAND RECONSTITUTED MEAT-LIKE CYLINDERS! 🐕\n🌭 CONSUME ACME(TM)-BRAND RECONSTITUTED MEAT-LIKE CYLINDERS! 🐕\nCongratulations! Your new MEGA COIN total is 1!\nReach MEMBER LEVEL 2 after gaining 10 all-time MEGA COINS and MEMBER LEVEL 3 after 20 MEGA COINS.\nWhat’s the exclusive MEMBER LEVEL 3? Well, you get the perk of an actually-correct answer like in MEMBER LEVEL 2… plus the value gets a randomised FREE HAT!\n\nadd_one(1)\n\n📅 You have 30 days left of your FREE TRIAL!\n🏅 Your MEMBER LEVEL is 3! Try watch_ad()!\n💰 Your MEGA COIN balance is now 19! Try watch_ad()!\n🎩 \n 2 \nWhat a tease! Oh, and the stats are persistent, so your users can’t refresh their session and wipe the slate clean. Watch the cash roll in!"
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#free-as-in-absolutely-not",
    "href": "posts/2023-08-01-monetize/index.html#free-as-in-absolutely-not",
    "title": "One weird trick to {monetize} your R package",
    "section": "Free as in absolutely not",
    "text": "Free as in absolutely not\nI hope this has been an inspirational eye-opener for you and that one day you can be as rich as me. Oh, you didn’t know I was rich? How else could I afford to keep this absolute juggernaut of a blog going?\nTo demonstrate how little I personally need them, here are some more ideas to maximise your financial rewards via R. You could try:\n\nreleasing version updates as paid add-ons, like videogame DLC (you could also make them take several hours to download, like videogame DLC, which would definitely heighten the tension)\nloot boxes to allow users to gamble—I mean, test their precognitive skills—for new functionality (add_two() could be a common drop, while multiply_by_two() is ultra rare)\nusing certified financial guru Duncan Garmonsway’s {ggbillboard} package (‘use vacant ggplot2 facets for advertising’)\n\nYou are welcome. Don’t read the small print for nerds.\n\n\nSmall print for nerds.\n\nIt’s a simple trick: up-to-date stats are stored on the user’s computer in the directory resolved by tools::R_user_dir(\"monetize\", \"data\")4 and are updated each time you use the functions in the package. Easy to circumvent… if you know how."
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#environment",
    "href": "posts/2023-08-01-monetize/index.html#environment",
    "title": "One weird trick to {monetize} your R package",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-01 11:37:35 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] monetize_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-08-01-monetize/index.html#footnotes",
    "href": "posts/2023-08-01-monetize/index.html#footnotes",
    "title": "One weird trick to {monetize} your R package",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCurious why they all start with ‘S’? It’s in deference to ‘R’, which comes first in the alphabet and in being really cool.↩︎\nDid you also know that the use of the New Zealand dollar is part of a wider conspiracy? The sheep dip goes deep on this one.↩︎\nDon’t.↩︎\nI consider this my hattrick of posts on R_user_dir(). I wrote about it as a way to cache data from the PokéAPI in {trapinch} and store cyber pet blueprints in {tamRgo}, the latter of which led to a post on saving high-score data with {hiscore}.↩︎"
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#tldr",
    "href": "posts/2021-08-31-add-biscuits/index.html#tldr",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a novelty R function that inserts comments after closing parentheses with the names of the functions they belong to. (These are called biscuits, apparently.) It’s available as an RStudio Addin from the {blogsnip} package."
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#matryoshka-functions",
    "href": "posts/2021-08-31-add-biscuits/index.html#matryoshka-functions",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Matryoshka functions",
    "text": "Matryoshka functions\nShiny apps can involve a lot of nested functions in the UI, which can make them difficult to handle.\nSometimes I comment after a closing parenthesis (‘paren’) with the name of the function that it’s closing, which makes it easier to match the pairs.\nDuncan told me these labels are called ‘biscuits’, which is charming.\n\nui &lt;- fluidPage(\n  \"hogwash\",\n  sidebarLayout(\n    \"tripe\",\n    mainPanel(\n      \"piffle\",\n      tabsetPanel(\n        \"bilge\",\n        tabPanel(\n          \"twaddle\"\n        )  # tabPanel\n      )  # tabsetPanel\n    )  # mainPanel\n  )  # sidebarLayout\n)  # fluidPage\n\nIdeally you don’t want to write ‘hadouken code’1 like this, though. A well-designed Shiny app would be modular and abstract away the functions, making everything a delight to read and understand.2"
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#paren-in-a-codestack",
    "href": "posts/2021-08-31-add-biscuits/index.html#paren-in-a-codestack",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Paren in a codestack",
    "text": "Paren in a codestack\nThere are a few ways that the RStudio IDE can help with the problem of bracket-buddying in long-winded scripts. In particular:\n\nPut your cursor next to a parenthesis and its partner will be automatically highlighted\nYou can auto-indent with Command + I and expose indent guides with Options &gt; Code &gt; Show indent guides so that paren-pairs are aligned vertically\nColour-match paren-pairs with rainbow colours, which you can activate with Options &gt; Code &gt; Display\nUse the keyboard shortcut Control + P to jump from an opening to a closing parenthesis\n\nYou can see these in action in this gif:\n\nThese go some way to helping, but each is not perfect for me, personally. For example, as someone with colourblindness, I find the rainbow colouring isn’t distinct enough."
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#a-biscuit-recipe",
    "href": "posts/2021-08-31-add-biscuits/index.html#a-biscuit-recipe",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "A biscuit recipe",
    "text": "A biscuit recipe\nSo what if we want to use those closing-paren labels, or ‘biscuits’, instead? There doesn’t seem to be an option in RStudio for that.\nNaturally, I wondered about filling that gap in the market.\nAs a result, consider this post a thought-experiment manifested with some clunky code that is poorly tested and probably doesn’t do exactly what you want it to do. You have been warned.\n\nEasy as A, B, D\nUsing R code, how can you work out the matching parentheses in an expression? Spoiler: it’s not that simple.\nMaybe you could treat an expression as a string, then label the opening and closing parens in forward and reverse order, respectively.\nIn this example, the labels match up the parens for each imaginary function (uppercase for open-parens and lowercase for closing-parens):\n\n\"first(second(third()))\"\n#     A      B     Ccba\n\nBut this simple reversing heuristic doesn’t work for these expressions:\n\n\"first(second(third(), fourth()))\"\n#     A      B     Cd        Dcba\n\n\"first(second(third(')')))\"\n#     A      B     C d cba\n\nIn the first example we’d get the parens for third() and fourth() mixed up. In the second we have a sneaky unopened closing paren inside a string.\nNot forgetting that this doesn’t solve how to extract each function name to use as the biscuit.\n\n\n‘Overengineer’ is my middle name\nRather than the naive approach of chopping up and counting strings, I decided to parse the actual R expressions from them.\nI created a function to do this, add_biscuits(), that contains sub-functions for three steps:\n\n.parse() to interpret the R code from an input\n.label() to match parenthesis pairs by their parent function, grab the parent function name and insert it as a comment after the closing paren\n.format() to stick it all back together and style it\n\nThe rest of the post walks through these functions. I’m certain there’s easier ways to do things, but the code here demonstrates the point I’m trying to reach.\nFor demonstration, we can use one of the trickier examples from above as our input.\n\nstring &lt;- \"first(second(third('x'), fourth('y')))\"\n\n\n1. Parse\nThe .parse() function takes a string containing R code and returns a dataframe of its ‘syntax tree’. In other words, it breaks the string into ‘tokens’ that are recognised as units of R code: function calls, assignment arrows, etc.\nI’ve used getParseData(parse()) to do the hard work of parsing the string into a dataframe with one row per token. The downside is that you must provide to it a file rather than a character object, so we first have to write it to a temporary file.\nI’ve then filtered the dataframe to get only the tokens that are R code (i.e. they aren’t spaces) and renumbered the rows so they’re consecutive. This will be useful when we want to extract the function names for each set of parens.\n\n\nExpand the .parse() function definition\n\n\n.parse &lt;- function(string) {\n  \n  file &lt;- tempfile(fileext = \".R\")\n  writeLines(string, file)\n  \n  tokens &lt;- getParseData(parse(file))\n  parsed &lt;- parsed[parsed$terminal == TRUE, ]\n  rownames(parsed) &lt;- as.character(seq(nrow(parsed)))\n  \n  return(parsed)\n  \n}\n\n\nHere’s what the output looks like:\n\ntree &lt;- .parse(string)\ntree[, c(\"line1\", \"col1\", \"parent\", \"token\", \"text\")]\n\n   line1 col1 parent                token   text\n1      1    1      3 SYMBOL_FUNCTION_CALL  first\n2      1    6     40                  '('      (\n3      1    7      6 SYMBOL_FUNCTION_CALL second\n4      1   13     35                  '('      (\n5      1   14      9 SYMBOL_FUNCTION_CALL  third\n6      1   19     16                  '('      (\n7      1   20     12            STR_CONST    'x'\n8      1   23     16                  ')'      )\n9      1   24     35                  ','      ,\n10     1   26     23 SYMBOL_FUNCTION_CALL fourth\n11     1   32     30                  '('      (\n12     1   33     26            STR_CONST    'y'\n13     1   36     30                  ')'      )\n14     1   37     35                  ')'      )\n15     1   38     40                  ')'      )\n\n\nSo each row is a recognised R token, e.g. the function name from the first() function is a SYMBOL_FUNCTION_CALL and 'x' is a STR_CONSTANT. Parentheses are recognised as separate special tokens too: '(' and ')'.\nWe also get returned the position of each token in the input (line* and col*) and a variable called parent which tells us something about the association of tokens. In our case, opening- and closing-parens have the same parent value.\n\n\n2. Label\nSo we can tie our paren pairs together with the parent variable and we know where to place the biscuit with the line1 and col1 information. But how to extract the function name and ‘biscuitise’ it?\nI’ve written the slightly awkward .label() function for this. It takes the output from .parse() and checks each row to see if it’s a closing-paren token; if so, it finds the position of the matching open-paren by parent; then it looks at the text of the token in the preceding row to get the function name and sticks that in a new column called label.\n\n\nExpand the .label() function definition\n\n\n.label &lt;- function(tree) {\n  \n  tree$label &lt;- NA_character_\n  \n  for (tkn in seq_len(nrow(tree))) {\n    \n    tree$label[tkn] &lt;- ifelse(\n      tree$token[[tkn]] == \"')'\",\n      tree[as.numeric(rownames(\n        tree[tree$parent == tree$parent[[tkn]] & tree$token == \"'('\", ]\n      )) - 1, \"text\"],\n      NA_character_\n    )\n    \n  }\n  \n  return(tree)\n  \n}\n\n\nSo now we have the required biscuit for each closing paren:\n\ntree_lbl &lt;- .label(tree)\ntree_lbl[!is.na(tree_lbl$label), c(\"text\", \"label\")]\n\n   text  label\n8     )  third\n13    ) fourth\n14    ) second\n15    )  first\n\n\n\n\n3. Format\nThe last step needs involves sticking everything back together again. My quick solution is hacky and needs a refactor for sure.\nThe .format() function does a couple of awkward things: recognises and pastes commas to their preceding token (otherwise we’ll get lines in the output that start with a comma, which is valid, but not my style) and pastes in the biscuits with a suffixed # to mark it as a comment. Of course, this blocks downstream code, so we can add a linebreak with \\n.\nThe output is still going to be a bit uggo though, so I employed {styler} to reformat it in tidyverse style. This is very definitely opinionated.\n\n\nExpand the .format() function definition\n\n\n.format &lt;- function(tree_lbl) {\n  \n  tree_lbl$comma &lt;- c(\n    ifelse(tree_lbl$text != \",\", NA_character_, \",\")[-1], NA_character_\n  )  # lag commas\n  \n  tree_lbl &lt;- tree_lbl[tree_lbl$token != \"','\", ]  # remove comma tokens\n  \n  tree_lbl$string &lt;- NA_character_\n  \n  for (tkn in seq_len(nrow(tree_lbl))) {\n    \n    if (!is.na(tree_lbl$comma[tkn])) {  # when there's a comma\n      \n      if (!is.na(tree_lbl$label[tkn])) {  # paste with biscuit\n        \n        tree_lbl$string[tkn] &lt;- paste0(\n          \"\\n\", tree_lbl$text[tkn], tree_lbl$comma[tkn],\n          \"#\", tree_lbl$label[tkn], \"\\n\"\n        ) \n        \n      } else if (is.na(tree_lbl$label[tkn])) {  # paste without biscuit\n        \n        tree_lbl$string[tkn] &lt;- paste0(\n          \"\\n\", tree_lbl$text[tkn], tree_lbl$comma[tkn], \"\\n\"\n        ) \n        \n      }\n      \n    } else if (is.na(tree_lbl$comma[tkn]) & !is.na(tree_lbl$label[tkn])) {\n      \n      tree_lbl$string[tkn] &lt;- paste0(\n        \"\\n\", tree_lbl$text[tkn], \"#\", tree_lbl$label[tkn], \"\\n\"\n      ) \n      \n    } else {  # no comma, no biscuit\n      \n      tree_lbl$string[tkn] &lt;- tree_lbl$text[tkn]\n      \n    }\n    \n  }\n  \n  string_out &lt;- paste0(tree_lbl$string, collapse = \"\")\n  string_out &lt;- gsub(\"\\n\\n\", \"\\n\", string_out)\n  \n  styled &lt;- suppressWarnings(\n    utils::capture.output(styler::style_text(string_out))\n  )\n  \n  paste(styled, collapse = \"\\n\")\n  \n}\n\n\nLet’s hand over to .format() the labelled tree dataframe that was output from .label():\n\nout &lt;- .format(tree_lbl)\nout\n\n[1] \"first(\\n  second(\\n    third(\\\"x\\\"), # third\\n    fourth(\\\"y\\\") # fourth\\n  ) # second\\n) # first\"\n\n\nSo the output is a character vector, with one element per line of our output R file. You can see in the console how this looks.\n\ncat(out)\n\nfirst(\n  second(\n    third(\"x\"), # third\n    fourth(\"y\") # fourth\n  ) # second\n) # first\n\n\nReal noice: we’ve got a comment after each closing bracket that notes which function it’s closing. You can argue that some of these biscuits are redundant, but the goal has been achieved!\nA reminder of the original input:\n\nstring\n\n[1] \"first(second(third('x'), fourth('y')))\"\n\n\n\n\n4. Combined function\nAnd so, we can put these three steps together in one function: add_biscuits(), which is a cuter name than label_parens() or whatever.\n\nadd_biscuits &lt;- function(string) { \n  .parse(string) |&gt; .label() |&gt; .format()\n}\n\nThe output from each sub-function passes to the next, so it’s a nice chance to use the pipe operator (R &gt;= v4.1).\nLet’s try it on that awkward example with the sneaky extra bracket.\n\nstring2 &lt;- \"first(second(third(')')))\"\ncat(add_biscuits(string2))\n\nfirst(\n  second(\n    third(\")\") # third\n  ) # second\n) # first\n\n\nSo only the ‘real’ closing-paren tokens have been recognised and labelled."
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#bonus-rstudio-addin",
    "href": "posts/2021-08-31-add-biscuits/index.html#bonus-rstudio-addin",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Bonus: RStudio addin",
    "text": "Bonus: RStudio addin\nYou’re thinking ‘cool, but how can I use this thing practically?’ The answer is an RStudio addin.\nI’ve written before about {blogsnip}, my package of R Markdown-related RStudio addins to help me prepare blog posts. I’ve put the add_biscuits() function in there for now.\nInstall from GitHub with {remotes} as follows and then restart RStudio. {blogsnip} doesn’t force you to install {styler}, so you’ll have to do that too (if you haven’t already).\n\ninstall.packages(c(\"remotes\", \"styler\"))\nremotes::install_github(\"matt-dray/blogsnip\")\n\nThere should now be a ‘BLOGSNIP’ section in the ‘Addins’ menu (top navigation bar) with an option to ‘Add closing paren labels’. Select a full R expression in the script window, then select ‘Add closing paren labels’. Your code will be replaced with the same code, but with biscuits inserted.\n\nBeware: your code will be replaced if you use the addin. Of course, you can edit or undo the output as necessary.\nYou can set a keyboard shortcut for this too, if you want. Go to Tools &gt; Modify Keyboard Shortcuts…. I set mine to Ctrl + Cmd + P, since Ctrl + P is the shortcut that jumps from opening to closing parens."
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#oh-crumbs",
    "href": "posts/2021-08-31-add-biscuits/index.html#oh-crumbs",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Oh, crumbs…",
    "text": "Oh, crumbs…\nLet me be clear: add_biscuits() is half-baked (lol). It works on the simple examples here, but I’m pretty sure it will break horribly on more complex things. I haven’t really tested it properly.\nIt gets confused if there’s already some labelled closing parens. It gets confused if you don’t highlight enough code to capture all the opening and closing parens. It gets confused if you run it over more than one expression. It ignores curly and square parentheses. Etc, etc.\nSo, use the function at your own risk, or better yet: improve it by contributing to {blogsnip}.\nOr even better yet, just use a good implementation of this functionality that someone else has probably written and I’ve been too lazy to search for.\nOr, y’know, don’t write heavily-nested code that requires you to write comments after closing parens."
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#environment",
    "href": "posts/2021-08-31-add-biscuits/index.html#environment",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        crayon_1.5.2       cli_3.6.1          knitr_1.43.1      \n [5] rlang_1.1.1        xfun_0.39          rex_1.2.1          processx_3.8.2    \n [9] purrr_1.0.1        styler_1.10.1      xmlparsedata_1.0.5 jsonlite_1.8.7    \n[13] rprojroot_2.0.3    htmltools_0.5.5    ps_1.7.5           rmarkdown_2.23    \n[17] R.cache_0.16.0     evaluate_0.21      fastmap_1.1.1      lifecycle_1.0.3   \n[21] yaml_2.3.7         cyclocomp_1.1.0    compiler_4.3.1     lintr_3.0.2       \n[25] htmlwidgets_1.6.2  rstudioapi_0.15.0  R.oo_1.25.0        R.utils_2.12.2    \n[29] digest_0.6.33      R6_2.5.1           magrittr_2.0.3     callr_3.7.3       \n[33] R.methodsS3_1.8.2  tools_4.3.1        withr_2.5.0        lazyeval_0.2.2    \n[37] xml2_1.3.5         remotes_2.4.2      desc_1.4.2"
  },
  {
    "objectID": "posts/2021-08-31-add-biscuits/index.html#footnotes",
    "href": "posts/2021-08-31-add-biscuits/index.html#footnotes",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe code looks like the shockwave emanating from a ‘hadouken’ energy-ball from the Street Fighter video games.↩︎\nAnd if you’re nesting too much, maybe consider Roger Peng’s eight-space indentation to punish yourself.↩︎"
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html",
    "href": "posts/2023-09-08-trash-combing/index.html",
    "title": "Combing through my trash",
    "section": "",
    "text": "Procyon lotor. Released graciously by the author under CC0."
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html#tldr",
    "href": "posts/2023-09-08-trash-combing/index.html#tldr",
    "title": "Combing through my trash",
    "section": "tl;dr",
    "text": "tl;dr\nThree little R things I never finished. Or are useless. Or both?"
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html#flotsam-and-jetsam",
    "href": "posts/2023-09-08-trash-combing/index.html#flotsam-and-jetsam",
    "title": "Combing through my trash",
    "section": "Flotsam and jetsam",
    "text": "Flotsam and jetsam\nIt’ll not surprise you that after all these years of blogging and farting around with R that I have a huge floating garbage patch of odds and sods that I sketched out at some point, but never finished or never found a use for.\nJoin me, fellow trash pandas, as we carouse through the accumulated bilge to dig up some certified D-rank content. Today I have three things to share:\n\nA method for finding treasure.\nInfinite abandoned dungeons.\nAn underwhelming ‘physics’ ‘simulation’ for ‘secret’ purposes.\n\n\n1. {plunderplot}\nlocator() is a funny base R function that lets you click a point on a plot to retrieve its coordinates.\nI had a little locator() phase on this blog: I used it to make the {pixeltrix} package for point-and-click editing of ‘pixel art’ and wrote a post about extracting coordinates from fictitious maps.\nThe {plunderplot} package was an extension of the ‘data extraction’ idea, really. The plunder() function plots your image1 and asks you to click and label the axes for calibration. Then you’re invited you to click points on the plot and get in return a dataframe of the coordinates.\nSo you’re plundering coordindates from a plot, right? Hence the name. Consequently, the package README uses some piratespeak to explain how it works. I won’t subject you to that here.\nTo keep with the theme, the example image here is a simple treasure map with treasure markers2.\n\ntreasure &lt;- plunderplot::plunder(\"resources/treasure.png\", labels = TRUE)\n\n\nThe console will talk to you during the process. You’ll be instructed to do things, one after the other. You calibrate the plot, select the points and optionally label them.\nClick x axis min\nClick x axis max\nClick y axis min\nClick y axis max\nType value at x axis min: 0\nType value at x axis max: 100\nType value at y axis min: 0\nType value at y axis max: 50\nClick points on the chart, press ESC when finished\nType a label for point 1: west\nType a label for point 2: centre\nType a label for point 3: east\nDone\nAnd then you get your coordinates back:\n\ntreasure\n\nx        y labels\n1 35.97651 32.19178   west\n2 55.94714 23.15068 centre\n3 61.96769 26.16438   east\nExcept, well, this package has done before3. More than once. I was aware of the {juicr} package, which contains an interactive GUI for extracting data out of plots in scientific PDFs and that sort of thing, but there’s already CRAN packages with {plunderplot}’s functionality: {digitize} and {metaDigitise}, which have been around for years.\nSo it’s not more useful than other tools… but I had fun coding it and I’ve used it myself for ‘real’ applications more than once.4\n\n\n2. Perlin dungeon\nI made a toy roguelike ‘game’ in the {r.oguelike} package5. An important feature of games in this genre is a procedurally-generated tile-based dungeon map for your character to do an adventure in.\nI came up with a basic system to create convincing connected caverns, but there are many ways to create this kind of map. One method is to use Perlin noise, which the {ambient} package can help you generate.\nThis print_perlin_dungeon() function never made it into the package, but it’s a pretty straightforward way of creating ‘dungeons’ with good balance between randomness and structure.\n\nprint_perlin_dungeon &lt;- function(\n    m,  # matrix of perlin noise via ambient::noise_perlin()\n    invert = FALSE  # flips tile positions (use set.seed before generating noise)\n) {\n  \n  tile_wall = \"#\"\n  tile_floor = \".\"\n  \n  # Standardise noise values from 0 to 1\n  m_bin &lt;- round((m - min(m)) / (max(m) - min(m)))\n  \n  # Lay floor and wall tiles, flip if invert = TRUE\n  if (!invert) {\n    m_tiled &lt;- ifelse(m_bin == 1, tile_wall, tile_floor)\n  } else {\n    m_tiled &lt;- ifelse(m_bin == 0, tile_wall, tile_floor)\n  }\n  \n  # Block off edges with wall tiles\n  m_tiled[, 1] &lt;- tile_wall\n  m_tiled[, ncol(m_tiled)] &lt;- tile_wall\n  m_tiled[1, ] &lt;- tile_wall\n  m_tiled[nrow(m_tiled), ] &lt;- tile_wall\n  \n  # Print to console, line-by-line\n  for (i in seq(nrow(m_tiled))) {\n    cat(m_tiled[i, ], \"\\n\")\n  }\n  \n}\n\nThe noise_perlin() function in the {ambient} package has lots of twiddly knobs for arguments. I can’t profess any science behind my choices here:\n\nm &lt;- ambient::noise_perlin(\n  dim = c(30, 42),\n  frequency = 0.2,\n  interpolator = \"linear\",\n  fractal = \"fbm\",\n  octaves = 2,\n  lacunarity = 3,\n  gain = 0.5,\n  pertubation = \"none\",\n  pertubation_amplitude = 1\n)\n\nYou can pass the matrix output from noise_perlin() to the print_perlin_dungeon() to print the map to the console.\n\nprint_perlin_dungeon(m)\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n# # # # # # # # # # # # # # . . # # # # # . . . . . . . # # . . . . # # . . . . . # \n# # # # # # # # # # # # # # # # # # # # # # # . . . . . . . . . . # # # # # # . . # \n# # # # # # # # # # # # # # # # # # # # # # # . . . . . . . . # # # # # # # # . . # \n# . # # # . # . . # # # # # # # # # # # # . . # . . . . . . . # # # # # # # # . . # \n# . # # # # . # # . # # # # # # # # # # # . # # . # # . . . # # # # # # # # # # # # \n# . . # # # # . . . . . # . # . # # # # . . . . . # # # # # # # # # # # # # # # # # \n# # # # # # # # # # . . . . # # # # # # # # # # # # # . . # # # # # # # # # # # # # \n# . # . # # # # # . . . . . . # # # # # # # # # # # # . . . # # # # # # # # # # # # \n# . . . . # # # # # # . . . . . # # # # . . . . # # # # # . . # # # # . . # # # # # \n# . . . . # # # # # # . . . # # # # # # # # . . . # . . . # # # # # # # . # # # # # \n# . # # . . # # # # # . . . . # # # # # # # # . . # # # # # # # # # # . . # # # . # \n# . # # . . # # # # # # # # . # # # # # . . . . . # # . . # # # # # # . . . . . # # \n# # # # # . . # # # # # # # . # # # # # . . . . . # # . . # # # # # # . . . . . # # \n# # # # # . . . # # # # # . . # # # # . . . . . . . # . . # # # # # # # . . . . . # \n# # # # # # . # # . # # # # # # # # # # # . . . . # # . . . # # # # # # . . . . # # \n# # # # # # # # # . . . . . # . # # # # # # # # # # . . . . . . # # # # # # # . # # \n# # # # # # # # # . . . . . # # # # # # # # # # # . . . . . . . # # # # # # # # # # \n# # # # # # # # # . . . . # # # # # # # # # # # . . . . . . . # # # # # # # # # # # \n# # # # # # # # # . . . # . . # # # # # # # . . # # # # . . . # # # # # # # # # # # \n# . . . # # # # # # # . # # # # # # # . # # . . # # # . . # # # # # # # # # # # # # \n# . . . . . . # # # # # # # # # # . . . . . . . . . . . . # # # # # # . # # # # # # \n# . . . . . # # # # # # # . . . # # # # . . . . . . . . # # # # # # # . . # # # # # \n# . . . . . . # # # # # # # . . . # # # . . . . . . . . # # # # # # # . . # # # # # \n# . . . . # . # # # # . # # # # . # # # . . . . . . # # . # # # # # # . . # # . # # \n# # . . . # . # # . # . # # . # # # # # # . . . . # # # # # # # # # # # . . . . # # \n# . . . . . . . . . # # # . . . # # # # # . . . # # # # # # # # # # # # # # . . . # \n# . . . # # . # # . # # . . . . # # # # # . . . # # # # # # # # # # # # # # . . . # \n# . . # # # . . . # # . . . . . # # # # # # . . # # # # # # # # # # # # # # . . . # \n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n\n\nOf course, this will generate a new map every time you run it. I would say it’s major flaw is that it’s missing an open path between all the caverns, but otherwise it looks pretty cavelike to me. If I squint.\nA version of this code is in a GitHub Gist. It might even have been in a tweet once.\n\n\n3. Droplet ‘physics’\nI experimented with this in support of a different (secret!) project that may never finish.\nIt’s a cross between the physics of water flowing under gravity and a pathfinding system. Except that description is way too grandiose. Basically, a droplet tile (o) ‘flows’ from top to bottom of a matrix defining a ‘map’ that you create, passing through empty tiles (.) and given ‘collisions’ with block tiles (#).\nHere’s a basic map to start, defined as a matrix:\n\nblock &lt;- \"#\"\nempty &lt;- \".\"\ndrop  &lt;- \"o\"\n\nm &lt;- matrix(\n  c(1, 0, 0, 0, 0,\n    1, 1, 0, 0, 0,\n    1, 1, 1, 0, 0,\n    0, 0, 0, 0, 1,\n    0, 0, 0, 1, 1,\n    1, 0, 1, 1, 1,\n    1, 1, 1, 1, 1),\n  nrow = 7,\n  byrow = TRUE\n)\n\nm[which(m == 1)] &lt;- block\nm[which(m == 0)] &lt;- empty\nm[8] &lt;- drop\n\nprint(m)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,] \"#\"  \"o\"  \".\"  \".\"  \".\" \n[2,] \"#\"  \"#\"  \".\"  \".\"  \".\" \n[3,] \"#\"  \"#\"  \"#\"  \".\"  \".\" \n[4,] \".\"  \".\"  \".\"  \".\"  \"#\" \n[5,] \".\"  \".\"  \".\"  \"#\"  \"#\" \n[6,] \"#\"  \".\"  \"#\"  \"#\"  \"#\" \n[7,] \"#\"  \"#\"  \"#\"  \"#\"  \"#\" \n\n\nYou can make this map more or less complicated. You can even use {pixeltrix} to make a map by interactively clicking squares in a plot window to receive back a matrix.\nThe code to run ‘the simulation’ is just a repeat loop that wipes and draws to the console following some basic ifs. It will break when the droplet comes to a stop.\n\nrepeat {\n  \n  cat(\"\\014\")\n  \n  for (row in seq(nrow(m))) {\n    cat(m[row, ], \"\\n\", sep = \" \")\n  }\n  \n  Sys.sleep(1)\n  \n  droplet_i      &lt;- which(m == drop)\n  droplet_i_save &lt;- droplet_i\n  below_i        &lt;- droplet_i + 1\n  \n  if (m[below_i] == empty) {\n    m[droplet_i] &lt;- empty\n    m[below_i]   &lt;- drop\n  }\n  \n  if (m[below_i] == block) {\n    \n    left_i  &lt;- droplet_i - nrow(m)\n    right_i &lt;- droplet_i + nrow(m)\n    \n    is_left_open  &lt;- FALSE\n    is_right_open &lt;- FALSE\n    \n    if (m[left_i] == empty)  is_left_open  &lt;- TRUE\n    if (m[right_i] == empty) is_right_open &lt;- TRUE\n    \n    if (is_left_open & is_right_open) {\n      sampled_direction_i &lt;- sample(c(left_i, right_i), 1)\n      m[droplet_i]           &lt;- empty\n      m[sampled_direction_i] &lt;- drop\n    }\n    \n    if (is_left_open & !is_right_open) {\n      m[droplet_i] &lt;- empty\n      m[left_i]    &lt;- drop\n    }\n    \n    if (!is_left_open & is_right_open) {\n      m[droplet_i] &lt;- empty\n      m[right_i]   &lt;- drop\n    }\n    \n  }\n  \n  droplet_i &lt;- which(m == drop)\n  if (droplet_i == droplet_i_save) break\n}\n\nHere’s a little gif showing how this basic example looks in the console:\n\n\n\n\n\nAlas, I am an untrustworthy narrator! The droplet will scooch left and right forever on a flat surface. The animation only stops if the droplet is trapped at the lowest point, like in the gif above. No one really understands physics though, right, so it’s basically fine.\nI think I wanted to have the droplet travel diagonally instead of across and down; try introducing tiles with different properties (e.g. angled, like \\ and /); and have the ability to add more than one droplet at a time. I’ll probably explain eventually about why I made this subpar toy6.\nYou can find a version of this code in a GitHub gist if you really must."
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html#now-wash-your-hands",
    "href": "posts/2023-09-08-trash-combing/index.html#now-wash-your-hands",
    "title": "Combing through my trash",
    "section": "Now wash your hands",
    "text": "Now wash your hands\nNothing here is going to change your life; I just wanted to set these ideas free for purposes of spiritual atonement.\nFor fun toys and proper R noodlings you can always check out anything by Mike (coolbutuseless), or stuff like Tomaz‘s ’Little Useless-Useful’ series. Far more fruitful.\nBeware: this may be the first post in a series. I’m not afraid to put my hand back in the waste disposal unit. Are you?"
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html#environment",
    "href": "posts/2023-09-08-trash-combing/index.html#environment",
    "title": "Combing through my trash",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-09-09 09:57:43 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     ambient_1.0.2    \n [5] cli_3.6.1         tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0\n [9] yaml_2.3.7        rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7   \n[13] xfun_0.39         digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-09-08-trash-combing/index.html#footnotes",
    "href": "posts/2023-09-08-trash-combing/index.html#footnotes",
    "title": "Combing through my trash",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSuch as a fictitious map of Sodor or a chart over time over Thomas the Tank mods in popular videogames. Whatever you like.↩︎\nThis just looks like a screenshot of treasure locations from The Legend of Zelda: The Windwaker, which I assume I was replaying at the time.↩︎\nI’ve reinvented the wheel more than once, like for {coloratio}/{savonliquide}, {badgr}/{badger} and {trapinch}/{pokeapi}.↩︎\n*Breathes in deep breath of copium.*↩︎\nR is a game engine, fight me.↩︎\nOr not. You can’t tell me what to do.↩︎"
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html",
    "href": "posts/2021-06-21-recreate-hlito/index.html",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "",
    "text": "I used base R to replicate some art as part of #RecreationThursday."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#tldr",
    "href": "posts/2021-06-21-recreate-hlito/index.html#tldr",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "",
    "text": "I used base R to replicate some art as part of #RecreationThursday."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#rando-hlito",
    "href": "posts/2021-06-21-recreate-hlito/index.html#rando-hlito",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "Rando-Hlito",
    "text": "Rando-Hlito\nThe first #RecreationThursday challenge involved Alfredo Hlito’s Curves and Straight Series (1948), held by New York’s MoMA.\nMy recreation uses only base R functions:\n\nMy remix is a 10 by 10 grid where the elemental geometry is randomised:\n\nI also made a gif remix that’s composed of 10 ‘rando-Hlitos’:"
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#approach",
    "href": "posts/2021-06-21-recreate-hlito/index.html#approach",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "Approach",
    "text": "Approach\nYou can find all the commented code and the outputs in my matt-dray/viz-recreation GitHub repo.\n\nRecreate\nI chose to use base R plotting functions for this project. Largely for the simplicity and for the lack of dependencies, but also due to success I had recently when recreating another artwork.1\nThe overall principle was relatively straightforward: use trial-and-error to place elements made with the line() and segments() functions. It’s not perfect, but it’s close enough.\nTo summarise the code, it first opens the png() graphics device; sets par()ameters to exclude margins and set the background colour; plot()s an empty plot; builds lines with x and y coordinates; builds circle segments with x, y, radius and theta; and finally closes the device with dev.off().\n\n\nRemix\nThere’s some great remixes on the #RecreationThursday hashtag in Twitter and I particularly liked the ones that went for slight variations in stroke and placement, as well as those with an animated approach.\nIn this vein, I chose to vary randomly the elements of the plot using a custom function, vary_hlito().\nThe randomisation was relatively simplistic: vary the y-axis location of each of the horizontal lines, but maintain their widths and colours; provide different segment lengths for each of the two circles while retaining their radii and centres; vary the length and placement of the diagonal line running top-left to bottom-right.\nThere’s a number of ways to present these ‘rando-Hlitos’. I thought it would be interesting to do two things: create a large grid of many recreations (i.e. create a ‘meta’ rando-Hlito) and create an animation (i.e. a sequential reveal of many recreations). I think these are interesting in different ways.\nIn particular, I think the 10 by 10 grid echoes two completely different styles: the repeating nature is a bit like a moquette pattern from the London Underground, while the colours and shapes aren’t far off a 90s Memphis Style.\nTo summarise the code, the grid was created by setting a 10 by 10 panel with mfrow = c(10, 10) passed to par() and then different seeds were passed into vary_hlito() with purrr::walk() to dictate the randomness. The animation was generated by looping over randomly-selected seeds and saving each output as a PNG, before stitching these frames into a gif with the {magick} package."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#get-involved",
    "href": "posts/2021-06-21-recreate-hlito/index.html#get-involved",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "Get involved",
    "text": "Get involved\nCheck out #RecreationThursday on Twitter. It’s a community challenge to recreate an art piece selected each fortnight by a rotating curator. The subject for the second week has been released already.\nThe timetable, art pieces, curators and example alt-text are available in Sharla Gelfand’s RecreationThursday repo on GitHub."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#environment",
    "href": "posts/2021-06-21-recreate-hlito/index.html#environment",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 15:01:33 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#footnotes",
    "href": "posts/2021-06-21-recreate-hlito/index.html#footnotes",
    "title": "Recreation Thursday: Hlito with base R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou may have noticed two very similar blogposts in a row about base R for recreating someone else’s graphics. I will return to the normal R-stats japes and whimsy for the next post. Maybe.↩︎"
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#tldr",
    "href": "posts/2023-07-15-hiscore/index.html#tldr",
    "title": "Save high scores for your R game",
    "section": "tl;dr",
    "text": "tl;dr\nYou can save your high score in games made with R. See the package {hiscore} for a demo."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#boot-up",
    "href": "posts/2023-07-15-hiscore/index.html#boot-up",
    "title": "Save high scores for your R game",
    "section": "Boot up",
    "text": "Boot up\nI wrote recently about how R is a game engine and started a list of games written in R.\nAll good game engines should let you save a high score, right?\nSo I’ve done exactly this for a tiny concept package called {hiscore}1 that contains a simple game of luck\nThe package runs code that saves your high score, which is retained between play sessions."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#install",
    "href": "posts/2023-07-15-hiscore/index.html#install",
    "title": "Save high scores for your R game",
    "section": "Install",
    "text": "Install\nYou can install the package from GitHub. It has no dependencies, but you’ll need to be running R version 4, at least.\n\ninstall.package(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/hiscore\")\nlibrary(hiscore)\n\nOf course, it’s just a concept and I’ve intentionally kept this as trivial as possible, but you can leave an issue with bugs or ideas."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#play",
    "href": "posts/2023-07-15-hiscore/index.html#play",
    "title": "Save high scores for your R game",
    "section": "Play",
    "text": "Play\nFor demonstration purposes, the inbuilt game is super simple: get the longest streak of correctly guessed coinflips.\nTo play, run play_coinflip() and type H or T and Enter when prompted. Basically, a coinflip is simulated with sample(c(\"H\", \"T\"), 1) and then compared to the user’s input, supplied from the console following a readline() call.\nKeep going until you get it wrong. If you get a new high score, it’ll be saved.\n\nplay_coinflip()\n\n[H]eads or [T]ails? Answer: H\nCorrect! Current score: 1\n[H]eads or [T]ails? Answer: H\nIncorrect! Final score: 1\nNew high score!\nNew high score saved.\nYou can retrieve the current high score with get_save_data(), which returns a little table.\n\nget_save_data()\n\n      game high_score\n1 coinflip          1\nOf course, you could also set up the function so that it records different player names too. And you could add additional games that would get their own row in this table."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#memory",
    "href": "posts/2023-07-15-hiscore/index.html#memory",
    "title": "Save high scores for your R game",
    "section": "Memory",
    "text": "Memory\nNote that the high score data is retained on your computer even if you restart your session or reboot your machine. How so?\nThis is thanks to the tools::R_user_dir() function, which was added to R in version 4.0. It builds system-specific paths to ‘directories for storing R-related user-specific data, configuration and cache files’ where you can save package-related information.\n{hiscore} records top scores in this fashion. On my machine, the save location resolves to the following:\n\ntools::R_user_dir(\"hiscore\", \"data\")\n\n[1] \"/Users/mattdray/Library/Application Support/org.R-project.R/R/hiscore\"\n\n\nRegular readers may remember that I used R_user_dir() in the {tamRgo} package (blog, source), which lets you look after a Tamagotchi-style cyber-pet in your console. I used the function to save a pet’s ‘blueprint’ (details such as name, age and hunger level) persistently."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#retry",
    "href": "posts/2023-07-15-hiscore/index.html#retry",
    "title": "Save high scores for your R game",
    "section": "Retry",
    "text": "Retry\nNow imagine you want to retry to beat that incredible top score of 1. Since you last played, you probably restarted your session or computer.\nRestarting R session...\nBut never fear: the high score was retained. You can see that when you run play_coinflip() again and are reminded of the current best.\n\nlibrary(hiscore)\nplay_coinflip()\n\nWelcome. Your current high score is 1\n[H]eads or [T]ails? Answer: h\nCorrect! Current score: 1\n[H]eads or [T]ails? Answer: t\nCorrect! Current score: 2\n[H]eads or [T]ails? Answer: h\nIncorrect! Final score: 2\nNew high score!\nNew high score saved.\nGreat job, you doubled the previous record!\nWhen you get a game over, the play_coinflip() function checks the current high score and compares it to the final score for the current play session. The saved data is overwritten if the score is higher.\n\nget_save_data()\n\n      game high_score\n1 coinflip          2\nI think it’s a good idea to make it easy for people to destroy the stored data if they want, which you can do easily with delete_save_data().\n\ndelete_save_data()\n\nReally delete? [Y]es/[N]o: Y\nHigh score data deleted."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#game-over",
    "href": "posts/2023-07-15-hiscore/index.html#game-over",
    "title": "Save high scores for your R game",
    "section": "Game over",
    "text": "Game over\nHow else could this approach be used in an R gaming perspective? You could use this to save a game state, similar to what’s done for {tamRgo}. The user could input Save instead of performing a guess, which would record the current status of the game so the user can return later. But that would feel like cheating for a game like coinflip.\nSpeaking of, here’s a cheatcode as a bonus for reading this far:\n\ncheat &lt;- function(game, new_score) {\n  user_dir &lt;- tools::R_user_dir(\"hiscore\", \"data\")\n  score_path &lt;- file.path(user_dir, \"score_table.rds\")\n  score_table &lt;- readRDS(score_path)\n  score_table[score_table[[\"game\"]] == game, \"high_score\"] &lt;- new_score\n  saveRDS(score_table, score_path)\n}\n\ncheat(\"coinflip\", 1e100)\nget_save_data()\n\n      game high_score\n1 coinflip     1e+100\nHeh heh heh."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#environment",
    "href": "posts/2023-07-15-hiscore/index.html#environment",
    "title": "Save high scores for your R game",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-25 15:10:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] hiscore_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#footnotes",
    "href": "posts/2023-07-15-hiscore/index.html#footnotes",
    "title": "Save high scores for your R game",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs in ‘high score’ not as in ‘his core’.↩︎"
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html",
    "href": "posts/2020-04-17-r-self-shame/index.html",
    "title": "Owning the shame of my old R code",
    "section": "",
    "text": "Scorn (all images from Brehm’s Life of Animals, 1895)."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#tldr",
    "href": "posts/2020-04-17-r-self-shame/index.html#tldr",
    "title": "Owning the shame of my old R code",
    "section": "tl;dr",
    "text": "tl;dr\nIn which I reflect on my past-self’s journey toward better R code.\nThis post suggests alternatives to file.choose(), setwd() and attach(); encourages sensible project structure; and talks about the benefit of writing functions."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#a-startling-discovery",
    "href": "posts/2020-04-17-r-self-shame/index.html#a-startling-discovery",
    "title": "Owning the shame of my old R code",
    "section": "A startling discovery",
    "text": "A startling discovery\nI dug up a time capsule from a decade ago. It contained poorly constructed R code.\nTwist: it was me who wrote it.\nReading these scripts brought back the sweet nostalgia of running the vanilla R GUI on my precious white MacBook, using R as little more than an interactive calculator for ecological analyses.\nThere were some things in that code that look alien to me now (click to jump ahead):\n\nfile.choose() and setwd() for non-reproducible file locations\nThe attach() function for basically hiding his data and forgetting it exists\nWorking in the same R workspace at all times regardless of context\nRepeating code over and over and over and over and…\n\nThis post is about learning. It’s about looking for improvements. Everyone is a beginner at some point and everyone is taught in a different way. There’s no shame in that.\nHopefully this post might act as a shortcut for you to hear about some alternative techniques.\n\n\n\nAgony."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#files",
    "href": "posts/2020-04-17-r-self-shame/index.html#files",
    "title": "Owning the shame of my old R code",
    "section": "1. Falling foul of a file-finding fail",
    "text": "1. Falling foul of a file-finding fail\nCan’t remember where a file is? Don’t want long file paths cluttering your scripts? Nevermind! Past-Matthew was using file.choose(), which opens your file explorer so you can navigate to the correct file.\n\ndf &lt;- read.csv(file.choose())\n\nBut how can anyone reading your script (including you) know what file you actually read in? It’s not recorded in your script. You can’t re-run this code without that information.\nSolutions:\n\ngood project-folder structure that puts all the elements of your analysis — data, scripts, outputs — in one place so its portable and others can use it without having to change anything\nrelative file paths that start from your project folder, so you can use computer-agnostic paths like data/cool-data.csv rather path/specific/to/my/machine/data/cool-data.csv\n\nTools:\n\nRStudio Projects encourage good folder structure and have the bonus of relative file paths, which start from the directory containing the .Rproj file.\nthe {here} package by Kirill Müller also helps with relative file paths; here() finds a file based on the perceived ‘home’ for the project, or just where a manually-placed hidden .here file is placed with set_here()\n\n\nJustified arson\nYou may wonder why I haven’t mentioned setwd() as a solution here. It’s because Jenny Bryan will set your computer on fire.\nBut past-Matthew did this.1 He used setwd() to point to where a project was stored locally:\n\nsetwd(\"/Users/Matthew//local/path/to/project/\")\ndf &lt;- read.csv(\"data/some_file.csv\")\n\nWhat’s the problem? The bit in setwd() is not reproducible — it’s the file location on one particular machine only.\n\n\n\nMirth."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#attach",
    "href": "posts/2020-04-17-r-self-shame/index.html#attach",
    "title": "Owning the shame of my old R code",
    "section": "2. Getting too attached",
    "text": "2. Getting too attached\nThis problem begins with a question: how does R know where to look for a variable?\nHere’s three ways to calculate Pokémon body mass index by reference to variables in a data set:\n\n# Read Pokémon data from URL\ndf &lt;- suppressMessages(readr::read_csv(\n  \"https://raw.githubusercontent.com/mwdray/datasets/master/pokemon_go_captures.csv\",\n))\n\n# BMI calculation three ways\nx &lt;- mean(df$weight_kg / df$height_m ^ 2)  # dollar notation\ny &lt;- mean(df[[\"weight_kg\"]] / df[[\"height_m\"]] ^ 2)  # square brackets\nz &lt;- with(df, mean(weight_kg / height_m ^ 2))  # with() function\n\n# All produce the same results?\nall(x == y, y == z, x == z)\n\n[1] TRUE\n\n\nSo each line specifies the data frame object where R should look for the named variables. If you don’t provide this object, R will error:\n\nmean(weight_kg / height_m ^ 2)\n\n## Error in mean(weight_kg / height_m ^ 2) : object 'weight_kg' not found\nR was searching for the weight_kg variable in a few places, starting with the global environment, but couldn’t find it. You can see the search path it takes:\n\nsearch()\n\n[1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\" \n[4] \"package:grDevices\" \"package:utils\"     \"package:datasets\" \n[7] \"package:methods\"   \"Autoloads\"         \"package:base\"     \n\n\nThe data object isn’t in there, so that’s why it can’t find those variables.\nPast-Matthew got around this by using attach(), which lets you add objects to the search path.\n\nattach(df)\nsearch()  # now 'df' is in the search path\n\n [1] \".GlobalEnv\"        \"df\"                \"package:stats\"    \n [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"    \n [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"        \n[10] \"package:base\"     \n\n\nThe following expression can now be calculated because R can find the variable names in the attached df object.\n\nmean(weight_kg / height_m ^ 2)\n\n[1] 31.17416\n\n\nSo we never need to refer to the data frame name at all. Wow, how can that be bad?\nHere’s one reason. Consider a data set with column names that match our original:\n\ndf2 &lt;- df[species == \"caterpie\", ]\nattach(df2)\n\nThe following objects are masked from df:\n\n    charge_attack, combat_power, fast_attack, height_bin, height_m,\n    hit_points, species, weight_bin, weight_kg\n\n\nYou might be able to guess the problem: R will get variables from df2 first, since it was the most recently attached.\nBad news: this means the code we wrote earlier will get a different result.\n\nmean(weight_kg / height_m ^ 2)\n\n[1] 31.64357\n\n\nThis has serious implications for reproducibility and the confidence you can have in your results.\nSee also the ‘search list shuffle’ danger of attach() referenced in Circle 8.1.35 of The R Inferno by Patrick Burns.\nPast-Matthew was using this approach because he was taught with Mick Crawley’s R Book. Mick says attach() ‘makes the code easier to understand for beginners’ (page 18)2 — possibly because expressions end up looking less cluttered. But this only sets up beginners (like me) for problems later. In fact, Mick even says, perhaps confusingly, to ‘avoid using attach wherever possible’ in his book.\nPro tip: if you do ever use attach() (don’t), you’ll want to make sure you detach() your objects from the search path.\n\ndetach(df)\ndetach(df2)\n\n\n\n\nBemusement."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#env",
    "href": "posts/2020-04-17-r-self-shame/index.html#env",
    "title": "Owning the shame of my old R code",
    "section": "3. Polluting the environment",
    "text": "3. Polluting the environment\nPast-Matthew clearly executed different projects and scripts in the same running instance of R.\nThe potential for confusion and error is high in this scenario. Was the object results created from analysis1.R or analysis2.R? Maybe results is now out of date because the code has been updated.\nI’m also certain that the content of past-Matthew’s workspace was being saved at the end of each session — the default behaviour — meaning all that trash would come back next time he fired up R.\nThere were also some strange defensive lines like the following, which pre-emptively unloads the {nlme} package because of a namespace conflict with {lme4}:\n\ndetach(\"package:nlme\")  # conflicts with lme4\n\nI assume this was because past-Matthew was never quite sure of the state of his current working environment.\nThese days I treat everything in my environment with suspicion and restart R regularly and rebuild objects from scratch. This means I can have confidence that my script does what I think it does and also stops interference from older objects that are clogging up my environment.\nI also modified the default behaviour of RStudio to prevent my workspace being saved, which means I can start afresh when I open a project. To do this, untick ‘Restore .Rdata on startup’ and set ‘Save workspace to .RData on exit’ to ‘Never’ in Tools &gt; Global Options &gt; General &gt; Basic &gt; Workspace.\nRead more about workflow in the R for Data Science book by Garrett Grolemund and Hadley Wickham.\n\n\n\nDisgust."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#repeat",
    "href": "posts/2020-04-17-r-self-shame/index.html#repeat",
    "title": "Owning the shame of my old R code",
    "section": "4. There’s a function for that",
    "text": "4. There’s a function for that\nTurns out past-Matthew repeated loads of code because functions looked too much like Real Programming and were therefore Quite Hard.\nHere’s a simple example of code repetition that was pretty common in past-Matthew’s scripts:\n\n# Subset the data and then get a mean value\nsub_koffing &lt;- subset(df, species == \"koffing\")\nmean_koffing &lt;- round(mean(sub_koffing[[\"weight_kg\"]]), 2)\n\n# Do it again for a different species\nsub_paras &lt;- subset(df, species == \"paras\")\nmean_paras &lt;- round(mean(sub_paras[[\"weight_kg\"]]), 2)\n\n# Do it again for a different species\nsub_geodude &lt;- subset(df, species == \"geodude\")\nmean_geodude &lt;- round(mean(sub_koffing[[\"weight_kg\"]]), 2)\n\n# Print results\nmean_koffing; mean_paras; mean_geodude\n\n[1] 0.92\n\n\n[1] 5.39\n\n\n[1] 0.92\n\n\nYou know this is bad news; copy-pasting leads to mistakes. See how two of those outputs are suspiciously similar? Oops.3\n(Note the use of semi-colons here as well. Past-Matthew seemed to like using these to print multiple results, but I don’t use these anymore and don’t see anyone else doing it.)\nFunctions let you write the meat of the code just once, eliminating the copy-paste error. You can then loop over the variables of interest to get your results.\nThe effort of learning to write your own functions is worth it to avoid the problems. See R for Data Science for more on this.\nHere’s one way to tackle the code repetition above:\n\n# Function to calcuate a rounded mean value for a given species\nget_sp_mean &lt;- function(\n  sp, data = df, var = \"weight_kg\", dp = 2\n) {\n  \n  sub_sp &lt;- subset(data, species == sp)  # subset data\n  mean_sp &lt;- round(mean(sub_sp[[var]]), dp)  # get mean\n  return(mean_sp)  # function will output the mean value\n  \n}\n\n# Create a named vector to iterate over\nspecies &lt;- c(\"koffing\", \"paras\", \"geodude\")\nnames(species) &lt;- species  # make it a named vector\n\n# Iterate over the vector to apply the function\npurrr::map(species, get_sp_mean)\n\n$koffing\n[1] 0.92\n\n$paras\n[1] 5.39\n\n$geodude\n[1] 23.24\n\n\nFriendship ended with code repetition. Now bespoke functions and {purrr} are my best friends.\n\n\n\nEmpathy."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#reflections",
    "href": "posts/2020-04-17-r-self-shame/index.html#reflections",
    "title": "Owning the shame of my old R code",
    "section": "Reflections",
    "text": "Reflections\nI think it’s a good exercise to look back and critique your old code. What changes have you made to your coding practices over time?\nThere’s no shame in writing code that does what you want it to do. I can see why past-Matthew did the things he did. But I’m also glad he stopped doing them.\nSee you in ten years to look back on the inevitably terrible code I’ve written in this blog."
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#environment",
    "href": "posts/2020-04-17-r-self-shame/index.html#environment",
    "title": "Owning the shame of my old R code",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 11:47:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2      vctrs_0.6.3       cli_3.6.1         knitr_1.43.1     \n [5] rlang_1.1.1       xfun_0.39         purrr_1.0.1       jsonlite_1.8.7   \n [9] bit_4.0.5         glue_1.6.2        htmltools_0.5.5   hms_1.1.3        \n[13] fansi_1.0.4       rmarkdown_2.23    evaluate_0.21     tibble_3.2.1     \n[17] tzdb_0.4.0        fastmap_1.1.1     yaml_2.3.7        lifecycle_1.0.3  \n[21] compiler_4.3.1    htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.15.0\n[25] digest_0.6.33     R6_2.5.1          tidyselect_1.2.0  readr_2.1.4      \n[29] utf8_1.2.3        curl_5.0.1        parallel_4.3.1    vroom_1.6.3      \n[33] pillar_1.9.0      magrittr_2.0.3    tools_4.3.1       bit64_4.0.5"
  },
  {
    "objectID": "posts/2020-04-17-r-self-shame/index.html#footnotes",
    "href": "posts/2020-04-17-r-self-shame/index.html#footnotes",
    "title": "Owning the shame of my old R code",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMy darling white plastic MacBook would have melted horribly if set on fire.↩︎\nTo be fair, Mick has taught a lot of R classes in his time.↩︎\nEspecially because Geodude is made of rock and Koffing is basically just made of gas.↩︎"
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#tldr",
    "href": "posts/2021-11-07-deepfry/index.html#tldr",
    "title": "Deep fried memes in R",
    "section": "tl;dr",
    "text": "tl;dr\nNow you can use a function to deep fry memes in R."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#extra-crispy",
    "href": "posts/2021-11-07-deepfry/index.html#extra-crispy",
    "title": "Deep fried memes in R",
    "section": "Extra crispy",
    "text": "Extra crispy\nYou can make memes in R with packages like Guangchang Yu’s {meme}. You could even post them to Twitter with #RStatsMemes for @rstatsmemes to find.\nHowever, it’s no longer enough to present memes as-is. They must be deep-fried to become modern and ironic. It will help people think that your meme is so edgy that it’s been re-saved thousands of times."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#get-to-temperature",
    "href": "posts/2021-11-07-deepfry/index.html#get-to-temperature",
    "title": "Deep fried memes in R",
    "section": "Get to temperature",
    "text": "Get to temperature\nYou’ll need image-manipulation wizardry from the {magick} package, along with {extrafont} to let you use fonts from your system.\nAt time of writing there is an issue with importing fonts, which requires an earlier version of {Rttf2pt1} to be installed.\n\ninstall.packages(c(\"magick\", \"extrafont\", \"remotes\"))\nremotes::install_version(\"Rttf2pt1\", version = \"1.3.8\")\n\nYou can then import fonts from your system.\n\nextrafont::font_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \nNow we can use important joke fonts—like Impact, Papyrus or Calibri—in our memes, assuming they’re installed on your system."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#small-fry",
    "href": "posts/2021-11-07-deepfry/index.html#small-fry",
    "title": "Deep fried memes in R",
    "section": "Small fry",
    "text": "Small fry\nI’ve cooked up a single, low-quality function, fry(), that:\n\nReads a meme template image (or any image) from a path\nAdds top/bottom text in Impact font\nReads from a URL a specific (cursed) cry/laugh emoji that’s popular in deep-frying and places it in a random location (corners or left/right sides)\nAdjusts the image contrast, saturation, etc,1, tints it orange and bulges it from the centre\nWrites the image to a temporary jpeg file—compressing it horribly—and then reads it back in\nOutputs a magick-image object that you can save with magick::image_write() and send to all your friend (sic)\n\nIt does what I want it to do; adjust it as you please.\n\nsuppressPackageStartupMessages(library(magick))\n\nfry &lt;- function(\n  img_path, emoji_path,\n  text_top, text_bottom,\n  depth = c(\"shallow\", \"deep\")) {\n  \n  depth &lt;- match.arg(depth)\n  \n  cat(\"Heating oil... \")\n  \n  emoji &lt;- magick::image_read(emoji_path)\n  \n  emoji_where &lt;-  sample(c(  \n    paste0(\"north\", c(\"east\", \"west\")),\n    paste0(\"south\", c(\"east\", \"west\")),\n    \"east\", \"west\"  # e.g. 'east' is right\n  ), 1)\n  \n  img &lt;- image_read(img_path) |&gt; \n    image_annotate(\n      text_top, \"north\", size = 80, font = \"Impact\",\n      color = \"white\", strokecolor = \"black\"\n    ) |&gt;\n    image_annotate(\n      text_bottom, \"south\", size = 80, font = \"Impact\",\n      color = \"white\", strokecolor = \"black\"\n    ) |&gt;\n    image_scale(\"1000\") |&gt; \n    image_composite(emoji, gravity = emoji_where) |&gt; \n    image_colorize(30, \"orange\") |&gt;  # tint\n    image_modulate(brightness = 80, saturation = 120, hue = 90) |&gt;\n    image_contrast(sharpen = 100) |&gt; \n    image_noise()\n  \n  cat(\"dunking meme... \")\n  \n  if (depth == \"shallow\") {\n    img &lt;- img %&gt;% image_implode(-0.5)  # bulge\n    compress &lt;- 8\n  } else if (depth == \"deep\") {\n    img &lt;- img %&gt;% image_implode(-1)  # more bulge\n    compress &lt;- 1  # maximum compression\n  } \n  \n  path_out &lt;- tempfile(\"meme\", fileext = \".jpeg\")\n  image_write(img, path_out, \"jpeg\", compress)\n  \n  cat(\"crisp.\")\n  image_read(path_out)\n  \n}"
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#get-cooking",
    "href": "posts/2021-11-07-deepfry/index.html#get-cooking",
    "title": "Deep fried memes in R",
    "section": "Get cooking",
    "text": "Get cooking\nWhat spicy meme shall I make? Well, the = versus &lt;- assignment-operator flamewar has been cold for a few days, so time to heat it up again.2 And why not incorporate the world’s most famous fry cook (in sarcastic form)?\n\nsponge_path &lt;- paste0(  # URL to meme image\n  \"https://raw.githubusercontent.com/matt-dray/rostrum-blog/\",\n  \"master/static/post/2021-11-07-deepfry_files/spongebob.jpg\"\n)\n\nemoji_path &lt;- paste0(  # URL to cry/laugh emoji\n  \"https://raw.githubusercontent.com/matt-dray/rostrum-blog/\",\n  \"master/static/post/2021-11-07-deepfry_files/deepfry-emoji.jpg\"\n)\n\nbot_txt &lt;- \"= sAvEs KeYsTrOkEs Vs &lt;-\"  # sarcastic text\ntop_txt &lt;- tolower(bot_txt)\n\nFirst, a nice shallow fry.\n\nfry(sponge_path, emoji_path, top_txt, bot_txt, \"shallow\")\n\nHeating oil... dunking meme... crisp.\n\n\n\n\n\nAnd now we deep fry.\n\nfry(sponge_path, emoji_path, top_txt, bot_txt, \"deep\")\n\nHeating oil... dunking meme... crisp.\n\n\n\n\n\n*Fry-cook’s kiss*"
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#footnotes",
    "href": "posts/2021-11-07-deepfry/index.html#footnotes",
    "title": "Deep fried memes in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDid I arrive at these settings scientifically? Yes, they were the ones that made me laugh when I saw the resulting output.↩︎\nI have written before about this very serious topic. I developed a method to detect = for assignment without you having to open a script that contains it.↩︎"
  },
  {
    "objectID": "posts/2019-04-14-one-year/index.html#tldr",
    "href": "posts/2019-04-14-one-year/index.html#tldr",
    "title": "A year of rostrum.blog",
    "section": "tl;dr",
    "text": "tl;dr\nHappy first birthday to this blog."
  },
  {
    "objectID": "posts/2019-04-14-one-year/index.html#one-year-visualised",
    "href": "posts/2019-04-14-one-year/index.html#one-year-visualised",
    "title": "A year of rostrum.blog",
    "section": "One year, visualised",
    "text": "One year, visualised\nThere’s been 27 posts on rostrum.blog in its first year, so about one every two weeks.\nThis interactive graphic shows the publishing frequency, where each dot is a post and the x-axis is time. Turn your mobile to landscape mode to see it in full.\n\n\n\n\n\n\n\n\nExpand for code\n\n\n# The data for the plot was scraped using {rvest} and visualised\n# with {ggplot2} and {plotly}.\n\n# Load packages\nlibrary(dplyr)  # data manipulation\nlibrary(rvest)  # web scrape\nlibrary(stringr)  # string manipulation\nlibrary(lubridate)  # deal with dates\nlibrary(ggplot2)  # plots\nlibrary(plotly)  # interactive plots\n\n# Scrape the rostrum.blog home page\nhtml &lt;- read_html(\"https://rostrum.blog/\")  # the site's homepage lists the posts\n\n# Extract the post titles\ntitle &lt;- html %&gt;%\n  html_nodes(\".archive-item-link\") %&gt;%  # node identified with SelectorGadget \n  html_text()  # extract the text from the node\n\n# Extract the post dates\ndate &lt;- html %&gt;%\n  html_nodes(\".archive-item-date\") %&gt;%  # element with the data we care about\n  html_text() %&gt;%  # convert to text\n  str_replace_all(\"\\n|[:space:]\", \"\")  # replace newline-space with blank\n\n# Dataframe of titles and dates\nposts &lt;- tibble(title = title, publish_date = date) %&gt;% \n  mutate(publish_date = ymd(date)) %&gt;%  # make column datetime\n  arrange(publish_date) %&gt;%  # order by date\n  filter(publish_date &lt; \"2019-04-14\")  # only posts before this one\n\n# Create plot object\np &lt;- posts %&gt;%\n  mutate(count = 1) %&gt;%   # dummy to indicate a post was made\n  ggplot(aes(x = publish_date, y = count, label = title)) +\n  geom_point(color = \"#1D8016\") +  # match the rostrum.blog green\n  theme_void() +  # strip plot elements\n  theme(panel.grid = element_blank())  # to stop plotly rendering grid\n\n# Object telling {plotly} not to do axes, etc \nax &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE,\n  showgrid = FALSE\n)\n\n# Pass the plot object to plotly (actually performed outside this code chunk)\nggplotly(\n  p,  # plot object\n  tooltip = c(\"publish_date\", \"title\")  # add mousover info\n) %&gt;%\n  layout(xaxis = ax, yaxis = ax) %&gt;%  # remove axes\n  config(displayModeBar = FALSE)  # don't show plotly toolbar"
  },
  {
    "objectID": "posts/2019-04-14-one-year/index.html#more-to-come",
    "href": "posts/2019-04-14-one-year/index.html#more-to-come",
    "title": "A year of rostrum.blog",
    "section": "More to come",
    "text": "More to come\nYou can continue to expect more posts about important topics like Pokemon, Dawson’s Creek, Kanye West, the National Basketball Association, Star Trek and dead deer.\nI hope you’ve learnt something new about R, like how to begin using it, how to create reproducible reports, how to create interactive maps, how to build network graphs, how to webscrape, how to build simple serverless apps, how to debug tidyverse pipelines, or just remind yourself that you can do it."
  },
  {
    "objectID": "posts/2019-04-14-one-year/index.html#environment",
    "href": "posts/2019-04-14-one-year/index.html#environment",
    "title": "A year of rostrum.blog",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 16:37:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] plotly_4.10.2   ggplot2_3.4.2   lubridate_1.9.2 stringr_1.5.0  \n[5] rvest_1.0.3     dplyr_1.1.2    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    selectr_0.4-2     compiler_4.3.1   \n [5] tidyselect_1.2.0  xml2_1.3.5        tidyr_1.3.0       scales_1.2.1     \n [9] yaml_2.3.7        fastmap_1.1.1     R6_2.5.1          labeling_0.4.2   \n[13] generics_0.1.3    curl_5.0.1        knitr_1.43.1      htmlwidgets_1.6.2\n[17] tibble_3.2.1      munsell_0.5.0     pillar_1.9.0      rlang_1.1.1      \n[21] utf8_1.2.3        stringi_1.7.12    xfun_0.39         lazyeval_0.2.2   \n[25] viridisLite_0.4.2 timechange_0.2.0  cli_3.6.1         withr_2.5.0      \n[29] magrittr_2.0.3    crosstalk_1.2.0   digest_0.6.33     grid_4.3.1       \n[33] rstudioapi_0.15.0 lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21    \n[37] glue_1.6.2        data.table_1.14.8 fansi_1.0.4       colorspace_2.1-0 \n[41] purrr_1.0.1       rmarkdown_2.23    httr_1.4.6        ellipsis_0.3.2   \n[45] tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html",
    "href": "posts/2019-05-31-brickr-soccer/index.html",
    "title": "Make a {brickr} soccer player",
    "section": "",
    "text": "You can create 3D Lego models with {brickr}. I made some models of soccer players."
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#tldr",
    "href": "posts/2019-05-31-brickr-soccer/index.html#tldr",
    "title": "Make a {brickr} soccer player",
    "section": "",
    "text": "You can create 3D Lego models with {brickr}. I made some models of soccer players."
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#virtual-lego",
    "href": "posts/2019-05-31-brickr-soccer/index.html#virtual-lego",
    "title": "Make a {brickr} soccer player",
    "section": "Virtual Lego",
    "text": "Virtual Lego\n{brickr} is a fun package by Ryan Timpe that lets you build 2D mosaics and 3D models with Lego-like virtual bricks,1 with a little help from Tyler Morgan Wall’s {rayshader} package.\nYou can get started with the brickr toybox, which lets you arrange bricks in a spreadsheet that {brickr} can turn into a 3D model.\n\n\n\nFrom Ryan’s original tweet."
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#kick-off",
    "href": "posts/2019-05-31-brickr-soccer/index.html#kick-off",
    "title": "Make a {brickr} soccer player",
    "section": "Kick-off",
    "text": "Kick-off\nFirst, we install {brickr} from GitHub.2\n\nremotes::install_github(\"ryantimpe/brickr\")\n\nAnd attach it along with some tidyverse packages.\n\nsuppressPackageStartupMessages({\n  library(brickr)\n  library(dplyr)\n  library(tibble)\n})\n\nI’ve written a function called create_brickr_player() that lets you build a soccer player and select the brick colours for the shirt, socks, and much more. It lets you create the same model but change the brick colours with minimum fuss.\nThe function is simple. It helps you create a data frame that specifies the location and colour of individual bricks on successive 2D planes to build up a 3D model.\nThis data frame is a plan that can be interpreted by {brickr} and transformed into a special list that can be rendered in 3D space.\n\n\nClick for the function definition.\n\nNote that the arguments must all be numeric codes as per brickr::lego_colors().\n\ncreate_brickr_player &lt;- function(\n  hair_col = 34,\n  skin_col = 5,\n  boot_col = 6,\n  shirt_body_col = 3,\n  shirt_sleeve_col = 1,\n  shorts_col = 1,\n  sock_col = 3,\n  sock_trim_col = 1\n){\n\n  tibble::tribble(\n\n    ~\"Level\", ~`1`, ~`2`, ~`3`, ~`4`, ~`5`,\n\n    \"A\", 0, 0, 0, 0, 0,\n    \"A\", 0, boot_col, 0, boot_col, 0,\n    \"A\", 0, boot_col, 0, boot_col,0,\n\n    \"B\", 0, 0, 0, 0, 0,\n    \"B\", 0, sock_col, 0, sock_col, 0,\n    \"B\", 0, 0, 0, 0, 0,\n\n    \"C\", 0, 0, 0, 0, 0,\n    \"C\", 0, sock_trim_col, 0, sock_trim_col, 0,\n    \"C\", 0, 0, 0, 0, 0,\n\n    \"D\", 0, 0, 0, 0, 0,\n    \"D\", 0, skin_col, 0, skin_col, 0,\n    \"D\", 0, 0, 0, 0, 0,\n\n    \"E\", 0, shorts_col, 0, shorts_col, 0,\n    \"E\", 0, shorts_col, 0, shorts_col, 0,\n    \"E\", 0, shorts_col, 0, shorts_col, 0,\n\n    \"F\", 0, shorts_col, shorts_col, shorts_col, 0,\n    \"F\", 0, shorts_col, shorts_col, shorts_col, 0,\n    \"F\", 0, shorts_col, shorts_col, shorts_col, 0,\n\n    \"G\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n    \"G\", skin_col, shirt_body_col, shirt_body_col, shirt_body_col, skin_col,\n    \"G\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n\n    \"H\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n    \"H\", skin_col, shirt_body_col, shirt_body_col, shirt_body_col, skin_col,\n    \"H\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n\n    \"I\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n    \"I\", skin_col, shirt_body_col, shirt_body_col, shirt_body_col, skin_col,\n    \"I\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n\n    \"J\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n    \"J\", shirt_sleeve_col, shirt_body_col, shirt_body_col, shirt_body_col, shirt_sleeve_col,\n    \"J\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n\n    \"K\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n    \"K\", shirt_sleeve_col, shirt_sleeve_col, shirt_body_col, shirt_sleeve_col, shirt_sleeve_col,\n    \"K\", 0, shirt_body_col, shirt_body_col, shirt_body_col, 0,\n\n    \"L\", 0, 0, 0, 0, 0,\n    \"L\", 0, 0, skin_col, 0, 0,\n    \"L\", 0, 0, 0, 0, 0,\n\n    \"M\", 0, skin_col, skin_col, skin_col, 0,\n    \"M\", 0, skin_col, skin_col, skin_col, 0,\n    \"M\", 0, skin_col, skin_col, skin_col, 0,\n\n    \"N\", 0, hair_col, hair_col, hair_col, 0,\n    \"N\", 0, hair_col, skin_col, hair_col, 0,\n    \"N\", 0, skin_col, skin_col, skin_col, 0,\n\n    \"O\", 0, hair_col, hair_col, hair_col, 0,\n    \"O\", 0, hair_col, hair_col, hair_col, 0,\n    \"O\", 0, hair_col, hair_col, hair_col, 0\n  )\n\n}\n\n\nHere’s what happens when you use the function with default arguments.\n\nplayer_plan &lt;- create_brickr_player()\nplayer_plan  # preview the object\n\n# A tibble: 45 × 6\n   Level   `1`   `2`   `3`   `4`   `5`\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 A         0     0     0     0     0\n 2 A         0     6     0     6     0\n 3 A         0     6     0     6     0\n 4 B         0     0     0     0     0\n 5 B         0     3     0     3     0\n 6 B         0     0     0     0     0\n 7 C         0     0     0     0     0\n 8 C         0     1     0     1     0\n 9 C         0     0     0     0     0\n10 D         0     0     0     0     0\n# ℹ 35 more rows\n\n\nEach layer of bricks gets a separate value in the Level column. The x-dimension is represented by the rows of the data frame and the y-dimension by the numbered columns.\nEvery non-zero number represents a brick and each value represents a different colour. For example, layer A has dimensions of 3 x 5 where 4 spots will be filled with a brick. Each of these has the value ‘2’, which encodes the colour black. Layer B, meanwhile, has a couple of bricks with value ‘7’, which is bright red.\nHow do you know which numbers encode which colours? You can access the codes from the lego_colors data frame in the {brickr} package.\n\nselect(lego_colors, brickrID, Color, hex)  # colour codes\n\n# A tibble: 54 × 3\n   brickrID Color             hex    \n      &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;  \n 1        1 White             #F4F4F4\n 2        2 Brick yellow      #CCB98D\n 3        3 Bright red        #B40000\n 4        4 Bright blue       #1E5AA8\n 5        5 Bright yellow     #FAC80A\n 6        6 Black             #1B2A34\n 7        7 Dark green        #00852B\n 8        8 Reddish brown     #5F3109\n 9        9 Medium stone grey #969696\n10       10 Dark stone grey   #646464\n# ℹ 44 more rows\n\n\n\n\nClick for full brick colour codes.\n\n\nlego_colors %&gt;% \n  mutate(\n    hex = cell_spec(\n      hex, \n      \"html\", \n      background = factor(brickrID, lego_colors$brickrID, lego_colors$hex)\n    )\n  ) %&gt;% \n  select(`Colour ID` = brickrID, Colour = Color, `Hex code` = hex) %&gt;% \n  kable(format = \"html\", escape = FALSE) %&gt;%\n  kable_styling(\"striped\", full_width = TRUE)\n\n\n\n\nColour ID\nColour\nHex code\n\n\n\n\n1\nWhite\n#F4F4F4\n\n\n2\nBrick yellow\n#CCB98D\n\n\n3\nBright red\n#B40000\n\n\n4\nBright blue\n#1E5AA8\n\n\n5\nBright yellow\n#FAC80A\n\n\n6\nBlack\n#1B2A34\n\n\n7\nDark green\n#00852B\n\n\n8\nReddish brown\n#5F3109\n\n\n9\nMedium stone grey\n#969696\n\n\n10\nDark stone grey\n#646464\n\n\n11\nNougat\n#BB805A\n\n\n12\nBright green\n#58AB41\n\n\n13\nMedium blue\n#7396C8\n\n\n14\nBright orange\n#D67923\n\n\n15\nBr. yellowish green\n#A5CA18\n\n\n16\nEarth blue\n#19325A\n\n\n17\nEarth green\n#00451A\n\n\n18\nDark red\n#720012\n\n\n19\nBright purple\n#C8509B\n\n\n20\nLight purple\n#FF9ECD\n\n\n21\nMedium azur\n#68C3E2\n\n\n22\nMedium lavender\n#9A76AE\n\n\n23\nDark orange\n#91501C\n\n\n24\nBright bluish green\n#009894\n\n\n25\nBright reddish violet\n#901F76\n\n\n26\nSand blue\n#70819A\n\n\n27\nSand yellow\n#897D62\n\n\n28\nSand green\n#708E7C\n\n\n29\nFlame yellowish orange\n#FCAC00\n\n\n30\nLight royal blue\n#9DC3F7\n\n\n31\nCool yellow\n#FFEC6C\n\n\n32\nMedium lilac\n#441A91\n\n\n33\nLight nougat\n#E1BEA1\n\n\n34\nDark brown\n#352100\n\n\n35\nMedium nougat\n#AA7D55\n\n\n36\nDark azur\n#469BC3\n\n\n37\nAqua\n#D3F2EA\n\n\n38\nLavender\n#CDA4DE\n\n\n39\nSpring yellowish green\n#E2F99A\n\n\n40\nOlive green\n#8B844F\n\n\n41\nVibrant coral\n#F06D78\n\n\n42\nTransparent\n#EEEEEE\n\n\n43\nTr. red\n#B80000\n\n\n44\nTr. light blue\n#ADDDED\n\n\n45\nTr. blue\n#0085B8\n\n\n46\nTr. yellow\n#FFE622\n\n\n47\nTr. green\n#73B464\n\n\n48\nTr. fl green\n#FAF15B\n\n\n49\nTr. brown\n#BBB29E\n\n\n50\nTr. bright orange\n#E18D0A\n\n\n51\nTr. fl red orange\n#CB4E29\n\n\n52\nTr. medium violet\n#FD8ECF\n\n\n53\nTr. bright violet\n#6F7AB8\n\n\n54\nTr. bright green\n#AFD246\n\n\n\n\n\n\n\n\nSo ‘1’ is white, ‘2’ is black and so on. I think Timpe selected this set of colours to match the colours available from Lego sets.\n\nBoring, boring Arsenal\nTo actually build the model, pass the data frame to a couple of {brickr} functions.\nThe first is bricks_from_table() that converts the data frame to a list containing several elements that define the required bricks and colours.\n\n# Convert plan to list with brick types and colours\nplayer_bricks &lt;- player_plan %&gt;%\n  bricks_from_table()\n\nnames(player_bricks)  # see the element names\n\n[1] \"Img_lego\"      \"brickr_object\" \"Img_bricks\"    \"ID_bricks\"    \n[5] \"pieces\"        \"use_bricks\"   \n\n\nAs a side note, you can use display_pieces() to find out the set of pieces you’ll need to recreate the model in real life!\n\nbuild_pieces(player_bricks)\n\n\n\n\nPass the list object to the display_bricks() function to get the plan rendered into 3D. This opens a new device window and the model will be built up layer by layer. When complete, you can use your mouse to click and drag the object to look at at from all directions.\n\nbuild_bricks(player_bricks)  # opens separate window\n\n\nSo the default set builds up to make a player that has red socks with white trim, white shorts, and a red shirt with white sleeves. An Arsenal player, of course.3\n\n\nShow your support\nTo change the colour of the player’s shirt you just need to change all the bricks associated with the shirt. This could be tedious by hand, so create_brickr_player() has an argument to do exactly this. Set shirt_body_col to ‘6’ to make it bright blue, for example.\nYou can change more than the shirt colour. Here’s the current set of arguments:\n\nshirt_body_col and shirt_sleeve_col\nshorts_col\nsock_col and sock_trim_col\nboot_col\nhair_col and skin_col\n\nSo you could create a Manchester City player with the following:\n\n# Build player plan with certain colours\nman_city &lt;- create_brickr_player(\n  hair_col = 6,           # Black\n  skin_col = 34,          # Dark brown\n  boot_col = 3,           # Bright red\n  shirt_body_col = 30,    # Light royal blue\n  shirt_sleeve_col = 30,  # Light royal blue\n  shorts_col = 1,         # White\n  sock_col = 16,          # Earth blue\n  sock_trim_col = 16      # Earth blue\n)\n\n# Convert plan to list and render it\nman_city %&gt;%\n  bricks_from_table() %&gt;%\n  display_bricks()\n\n\nIn fact, this is a faithful rendering of the 2019 Premier League winner, FA Cup winner, League Cup winner, PFA Team of the Year inductee, PFA Young Player of the Year and FWA Footballer of the Year Raheem Sterling. Obviously.\nI’ve added a couple more to a GitHub Gist. Feel free to add more."
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#extra-time",
    "href": "posts/2019-05-31-brickr-soccer/index.html#extra-time",
    "title": "Make a {brickr} soccer player",
    "section": "Extra-time",
    "text": "Extra-time\nHopefully this is useful for anyone who wants to create the same {brickr} model in multiple colours. I realise that might be a niche audience.\nThe obvious next step would be to allow for features of the plan to change. For example, you could set an argument for player_height and add or remove layers from the plan to make the final model taller or shorter. Or maybe different shirt types could be specified, like horizontal_stripe = TRUE.\nPull requests always welcome!"
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#environment",
    "href": "posts/2019-05-31-brickr-soccer/index.html#environment",
    "title": "Make a {brickr} soccer player",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-01 18:53:57 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tibble_3.2.1     dplyr_1.1.2      brickr_0.3.5     kableExtra_1.3.4\n[5] knitr_1.43.1    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    compiler_4.3.1    webshot_0.5.5    \n [5] tidyselect_1.2.0  xml2_1.3.5        stringr_1.5.0     tidyr_1.3.0      \n [9] systemfonts_1.0.4 scales_1.2.1      yaml_2.3.7        fastmap_1.1.1    \n[13] ggplot2_3.4.2     R6_2.5.1          labeling_0.4.2    generics_0.1.3   \n[17] htmlwidgets_1.6.2 munsell_0.5.0     svglite_2.1.1     pillar_1.9.0     \n[21] rlang_1.1.1       utf8_1.2.3        stringi_1.7.12    xfun_0.39        \n[25] viridisLite_0.4.2 cli_3.6.1         withr_2.5.0       magrittr_2.0.3   \n[29] grid_4.3.1        digest_0.6.33     rvest_1.0.3       rstudioapi_0.15.0\n[33] lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21     glue_1.6.2       \n[37] farver_2.1.1      fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[41] purrr_1.0.1       httr_1.4.6        tools_4.3.1       pkgconfig_2.0.3  \n[45] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2019-05-31-brickr-soccer/index.html#footnotes",
    "href": "posts/2019-05-31-brickr-soccer/index.html#footnotes",
    "title": "Make a {brickr} soccer player",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot an official product (yet).↩︎\nThe package was on CRAN when this post was originally written, but it was later removed.↩︎\nWhy Arsenal? Mostly to demonstrate that sleeves can be a different colour to the shirt body, but also because they just got binned 4-1 by Chelsea in the Europa League final and I feel sorry for them.↩︎"
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html",
    "href": "posts/2019-05-10-swirlify/index.html",
    "title": "Teach a person to {swirl}",
    "section": "",
    "text": "A metaphor for all the {swirl} courses you’ll make (via Giphy)"
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html#tldr",
    "href": "posts/2019-05-10-swirlify/index.html#tldr",
    "title": "Teach a person to {swirl}",
    "section": "tl;dr",
    "text": "tl;dr\nTeach people to teach other people. That seems an efficient way to maximise impact.\n\n{swirl} lets people learn R from within R\n{swirlify} is a package to help write Swirl courses\nThis post explains how to start a Swirl course with Swirlify\nFor example, I’ve begun Tidyswirl for teaching tidyverse packages\n\n\n Note\nI never got around to fully developing Tidyswirl and so I archived the GitHub repo. You should take a look at swirl-tidy by Seo-young Silvia Kim instead."
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html#swirl",
    "href": "posts/2019-05-10-swirlify/index.html#swirl",
    "title": "Teach a person to {swirl}",
    "section": "Swirl",
    "text": "Swirl\nSwirl is a platform that:\n\nteaches you R programming and data science interactively, at your own pace, and right in the R console!\n\nLearning with Swirl is active and your understanding is checked throughout. You can move at your own pace and download additional courses to learn about new things. And it’s free.\nInstall and load Swirl to begin and then follow the instructions printed in the console.\n\ninstall.packages(\"swirl\")\nlibrary(swirl)\nswirl()\n\nHere’s what the first few lines of interaction with Swirl look like.\n\nYou’ll be given a list of courses to install, but you can also download them from elsewhere. This post is about how you can quickly create and distribute such a course."
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html#swirlify",
    "href": "posts/2019-05-10-swirlify/index.html#swirlify",
    "title": "Teach a person to {swirl}",
    "section": "Swirlify",
    "text": "Swirlify\nSean Kross and Nick Carchedi have created the {swirlify} package to make course creation easy. This post covers a simple workflow to get you started, but full Swirlify guidance is available.\n\nGet up and running\nCreate a new lesson folder (‘Lesson 1’), which will be autopopulated with template files for your lesson. This will also create a new parent course folder (‘New Course’) if it doesn’t already exist.\n\nlibrary(swirl)  # install.packages(\"swirl\")\nlibrary(swirlify)  # install.packages(\"swirlify\")\nnew_lesson(course_name = \"New Course\", lesson_name = \"Lesson 1\")\n\nThe following folder structure is generated:\nWorking directory/\n└── New_Course/\n    └── Lesson_1/\n        ├── customTests.R\n        ├── dependson.txt\n        ├── initLesson.R\n        └── lesson.yaml\nThe lesson.yaml file is the most important one. It’s basically a text file where each question is stored as text. Users advance through each of these questions when they run the lesson.\nThe lesson file can be edited directly, but we’ll focus on the built-in Swirlify Shiny app for simplicity:\n\nswirlify(course_name = \"New Course\", lesson_name = \"Lesson 1\")\n\nThe app will open the named lesson from the named course in a new browser window. On the left is where you create new questions. On the right you can see the lesson.yaml file itself.\n\nNote the ‘Help’ tab, which tells you about the types of questions you can make, or you can see the Swirlify guidance). Basically the question types are:\n\n‘message’ for informational text (not for questions per se)\n‘command’ for answers that require simple R expressions as answers\n‘numerical’ and ‘text’ for answers that are numbers or words\n‘multiple choice’ for multiple choice (as in the figure above)\n‘figure’ and ‘video’ for referring to media (‘video’ can take a user to any URL)\n‘script’ for longer R expressions that requires you to write custom answer tests (this is more advanced)\n\nTo build a question:\n\nChoose a question type from the dropdown menu on the left\nFill in the text boxes (note that the answer tests box is completed for you if you type into the correct answer box and then press the ‘Make Answer Test from Correct Answer’ button)\nClick the ‘Add Question’ button see the question added to the file (on the right hand side)\nClick ‘Save Lesson’\nRun test_lesson() to look for errors\nClick ‘Demo Lesson’ to try it out\n\n\nContinue adding questions until the lesson is complete. Then:\n\nRun add_to_manifest() to add the lesson to the MANIFEST file (it’ll be created in the course directory if it doesn’t already exist). Lessons in here are recognised as part of the course in the declared order.\nUse new_lesson() to create a new one, remembering to change the lesson_name argument and also add this lesson to the MANIFEST as well.\n\nYou should end up with a folder structure like this:\nWorking directory/\n└── New_Course/\n    ├── Lesson_1/\n    |   ├── customTests.R\n    |   ├── dependson.txt\n    |   ├── initLesson.R\n    |   └── lesson.yaml\n    ├─ Lesson_2/\n    |   ├── customTests.R\n    |   ├── dependson.txt\n    |   ├── initLesson.R\n    |   └── lesson.yaml\n    └─ MANIFEST\nWhen your lessons are completed, you’re ready to share your course. Jump now to the share your course section or first learn some extra knowledge about lesson file structure, correct answers or lesson startup below.\n\n\nExtra knowledge\nClearly the process of course building is more nuanced than outlined above, but you can learn more from the documentation on the Swirlify site and reference manual. In particular, See the course structure and writing lessons pages of the Swirlify guidance.\nI’ll touch on three things here: lesson file structure, correct answers and lesson start-up.\n\nLesson file structure\nThe lesson file is written in YAML, which is basically a special form of plain text. Questions appear as separate blocks of text that start with a hyphen and a question type (class) declaration, followed by further arguments on new indented lines.\nThe first block is always Class: meta and provides basic information about the file, like your name and the lesson name. Another simple one is Class: text to which you supply only one more argument, the Output, which is text to display to the user.\n\n- Class: text\n  Output: Did I mention chocolate hobnobs are great?\n\nThere are actually three ways to add questions:\n\nIn the Shiny app, as outlined earlier in this post.\nBy using the wq_*() family of functions to add questions to the active lesson – wq_message(output = \"Text here\") adds informative text, for example.\nBy writing directly into the YAML file.\n\nThere’s more on questions classes and how to write them in the Swirlify guidance.\n\n\nCorrect answers\nHow are answers encoded and checked in lesson.yaml? Consider the YAML for this question:\n\n- Class: cmd_question\n  Output: Use mean() to calculate the mean of the numbers 1 to 5.\n  CorrectAnswer: mean(1:5)\n  AnswerTests: omnitest(correctExpr='mean(1:5'))\n  Hint: Use the form x:y to provide numbers to mean().\n\nSo CorrectAnswer is where you provide the correct answer (!). This line will be run if the user chooses to skip() the question. AnswerTests is, however, what the user’s input will actually be evaluated against. It uses the omnitest function to compare the correct expression (correctExpr) to the user’s answer.\nBut often there’s more than one way to answer. The any_of_exprs() function should be used in this case.\n\n- Class: cmd_question\n  Output: Use mean() to calculate the mean of the numbers 1 to 5.\n  CorrectAnswer: mean(1:5)\n  AnswerTests: any_of_exprs('mean(1:5)', 'mean(c(1, 2, 3, 4, 5))')\n  Hint: You can use the form x:y or c(x, y) to provide numbers to mean().\n\nThere’s more on answer testing in the Swirlify guidance, including how to write custom answer tests.\n\n\nLesson start-up\nAnything in the initLesson.R file will be run when the lesson is loaded. You can create objects and refer to them in your questions. For example, you could add a data frame:\n\nbiscuits &lt;- data.frame(\n  name = c(\"Chocolate hobnob\", \"Digestive\", \"Custard cream\"),\n  rating = c(10, 5, 7) \n)\n\nYou could then ask in lesson.yaml something like:\n\n- Class: cmd_question\n  Output: Use index notation to subset for biscuits rated over 5.\n  CorrectAnswer: biscuits[biscuits$rating &gt; 5, ]\n  AnswerTests: omnitest(correctExpr='biscuits[, biscuits$rating &gt; 5]')\n  Hint: Remember the indexing format dataframe[rows, columns].\n\nThe data frame was loaded on start-up, so the user can interact with it to answer the question.\nYou can also add data sets to the lesson folder and read them into the user’s environment via the initLesson.R file. See the Swirlify guidance on including data for more information.\n\n\n\nShare your course\nCongratulations. You’re ready to share your course.\nThere are several ways to do this. It’s easiest for learners to use Swirl’s swirl::install_course_*() functions to install courses from:\n\na GitHub repo\na zip file stored on DropBox, Google Drive, or some URL\na course folder—zipped or not—-downloaded locally on their machine\n\nYou can also compress your course to a single .swc file with compress_course() and raise a pull request for it to be hosted on the Swirl Course Network. It can be downloaded from there with install_course().\nSwirl is strengthened by having a greater number and range of courses."
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html#plea",
    "href": "posts/2019-05-10-swirlify/index.html#plea",
    "title": "Teach a person to {swirl}",
    "section": "Plea",
    "text": "Plea\nThe R community is large and friendly. Swirl helps people learn. It would be great to see more courses being made. Consider making one to teach your colleagues about common R tasks in your department, for example."
  },
  {
    "objectID": "posts/2019-05-10-swirlify/index.html#environment",
    "href": "posts/2019-05-10-swirlify/index.html#environment",
    "title": "Teach a person to {swirl}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-01 19:49:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html",
    "href": "posts/2020-12-30-coloratio/index.html",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "",
    "text": "This blog’s original theme: insufficient contrast!"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#tldr",
    "href": "posts/2020-12-30-coloratio/index.html#tldr",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a small R package called {coloratio} to evaluate colour-contrast ratios for accessibility. Then I found out that {savonliquide} already exists to do this."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#accessible-charts",
    "href": "posts/2020-12-30-coloratio/index.html#accessible-charts",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Accessible charts",
    "text": "Accessible charts\nThe UK government’s website, GOV.UK, was developed with user needs and accessibility in mind. I’ve been using {ggplot2} to recreate the simple, accessible chart styles suggested for use on GOV.UK by the Government Statistical Service.\nBut I wondered: is it possible to programmatically select a high-contrast text colour to overlay the fill colours of a {ggplot2} barplot? You would want black text over white and vice versa, for example.\nWhat is ‘high contrast’ anyway? GOV.UK’s Design System refers to W3C’s contrast guidance from WCAG 2.1, which suggests a ratio of 4.5:1 for regular text on a block-coloured background.\nIt isn’t a big deal to program this ‘manually’, but that’s not fun."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#ratio-calculation",
    "href": "posts/2020-12-30-coloratio/index.html#ratio-calculation",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Ratio calculation",
    "text": "Ratio calculation\n\nIs the contrast accessible?\nHow about a small package with some functions to derive colour contrast ratios? Introducing {coloratio}.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/coloratio\")\n\nPass two colours to cr_get_ratio() as hex values or named colours—see colors()—and it performs the necessary calculations to derive relative luminance and return a colour contrast ratio.\n\nlibrary(coloratio)  # attach package\n\ncr_get_ratio(\n  \"papayawhip\", \"#000000\",  # colours to compare\n  view = TRUE  # optional demo of colours \n)\n\n\n\n\n[1] 18.55942\n\n\nThis contrast value is above the 4.5 threshold, so we’re good to go. You’ll get a warning if the contrast is insufficient.\n\ncr_get_ratio(\"olivedrab\", \"olivedrab2\")\n\nWarning in cr_get_ratio(\"olivedrab\", \"olivedrab2\"): Aim for a value of 4.5 or higher.\n\n\n[1] 2.755693\n\n\nSurprise: as stunning as an all-olivedrab palette might be, these colours aren’t distinct enough to be accessible.\n\n\nBlack or white?\ncr_get_ratio() in turn powers the function cr_choose_bw(), which returns black or white depending on the greatest contrast with a supplied background colour.\n\ncr_choose_bw(\"snow\")\n\n[1] \"black\"\n\ncr_choose_bw(\"saddlebrown\")\n\n[1] \"white\"\n\n\nTo demonstrate better, let’s create a grouped barplot with lighter (lemonchiffon3) and darker (hotpink4) fill colours, then use cr_choose_bw() to choose black or white for the overlaying text.\n\nlibrary(tidyverse)  # for data manipulation\n\n# Example data\nd &lt;- data.frame(\n  x_val = c(\"A\", \"A\", \"B\", \"B\"),\n  y_val = c(3, 6, 4, 10),\n  z_val = c(\"a\", \"b\", \"a\", \"b\")\n) %&gt;% \n  mutate(  # add colour columns\n    fill_col = rep(c(\"hotpink4\", \"lemonchiffon3\"), 2),\n    text_col = map_chr(fill_col, cr_choose_bw)\n  )\n\nd  # preview\n\n  x_val y_val z_val      fill_col text_col\n1     A     3     a      hotpink4    white\n2     A     6     b lemonchiffon3    black\n3     B     4     a      hotpink4    white\n4     B    10     b lemonchiffon3    black\n\n\nNo surprise: white was returned for the darker fill and black for the lighter fill.\nWe can now refer to this information in the colour argument of geom_text().\n\nggplot(d, aes(x_val, y_val, fill = z_val)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_manual(values = d$fill_col) +    # fill colour\n  geom_text(aes(y = 0.5, label = y_val), \n            position = position_dodge(0.9), \n            size = 5, colour = d$text_col) +  # text colour \n  coord_flip() + \n  theme_minimal(base_size = 16) +  # clean up the theme\n  theme(axis.text.x = element_blank(), axis.title = element_blank(), \n        legend.title = element_blank(), panel.grid = element_blank())\n\n\n\n\nAs desired: black on the lighter fill; white on the darker fill. The default would be black text, which would provide insufficient contrast for darker fills.\n\n\nAside: cr_choose_bw() in geom_text()?\nOriginally I wanted geom_text() to choose text colours on the fly, rather than adding them to the input data. This roundabout solution—which outputs a similar plot to the one above—requires you to build the plot object, then interrogate it with ggplot_build() to identify the bar-fill colours.\n\n# Build simple grouped barplot again\np &lt;- ggplot(d, aes(x_val, y_val, fill = z_val)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_manual(values = c(\"hotpink4\", \"lemonchiffon3\")) +\n  coord_flip()\n\n# Extract the p-object fills and choose text overlay colour\np + geom_text(\n  aes(y = 0.5, label = y_val), position = position_dodge(0.9), size = 5,\n  colour = map_chr(  # make text colour dependent on bar colour\n    ggplot_build(p)[[1]][[1]]$fill,  # access p-object fills\n    coloratio::cr_choose_bw   # choose black/white text based on fill\n  )\n)\n\nI put this to the RStudio Community with no answer to date. Let me know if you have any ideas."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#a-soapy-slip-up",
    "href": "posts/2020-12-30-coloratio/index.html#a-soapy-slip-up",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "A soapy slip-up",
    "text": "A soapy slip-up\nHaving addressed my need, I was suspicious. Surely this has been done in R before?\nWhoops. {savonliquide} by Ihaddaden M. EL Fodil can query the WebAIM contrast checker API to get the contrast ratio for two colours. And it’s on CRAN.\n\ninstall.packages(\"savonliquide\")\n\nMaybe I missed it because of the name, which translates to ‘liquid soap’?\nAnyway, like coloratio::cr_get_ratio(), you can pass two hex values or named colours to {savonliquide}’s check_contrast() function.\n\nsavonliquide::check_contrast(\"blanchedalmond\", \"bisque2\")\n\n\n* The Contrast Ratio is 1.04\n\n* The result for the AA check is : FAIL\n\n* The result for the AALarge check is : FAIL\n\n* The result for the AAA check is : FAIL\n\n* The result for the AAALarge check is : FAIL\n\n\nThe output is richer than coloratio::cr_get_ratio(). You can see here that the supplied colours fail additional accessibility checks from WCAG 2.1 that involve large text and more stringent contrast thresholds.\nHandily, there’s also the savonliquide::check_contrast_raw() variant that returns a list with each result as an element."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#acceptance",
    "href": "posts/2020-12-30-coloratio/index.html#acceptance",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Acceptance",
    "text": "Acceptance\nSo… should you wash your hands of {coloratio}?1 Well, it fills the micro-niche of an R package that doesn’t require an internet connection to fetch colour contrast ratios. But it’s probably never going to go on CRAN, so you should use {savonliquide}.\nI certainly learnt a lesson about due diligence during package development. Especially because I also discovered recently that I had also somehow managed to reinvent the {badger} package with my own {badgr} package.2 Whoops again.\nAt worst, I got to learn more about accessibility, practice some package building, and solve my initial problem (kinda).\nI also got to admire the creativity of the names in the named-colour set. ‘Papayawhip’ sounds really appealing. Or perhaps painful. Just like package development.3"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#environment",
    "href": "posts/2020-12-30-coloratio/index.html#environment",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 17:58:44 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2      forcats_1.0.0        stringr_1.5.0       \n [4] dplyr_1.1.2          purrr_1.0.1          readr_2.1.4         \n [7] tidyr_1.3.0          tibble_3.2.1         ggplot2_3.4.2       \n[10] tidyverse_2.0.0      coloratio_0.0.0.9004\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3       jsonlite_1.8.7     crayon_1.5.2       compiler_4.3.1    \n [5] tidyselect_1.2.0   scales_1.2.1       yaml_2.3.7         fastmap_1.1.1     \n [9] R6_2.5.1           labeling_0.4.2     generics_0.1.3     curl_5.0.1        \n[13] knitr_1.43.1       htmlwidgets_1.6.2  munsell_0.5.0      pillar_1.9.0      \n[17] tzdb_0.4.0         rlang_1.1.1        utf8_1.2.3         savonliquide_0.2.0\n[21] stringi_1.7.12     xfun_0.39          timechange_0.2.0   cli_3.6.1         \n[25] withr_2.5.0        magrittr_2.0.3     digest_0.6.31      grid_4.3.1        \n[29] rstudioapi_0.15.0  hms_1.1.3          lifecycle_1.0.3    vctrs_0.6.3       \n[33] evaluate_0.21      glue_1.6.2         farver_2.1.1       fansi_1.0.4       \n[37] colorspace_2.1-0   httr_1.4.6         rmarkdown_2.23     tools_4.3.1       \n[41] pkgconfig_2.0.3    htmltools_0.5.5"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#footnotes",
    "href": "posts/2020-12-30-coloratio/index.html#footnotes",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI assure you this is an excellent savon liquide pun.↩︎\n{badger} has functions to generate a bunch of badges you’re likely to want. {badgr} focuses only on custom badges and has some extra options relative to badger::badge_custom(), like the ability to add an icon. But wow, how did I miss this?↩︎\n#deep↩︎"
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html",
    "href": "posts/2019-10-27-git-github/index.html",
    "title": "Git going: Git and GitHub",
    "section": "",
    "text": "Git is software on your computer that acts as a brain to store the version history of your files. Forget the discombobulation of file names like weasel-facts_FINAL.txt, weasel-facts_FINAL_comments.txt, etc, etc. GitHub is a website and cloud service for storing your version history remotely and for making collaboration easier."
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#tldr",
    "href": "posts/2019-10-27-git-github/index.html#tldr",
    "title": "Git going: Git and GitHub",
    "section": "",
    "text": "Git is software on your computer that acts as a brain to store the version history of your files. Forget the discombobulation of file names like weasel-facts_FINAL.txt, weasel-facts_FINAL_comments.txt, etc, etc. GitHub is a website and cloud service for storing your version history remotely and for making collaboration easier."
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#summary",
    "href": "posts/2019-10-27-git-github/index.html#summary",
    "title": "Git going: Git and GitHub",
    "section": "Summary",
    "text": "Summary\nThis post is a basic and non-comprehensive introduction to Git and GitHub, with a focus on Mac users who are starting a project and working alone. You may want to read my preparatory post on basic use of the command line to interact with your computer.\nThe image below provides an overview of the relationship between Git and GitHub:\n\nyou have file.txt under version control with Git on your computer (it’s ‘local’)\nGit stores all the versions in a special hidden .git/ folder\nyou can send (‘push’) this version history to a folder (‘repository’) on GitHub, a cloud-based version-history-storage and exploration service\nGitHub is not on your machine, it’s out in the world (it’s ‘remote’)\nyou can easily share the files with the rest of the world and work collaboratively from there\n\n\n\n\nA simple overview of the relationship between your files, Git and GitHub\n\n\nThe next diagram summarises a basic Git/GitHub workflow, which breaks into the following steps:\n\nUse git status to check what’s changed\nUse git add to stage a file\nUse git commit to confirm the change and write an explanatory message\nUse git push to send the new version information to GitHub\n\n\n\n\nA simple overview of the steps for recording versions and sending to GitHub\n\n\nAlso here’s a quick reference for some of the commonly-used Git commands used in this post:\n\n\n\n\n\n\n\nCommand\nShort explanation\n\n\n\n\ngit init\nPut a folder under version control with Git\n\n\ngit status\nShow which files are new or changed\n\n\ngit add &lt;file&gt;\nConfirm the changes to be committed\n\n\ngit commit -m \"&lt;message&gt;\"\nCommit the changes with an explanation\n\n\ngit push\nSend your commits to GitHub\n\n\ngit clone\nCopy the repo from GitHub to your computer"
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#version-control",
    "href": "posts/2019-10-27-git-github/index.html#version-control",
    "title": "Git going: Git and GitHub",
    "section": "Version control",
    "text": "Version control\nIt’s good to store intermediate versions of your files. The process of ‘version controlling’ means you can revert to prior states and prevents the confusion of having folders filled with things like file_FINAL.txt, file_comments2.txt and file_comments_FINAL.txt. Version control can be achieved in a number of ways, but one popular approach is to use Git software and the GitHub website.\n\nTools\n\nGit is an open-source version control system that tracks file changes on your computer, records why they were made and lets you revert to a past state if something goes wrong. Alternatives include Mercurial and Apache Subversion.\n\nGitHub is a Microsoft-owned website where you can store the Git history of your files remotely on the web. It acts as a place to inspect your version history in the browser; lets other people see your code in the open, use it themselves and collaborate with you; lets you record issues and to-do items; and much, much more. Alternative products include GitLab and BitBucket.\n\n\nThis post\nThe goal of this post is to put a new project folder under version control with Git and then upload the version history to GitHub. I assume you’re a beginner and are, for now, working alone on a project.1\nWe’ll be using the bash language at the command line to do all of this. In this post, lines should be typed into the command line when the example starts with a $ (you don’t need to type the dollar symbol yourself).\nThe command line is the place where you write instructions directly to your computer and you can access it via software like ‘Terminal’ on a Mac. You may want to see my earlier post for how to get basic stuff done at the command line before you continue.\nIt’s okay if you aren’t comfortable the command line. The bottom line is to get your work under some form of version control. You could always use GitHub’s drag and drop interface without needing to use the command line at all. There are guides available for using GitHub without using the command line."
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#stepbystep",
    "href": "posts/2019-10-27-git-github/index.html#stepbystep",
    "title": "Git going: Git and GitHub",
    "section": "Step-by-step",
    "text": "Step-by-step\nLet’s break down the steps required to:\n\nSet up Git and GitHub (do this once)\nPut a project folder under version control with Git (once per project)\nSave a version of your work and record it on GitHub (rinse and repeat during your project’s development)\n\nI’ve written a section for each of these things. Click a link to jump to that section.\n\nOne-time tasks:\n\nInstall Git\nCreate a GitHub account\n\nProject set-up:\n\nCreate your project folder\nInitiate Git\nCreate a .gitignore file\nCreate a remote GitHub repository\n\nA Git/GitHub workflow:\n\nWork on your files\nCheck file status\nAdd changes\nCommit changes\nAdd and edit files (repeat as necessary)\nPush changes to GitHub\nClone the repo to your machine\n\n\n\n1. One-time tasks\nYou need to install Git on each computer you’ll be working from (feasibly only one computer), but only need to sign up once for GitHub.\n\nInstall Git\nGit is basically a bunch of functions you can use via the command line, with each command preceded with the word git.\nYou can check to see if Git is installed on your machine by asking for its version number from the command line:\n\n$ git --version\n\ngit version 2.20.1 (Apple Git-117)\nThis response shows that I already have Git installed. If the git command isn’t recognised then you will need to download Git and install it.\nOnce installed, Git needs to know who you are so that file changes can be ascribed to you. Introduce yourself by supplying your name and email address:\n\n$ git config --global user.name 'Your Name'\n$ git config --global user.email 'youremail@address.com'\n\nThese details are written to a special configuration file. You can print its contents to check it’s worked:\n\n$ git config --global --list\n\nuser.name=Your Name\nuser.email=youremail@address.com\n\n\nCreate a GitHub account\nGitHub is free to use but you need an account. Go to the GitHub website and click ‘Sign-up for GitHub’. You’ll need to provide a username, email address and password.\n\nWhen prompted for a subscription level, choose ‘free subscription’. You’ll be able to do everything you need to do with this type of account; a premium account is more suitable for teams.\nYou’ll be sent an automated email to verify your email address. Click the button in the email to confirm, then check that your GitHub profile page is viewable at github.com/yourusername.\n\n\n\n2. Project set-up\nThe following subsections are about creating a project folder and putting it under version control by activating Git.\n\nCreate your project folder\nIt’s good practice for each project to exist in its own repository (folder), so all the code, data, tests and documentation are in the same place. Let’s create a project folder now.\nUsing the command line, navigate with cd to where we want the folder to be, create it with mkdir and then navigate into it:\n\n$ cd ~/Documents\n$ mkdir demo-project\n$ cd demo-project\n$ pwd\n\n/Users/matt/Documents/demo-project\nYou could also create a new folder by pointing and clicking; just make sure you navigate to the folder at the command line with cd.\n\n\nInitiate Git\nSo we have our empty project folder, but it’s not yet under version control. How can we make Git aware of this folder and start tracking changes? We can initiate Git there:\n\n$ git init\n\nInitialized empty Git repository in /Users/matt/Documents/demo-project/.git\nWhat did this do? If you look inside the folder through your file explorer you’ll see nothing new. But look what happens when you ask at the command line to list (ls) all (the -A flag) the files and folders (marked by a / with the -p flag):\n\n$ ls -A -p\n\n.git/\nSo the project folder actually contains a folder called .git. This is where the version information will be stored, among other things. Why can’t you see it from your file explorer? Because it starts with a period, which marks it as a hidden file not to be shown unless specifically asked for.\nNote that we haven’t yet recorded any versions; we’ve just added the relevant file structure for Git to operate in our project repository.\n\n\nCreate a .gitignore file\nThere are files that you may not want to put under version control. This might include sensitive files, large data sets or language-specific artefacts.\nYou can list such files in a special .gitignore file that tells Git not to worry about recording changes. Note that this file starts with a period, so it’s a hidden file like the .git file in the last section.\nTo create a gitignore file, navigate to your project file and use touch to create it and then open it with your computer’s default text editor (you can also edit it from the command line itself).\n\n$ touch .gitignore\n$ open .gitignore\n\nNow to add things to the gitignore file. You could start by copying from a template, like the one for R. As an example, the first file in that template is .Rhistory – a log of all the commands you’ve typed – which you probably don’t need to track.\nYou could add things to your gitignore like sensitive-data.csv to ignore a specific data set, or something like *.csv (meaning any file name that ends with .csv) to ignore all files of a particular type. Mac users will also want to add .DS_Store, which is a kind of Mac-specific metadata file.\n\n\nCreate a remote GitHub repository\nEverything we’ve done so far is on your machine; it’s all ‘local’. All the files we add and change will be local until we choose to send a copy of the information to GitHub.\nNow we’re going to create a repository (folder) for the local information to be stored on GitHub. This location is ‘remote’. We’re doing this now as part of the project set-up steps, but you needn’t necessarily do it until later when you finally want to upload your version control history to GitHub.\nTo begin, make sure you’re logged into GitHub and click the ‘plus’ symbol in the upper right corner and then ‘New repository’. You can then input a repository name (i.e. the name of the project folder you created) and a short description.\n\nYou can choose to keep the project private, but far better for it to be public. You can also start this remote repository with a ‘readme’ file, ‘gitignore’ and a license if you want, but in this example we’re going to do these steps locally on our own machine.\nClick the green ‘create repository’ button to continue, which looks like this:\n\nThis sets-up the remote repository on GitHub, but it’s empty right now. We haven’t sent any information yet. This will be the final step of the next section.\nFor now, let’s associate our local repository with the remote repository:\n\ngit remote add origin https://github.com/matt-dray/demo-project.git\n\nRemember to change the file path to match your the URL to your project.\n\n\n\n3. A Git/GitHub workflow\nSo far nothing has been put under version control; we’ve just been doing some set-up steps. Now we’ll create a file structure and start using Git and GitHub.\n\nWork on your files\nStart adding project files to your folder. Let’s say you’ve added a data set in raw-data/data.csv; an analysis.R script to analyse it; and a very important README.md file to to explain what your project is about.\nLet’s say the CSV file contains these data:\nnumber,position,name,nationality\n1,\"GK\",\"Nicky Weaver\",\"England\"\n9,\"FW\",\"Paul Dickov\",\"Scotland\"\n10,\"FW\",\"Shaun Goater\",\"Bermuda\"\n22,\"DF\",\"Richard Dunne\",\"Ireland\"\n29,\"MF\",\"Shaun Wright-Phillips\",\"England\"\n\n\n\nRichard Dunne (Wikimedia Commons, edited).\n\n\nAnd the R script looks like this:\n\nmancity &lt;- read.csv(\"raw-data/data.csv\")  # read data\nmancity[mancity$position == \"FW\", ]  # filter for forwards\n\nAnd the readme file, written here using Markdown, says:\n# demo-project\n\nThis is a demonstration of how to use Git and GitHub. It accompanies a blog post on [rostrum.blog](https://rostrum.blog).\nSo the file tree ends up looking like this:\ndemo-project/\n├── analysis.R\n├── .git\n├── .gitignore\n├── raw-data/\n│   └── data.csv\n└── README.md\nGreat, now let’s capture this version with Git.\n\n\nCheck file status\nRun git status to see the files that have been created or modified.\n\n$ git status\n\n\nOn branch master\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    .gitignore\n    README.md\n    analysis.R\n    raw-data/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\nAll our new files and folders are listed under ‘Untracked files’. By ‘untracked’ Git is telling us that these are new files that haven aren’t yet under version control. All the files will be new the first time you run this process, of course.\nNote that any files that are in your .gitignore will not appear here, since they’ve been ignored.\nHelpfully, the output of git status also tells us what we need to do next: we need to use git add.\n\n\nAdd changes\nNow you need to earmark the files whose changes you want to record. This process is called staging. The stage is a safe place where you can add files to be captured; they’re not yet confirmed. This is a preventative measure so you don’t accidentally record anything you didn’t mean to.\nAs mentioned in the output of git status, we can type git add &lt;file&gt; to do this. We have three files to add, so we can name them all:\n\n$ git add .gitignore README.md analysis.R raw-data/\n\nYou could also use git add ., where the period means ‘all the files’. Be careful if you use this – you don’t want to end up capturing things you didn’t mean to.\nYou won’t get any output, so how do we know this worked? Check the status again.\n\n$ git status\n\n\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n    new file:   .gitignore\n    new file:   README.md\n    new file:   analysis.R\n    new file:   raw-data/data.csv\n\nThese files are now staged and marked as ‘changes to be committed’.\nIf you made a mistake at this point and want to remove files from the stage, you can type git rm --cached &lt;file&gt;. This line is helpfully printed in the output from git status.\n\n\nCommit changes\nWhen you’re happy with the files that have been staged, you can now commit them. This confirms that you want Git to record the changes made to these files.\nYou commit the staged changes using git commit. It’s good practice to leave a message explaining what changes were made and why. You can leave a simple message using the -m flag of git commit2. The message should be short (typically less than 50 characters) but informative (not just ‘changed stuff’). It’s convention to start with a verb, like ‘add this thing’ or ‘fix that thing’.\n\n$ git commit -m \"Add readme, gitignore, script and data\"\n\n\n[master (root-commit) 133733b] Add readme, gitignore, script and data\n 4 files changed, 50 insertions(+)\n create mode 100644 .gitignore\n create mode 100644 README.md\n create mode 100644 analysis.R\n create mode 100644 raw-data/data.csv\n\nThe output confirms the files that have been added. It also tells us how many insertions (characters added) and deletions (characters removed) there were. The create mode lines reference that a file has started to be tracked.\nHow often should you make commits? It’s up to you, but it’s probably a good idea to do it when you’ve completed a section of code that does something useful and that you might want to revert to if there’s a problem later.\nJust to prove that we’re up to date, we can check the status of the repository once more.\n\n$ git status\n\n\nOn branch master\nnothing to commit, working tree clean\n\nCool. Everything’s up to date.\n\n\nAdd and edit files (repeat as necessary)\nContinue to create and edit files, adding and committing them when necessary. For example, let’s add a row to the data set:\n22,\"FWD\",\"George Weah\",\"Liberia\"\n\n\n\nPresident of Liberia, George Weah (Wikimedia Commons, edited).\n\n\nAnd add this line to the bottom of our README file:\nThe data are a selection of [Manchester City Football Club players from the 2000 to 2001 Premier League season](https://en.wikipedia.org/wiki/2000%E2%80%9301_Manchester_City_F.C._season).\nGiven that we’ve changed our files and want to store this in our Git version history, let’s go through the status-add-commit workflow again. First, let’s check the status of the files:\n\n$ git status\n\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   README.md\n    modified:   raw-data/data.csv\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nSo the altered files are now marked as ‘modified’. Let’s add them both; I’ll use the period shortcut to add both without typing their full names:\n\n$ git add .\n\nOne more look at the status to check it’s done what we wanted:\n\n$ git status\n\n\nOn branch master\nChanges to be committed:\n  (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n\n    modified:   README.md\n    modified:   raw-data/data.csv\n\nAnd now to commit with a message:\n\ngit commit -m \"Add King George to the data, update readme with Wikipedia link\"\n\n\n[master 1359d3f] Add King George to the data, update readme with Wikipedia link\n 2 files changed, 3 insertions(+)\n\nAnd lets check we’re up to date:\n\n$ git status\n\n\nOn branch master\nnothing to commit, working tree clean\n\nBoom. We’re up to date.\nYou can rinse and repeat this edit-status-add-commit to store versions of the files in your repository.\n\n\nPush changes to GitHub\nGreat, you’ve used Git to version control your files. But the commits are stored locally on your machine. How do you send them to GitHub so you have a remote copy of your version history?\nRemember when we set up the GitHub repository for this project earlier on? Now we’re ready to send the version history from our local project folder to this remote repository.\nYou do this by ‘pushing’ the local information to GitHub.\n\ngit push -u origin master\n\n\nCounting objects: 12, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (10/10), done.\nWriting objects: 100% (12/12), 1.52 KiB | 388.00 KiB/s, done.\nTotal 12 (delta 3), reused 0 (delta 0)\nremote: Resolving deltas: 100% (3/3), done.\nTo https://github.com/matt-dray/demo-project.git\n * [new branch]      master -&gt; master\nBranch 'master' set up to track remote branch 'master' from 'origin'.\n\nThe output confirms that the push was successful.\nIf you go now to your repository on GitHub, you’ll see that your files have been added. For example, I would navigate to https://github.com/matt-dray/demo-project (this is a real link to the project used in this post!).\n\nYou can see the files at the top and our README.md has helpfully been rendered by GitHub so that people can see what the repository is all about.\nThere’s lots of stuff you can do from here. For example, click ‘Commits’ above and to the left of the list of your files. You can see each of the commits we made earlier.\n\nYou can do things like explore the repository at any given commit (click the &lt;&gt; button) or if you click the alphanumeric code (a unique code given to each commit) you can see the changes that were made with that commit. In this split view, the left panel is the state of each file before the commit, with changes on the right. Additions are green and start with a +; deletions are red with a — symbol.\n\nSo now you the version history is available remotely and you can easily navigate the changes and explore the various snapshots of your work.\nNow you can continue to work locally on your files and push the changes to GitHub when you’re ready.\n\n\nClone the repo to your machine\nLet’s say you’re on a different machine or a collaborator wants a copy of the GitHub repo. How do you get the files from GitHub onto the new machine?\nYou can ‘clone’ the repo.\nTo do this, we need to tell Git where to clone from. One method is via HTTPS using the repo’s URL:\n\nNavigate to the repo\nClick the ‘clone or download’ button and copy the path\nUse cd on the command line to navigate to where you want to clone the repo\nRun git clone &lt;path&gt;\n\n\n\n\nClick the green button, copy the path\n\n\nYou’ll see something like this when you run git clone from the command line:\n\ngit clone https://github.com/matt-dray/demo-project.git\n\n\nCloning into 'demo-project'...\nremote: Enumerating objects: 15, done.\nremote: Counting objects: 100% (15/15), done.\nremote: Compressing objects: 100% (10/10), done.\nremote: Total 15 (delta 5), reused 10 (delta 3), pack-reused 0\nUnpacking objects: 100% (15/15), done.\n\nThe output shows the progress of the download. Congratulations, the repo has been copied from GitHub to your machine!"
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#what-next",
    "href": "posts/2019-10-27-git-github/index.html#what-next",
    "title": "Git going: Git and GitHub",
    "section": "What next?",
    "text": "What next?\nThis post has been for beginners to get to grips with the fundamental Git commands init, status, add, commit, push and clone.\nGit is extremely powerful and does so much more that wasn’t covered here.\nA sensible next step would be to learn more about ‘branching’ in particular. This involves working on an isolated copy of the repo so you can work safely on new features without fear of ruining the main, or ‘master’ branch of work. If your development is successful, you can merge it back into the ‘master’ branch with a ‘pull request’.\nYou will also want to think about working collaboratively on a project. GitHub has lots of facilities for encouraging team work, like issue tracking and the ability to comment on changes. If you’re working on a new feature in a branch you can request a review from your colleagues to merge your work into the main ‘master’ branch; this is called a ‘pull request’.\nI recommend checking out some of the great materials that are alreay out there. See the next section for some starters."
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#other-resources",
    "href": "posts/2019-10-27-git-github/index.html#other-resources",
    "title": "Git going: Git and GitHub",
    "section": "Other resources",
    "text": "Other resources\nThe concepts in this blog post and more are explained well and in more depth in other blog posts, articles and books.\n\nVersion control\n\nExcuse me, do you have a moment to talk about version control? – a freely-available and very readable introduction in the PeerJ journal by Jenny Bryan\n\n\n\nGit-specific\n\nGit for humans slides by Alice Bartlett\nVersion Control with Git is a beginners’ course by Software Carpentry – you can sign up to have it delivered in a session, or follow at home\nThere are introductory Git videos on the Git website\nPro Git is a free online book by Scott Chacon and Ben Straub – don’t be alarmed by the title; it starts from first principles\nGitHub has a suite of reading and training materials for Git\nLearn Git Branching, an interactive visual walkthrough by Peter Cottle\n\n\n\nGitHub-specifc\n\nGitHub Learning Lab for learning GitHub from within GitHub\nUsing GitHub without the command line by Craig Lockwood is a way of having the power of GitHub and version control without needing to use Git\n\n\n\nR-specific\n\nHappy Git and GitHub for the useR, a book about interacting with Git and GitHub in R workflows by Jenny Bryan, the teaching assistants of STAT545 and Jim Hester\nVersion Control with Git and SVN, a walkthrough for using Git in RStudio’s IDE by Nathan Stephens"
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#environment",
    "href": "posts/2019-10-27-git-github/index.html#environment",
    "title": "Git going: Git and GitHub",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-09-14 15:09:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2019-10-27-git-github/index.html#footnotes",
    "href": "posts/2019-10-27-git-github/index.html#footnotes",
    "title": "Git going: Git and GitHub",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, the real audience are the participants of the UK government’s Data Science Accelerator. Participants are analysts who may have little knowledge of programming.↩︎\nYou can also commit with both a short message and a longer description. To do this, run git commit without the -m flag. By default on macOS this will open Vim, a text editor, inside Terminal. Type in your comments and then type Esc : w q to ‘write-quit’ (save and exit) and return to the command line.↩︎"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html",
    "href": "posts/2023-04-23-type-convert/index.html",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "",
    "text": "Confirmed: Unown is character type.1"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#tldr",
    "href": "posts/2023-04-23-type-convert/index.html#tldr",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "tl;dr",
    "text": "tl;dr\nI forgot that the base R function type.convert() exists. Handy for ‘simplifying’ all the columns of a dataframe to appropriate data types."
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#suppression-depression",
    "href": "posts/2023-04-23-type-convert/index.html#suppression-depression",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Suppression depression",
    "text": "Suppression depression\n{a11ytables} is an R package that lets you generate publishable spreadsheets that follow the UK government’s best practice guidance.\nOne requirement is to replace missing values with placeholder symbols. For example, suppressed data can be replaced with the string \"[c]\" (‘confidential’).\nOf course, R’s behaviour means it can store only one data type per column, so a numeric-type column will be automatically converted to character when you introduce at least one string value (i.e. something in \"quotes\").2\nFor example, this vector is type ‘double’ (i.e. decimals and not ‘whole-number’ integers) and has the more general ‘numeric’ class:\n\nnums &lt;- runif(100)\ntypeof(nums); class(nums)\n\n[1] \"double\"\n\n\n[1] \"numeric\"\n\n\nThe whole thing is converted to character type if you append just one character value.\n\ntypeof(c(nums, \"[c]\"))\n\n[1] \"character\"\n\n\nThis is known behaviour, yes, but it causes a minor annoyance in the xlsx files output from an {a11ytables} workflow: Excel puts a warning marker in the corner of any cell in a text column that contains a numeric value.3\n\nCat left a GitHub issue related to this: columns entirely made of numbers were being marked by Excel with the ‘number in a text column’ warning. In this case, it was because Cat’s suppression process resulted in all columns being converted to character.\nIt would be great to convert back to numeric any columns that did not receive a placeholder symbol during the wrangling process. How can you do this?"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#type-specimen",
    "href": "posts/2023-04-23-type-convert/index.html#type-specimen",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Type specimen",
    "text": "Type specimen\nLet’s consider a demo example. First I’ll attach {dplyr}, which is commonly used by stats producers in the UK government.\n\nsuppressPackageStartupMessages(library(dplyr))\n\nHere’s a very simple dataframe, tbl, to use as a demo. Column x contains values that will need to be suppressed because they’re lower than 5. There are no such values in column y.\n\nset.seed(1337)\n\ntbl &lt;- tibble(\n  id = LETTERS[1:5],\n  x  = round(runif(5, 0, 10), 2),\n  y  = round(runif(5, 6, 10), 2)\n)\n\ntbl\n\n# A tibble: 5 × 3\n  id        x     y\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      5.76  7.33\n2 B      5.65  9.79\n3 C      0.74  7.12\n4 D      4.54  6.98\n5 E      3.73  6.58\n\n\nSo, to borrow and simplify Cat’s approach: for each numeric column in tbl (i.e. x and y), replace any value of less than 5 with the placeholder string \"[c]\", otherwise retain the original value.\n\ntbl_supp &lt;- tbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) if_else(\n        condition = value &lt; 5, \n        true      = \"[c]\",\n        false     = as.character(value)\n      )\n    )\n  )\n\ntbl_supp\n\n# A tibble: 5 × 3\n  id    x     y    \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 A     5.76  7.33 \n2 B     5.65  9.79 \n3 C     [c]   7.12 \n4 D     [c]   6.98 \n5 E     [c]   6.58 \n\n\nSo column x now contains text values and has predictably been converted to character, which you can see as &lt;chr&gt; in the tibble header. But notice that y is also character type despite all the numeric values being retained.\nThis happened because the if_else() we used to create tbl_supp required the true and false arguments to resolve to the same type. The false argument must use as.character() because true resolves to the character value \"[c]\".\nIdeally we’d perform our suppression step but column x would end up as character and y as numeric. How can we achieve this?"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#adjust-my-type",
    "href": "posts/2023-04-23-type-convert/index.html#adjust-my-type",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Adjust my type",
    "text": "Adjust my type\nIn this section are some methods to fix the problem by:\n\nCausing yourself further brainache\nUsing a (relatively little known?) base R function\nDoing it ‘properly’ from the outset\n\n\nType 1: nah\nOf course, we could run tbl_supp |&gt; mutate(y = as.numeric(y)) to convert that specific column back to numeric. But imagine if you have a lot more columns and you can’t be sure which ones need to be converted.\nMaybe you could apply as.numeric() across all columns? Columns of numbers stored as text will then be converted entirely to numeric:\n\nas.numeric(c(\"1\", \"2\", \"3\"))\n\n[1] 1 2 3\n\n\nBut this causes a problem for character columns that contain text, like our placeholder symbol:\n\nas.numeric(c(\"1\", \"[c]\"))\n\nWarning: NAs introduced by coercion\n\n\n[1]  1 NA\n\n\nSo \"1\" becomes 1, but we’re warned that \"[c]\" has been converted to NA (well, NA_real_, which is the numeric form of NA).\nWe could do something convoluted, like see which columns didn’t gain NA values and should be retained as numeric. But that’s bonkers. This approach ultimately makes things worse because we’ve actually lost information!\nReally we want to check each column to see if it contains numbers only and then convert it to numeric. How?\n\n\nType 2: better\nThere’s a handy base R function that I had forgotten about: type.convert().\nIt takes a vector and, in turn, tries to coerce it to each data type. The process stops when coercion occurs without error. As the help file (?type.convert) puts it:\n\nGiven a vector, the function attempts to convert it to logical, integer, numeric or complex, and when additionally as.is = FALSE… converts a character vector to factor. The first type that can accept all the non-missing values is chosen.\n\nAnd handily:\n\nWhen the data object x is a data frame or list, the function is called recursively for each column or list element.\n\nSo we can pass our entire dataframe to type.convert() and it’ll check them all for us:\n\ntbl_supp_conv &lt;- type.convert(tbl_supp, as.is = TRUE)\n\ntbl_supp_conv\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nAs we wanted, our character column y has become numeric type (&lt;dbl&gt;) while x remains as character. Neato.\n\n\nType 3: betterer\nThere are probably better approaches to this problem from the outset, rather than after-the-fact application of type.convert().\nAs Tim has pointed out, you could actually just use the base R form of ifelse():\n\ntbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) ifelse(\n        test = value &lt; 5, \n        yes  = \"[c]\",\n        no   = value\n      )\n    )\n  )\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nI think people use dplyr::if_else() for (a) consistency if they’re already using tidyverse in the script and (b) it’s ‘strictness’ compared to ifelse(). if_else() will force you to declare the true and false arguments so they resolve to the same type, whereas ifelse() will silently force type coercion, which may be undesirable in some cases.\nAnother method would be to iterate the suppression over only the columns that need it. For example, you could do that with a simple for and if:\n\ncols_numeric &lt;- names(select(tbl, where(is.numeric)))\n\nfor (col in cols_numeric) {\n  if (any(tbl[col] &lt; 5)) {\n    tbl[col] &lt;- ifelse(\n      tbl[col] &lt; 5,\n      \"[c]\",\n      as.character(tbl[[col]])\n    )\n  }\n}\n\ntbl\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nThis reads as ‘for each numeric column that contains at least one value less than 5, replace those values with the placeholder symbol \"[c]\".’"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#preach-to-the-converted-types",
    "href": "posts/2023-04-23-type-convert/index.html#preach-to-the-converted-types",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Preach to the converted types",
    "text": "Preach to the converted types\nIt’s almost like this post could have just been a tweet saying ‘😮 yo, type.convert() is 🪄magic🪄 y’all’. But this post is now a handy reference in case anyone has the same problems with Excel’s handling of {a11ytables} outputs in future.\nAlso I needed to hit my pun quota for the month.4"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#environment",
    "href": "posts/2023-04-23-type-convert/index.html#environment",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:06:53 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     utf8_1.2.3        R6_2.5.1          fastmap_1.1.1    \n [5] tidyselect_1.2.0  xfun_0.39         magrittr_2.0.3    glue_1.6.2       \n [9] tibble_3.2.1      knitr_1.43.1      pkgconfig_2.0.3   htmltools_0.5.5  \n[13] generics_0.1.3    rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1        \n[17] fansi_1.0.4       vctrs_0.6.3       withr_2.5.0       compiler_4.3.1   \n[21] rstudioapi_0.15.0 tools_4.3.1       pillar_1.9.0      evaluate_0.21    \n[25] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#footnotes",
    "href": "posts/2023-04-23-type-convert/index.html#footnotes",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a Pokémon joke. I could have gone with Type: Null, but it’s too hard to draw.↩︎\nThere’s a sort of ‘coercion hierarchy’ in R. The order is like logical &gt; integer &gt; numeric &gt; character, where the latter are ‘dominant’ to those prior (massive oversimplification). As an aside, this results in some oddities to the untrained eye: sum(2, TRUE) resolves to 3, because TRUE is coerced to the numeric value 1 (FALSE is 0) and so we get 2 + 1 = 3.↩︎\nYou can dismiss these warning markers in the Excel GUI, but I don’t think it’s possible to suppress these markers programmatically and proactively in {a11ytables}. Note also that {a11ytables} cheats a bit here for sake of presentation. The generate_workbook() function guesses that the column was intended to be numeric and adds style information to right-align the values in the output xlsx, which is how numeric values are normally treated in Excel.↩︎\nTurns out there’s literally such a thing as type punning.↩︎"
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html",
    "href": "posts/2018-11-21-waggle-dance/index.html",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "",
    "text": "Beeswarm plots are a thing. Duncan made a beswarm plot that looks like a beeswarm and I animated it."
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#tldr",
    "href": "posts/2018-11-21-waggle-dance/index.html#tldr",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "",
    "text": "Beeswarm plots are a thing. Duncan made a beswarm plot that looks like a beeswarm and I animated it."
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#how-to-plot-grouped-continuous-data",
    "href": "posts/2018-11-21-waggle-dance/index.html#how-to-plot-grouped-continuous-data",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "How to plot grouped continuous data?",
    "text": "How to plot grouped continuous data?\nA boxplot lets you show continuous data split by categories, but it hides the data points and doesn’t tell you much about distribution. A violin chart will show the distribution but you still don’t know about the density of data.\nStripcharts show the data for each category as individual points. The points can be layered on top of each other where they take the same Y value and can be stretched arbitrarily along the X axis.\nIf you don’t have too much data, or if you sample it, you can stop the data points in a stripchart from overlapping and instead line them up side by side where they take the same Y value. This is called a ‘beeswarm’. Why? Probably because the cloud of data you’re plotting looks a bit like a swarm of bees.\nBelow is how the plots look side by side.\n\nlibrary(ggplot2)     # for plotting\nlibrary(ggbeeswarm)  # more on this later\nlibrary(cowplot)     # arrange plots\n\n# Create data set\ndata &lt;- data.frame(\n  \"variable\" = rep(c(\"runif\", \"rnorm\"), each = 100),\n  \"value\" = c(runif(100, min = -3, max = 3), rnorm(100))\n)\n\n# Generate different plot types\ncanvas &lt;- ggplot(data, aes(variable, value)) \nbox &lt;- canvas + geom_boxplot() + ggtitle(\"Boxplot\")\nviolin &lt;- canvas + geom_violin() + ggtitle(\"Violin\")\nstrip &lt;- canvas + geom_jitter(width = 0.2)  + ggtitle(\"Stripchart\")\nbee &lt;- canvas + geom_quasirandom()  + ggtitle(\"Beeswarm\")\n\n# Arrange plots\ngrid &lt;- plot_grid(box, violin, strip, bee)\n\nprint(grid)"
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#obvious-next-step",
    "href": "posts/2018-11-21-waggle-dance/index.html#obvious-next-step",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "Obvious next step",
    "text": "Obvious next step\nWe can test this theory by plotting the points as actual bees, lol. Well, emoji bees. Duncan (of {tidyxl} and {unpivotr} fame) did exactly this and tweeted the plot and code.\n\n\n\nDuncan’s original plot.\n\n\nTo summarise, Duncan did this by hacking emojis via {emoGG} into {ggbeeswarm}’s geom_beeswarm() function to create gg_beeswarm_emoji(). Patent pending, presumably."
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#obvious-next-next-step",
    "href": "posts/2018-11-21-waggle-dance/index.html#obvious-next-next-step",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "Obvious next next step",
    "text": "Obvious next next step\nWouldn’t it be great if the little emoji bees moved around a little bit? Almost like a waggle dance?\nI cheated a little bit and recoded the geom_quasirandom() function from {ggbeeswarm} instead of geom_beeswarm(). Why? Beeswarm plots have an inherent ‘neatness’ to them. That is not becoming of a beeswarm. Instead, geom_quasirandom() gives you some ‘random’ jitter each time you plot the data.\nSo we can plot the same data several times and stack the images into a gif. One easy way to do this is via the {magick} package, a re-engineering of the open-source ImageMagick sute of tools from Jeroen Ooms at rOpenSci."
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#code",
    "href": "posts/2018-11-21-waggle-dance/index.html#code",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "Code",
    "text": "Code\nAttach the packages.\n\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\nlibrary(emoGG)  # remotes::install_github(\"dill/emoGG\")\nlibrary(magick)\n\nRecode the geom_quasirandom() to display emoji, as per Duncan’s tweet.\n\ngeom_quasi_emoji &lt;- function (\n  mapping = NULL, data = NULL, width = NULL, varwidth = FALSE, \n  bandwidth = 0.5, nbins = NULL, method = \"quasirandom\", groupOnX = NULL, \n  dodge.width = 0, stat = \"identity\", position = \"quasirandom\", \n  na.rm = FALSE, show.legend = NA, inherit.aes = TRUE, emoji = \"1f4l1d\", ...\n) {\n  \n  img &lt;- emoji_get(emoji)[[1]]\n  \n  position &lt;- position_quasirandom(\n    width = width, varwidth = varwidth, \n    bandwidth = bandwidth, nbins = nbins, method = method, \n    groupOnX = groupOnX, dodge.width = dodge.width\n  )\n  \n  ggplot2::layer(\n    data = data, mapping = mapping, stat = stat, \n    geom = emoGG:::GeomEmoji, position = position, show.legend = show.legend, \n    inherit.aes = inherit.aes, params = list(na.rm = na.rm, img = img, ...)\n  )\n}\n\nIt makes sense to use the data that Duncan generated so we can compare the static plot to the animated one.\n\nswarm &lt;- data.frame(\n  \"variable\" = rep(c(\"runif\", \"rnorm\"), each = 100),\n  \"value\" = c(runif(100, min = -3, max = 3), rnorm(100))\n)\n\nLet’s define what our plot should look like. method = \"pseudorandom\" is the bit that gives us the jittering.\n\nplot &lt;- ggplot(swarm, aes(variable, value)) +\n  geom_quasi_emoji(emoji = \"1f41d\", method = \"pseudorandom\") +\n  theme(panel.background = element_rect(fill = \"skyblue\")) +\n  ggtitle(\"WAGGLE DANCE\")\n\nNow we can create a few versions of this plot with different jittering. The plots are magick-class objects made with image_graph() from the {magick} package.\nWe can loop through a few plots, each representing a frame in the final gif.\nAnd now image_animate() can be used to combine those magick objects into a gif.\n\nwaggle_dance &lt;- image_animate(c(t1, t2, t3, t4))\nwaggle_dance\n\n\n\n\n\n\nAnd we can save this with image_write().\n\nimage_write(waggle_dance, \"waggle_dance.gif\")\n\nWell done, we got through this without any bee puns."
  },
  {
    "objectID": "posts/2018-11-21-waggle-dance/index.html#environment",
    "href": "posts/2018-11-21-waggle-dance/index.html#environment",
    "title": "Waggle dance with {ggbeeswarm} and {emoGG}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-05 17:48:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] cowplot_1.1.1    ggbeeswarm_0.7.2 ggplot2_3.4.2   \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         generics_0.1.3    jsonlite_1.8.7    labeling_0.4.2   \n [9] glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5   scales_1.2.1     \n[13] fansi_1.0.4       rmarkdown_2.23    grid_4.3.1        evaluate_0.21    \n[17] munsell_0.5.0     tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7       \n[21] lifecycle_1.0.3   vipor_0.4.5       compiler_4.3.1    dplyr_1.1.2      \n[25] htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.15.0 beeswarm_0.4.0   \n[29] farver_2.1.1      digest_0.6.33     R6_2.5.1          tidyselect_1.2.0 \n[33] utf8_1.2.3        pillar_1.9.0      magrittr_2.0.3    withr_2.5.0      \n[37] tools_4.3.1       gtable_0.3.3"
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html",
    "href": "posts/2018-11-25-art-of-the-possible/index.html",
    "title": "Quantify colour by {magick}",
    "section": "",
    "text": "I used the {magick} package in R to map an image’s colours to their nearest match from a simplified palette, then quantified how much of the image was covered by each colour in that palette.\n\n Note\nI later learnt about {colorfindr} by David Zumbach, which can extract colours from images, provide composition details and generate palettes. Check it out."
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#tldr",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#tldr",
    "title": "Quantify colour by {magick}",
    "section": "",
    "text": "I used the {magick} package in R to map an image’s colours to their nearest match from a simplified palette, then quantified how much of the image was covered by each colour in that palette.\n\n Note\nI later learnt about {colorfindr} by David Zumbach, which can extract colours from images, provide composition details and generate palettes. Check it out."
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#colour-search",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#colour-search",
    "title": "Quantify colour by {magick}",
    "section": "Colour search",
    "text": "Colour search\nAs a side project at work, we wanted users to be able to search images of artwork by their prevalence of colours from a small simple palette (red, blue, yellow, etc). Lots of online services let you sort images by colour, like Google Arts & Culture, Designspiration and TinEye Multicolr."
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#art-of-the-possible",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#art-of-the-possible",
    "title": "Quantify colour by {magick}",
    "section": "Art of the possible",
    "text": "Art of the possible\nWhat might be a relatively simple and straightforward way to do this in R? By ‘simple’ I mean we don’t want to do any hard work. We don’t want to consider any colour theory1 and we want to stick to simple, easily-named colours like ‘green’.2\nSo, we can do the following:\n\nRead in an image\nPrepare a set of ‘simple colours’\nMap the simple colours to the image\nQuantify the colours"
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#its-a-kind-of-imagemagick",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#its-a-kind-of-imagemagick",
    "title": "Quantify colour by {magick}",
    "section": "It’s a kind of ImageMagick",
    "text": "It’s a kind of ImageMagick\nThe {magick} R package is an implementation of ImageMagick, an open-source software suite whose emphasis is image manipulation from the command line. The flexibility of {magick} can be seen in its vignette.\nThe package was created and is maintained by Jeroen Ooms, a software engineer and postdoc at rOpenSci, a collective that seeks to develop tools for open and reproducible research.\nrOpenSci hosted a workshop from Ooms about working with images in R and the presentation slides caught my attention. I’ve used some of Jeroen’s code below."
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#code",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#code",
    "title": "Quantify colour by {magick}",
    "section": "Code",
    "text": "Code\nFirst we need to load our packages; all are available from CRAN.\n\nsuppressPackageStartupMessages({\n  library(dplyr)\n  library(tibble)\n  library(magick)\n})\n\n\nRead a test image\nI’ve chosen a colourful image to use for our test case: it’s a picture of a bunch of Lego Duplo bricks.3\nWe’ll use image_read() to read the JPEG as an object of class ‘magick’ and then image_scale() to reduce the image size and save some space.\nPrinting the image also gives us some details of format, dimensions, etc.\n\n# Path to the image\nduplo_path &lt;- \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Lego_dublo_arto_alanenpaa_2.JPG/2560px-Lego_dublo_arto_alanenpaa_2.JPG\"\n\n# Read as magick object and resize\nduplo &lt;- image_read(duplo_path) %&gt;%\n  image_scale(geometry = c(\"x600\"))\n\nprint(duplo)\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n1 JPEG     900    600 sRGB       FALSE        0 72x72  \n\n\n\n\n\n\n\nPrepare simple colours\nWe’ll map a set of simple colours to the test image. This means that the colours from the test image will be replaced by the ‘closest’ colour from our simple set.\nOne way to do this is to define our simple colour set and create an image from them. In this case I’m taking just six colours.\n\n# Generate named vector of 'simple' colours\ncols_vec &lt;- setNames(\n  c(\"#000000\", \"#0000ff\", \"#008000\", \"#ff0000\", \"#ffffff\", \"#ffff00\"),\n  c(\"black\", \"blue\", \"green\", \"red\", \"white\", \"yellow\")\n)\n\nThen we can plot squares of these colours, using image_graph() to read them as magick-class objects.4 My method here is not the most efficient, but you can see the output is an image that contains our six colours.\n\n\nClick for code\n\n\n# For each vector element (colour) create a square of that colour\nfor (i in seq_along(cols_vec)) {\n  fig_name &lt;- paste0(names(cols_vec)[i], \"_square\")  # create object name\n  assign(\n    fig_name,  # set name\n    image_graph(width = 100, height = 100, res = 300)  # create magick object\n  )\n  par(mar = rep(0, 4))  # set plot margins\n  plot.new()  # new graphics frame\n  rect(0, 0, 1, 1, col = cols_vec[i], border = cols_vec[i])  # build rectangle\n  assign(fig_name, magick::image_crop(get(fig_name), \"50x50+10+10\")) # crop\n  dev.off()  # shut down plotting device\n  rm(i, fig_name)  # clear up\n}\n\n# Generate names of the coloured square objects\ncol_square &lt;- paste0(names(cols_vec), \"_square\")\n\n# Combine magick objects (coloured squares)\nsimple_cols &lt;- image_append(c(\n  get(col_square[1]), get(col_square[2]), get(col_square[3]),\n  get(col_square[4]), get(col_square[5]), get(col_square[6])\n))\n\n\n\nprint(simple_cols)\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n1 PNG      300     50 sRGB       TRUE         0 300x300\n\n\n\n\n\n\nMap to the image\nNow we can apply the simple colour set to the test image using image_map().\n\nduplo_mapped &lt;- image_map(image = duplo, map = simple_cols)\n\nAnd we can use image_animate() to see the difference between the two.\n\nimage_animate(c(duplo, duplo_mapped), fps = 1)\n\n\n\n\nGreat. You can see where the original colours have been replaced by the ‘closest’ simple colours.\nNote in particular where the more reflective surfaces are mapped to white than the actual brick colour.\nThis is okay: the brick may be blue, but we’ve only defined one shade of blue. If a particular shade is closer to white, then so be it.\n\n\n\nQuantify the colours\nNow we can take this mapped image and quantify how much of the image belongs to each colour. Imagine we’ve broken the image into pixels and then we’re counting how many belng to each of our six colours.\n\n# Function to count the colours (adapted from Jeroen Ooms)\ncount_colors &lt;- function(image) {\n  data &lt;- image_data(image) %&gt;%\n    apply(2:3, paste, collapse = \"\") %&gt;% \n    as.vector %&gt;% table() %&gt;%  as.data.frame() %&gt;% \n    setNames(c(\"hex\", \"freq\"))\n  data$hex &lt;- paste(\"#\", data$hex, sep=\"\")\n  return(data)\n}\n\n# Dataframe of dominant colours \nduplo_col_freq &lt;- duplo_mapped %&gt;%\n  count_colors() %&gt;%\n  left_join(\n    enframe(cols_vec) %&gt;% rename(hex = value),\n    by = \"hex\"\n  ) %&gt;% \n  arrange(desc(freq)) %&gt;% \n  mutate(percent = 100*round((freq/sum(freq)), 3)) %&gt;% \n  select(\n    `Colour name` = name, Hexadecimal = hex,\n    `Frequency of colour` = freq, `Percent of image` = percent\n  )\n\nduplo_mapped  # see mapped image again\n\n\n\nknitr::kable(duplo_col_freq)  # quantify colour\n\n\n\n\nColour name\nHexadecimal\nFrequency of colour\nPercent of image\n\n\n\n\nred\n#ff0000\n132135\n24.5\n\n\nwhite\n#ffffff\n107841\n20.0\n\n\nblack\n#000000\n103645\n19.2\n\n\nyellow\n#ffff00\n79750\n14.8\n\n\ngreen\n#008000\n64868\n12.0\n\n\nblue\n#0000ff\n51761\n9.6\n\n\n\n\n\nSo red makes up almost a quarter of the image, with white and black just behind. This makes sense: many of the bricks are red and much of the shadow areas of yellow bricks were rendered as red, while black and white make up many of the other shadows and reflective surfaces."
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#and-so-we-must-p-art",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#and-so-we-must-p-art",
    "title": "Quantify colour by {magick}",
    "section": "And so we must p-art",
    "text": "And so we must p-art\nSo, you can map a simple colour set to an image with {magick} and then quantify how much of the image is covered by that simple set.\nOf course, there are many possibilities beyond what’s been achieved here. For example, you could create a tool where the user chooses a colour and images are returned in order of dominance for that colour. You could also write this all into a function that takes a folder of images and returns the percentage of each colour in each image.\nBelow are some additional examples of the approach taken in this post.\n\nReef fish\n\n\nClick for details\n\nImage by Richard L Pyle from Wikimedia Commons, CC0 1.0.\n\nreef_path &lt;- \"https://upload.wikimedia.org/wikipedia/commons/0/05/100%25_reef-fish_Endemism_at_90_m_off_Kure_Atoll.jpg\"\n\nreef &lt;- image_read(reef_path) %&gt;%\n  image_scale(geometry = c(\"x600\"))\n\nreef_mapped &lt;- image_map(image = reef, map = simple_cols)\n\nreef_col_freq &lt;- reef_mapped %&gt;%\n  count_colors() %&gt;%\n  left_join(\n    enframe(cols_vec) %&gt;% rename(hex = value),\n    by = \"hex\"\n  ) %&gt;% \n  arrange(desc(freq)) %&gt;% \n  mutate(percent = 100*round((freq/sum(freq)), 3)) %&gt;% \n  select(\n    `Colour name` = name, Hexadecimal = hex,\n    `Frequency of colour` = freq, `Percent of image` = percent\n  )\n\nreef_animate &lt;- image_animate(c(reef, reef_mapped), fps = 1)\n\n\n\n\n\n\n\n\n\n\nColour name\nHexadecimal\nFrequency of colour\nPercent of image\n\n\n\n\nblue\n#0000ff\n317143\n49.5\n\n\nblack\n#000000\n214642\n33.5\n\n\ngreen\n#008000\n76234\n11.9\n\n\nyellow\n#ffff00\n13296\n2.1\n\n\nred\n#ff0000\n10086\n1.6\n\n\nwhite\n#ffffff\n8799\n1.4\n\n\n\n\n\n\n\nHong Kong lights\n\n\nClick for details\n\nImage by Daniel Case from Wikimedia Commons, CC BY-SA 3.0\n\nneon_path &lt;- \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Neon_lights%2C_Nathan_Road%2C_Hong_Kong.jpg/900px-Neon_lights%2C_Nathan_Road%2C_Hong_Kong.jpg\"\n\nneon &lt;- image_read(neon_path) %&gt;%\n  image_scale(geometry = c(\"x600\"))\n\nneon_mapped &lt;- image_map(image = neon, map = simple_cols)\n\nneon_col_freq &lt;- neon_mapped %&gt;%\n  count_colors() %&gt;%\n  left_join(\n    enframe(cols_vec) %&gt;% rename(hex = value),\n    by = \"hex\"\n  ) %&gt;% \n  arrange(desc(freq)) %&gt;% \n  mutate(percent = 100*round((freq/sum(freq)), 3)) %&gt;% \n  select(\n    `Colour name` = name, Hexadecimal = hex,\n    `Frequency of colour` = freq, `Percent of image` = percent\n  )\n\nneon_animate &lt;- image_animate(c(neon, neon_mapped), fps = 1)\n\n\n\n\n\n\n\n\n\n\nColour name\nHexadecimal\nFrequency of colour\nPercent of image\n\n\n\n\nblack\n#000000\n191573\n71.0\n\n\ngreen\n#008000\n23126\n8.6\n\n\nblue\n#0000ff\n18454\n6.8\n\n\nred\n#ff0000\n17553\n6.5\n\n\nyellow\n#ffff00\n10872\n4.0\n\n\nwhite\n#ffffff\n8422\n3.1\n\n\n\n\n\n\n\nLadybird\n\n\nClick for details\n\nImage by Elena Andreeva from Wikimedia Commons, CC0 1.0.\n\nlbird_path &lt;- \"https://upload.wikimedia.org/wikipedia/commons/d/d5/Erysimum_Cheiranthoides_%28215134987%29.jpeg\"\n\nlbird &lt;- image_read(lbird_path) %&gt;%\n  image_scale(geometry = c(\"x600\"))\n\nlbird_mapped &lt;- image_map(image = lbird, map = simple_cols)\n\nlbird_col_freq &lt;- lbird_mapped %&gt;%\n  count_colors() %&gt;%\n  left_join(\n    enframe(cols_vec) %&gt;% rename(hex = value),\n    by = \"hex\"\n  ) %&gt;% \n  arrange(desc(freq)) %&gt;% \n  mutate(percent = 100*round((freq/sum(freq)), 3)) %&gt;% \n  select(\n    `Colour name` = name, Hexadecimal = hex,\n    `Frequency of colour` = freq, `Percent of image` = percent\n  )\n\nlbird_animate &lt;- image_animate(c(lbird, lbird_mapped), fps = 1)\n\n\n\n\n\n\n\n\n\n\nColour name\nHexadecimal\nFrequency of colour\nPercent of image\n\n\n\n\nwhite\n#ffffff\n302626\n54.6\n\n\nblue\n#0000ff\n118010\n21.3\n\n\nyellow\n#ffff00\n101797\n18.4\n\n\ngreen\n#008000\n27892\n5.0\n\n\nred\n#ff0000\n2322\n0.4\n\n\nblack\n#000000\n1153\n0.2"
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#environment",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#environment",
    "title": "Quantify colour by {magick}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-05 17:29:58 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.7.4 tibble_3.2.1 dplyr_1.1.2 \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         png_0.1-8         generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     fontawesome_0.5.1 fastmap_1.1.1     yaml_2.3.7       \n[17] lifecycle_1.0.3   compiler_4.3.1    htmlwidgets_1.6.2 Rcpp_1.0.11      \n[21] pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[25] tidyselect_1.2.0  utf8_1.2.3        curl_5.0.1        pillar_1.9.0     \n[29] magrittr_2.0.3    withr_2.5.0       tools_4.3.1"
  },
  {
    "objectID": "posts/2018-11-25-art-of-the-possible/index.html#footnotes",
    "href": "posts/2018-11-25-art-of-the-possible/index.html#footnotes",
    "title": "Quantify colour by {magick}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJust as well, because I’m colourblind.↩︎\nThere are five named versions of olive drab in R’s named palette.↩︎\nPhoto by Arto Alanenpää, CC0-BY-4.0 from Wikimedia Creative Commons.↩︎\nArtefacts introduced during compression of PNGs and JPGs might mean that your set of six colours ends up being more than six. It’s preferable to generate our colour set within R, inside image_graph(), so that we have only our six defined colours.↩︎"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "",
    "text": "Closest I’ve been to Leicester Square since the start of lockdown."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#tldr",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#tldr",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "tl;dr",
    "text": "tl;dr\nI recently made a Twitter bot with R, {rtweet}, MapBox and GitHub Actions – londonmapbot – that tweets images of random coordinates in London. I decided to explore them interactively by creating a simple {leaflet} map. You can jump directly to the map).\n\n Note\nTwitter changed its API terms in 2023. As a result, you probably can’t re-run the code in this blog. Read about how I moved londonmapbot to Mastodon at botsin.space/@londonmapbot because of these changes."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#the-bot",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#the-bot",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "The bot",
    "text": "The bot\nI built the londonmapbot Twitter bot as a fun little project to get to grips with GitHub Actions. An action is scheduled every 30 minutes to run some R code that (1) selects random coordinates in London, (2) fetches a satellite image from the MapBox API, (3) generates an OpenStreetMap URL, all of which are (4) passed to {rtweet} to post to the londonmapbot account.\nThe outputs have been compelling so far. The composition is usually ‘accidentally’ pleasing. Sometimes landmarks are captured, like The Shard, The Natural History Museum and V&A and Heathrow.\n\n\n\nThe Shard looks pointy even in 2D.\n\n\nI was wondering whether the bot has ‘found’ other landmarks that I hadn’t noticed or whether it’s found my house. The londonmapbot source code doesn’t have a log file for all the coordinates it’s generated, so I figured the easiest way to get this information and explore it would be to grab all the tweets – which contain the coordinates as text – and then map the results."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#packages",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#packages",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Packages",
    "text": "Packages\nI’m loading the tidyverse for data manipulation with {dplyr}, {tidyr} and {stringr}. {rtweet} greatly simplifies the Twitter API and the objects it returns. We’ll use it to fetch all the tweets from londonmapbot.\nI’m using a few geography-related packages:\n\n{sf} for tidy dataframes with spatial information\n{geojsonio} to read spatial files in geojson format\n{PostcodesioR} to fetch additional geographic data given our x-y information\n{leaflet} to build interactive maps from spatial data.\n\n\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(rtweet)\n  library(sf)\n  library(geojsonio)\n  library(PostcodesioR)\n  library(leaflet)\n})\n\nA particular shoutout to rOpenSci for this post: {rtweet}, {geojsonio} and {PostcodesioR} have all passed muster to become part of the rOpenSci suite of approved packages."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#fetch-tweets",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#fetch-tweets",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Fetch tweets",
    "text": "Fetch tweets\n{rtweet} does all the legwork to fetch and parse information from the Twitter API, saving you loads of effort.\nThe rtweet::get_timeline() function is amazing in its user-side simplicity. Pass the account name from which to fetch tweets, along with the number of tweets to get (3200 is the maximum).\n\nlmb_tweets &lt;- get_timeline(\"londonmapbot\", n = 3200)\nlmb_tweets[1:5, c(\"created_at\", \"text\")]  # limited preview\n\n# A tibble: 5 x 2\n  created_at          text                                                      \n  &lt;dttm&gt;              &lt;chr&gt;                                                     \n1 2020-12-29 09:36:20 \"51.5519, -0.33\\nhttps://t.co/ica9ZypBLS https://t.co/5gS…\n2 2020-12-29 08:59:46 \"51.4392, 0.1636\\nhttps://t.co/2DsbbLYIDG https://t.co/KV…\n3 2020-12-29 06:28:48 \"51.6773, -0.2555\\nhttps://t.co/1hu2VoxCBF https://t.co/b…\n4 2020-12-29 05:56:15 \"51.674, -0.4042\\nhttps://t.co/HMhmUVVrIn https://t.co/mP…\n5 2020-12-29 05:31:03 \"51.4451, 0.1058\\nhttps://t.co/nWuqy4s7am https://t.co/qv…\n{rtweet} has a function to quick-plot tweets over time. There’s meant to be a tweet every half-hour from londonmapbot, but GitHub Actions has been a little inconsistent and sometimes fails to post.\n\nrtweet::ts_plot(lmb_tweets) +  # plot daily tweets\n  labs(\n    title = \"@londonmapbot tweets per day\",\n    x = \"\", y = \"\", caption = \"Data collected via {rtweet}\"\n  )"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#extract-tweet-information",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#extract-tweet-information",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Extract tweet information",
    "text": "Extract tweet information\nThe dataframe returned by {rtweet} contains nearly 100 columns. For our purposes we can minimise to:\n\nthe unique tweet identifier, status_id, which we can use to build a URL back to the tweet\nthe datetime the tweet was created_at\nthe tweet text content, from which we can isolate the latitude and longitude values\nthe media_url to the MapBox image attached to each tweet\nthe full OpenStreetMap link in each tweet via urls_expanded_urls\n\n\nlmb_simple &lt;- lmb_tweets %&gt;% \n  filter(str_detect(text, \"^\\\\d\")) %&gt;%  # must start with a digit\n  separate(  # break column into new columns given separator\n    text,  # column to separate\n    into = c(\"lat\", \"lon\"),  # names to split into\n    sep = \"\\\\s\",  # separate on spaces\n    extra = \"drop\" # discard split elements\n  ) %&gt;% \n  mutate(  # tidy up variables \n    lat = str_remove(lat, \",\"),\n    across(c(lat, lon), as.numeric)\n  ) %&gt;% \n  select(  # focus variables\n    status_id, created_at, lat, lon,\n    osm_url = urls_expanded_url, media_url\n  )\n\nlmb_simple[1:5, c(\"status_id\", \"lat\", \"lon\")]  # limited preview\n\n# A tibble: 5 x 3\n  status_id             lat    lon\n  &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;\n1 1343853346478841862  51.6 -0.33 \n2 1343844145518026752  51.4  0.164\n3 1343806154397409280  51.7 -0.256\n4 1343797964645523456  51.7 -0.404\n5 1343791619049480192  51.4  0.106"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#reverse-geocode",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#reverse-geocode",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Reverse geocode",
    "text": "Reverse geocode\nTweets from londonmapbot are really simple by design; they only have the latitude and longitude, a link to OpenStreetMap and a satellite image pulled from the MapBox API. It might be interesting to provide additional geographic information.\n{PostcodesioR} can perform a ‘reverse geocode’1 of our coordinates. Give latitude and longitude to PostcodesioR::reverse_geocoding() and it returns a list with various administrative geographies for that point.\n\nlmb_geocode &lt;-lmb_simple %&gt;% \n  mutate(\n    reverse_geocode = map2(\n      .x = lon, .y = lat,\n      ~reverse_geocoding(.x, .y, limit = 1)  # limit to first result\n    )\n  ) %&gt;% \n  unnest(cols = reverse_geocode) %&gt;%  # unpack listcol\n  hoist(reverse_geocode, \"postcode\") %&gt;%  # pull out postcode into a \n  hoist(reverse_geocode, \"admin_district\") # pull out borough\n\nlmb_geocode[1:5, c(\"lat\", \"lon\", \"postcode\", \"admin_district\")]  # limited preview\n\n# A tibble: 5 × 4\n    lat    lon postcode admin_district\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;         \n1  51.6 -0.33  UB6 7QT  Ealing        \n2  51.4  0.164 DA5 2DJ  Bexley        \n3  51.7 -0.256 WD6 5PL  Hertsmere     \n4  51.7 -0.404 WD24 5TU Watford       \n5  51.4  0.106 DA15 9BQ Bexley        \n\n\nThe object returned from the reverse geocode is a nested list that we can tidyr::hoist() the geographic information from. Here we grabbed the postcode and ‘administrative district’, which for our purposes is the London borough that the point is in."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#convert-to-spatial-object",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#convert-to-spatial-object",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Convert to spatial object",
    "text": "Convert to spatial object\nRight now we have a dataframe where the geographic information is stored as numeric values. We can use the {sf} package to convert and handle this information as spatial information instead.\nBasically we can use {sf} to ‘geographise’ our dataframe. It can add geometry (points in our case), dimensions (XY, meaning 2D), the maximum geographic extent (a ‘bounding box’ that roughly covers London) and recognition of the coordinate reference system (‘4236’ for latitude-longitude).\nThe sf::st_as_sf() function performs the magic of converting our tidy dataframe into a tidy spatial dataframe. You’ll see that the print method provides us the extra spatial metadata and that our geographic information has been stored in a special geometry column with class sfc_POINT.\n\nlmb_sf &lt;- lmb_geocode %&gt;% \n  st_as_sf(\n    coords = c(\"lon\", \"lat\"),  # xy columns\n    crs = 4326,  # coordinate reference system code\n    remove = FALSE  # retain the xy columns\n  )\n\nlmb_sf[1:5, c(\"status_id\", \"geometry\")]  # limited preview\n\nSimple feature collection with 5 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -0.4042 ymin: 51.4392 xmax: 0.1636 ymax: 51.6773\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 2\n  status_id                    geometry\n  &lt;chr&gt;                     &lt;POINT [°]&gt;\n1 1343853346478841862   (-0.33 51.5519)\n2 1343844145518026752  (0.1636 51.4392)\n3 1343806154397409280 (-0.2555 51.6773)\n4 1343797964645523456  (-0.4042 51.674)\n5 1343791619049480192  (0.1058 51.4451)"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#map-it",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#map-it",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Map it",
    "text": "Map it\nYou can build up layers in {leaflet} in a similar kind of way to a {ggplot2} graphic. The base map is applied with addProviderTiles() and points added as circle-shaped markers with addCircleMarkers(). I used addRectangles() to show the bounding box from within which points are randomly sampled.\n\nlmb_map &lt;- leaflet(lmb_sf, width = '100%') %&gt;% \n  addProviderTiles(\"CartoDB.Positron\") %&gt;%\n  addRectangles(\n    lng1 = -0.489, lat1 = 51.28,\n    lng2 =  0.236, lat2 = 51.686,\n    fillColor = \"transparent\"\n  ) %&gt;%\n  addCircleMarkers(  # locations as points\n    lng = lmb_sf$lon, lat = lmb_sf$lat,  # xy\n    radius = 5, stroke = FALSE,  # marker design\n    fillOpacity = 0.5, fillColor = \"#0000FF\",  # marker colours\n    clusterOptions = markerClusterOptions(),  # bunch-up markers\n    popup = ~paste0(  # dynamic HTML-creation for popup content\n      emo::ji(\"round_pushpin\"), \" \", lmb_sf$lat, \", \", lmb_sf$lon, \"&lt;br&gt;\",\n      emo::ji(\"postbox\"), lmb_sf$admin_district, \n      \", \", lmb_sf$postcode, \"&lt;br&gt;\",\n      emo::ji(\"bird\"), \" &lt;a href='https://twitter.com/londonmapbot/status/\",\n      lmb_sf$status_id, \"'&gt;Tweet&lt;/a&gt;&lt;br&gt;\",\n      emo::ji(\"world_map\"), \" \", \"&lt;a href='\",\n      lmb_sf$osm_url, \"' width='100%'&gt;OpenStreetMap&lt;/a&gt;&lt;br&gt;&lt;br&gt;\",\n      \"&lt;img src='\", lmb_sf$media_url, \"' width='200'&gt;\"\n    )\n  )\n\nThe markers, which are blue dots, have rich pop-ups when clicked. The information is generated dynamically for each point by pasting HTML strings with the content of the dataframe. Props to Matt Kerlogue’s narrowbotR, which uses this emoji-info layout in its automated tweets.\nTo keep the design simple and uncluttered, I’ve intentionally used a muted base map (‘Positron’ from CartoDB) and limited the amount of pop-up content.\nIn the pop-up you’ll see information from the tweet, including the satellite image and printed coordinates; URLs to the original tweet and OpenStreetMap; plus the reverse-geocoded info we got from {PostcodesioR}.\nSince there are thousands of points, it makes sense to cluster them with markerClusterOptions() to avoid graphical and navigational troubles. Click a cluster to expand until you reach a marker."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#map",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#map",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "The map",
    "text": "The map\n\nlmb_map\n\n\n\n\n\n If you can’t see the satellite photos in each pop-up you may need to change browser."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#development",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#development",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Development",
    "text": "Development\nI made this for my own amusement and as an excuse to use {PostcodesioR} and reacquaint myself with {leaflet}. If I were going to develop it, I would make a Shiny app that continuously refreshes with the latest tweet information. I may revisit londonmapbot in future, or create a new bot; in which case the reverse geocoding capabilities of {PostcodesioR} could come in handy for providing more content in tweet text."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#environment",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#environment",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-20 22:35:11 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] leaflet_2.1.2      PostcodesioR_0.3.1 geojsonio_0.11.1   sf_1.0-14         \n [5] rtweet_1.1.0       lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0     \n [9] dplyr_1.1.2        purrr_1.0.1        readr_2.1.4        tidyr_1.3.0       \n[13] tibble_3.2.1       ggplot2_3.4.2      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            xfun_0.39               htmlwidgets_1.6.2      \n [4] lattice_0.21-8          tzdb_0.4.0              leaflet.providers_1.9.0\n [7] crosstalk_1.2.0         vctrs_0.6.3             tools_4.3.1            \n[10] generics_0.1.3          curl_5.0.1              proxy_0.4-27           \n[13] fansi_1.0.4             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] assertthat_0.2.1        lifecycle_1.0.3         compiler_4.3.1         \n[19] munsell_0.5.0           fontawesome_0.5.1       jqr_1.2.3              \n[22] htmltools_0.5.5         class_7.3-22            yaml_2.3.7             \n[25] lazyeval_0.2.2          crayon_1.5.2            pillar_1.9.0           \n[28] ellipsis_0.3.2          classInt_0.4-9          tidyselect_1.2.0       \n[31] digest_0.6.33           stringi_1.7.12          fastmap_1.1.1          \n[34] grid_4.3.1              colorspace_2.1-0        cli_3.6.1              \n[37] magrittr_2.0.3          emo_0.0.0.9000          crul_1.4.0             \n[40] utf8_1.2.3              e1071_1.7-13            withr_2.5.0            \n[43] scales_1.2.1            sp_2.0-0                timechange_0.2.0       \n[46] httr_1.4.6              rmarkdown_2.23          hms_1.1.3              \n[49] evaluate_0.21           knitr_1.43.1            V8_4.3.3               \n[52] geojson_0.3.4           rlang_1.1.1             Rcpp_1.0.11            \n[55] glue_1.6.2              DBI_1.1.3               httpcode_0.3.0         \n[58] geojsonsf_2.0.3         rstudioapi_0.15.0       jsonlite_1.8.7         \n[61] R6_2.5.1                units_0.8-2"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#footnotes",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#footnotes",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’m going to assume this is also a wrestling move.↩︎"
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#tldr",
    "href": "posts/2022-03-15-renv-profiles/index.html#tldr",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "tl;dr",
    "text": "tl;dr\nI think you can use the {renv} package to create separate reproducible environment profiles for each of your {distill} blog posts."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#profiled",
    "href": "posts/2022-03-15-renv-profiles/index.html#profiled",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Profiled",
    "text": "Profiled\nFunctionality comes and goes in R packages. How do you deal with that in the context of a blog built with R? What if you need to go back and change something in a post from four years ago?1\nI built a demo {distill} blog to test whether the {renv} package might be a viable solution for reproducibility on a post-by-post basis.\n{renv} is a package by Kevin Ushey that records your dependencies in a text ‘lockfile’. It typically works on the scale of a whole project, but since version 0.13.0 you can have multiple profiles within a given project.\nI think this means that each post can have its own profile with its own distinct set of packages and package versions.\nThat means you can easily recreate a specific environment for a given post at a given time if you need to alter and re-render it in future."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#example",
    "href": "posts/2022-03-15-renv-profiles/index.html#example",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Example",
    "text": "Example\nI’m presenting this here as a theory, really, but I’ve also made a demo blog to try it out. It seems to work.\nThere are two posts on the demo blog. They both use the {dplyr} package, but one depends on an old version (0.8.5) and one depends on the current version (1.0.8).\nUsing {renv} profiles means that these package versions don’t interfere with each other.\nThe post depending on the older {dplyr} version can’t access the across() function, but the post depending on the newer {dplyr} version can use across().\nIn other words, the environments associated with the profiles for each post are totally isolated from each other."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#how-to",
    "href": "posts/2022-03-15-renv-profiles/index.html#how-to",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "How to",
    "text": "How to\nOf course, you first need a blog. I used {distill}2 for the demo, a package by JJ Allaire, Rich Iannone, Alison Presmanes Hill and Yihui Xie. You can follow the guidance from RStudio, but basically:\n\nCreate your blog with distill::create_blog()\nBuild it with rmarkdown::render_site() (or ‘Build Website’ from the Build pane of RStudio)\nInitiate a reproducible environment for the blog as a whole with renv::init()\n\nAnd then a new-post workflow could look like this:\n\nCreate a new post with distill_create_post()\nActivate a profile for the new post with renv::activate(), providing a unique name to the profile argument (I suggest the post’s folder name as seen in the blog’s _posts/ folder)\nInstall the packages you need for the post with renv::install()\nCapture the dependencies in the profile’s lockfile with renv::snapshot()\n\nIn code, that might look a bit like this:\n\ndistill::create_post(\"new-post\")\n\nrenv::activate(profile = \"YYYY-MM-DD-new-post\")\n\nrenv::install(\n  \"distill\",\n  \"rmarkdown\",\n  \"palmerpenguins\",\n  \"dplyr\"\n)\n\nrenv::snapshot()\n\nFor the demo blog, I called the two profiles ‘2022-03-14-dplyr-085’ and ‘2022-03-14-dplyr-108’, which you can see in the renv/profiles/ folder of the project repo.\nThese are named uniquely for the two separate folders in the _posts/ directory that contain each post’s files. This naming structure should make it easy to remember the profile associated with each post.\nAs I worked on the posts, I switched between the two profiles with renv::activate(), passing the relevant profile name to the profile argument.\nNote that passing NULL as the profile argument means you switch to the default profile associated with the project as a whole, i.e. when you ran renv::init()."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#yeah-but",
    "href": "posts/2022-03-15-renv-profiles/index.html#yeah-but",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Yeah, but?",
    "text": "Yeah, but?\nThere are obvious pros and cons to this approach.\nFor example, maybe it’s a bit too dependent on the user: they have to remember to switch between the profiles, etc.\nAnd I don’t think you can properly rebuild the site again with rmarkdown::render_site(), because this function will run based only the currently active {renv} profile, rather than rendering each post in the context of its own specific profile.\nBut ultimately isn’t it worthwhile to be able to rebuild a post in future if you need to change or update something? Maybe.\nI’d be interested to hear other criticisms, especially before I try and use this approach for real.\nMeanwhile, I know that Danielle Navarro has approached this with a more thought-out and sophisticated approach and has created a work-in-progress package called {refinery} to help build a separate environment for each post in a {distill} blog.\nIn general, Danielle’s blog does a brilliant job of explaining the problem of blog reproducibility and the technicals behind it. I suggest you read that post if you want to know more."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#environment",
    "href": "posts/2022-03-15-renv-profiles/index.html#environment",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#footnotes",
    "href": "posts/2022-03-15-renv-profiles/index.html#footnotes",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, I’m thinking about this because this blog is nearly four years old and I’ve had some headaches trying to rebuild posts from that long ago.↩︎\nThis site is built with {blogdown} rather than {distill}, so I’m using this post as a chance to learn a bit more about it. {distill} has also become quite popular in the R community, so it may be helpful for a wider readership if I use it in this demo.↩︎"
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#captains-log",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#captains-log",
    "title": "R Trek: exploring stardates",
    "section": "Captain’s log",
    "text": "Captain’s log\n\nStar date 71750.51. Our mission is to use R statistical software to extract star dates mentioned in the captain’s log from the scripts of Star Trek: The Next Generation and observe their progression over the course of the show’s seven seasons. There appears to be some mismatch in the frequency of digits after the decimal point – could this indicate poor ability to choose random numbers? Or something more sinister? We shall venture deep into uncharted territory for answers…\n\nWe’re going to:\n\niterate reading in text files – containing ‘Star Trek: The Next Generation’ (ST:TNG) scripts – to R and then extract stardates using the {purrr} and {stringr} packages\nweb scrape episode names using the {rvest} package and join them to the stardates data\ntabulate and plot these interactively with {ggplot2}, {plotly} and {DT}\n\nAlso, very minor spoiler alert for a couple of ST:TNG episodes."
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#lieutenant-commander-data",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#lieutenant-commander-data",
    "title": "R Trek: exploring stardates",
    "section": "Lieutenant Commander Data",
    "text": "Lieutenant Commander Data\nI’m using the the Star Trek Minutiae website to access all the ST:TNG scripts as text files. You can download the scripts as zipped folder with 176 text files.\nEach episode has a dedicated URL where we can read the script from with readLines(). We can loop over each episode to get a list element per script. This will take a few moments to run.\n\n# Build URL paths to each script\nbase_url &lt;- \"https://www.st-minutiae.com/resources/scripts/\"\nep_numbers &lt;- 102:277  # ep 1 & 2 combined, so starts at 102\nep_paths &lt;- paste0(base_url, ep_numbers, \".txt\")\n\n# Preallocate a list to fill with each script\nscripts &lt;- vector(\"list\", length(ep_numbers))\nnames(scripts) &lt;- ep_numbers\n\n# For each URL path, read the script and add to the list\nfor (ep in seq_along(ep_paths)) {\n  txt &lt;- readLines(ep_paths[ep], skipNul = TRUE)\n  ep_num &lt;- tools::file_path_sans_ext(basename(ep_paths[ep]))\n  scripts[[ep_num]] &lt;- txt\n}\n\nWe can take a look at some example lines from the title page of the first script.\n\nscripts[[\"102\"]][17:24]\n\n[1] \"                STAR TREK: THE NEXT GENERATION \"\n[2] \"                              \"                 \n[3] \"                    \\\"Encounter at Farpoint\\\" \" \n[4] \"                              \"                 \n[5] \"                              by \"              \n[6] \"                         D.C. Fontana \"         \n[7] \"                              and \"             \n[8] \"                       Gene Roddenberry \"       \n\n\nOur first example of a star date is in the Captain’s log voiceover in line 47 of the first script. (The \\t denotes tab space.)\n\nscripts[[\"102\"]][46:47]\n\n[1] \"\\t\\t\\t\\t\\tPICARD V.O.\"                 \n[2] \"\\t\\t\\tCaptain's log, stardate 42353.7.\""
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#engage",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#engage",
    "title": "R Trek: exploring stardates",
    "section": "Engage!",
    "text": "Engage!\nWe want to extract stardate strings from each script in our list. As you can see from Picard’s voiceover above, these are given in the form ‘XXXXX.X’, where each X is a digit.\nWe can extract these with str_extract_all() from the {stringr} package, using a regular expression (regex).\nOur regex is written date[:space:][[:digit:]\\\\.[:digit:]]{7}. This means:\n\nfind a string that starts with the word date and is followed by a space (i.e. date)\nwhich is followed by a string that contains digits ([:digit:]) with a period (\\\\.) inside\nwith a total length of seven characters ({7})’\n\nThis creates a list object with an element for each script that contains all the regex-matched strings.\n\nlibrary(stringr)\n\n# Collapse each script to a single element\nscripts_collapsed &lt;- lapply(scripts, paste, collapse = \" \")\n\n# Declare the regex\nstardate_regex &lt;- \"date[:space:][[:digit:]\\\\.[:digit:]]{7}\"\n\n# For each script, extract all the stardates\nstardate_extract &lt;- lapply(\n  scripts_collapsed, \n  function(script) str_extract_all(script, stardate_regex)[[1]]\n)\n\nstardate_extract[1:3]\n\n$`102`\n[1] \"date 42353.7\" \"date 42354.1\" \"date 42354.2\" \"date 42354.7\" \"date 42372.5\"\n\n$`103`\n[1] \"date 41209.2\" \"date 41209.3\"\n\n$`104`\n[1] \"date 41235.2\" \"date 41235.3\"\n\n\nWe’re now going to make the data into a tidy dataframe and clean it up so it’s easier to work with. We can use some tidyverse packages for this.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tibble)\nlibrary(tidyr)\n\nstardate_tidy &lt;- stardate_extract %&gt;% \n  enframe() %&gt;%  # list to dataframe (one row per episode)\n  unnest(cols = value) %&gt;%  # dataframe with one row per stardate\n  transmute(  # create columns and retain only these\n    episode = as.numeric(name),\n    stardate = str_replace(value, \"date \", \"\")\n  ) %&gt;%\n  mutate(\n    stardate = str_replace(stardate, \"\\\\.\\\\.$\", \"\"),\n    stardate = as.numeric(stardate)\n  )\n\nhead(stardate_tidy)\n\n# A tibble: 6 × 2\n  episode stardate\n    &lt;dbl&gt;    &lt;dbl&gt;\n1     102   42354.\n2     102   42354.\n3     102   42354.\n4     102   42355.\n5     102   42372.\n6     103   41209.\n\n\nNow we can add a couple more columns for convenience: each episode’s season number and the number after the decimal point in each stardate.\n\nstardate_tidy_plus &lt;- stardate_tidy %&gt;% \n  mutate(\n    season = case_when(\n      episode %in% 102:126 ~ 1,\n      episode %in% 127:148 ~ 2,\n      episode %in% 149:174 ~ 3,\n      episode %in% 175:200 ~ 4,\n      episode %in% 201:226 ~ 5,\n      episode %in% 227:252 ~ 6,\n      episode %in% 253:277 ~ 7\n    ),\n    stardate_decimal = str_sub(stardate, 7, 7)  # 7th character is the decimal\n  )\n\nhead(stardate_tidy_plus)\n\n# A tibble: 6 × 4\n  episode stardate season stardate_decimal\n    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           \n1     102   42354.      1 7               \n2     102   42354.      1 1               \n3     102   42354.      1 2               \n4     102   42355.      1 7               \n5     102   42372.      1 5               \n6     103   41209.      1 2"
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#prepare-a-scanner-probe",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#prepare-a-scanner-probe",
    "title": "R Trek: exploring stardates",
    "section": "Prepare a scanner probe",
    "text": "Prepare a scanner probe\nWe could extract episode names from the scripts, but another option is to scrape them from the ST:TNG episode guide on Wikipedia.\nIf you visit that link, you’ll notice that the tables of episodes actually give a stardate, but they only provide one per episode – our script-scraping shows that many episodes have multiple instances of stardates.\nWe can use the {rvest} package by Hadley Wickham to perform the scrape. This works by supplying a website address and the path of the thing we want to extract – the episode name column of tables on the Wikipedia page. I used SelectorGadget – a point-and-click tool for finding the CSS selectors for elements of webpages – for this column in each of the tables on the Wikipedia page (.wikiepisodetable tr &gt; :nth-child(3)). A short how-to vignette is available for {rvest} + SelectorGadget.\n\nlibrary(rvest)\n\n# store website address\ntng_ep_wiki &lt;- read_html(\n  \"https://en.wikipedia.org/wiki/List_of_Star_Trek:_The_Next_Generation_episodes\"\n)\n\n# extract and tidy\ntng_ep_names &lt;- tng_ep_wiki %&gt;%  # website address\n  html_nodes(\".wikiepisodetable tr &gt; :nth-child(3)\") %&gt;%  # via SelectorGadget\n  html_text() %&gt;%  # extract text\n  tibble() %&gt;%  # to dataframe\n  rename(episode_title = \".\") %&gt;%  # sensible column name\n  filter(episode_title != \"Title\") %&gt;%  # remove table headers\n  mutate(episode = row_number() + 101)  # episode number (join key)\n\nhead(tng_ep_names)\n\n# A tibble: 6 × 2\n  episode_title                      episode\n  &lt;chr&gt;                                &lt;dbl&gt;\n1 \"\\\"Encounter at Farpoint\\\"\"            102\n2 \"\\\"The Naked Now\\\"\"                    103\n3 \"\\\"Code of Honor\\\"\"                    104\n4 \"\\\"The Last Outpost\\\"\"                 105\n5 \"\\\"Where No One Has Gone Before\\\"\"     106\n6 \"\\\"Lonely Among Us\\\"\"                  107\n\n\nSo now we can join the episode names to the dataframe generated from the scripts. This gives us a table with a row per stardate extracted, with its associated season, episode number and episode name.\n\nstardate_tidy_names &lt;- stardate_tidy_plus %&gt;%\n  left_join(tng_ep_names, by = \"episode\") %&gt;% \n  select(season, episode, episode_title, stardate, stardate_decimal)\n\nWe can make these data into an interactive table with the DT::datatable() htmlwidget.\n\nlibrary(DT)\n\ndatatable(\n  stardate_tidy_names,\n  rownames = FALSE,\n  options = list(pageLength = 5, autoWidth = TRUE)\n)\n\n\n\n\n\n\nSo that’s a searchable list of all the stardates in each episode."
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#on-screen",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#on-screen",
    "title": "R Trek: exploring stardates",
    "section": "On screen",
    "text": "On screen\nLet’s visualise the stardates by episode.\nWe can make this interactive using the {plotly} package – another htmlwidget for R – that conveniently has the function ggplotly() that can turn a ggplot object into an interactive plot. You can hover over each point to find out more information about it.\nObviously there’s a package ({ggsci}) that contains a discrete colour scale based on the shirts of the Enterprise crew. Obviously we’ll use that here.\n\nlibrary(ggplot2)  # basic plotting\nlibrary(plotly, warn.conflicts = FALSE)  # make plot interactive\nlibrary(ggsci)  # star trek colour scale\nlibrary(ggthemes)  # dark plot theme\n\n# create basic plot\nstardate_dotplot &lt;- stardate_tidy_names %&gt;% \n  mutate(season = as.character(season)) %&gt;%\n  ggplot() +\n  geom_point(  # dotplot\n    aes(\n      x = episode - 100,\n      y = stardate,\n      color = season,  # each season gets own colour\n      group = episode_title\n    )\n  ) +\n  labs(title = \"Stardates are almost (but not quite) chronological\") +\n  theme_solarized_2(light = FALSE) +  # dark background\n  theme(legend.position = \"none\") +\n  scale_color_startrek()  # Star Trek uniform colours\n\nWe can make this interactive with {plotly} You can hover over the points to see details in a tooltip and use the Plotly tools that appear on hover in the top-right to zoom, download, etc.\n\n# make plot interactive\nstardate_dotplot %&gt;% \n  ggplotly() %&gt;% \n  layout(margin = list(l = 75))  # adjust margin to fit y-axis label\n\n\n\n\n\nSo there were some non-chronological stardates between episodes of the first and second series and at the beginning of the third, but the stardate-episode relationship became more linear after that.\nThree points seem to be anomalous with stardates well before the present time period of the episode. Without spoiling them (too much), we can see that each of these episodes takes place in, or references, the past.\n‘Identity Crisis’ (season 4, episode 91, stardate 40164.7) takes place partly in the past:\n\nscripts[[91]][127:129]\n\n[1] \"\\tGEORDI moves into view, holding a Tricorder. (Note:\"  \n[2] \"\\tGeordi is younger here, wearing a slightly different,\"\n[3] \"\\tearlier version of his VISOR.)\"                       \n\n\n‘Dark Page’ (season 7, episode 158, stardate 30620.1) has a scene involving a diary:\n\nscripts[[158]][c(2221:2224, 2233:2235)]\n\n[1] \"\\t\\t\\t\\t\\tTROI\"                         \n[2] \"\\t\\t\\tThere's a lot to review. My\"      \n[3] \"\\t\\t\\tmother's kept a journal since she\"\n[4] \"\\t\\t\\twas first married...\"             \n[5] \"\\t\\t\\t\\t\\tPICARD\"                       \n[6] \"\\t\\t\\tThe first entry seems to be\"      \n[7] \"\\t\\t\\tStardate 30620.1.\"                \n\n\n‘All Good Things’ (season 7, episode 176, stardate 41153.7) involves some time travel for Captain Picard:\n\nscripts[[176]][1561:1569]\n\n[1] \"\\t\\t\\t\\t\\tPICARD (V.O.)\"                 \n[2] \"\\t\\t\\tPersonal Log: Stardate 41153.7.\"   \n[3] \"\\t\\t\\tRecorded under security lockout\"   \n[4] \"\\t\\t\\tOmega three-two-seven. I have\"     \n[5] \"\\t\\t\\tdecided not to inform this crew of\"\n[6] \"\\t\\t\\tmy experiences. If it's true that\" \n[7] \"\\t\\t\\tI've travelled to the past, I\"     \n[8] \"\\t\\t\\tcannot risk giving them\"           \n[9] \"\\t\\t\\tforeknowledge of what's to come.\""
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#speculate",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#speculate",
    "title": "R Trek: exploring stardates",
    "section": "Speculate",
    "text": "Speculate\nSo stardates are more or less chronological across the duration of ST:TNG’s seven series, implying that the writers had a system in place. A few wobbles in consistency appear during the first few season suggest that it took some time to get this right. None of this is new information (see the links in the ‘Open Channel!’ section below).\nIt seems the vast majority of episodes take place in the programme’s present with a few exceptions. We may have missed some forays through time simply because the stardate was unknown or unmentioned."
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#open-channel",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#open-channel",
    "title": "R Trek: exploring stardates",
    "section": "Open channel",
    "text": "Open channel\nOnly too late did I realise that there is an RTrek GitHub organisation with a Star Trek package, TNG datasets and some other functions.\nA selection of further reading:\n\n‘Memory Alpha is a collaborative project to create the most definitive, accurate, and accessible encyclopedia and reference for everything related to Star Trek’, including stardates\n‘The STArchive is home to the… Ships and Locations lists… [and] a few other technical FAQs’, including a deep-dive into the theories in a Stardates in Star Trek FAQ\nTrekguide’s take on the messiness of stardates also includes a stardate converter\nThere’s a handy universal stardate converter at Redirected Insanity\nThe scripts were downloaded from Star Trek Minutiae, a site that has ‘obscure references and little-known facts’ and ‘explore[s] and expand[s] the wondrous multiverse of Star Trek’\nA simpler guide to stardates can be found on Mentalfloss\nYou can find the full list of The Next Generation episodes on Wikipedia"
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#full-stop",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#full-stop",
    "title": "R Trek: exploring stardates",
    "section": "Full stop!",
    "text": "Full stop!"
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#environment",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#environment",
    "title": "R Trek: exploring stardates",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-09 23:26:14 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggthemes_4.2.4 ggsci_3.0.0    plotly_4.10.2  ggplot2_3.4.2  DT_0.28       \n [6] rvest_1.0.3    tidyr_1.3.0    tibble_3.2.1   dplyr_1.1.2    stringr_1.5.0 \n\nloaded via a namespace (and not attached):\n [1] sass_0.4.7        utf8_1.2.3        generics_0.1.3    xml2_1.3.5       \n [5] stringi_1.7.12    digest_0.6.33     magrittr_2.0.3    evaluate_0.21    \n [9] grid_4.3.1        fastmap_1.1.1     jsonlite_1.8.7    httr_1.4.6       \n[13] purrr_1.0.1       fansi_1.0.4       selectr_0.4-2     viridisLite_0.4.2\n[17] crosstalk_1.2.0   scales_1.2.1      lazyeval_0.2.2    jquerylib_0.1.4  \n[21] cli_3.6.1         rlang_1.1.1       ellipsis_0.3.2    munsell_0.5.0    \n[25] withr_2.5.0       cachem_1.0.8      yaml_2.3.7        tools_4.3.1      \n[29] colorspace_2.1-0  curl_5.0.1        vctrs_0.6.3       R6_2.5.1         \n[33] lifecycle_1.0.3   htmlwidgets_1.6.2 pkgconfig_2.0.3   pillar_1.9.0     \n[37] bslib_0.5.0       gtable_0.3.3      glue_1.6.2        data.table_1.14.8\n[41] xfun_0.39         tidyselect_1.2.0  rstudioapi_0.15.0 knitr_1.43.1     \n[45] htmltools_0.5.5   labeling_0.4.2    rmarkdown_2.23    compiler_4.3.1"
  },
  {
    "objectID": "posts/2018-04-14-r-trek-exploring-stardates/index.html#footnotes",
    "href": "posts/2018-04-14-r-trek-exploring-stardates/index.html#footnotes",
    "title": "R Trek: exploring stardates",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe star date for today’s date (14 April 2018) as calculated using the trekguide.com method; this ‘would be the stardate of this week’s episode if The Next Generation and its spinoffs were still in production’.↩︎"
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html",
    "title": "Friendship ended with Google Analytics",
    "section": "",
    "text": "mudasir.jpg"
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#tldr",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#tldr",
    "title": "Friendship ended with Google Analytics",
    "section": "tl;dr",
    "text": "tl;dr\nThis blog now uses GoatCounter instead of Google Analytics. GoatCounter is a lightweight and unobtrusive site-visit counter made by developer Martin Tournoij.\n\n Note\nAs of November 2023, I no longer use Goatcounter or any other visitor-counting service."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#do-blogposts-dream-of-electric-goats",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#do-blogposts-dream-of-electric-goats",
    "title": "Friendship ended with Google Analytics",
    "section": "Do blogposts dream of electric goats?",
    "text": "Do blogposts dream of electric goats?\nI write posts on this blog for me and for other learners. It’s great if people find the content useful or interesting.\nBut I don’t and never will make money from this site, so why would I care how many visits it gets?\nA highly-viewed post indicates to me that the topic is worth talking about. It’s a signal that it might be worth writing more about that thing in future. Popular posts might also need updating over time to keep the information up to date.\nSo I think I have a use case. Except I don’t want to ‘track’ people; I just want to count visits and views."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#friendship-ended",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#friendship-ended",
    "title": "Friendship ended with Google Analytics",
    "section": "Friendship ended",
    "text": "Friendship ended\nI’ve been using Google Analytics for this blog since it began in April 2018. Why? My naïve reasons were that it’s free, it’s ubiquitous and it’s easily implemented in {blogdown}.\nIt’s massively bloated for my use case though. Acquisition reports, revenue per user and cohort analysis are not relevant to me. And I don’t even know what they mean.\nMore importantly, I’m uncomfortable with various privacy concerns around the company and platform. I don’t need or want you to be the product.\nThis change has been a long time coming and follows my earlier removal of the Disqus comment platform, thanks to a Maëlle Salmon post."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#new-best-friend",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#new-best-friend",
    "title": "Friendship ended with Google Analytics",
    "section": "New best friend",
    "text": "New best friend\nA number of alternatives are available,1 but I chose GoatCounter by independent developer Martin Tournoij. Why?\nTo summarise, the large type at the top of the GoatCounter home page says:\n\nEasy web analytics. No tracking of personal data.\n\nWhat does that encompass?\n\n\n\nWhat\nExplain\n\n\n\n\nPrivacy\nGoatCounter doesn’t collect personally-identifiable data and as such it ‘probably doesn’t require a GDPR consent notice’.\n\n\nSimple web interface\nA clean interface with focus on visits and viewers over time (see a live demo).\n\n\nTransparent\nGoatCounter is open source and the creator is open about comparisons to other products.\n\n\nThoughtful\nThe creator has written openly about the rationale and has considered users of assistive tech.\n\n\nFree\nWith paid plans or donations available (Patreon, GitHub Sponsors).\n\n\nLightweight\nIt’s less than 3 kb."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#herding-goatcounter",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#herding-goatcounter",
    "title": "Friendship ended with Google Analytics",
    "section": "Herding GoatCounter",
    "text": "Herding GoatCounter\nSwitching to GoatCounter was straightforward.\nThis blog was created with the R package {blogdown}, which is built on the Hugo static site generator, and it’s deployed via Netlify. Your mileage may vary, but there were basically three steps:\n\nRemove the Google Analytics token from the site’s config.toml file.\nCreate a GoatCounter account.\nAdd a single script tag to the &lt;body&gt; of your site2.\n\nFor that last step I used a special Netlify feature that inserts code snippets into the HTML of your site on deployment.3 I didn’t have to worry about where to put it in the code of the site.\n\n\n\nAnalytics straight into the vein.\n\n\nYour stats will then be available from a URL in the form https://yoursite.goatcounter.com, which you set during the sign-up process.\nNow you can start counting sheep. Er… goats."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#greatest-of-all-time-goat",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#greatest-of-all-time-goat",
    "title": "Friendship ended with Google Analytics",
    "section": "Greatest Of All Time (GOAT)",
    "text": "Greatest Of All Time (GOAT)\nThe switch does mean I’ll lose cumulative view counts for posts that already exist, but I’m not bothered about that. I can always export the Google Analytics data and manually add it to GoatCounter’s counts.\nFor interest, here’s the most viewed posts as counted by Google Analytics:\n\nRepaying Tom Nook with {R6} (Apr 2020)\nPackages that Sparked Joy in 2019 (Dec 2019)\nPackage a {xaringan} template (May 2019)\nMail merge with R and Dawson’s Creek (Jun 2018)\nHow do you pronounce {dplyr}? (Sep 2019)\n\nIn particular, the post about {R6} is a good example of something I wanted to learn and then blog about for posterity. I think the timing helped in people viewing it, since Animal Crossing: New Horizons had just been released to great fanfare. To illustrate the ‘zeitgeistiness’, this post had the highest view spike of any post and has settled down a great deal since then.\nThe ‘mail merge’ post is a good example of that classic David Robinson tweet:\n\nWhen you’ve written the same code 3 times, write a function. When you’ve given the same in-person advice 3 times, write a blog post\n\nGiven its popularity, I also decided to overhaul it to make it more simple and accessible. It also led to a later post on parameterised R Markdown reports, which I think is actually the better solution in most cases.\nI wouldn’t have known any of this without having a record of page views, but the method for collecting that data no longer grinds my goat."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#environment",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#environment",
    "title": "Friendship ended with Google Analytics",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-11-26 15:40:57 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.2 evaluate_0.23"
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#footnotes",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#footnotes",
    "title": "Friendship ended with Google Analytics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can read about some further considerations in a blog by David Papandrew.↩︎\nThis is provided to you by GoatCounter when you set up an account, but it’s just in the form &lt;script data-goatcounter=\"https://yoursite.goatcounter.com/count\" async src=\"//gc.zgo.at/count.js\"&gt;&lt;/script&gt;.↩︎\nThanks to a post by Max.↩︎"
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html",
    "href": "posts/2023-11-25-kanto-graph/index.html",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "",
    "text": "This is a preview."
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#tldr",
    "href": "posts/2023-11-25-kanto-graph/index.html#tldr",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "tl;dr",
    "text": "tl;dr\nI extracted data from the disassembled code of Pokémon Red to create an interactive graph of the game’s locations and their connections. You can jump to the graph below.\n\n Note\nCoincidentally, a few days after posting this, someone posted to Hacker News a non-R implementation by Peter Hajas from a few years ago. I should’ve guessed!"
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#kanto",
    "href": "posts/2023-11-25-kanto-graph/index.html#kanto",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Kanto",
    "text": "Kanto\nI wrote a while back about using the wonderful locator() function to extract coordinates from fictitious maps. In that example I used the Kanto region from the original Pokémon games.\nToday I’m back with the same map1, but we’re going to be far more methodical and abstract: we’re going to extract data from the underlying game files to build a graph that describes all the locations and connections between them.\nThis is made possible by the ‘pret’ collaborative, who have reverse-engineered, or ‘disassembled’, a number of Pokémon games. This is interesting for digi-archaeological reasons2, but also for our frivolous purposes."
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#assemble",
    "href": "posts/2023-11-25-kanto-graph/index.html#assemble",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Assemble",
    "text": "Assemble\nTo get a copy of the game’s3 disassembled code, go to the pret/pokered GitHub repo, click the ‘Code’ button, then ‘Download as zip’ and finally unzip the file on your computer.\nWe’re interested in two subfolders: /data/maps/objects/ and /data/maps/headers/. These both contain one file of Assembly code per named location in the game, like AgathasRoom.asm and Bikeshop.asm. We’ll be handling these as simple text files.\nThe ‘objects’ files contain information required to set up things like sprites and text for each location in the game. The example below is for the starting area: Pallet Town. For our purposes, we care about the warp_events, which indicate that you can step on a tile and be warped somewhere else. For example, standing on the door tile at tile location 5, 5 would warp you to REDS_HOUSE_1F, i.e. the first floor of the player’s house.\nobject_const_def\nconst_export PALLETTOWN_OAK\nconst_export PALLETTOWN_GIRL\nconst_export PALLETTOWN_FISHER\n\nPalletTown_Object:\ndb $b ; border block\n\ndef_warp_events\nwarp_event  5,  5, REDS_HOUSE_1F, 1\nwarp_event 13,  5, BLUES_HOUSE, 1\nwarp_event 12, 11, OAKS_LAB, 2\n\ndef_bg_events\nbg_event 13, 13, TEXT_PALLETTOWN_OAKSLAB_SIGN\nbg_event  7,  9, TEXT_PALLETTOWN_SIGN\nbg_event  3,  5, TEXT_PALLETTOWN_PLAYERSHOUSE_SIGN\nbg_event 11,  5, TEXT_PALLETTOWN_RIVALSHOUSE_SIGN\n\ndef_object_events\nobject_event  8,  5, SPRITE_OAK, STAY, NONE, TEXT_PALLETTOWN_OAK\nobject_event  3,  8, SPRITE_GIRL, WALK, ANY_DIR, TEXT_PALLETTOWN_GIRL\nobject_event 11, 14, SPRITE_FISHER, WALK, ANY_DIR, TEXT_PALLETTOWN_FISHER\n\ndef_warps_to PALLET_TOWN\nSome terminology for graphs: the game’s locations are ‘nodes’ connected by common ‘edges’. So Pallet Town and Red’s House are nodes that share an edge.\nNote that warping isn’t the only thing that creates an edge between two nodes. If we look in the ‘headers’ file for Pallet Town, you can see that some locations have a simple connection parameter: you can just walk north of Pallet Town to Route 1 (the road to Viridian City) or approach from the south along Route 21 (from Cinnabar Island). Yes, ‘routes’ connect two places, but routes themselves act as nodes in this demo.\nmap_header PalletTown, PALLET_TOWN, OVERWORLD, NORTH | SOUTH\nconnection north, Route1, ROUTE_1, 0\nconnection south, Route21, ROUTE_21, 0\nend_map_header\nThe headers file is useful to us in another way: it maps location names from the ‘PalletTown’ format (used in .asm filenames) to the ‘PALLET_TOWN’ format (as referenced within files). This knowledge will help us to better handle the data as we progress."
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#prepare-data",
    "href": "posts/2023-11-25-kanto-graph/index.html#prepare-data",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Prepare data",
    "text": "Prepare data\nSo let’s crack open the data and use some base R for corralling. Note that absolutely nothing here is optimised (or even written well in the first place), but regular readers will be used to that.\n\nPrepare functions\nTo begin, I’ve made a few helper functions to extract and wrangle the data that we need:\n\nget_file_paths() to return the filepaths for all the Assembly files (.asm) we need\nget_warps() to extract the warps in the text of each objects file\nget_connections() to extract and wrangle all the connections from the headers files\ncreate_names_lookup() to map the UpperCamelCase and SCREAMING_SNAKE_CASE name variants for each location\n\n\n\nClick for function definitions.\n\n\nget_file_paths &lt;- function(\n    dir = \"~/Documents/data/pokered-master/data/maps\",\n    type = c(\"objects\", \"headers\")\n) {\n  path &lt;- file.path(dir, type)\n  list.files(path, pattern = \".asm$\", full.names = TRUE)\n}\n\nget_warps &lt;- function(objects_content) {\n  warp_string &lt;- \"warp_event \"\n  warp_events &lt;- objects_content[grepl(warp_string, objects_content)]\n  warp_events &lt;- strsplit(warp_events, \", \")\n  warp_events &lt;- lapply(warp_events, `[[`, 3)  # third element is warps\n  unique(unlist(warp_events))  # vector of unique locations\n}\n\nget_connections &lt;- function(headers_content) {\n  con_string &lt;- \"connection\"\n  con_detected &lt;- headers_content[grepl(con_string, headers_content)]\n  con_isolated &lt;- lapply(con_detected, \\(x) x[which(grepl(con_string, x))])\n  lapply(con_isolated, \\(x) unlist(lapply(strsplit(x, \", \"), `[[`, 3)))\n}\n\ncreate_names_lookup &lt;- function(headers_content) {\n  headers_split &lt;- strsplit(headers_content, \",\")[[1]]\n  headers_split &lt;- headers_split[1:2]\n  name_pair &lt;- gsub(\"map_header \", \"\", trimws(headers_split))\n  setNames(name_pair[1], name_pair[2])\n}\n\n\n\n\nExtract connections\nNow down to business. We’ll read the text content of each headers file into a list, then name these elements using the SCREAMING_SNAKE_CASE name for each location.\n\nheaders_files &lt;- get_file_paths(type = \"headers\")\nheaders_content &lt;- lapply(headers_files, readLines)\nheaders_lookup &lt;- unlist(lapply(headers_content, create_names_lookup))\nnames(headers_content) &lt;- names(headers_lookup)\n\nHere’s how Pallet Town looks in this format:\n\nheaders_content[\"PALLET_TOWN\"]\n\n$PALLET_TOWN\n[1] \"\\tmap_header PalletTown, PALLET_TOWN, OVERWORLD, NORTH | SOUTH\"\n[2] \"\\tconnection north, Route1, ROUTE_1, 0\"                        \n[3] \"\\tconnection south, Route21, ROUTE_21, 0\"                      \n[4] \"\\tend_map_header\"                                              \n\n\nNow we can take these lines of text and extract the node pairs that have an edge due to a ‘connection’ between them.\n\nconns &lt;- get_connections(headers_content)\nconns_df &lt;- stack(conns)\nconns_df &lt;- conns_df[, c(\"ind\", \"values\")]\nnames(conns_df) &lt;- c(\"from\", \"to\")\nconns_df[[\"from\"]] &lt;- as.character(conns_df[[\"from\"]])\nhead(conns_df)\n\n           from       to\n1  CELADON_CITY ROUTE_16\n2  CELADON_CITY  ROUTE_7\n3 CERULEAN_CITY ROUTE_24\n4 CERULEAN_CITY  ROUTE_5\n5 CERULEAN_CITY  ROUTE_4\n6 CERULEAN_CITY  ROUTE_9\n\n\n\n\nExtract warps\nSimilarly, we can get the warp data in a node-pair data frame as well. The first step is to read the text of each objects file into a list.\n\nobj_files &lt;- get_file_paths(type = \"objects\")\nobj_names &lt;- gsub(\".asm\", \"\", basename(obj_files))\nobj_content &lt;- lapply(obj_files, readLines) |&gt; setNames(names(headers_lookup))\nobj_content[\"PALLET_TOWN\"]\n\n$PALLET_TOWN\n [1] \"\\tobject_const_def\"                                                         \n [2] \"\\tconst_export PALLETTOWN_OAK\"                                              \n [3] \"\\tconst_export PALLETTOWN_GIRL\"                                             \n [4] \"\\tconst_export PALLETTOWN_FISHER\"                                           \n [5] \"\"                                                                           \n [6] \"PalletTown_Object:\"                                                         \n [7] \"\\tdb $b ; border block\"                                                     \n [8] \"\"                                                                           \n [9] \"\\tdef_warp_events\"                                                          \n[10] \"\\twarp_event  5,  5, REDS_HOUSE_1F, 1\"                                      \n[11] \"\\twarp_event 13,  5, BLUES_HOUSE, 1\"                                        \n[12] \"\\twarp_event 12, 11, OAKS_LAB, 2\"                                           \n[13] \"\"                                                                           \n[14] \"\\tdef_bg_events\"                                                            \n[15] \"\\tbg_event 13, 13, TEXT_PALLETTOWN_OAKSLAB_SIGN\"                            \n[16] \"\\tbg_event  7,  9, TEXT_PALLETTOWN_SIGN\"                                    \n[17] \"\\tbg_event  3,  5, TEXT_PALLETTOWN_PLAYERSHOUSE_SIGN\"                       \n[18] \"\\tbg_event 11,  5, TEXT_PALLETTOWN_RIVALSHOUSE_SIGN\"                        \n[19] \"\"                                                                           \n[20] \"\\tdef_object_events\"                                                        \n[21] \"\\tobject_event  8,  5, SPRITE_OAK, STAY, NONE, TEXT_PALLETTOWN_OAK\"         \n[22] \"\\tobject_event  3,  8, SPRITE_GIRL, WALK, ANY_DIR, TEXT_PALLETTOWN_GIRL\"    \n[23] \"\\tobject_event 11, 14, SPRITE_FISHER, WALK, ANY_DIR, TEXT_PALLETTOWN_FISHER\"\n[24] \"\"                                                                           \n[25] \"\\tdef_warps_to PALLET_TOWN\"                                                 \n\n\nThen we can extract the warps. Note that some warps don’t explicitly take you back where you came from. Instead the instruction is to warp to the last location. We can remove this from our data, since LAST_MAP isn’t a literal location.\n\nwarps &lt;- lapply(obj_content, get_warps)\nwarps &lt;- lapply(warps, \\(x) x[x != \"LAST_MAP\"])  # remove LAST_MAP\nwarps &lt;- warps[lengths(warps) &gt; 0]\nwarps_df &lt;- stack(warps)  # to data.frame\nwarps_df &lt;- warps_df[, c(\"ind\", \"values\")]\nnames(warps_df) &lt;- c(\"from\", \"to\")\nwarps_df[[\"from\"]] &lt;- as.character(warps_df[[\"from\"]])\nhead(warps_df)\n\n          from                 to\n1 AGATHAS_ROOM        BRUNOS_ROOM\n2 AGATHAS_ROOM        LANCES_ROOM\n3  BRUNOS_ROOM      LORELEIS_ROOM\n4  BRUNOS_ROOM       AGATHAS_ROOM\n5 CELADON_CITY    CELADON_MART_1F\n6 CELADON_CITY CELADON_MANSION_1F\n\n\n\n\nCombine all node pairs\nNow we can combine all the node pairs that share edges, whether by simple connections or warps. In this example we’re interested in combinations, rather than permutations, of node pairs4. This means that we can treat A→B and B→A as equivalent and simplify down to just A→B.\n\nedges &lt;- rbind(warps_df, conns_df)\nedges &lt;- edges[!duplicated(data.frame(t(apply(edges, 1, sort)))), ]  # https://stackoverflow.com/a/50117582\n\nWe also want a full list of the nodes, which will help us to label and filter them in the final visualisation.\n\nnodes &lt;- data.frame(id = unique(c(edges[[\"from\"]], edges[[\"to\"]])))\nnodes &lt;- nodes[order(nodes[[\"id\"]]), , drop = FALSE]"
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#visualise",
    "href": "posts/2023-11-25-kanto-graph/index.html#visualise",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Visualise",
    "text": "Visualise\n\nSet up\nThe {visNetwork} package wraps the vis.js JavaScript library, which will help output an interactive HTML graph. We just need to feed it our nodes and edges and a bunch of configuration and styling options.\nFirst some CSS to import a font that mimics the font used in the game5.\n\n@font-face {\n  font-family: 'pokemon-font';\n  src: url('resources/pokemon-font.ttf');\n}\n\n\nWhile we’re dealing with font style, we can set up a function to build a CSS style string for when we need it in the visNetwork. Obviously we’ll use red as the accent colour, given the data is for the Red version of the game6.\n\npoke_style &lt;- function(size = 16, colour = \"black\") {\n  paste0(\n    \"font-family:pokemon-font,sans-serif;\",\n    \"font-size:\", size, \"px;\",\n    \"color:\", colour, \";\"\n  )\n}\n\nNow we can build the visNetwork object with vis* functions.\n\nlibrary(visNetwork)\n\ngraph &lt;- visNetwork(\n  nodes,\n  edges,\n  width = \"100%\",\n  height = \"600px\",\n  main = list(text = \"Kanto\", style = poke_style(30)),\n  submain = list(\n    text = \"A graph of locations in PKMN Red&lt;br&gt;&lt;br&gt;\",\n    style = poke_style()\n  ),\n  footer = list(\n    text = \"Source: Nintendo and Game Freak via the pret/pokered dissassembly project\",\n    style = poke_style(8)\n  )\n) |&gt;\n  visEdges(\n    color = list(color = \"#FF7777\", highlight = \"red\", opacity = 0.5),\n    width = 3,\n    selectionWidth = 5\n  ) |&gt;\n  visNodes(\n    color = \"#FF7777\",\n    font = list(face = \"pokemon-font\", size = 14),\n    borderWidth = 0,\n    borderWidthSelected = 3,\n  ) |&gt;\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = list(\n      enabled = TRUE, \n      main = \"Select a location\",\n      style = poke_style(colour = \"red\")\n    )\n  ) |&gt;\n  visLayout(randomSeed = 150) |&gt;\n  visPhysics(\n    solver = \"barnesHut\",\n    barnesHut = list(springConstant = 0.1, gravitationalConstant = -10000)\n  )\n\n\n\nThe graph\nSo here’s the final result:\n\ngraph\n\n\n\n\n\n It can take a moment to load. You can select a node from the dropdown menu, scroll to zoom, and click on the nodes and edges themselves. The node labels will appear when you zoom in.\nIt’s interesting to see the simple radial networks around each city; the spaghetti and meatballs of Silph Co caused by all the warp tiles (also note its unused location); the long ‘tail’ from Victory Road through the Elite Four to the Hall of Fame; and the hand-like structure of the Safari Zone.\nOf course, you could spend all day tweaking things like the physics of the relationship between each node, or you could replace each node an images of its in-game sprite. I’ve chosen to keep things relatively simple because it’s bed time and I need to go and count some Mareep."
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#environment",
    "href": "posts/2023-11-25-kanto-graph/index.html#environment",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 09:56:18 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] visNetwork_2.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.41         fontawesome_0.5.2\n [5] magrittr_2.0.3    knitr_1.45        htmltools_0.5.6.1 rmarkdown_2.25   \n [9] cli_3.6.2         compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[13] ellipsis_0.3.2    evaluate_0.23     yaml_2.3.8        rlang_1.1.3      \n[17] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-11-25-kanto-graph/index.html#footnotes",
    "href": "posts/2023-11-25-kanto-graph/index.html#footnotes",
    "title": "An interactive graph of Pokémon Red locations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOh no! He’s running out of ideas!↩︎\nNot to mention that you can mess about with modding the game, like adjusting the code to set Mew as one of the starter ’mons.↩︎\nAs a diehard Blue-version enjoyer, it pains me slightly that this is the Red version. Red is the bad guy! Blue is the good guy!↩︎\nThis wrangling was actually mildly trickier than I thought it was be and so I ‘borrowed’ from StackOverflow to save time.↩︎\nI can’t actually remember where I got this exact font file from, but I know it’s available from free font sites.↩︎\nGraphic design is my passion, etc. As a colourblind person, I’m just glad they didn’t release Red and Green versions simultaneously.↩︎"
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html",
    "title": "Fix leaky pipes in R",
    "section": "",
    "text": "Data leaking from a pipe."
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#tldr",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#tldr",
    "title": "Fix leaky pipes in R",
    "section": "tl;dr",
    "text": "tl;dr\nYou can chain function calls in R with %&gt;%. There’s a few ways to catch errors in these pipelines.\n\n Note\nThis post was first published before the base pipe (|&gt;) existed. You should assume that the solutions here work for the {magrittr} pipe (%&gt;%) only.\nMore solutions have emerged since this post was published, like Antoine Fabri’s {boomer} and Sean Kross’s {mario}. I may update this post in future."
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#cest-un-pipe",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#cest-un-pipe",
    "title": "Fix leaky pipes in R",
    "section": "C’est un pipe",
    "text": "C’est un pipe\nR users will be familiar with {magrittr}’s %&gt;% (pipe) operator by now, created for Stefan Milton Bache and Hadley Wickham’s {magrittr} package and popularised by the tidyverse.\nIt lets you chain function calls. x %&gt;% y() evaluates the same way as y(x). Par exemple, avec les pingouins:\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(palmerpenguins)\n\n# Get mean mass for two \npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\npeng_pipe\n\n# A tibble: 2 × 2\n  species   mean_length\n  &lt;fct&gt;           &lt;dbl&gt;\n1 Adelie             39\n2 Chinstrap          49"
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#ce-nest-pas-debuggable",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#ce-nest-pas-debuggable",
    "title": "Fix leaky pipes in R",
    "section": "Ce n’est pas debuggable?",
    "text": "Ce n’est pas debuggable?\nNot everyone likes this approach. That’s okay. Multi-step pipes could obscure what’s happened to your data and might make debugging harder.\nI think most people create pipes interactively and check outputs as they go, or else make sensibly-lengthed chains for each ‘unit’ of wrangling (read, clean, model, etc). Hadley discusses this in the pipes chapter of the R for Data Science book.\nI’ve summarised a few solutions in this post, which can be summarised even more in this table:\n\n\n\n\n\n\n\n\n\n\n\nPackage\nDescription\nMessage\nView()\nprint()\nDebug\n\n\n\n\n{tidylog}\nConsole-printed description of changes\n✔\n✘\n✘\n✘\n\n\n{ViewPipeSteps}\nRStudio Addin: see changes to data set per step\n✘\n✔\n✔\n✘\n\n\n{tamper}\nStack trace replacement for pipe debugging\n✔\n✘\n✘\n✔\n\n\n{pipecleaner}\nRStudio Addin: ‘burst’ pipes and debug\n✘\n✘\n✘\n✔\n\n\n{magrittr}\ndebug_pipe() function\n✘\n✘\n✘\n✔\n\n\ndebug()\nR’s good old debug() function\n✘\n✘\n✘\n✔\n\n\n{pipes}\nSpecial assignment operators\n✘\n✔\n✔\n✔\n\n\nBizarro pipe\nReplace %&gt;% with -&gt;.; and observe .Last.level\n✘\n✘\n✘\n✘\n\n\n\n‘Message’ means whether it prints something informative to the console; View() and print() tell you if the data set can be viewed at each step; and ‘debug’ if it opens the debug menu."
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#ce-nest-pas-une-probleme",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#ce-nest-pas-une-probleme",
    "title": "Fix leaky pipes in R",
    "section": "Ce n’est pas une probleme?",
    "text": "Ce n’est pas une probleme?\nI’ve gathered the solutions into three categories (click to jump):\n\nSummary inspection\n\n\n{tidylog}\n{ViewPipeSteps}\n\n\nDebug mode\n\n\n{tamper}\n{pipecleaner}\n{magrittr}\ndebug()\n\n\nOperator hacking\n\n\n{pipes}\nBizarro pipe\n\n\n1. Summary inspection\nThese are packages for seeing what happened to your data set at each step of your pipeline, rather than highlighting where the problem was.\n\n1a. {tidylog}\nThe {tidylog} package by Benjamin Elbers prints to the console some summary sentences of the changes that have happened to your data after each pipe step. You can install it from CRAN:\n\ninstall.packages(\"tidylog\")\n\nMake sure you attach it after {dplyr}.\n\nlibrary(tidylog)\n\n\nAttaching package: 'tidylog'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    add_count, add_tally, anti_join, count, distinct, distinct_all,\n    distinct_at, distinct_if, filter, filter_all, filter_at, filter_if,\n    full_join, group_by, group_by_all, group_by_at, group_by_if,\n    inner_join, left_join, mutate, mutate_all, mutate_at, mutate_if,\n    relocate, rename, rename_all, rename_at, rename_if, rename_with,\n    right_join, sample_frac, sample_n, select, select_all, select_at,\n    select_if, semi_join, slice, slice_head, slice_max, slice_min,\n    slice_sample, slice_tail, summarise, summarise_all, summarise_at,\n    summarise_if, summarize, summarize_all, summarize_at, summarize_if,\n    tally, top_frac, top_n, transmute, transmute_all, transmute_at,\n    transmute_if, ungroup\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nYou can see from the output that {tidylog} masks all the {dplyr} functions. In other words, you can continue use the {dplyr} function names as usual, but {tidylog} will add a side-effect: it will print in English a summary of the changes.\n\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\nfilter: removed 124 rows (36%), 220 rows remaining\n\n\ngroup_by: one grouping variable (species)\n\n\nsummarise: now 2 rows and 2 columns, ungrouped\n\n\nmutate: changed 2 values (100%) of 'mean_length' (0 new NA)\n\n\nThis a nice passive approach. But how does this help? We can sense-check each step. For example:\n\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Cycliophora\", \"Onychophora\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\nfilter: removed all rows (100%)\n\n\ngroup_by: one grouping variable (species)\n\n\nsummarise: now 0 rows and 2 columns, ungrouped\n\n\nmutate: no changes\n\n\nDid you spot the extremely contrived error? I filtered for species that don’t exist in the data set1. This was reported as filter: removed all rows (100%) in the first step.\nI’ll unload {tidylog} before continuing so it doesn’t interfere with the other examples.\n\nunloadNamespace(\"tidylog\")\n\n\n\n1b. {ViewPipeSteps}\nThe {ViewPipeSteps} package by David Ranzolin is an RStudio Addin available from GitHub. Basically it lets you View() or print() at each step of your pipeline so you can see what’s happened to the the data set.\n\nremotes::install_github(\"daranzolin/ViewPipeSteps\")\nlibrary(ViewPipeSteps)\n\nAfter installing you can simply highlight your code and select ‘View Pipe Chain Steps’ or ‘Print Pipe Chain Steps’ from the RStudio Addins menu.\nBeware if you have lots of steps in your pipeline because it’s going to fill up your console, or a whole bunch of RStudio tabs or windows containing each cut of the data set.\n\n\n\n2. Debug mode\nThese are packages that help highlight where a problem occurred. These take you to the debug menu, which is worth reading up on if you haven’t used it before.\n\n2a. {tamper}\nGábor Csárdi’s {tamper} package makes pipe debugging easier with a simple, informative interface. The package is currently available on GitHub but is archived.\nYou set the error argument of options() to tamper once installed and loaded. From now on {tamper} will override the default stack trace report you get when an error is found. Here I’ve used a column that doesn’t exist in the data set:\n\nremotes::install_github(\"gaborcsardi/tamper\")\noptions(error = tamper::tamper)\n\npenguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_girth, na.rm = TRUE)) %&gt;%  # error here!\n  mutate(mean_length = round(mean_length))\n\nWhen there’s an error, {tamper} highlights the problematic line with an arrow. Typing ‘0’ will exit the {tamper} report; ‘1’ switches you back to the stack trace; ‘2’ will enter debug mode. Here’s how that looks in the console at first:\n## Error in mean(Sepal.Girth) : object 'Sepal.Girth' not found\n## \n## Enter 0 to exit or choose:\n## \n## 1:    Switch mode\n## 2:    Take me to the error\n## \n## 3:    penguins %&gt;%\n## 4: -&gt;   filter(., Species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;%\n## 5:      group_by(., species) %&gt;%\n## 6:      summarise(., mean_length = mean(bill_girth, na.rm = TRUE)) %&gt;%\n## 7:      mutate(., mean_length = round(mean_length))\n## \n## Selection:\n\n\n2b. {pipecleaner}\nThe {pipecleaner} package by Edward Visel is another RStudio Addin available on GitHub. It has the best name.\nYou highlight your code and select ‘debug pipeline in browser’ from the RStudio Addins menu. This ‘bursts’ your pipeline to one intermediate object per function call, then opens the debug menu. You can also simply ‘burst pipes’ from the Addins menu without debug mode.\n\nremotes::install_github(\"alistaire47/pipecleaner\")\nlibrary(pipecleaner)\n\n# Intact, original pipeline\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\n# Highlight the original pipeline and select 'debug pipeline in browser' or \n# 'burst pipes' from the RStudio Addins menu\ndot1 &lt;- filter(penguins, species %in% c(\"Adelie\", \"Chinstrap\"))\ndot2 &lt;- group_by(dot1, species)\ndot3 &lt;- summarise(dot2, mean_length = mean(bill_length_mm, na.rm = TRUE))\npeng_pipe &lt;- mutate(dot3, mean_length = round(mean_length))\n\nSo effectively it steps through each new object to report back errors. But it leaves you with multiple objects (with meaningless names) to clean up; there’s no ‘fix pipes’ option to return to your original pipeline.\n\n\n2c. {magrittr}\nSurprise: the {magrittr} package itself has the function debug_pipe() to let you see what’s being passed into the next function.\n\nlibrary(magrittr)\n\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  debug_pipe() %&gt;%\n  mutate(mean_length = round(mean_length))\n\nNot much to say about this one, but worth mentioning because %&gt;% gets re-exported in other packages2 but debug_pipe() doesn’t.\n\n\n2d. debug()\nYou can simply use R’s debug() function, as pointed out by Nathan Werth.\nYou can do this for a given function in the pipeline:\n\ndebug(summarise)\n\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %&gt;% \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\nundebug(summarise)\n\nOr you can even debug each step by setting up debug(`%&gt;%`), since the pipe is itself a function, after all.\n\n\n\n3. Operator hacking\nIt’s possible to make variant pipe operators. Maybe we don’t even need %&gt;%?\n\n3a. {pipes}\nAntoine Fabri forked the {magrittr} GitHub repo to add a bunch of %&gt;% variants that have side properties. These are available from his {pipes} package.\nA few of direct relevance to this discussion:\n\n%P&gt;% to print() the data set to the console\n%V&gt;% will View() the full data set\n%D&gt;% opens with debug menu\n\nOthers apply different functions during the piping step. There’s some nice ones for summaries, like %glimpse&gt;% and %skim&gt;%.\n\nremotes::install_github(\"moodymudskipper/pipes\")\nlibrary(pipes)\n\nAttaching package: 'pipes'\n\nThe following object is masked from 'package:dplyr':\n\n    %&gt;%\nHere’s an example of %P&gt;% that pipes forward into the next function and prints it to console.\n\npeng_pipe &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% \n  group_by(species) %P&gt;%  # note %P&gt;% operator \n  summarise(mean_length = mean(bill_length_mm, na.rm = TRUE)) %&gt;% \n  mutate(mean_length = round(mean_length))\n\nsummarise(., mean_length = mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  species   mean_length\n  &lt;fct&gt;           &lt;dbl&gt;\n1 Adelie           38.8\n2 Chinstrap        48.8\nNoe that the final output of the chain is assigned to peng_pipe. We’re seeing the printed output of the summarise() step without the following mutate() step, given where we placed the %P&gt;% operator.\nSo this one could have gone in the ‘summary inspection’ section above, but it contains more functions than for printing and viewing alone.\n\n\n3b. Bizarro pipe\nForget installing a package to get the pipe. We can create an operator that acts like a pipe but can be run so that we can check what’s happening at each step.\nJohn Mount’s solution is the ‘Bizarro pipe’, which looks like -&gt;.;. This is a simple hack that’s legitimate base R code. The -&gt;.; operator reads as ‘right-assign the left-hand side to a period and then perform the next operation’.\nThings you might be wondering:\n\nyes, you can use a -&gt; for assignment to the right\nyes, you can assign to ., but you’ll need to explicitly supply it as the data argument to the next function call in your Bizarro pipeline\nyes, you can use semi-colons in R for run-on code execution, try head(penguins); tail(penguins)\n\nThis means you can execute each line in turn and check the output. But wait: an object called . is not presented in the global environment. Not unless you check ‘Show .Last.value in environment listing’ in RStudio’s settings. Now when you run the line you’ll see the ‘.Last.value’ that’s been output.\n\npenguins -&gt;.;\nfilter(., species %in% c(\"Adelie\", \"Chinstrap\")) -&gt;.;\ngroup_by(., species) -&gt;.;\nsummarise(., mean_length = mean(bill_length_mm, na.rm = TRUE)) -&gt;.;\nmutate(., mean_length = round(mean_length)) -&gt; peng_pipe\n\nNote that the name of the object comes at the end; we’re always passing the object to the right.\nThis might confuse your colleagues, but hey, no dependencies are needed!"
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#maider",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#maider",
    "title": "Fix leaky pipes in R",
    "section": "M’aider",
    "text": "M’aider\nWhat’s your approach to this problem? What have I missed?"
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#environment",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#environment",
    "title": "Fix leaky pipes in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 20:22:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] palmerpenguins_0.1.1 dplyr_1.1.2         \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      clisymbols_1.2.0 \n [5] rlang_1.1.1       xfun_0.39         purrr_1.0.1       generics_0.1.3   \n [9] jsonlite_1.8.7    glue_1.6.2        htmltools_0.5.5   fansi_1.0.4      \n[13] rmarkdown_2.23    evaluate_0.21     tibble_3.2.1      fontawesome_0.5.1\n[17] fastmap_1.1.1     yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1   \n[21] htmlwidgets_1.6.2 pkgconfig_2.0.3   tidyr_1.3.0       rstudioapi_0.15.0\n[25] digest_0.6.33     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3       \n[29] pillar_1.9.0      magrittr_2.0.3    tools_4.3.1"
  },
  {
    "objectID": "posts/2019-04-07-fix-leaky-pipes/index.html#footnotes",
    "href": "posts/2019-04-07-fix-leaky-pipes/index.html#footnotes",
    "title": "Fix leaky pipes in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWelcome to Biology Geek Corner. Cycliophora is a phylum containing just one genus and (probably) three species. Our own phylum – Chordata – contains 55,000 species. Symbion pandora was the first cycliophoran species found in 1995, which appears to live commensally and exclusively on lobster lips. Onychophora is the velvet worm phylum that contains wee beasties that spray slime, have little adorable claws and are, surprise, kinda velvety (one species is named ‘totoro’ because of its similarity to My Neighbour Totoro’s Catbus).↩︎\nCheck out usethis::use_pipe() for re-exporting the pipe to use in your own package.↩︎"
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#tldr",
    "href": "posts/2022-01-19-keypress/index.html#tldr",
    "title": "Impress with {keypress} minigames",
    "section": "tl;dr",
    "text": "tl;dr\nThe {keypress} R package by Gábor Csárdi records input from a simple keyboard-button press. You can use this to control games, like the ones in the tiny {hokey} package."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#whaddup-gamers",
    "href": "posts/2022-01-19-keypress/index.html#whaddup-gamers",
    "title": "Impress with {keypress} minigames",
    "section": "Whaddup gameRs?",
    "text": "Whaddup gameRs?\nI’ve made some silly games in R using the {R6} package for encapsulated OOP. For example:\n\n{ActionSquirrel} a 2D action-adventure game (blog, source)\n{safar6} a text-based recreation of Pokémon’s Safari Zone (blog, source)\nan ‘Automatic Bell Dispenser’ to mimics the cash machine used in Animal Crossing: New Horizons (blog)\n\nIn {ActionSquirrel} you move a character around a 2D grid. Problem (kinda): to go up you type x$move(\"up\"), which means ‘apply the move method to the previously-initialised R6 object called x, and supply to the where argument the direction \"up\"’. A bit long-winded, eh?\nIt would be more natural to provide a single keyboard input to a game scenario, so a left-arrow press moves the player to the left, right? Right.1"
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#record-inputs",
    "href": "posts/2022-01-19-keypress/index.html#record-inputs",
    "title": "Impress with {keypress} minigames",
    "section": "Record inputs",
    "text": "Record inputs\nSure, R’s readline() can take user input, but you would literally have to type l, e, f, t and Enter, because the function doesn’t recognise key presses directly.\nThis is where Gábor Csárdi’s {keypress} package comes in. It accepts a single button press from the keyboard, including the arrow keys. It’s available on CRAN:\n\ninstall.packages(\"keypress\")\nkey &lt;- keypress::keypress()  # up arrow pressed\nkey\n\n\"up\"\n{keypress} works in the terminal but doesn’t work everywhere, such as RStudio. Use keypress::has_keypress_support() to see if it’s supported by the console you’re using. See the package README for details of the platforms supported and the keys that are accepted as input."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#minigames",
    "href": "posts/2022-01-19-keypress/index.html#minigames",
    "title": "Impress with {keypress} minigames",
    "section": "Minigames",
    "text": "Minigames\nI thought I’d try out with {keypress} with three tiny interactive games, which I’ve bundled into a pico package2 called {hokey}.\n\nremotes::install_github(\"matt-dray/hokey\")\n\nEach one takes a keypress input from keypress::keypress() to affect the game, which is just a bunch of if or while statements, basically. You can see the functions in the {hokey} package itself, if you’re a nerd.3\nThe games in order of complexity:\n\ntype(), a test of typing skills\nadventure(), a 2D side-scrollling adventure\nbattle(), a clicker-style monster smasher\n\nThese aren’t properly documented ot tested or anything. They’re just for demo’s sake.\nThe rest of this post describes the games with a dash of dry humour.\n\n1. Typing test\nHow fast you can you type randomly-selected letters?\nIn the type() game a countdown will begin and then you’ll be prompted to type one letter at a time, the total number of which can be controlled with the n argument.\nHere’s what a completed game might look like, where each letter is revealed sequentially after typing the previous one.\n\nhokey::type(n = 5)\n\n3... 2... 1... Go!\nPress 'r'! Hit!\nPress 'o'! Hit!\nPress 'f'! Hit!\nPress 'l'! 'h'? Miss!\nPress 'z'! Hit!\nEnd! 4/5 in 5.403 seconds.\nYes, three decimal places in the elapsed time so that people can be more easily ranked on speedruns.com.\n\n\n2. An adventure\nYou’ve played 2D games (e.g. Mario). You’ve played 2.5D games (e.g. Mario). You’ve played 3D games (e.g. Mario).\nYou’re thinking the future is four-dimensional Mario. But you’re wrong.\nInstead, hokey::adventure() explores the full power of moving along a one-dimensional line.\nTake control of the hero. Which is a dot. Move around the overworld. Which is a line. Simulate the lustrous points of Lineland from Edwin A Abbott’s Flatland!\n\nhokey::adventure(len = 10)\n\nPress left/right arrow keys\n--.------- \nBelow is a demo of what happens if you start the game and travel to the dangerous lands of the west (two left-key presses, resulting in you being bumped back on course), before heading for the utopian kingdom in the east (multiple right-key presses).\nThe symbol to the right of the line explains what’s happened (&lt; is left, &gt; is right, x is an illegal move, ! is a win).\nPress left/right arrow keys\n--.------- \n-.-------- &lt; \n.--------- x \n-.-------- &gt; \n--.------- &gt; \n---.------ &gt; \n----.----- &gt; \n-----.---- &gt; \n------.--- &gt; \n-------.-- &gt; \n--------.- &gt; \n---------. ! \nSuch graphics! Such dimensions!\n\n\n3. A clicker\nEver heard of Cookie Clicker? It’s a game where you click. A cookie. A whole bunch of times. Like, seriously, a whole bunch of times. Why? To win, of course.\nHere instead is a ‘presser’, where where you tap keys to vanquish randomised foes. Are there upgrades? No. Are there cool sprites? Not really. But do you click a lot? Also no, but you get to press buttons a lot.\nSo, initiate a battle with hokey::battle() and you’re faced with monstrous foes, who have terrifying randomised faces made of letters and symbols.\n\nhokey::battle(n = 3)\n\nNEW FOE! { O _ O } 10 HP \nSmash a key (I recommend Enter because of its large surface area) to deplete the foe’s hit points (HP) until they’re defeated. Each hit is printed as a period.\nNEW FOE! { O _ O } 10 HP \n..........\nVICTORY! { x _ x }  0 HP\nIncrementally more powerful foes will appear!\nNEW FOE! | - o - | 20 HP \n....................\nVICTORY! | x o x |  0 HP\n\nNEW FOE! [ ' v ' ] 30 HP \n..............................\nVICTORY! [ x v x ]  0 HP\nYou know they’re beaten because their eyes become crosses."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#game-over",
    "href": "posts/2022-01-19-keypress/index.html#game-over",
    "title": "Impress with {keypress} minigames",
    "section": "Game over",
    "text": "Game over\nChallenging. A test of wits. Worth your time.\nAll are phrases that do not sum up the games of {hokey}.\nBut, for me at least, I’ve got a better understanding of how {keypress} could be used for games written in R, a burgeoning field in the world of R programming.4\nLet me know how much you enjoyed these games and how much it’s going to suck to go back to your cutting-edge Neo Geo or Master System or whatever the kids are playing these days."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#environment",
    "href": "posts/2022-01-19-keypress/index.html#environment",
    "title": "Impress with {keypress} minigames",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] keypress_1.3.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#footnotes",
    "href": "posts/2022-01-19-keypress/index.html#footnotes",
    "title": "Impress with {keypress} minigames",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYeah, left.↩︎\nThis means it’s built with the absolute bare skeleton for an R package, because it’s not intended for ‘real’ consumption. It’s just for experimentation.↩︎\nI’m not going to shame you, but you are 100% a nerd. Why else are you here?↩︎\nIs it though?↩︎"
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html",
    "href": "posts/2023-05-07-bd2q/index.html",
    "title": "Automate {blogdown} to Quarto",
    "section": "",
    "text": "gRaPhIc DeSiGn Is My PaSsIoN."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#tldr",
    "href": "posts/2023-05-07-bd2q/index.html#tldr",
    "title": "Automate {blogdown} to Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve written a quick R package, {bd2q}, to help me convert my {blogdown} blog to Quarto. Whether I’ll actually complete the conversion is another story."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "href": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "title": "Automate {blogdown} to Quarto",
    "section": "Upside blogdown",
    "text": "Upside blogdown\nIt is destiny: no-one is ever completely happy with their blog.\nThis site was built five years ago1 with {blogdown}, which lets you write R Markdown files and have them knitted into a blog. I ignored the newer {distill} package2, but Quarto may be worth the switch. It’ll let me simplify the blog’s structure3 and take advantage of Quarto’s snazzy features4.\nBut I didn’t fancy transferring and editing ~150 posts by hand, so I’ve written a few functions to help out."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "href": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "title": "Automate {blogdown} to Quarto",
    "section": "When in doubt, make a package",
    "text": "When in doubt, make a package\nAnd so the {bd2q} R package5 is available from GitHub. It does what I need it to do for now, but note it only has basic error checking, has no unit tests, etc. Use at own risk, etc. It’s likely to remain unpolished forever, but feel free to add issues or pull requests. To install:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/bd2q\")\n\nThree things were in scope for this package:\n\nCreate a template Quarto blog.\nCreate the necessary Quarto folder structure for posts, then transfer posts and resources from the old {blogdown} blog.\nTweak the posts to remove or replace selected lines.\n\n\n1. Quarto blog template\nI assume someone has already written a version of usethis::create_project() for creating a Quarto blog. Regardless, I’ve written bd2q::create_template() to generate a folder with the minimal structure required, which makes my life easier for testing purposes.\n\nbd2q::create_template(q_path = \"~/new-quarto-blog\")\n\n✔ Created template Quarto blog at /Users/mattdray/new-quarto-blog\nThe skeleton content is opinionated and differs a bit to the one generated through RStudio’s ‘new project’ menu, for example, but the structure is the same:\nblog\n├── about.qmd\n├── index.qmd\n├── posts/\n│   └── metadata.yml\n├── styles.css\n└── blog.rproj\nOf course, now we need to pull in the posts from the old {blogdown} blog.\n\n\n2. Transfer posts and resources\nTypically in a {blogdown} blog, all R Markdown posts and their rendered HTML files are stored together in content/post/ in the form YYYY-MM-DD-post-name.Rmd and YYYY-MM-DD-post-name.html. Resources, like images, live separately in static/post/ with a folder per post in the form YYYY-MM-DD-post-name_files/.\nHere’s a simplified folder structure that focuses on a single post and its resources:\nblog/\n├── content/\n│   └── post/\n│       ├── YYYY-MM-DD-post-name.Rmd\n│       └── YYYY-MM-DD-post-name.html\n└── static/\n    └── post/\n        └── YYYY-MM-DD-post-name_files/\n            └── image.png\nQuarto simplifies this structure. Each post gets its own folder in posts/, like YYYY-MM-DD-post-name, which contains the post as index.qmd and a folder of resources. This means the post and all its content are stored together in one containing folder.\nblog/\n└── posts/\n    └── YYYY-MM-DD-post-name/\n        ├── index.qmd\n        └── resources/\n            └── image.png\nTo do the conversion, bd2q::transfer_posts() copies posts from a {blogdown} blog structure to a Quarto blog structure, setting up the required folders and renaming each post to index.qmd.\n\ntransfer_posts(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\"\n)\n\n✔ Created posts/ directory structure.\nℹ Copying posts.\n✔ Copied 148 posts to /Users/mattdray/new-quarto-blog.\nOnce that’s been run, bd2q::transfer_resources() can copy each post’s resources into an accompanying subfolder, which defaults to the name ‘resources’. You can choose which file types you want transfer with the exts_keep argument.\n\ntransfer_resources(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  exts_keep = c(\"gif\", \"jpg\", \"jpeg\", \"png\", \"svg\", \"wav\"),\n)\n\nℹ Copying resources.\n✔ Copied 455 resources to each post's resources/ folder in Users/mattdray/new-quarto-blog/posts.\nOf course this doesn’t account for everything, like bits of JavaScript and CSS related to the use of htmlwidgets. I’m not really bothered about this, because these should be recreated when I re-render each post.\nNote that you can use bd2q::create_and_transfer() if you want to run create_template(), transfer_posts() and transfer_resources() all at once. Regardless, once you’ve got the structure sorted, you can begin to adjust the posts if you need to.\n\n\n3. Tweak post content\nThere’s content in the body of each post that I want to get rid of or make more Quarto-like. I made a few functions that iterate over all the index.qmd files and replace or remove certain content.\nOne obvious necessity is to rebuild the resource paths (to images, sound files, etc), which can be done specifically with bd2q::update_resource_paths(). It defaults to creating paths to each post’s ‘resources’ subfolder, as generated by bd2q::transfer_resources(). For example, you could use a regular expression to match rows you know will contain a resource path and have them updated for the new Quarto folder structure (I tend to insert images with HTML rather than Markdown, hence the &lt;img&gt; tag in the example below).\n\nupdate_resource_paths(\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  resource_rx = \"&lt;img src=\"\n)\n\nℹ Updating posts.\n✔ 148 posts updated.  \nI also added two replace/remove functions that are a little more generic.\nThe first is bd2q::remove_line(), which deletes a single line from each post based on a provided regular expression. When I was messing around with converting the blog to Quarto manually, I found that the presence of the ‘draft’ status in the YAML header would prevent the post from appearing on the homepage, even if was set to ‘no’. As a result, you can run something like this to find and remove the lines that start with ‘draft’:\n\nbd2q::remove_line(\n  q_path = \"~/new-quarto-blog\",\n  detect_rx = \"^draft:\"\n)\n\nℹ Making corrections.\n✔ Removed lines matching the regular expression '^draft:' from 128 out of 148 posts.\nThat’s fine for individual lines, but what if you have a sequence of consecutive lines that you want to find and remove, or replace with some other text?\nThat’s what bd2q::replace_lines() does. Provide a vector of strings that exactly match some consecutive lines in each post, then provide a vector of strings to replace them with (or NULL to simply remove them)6.\nThis addresses another specific problem I was having. I wanted to update my custom session-info blocks at the bottom of each post so that they instead appear as a Quarto ‘appendix’. That can be done like this:\n\nold_lines &lt;- c(\n  \"---\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r eval=TRUE, sessioninfo, echo=FALSE}\",\n  \"sessioninfo::session_info()\",\n  \"```\",\n  \"&lt;/details&gt;\"\n)\n\nnew_lines &lt;- c(\n  \"## Details {.appendix}\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r}\",\n  \"#' eval = TRUE,\",\n  \"#' echo = FALSE\",\n  'cat(\"Date:\", cat(format(Sys.time(), format = \"%Y-%m-%d\")), \"\\n\\n\"); sessionInfo()',\n  \"```\"\n)\n\nbd2q::replace_lines(\n  q_path = \"~/new-quarto-blog\",\n  match_str = old_lines,\n  replacement_str = new_lines\n)\n\nℹ Making corrections.\n✔ Removed lines matching the provided string vector from 9 out of 148 posts.   \nHaha, uhoh, I was expecting to have fixed more posts than that! Looks like I might have written my custom session-info block slightly differently in each post (maybe an extra space or empty line?), so I’ll have to run the bd2q::replace_lines() multiple times to make sure I can replace it in each post that it appears."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "href": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "title": "Automate {blogdown} to Quarto",
    "section": "Actually use the package? Pfft!",
    "text": "Actually use the package? Pfft!\nSo, is {bd2q} objectively good? No. Does it do what I personally want it to do? Absolutely. Mostly. Yeah?\nOf course, transferring files into a new structure is the easy part. The hard part is to see if each post will still re-render after all these years. It’s unlikely! There’s no dependency management in this blog because there was no easy easy to do it. Quarto, meanwhile, has the ability to ‘freeze’ posts and link each post to a {renv} lockfile (thanks Albert) that captures each post’s package dependencies.\nThere are some other dependencies outside of packages though. For example, I have posts that use the {rtweet} package to fetch tweets from Twitter, but Twitter is a garbage fire and I may never be able to fetch tweets from the API in future. I may have to just copy-paste the outputs that were created when the post was originally rendered, oh well.\nTo be clear: this is hard work. I may not be brave enough to do it any time soon. I’ve set up a GitHub repo for ‘rostrum-blog-2’ where I’ve been experimenting with styles and structure, so if I ever get round to this task then that’s where the fireworks will be happening.\nAnd hey, at worst I got more familiar with the {fs} and {cli} packages when making {bd2q}, which are for ‘tidy’ path handling and nice user interfaces. A convoluted way to learn!\nBut that’s what this blog is all about, amirite."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#environment",
    "href": "posts/2023-05-07-bd2q/index.html#environment",
    "title": "Automate {blogdown} to Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:25:33 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] bd2q_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#footnotes",
    "href": "posts/2023-05-07-bd2q/index.html#footnotes",
    "title": "Automate {blogdown} to Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nActually, we began this blog on WordPress in 2013. But WordPress doesn’t evaluate R code, so code outputs had to be pasted in manually. The original blog was meant to be more about general ecology, hence the name ‘rostrum’, which refers to the snouty bit of an insect and also the platform a speaker talks from. Seemed like a neat pun at the time, but the joke is kinda lost on an audience that’s no longer comprised mostly of entomologists. But the audience is mostly me, so I can live with it.↩︎\nAlthough I did use it to investigate a method with {renv} for managing dependencies on a post-by-post basis.↩︎\nIn particular, {blogdown} depends on Hugo, a ‘framework for building websites’. Quarto blogs are just… built on Quarto.↩︎\nEspecially things like WebR for Quarto that helps you embed interactive R chunks into your posts, which I wrote about recently.↩︎\n‘bd2q’ as in ‘{blogdown} to Quarto’. Which is a boring name, I know.↩︎\nThis was actually more painful than I was hoping. There’s no easy way to match consecutive strings between vectors. In other words, try to extract the sequence c(\"a\", \"b\", \"c\"), in that order, from the vector c(\"a\", \"b\", \"d\", \"a\", \"b\", \"c\", \"d\"). Surely there’s an R function that will do this? Anyway, I fudged it by collapsing all the lines of a post into a single string and then finding the matching (collapsed) string provided by the user. Of course, the string will have to be ‘uncollapsed’ to get a string per line, so you can use paste() with a string provide to the collapse argument. But this separator will need to be a string that doesn’t appear in any of your posts, otherwise the uncollapsing process will break a line that you didn’t intend to be broken! I went with /// by default, but the user can change this with the collapse_str argument in bd2q::replace_lines(). Sheesh.↩︎"
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html",
    "href": "posts/2021-06-28-pixel-art/index.html",
    "title": "Very simple pixel art in R",
    "section": "",
    "text": "It’s dangerous to code alone…"
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#tldr",
    "href": "posts/2021-06-28-pixel-art/index.html#tldr",
    "title": "Very simple pixel art in R",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R’s image() function to convert a matrix to a pixelly graphic.\n\n Note\nI’ve now written a little R package called {pixeltrix}, which lets you click on squares in a plot window to generate a matrix of ‘pixels’. This means you don’t have to type out any vectors by hand. You can read more in some other blog posts."
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#pixel-fixation",
    "href": "posts/2021-06-28-pixel-art/index.html#pixel-fixation",
    "title": "Very simple pixel art in R",
    "section": "Pixel fixation",
    "text": "Pixel fixation\nMy last post was about the {emojiscape} package, which makes a little scene out of sampled emojis.\nFollowing a similar approach, you could write a matrix by hand and plot it via the base function image(). Here’s a very basic example with a ‘glider’ from Conway’s Game of Life. Values of 0 are ‘dead’ cells and values of 1 are ‘live’.\n\nglider_v &lt;- c(0,0,0,0,0, 0,0,1,0,0, 0,0,0,1,0, 0,1,1,1,0, 0,0,0,0,0)\nglider_m &lt;- matrix(glider_v, 5)           # convert to matrix\nglider_m &lt;- glider_m[, ncol(glider_m):1]  # reverse cols\npar(mar = rep(0, 4))                      # ensure no margins\nimage(glider_m)                           # plot it\n\n\n\n\nNote that I input the vector values from what would become the top left to bottom right of the output matrix. The image() function doesn’t read them in this order, however, so I’ve added a step to reverse the column order so the plot output appears as I intended.\nAlso, image() normally outputs with labelled axes, but we can effectively hide those by minimising the margins par()ameter of the plot to 0."
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#reprologoducibility",
    "href": "posts/2021-06-28-pixel-art/index.html#reprologoducibility",
    "title": "Very simple pixel art in R",
    "section": "Reprologoducibility",
    "text": "Reprologoducibility\nBut really my motivation is to make a reproducible version of this blog’s logo: an insect composed of ‘pixels’ in a 16-by-16 square.\nSo, I’ve hand-coded a binary vector of length 256 (i.e. 16 * 16). The 0s and 1s here represent background and insect pixels, respectively. I’ve used line breaks to make it easier to create and edit the vector manually.\nHere’s the vector that represents the logo:\n\nlogo_v &lt;- c(\n  \n  0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,\n  0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,\n  0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,\n  0,0,1,0,0,1,0,1,1,0,1,0,0,1,0,0,\n  \n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,0,\n  0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,\n  0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,\n  \n  0,0,1,0,1,1,0,1,1,0,1,1,0,1,0,0,\n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,0,0,1,0,1,1,0,1,0,0,0,0,0,\n  0,0,0,0,1,1,0,1,1,0,1,1,0,0,0,0,\n  \n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,1,0,0,1,0,1,1,0,1,0,0,1,0,0,\n  0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0\n\n)\n\nI might as well make a (non-generic) function to matrixify (definitely a word) and plot the vector, so I can then tweak a few parameters as I please.\n\nplot_logo &lt;- function(\n  x = logo_v,           # vector\n  px = 16,              # width/length of output (square)\n  col_0 = \"black\",      # colour for values of 0\n  col_1 = \"#1e8016\",    # colour for values of 1\n  lwd = 8               # to separate the squares\n) {\n  \n  par(mar = rep(0, 4))  # set margins outside plot region\n  \n  m &lt;- matrix(x, px)    # create a matrix from the vector\n  m &lt;- m[, ncol(m):1]   # reverse cols\n  \n  image(m, col = c(col_0, col_1))  # plot matrix, colour by number\n  \n  # If line width provided, draw lines between squares\n  if (!is.null(lwd)) {\n    px_half &lt;- px * 2\n    s &lt;- seq(-1 / px_half, 1 + (1 / px_half), 1 / (px - 1))\n    abline(h = s, v = s, col = col_0, lwd = lwd)\n  }\n  \n}\n\nNote that I added a line width argument (lwd). If specified, horizontal and vertical lines are drawn to give the impression that the squares are ‘separated’ from each other.\nHere’s the logo.\n\nplot_logo(lwd = 2)\n\n\n\n\nAnd here’s what happens if we remove the lines and swap the colours, for example.\n\nplot_logo(col_0 = \"#1e8016\", col_1 = \"black\", lwd = NULL)\n\n\n\n\nAnd given it’s Pride Month:\n\nfor (i in rainbow(7)) {\n  plot_logo(lwd = 1, col_0 = \"white\", col_1 = i)\n}"
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#sprite-delight",
    "href": "posts/2021-06-28-pixel-art/index.html#sprite-delight",
    "title": "Very simple pixel art in R",
    "section": "Sprite delight",
    "text": "Sprite delight\nThis approach is basically pixel-art-by-numbers, right?\nSo I’ve written and animated two frames of a classic videogame character, Link from The Legend of Zelda on the NES, using the {magick} package to create a gif.\nThere’s four colours in this one, so the vectors are no longer binary: there’s 0 for the background, 1 for green, 2 for skin and 3 for the darker spots.\nThe top part of the sprite doesn’t change between frames, but the bottom does. To avoid repetition, we can store the top part as a separate vector, then combine it with each frame’s lower section. It’s still a bit of a slog to input these by hand!\n\nlink_v_top &lt;- c(\n  0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,\n  0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,\n  0,0,2,0,1,3,3,3,3,3,3,1,0,2,0,0,\n  0,0,2,0,3,3,3,3,3,3,3,3,0,2,0,0,\n  \n  0,0,2,2,3,2,1,2,2,1,2,3,2,2,0,0,\n  0,0,2,2,3,2,3,2,2,3,2,3,2,2,0,0,\n  0,0,0,2,2,2,2,2,2,2,2,2,2,3,0,0\n)\n\nlink_v_b1 &lt;- c(\n  0,0,0,1,1,2,2,3,3,2,2,1,1,3,0,0,\n  \n  0,3,3,3,3,3,2,2,2,2,1,1,3,3,3,0,\n  3,3,2,3,3,3,3,1,1,1,1,1,2,3,3,0,\n  3,2,2,2,3,3,2,3,3,1,1,2,2,2,3,0,\n  3,3,2,3,3,3,2,1,3,3,3,3,2,2,2,0,\n  \n  3,3,2,3,3,3,2,3,3,1,1,1,1,2,0,0,\n  3,3,3,3,3,3,2,1,1,1,1,1,0,0,0,0,\n  0,2,2,2,2,2,3,0,0,3,3,3,0,0,0,0,\n  0,0,0,0,3,3,3,0,0,0,0,0,0,0,0,0\n)\n\nlink_v_b2 &lt;- c(\n  0,0,0,0,1,2,2,3,3,2,2,1,3,3,0,0,\n  \n  0,0,3,3,3,3,3,2,2,2,1,1,1,2,0,0,\n  0,3,3,2,3,3,3,3,1,1,1,1,1,2,0,0,\n  0,3,2,2,2,3,3,2,3,3,1,1,3,0,0,0,\n  0,3,3,2,3,3,3,2,1,3,3,3,1,0,0,0,\n  \n  0,3,3,2,3,3,3,2,3,3,1,1,1,0,0,0,\n  0,3,3,3,3,3,3,2,1,1,1,3,0,0,0,0,\n  0,0,2,2,2,2,2,0,0,3,3,3,0,0,0,0,\n  0,0,0,0,0,0,0,0,0,3,3,3,0,0,0,0\n)\n\n# Combine vectors to get frames\nlink_f1 &lt;- c(link_v_top, link_v_b1)\nlink_f2 &lt;- c(link_v_top, link_v_b2)\n\nNow we have the vectors representing Link for each frame of the animation. The approach now is like before: convert this to a 16 by 16 matrix and plot it. This time I’ve got a function that also saves the plots by first opening a png() graphics device and closing it at the end with dev.off(). I’ve saved these to a temporary directory for the purposes of the post, rather than my local disk.\n\ntmp &lt;- tempdir()  # store temporary folder path\n\n# Function to write frame to temporary folder\nwrite_link &lt;- function(vec) {\n  write_path &lt;- file.path(tmp, paste0(substitute(vec), \".png\"))\n  png(write_path, width = 160, height = 160)\n  link_m &lt;- matrix(vec, 16)\n  link_m &lt;- link_m[, ncol(link_m):1]\n  par(mar = rep(0, 4))\n  link_cols &lt;- c(\"white\", \"#7bc702\", \"#cc8f2d\", \"#6c430a\")\n  image(link_m, col = link_cols)\n  dev.off()\n}\n\n# Write the frames\nwrite_link(link_f1); write_link(link_f2)\n\nquartz_off_screen \n                2 \n\n\nquartz_off_screen \n                2 \n\n\nWe get a couple of messages to say that the devices have been closed, confirming the save.\nNow we can use the {magick} package to create a gif: image_read() to load both PNG frames into a single object from their save location, and then image_animate() to combine the images into an output that flips between the two frames. You could also use image_write() to save this object to gif format.\n\n# Generate a gif from the saved frames\npng_paths &lt;- list.files(tmp, \"*.png$\", full.names = TRUE)     # get file paths\nframes &lt;- magick::image_read(png_paths)                       # load the files\nmagick::image_animate(frames, fps = 2, dispose = \"previous\")  # combine frames\n\n\n\n\nI’m not sure I’ll be coding the graphics for the whole game anytime soon…"
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#hip-to-be-square",
    "href": "posts/2021-06-28-pixel-art/index.html#hip-to-be-square",
    "title": "Very simple pixel art in R",
    "section": "Hip to be square",
    "text": "Hip to be square\nI’m not the first person to think or do this in R, I’m sure.\nI did come across a really neato {pixelart} package and Shiny app by Florian Privé where you upload an image and it gets converted into a pixel form. As Florian said in his blogpost:\n\nKids and big kids can quickly become addicted to this\n\nYes. And that’s exactly why this post exists.\nLet me know if you know of any more packages or whatever that do this sort of thing.\n\n Note\nTurns out that mikefc, aka coolbutuseless, (who else?) wrote a great blog post with a method for grabbing, plotting and animating sprites with the packages {png}, {raster}, {ggplot2} and {gganimate}. Slightly less painful than writing vectors by hand!\nIf you want to design your own sprites rather than copy others, try my little {pixeltrix} package for interactive pixel selection from a plot window, which returns a matrix."
  },
  {
    "objectID": "posts/2021-06-28-pixel-art/index.html#environment",
    "href": "posts/2021-06-28-pixel-art/index.html#environment",
    "title": "Very simple pixel art in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7        magick_2.7.4     \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#tldr",
    "href": "posts/2019-06-20-goat-scope/index.html#tldr",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "tl;dr",
    "text": "tl;dr\nI used {trelliscopejs} to make an interactive ‘small multiples’ display for The Mountain Goats discography. You can interact with an embedded version above or click here to open full screen.\n\n Note\nThe {trelliscopejs} package has been superseded by {trelliscope}."
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#small-multiples",
    "href": "posts/2019-06-20-goat-scope/index.html#small-multiples",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Small multiples",
    "text": "Small multiples\nThe {trelliscopejs} R package by Ryan Hafen harnesses the power of his trelliscopejs-lib JavaScript library.\nWhat does it do? It provides an interactive interface for visualising, organising and exploring data visualisations in small multiples.\nWhat are ‘small multiples’? Rather than over-plotting data for multiple levels of some variable, you can facet by them into separate ‘panels’ and display the outputs side by side for easy comparison.\nRyan has written documentation, an introductory post and has created some trelliscopes using using gapminder and Pokémon data, for example.1 His package is relatively simple to use and does a lot of legwork to provide a nice interface for your data."
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#goat-discography",
    "href": "posts/2019-06-20-goat-scope/index.html#goat-discography",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Goat discography",
    "text": "Goat discography\nIn a previous post I used the {spotifyr}, {genius} and {markovifyR} packages to generate new lyrics for the band The Mountain Goats.\nThe data from Spotify is interesting. It has musical information like key and tempo, but also audio features like ‘danceability’ and ‘acousticness’ scaled from 0 to 1. We also got links to album art in that data set.\nI’m going to use these data in this post to provide a trelliscope example. Each panel will be a track; the visualisation will be album artwork rather than a plot; and audio features will be available to sort and filter data."
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#ready-the-data",
    "href": "posts/2019-06-20-goat-scope/index.html#ready-the-data",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Ready the data",
    "text": "Ready the data\nWe’ll load {trelliscopejs} and some tidyverse packages to help us out.\n\nsuppressPackageStartupMessages({\n  library(trelliscopejs)\n  library(dplyr)\n  library(readr)\n  library(tidyr)\n})\n\n\nGet data and simplify\nYou can follow the instructions in the previous post to get the data. I’m going to load those data from a pre-prepared RDS file.\n\n# Read the file from a local source and check number of columns\nraw_goat &lt;- read_rds(\"resources/goat_discography.RDS\")\nlength(raw_goat)\n\n[1] 41\n\n\nThere’s 41 variables, so let’s simplify.\n\nsmall_goat &lt;- raw_goat %&gt;% \n  unnest(available_markets) %&gt;%  # unnest character vector\n  filter(available_markets == \"US\") %&gt;%  # releases from one country only\n  select(\n    track_name, album_name, track_n, album_release_year,  # track detail\n    duration_ms, key_mode, time_signature, # musical info\n    danceability, energy, speechiness, acousticness,  # audio features\n    instrumentalness, liveness, valence, loudness  # audio features\n  ) %&gt;%\n  arrange(desc(energy))  # order by 'energy' audio feature\n\nglimpse(small_goat)\n\nRows: 313\nColumns: 15\n$ track_name         &lt;chr&gt; \"Choked Out\", \"Pure Intentions\", \"If You See Light\"…\n$ album_name         &lt;chr&gt; \"Beat the Champ\", \"Bitter Melon Farm\", \"Get Lonely\"…\n$ track_n            &lt;int&gt; 5, 18, 10, 16, 14, 20, 17, 8, 21, 4, 2, 13, 3, 9, 8…\n$ album_release_year &lt;dbl&gt; 2015, 2002, 2006, 2011, 1996, 2012, 2002, 2002, 201…\n$ duration_ms        &lt;int&gt; 102653, 134333, 118013, 167120, 234600, 165840, 137…\n$ key_mode           &lt;chr&gt; \"D major\", \"A major\", \"C major\", \"B minor\", \"D majo…\n$ time_signature     &lt;int&gt; 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ danceability       &lt;dbl&gt; 0.565, 0.648, 0.566, 0.422, 0.281, 0.681, 0.592, 0.…\n$ energy             &lt;dbl&gt; 0.951, 0.934, 0.927, 0.903, 0.899, 0.895, 0.884, 0.…\n$ speechiness        &lt;dbl&gt; 0.0808, 0.0989, 0.0642, 0.0682, 0.0526, 0.0253, 0.0…\n$ acousticness       &lt;dbl&gt; 0.000239, 0.646000, 0.002930, 0.000620, 0.262000, 0…\n$ instrumentalness   &lt;dbl&gt; 2.78e-05, 2.14e-01, 8.52e-01, 1.01e-02, 2.72e-02, 4…\n$ liveness           &lt;dbl&gt; 0.1320, 0.3890, 0.1990, 0.3420, 0.2080, 0.1390, 0.4…\n$ valence            &lt;dbl&gt; 0.726, 0.424, 0.324, 0.860, 0.350, 0.970, 0.591, 0.…\n$ loudness           &lt;dbl&gt; -3.970, -15.557, -8.047, -8.562, -9.177, -6.936, -1…\n\n\nNote that I’ve ordered by ‘energy’. The trelliscope output being created will be sorted in this variable.\n\n\nAlbum artwork\nUnnesting the available_markets character vector removed the album_image variable, which is a nested data frame with URLs to different-sized album artwork. We can grab unique album image URLs and join them back to our data set.\n\ngoat_pics &lt;- raw_goat %&gt;%\n  unnest(album_images) %&gt;%  # unnest dataframe fo URLs\n  filter(width == 640) %&gt;%  # just the largest images\n  select(album_name, url) %&gt;%  # simplify dataset\n  distinct(album_name, .keep_all = TRUE)  # one unique entry per album\n\nglimpse(goat_pics)\n\nRows: 21\nColumns: 2\n$ album_name &lt;chr&gt; \"In League with Dragons\", \"Goths\", \"Beat the Champ\", \"Trans…\n$ url        &lt;chr&gt; \"https://i.scdn.co/image/3896e2b47b548a33d0c9e9f662011a2a09…\n\n\nAnd now to join the album image URLs back to our simplified data set.\n\nsmall_goat_pics &lt;- left_join(\n  x = small_goat,\n  y = goat_pics,\n  by = \"album_name\"\n)\n\nglimpse(small_goat_pics)\n\nRows: 313\nColumns: 16\n$ track_name         &lt;chr&gt; \"Choked Out\", \"Pure Intentions\", \"If You See Light\"…\n$ album_name         &lt;chr&gt; \"Beat the Champ\", \"Bitter Melon Farm\", \"Get Lonely\"…\n$ track_n            &lt;int&gt; 5, 18, 10, 16, 14, 20, 17, 8, 21, 4, 2, 13, 3, 9, 8…\n$ album_release_year &lt;dbl&gt; 2015, 2002, 2006, 2011, 1996, 2012, 2002, 2002, 201…\n$ duration_ms        &lt;int&gt; 102653, 134333, 118013, 167120, 234600, 165840, 137…\n$ key_mode           &lt;chr&gt; \"D major\", \"A major\", \"C major\", \"B minor\", \"D majo…\n$ time_signature     &lt;int&gt; 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ danceability       &lt;dbl&gt; 0.565, 0.648, 0.566, 0.422, 0.281, 0.681, 0.592, 0.…\n$ energy             &lt;dbl&gt; 0.951, 0.934, 0.927, 0.903, 0.899, 0.895, 0.884, 0.…\n$ speechiness        &lt;dbl&gt; 0.0808, 0.0989, 0.0642, 0.0682, 0.0526, 0.0253, 0.0…\n$ acousticness       &lt;dbl&gt; 0.000239, 0.646000, 0.002930, 0.000620, 0.262000, 0…\n$ instrumentalness   &lt;dbl&gt; 2.78e-05, 2.14e-01, 8.52e-01, 1.01e-02, 2.72e-02, 4…\n$ liveness           &lt;dbl&gt; 0.1320, 0.3890, 0.1990, 0.3420, 0.2080, 0.1390, 0.4…\n$ valence            &lt;dbl&gt; 0.726, 0.424, 0.324, 0.860, 0.350, 0.970, 0.591, 0.…\n$ loudness           &lt;dbl&gt; -3.970, -15.557, -8.047, -8.562, -9.177, -6.936, -1…\n$ url                &lt;chr&gt; \"https://i.scdn.co/image/ecf370a7190fa0673b0aa2ff0c…\n\n\nSo the album artwork URL has been added to the url column.\n\n\nPrep for trelliscope\nNow we have a nice tidy data frame, but I’m going to make a couple more changes to prepare the data for trelliscoping2. First, I need to use the img_panel() function to declare that the album images should be the thing being visualised in each panel. Then I can rename the variables to make them look nicer when displayed.\n\nprepared_goat &lt;- small_goat_pics %&gt;% \n  mutate(panel = img_panel(url)) %&gt;%  # identify as viz for panel\n  rename_all(tools::toTitleCase) %&gt;%  # first letter capitalised\n  rename(\n    Track = Track_name,\n    Album = Album_name,\n    `Track #` = Track_n,\n    Year = Album_release_year,\n    `Duration (ms)` = Duration_ms,\n    `Key mode` = Key_mode,\n    `Time sig` = Time_signature\n  ) %&gt;% \n  select(-Url)  # discard unneeded variable"
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#generate-trelliscope",
    "href": "posts/2019-06-20-goat-scope/index.html#generate-trelliscope",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Generate trelliscope",
    "text": "Generate trelliscope\nNow we’re ready. The call to trelliscope() takes the data set and then a bunch of other arguments like a title and subtitle and the default state for the number of rows and columns of panels and the default data to show on the panel under the visualisation.\n\ntrelliscope(\n  prepared_goat,\n  name = \"The Mountain Goats discography\",\n  desc = \"Explore the Mountain Goats backcatalogue and filter and sort by audio features\",\n  md_desc = \"[The Mountain Goats](http://www.mountain-goats.com/) are a band. Data were collected from [Genius](https://genius.com/) and [Spotify](https://www.spotify.com/) APIs using the [{genius}](https://github.com/josiahparry/genius) and [{spotifyr}](https://www.rcharlie.com/spotifyr/) R packages, respectively.\",\n  nrow = 2, ncol = 5,  # arrangement of panels\n  state = list(labels = c(\"Track\", \"Album\", \"Track #\", \"Year\", \"Energy\")),  # display on panels\n)\n\nI’ve embedded the trelliscope at the top of this post, but I recommend you click here to open it full screen.\nExplore the data by altering the defaults in the grid, labels, filter and sort buttons in the left-hand navigation panel. Cycle through the panels with the arrows in the upper right. Hit the ‘?’ button in the upper right to get more information on trelliscope and its shortcuts.\n\nHost your trelliscope\nUse the argument path = \"&lt;file path to save to&gt;\" in the trelliscope() function to save the files (I learnt this from a GitHub issue). You can then host the folder’s contents somewhere. I put mine in a GitHub repo so it could be served via GitHub Pages."
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#energy",
    "href": "posts/2019-06-20-goat-scope/index.html#energy",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Energy",
    "text": "Energy\nI’ve ordered the panels of the trelliscope by the ‘energy’ of the tracks; most energetic first. The top track for energy is one of my favourites: ‘Choked Out’ from ‘Beat the Champ’. Here’s an embedded Spotify snippet."
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#environment",
    "href": "posts/2019-06-20-goat-scope/index.html#environment",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-02 16:18:25 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.0         readr_2.1.4         dplyr_1.1.2        \n[4] trelliscopejs_0.2.6\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            jsonlite_1.8.7          compiler_4.3.1         \n [4] crayon_1.5.2            webshot_0.5.5           tidyselect_1.2.0       \n [7] progress_1.2.2          scales_1.2.1            yaml_2.3.7             \n[10] fastmap_1.1.1           ggplot2_3.4.2           R6_2.5.1               \n[13] autocogs_0.1.4          generics_0.1.3          knitr_1.43.1           \n[16] backports_1.4.1         htmlwidgets_1.6.2       checkmate_2.2.0        \n[19] tibble_3.2.1            munsell_0.5.0           xaringanExtra_0.7.0    \n[22] tzdb_0.4.0              pillar_1.9.0            rlang_1.1.1            \n[25] utf8_1.2.3              xfun_0.39               cli_3.6.1              \n[28] withr_2.5.0             magrittr_2.0.3          digest_0.6.33          \n[31] grid_4.3.1              rstudioapi_0.15.0       fontawesome_0.5.1      \n[34] base64enc_0.1-3         DistributionUtils_0.6-0 hms_1.1.3              \n[37] mclust_6.0.0            lifecycle_1.0.3         prettyunits_1.1.1      \n[40] vctrs_0.6.3             evaluate_0.21           glue_1.6.2             \n[43] fansi_1.0.4             colorspace_2.1-0        purrr_1.0.1            \n[46] rmarkdown_2.23          tools_4.3.1             pkgconfig_2.0.3        \n[49] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2019-06-20-goat-scope/index.html#footnotes",
    "href": "posts/2019-06-20-goat-scope/index.html#footnotes",
    "title": "The Mountain Goats with {trelliscopejs}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI also once explored the use of Trelliscope for UK education data and have been meaning to write about it ever since.↩︎\nDefinitely a real verb.↩︎"
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html",
    "href": "posts/2019-02-14-relayverse/index.html",
    "title": "Graphing the Relayverse of podcasts",
    "section": "",
    "text": "The Relay FM podcast network, visualised. View it here."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#tldr",
    "href": "posts/2019-02-14-relayverse/index.html#tldr",
    "title": "Graphing the Relayverse of podcasts",
    "section": "tl;dr",
    "text": "tl;dr\nI made an interactive graph network of the podcast host relationships on Relay FM using R. You can interact with it in a separate window and find out below how it was made."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#podcast-networks",
    "href": "posts/2019-02-14-relayverse/index.html#podcast-networks",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Podcast networks",
    "text": "Podcast networks\nPodcasting is becoming big business. Music-streaming giant Spotify just acquired the podcast network Gimlet for a reported $200 million.\nOther networks include The Incomparable, 5by5 and Radiotopia. Such networks can boost revenue and listener numbers and provide access to expertise, management and resources.\nRelay FM is a network that focuses largely on tech content1. It was started by Myke Hurley and Stephen Hackett in 2014 and you can find a list of shows and personnel on their site. Many of Relay FM’s hosts have hosted more than one podcast within the network. What do the relationships between them look like?\nThis post is about preparing and visualising this ‘Relayverse’ using the R packages {tidygraph}for network data handling and {ggraph} for network visualisation (both by Thomas Lin Pedersen), along with the {visNetwork} package.\nScroll to the bottom to find the interactive tool if you aren’t interested in the code."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#packages",
    "href": "posts/2019-02-14-relayverse/index.html#packages",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Packages",
    "text": "Packages\nI’m using two suites of ‘tidy’ packages in this post: one set for data collection and manipulation, and one set for graph network building, analysis and visualisation.\n\nsuppressPackageStartupMessages({\n  \n  # Data collection and manipulation\n  library(dplyr)  # data manipulation\n  library(rvest)  # for scraping webpages\n  library(stringr)  # string manipulation\n  library(tidyr)  # tidying dataframes\n  library(purrr)  # applying functions over data\n  \n  # Graph networks\n  library(tidygraph)  # set up graph network\n  library(ggraph)  # visualise static graphs\n  library(cowplot)  # for plot arrangement\n  library(visNetwork)  # wrapper for javascript interactive viz\n  \n})"
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#harvest-data",
    "href": "posts/2019-02-14-relayverse/index.html#harvest-data",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Harvest data",
    "text": "Harvest data\nWe can use the {rvest} package to scrape podcast details from the Wikipedia page for Relay FM. There are two separate tables: one for current and one for retired (discontinued) shows.\n\n\n\nOne of the target Wikipedia tables of current Relay FM shows\n\n\nread_html() gets the HTML for the selected page; html_node() identifies which element needs to be scraped2; and html_table() interprets the HTML information as a data frame. I’ve removed the show ‘B-Sides’ because it’s clips from other shows.\n\n# Get the HTML for the selected page\nrelay_wiki &lt;- read_html(\"https://en.wikipedia.org/wiki/Relay_FM\")\n\n# Get the table with current shows\ncurrent &lt;- relay_wiki %&gt;%\n  html_node(xpath = '//*[@id=\"mw-content-text\"]/div/table[2]') %&gt;%\n  html_table() %&gt;%\n  filter(\n    !Podcast %in% c(\"Members Only\", 'Paid \"Members Only\" Shows', \"B-Sides\")\n  ) %&gt;%\n  mutate(Status = \"Current\")  # label rows as current shows\n\n# Get the table with retired shows\nretired &lt;- relay_wiki %&gt;%\n  html_node(xpath = '//*[@id=\"mw-content-text\"]/div/table[3]') %&gt;%\n  html_table() %&gt;%\n  select(-`Number of episodes`) %&gt;%\n  mutate(Status = \"Retired\")  # label rows as retired shows\n\n# Combine the tables into one dataframe\nshows &lt;- bind_rows(current, retired)\n\n# Look at a few random hosts/podcasts from the table\nselect(shows, Podcast, Hosts) %&gt;%\n  sample_n(5) %&gt;% knitr::kable()\n\n\n\n\nPodcast\nHosts\n\n\n\n\nVirtual\nFederico ViticciMyke Hurley\n\n\nFree Agents\nJason SnellDavid Sparks\n\n\nBionic\nMyke HurleyMatt Alexander\n\n\nLess Than or Equal\nAleen Simms\n\n\nCanvas\nFederico ViticciFraser Spiers\n\n\n\nUnfortunately the host names are in the form ‘First LastFirst Last’ so we need a regular expression to split the string where a lowercase letter meets an uppercase letter3. This leaves us with a list column that we can unnest() to get one row per podcast-host combination.\n\n# Clean the host names\nshows_clean &lt;- shows %&gt;%\n  mutate(\n    Hosts = str_remove_all(Hosts, \"formerly hosted by.*$\"),  # remove text and former hosts\n    Hosts = str_remove_all(Hosts, \" \\\\(originally\\\\)\"),  # remove '(originally)' text\n    Hosts = str_remove_all(Hosts, \"\\\\[[:digit:]\\\\]\"),  # remove Wikipedia references\n    Hosts = str_split(Hosts, \"(?&lt;=[a-z])(?=[A-Z])\") # split where lowercase meets uppercase\n  ) %&gt;%\n  filter(Hosts != \"Maddy Myers\") %&gt;%  # hack to remove a former host\n  unnest() %&gt;% \n  select(Podcast, Hosts, Status)\n\n# Print a random sample of 10\nsample_n(shows_clean, 10) %&gt;% knitr::kable()\n\n\n\n\nPodcast\nHosts\nStatus\n\n\n\n\nConnected\nMyke Hurley\nCurrent\n\n\nMixed Feelings\nGillian Parker\nCurrent\n\n\nBONANZA\nMatt Alexander\nCurrent\n\n\nRemaster\nMyke Hurley\nCurrent\n\n\nIsometric\nSteve Lubitz\nRetired\n\n\nThe Prompt\nStephen M. Hackett\nRetired\n\n\nPresentable\nJeff Veen\nCurrent\n\n\nRemaster\nShahid Kamal Ahmad\nCurrent\n\n\nRemaster\nFederico Viticci\nCurrent\n\n\nLiftoff\nStephen M. Hackett\nCurrent\n\n\n\nNotice there were a couple of cleaning steps there to remove the text ‘formerly hosted by’ and the names of the former hosts. There’s one instance where this protocol isn’t followed in the table and the host’s name is followed by ‘(originally)’. I removed the text with regex, but then just removed the host’s name manually with a filter() to avoid some complex regex.\nOur data frame is now tidy and ready for Tidygraph, but before moving on, we can do things like look at the host with the most active shows.\n\nshows_clean %&gt;% \n  filter(Status == \"Current\") %&gt;% \n  count(Hosts) %&gt;%\n  filter(n &gt; 2) %&gt;% \n  arrange(desc(n)) %&gt;% \n  knitr::kable()\n\n\n\n\nHosts\nn\n\n\n\n\nMyke Hurley\n10\n\n\nStephen M. Hackett\n6\n\n\nDavid Sparks\n3\n\n\nJason Snell\n3\n\n\nMikah Sargent\n3\n\n\nTiffany Arment\n3\n\n\n\nOr out of interest, the shows that have had the most hosts.\n\nshows_clean %&gt;% \n  count(Podcast) %&gt;%\n  arrange(desc(n)) %&gt;% \n  slice(1:6) %&gt;% \n  knitr::kable()\n\n\n\n\nPodcast\nn\n\n\n\n\nIsometric\n5\n\n\nDisruption\n4\n\n\nConnected\n3\n\n\nRemaster\n3\n\n\nRocket\n3\n\n\nThe Prompt\n3"
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#tidygraph",
    "href": "posts/2019-02-14-relayverse/index.html#tidygraph",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Tidygraph",
    "text": "Tidygraph\nThe tidygraph package was created by Thomas Lin Pedersen. It is:\n\nan entry into the tidyverse that provides a tidy framework for all things relational (networks/graphs, trees, etc)\n\nTo use the package, we need every host combination4 for each podcast, which can be achieved with the combn() function. This gives us a pair of points (‘nodes’ in graph-speak) that can be connected by a line (an ‘edge’) to indicate their relationship.\nBut a show with one host doesn’t have a pair of points, so I’m going to duplicate these rows first. If we don’t do this, we can’t plot these shows because they won’t have a connection between two nodes.\n\n# Isolate the shows with one host \nsolo_vec &lt;- shows_clean %&gt;%\n  count(Podcast) %&gt;%\n  filter(n == 1) %&gt;%\n  pull(Podcast)\n\n# Filter the show-host dataframe by solo-hosted podcasts\nsolo_df &lt;- filter(shows_clean, Podcast %in% solo_vec)\n\nNow we can bind these rows to the data and then get our host combinations. Big shout out to William Chase for a solution to getting all combinations of elements within some parent element (e.g. hosts within podcasts).\n\n# Prepare host combinations per show\nrelay_combos &lt;- shows_clean %&gt;%\n  bind_rows(solo_df) %&gt;%  # to duplicate the shows with solo hosts\n  group_by(Podcast) %&gt;%  # operate within each podcast\n  split(.$Podcast) %&gt;%  # split on podcast\n  map(., 2) %&gt;%  # gets vector of hosts per podcast list element\n  map(~combn(.x, m = 2)) %&gt;%   # all pair combiantions\n  map(~t(.x)) %&gt;%  # transpose the matrix\n  map(as_tibble) %&gt;%  # convert to a tibble dataframe\n  bind_rows(.id = \"Podcast\") %&gt;%  # list-element name to column\n  select(V1, V2, Podcast)\n\nsample_n(relay_combos, 10) %&gt;% knitr::kable()  # random sample of 10\n\n\n\n\nV1\nV2\n\n\n\n\nMyke Hurley\nTom Gerhardt\n\n\nDavid Sparks\nRose Orchard\n\n\nFederico Viticci\nFraser Spiers\n\n\nChristina Warren\nSimone de Rochefort\n\n\nAlex Cox\nSavannah Million\n\n\nAndy Ihnatko\nFlorence Ion\n\n\nStephen M. Hackett\nMyke Hurley\n\n\nJason Snell\nStephen M. Hackett\n\n\nK Tempest Bradford\nAleen Simms\n\n\nMyke Hurley\nStephen M. Hackett\n\n\n\nWe can turn this data frame of host-pair combinations into a tidygraph object with the as_tbl_graph() function. This class of object contains two data frames (the nodes and the edges) and some metadata.\nWe can also use functions from the {tidygraph}package to help calculate various network statistics. For example, the centrality_degree() function tells us the nodes with the most connections. We can add this as a column in our node data and use this later to do things like resize nodes depending on their centrality.\nYou can manipulate the nodes and edges data frames in this tidygraph object by using the activate() function to switch between them. Currently the node data are active (it says ‘active’ above the nodes data frame), so our application of centrality_degree() to the network object will affect the node data specifically.\n\nrelay_graph &lt;- as_tbl_graph(relay_combos, directed = FALSE)%&gt;% \n  mutate(connections = centrality_degree()) %&gt;%  # number of connections\n  arrange(desc(connections))  # order by number of shows\n\nprint(relay_graph)  \n\n# A tbl_graph: 38 nodes and 64 edges\n#\n# An undirected multigraph with 8 components\n#\n# Node Data: 38 x 2 (active)\n  name               connections\n  &lt;chr&gt;                    &lt;dbl&gt;\n1 Myke Hurley                 21\n2 Stephen M. Hackett          11\n3 Brianna Wu                   9\n4 Mikah Sargent                9\n5 Federico Viticci             8\n6 Georgia Dow                  7\n# … with 32 more rows\n#\n# Edge Data: 64 x 3\n   from    to Podcast   \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;     \n1    10    10 Almanac   \n2     1    30 Analog(ue)\n3    11    31 Automators\n# … with 61 more rows\nThe edges and nodes are now in the same object. You can see we have about 38 nodes and 64 edges and that the network is undirected (nodes don’t ‘point’ to each other). We also have eight ‘components’, which are the isolated groups of nodes that connect to each other, but not to other groups."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#visualisation",
    "href": "posts/2019-02-14-relayverse/index.html#visualisation",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Visualisation",
    "text": "Visualisation\n\nStatic with {ggraph}\nThe {ggraph} package was designed to work seamlessly with {tidygraph}objects and the {ggplot2} plotting package. You simply pass your {tidygraph}object to {ggraph}‘s ’graph’ argument. Below are a couple of examples for demonstration purposes that show you just a handful of options. You can learn more about {ggraph}’s layouts, nodes and edges in a series of blog posts from Thomas Lin Pedersen. This example arranges the nodes (hosts) circularly (plot A) and a straight line (B) and sizes them by the number of connections to other hosts. Each line (edge) represents a co-hosting relationship.\n\ng1 &lt;- ggraph(\n  graph = relay_graph,\n  layout = \"linear\",\n  circular = TRUE\n) +\n  geom_node_point(aes(size = connections)) +\n  geom_edge_arc() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\ng2 &lt;- ggraph(\n  graph = relay_graph,\n  layout = \"linear\"\n) +\n  geom_node_point(aes(size = connections)) +\n  geom_edge_arc() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\nplot_grid(g1, g2, labels = c(\"A\", \"B\"))\n\n\nThis example arranges the nodes (hosts) according to an algorithm specified by the layout argument to ggraph() and sizes them by the number of connections to other hosts. Each line (edge) represents a co-hosting relationship and multiple connections are shown separately by ‘fanning’ them out (hence the geom_edge_fan()).\n\nggraph(graph = relay_graph, layout = \"nicely\") + \n  geom_node_point(aes(size = connections)) +\n  geom_edge_fan() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\nI haven’t added labels on the nodes nor the points because of the visual clutter it creates for this particular example. You could use geom_node_text() to add node labels and something like aes(label = &lt;column_name&gt;) in your edge geom to label the connections.\nThis is where interactive network graphs come in handy, as you can zoom, pan and hover to get more info.\n\n\nInteractive with {visNetwork}\nThe {visNetwork} package wraps the vis.js library to make interactive network graphs. Its visNetwork() function takes separate data frames of edges and nodes that are in a pre-specified format, so we won’t be able to use our tidygraph object for this.\n\n# Dataframe of unique nodes with an ID value\nnodes &lt;- shows_clean %&gt;%  # take our podcast-host dataset\n  distinct(Hosts) %&gt;%  # get column of unique hosts\n  arrange(Hosts) %&gt;%  # alphabetical order\n  mutate(id = as.character(row_number()), label = Hosts) %&gt;% \n  select(-Hosts) #%&gt;%  # provides pop up value on viz\n\n# Dataframe of 'origin' and 'destination' nodes for edge drawing\nedges &lt;- relay_combos %&gt;% \n  left_join(nodes, by = c(\"V1\" = \"label\")) %&gt;% \n  left_join(nodes, by = c(\"V2\" = \"label\")) %&gt;%\n  rename(from = id.x, to = id.y, title = Podcast)\n\nNow we plug the data into the visNetwork() function and pipe this into some other other functions to set some options. It’s quite a lot of code, but the piping into other vis*() functions breaks it up into more manageable chunks.\n\nvisNetwork(  # add main features\n  nodes, edges,  # add node and edge data\n  main = list(  # set main title and style it\n    text = \"The Relayverse\",\n    style = \"font-family:Lekton, monospace;font-weight:bold;font-size:30px;text-align:center;\"\n  ),\n  submain = list(  # set subtitle and style it\n    text = \"Click hosts (nodes) to see co-host relationships (edges)\",\n    style = \"font-family:Lekton, monospace;font-weight:regular;font-size:20px;text-align:center;\"\n  ),\n  footer = list(  # add a footer and style it\n    text = paste0(\"Source: Wikipedia (\", format(Sys.Date(), \"%Y/%m/%d\"), \")\"),\n    style = \"font-family:Lekton, monospace;font-weight:regular;font-size:15px;text-align:right;\"\n  )\n) %&gt;% \n  visNodes(  # node styling\n    shape = \"icon\",  # node is an icon specified below \n    icon = list(code = \"f130\", size = 75, color = \"#000000\"),  # microphone icon\n    font = list(face = \"Lekton\", size = 20)\n  ) %&gt;% \n  visEdges(  # edge styling\n    color = list(color = \"#447d9b\", highlight = \"#c83c3c\", opacity = 0.5),\n    width = 3, selectionWidth = 5  # selected edge is thicker\n  ) %&gt;% \n  visOptions(  # general graph options\n    highlightNearest = TRUE,  # on-hover highlight nearest nodes\n    nodesIdSelection = TRUE  # select node from dropdown\n  ) %&gt;%\n  visPhysics(  # set physics 'engine' and options\n    solver = \"forceAtlas2Based\", \n    forceAtlas2Based = list(gravitationalConstant = -50)\n  ) %&gt;%\n  visLayout(randomSeed = 1337) %&gt;%  # reproduce the same network each time\n  visInteraction(navigationButtons = TRUE) %&gt;%  # add naviagation buttons\n  addFontAwesome()  # makes sure that FontAwesome dependency is in place\n\nAnd that outputs the graph below. You can:\n\nuse the navigation buttons or your trackpad/mouse to navigate the network\nclick a node to highlight a host and their co-hosts (single hosts loop back to themselves)\nhover over an edge to show a label with the show name\nselect a host from the dropdown menu to highlight them and their co-hosts\nclick and drag a node to move it\n\n\n\n\n\n\n\n\n\nYou can also view the network in its own window.\nThis is a very simple example, but lots of other {visNetwork} options are available."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#what-now",
    "href": "posts/2019-02-14-relayverse/index.html#what-now",
    "title": "Graphing the Relayverse of podcasts",
    "section": "What now?",
    "text": "What now?\nThis was really just an introduction to {tidygraph}, {ggraph} and {visNetwork}. These packages make network analysis a little more consistent and can provide some interesting stats and visuals very quickly. A next step might be to produce a ‘network of podcast networks’, since Relay FM hosts appear in shows on other networks as well."
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#environment",
    "href": "posts/2019-02-14-relayverse/index.html#environment",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-14 08:53:33 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2019-02-14-relayverse/index.html#footnotes",
    "href": "posts/2019-02-14-relayverse/index.html#footnotes",
    "title": "Graphing the Relayverse of podcasts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSome personal favourites: Analogue, Cortex, Playing For Fun, Reconcilable Differences, Top Four and Connected.↩︎\nTry SelectorGadget or your your browser’s ‘Inspect’ tool to help isolate the xpath of the element of interest.↩︎\nThe regex (?&lt;=[a-z])(?=[A-Z]) can be interpreted as ‘split after but not including (?&lt;=) a lowercase letter ([a-z]), and before but not including (?=) a capital letter ([A-Z])’.↩︎\nWe want combinations, not permutations. ‘Federico Viticci to Stephen M. Hackett’ is the same as ‘Stephen M. Hackett to Federico Viticci’, for example.↩︎"
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#tldr",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#tldr",
    "title": "Building a {r.oguelike} in R",
    "section": "tl;dr",
    "text": "tl;dr\nI started writing a roguelike game (well, more of a ‘tech demo’) in an R package called {r.oguelike}."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#rogue-like",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#rogue-like",
    "title": "Building a {r.oguelike} in R",
    "section": "Rogue… like?",
    "text": "Rogue… like?\nThere’s loads of video game genres: beat ’em up, platformer, rhythm, MMORPG, sports, puzzle. Have you heard of roguelikes?\nThe name is literal: they’re games that play like Rogue, a legendary dungeon-explorer from 1980 that set the bar for role-playing games.\nPerhaps most recognisably, it used ASCII text as ‘graphics’: the player controls a character denoted by the at symbol (@), while floor tiles are made of periods (.), for example.\n\n\n\nScreenshot of Rogue via Thedarkb on Wikipedia\n\n\nThere are many interpretations of what exactly constitutes a ‘roguelike’, one of which is the strict ‘Berlin Interpretation’1. Must-haves include:\n\nrandomly-generated dungeons (a different map every time)\npermadeath (it’s game over when you die)\nturn-based battles (limitless thinking time, then one action)\ngrid-based (everything takes up one tile of space)\nnon-modal (all actions are possible at any time)\ncomplexity (rich problem solving with items, characters and interactions)\nresource management (items are limited and must be managed)\nhack ‘n’ slash (kill lots of monsters)\nexploration and discovery (find all corners of the map to solve problems)\n\nThese aren’t necessarily hard and fast rules—many games have added their own twist—but they provide the essence of the genre."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#like-rogue",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#like-rogue",
    "title": "Building a {r.oguelike} in R",
    "section": "Like Rogue!",
    "text": "Like Rogue!\nSo, what would it take to make a roguelike using R?\nI once made a tiny game-in-a-package called {ActionSquirrel}. You control an emoji squirrel on the R console, moving around a forest grid to collect randomly-placed nuts. Collect enough nuts to survive winter, which arrives within a certain number of turns, while avoiding a randomly-moving owl.\n\nx &lt;- ActionSquirrel::ActionSquirrel$new()\n\n\f🌳 🌳 🌳 🌳 🌳 \n🌳 🌳 🌰 🌳 🌳 \n🌳 🌳 🌳 🐿 🌳 \n🌳 🦉 🌳 🌳 🌳 \n🌳 🌳 🌳 🌳 🌳 \nMoves: 0 \nNuts: 0\n\n\nThat’s not far off from some of the roguelike requirements: it has randomness and permadeath, is turn-based and grid-based and has non-modality. But it’s missing complexity, resource management, hack ‘n’ slash gameplay and exploration.\nAnd the aesthetic isn’t particularly… dungeony?"
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#r.oguelike",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#r.oguelike",
    "title": "Building a {r.oguelike} in R",
    "section": "{r.oguelike}",
    "text": "{r.oguelike}\nSo I started to build an R package containing an ‘engine’ for a game in the roguelike style, called {r.oguelike}.\nYou can visit the package website or look at the source code in the GitHub repo.\n\nFor now it’s just a toy to demo some possible approaches for some of the main game elements: ‘graphics’, movement, an inventory, item use and battling.\nAs ever, everything in the package is subject to change and improvement (though I also may never finish it). Consider this a quick devlog about progress so far.2\n\nInstall (or don’t)\nYou can install from GitHub to make the package available on your machine.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r.oguelike\")\n\nIf you prefer, you can also play in your browser without having to install anything. I’ve set up a Binder instance of RStudio with {r.oguelike} preinstalled so you can just click the button below to launch it (it may take a moment to load):\n\n\n\nLaunch Rstudio Binder\n\n\nThis also means it’s possible to play this game from your phone, lol.\n\n Note\nThe {r.oguelike} package is a work in progress and is developing at pace. Many things explained below may have been superseded or changed by the time you read this.\n\n\n\nDemo\nTop-tip: improve immersion by changing your console colour palette to dark mode, so it’s like you’re really inside a cave, wow.\nTo begin:\n\nr.oguelike::start_game()\n\nWhen you start, the console clears and the user interface is printed.\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . a . . # \n# . . . . . @ . # \n# # # # # # # # # \nT: 25 | HP: 10 | G: 0 | A: 0\nPress key to start\nInput: \nAt the top is a map of a dungeon room, made of floor (.) and wall (#) tiles. The room has randomly-selected dimensions from within a certain range. Within the room are randomly-placed characters and objects: the player (@), an enemy (E), and a collectible apple (a) and gold ($).\nBelow the dungeon room there’s:\n\na status/inventory bar, which gives a numeric value for Turns remaining, Hit Points, Gold and Apples3\na status message to provide information, usually to let the user know what has just happened\na prompt for the user to input a key press\n\nThe game is turn-based and begins when the user chooses a direction to move the player character. There are two methods for registering a key press:\n\npress W, A, S or D (i.e. up, left, down or right) and hit Enter\njust press an arrow key if your console supports {keypress} (not available in RStudio), a package from Gábor Csárdi that I wrote about recently\n\nIn this demo, let’s aim first for the apple. The apple will return us 1 HP when consumed, so it’s a good idea to get it in our inventory as soon as possible. So, let’s input W and Enter (or press the up arrow if {keypress} is enabled).\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . a @ . # \n# . . . . . . . # \n# # # # # # # # # \nT: 24 | HP: 10 | G: 0 | A: 0\nMoved up\nInput: \nThe console will wipe the user interface will be re-printed. You’ll notice that your character has moved up one tile, the turn counter has decreased by 1 and the status message has changed to say ‘Moved up’.\nNow we can move left to collect the apple.\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . @ . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 23 | HP: 10 | G: 0 | A: 1\nCollected apple (+1 A)\nInput: \nAgain, you can see the player has progressed one tile and the turn counter decreased. You’ll notice that the inventory spot for the apple increased by 1 and the status message has changed to Collected apple (+1 A) so we know what happened.\nWhat next? Let’s aim for the loot, signified by $ on the map. I’ll fast-forward to show you what happens after moving left twice and up twice.\n# # # # # # # # # \n# . . @ . . E . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 19 | HP: 10 | G: 1 | A: 1\nFound gold (+1 G)\nInput: \nThe player now occupies the space where the gold was and the turn counter has decreased by 4. You’ll see that the status messages has updated to Found gold (+1 G) and the gold spot in the inventory has increased by 1, but note that the amount of gold is randomly selected from a range of possible values.\nThere’s one obvious target left: the enemy character (E). So if we move right twice, we’ll start an encounter.\nWhen you occupy the space of the enemy, you begin a turn-based battle. At the moment, this is actually an ‘auto-battler’: a routine is run under-the-hood where the player and enemy trade blows until one is vanquished.\nEach character has attack and HP values. Of course, you can see that the player has 10 HP to start, but they also have attack strength of 2. The enemy character starts with a randomly selected HP value from within a range, and their attack strength is 1. The player attacks first, so will receive three points of damage from the enemy that has 4 HP, for example.\n# # # # # # # # # \n# . . . . . @ . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 12 | HP: 7 | G: 1 | A: 1\nYou win! (-3 HP)\nInput: \nSo we know we won because the status message changed to You win! and a note of how many hit points we lost: (-3 HP). Concurrently the HP in the inventory bar has reduced by that amount.\nHaving lost some HP, we can add some back by consuming the apple, an action mapped to the number 1 key on your keyboard (regardless of whether you’re using {keypress} or not).\n# # # # # # # # # \n# . . . . . @ . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 11 | HP: 8 | G: 1 | A: 0\nAte apple (+1 HP)\nInput: \nSo we get a message Ate apple and that our hit points have increased as a result: (+1 HP). Of course, this means that the apple spot in the inventory has decreased to zero. Note that the HP maxes out at 10, so eating the apple won’t raise the HP value above that.\nThis is the end of the demo: you’ve collected all the items and defeated the enemy. But I also added a lose condition, which occurs when you run out of turns.\n# # # # # # # # # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# @ . . . . . . # \n# # # # # # # # # \nT: 1 | HP: 8 | G: 1 | A: 0\nMoved left\nInput: a\nYou died (max turns)! Try again!\n&gt; \nThe game ends and the command prompt (&gt;) returns.\n\n\nEngine?\nThe technicals aren’t much to marvel at, really, but you can take a look at the code in the GitHub repo or on the website.\nI called it an ‘engine’ earlier, but that was deceitful, lol.\nIt’s just a while loop that keeps running so long as the is_alive state is set to TRUE. So running out of turns sets the is_alive value to FALSE and the loop is broken.\nThe content of the loop is run after the player inputs a key press, which results in various counters being adjusted for the HP, etc. The loop concludes by printing the room with updated player locations, inventory bar and status messsage, ready for the next input.\nThe room itself is just a matrix. When you move the player, a small calculation is done to determine where the player character should be in the next iteration. Imagine the player is in the centre of a 3 by 3 room, i.e. they’re in position [2,2] of a matrix with x and y dimensions of 3. If they move down, that’s equivalent to adding 1 to their current position, so 5 + 1 = 6. Similarly, moving right would be equivalent to adding 3, so 5 + 3 = 8.\n\nmatrix(1:9, 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nThe code is pretty rough and you can see that the logic can start to become complicated quickly, but remember it’s just a demo for now.\n\n\nObvious improvements\nThere’s some obvious user-facing improvements to the features that are already in place:\n\ninteractive turn-based battles, where the user can choose what move to make (perhaps defensive moves, HP replenishment or magic)\nenemy movement, so they aren’t just stationary\ndifferent enemy types, with differing ‘AI’ (random movement, ‘chase’ player, etc) and attack/HP stats\ntraps (e.g. certain tiles are hidden traps, some collectible items are bogus)\nfog of war/vision cones (you can’t see what’s ahead until you get there, or you can only see a certain distance around you at all times)\n\nThere’s also a big-ticket item I haven’t touched: randomised or procedural dungeon generation. This is quite a big task and might end up as a blog post of its own. I encourage you to watch Herbert Wolverson’s talk at Roguelike Celebration 2020 for some ideas on this. At least at first, it could simply involve letting the player walk through doors to a few other rooms that contain randomised items.\nOn the back-end, I’ve so far written everything in base R; the only dependency is {keypress} to make inputs easier for consoles that support it. But there’s only so many if-else statements you can write before your brain explodes. To this end, I’m working in a branch to make use of the object-oriented approach of the {R6} package–as used in {ActionSquirrel}–to create general objects like enemies, rooms, etc, that should make it easier to handle and work with the elements of the game."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#the-future",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#the-future",
    "title": "Building a {r.oguelike} in R",
    "section": "The future",
    "text": "The future\nThe package will change and grow as I add stuff, so do check out the repo on GitHub for any updates that may happened since you read this post.\nObviously I’ll need some seed funding to set up my indie game company so I can begin making a cool 3D version of this. Oh, wait, mifekc is already on the case!\nAlright, nevermind. How about, erm, a roguelike-themed Wordle? Oh wait, it’s already been done!\nMight just take a nap instead, to be honest.\n\n Note\nYou can now read about how I’ve generated and integrated (very simple) procedural dungeons into the package, replacing the rectangular rooms demonstrated above."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#environment",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#environment",
    "title": "Building a {r.oguelike} in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:15:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31        R6_2.5.1             fastmap_1.1.1       \n [4] xfun_0.39            fontawesome_0.5.1    knitr_1.43.1        \n [7] htmltools_0.5.5      rmarkdown_2.23       cli_3.6.1           \n[10] ActionSquirrel_0.1.0 compiler_4.3.1       rstudioapi_0.15.0   \n[13] tools_4.3.1          evaluate_0.21        yaml_2.3.7          \n[16] rlang_1.1.1          jsonlite_1.8.7       htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#footnotes",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#footnotes",
    "title": "Building a {r.oguelike} in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Design Doc YouTube channel has a nice explainer.↩︎\nI’ve been watching indie game devlogs on YouTube by people like Sebastian Lague, Karl (ThinMatrix) and Dani. I’d love to see more of this sort of thing for R package development, like what Bruno Rodrigues has been doing on YouTube for the development of the {chronicler} package, for example.↩︎\nWhy are they $ and a on the map, but G and A in the inventory bar? Good question. I’ll probably change that in future.↩︎"
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#tldr",
    "href": "posts/2023-09-17-choosethis/index.html#tldr",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "tl;dr",
    "text": "tl;dr\nThe {cli} R package can help build clickable hyperlinks in the R console, which you can use to execute functions. Of course, I used this for japes."
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#error",
    "href": "posts/2023-09-17-choosethis/index.html#error",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "Error!",
    "text": "Error!\nHave you noticed that tidyverse error messages are both helpful and pretty? This is in part due to Gabor’s {cli} package, which helps to style command-line output. Sometimes I make errors on purpose just to see these messages (that’s how I explain my mistakes to colleagues, anyway).\nHave you noticed that sometimes the error message will include a link that, when clicked, will execute some code to help explore the bug? When you hover over the link, you get a popup in RStudio showing you a green ‘play’ arrow, the name and description of the function and the phrase ‘click to run’.\nFor example, if we ask {dplyr}’s select() to retain a column that doesn’t exist and then hover over the link in the error message:\n\nThat’s curious isn’t it? It also appears in other scenarios and sometimes even links to specific lines in specific scripts."
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#how",
    "href": "posts/2023-09-17-choosethis/index.html#how",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "How?",
    "text": "How?\n{cli} functions like cli_text() accept {glue} strings that begin with a .run keyword and contain a Markdown hyperlink. Something like this: \"{.run [function](package::function())}\". The outcome is a link in the console with the text ‘function’ that will execute package::function() when clicked.\nYou can read more about hyperlinks in the {cli} docs. There’s some limitations, including that your terminal must be capable of supporting this type of hyperlink (RStudio is capable). Note also that links are ‘experimental’ in {cli}.\nYou might be wondering if a bad actor could exploit this to execute arbitrary code. As per the {cli} docs, there are several restrictions in place:\n\nTo make .run hyperlinks more secure, RStudio [will] not run code\n\nthat is not in the pkg::fun(args) form,\nif args contains (, ) or ;,\nif it calls a core package (base, stats, etc.),\nif it calls a package that is not loaded, and it is not one of testthat, devtools, usethis, or rlang, which are explicitly allowed.\n\n\nNote that this doesn’t stop nerd hobbyists like me from going off-piste."
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#demos",
    "href": "posts/2023-09-17-choosethis/index.html#demos",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "Demos",
    "text": "Demos\nI’ve made two quick sketches that use {cli}’s .run-enabled links. I’ve put these in the {choosethis} package1, which is on GitHub.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/choosethis\")\n\nThese nonserious demos are pretty minimal and only exist to prove the point. Maybe you can take these ideas and run with them?\n\n1. A clickable text adventure\nYou can set up a narrative in the console that prompts the user for an action to advance the story. Clicking a link takes you down a story branch and prompts you with a new set of options.\n\n\n\n\n\nIn other words, a classic text adventure in with the flavour of a ‘Choose Your Own Adventure’ book.\nThis works by setting up a function for each option. Click a link and it will run that function, which itself will present more clickable options with their own underlying functions. And so on. In this demo, the chain starts when the user runs choosethis::begin().\nOf course, the more complicated the story, the more functions there are to create and maintain.\n\n\n2. An R GUI\nAdriana suggested that .run could be used to create a sort-of ‘clickable R interface’ to do away with all that pesky typing and emulate superior statistical packages like SPSS, lol. She was definitely joking2, but like, you could do something like that, right?3\nBut this is… tricky. First there’s the limitations of .run itself, but the user prompts could also become overwhelming. For example, if you want to summarise a data.frame. Which columns should be summarised? Do you want the sum or mean or something else? Should NAs be ignored? And so on.\nI made a tiny demo of this anyway. The user runs choosethis::ask_col_means() with a data.frame and they’re presented the names of any numeric columns as clickable links. The dataframe and selected column name are passed to choosethis::get_mean(), a bespoke function for calculating the summary.\n\n\n\n\n\nYes, due (I think) to the limitations of .run, we need a separate function in the package to calculate the mean for us (at least I think that’s the case). You can see how tedious it would be to wrap loads of potential summary functions using this approach.\n\n\n3. Bonus: de-linkification\nIt feels a bit mean to write an exciting text adventure that people can’t play if their terminal doesn’t support hyperlinks. So you can check the user’s console and either provide them an executable link, or otherwise print the underlying expression to copy-paste.\nTo perform this check, you can use cli::ansi_has_hyperlink_support()4. I added the argument show_links to the choosethis::begin() function that defaults to this:\n\ngetOption(\"choosethis.show_links\", cli::ansi_has_hyperlink_support())\n\nBy making this an option, the user can set options(choosethis.show_links = FALSE) to avoid seeing links even if their terminal supports them."
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#hype-man",
    "href": "posts/2023-09-17-choosethis/index.html#hype-man",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "Hype man",
    "text": "Hype man\nSo yeah, hyperlinks are ‘experimental’ in {cli} and—quite rightly—they’re limited to prevent nefarious activity. Everything I’ve created here might stop working tomorrow. And of course, the intent for links is to help people with errors, not mess around. But it is fun isn’t it?\nI’d be interested to know if anyone is already using {cli}-enacted links in their packages, or if the ideas in {choosethis} spark some inspiration."
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#environment",
    "href": "posts/2023-09-17-choosethis/index.html#environment",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-13 09:58:39 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       evaluate_0.23"
  },
  {
    "objectID": "posts/2023-09-17-choosethis/index.html#footnotes",
    "href": "posts/2023-09-17-choosethis/index.html#footnotes",
    "title": "{cli}ckable hyperlinks in the R console",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, a very clever pun on {usethis}, but infinitely less useful than that package.↩︎\nMy lawyers have insisted I must clarify that, unequivocally, she definitely does not want R to be corrupted into an SPSS-like thing.↩︎\nDoesn’t mean you should, amirite.↩︎\nThanks to Tim for suggesting a method for using options in this function.↩︎"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html",
    "href": "posts/2019-11-27-pivot/index.html",
    "title": "A pivotal change to Software Carpentry",
    "section": "",
    "text": "Via frinkiac.com"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#tldr",
    "href": "posts/2019-11-27-pivot/index.html#tldr",
    "title": "A pivotal change to Software Carpentry",
    "section": "tl;dr",
    "text": "tl;dr\nTeaching materials from The Carpentries depend on the community to amend and update them. This post is about my first proper contribution by helping to update the Software Carpentry lesson that teaches the R package {tidyr}.\nSome helpful materials for learning about {tidyr}’s new pivot_*() functions:\n\nthe {tidyr} vignette about pivoting\nHiroaki Yutani’s slides — ’A graphical introduction to tide’s pivot_*()’\nBruno Rodrigues’s blogpost — ‘Pivoting data frames just got easier thanks to pivot_wide() and pivot_long()’\nSharon Machlis’s video — ‘How to reshape data with tidyr’s new pivot functions’\nGavin Simpson’s blog — ‘Pivoting tidily’ (a real-world problem)\nI wrote a {tidyr} lesson for Tidyswirl, a Swirl course for learning the tidyverse from within R itself (read the blog post)"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#contribute",
    "href": "posts/2019-11-27-pivot/index.html#contribute",
    "title": "A pivotal change to Software Carpentry",
    "section": "Contribute!",
    "text": "Contribute!\nSoftware Carpentry ‘teach[es] foundational coding and data science skills to researchers worldwide’ as part of The Carpentries initiative. I wrote an earlier post about live coding1 as part of the training to become an instructor.\nA great thing about the The Carpentries is that the lessons are openly available on GitHub. This means anyone can improve them to improve the experience for learners all over the globe.\nTo this end, I raised in in an issue: to update the entire episode about {tidyr}–a tidyverse package used for reshaping data frames–in the R for Reproducible Scientific Analysis lesson.2"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#pivot",
    "href": "posts/2019-11-27-pivot/index.html#pivot",
    "title": "A pivotal change to Software Carpentry",
    "section": "Pivot",
    "text": "Pivot\nWhy? The pivot_longer() and pivot_wider() functions replaced spread() and gather() in {tidyr} version 1.0.0.\nThese pairs of functions change the ‘shape’ of a data set from ‘wide’ to ‘long’ and vice versa.\nHere’s an example of wide data from the World Health Organisation:\n\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nThere’s a row per country and a column per year of data. Each yearly column filled with a value. Note that these data aren’t ‘tidy’: the column headers are values, not variable names, and there isn’t a single observation per row. You have no way of knowing that the values in the columns are tuberculosis cases.\nThis data frame can be made more tidy by making it longer. Here’s what that looks like:\n\n\n# A tibble: 6 × 3\n  country      year  cases\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan  1999    745\n2 Afghanistan  2000   2666\n3 Brazil       1999  37737\n4 Brazil       2000  80488\n5 China        1999 212258\n6 China        2000 213766\n\n\nSo the year values from the headers have been put into their own column and the corresponding counts of tuberculosis are in a column with a more sensible name.\n{tidyr} helps you shift between these formats: pivot_wider() spreads long data into wide form and pivot_longer() gathers the wide data into long form. Why these names? Hadley did a poll to see how people referred to these two table shapes and ‘wider’ and ‘longer’ were most popular.3"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#re-writing-the-episode",
    "href": "posts/2019-11-27-pivot/index.html#re-writing-the-episode",
    "title": "A pivotal change to Software Carpentry",
    "section": "Re-writing the episode",
    "text": "Re-writing the episode\nI started re-writing the episode, but turns out it wasn’t as simple as replacing spread() with pivot_longer() and gather() with pivot_wider(). For two reasons: different function arguments and slightly different outputs.\n\nArguments\nThe key and value arguments take the names of new columns to gather() into or spread(). People struggle with what these things mean. The pivot_*() functions make this a little easier: pivot_longer() has names_to and values_to, and pivot_wider() has names_from and values_from. The ‘to’ and ‘from’ suffixes make clearer what is happening.\nFor example, we can start with our wide-table example (built into the {tidyr} package as table4a) and turn it into the long-table example:\n\nlibrary(tidyr)\n\nlong &lt;- pivot_longer(\n  data = table4a,  # wide data example \n  cols = c(`1999`, `2000`),  # the columns to be pivoted\n  names_to = \"year\",  # new column for the current column headers\n  values_to = \"cases\"  # new column for the corresponding values\n)\n\nprint(long)\n\n# A tibble: 6 × 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\nAnd back:\n\nwide &lt;- pivot_wider(\n  data = long,  # dataset created above\n  names_from = year,  # create cols from data in this column\n  values_from = cases  # fill the new columns with data from this column\n)\n\nprint(wide)\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nIt was pretty straightforward to update the training materials with these function arguments, remembering that names_to needs to be supplied with a quoted string to become the name of the new column, for example, whereas names_from refers to an existing column and is a bare variable name.\n\n\nOutput changes\nI raised some things about outputs in my issue: (1) outputs from the new functions have tibble class even with a data.frame input and (2) might be ordered differently to outputs from the old functions. This required some changes to the images in the lesson, but didn’t change much else fundamentally."
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#teamwork",
    "href": "posts/2019-11-27-pivot/index.html#teamwork",
    "title": "A pivotal change to Software Carpentry",
    "section": "Teamwork",
    "text": "Teamwork\nWhile busy with other things, another user–Katrin Leinweber–took the branch I’d started, improved it and it was merged into the source thanks to Jeff Oliver. This is a huge benefit of working in the open; other people can see what you’ve done, suggest improvements and help write code.\nThe page is now live. Learners can now be up to speed with the latest developments in the {tidyr} package. This is an important improvement for new R and tidyverse users because I think these functions are more intuitive than their old counterparts, which are no longer under active development.\nConsider contributing to The Carpentries or another open-source project."
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#environment",
    "href": "posts/2019-11-27-pivot/index.html#environment",
    "title": "A pivotal change to Software Carpentry",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-23 11:23:16 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.0\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7       \n[17] lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2       htmlwidgets_1.6.2\n[21] pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[25] tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0      magrittr_2.0.3   \n[29] tools_4.3.1       withr_2.5.0"
  },
  {
    "objectID": "posts/2019-11-27-pivot/index.html#footnotes",
    "href": "posts/2019-11-27-pivot/index.html#footnotes",
    "title": "A pivotal change to Software Carpentry",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCross-posted on The Carpentries blog.↩︎\nAnd a little pull request to correct a small problem with bullet points, which helped me complete my requirements to become an instructor.↩︎\nYeah, but pivot_thicc() and pivot_sticc() would have been amusing.↩︎"
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#tldr",
    "href": "posts/2023-06-11-apple-health-redux/index.html#tldr",
    "title": "Extract run data from Apple Health (redux)",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R to extract running details from a downloaded of your Apple Health data. The format of the data has changed since I last tried this, so I re-wrote my code."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#on-your-marks",
    "href": "posts/2023-06-11-apple-health-redux/index.html#on-your-marks",
    "title": "Extract run data from Apple Health (redux)",
    "section": "On your marks",
    "text": "On your marks\nIn 2021 I extracted my running activities from my Apple Health data using the {xml2} package. You can read there for some theory and background.\nAt that point I’d been running for one year. I’m nearly at 500 runs, so I thought I would re-execute my code with the latest data. Alas, the original code no longer works because Apple seems to have updated the format of the XML file they provide.\n\n Note\nI have since re-rendered this post after passing 500 runs.\n\n\nSo I’ve written a new function that takes a path to the zipped download of my Apple Health data and outputs a dataframe of time and distance data, with one row per run."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#get-set",
    "href": "posts/2023-06-11-apple-health-redux/index.html#get-set",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Get set",
    "text": "Get set\nI followed the same steps as before to get my Apple Health data off my phone.\nI smashed together a quick function to unzip the file to a temporary location and then extract workout data using the the {xml2} package. There’s a bit of base R wrangling to output a dataframe with a row per run workout, focusing on total time and distance.\n\n\nClick to expand the function definition\n\n\nget_run_distances &lt;- function(zip_path) {\n  \n  # Unzip Apple Health export to temporary location\n  message(\"Unzipping and reading XML\")\n  temp &lt;- tempdir()\n  unzip(zipfile = zip_path, exdir = temp)\n  xml_in &lt;- xml2::read_xml(file.path(temp, \"apple_health_export\", \"export.xml\"))\n  unlink(temp)\n  \n  # Isolate workouts only and convert to an R list object\n  message(\"Isolating workouts from XML\")\n  wo_in &lt;- xml2::xml_find_all(xml_in, \"//Workout\") |&gt; xml2::as_list()\n  \n  # Pre-allocate a list to be filled with output data\n  wo_total &lt;- length(wo_in)\n  wo_out &lt;- vector(\"list\", wo_total)\n  \n  # For each viable workout, extract the details\n  message(\"Iterating over workouts to extract run data\")\n  for (wo_n in seq(wo_total)) {\n    \n    # Extract details for current workout\n    wo &lt;- wo_in[[wo_n]]\n    wo_attrs &lt;- attributes(wo)  # the data is stored as attributes\n    is_run &lt;- \n      wo_attrs[[\"workoutActivityType\"]] == \"HKWorkoutActivityTypeRunning\"\n    \n    # If the workout wasn't a run, then skip to the next workout\n    if (!is_run) next\n    \n    # if it is a run, then extract the data to a single-row dataframe\n    if (is_run) {\n      \n      # There can be more than one element named 'WorkoutStatistics'. We want to \n      # get the one with distance information and extract the details.\n      wo_stats &lt;- wo[grep(\"WorkoutStatistics\", names(wo))]\n      wo_stats_types &lt;- lapply(wo_stats, \\(x) attr(x, c(\"type\")))\n      dist_type &lt;- \"HKQuantityTypeIdentifierDistanceWalkingRunning\"\n      dist_index &lt;- which(wo_stats_types == dist_type)\n      wo_dist &lt;- wo_stats[[dist_index]]\n      \n      # Prepare single-row dataframe and add to the pre-allocated list\n      wo_details &lt;- data.frame(\n        source = wo_attrs[[\"sourceName\"]],\n        start = as.POSIXct(wo_attrs[[\"startDate\"]]),\n        end = as.POSIXct(wo_attrs[[\"endDate\"]]),\n        distance_km = attr(wo_dist, \"sum\") |&gt; as.numeric() |&gt; round(2)\n      )\n      wo_details[[\"duration_s\"]] &lt;- \n        as.numeric(wo_details[[\"end\"]] - wo_details[[\"start\"]], units = \"secs\")\n      wo_out[[wo_n]] &lt;- wo_details\n      \n    }\n    \n  }\n  \n  # Convert to dataframe, select columns\n  message(\"Combining data\")\n  wo_out_df &lt;- do.call(rbind, wo_out)\n  wo_out_df[, c(\"source\", \"start\", \"end\", \"duration_s\", \"distance_km\")]\n  \n}\n\n\nI won’t go through it line by line, but there’s some commentary to explain what’s happening at each step. It does what I need it to do for now, but no doubt there’s some refactoring to be done.\nThere’s a few things to note:\n\nI’m more comfortable handling R objects, so I converted early to a list with xml2::as_list(). Awkwardly, the data in the list object was stored as attributes to each element.\nThe distance data is stored in an element called ‘WorkoutStatistics’, but more than one element will have this name. We first have to isolate the element that is of the correct type, which has the name ‘HKQuantityTypeIdentifierDistanceWalkingRunning’.\nI converted the start and end variables to datetime class (POSIXct) and subtracted one from the other to get the duration of the run. This yields the ‘difftime’ class that can be converted to seconds with as.numeric() and the argument units = \"secs\".\nThere’s no input handling, because this was quick and for ‘fun’, lol."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#go",
    "href": "posts/2023-06-11-apple-health-redux/index.html#go",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Go",
    "text": "Go\nSo, to use the function you pass a path to where your zipped Apple Health export lives. Mine is in my ‘Documents’ folder.\n\nruns &lt;- get_run_distances(\"~/Documents/data/export.zip\")\n\nUnzipping and reading XML\n\n\nIsolating workouts from XML\n\n\nIterating over workouts to extract run data\n\n\nCombining data\n\n\nI recorded all my runs with the Nike Run Club app, so I’ll filter out duplicates where I dual-recorded with Apple’s Workout app. I think I accidentally started the app by mistake a couple of times, so we’ll only grab runs of over 1 km. I’ll also convert the seconds to a friendlier-looking ‘period’ class using {lubridate}1.\nHere’s the most recent few:\n\nruns &lt;- runs[runs$source == \"Nike Run Club\" & runs$distance_km &gt; 1, ]\nruns$duration &lt;- lubridate::seconds_to_period(runs$duration_s)\nruns &lt;- runs[, c(\"start\", \"distance_km\", \"duration\")]\nrow.names(runs) &lt;- NULL\ntail(runs)\n\n                  start distance_km duration\n497 2023-06-15 08:45:46        6.39  30M 36S\n498 2023-06-17 11:07:03       10.52  50M 58S\n499 2023-06-18 10:36:58       10.42  51M 29S\n500 2023-06-22 08:14:51        6.34  30M 43S\n501 2023-06-24 08:47:05       10.13  48M 43S\n502 2023-06-25 09:20:20       12.12  59M 48S\n\n\nFor my own tracking purposes, I’ve run:\n\n502 times\nfor a total distance of 4119 km\nfor a total duration of about 14 days\n\nAnd I can recreate a couple of the plots from the old post while we’re here. Here’s the ‘run barcode’, with one vertical line per run (the darker it is the greater the distance):\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tidyr)\n\nrun_days &lt;- left_join(\n  data.frame(date = as_date(ymd(\"2020-03-23\"):ymd(\"2023-06-25\"))),\n  runs |&gt;\n    transmute(date = ymd(as_date(start)), km = distance_km, duration) |&gt;\n    filter(date &gt;= \"2020-03-23\" & date &lt;= \"2023-06-25\") |&gt;\n    group_by(date) |&gt; \n    summarise(km = sum(km), .groups = \"drop\"),\n  by = \"date\"\n) |&gt;\n  replace_na(list(run = 0))\n\npar(mar = rep(0, 4))\nimage(matrix(run_days$km), col = grey.colors(11, 0.8, 0))\nbox(col = \"white\")\n\n\n\n\nAnd of course, a simple distance over time plot:\n\nplot(\n  x = runs$start, \n  y = runs$distance_km, \n  las = 1,  # rotate y-axis labels\n  main = \"Runs captured with Nike Run Club in Apple Health\",\n  xlab = \"Date\",\n  ylab = \"Distance (km)\"\n)\n\n\n\n\nSome patterns are obvious. For example, there’s lots of 5 km runs until about mid-2021, when it hops to more like 7 km. That’s when I started running for 30 mins at a time, rather than for 5 km specifically.\nI’m pretty happy at 5 and 10 km, obviously, but maybe I should do more 21.1 km half-marathons. Or a full marathon? No no, that’s foolish: it would expand my y-axis too much and make it harder to observe patterns at shorter distances, amirite."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#environment",
    "href": "posts/2023-06-11-apple-health-redux/index.html#environment",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-21 19:29:55 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.0     dplyr_1.1.2     lubridate_1.9.2\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     tibble_3.2.1      fontawesome_0.5.1 fastmap_1.1.1    \n[17] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    htmlwidgets_1.6.2\n[21] timechange_0.2.0  pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.33    \n[25] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0     \n[29] magrittr_2.0.3    tools_4.3.1       xml2_1.3.5"
  },
  {
    "objectID": "posts/2023-06-11-apple-health-redux/index.html#footnotes",
    "href": "posts/2023-06-11-apple-health-redux/index.html#footnotes",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n{lubridate} is handy for time handling for many reasons. Here it’s helpful because it can resolve minutes and seconds (e.g. 21M 30S) instead of the decimal minutes (e.g. 21.5) in a difftime object.↩︎"
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html",
    "href": "posts/2020-04-05-yo-dawg/index.html",
    "title": "Plotception with {ggpattern}",
    "section": "",
    "text": "The {ggpattern} package lets you add pattern fills to your {ggplot2} plot… so I did the inevitable."
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html#tldr",
    "href": "posts/2020-04-05-yo-dawg/index.html#tldr",
    "title": "Plotception with {ggpattern}",
    "section": "",
    "text": "The {ggpattern} package lets you add pattern fills to your {ggplot2} plot… so I did the inevitable."
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html#yo-dawg",
    "href": "posts/2020-04-05-yo-dawg/index.html#yo-dawg",
    "title": "Plotception with {ggpattern}",
    "section": "Yo dawg",
    "text": "Yo dawg\nFollowers of this blog might remember the unveiling of cloud_pie(), the greatest new visualisation technique of the 21st Century.\nLuckily, R-package machine mikefc of @coolbutuseless has released {ggpattern}, which lets you image- or pattern-fill the bars of your {ggplot2} plot. Most usefully with pictures of kittens or Bill Murray.\nThis has opened the door to yet another ground-breaking viz. The secret yet obvious real purpose of {ggpattern} is to put plots inside your plots.1\nVoilà.\n\n\n\nShield the eyes of any younglings.\n\n\nIt may be too much to take in; let me explain. The main plot is of car weight by the number of cylinders from the mtcars dataset.\nBut lo, each bar is itself a plot of weight by gears for the number of cylinders on the x-axis of the main plot. The most efficient plot of all time?\nPlease clean your blown mind from the ceilling before you leave, thank you."
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html#the-secret",
    "href": "posts/2020-04-05-yo-dawg/index.html#the-secret",
    "title": "Plotception with {ggpattern}",
    "section": "The secret",
    "text": "The secret\n\n\nExpand for the full, hacky, non-reproducible code used to create this masterpiece.\n\n\n# Plot weight by cylinders, with weight by gear inside\n# Using {ggpattern} by @coolbutuseless\n# https://coolbutuseless.github.io/package/ggpattern/\n\n# Load packages\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggpattern)\n\n# Prepare mean wt per cyl with filenames for gear-wt plots\ncyl_weights &lt;- mtcars %&gt;% group_by(cyl) %&gt;% summarise(mean_wt = mean(wt))\n\n# See the pixel dimensions of the bars\n# This will depend on the size of your plot; I just used the default 7 x 7\ndummy_plot &lt;- ggplot(cyl_weights, aes(as.character(cyl), mean_wt)) +\n  geom_col_pattern(pattern = \"placeholder\", pattern_type = \"dummy\") +\n  labs(\n    title = \"Weight by gears by weight by cylinders\",\n    caption = \"Thanks to {ggpattern} by @coolbutuseless\",\n    x = \"Cylinders\", y = \"Weight\"\n  ) +\n  theme_grey(base_size = 15)\n\n# Save the dummy plot\nggsave(\"~/Desktop/dummy_plot.png\", dummy_plot)  # defaults to 7 x 7 output\n\n[](resources/dummy_plot.png]{fig-alt=“Subplot of weight by gears for 4 cylinders.” width=“100%”}\n\n# Plot of mean weight by gear for each cyl\nsub_plots &lt;- mtcars %&gt;% \n  group_by(cyl) %&gt;% nest() %&gt;% ungroup() %&gt;%  # listcol by cyl\n  mutate(\n    data_mean = map(data, ~group_by(., gear) %&gt;% summarise(mean_wt = mean(wt))),\n    plot = map(  # listcol of plots for each cyl\n      data_mean,\n      ~ggplot(., aes(as.character(gear), mean_wt)) +\n        labs(title = \"Weight by gears\", x = \"Gears\", y = \"Weight\") +\n        geom_col() +\n        theme_grey(base_size = 60)  # trial and error until it looked okay\n    ),\n    filename = paste0(cyl, \"_cyl.png\")  # unique filename based on cyl value\n  ) %&gt;% \n  arrange(cyl) %&gt;%   # in order of cy number\n  mutate(  # pixel values manually added from looking at the dummy plot output!\n    width = 141 * 0.084666667,  # conversion from pixels to mm given 300 dpi\n    height = c(261, 357, 458) * 0.084666667\n  ) %&gt;% \n  select(filename, plot, height, width)\n\n# Save the sub-plots as separate files wth provided dimensions\n# These will be read into the main plot\npwalk(sub_plots, ggsave, path = \"~/Desktop/\")\n\n\n\n# Plot weight by cylinders, with weight by gear inside\nmain_plot &lt;- cyl_weights %&gt;% \n  mutate(  # add filepaths for where to find the saved subplots\n    filename = case_when(\n      cyl == 4 ~ \"~/Desktop/4_cyl.png\",\n      cyl == 6 ~ \"~/Desktop/6_cyl.png\",\n      cyl == 8 ~ \"~/Desktop/8_cyl.png\",\n    )\n  ) %&gt;% \n  ggplot(aes(as.character(cyl), mean_wt)) +\n  geom_col_pattern(\n    aes(pattern_filename = I(filename)),\n    pattern = \"image\",\n    pattern_type = \"squish\"\n  ) +\n  labs(\n    title = \"Weight by gears by weight by cylinders\",\n    caption = \"Thanks to {ggpattern} by @coolbutuseless\",\n    x = \"Cylinders\", y = \"Weight\"\n  ) +\n  theme_grey(base_size = 15)\n\n# Save plot\nggsave(\"~/Desktop/ggpattern_plot.png\", main_plot)  # default 7 x 7 output\n\n\nIn short, you can use arguments pattern = \"placeholder\" and pattern_type = \"dummy\" to geom_col_pattern() to produce a plot containing pixel dimensions for each bar.\nFrom there, you can create plots that match those dimensions. Then you can recreate your plot but this time use argument pattern = \"image\" and provide the filepaths as an aes()thetic.\nBless you, @coolbutuseless."
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html#environment",
    "href": "posts/2020-04-05-yo-dawg/index.html#environment",
    "title": "Plotception with {ggpattern}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-22 11:54:44 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-04-05-yo-dawg/index.html#footnotes",
    "href": "posts/2020-04-05-yo-dawg/index.html#footnotes",
    "title": "Plotception with {ggpattern}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt can’t be chartjunk if it’s simply more charts, he said, posting a tweet on April 1st.↩︎"
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html",
    "href": "posts/2018-12-24-nba-travel/index.html",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "",
    "text": "Classic Jazz: Stockton to Malone for the dunk (via Giphy"
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html#tldr",
    "href": "posts/2018-12-24-nba-travel/index.html#tldr",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {osrm} R package can retrieve from the OSRM API the travel duration between points. I looked at these data for NBA basketball-team arenas, whose details I scraped from the web using {rvest} and mapped with {leaflet}.\n\n Note\nThe original version of this post used the {gmapsdistance} package. I updated it extensively in 2020 to use the {osrm} package, which doesn’t require an API key nor billing details."
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html#on-the-road",
    "href": "posts/2018-12-24-nba-travel/index.html#on-the-road",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "On the road",
    "text": "On the road\nFans don’t have far to travel in the UK if they want to see their favourite sports team play an away match.\nThe USA is pretty big, though.\nThe National Basketball Association (NBA) compensates by separating its teams into Eastern and Western conferences, each with three divisions of five teams. This means that the majority of regular-season games aren’t too far away.\nBut this varies. Teams are clustered near Lakes Michigan and Erie in the Central division, but the Northwest division stretches from Portland in the Pacific Northwest to Oklahoma City in the centre-south of the country.\nWhat would it take to be a basketball fan who wanted to drive to away games? How long would it take?"
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html#r-can-help",
    "href": "posts/2018-12-24-nba-travel/index.html#r-can-help",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "R can help",
    "text": "R can help\nSurprise, this is all a ruse for me to practice with some R packages:\n\n{rvest} for scraping web pages\n{leaflet} for interactive mapping\n{osrm} for calculating duration of travel between points\n\nThere’s four main parts to the post (click to jump):\n\nScrape team data\nMap the locations\nGet travel duration\nMake a heatmap\n\nLet’s start by attaching the packages we need. As always, make sure these are installed first, using install.packages().\n\nsuppressPackageStartupMessages({\n  \n  # Tidyverse and friends\n  library(tidyverse)  # data handling and plotting\n  library(rvest)      # scrape data\n  library(janitor)    # misc cleaning\n  \n  # Geography and travel\n  library(sf)         # handle geographies\n  library(osrm)       # fetch travel info\n  \n  # Interactive elements\n  library(leaflet)    # interactive maps\n  library(DT)         # interactive tables\n  library(plotly)     # interactive plots\n  \n})\n\n\n1. Scrape team data\n\nUse {rvest}\nThe Wikipedia page for the NBA has a table with each team and its location, including coordinates. We can use the {rvest} web-scraping package to extract that table into a data frame with these steps:\n\nRead the HTML of the page with xml2::read_html()\nExtract the HTML node for the table with rvest::html_nodes()\nParse the HTML as a table with rvest::html_table()\n\nNote that you have to provide to html_nodes() a CSS selector or an XPath that identifies the table’s ‘location’ in the HTML. You can find these using a tool like SelectorGadget, or with your browser’s ‘inspect’ tool (for Chrome, right-click the element on the page, select ‘inspect’, right-click the HTML for that element, go to ‘Copy’, then ’Copy full XPath). Beware: if the Wikipedia page changes, then this path could change in future.\n\nnba_scrape &lt;-\n  read_html(\"https://en.wikipedia.org/wiki/National_Basketball_Association\") %&gt;% \n  html_nodes(xpath = \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[4]\") %&gt;%\n  html_table(fill = TRUE, header = NA) %&gt;%\n  .[[1]]  # list was returned, so extract first list element\n\nHere’s a preview:\n\nglimpse(nba_scrape)\n\nRows: 32\nColumns: 9\n$ Division    &lt;chr&gt; \"Eastern Conference\", \"Atlantic\", \"Atlantic\", \"Atlantic\", …\n$ Team        &lt;chr&gt; \"Eastern Conference\", \"Boston Celtics\", \"Brooklyn Nets\", \"…\n$ Location    &lt;chr&gt; \"Eastern Conference\", \"Boston, Massachusetts\", \"New York C…\n$ Arena       &lt;chr&gt; \"Eastern Conference\", \"TD Garden\", \"Barclays Center\", \"Mad…\n$ Capacity    &lt;chr&gt; \"Eastern Conference\", \"19,156\", \"17,732\", \"19,812\", \"20,47…\n$ Coordinates &lt;chr&gt; \"Eastern Conference\", \".mw-parser-output .geo-default,.mw-…\n$ Founded     &lt;chr&gt; \"Eastern Conference\", \"1946\", \"1967*\", \"1946\", \"1946*\", \"1…\n$ Joined      &lt;chr&gt; \"Eastern Conference\", \"1946\", \"1976\", \"1946\", \"1949\", \"199…\n$ ``          &lt;chr&gt; \"Eastern Conference\", NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nSo, the table has been returned, but it needs to be tidied up.\n\n\nWrangle the data\nTo summarise the main cleaning steps required:\n\nremove the rogue NA-filled column\nfilter out the spanning headers that identify the conferences\nadd a column for each team’s conference\nmake numeric the arena capacity\nseparate city and state into separate columns\nisolate the latitude and longitude by separating them from the Coordinates column\nremove the ‘zero width no-break space’ unicode character in the longitude column\nretain only the columns of interest\n\n\nnba_wrangle &lt;- nba_scrape %&gt;% \n  select(-length(.)) %&gt;%  # remove the last column (NA)\n  dplyr::filter(!str_detect(Division, \"Conference\")) %&gt;% \n  mutate(\n    Conference = c(rep(\"Eastern\", 15), rep(\"Western\", 15)),\n    Capacity = as.numeric(str_remove(Capacity, \",\"))\n  ) %&gt;% \n  separate(Location, c(\"City\", \"State\"), sep = \", \") %&gt;% \n  separate(Coordinates, c(\"Coords1\", \"Coords2\", \"Coords3\"), \" / \") %&gt;% \n  separate(Coords3, c(\"Latitude\", \"Longitude\"), sep = \"; \") %&gt;% \n  separate(Longitude, c(\"Longitude\", \"X\"), sep = \" \\\\(\") %&gt;% \n  mutate(\n    Latitude = as.numeric(Latitude),\n    Longitude = as.numeric(str_remove(Longitude, \"\\\\ufeff\"))  # rogue unicode\n  ) %&gt;% \n  select(\n    Team, Conference, everything(),\n    -Founded, -Joined, -Coords1, -Coords2, -X\n  ) %&gt;% \n  as_tibble()  # convert to tibble\n\nglimpse(nba_wrangle)\n\nRows: 30\nColumns: 9\n$ Team       &lt;chr&gt; \"Boston Celtics\", \"Brooklyn Nets\", \"New York Knicks\", \"Phil…\n$ Conference &lt;chr&gt; \"Eastern\", \"Eastern\", \"Eastern\", \"Eastern\", \"Eastern\", \"Eas…\n$ Division   &lt;chr&gt; \"Atlantic\", \"Atlantic\", \"Atlantic\", \"Atlantic\", \"Atlantic\",…\n$ City       &lt;chr&gt; \"Boston\", \"New York City\", \"New York City\", \"Philadelphia\",…\n$ State      &lt;chr&gt; \"Massachusetts\", \"New York\", \"New York\", \"Pennsylvania\", \"O…\n$ Arena      &lt;chr&gt; \"TD Garden\", \"Barclays Center\", \"Madison Square Garden\", \"W…\n$ Capacity   &lt;dbl&gt; 19156, 17732, 19812, 20478, 19800, 20917, 19432, 20332, 179…\n$ Latitude   &lt;dbl&gt; 42.36630, 40.68265, 40.75056, 39.90111, 43.64333, 41.88056,…\n$ Longitude  &lt;dbl&gt; -71.06223, -73.97469, -73.99361, -75.17194, -79.37917, -87.…\n\n\n\n\nAdd more information\nI made a table of three-letter team codes and colours for the markers and icons that will appear in the pins on the interactive map. I got these from teamcolorcodes.com. With {leaflet}. The markers can only take a small set of named colours (see ?awesomeIcons), whereas the icon can use any CSS-valid colour (like hex codes).\n\n\nClick for the code that creates a data frame of team codes and colours\n\n\nnba_abbr_cols &lt;- tribble(\n  ~Code, ~Franchise, ~colour_marker, ~colour_icon,\n  \"ATL\", \"Atlanta Hawks\",          \"red\",       \"#C1D32F\",\n  \"BKN\", \"Boston Celtics\",         \"black\",     \"#FFFFFF\",\n  \"BOS\", \"Brooklyn Nets\",          \"green\",     \"#BA9653\",\n  \"CHA\", \"Charlotte Hornets\",      \"darkblue\",  \"#00788C\",\n  \"CHI\", \"Chicago Bulls\",          \"red\",       \"#000000\",\n  \"CLE\", \"Cleveland Cavaliers\",    \"darkred\",   \"#FDBB30\",\n  \"DAL\", \"Dallas Mavericks\",       \"blue\",      \"#B8C4CA\",\n  \"DEN\", \"Denver Nuggets\",         \"darkblue\",  \"#FEC524\",\n  \"DET\", \"Detroit Pistons\",        \"red\",       \"#1D42BA\",\n  \"GSW\", \"Golden State Warriors\",  \"blue\",      \"#FFC72C\",\n  \"HOU\", \"Houston Rockets\",        \"red\",       \"#000000\",\n  \"IND\", \"Indiana Pacers\",         \"darkblue\",  \"#FDBB30\",\n  \"LAC\", \"Los Angeles Clippers\",   \"red\",       \"#1D428A\",\n  \"LAL\", \"Los Angeles Lakers\",     \"blue\",      \"#FDB927\",\n  \"MEM\", \"Memphis Grizzlies\",      \"lightblue\", \"#12173F\",\n  \"MIA\", \"Miami Heat\",             \"red\",       \"#F9A01B\",\n  \"MIL\", \"Milwaukee Bucks\",        \"darkgreen\", \"#EEE1C6\",\n  \"MIN\", \"Minnesota Timberwolves\", \"darkblue\",  \"#9EA2A2\",\n  \"NOP\", \"New Orleans Pelicans\",   \"darkblue\",  \"#C8102E\",\n  \"NYK\", \"New York Knicks\",        \"blue\",      \"#F58426\",\n  \"OKC\", \"Oklahoma City Thunder\",  \"blue\",      \"#EF3B24\",\n  \"ORL\", \"Orlando Magic\",          \"blue\",      \"#C4CED4\",\n  \"PHI\", \"Philadelphia 76ers\",     \"blue\",      \"#ED174C\",\n  \"PHX\", \"Phoenix Suns\",           \"darkblue\",  \"#E56020\",\n  \"POR\", \"Portland Trail Blazers\", \"red\",       \"#000000\",\n  \"SAC\", \"Sacramento Kings\",       \"purple\",    \"#63727A\",\n  \"SAS\", \"San Antonio Spurs\",      \"black\",     \"#C4CED4\",\n  \"TOR\", \"Toronto Raptors\",        \"red\",       \"#000000\",\n  \"UTA\", \"Utah Jazz\",              \"darkblue\",  \"#F9A01B\",\n  \"WAS\", \"Washington Wizards\",     \"darkblue\",  \"#E31837\"\n)\n\n\n\nhead(nba_abbr_cols)\n\n# A tibble: 6 × 4\n  Code  Franchise           colour_marker colour_icon\n  &lt;chr&gt; &lt;chr&gt;               &lt;chr&gt;         &lt;chr&gt;      \n1 ATL   Atlanta Hawks       red           #C1D32F    \n2 BKN   Boston Celtics      black         #FFFFFF    \n3 BOS   Brooklyn Nets       green         #BA9653    \n4 CHA   Charlotte Hornets   darkblue      #00788C    \n5 CHI   Chicago Bulls       red           #000000    \n6 CLE   Cleveland Cavaliers darkred       #FDBB30    \n\n\nNow this extra information can be joined to our scraped and wrangled data frame from before.\n\nnba_table &lt;- nba_wrangle %&gt;% \n  left_join(nba_abbr_cols, by = c(\"Team\" = \"Franchise\")) %&gt;%\n  select(Code, everything())\n\nglimpse(nba_table)\n\nRows: 30\nColumns: 12\n$ Code          &lt;chr&gt; \"BKN\", \"BOS\", \"NYK\", \"PHI\", \"TOR\", \"CHI\", \"CLE\", \"DET\", …\n$ Team          &lt;chr&gt; \"Boston Celtics\", \"Brooklyn Nets\", \"New York Knicks\", \"P…\n$ Conference    &lt;chr&gt; \"Eastern\", \"Eastern\", \"Eastern\", \"Eastern\", \"Eastern\", \"…\n$ Division      &lt;chr&gt; \"Atlantic\", \"Atlantic\", \"Atlantic\", \"Atlantic\", \"Atlanti…\n$ City          &lt;chr&gt; \"Boston\", \"New York City\", \"New York City\", \"Philadelphi…\n$ State         &lt;chr&gt; \"Massachusetts\", \"New York\", \"New York\", \"Pennsylvania\",…\n$ Arena         &lt;chr&gt; \"TD Garden\", \"Barclays Center\", \"Madison Square Garden\",…\n$ Capacity      &lt;dbl&gt; 19156, 17732, 19812, 20478, 19800, 20917, 19432, 20332, …\n$ Latitude      &lt;dbl&gt; 42.36630, 40.68265, 40.75056, 39.90111, 43.64333, 41.880…\n$ Longitude     &lt;dbl&gt; -71.06223, -73.97469, -73.99361, -75.17194, -79.37917, -…\n$ colour_marker &lt;chr&gt; \"black\", \"green\", \"blue\", \"blue\", \"red\", \"red\", \"darkred…\n$ colour_icon   &lt;chr&gt; \"#FFFFFF\", \"#BA9653\", \"#F58426\", \"#ED174C\", \"#000000\", \"…\n\n\nNow we have everything we need to visualise the data and fetch the travel duration times.\n\n\n\n2. Map the locations\nSo where are all the arenas?\nWe can create a simple interactive map with {leaflet} by plotting the Latitude and Longitude columns and creating custom point markers with a basketball icon and each team’s colours, as well as an information box that appears on-click.\n\nleaflet(nba_table) %&gt;%\n  addProviderTiles(providers$Stamen.TonerLite) %&gt;%  # add basemap\n  addAwesomeMarkers(  # add markers\n    lng = ~Longitude, lat = ~Latitude,  # coordinates\n    popup = ~paste0(  # HTML content for popup info\n      \"&lt;b&gt;\", nba_table$Team, \"&lt;/b&gt;\",  # team name\n      \"&lt;br&gt;\", paste0(nba_table$Arena, \", \", nba_table$City),  # location\n      if_else(  # division/conference information\n        nba_table$Conference == \"Eastern\",\n        paste0(\"&lt;br&gt;&lt;font color='#0000FF'&gt;\", nba_table$Division,\n               \" Division (Eastern Conference)&lt;/font&gt;\"),\n        paste0(\"&lt;br&gt;&lt;font color='#FF0000'&gt;\", nba_table$Division,\n               \" Division (Western Conference)&lt;/font&gt;\")\n      )\n    ),\n    icon = awesomeIcons(\n      library = \"ion\", icon = \"ion-ios-basketball\", # add basketball icon\n      markerColor = nba_table$colour_marker,  # colour the marker\n      iconColor = nba_table$colour_icon  # colour the basketball icon\n    )\n  ) %&gt;%\n  addMeasure()  # add straight-line distance-measuring tool\n\n\n\n\n\nYou can drag and zoom and click the points.\n\n\n3. Get travel duration\nSo how far between these locations?\nThe {osrm} R package from Timothée Giraud, Robin Cura and Matthieu Viry lets you fetch shortest paths and travel times from OpenStreetMap via the OSRM API. It defaults to driving, but you can select walking and biking too. Since we’re using the demo server for OSRM, we can only fetch duration.\n\nDuration matrix\nThe osrm::osrmTable() function takes a data frame (or spatial object) where the first three columns are an identifier and coordinates. The return object is a list, where the first element is a matrix of durations for each pair of points.\n\nnba_locs &lt;- nba_table %&gt;% \n  select(Code, Longitude, Latitude) %&gt;% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\nnba_dur &lt;- osrmTable(loc = nba_locs)\n\nglimpse(nba_dur)\n\nList of 3\n $ durations   : num [1:30, 1:30] 0 282 276 385 650 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:30] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:30] \"1\" \"2\" \"3\" \"4\" ...\n $ sources     :'data.frame':   30 obs. of  2 variables:\n  ..$ lon: num [1:30] -71.1 -74 -74 -75.2 -79.4 ...\n  ..$ lat: num [1:30] 42.4 40.7 40.7 39.9 43.6 ...\n $ destinations:'data.frame':   30 obs. of  2 variables:\n  ..$ lon: num [1:30] -71.1 -74 -74 -75.2 -79.4 ...\n  ..$ lat: num [1:30] 42.4 40.7 40.7 39.9 43.6 ...\n\n\n\n\nDuration: all teams\nLet’s take this matrix and tidy it into a data frame so there’s one row per team-pair. We can also round to the nearest minute and calculate the nearest number of hours.\n\nnba_dur_all &lt;-\n  as.data.frame(nba_dur$durations) %&gt;% \n  rownames_to_column(\"Start\") %&gt;% \n  mutate(Start = nba_locs$Code) %&gt;%\n  rename_with(~c(\"Start\", nba_locs$Code), all_of(names(.))) %&gt;%\n  pivot_longer(\n    cols = BKN:SAS,\n    names_to = \"End\",\n    values_to = \"Duration (mins)\"\n  ) %&gt;% \n  mutate(\n    `Duration (mins)` = round_half_up(`Duration (mins)`),\n    `Duration (hrs)` = round_half_up(`Duration (mins)` / 60)\n  ) %&gt;% \n  arrange(desc(`Duration (mins)`))\n\nHere’s a {DT} interactive table sorted by duration that you can filter. Click the ‘CSV’ button to download the data.\n\nnba_dur_all %&gt;% \n  datatable(\n    filter = \"top\",\n    extensions = c(\"Buttons\",\"Scroller\"),\n    class = \"compact\", width = \"100%\",\n    options = list(\n      dom = \"Blrtip\",\n      scroller = TRUE, scrollY = 300,\n      buttons = list(\"csv\")\n    )\n  )\n\n\n\n\n\n\nSo an incredible 58 hours of driving to get from Miami to Portland.\n\n\nDuration: by division\nWe can also narrow this down to get only the team-pairs that play in the same division as each other.\n\nnba_dur_div &lt;- nba_dur_all %&gt;%\n  left_join(select(nba_table, Code, Division), by = c(\"Start\" = \"Code\")) %&gt;% \n  left_join(select(nba_table, Code, Division), by = c(\"End\" = \"Code\")) %&gt;% \n  dplyr::filter(Division.x == Division.y, `Duration (mins)` != 0) %&gt;% \n  select(Division = Division.x, everything(), -Division.y) %&gt;% \n  arrange(Division, desc(`Duration (mins)`))\n\nAgain, here’s an interactive table that you can use to explore the data. Note that it’s ordered by Division and then duration in minutes. I’ve hidden the code because it’s the same as for the table above.\n\n\nClick for the {DT} code\n\n\nnba_dur_div %&gt;% \n  datatable(\n    filter = \"top\",\n    extensions = c(\"Buttons\",\"Scroller\"),\n    rownames = FALSE,\n    class = \"compact\", width = \"100%\",\n    options = list(\n      dom = \"Blrtip\",\n      scroller = TRUE, scrollY = 300,\n      buttons = list(\"csv\")\n    )\n  )\n\n\n\n\n\n\n\n\n\nThis time we can see that there’s a maximum of 33 hours of driving required between two teams in the same division: Portland to Oklahoma City.\n\n\nA quick diversion: routing\nWe know from using osrm::osrmTable() that Miami to Portland has the longest travel duration. What’s the route?\nFortunately, {osrm} has the function osrmRoute() for fetching the routes between a pair of points.\nWe can grab a vector of coordinates for each team from our nba_table object and set these as our origin (src) and destination (dst) in osrm::osrmRoute(). The return object is a ‘linestring’ object that contains detail on the coordinates and coordinate system for the route.\n\n# Function to extract latlong vectors for teams\nget_ll &lt;- function(data, team_code) {\n  team_data &lt;- dplyr::filter(data, Code == team_code)\n  lng &lt;- pull(team_data, Longitude)\n  lat &lt;- pull(team_data, Latitude)\n  lnglat &lt;- c(lng, lat)\n  return(lnglat)\n}\n\n# Get route between latlong pairs\nroute &lt;- osrmRoute(\n  src = get_ll(nba_table, \"MIA\"),\n  dst = get_ll(nba_table, \"POR\"),\n  returnclass = \"sf\"\n)\n\nWarning: \"returnclass\" is deprecated.\n\nroute\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -122.6658 ymin: 25.78202 xmax: -80.15664 ymax: 45.8407\nGeodetic CRS:  WGS 84\n        src dst duration distance                       geometry\nsrc_dst src dst 3461.665 5247.537 LINESTRING (-80.18809 25.78...\n\n\nNow we can set up the same type of {leaflet} map as earlier, but we’ll include only Portland and OKC. I’ve hidden the map definition because it’s almost the same as before.\n\n\nClick for the {leaflet} map definition\n\n\nmia_por &lt;- nba_table %&gt;%\n  dplyr::filter(Code %in% c(\"MIA\", \"POR\"))\n\nmia_por_map &lt;- \n  leaflet(mia_por) %&gt;%\n  addProviderTiles(providers$Stamen.TonerLite) %&gt;%  # add basemap\n  addAwesomeMarkers(  # add markers\n    lng = ~Longitude, lat = ~Latitude,  # coordinates\n    popup = ~paste0(  # HTML content for popup info\n      \"&lt;b&gt;\", mia_por$Team, \"&lt;/b&gt;\",  # team name\n      \"&lt;br&gt;\", paste0(mia_por$Arena, \", \", mia_por$City),  # location\n      if_else(  # division/conference information\n        mia_por$Conference == \"Eastern\",\n        paste0(\"&lt;br&gt;&lt;font color='#0000FF'&gt;\", mia_por$Division,\n               \" Division (Eastern Conference)&lt;/font&gt;\"),\n        paste0(\"&lt;br&gt;&lt;font color='#FF0000'&gt;\", mia_por$Division,\n               \" Division (Western Conference)&lt;/font&gt;\")\n      )\n    ),\n    icon = awesomeIcons(\n      library = \"ion\", icon = \"ion-ios-basketball\", # add basketball icon\n      markerColor = mia_por$colour_marker,  # colour the marker\n      iconColor = mia_por$colour_icon  # colour the basketball icon\n    )\n  ) %&gt;%\n  addMeasure()  # add straight-line distance-measuring tool\n\n\nAnd to that map we can add the line that defines the route\n\nmia_por_map %&gt;% addPolylines(data = st_geometry(route))\n\n\n\n\n\nThat’s a long way.\n\n\n\n4. Make a heatmap\nA quick way to visualise the data is to create a heatmap, where we take a matrix of teams in each division and colour by duration. Here, lighter colours indicate greater travel duration.\nThe plot is interactive; you can hover over squares in each facet to see specific information about that pair, including the exact duration value.\n\np &lt;- nba_dur_div %&gt;% \n  ggplot(aes(Start, End)) +\n  geom_tile(aes(fill = `Duration (hrs)`)) +\n  xlab(\"\") + ylab(\"\") + \n  facet_wrap(~Division, scales = \"free\")\n\nggplotly(p)\n\n\n\n\n\nNote the light colours in the Northwest division where teams have to travel far (like the 33 hour trip from Portland and Oklahoma City), while travel durations in the Atlantic and Central divisions are shorter. Of course, the Clippers and Lakers both play in the Staples Center in LA, so their journey time is zero."
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html#ending-the-journey",
    "href": "posts/2018-12-24-nba-travel/index.html#ending-the-journey",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "Ending the journey",
    "text": "Ending the journey\nSo, this post shows the the power of the {osrm} package for travel distance, duration and routing information.\nOf course, it’s never usually as simple as having your geographic data ready to go, so I hope this post also provides a good use-case for {rvest} to help you collect information and {tidyverse} for wrangling it.\nThe plots here are pretty minimal, but they hopefully give a flavour of how to use {leaflet} for plotting points and the routing between them according to {osrm}.\nThis post was initially written before the travel restrictions brought about by the 2020 pandemic. Of course, the maps would have been much simpler during for the 2020 playoffs, which all took place in a ‘bubble’ at Disney World, Florida."
  },
  {
    "objectID": "posts/2018-12-24-nba-travel/index.html#environment",
    "href": "posts/2018-12-24-nba-travel/index.html#environment",
    "title": "Travel the NBA with {rvest}, {leaflet} and {osrm}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-08-05 16:58:43 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] plotly_4.10.2   DT_0.28         leaflet_2.1.2   osrm_4.1.1     \n [5] sf_1.0-14       janitor_2.2.0   rvest_1.0.3     lubridate_1.9.2\n [9] forcats_1.0.0   stringr_1.5.0   dplyr_1.1.2     purrr_1.0.1    \n[13] readr_2.1.4     tidyr_1.3.0     tibble_3.2.1    ggplot2_3.4.2  \n[17] tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            bslib_0.5.0             xfun_0.39              \n [4] htmlwidgets_1.6.2       tzdb_0.4.0              leaflet.providers_1.9.0\n [7] vctrs_0.6.3             tools_4.3.1             crosstalk_1.2.0        \n[10] generics_0.1.3          curl_5.0.1              proxy_0.4-27           \n[13] fansi_1.0.4             pkgconfig_2.0.3         KernSmooth_2.23-21     \n[16] data.table_1.14.8       lifecycle_1.0.3         farver_2.1.1           \n[19] compiler_4.3.1          googlePolylines_0.8.3   munsell_0.5.0          \n[22] fontawesome_0.5.1       snakecase_0.11.0        sass_0.4.7             \n[25] htmltools_0.5.5         class_7.3-22            yaml_2.3.7             \n[28] lazyeval_0.2.2          jquerylib_0.1.4         pillar_1.9.0           \n[31] ellipsis_0.3.2          classInt_0.4-9          cachem_1.0.8           \n[34] tidyselect_1.2.0        digest_0.6.33           stringi_1.7.12         \n[37] labeling_0.4.2          fastmap_1.1.1           grid_4.3.1             \n[40] colorspace_2.1-0        cli_3.6.1               magrittr_2.0.3         \n[43] utf8_1.2.3              e1071_1.7-13            RcppSimdJson_0.1.10    \n[46] withr_2.5.0             scales_1.2.1            timechange_0.2.0       \n[49] rmarkdown_2.23          httr_1.4.6              hms_1.1.3              \n[52] evaluate_0.21           knitr_1.43.1            viridisLite_0.4.2      \n[55] rlang_1.1.1             Rcpp_1.0.11             isoband_0.2.7          \n[58] glue_1.6.2              DBI_1.1.3               xml2_1.3.5             \n[61] mapiso_0.3.0            rstudioapi_0.15.0       jsonlite_1.8.7         \n[64] R6_2.5.1                units_0.8-2"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html",
    "href": "posts/2023-05-10-spear-ggplot2/index.html",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "",
    "text": "They’re the same picture. Nearly."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#tldr",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#tldr",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "tl;dr",
    "text": "tl;dr\nTwo years ago I won a data-viz recreation competition run by the Royal Statistical Society (RSS) using base R’s plotting. I wrote a short {ggplot2} how-to for RSS’s ‘Significance’ magazine that was never published1, so here it is now."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#recreate",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#recreate",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Recreate",
    "text": "Recreate\nThis short code walkthrough will get you started on recreating Mary Eleanor Spear’s cotton plot (1952), as used in the Royal Statistical Society’s #CottonViz challenge. We’ll concentrate on the line chart for now.\n\nThe {ggplot2} package in R is a good choice, since we can build up the chart in steps: first, we’ll build a basic line chart, remove unneeded elements, fix the axes and finally add the labels. It won’t look perfectly like Spear’s original, but we’ll get close.\nThis isn’t a guide to learn {ggplot2}, so you may want to learn the basics first. Alternatively, I wrote a blog post about building Spear’s entire visualisation using base R only."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#requirements",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#requirements",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Requirements",
    "text": "Requirements\nFirst, some preparation. If you haven’t already, install the {ggplot2} package for plotting, {tidyr} data reshaping and {extrafont} for font handling.\n\ninstall.packages(\"ggplot2\", \"tidyr\", \"extrafont\")\n\nYou can download for free the Routed Gothic font by Darren Embry, which is a good approximation of the stencil lettering used by Spear. Installation will depend on your system, but in macOS you can simply drag the font files to the Font Book app. When you attach {extrafont} it’ll fetch automatically your installed fonts (including Routhed Gothic) so you can use them in R.\n\nlibrary(extrafont)"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#tidying-up",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#tidying-up",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Tidying up",
    "text": "Tidying up\nThe cotton dataset is quite small, so we can create the dataframe ourselves. It provides information on the supply of cotton in the USA in the 1940s.\n\ncotton_raw &lt;- data.frame(\n  year           = 1942:1948,\n  us_consumption = c(11160, 9993,  9693,  9423,  10072, 9374,  7833),\n  exports        = c(1480,  1139,  2007,  3613,  3545,  1968,  4785),\n  stocks         = c(10657, 10744, 11164, 7326,  2530,  3080,  5283),\n  total_supply   = c(23297, 21876, 22864, 20362, 16147, 14422, 17901)\n)\n\nIt’s preferable to make the data ‘tidy’ so that there’s one row per year and consumption type, and one column for each variable. The {tidyr} package can help us pivot the data to ‘long’ format from this ‘wide’ format.\n\nlibrary(tidyr)\n\ncotton &lt;- cotton_raw %&gt;% \n  pivot_longer(\n    c(us_consumption, exports, stocks), \n    names_to = \"consumption_type\", values_to = \"boles\"\n  )\n\nhead(cotton, 4)  # preview first few rows\n\n# A tibble: 4 × 4\n   year total_supply consumption_type boles\n  &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  1942        23297 us_consumption   11160\n2  1942        23297 exports           1480\n3  1942        23297 stocks           10657\n4  1943        21876 us_consumption    9993"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#how-to",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#how-to",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "How-to",
    "text": "How-to\n\nStep 1: line chart\nNow we can create a basic line chart of the data with geom_line() and set with scale_linetype_manual() a unique dashed line per group. Further arguments set the title and the typeface to be used throughout the plot, while a small tweak to theme() adjusts the title’s position.\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot() +\n  geom_line(\n    data = cotton,\n    aes(x = year, y = boles / 1000, linetype = consumption_type),\n    linewidth = 1.5\n  ) +\n  scale_linetype_manual(values = c(\"longdash\", \"dashed\", \"solid\")) +\n  labs(title = \"Millions of Boles\") +\n  theme(\n    plot.title = element_text(hjust = -0.05),\n    text = element_text(family = \"Routed Gothic\")\n  )\n\np1\n\n\n\n\n\n\nStep 2: remove features\nLet’s clear away the unneeded features: the background panel, the axes titles and the legend. You can empty these with element_blank() in the theme() function.\n\np2 &lt;- p1 + \n  theme(\n    panel.background = element_blank(),\n    axis.title = element_blank(),\n    legend.position = \"none\"\n  )\n\np2\n\n\n\n\n\n\nStep 3: correct the axes\nNow we can address the axes. Use the scale_*_continuous() functions to set the axes values, limits, origin and labels. With sec.axis you can create a secondary y-axis that mirrors the first, then remove the tick labels in the theme() function. You can also put a box around the chart area with the panel.border argument.\n\np3 &lt;- p2 +\n  scale_x_continuous(\n    breaks = seq(1942, 1948, 1),\n    labels = c(\"1942\", paste0(\"'\", 43:48)),\n    expand = c(0, 0)\n  ) +\n  scale_y_continuous(\n    breaks = seq(0, 12, 2),\n    limits = c(0, 12),\n    expand = c(0, 0),\n    sec.axis = dup_axis()\n  ) +\n  theme(\n    axis.ticks = element_line(linewidth = c(0, rep(0.5, 5), 0)),\n    axis.ticks.length = unit(-0.5, \"lines\"),\n    axis.text.y.right = element_blank(),\n    panel.border = element_rect(fill = NA, linewidth = 1)\n  )\n\np3\n\n\n\n\n\n\nStep 4: labels\nThe only missing features are the labels and arrows, which can be added with the annotate() and geom_segment(), respectively. A bit of trial-and-error will help you find the correct coordinates to place these elements.\n\np4 &lt;- p3 +\n  annotate(\n    geom = \"text\",\n    x = c(1946.1, 1945.9, 1943.75),\n    y = c(10.8, 7.1, 3.2),\n    label = c(\"U. S. Consumption\", \"Carry – over\\nStocks\", \"Exports\"),\n    family = \"Routed Gothic\"\n  ) +\n  geom_segment(\n    aes(\n      x = c(1945.2, 1945.3, 1944.2),\n      y = c(10.5, 7.4, 3.1),\n      xend = c(1945, 1945.1, 1944.4), \n      yend = c(9.7, 7.1, 2.8)\n    ),\n    arrow = arrow(\n      length = unit(2, \"mm\"),\n      type = \"closed\"\n    )\n  )\n\np4"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#next-steps",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#next-steps",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Next steps",
    "text": "Next steps\nFinally we’ve got a lineplot that looks pretty close to Spear’s visualisation. What subtle differences do you notice, though? Try to find ways to improve them.\nNext, try to recreate the stacked-barchart from Spear’s original and then arrange the plots with a main title and surrounding text labels. The {ggpattern} package may help you recreate the hatchlines on the bars and {patchwork} could help with the arrangement of the plot and text elements."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#full-base-r-alternative",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#full-base-r-alternative",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Full base R alternative",
    "text": "Full base R alternative\nFor the original challenge I used only base R’s plotting system rather than {ggplot2}. This is what my submitted image looked like:\n\nYou can read more about it in the accompanying blog post and you can find the original code on GitHub."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#environment",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#environment",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:43 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.2 tidyr_1.3.0  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.7   \n [9] labeling_0.4.2    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5  \n[13] scales_1.2.1      fansi_1.0.4       rmarkdown_2.23    grid_4.3.1       \n[17] munsell_0.5.0     evaluate_0.21     tibble_3.2.1      fastmap_1.1.1    \n[21] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2      \n[25] htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.14   farver_2.1.1     \n[29] digest_0.6.31     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3       \n[33] pillar_1.9.0      magrittr_2.0.3    gtable_0.3.3      tools_4.3.1      \n[37] withr_2.5.0"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#footnotes",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#footnotes",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt least I don’t think so. I can’t find it by searching on the website, anyway. Also, enough time has passed that certain bits of the original code have since been deprecated in {ggplot2}, lol.↩︎"
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html",
    "href": "posts/2021-04-14-gha-readme/index.html",
    "title": "Up-to-date blog stats in your README",
    "section": "",
    "text": "Yesterday’s render of the GitHub README for this blog."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#tldr",
    "href": "posts/2021-04-14-gha-readme/index.html#tldr",
    "title": "Up-to-date blog stats in your README",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use a scheduled GitHub Action to render up-to-date stats about your blog into its README."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#happy-blogday",
    "href": "posts/2021-04-14-gha-readme/index.html#happy-blogday",
    "title": "Up-to-date blog stats in your README",
    "section": "Happy blogday",
    "text": "Happy blogday\nThis blog has been knocking around for three years now. I wrote a post on its first birthday with a simple, interactive 2D plot of the posts to date.\nOnly now, two years later, have I thought to put this info into the blog’s README on GitHub—along with some other little stats, like total number of posts—and have it update automatically on a schedule using a GitHub Action.1\nThis is useful for me so I can keep track of things without counting on my fingers, but it also signals activity on the blog to any curious visitors. I may change its content at some point, but it does what I want it to do for now."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#unwrap-your-github-action",
    "href": "posts/2021-04-14-gha-readme/index.html#unwrap-your-github-action",
    "title": "Up-to-date blog stats in your README",
    "section": "Unwrap your GitHub Action",
    "text": "Unwrap your GitHub Action\nI’ve scheduled a GitHub Action for the early hours of each day. The YAML file for it reads like ‘at the specified time2, set up a remote environment with R and some dependencies, then render the R Markdown file and push the changes to GitHub.’\nI’ve modified r-lib’s pre-written YAML for this, which can be generated in the correct location in your project with usethis::use_github_action(\"render-rmarkdown.yaml\").\n\n\nClick for the GitHub Action YAML\n\nname: Render README\n\non:\n  schedule:\n    - cron: '09 05 * * *'\n\njobs:\n  render:\n    name: Render README\n    runs-on: macOS-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@v1\n      - uses: r-lib/actions/setup-pandoc@v1\n      - name: Install CRAN packages\n        run: Rscript -e 'install.packages(c(\"remotes\", \"rmarkdown\", \"knitr\", \"tidyverse\"))'\n      - name: Install GitHub packages\n        run: Rscript -e 'remotes::install_github(\"hadley/emo\")'\n      - name: Render README\n        run: Rscript -e 'rmarkdown::render(\"README.Rmd\")'\n      - name: Commit results\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n          git commit README.md README_files/ -m 'Re-build README.Rmd' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\"\n\nBasically, the action knits the repo’s README.Rmd (R Markdown format containing R code) to a counterpart README.md (GitHub-flavoured markdown), which is displayed when you visit the repo."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#party-time",
    "href": "posts/2021-04-14-gha-readme/index.html#party-time",
    "title": "Up-to-date blog stats in your README",
    "section": "PaRty time",
    "text": "PaRty time\nThe real magic is in some R code chunks at the top of the README.Rmd file itself. There’s some R code there that uses {rvest} to scrape the archive page of the blog and create a dataframe of the titles, links and publish dates of each post.\n\n\nClick for the scraping code\n\n\n# Attach packages\nlibrary(tidyverse) # CRAN v1.3.0\nlibrary(rvest)     # CRAN v1.0.0\n\n# Scrape the rostrum.blog home page\nhtml &lt;- read_html(\"https://rostrum.blog/\")\n\n# Extract the post titles\ntitle &lt;- html %&gt;%\n  html_nodes(\".archive-item-link\") %&gt;%  # extract title node\n  html_text()                           # extract text\n\n# Extract the post URLs\nlink &lt;- html %&gt;% \n  html_nodes(\".archive-item-link\") %&gt;%  # extract title node\n  html_attr(\"href\")                     # extract href attribute\n\n# Extract the post dates\ndate &lt;- html %&gt;%\n  html_nodes(\".archive-item-date\") %&gt;%  # extract date nodes only\n  html_text() %&gt;%                       # extract text\n  str_replace_all(\"[:space:]\", \"\")      # remove newline/space\n\n# Dataframe of titles and dates\nposts &lt;- tibble(date, title link), %&gt;% \n  transmute(\n    n = nrow(.):1,             # number starting from first post\n    publish_date = ymd(date),  # convert to date class\n    title,                     # title text\n    link = paste0(\"https://www.rostrum.blog\", link)  # create full URL\n  )\n\n\nThat information can be cajoled to show some basic stats. The README includes inline R code that renders to show:\n\nthe total number of posts\nposting rates (posts per month and days per post)\nthe number of days since since the last post and a link to it\na clickable details block containing a table of all the posts to date\na simple 2D plot showing the distribution of posts over time3 (preview below)\n\n\n\nClick for plot code\n\n\n# Create plot object\np &lt;- posts %&gt;%\n  ggplot(aes(x = publish_date, y = 1)) +\n  geom_point(shape = \"|\", size = 10, stroke = 1, color = \"#1D8016\") + \n  theme_void()\n\n\n\nI also added a call to lubridate::today() at the bottom of the README.Rmd so it’s obvious when the stats were last updated."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#until-next-year",
    "href": "posts/2021-04-14-gha-readme/index.html#until-next-year",
    "title": "Up-to-date blog stats in your README",
    "section": "Until next year",
    "text": "Until next year\nFinally, and most importantly, I included a tiny Easter egg: an emoji balloon 🎈 will appear on the page when the README is rendered on the anniversary of the blog’s inception.4"
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#environment",
    "href": "posts/2021-04-14-gha-readme/index.html#environment",
    "title": "Up-to-date blog stats in your README",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 20:34:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#footnotes",
    "href": "posts/2021-04-14-gha-readme/index.html#footnotes",
    "title": "Up-to-date blog stats in your README",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI’ve written before about GitHub Actions to create a Twitter bot and for continuous integration of R packages.↩︎\nI wrote about scheduling with cron strings in an earlier post, which details the {dialga} package for translating from R to cron to English.↩︎\nThe original chart was made with {plotly}, so you could hover over the points to see the post titles and publishing dates. Plotly isn’t supported in GitHub Markdown, so I included a static chart instead. I used a similar ‘barcode’ format in a recent post about health data.↩︎\nThat’s today if you’re reading this on the day it was published.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rostrum.blog",
    "section": "",
    "text": "Start an argument with R\n\n\n\n2024-02-03\n\n\n\n\n\n\n\n\n\n\n\nKill your darlings (but bugfix first)\n\n\n\n2024-01-27\n\n\n\n\n\n\n\n\n\n\n\nPseudo-apps in the browser with WebR and Quarto?\n\n\n\n2024-01-20\n\n\n\n\n\n\n\n\n\n\n\nYihui Xie: RAP god\n\n\n\n2024-01-12\n\n\n\n\n\n\n\n\n\n\n\nNo tears over missed eyedrops\n\n\n\n2023-12-03\n\n\n\n\n\n\n\n\n\n\n\nAn interactive graph of Pokémon Red locations\n\n\n\n2023-11-25\n\n\n\n\n\n\n\n\n\n\n\nUnlock R functions with QR codes\n\n\n\n2023-11-01\n\n\n\n\n\n\n\n\n\n\n\nBase slaps!\n\n\n\n2023-10-17\n\n\n\n\n\n\n\n\n\n\n\nGovspeakify tables with {shinylive}\n\n\n\n2023-10-08\n\n\n\n\n\n\n\n\n\n\n\n{cli}ckable hyperlinks in the R console\n\n\n\n2023-09-17\n\n\n\n\n\n\n\n\n\n\n\nDear John, I’m sorry\n\n\n\n2023-09-16\n\n\n\n\n\n\n\n\n\n\n\nThe life and death of the tidyverse\n\n\n\n2023-09-10\n\n\n\n\n\n\n\n\n\n\n\nCombing through my trash\n\n\n\n2023-09-09\n\n\n\n\n\n\n\n\n\n\n\nAutodetect Quarto formats with {quartostamp}. Or not.\n\n\n\n2023-09-01\n\n\n\n\n\n\n\n\n\n\n\nConscious uncoupling with {blogdown}\n\n\n\n2023-08-26\n\n\n\n\n\n\n\n\n\n\n\nObject of type closure can shut up\n\n\n\n2023-08-19\n\n\n\n\n\n\n\n\n\n\n\nOne weird trick to {monetize} your R package\n\n\n\n2023-08-01\n\n\n\n\n\n\n\n\n\n\n\nSave high scores for your R game\n\n\n\n2023-07-15\n\n\n\n\n\n\n\n\n\n\n\nConvert a Word table to Markdown\n\n\n\n2023-06-21\n\n\n\n\n\n\n\n\n\n\n\nPanic! In The Toolshed\n\n\n\n2023-06-13\n\n\n\n\n\n\n\n\n\n\n\nExtract run data from Apple Health (redux)\n\n\n\n2023-06-11\n\n\n\n\n\n\n\n\n\n\n\nRectangularise Word tables extracted by {officer}\n\n\n\n2023-06-07\n\n\n\n\n\n\n\n\n\n\n\nRecreating a dataviz with {ggplot2}\n\n\n\n2023-05-10\n\n\n\n\n\n\n\n\n\n\n\nAutomate {blogdown} to Quarto\n\n\n\n2023-05-07\n\n\n\n\n\n\n\n\n\n\n\nMatt Dray Teaches (Data) Typing\n\n\n\n2023-04-23\n\n\n\n\n\n\n\n\n\n\n\nR is a game engine, fight me\n\n\n\n2023-04-02\n\n\n\n\n\n\n\n\n\n\n\nPlaygrounds with WebR and Quarto\n\n\n\n2023-03-16\n\n\n\n\n\n\n\n\n\n\n\nFun and learning. In a dungeon!\n\n\n\n2023-03-15\n\n\n\n\n\n\n\n\n\n\n\nI can’t be parsed, mate\n\n\n\n2023-03-03\n\n\n\n\n\n\n\n\n\n\n\nRepaying Tom Nook with {S7}\n\n\n\n2023-02-26\n\n\n\n\n\n\n\n\n\n\n\nPorting a Twitter bot to Mastodon\n\n\n\n2023-02-09\n\n\n\n\n\n\n\n\n\n\n\nWrapping PokéAPI with {trapinch}\n\n\n\n2023-02-02\n\n\n\n\n\n\n\n\n\n\n\nStiliyan Petrov: Jesus?\n\n\n\n2023-01-08\n\n\n\n\n\n\n\n\n\n\n\n.-././–/—/.-./…/.\n\n\n\n2023-01-06\n\n\n\n\n\n\n\n\n\n\n\nDing! Sound effects in {r.oguelike}\n\n\n\n2023-01-04\n\n\n\n\n\n\n\n\n\n\n\nAnimate sprites in R with {pixeltrix}\n\n\n\n2022-12-11\n\n\n\n\n\n\n\n\n\n\n\nTamagotchi in R?\n\n\n\n2022-11-13\n\n\n\n\n\n\n\n\n\n\n\nInteractive pixel art in R with {pixeltrix}\n\n\n\n2022-09-24\n\n\n\n\n\n\n\n\n\n\n\nYou are a halfling, trying to harvest {potato}\n\n\n\n2022-09-13\n\n\n\n\n\n\n\n\n\n\n\nEARL 22: {a11ytables} for better spreadsheets\n\n\n\n2022-09-07\n\n\n\n\n\n\n\n\n\n\n\nTwo RStudio Addins: {quartostamp} and {snorkel}\n\n\n\n2022-08-11\n\n\n\n\n\n\n\n\n\n\n\nFixing londonmapbot for {rtweet} v1.0\n\n\n\n2022-07-22\n\n\n\n\n\n\n\n\n\n\n\nStop opening the same RStudio Project twice\n\n\n\n2022-07-08\n\n\n\n\n\n\n\n\n\n\n\nAn isometric dungeon chase in R\n\n\n\n2022-06-28\n\n\n\n\n\n\n\n\n\n\n\nAutomated pathfinding in {r.oguelike}\n\n\n\n2022-06-10\n\n\n\n\n\n\n\n\n\n\n\nDown with R’s assignment flamewars!\n\n\n\n2022-06-07\n\n\n\n\n\n\n\n\n\n\n\nTry R v4.2 in your browser\n\n\n\n2022-06-01\n\n\n\n\n\n\n\n\n\n\n\nSimple procedural dungeons in R\n\n\n\n2022-05-01\n\n\n\n\n\n\n\n\n\n\n\nTurn the {tide} on R’s secret spreadsheet editor\n\n\n\n2022-04-27\n\n\n\n\n\n\n\n\n\n\n\nBuilding a {r.oguelike} in R\n\n\n\n2022-04-25\n\n\n\n\n\n\n\n\n\n\n\nInteractive maps of Hastings Half Marathon\n\n\n\n2022-03-31\n\n\n\n\n\n\n\n\n\n\n\nReproducible {distill} posts with {renv} profiles\n\n\n\n2022-03-15\n\n\n\n\n\n\n\n\n\n\n\nAdd in an RStudio Addin to add in backticks\n\n\n\n2022-02-19\n\n\n\n\n\n\n\n\n\n\n\nlondonmapbot at LondonR\n\n\n\n2022-02-12\n\n\n\n\n\n\n\n\n\n\n\nIntroduce me to your {soccercolleagues}\n\n\n\n2022-02-04\n\n\n\n\n\n\n\n\n\n\n\nImpress with {keypress} minigames\n\n\n\n2022-01-19\n\n\n\n\n\n\n\n\n\n\n\nWordle, twirdle and eldrow\n\n\n\n2022-01-14\n\n\n\n\n\n\n\n\n\n\n\nThe most popular Animal Crossing villagers\n\n\n\n2022-01-07\n\n\n\n\n\n\n\n\n\n\n\nYour workout route (in three dimensions!)\n\n\n\n2021-12-30\n\n\n\n\n\n\n\n\n\n\n\nR has obscenely long function names\n\n\n\n2021-11-27\n\n\n\n\n\n\n\n\n\n\n\n{itdepends} on {lubridate}\n\n\n\n2021-11-27\n\n\n\n\n\n\n\n\n\n\n\nDeep fried memes in R\n\n\n\n2021-11-07\n\n\n\n\n\n\n\n\n\n\n\nGet coordinates from fictitious maps\n\n\n\n2021-11-04\n\n\n\n\n\n\n\n\n\n\n\nReveal a hidden gorilla with {magick}\n\n\n\n2021-10-05\n\n\n\n\n\n\n\n\n\n\n\n{ActionSquirrel}: a game in the R console\n\n\n\n2021-10-03\n\n\n\n\n\n\n\n\n\n\n\nWot3LdnEmojis\n\n\n\n2021-09-14\n\n\n\n\n\n\n\n\n\n\n\nExtract punctuation from books with R\n\n\n\n2021-09-12\n\n\n\n\n\n\n\n\n\n\n\nAuto-label closing parentheses in RStudio\n\n\n\n2021-08-31\n\n\n\n\n\n\n\n\n\n\n\nAdding a Shiny app to {dehex}\n\n\n\n2021-08-27\n\n\n\n\n\n\n\n\n\n\n\nExploring R package startup messages\n\n\n\n2021-08-27\n\n\n\n\n\n\n\n\n\n\n\nRead a hex colour code with {dehex}\n\n\n\n2021-08-10\n\n\n\n\n\n\n\n\n\n\n\nOG emoji SVGs\n\n\n\n2021-07-31\n\n\n\n\n\n\n\n\n\n\n\nMake an art gallery with {bs4cards}\n\n\n\n2021-07-25\n\n\n\n\n\n\n\n\n\n\n\nWhat colour is London?\n\n\n\n2021-07-23\n\n\n\n\n\n\n\n\n\n\n\nEXPOSED: a Kiwi conspiracy built into R!\n\n\n\n2021-07-15\n\n\n\n\n\n\n\n\n\n\n\nDecay is inevitable, accept {linkrot}?\n\n\n\n2021-07-10\n\n\n\n\n\n\n\n\n\n\n\nRecreationThursday: a LeWitt Shiny app\n\n\n\n2021-07-05\n\n\n\n\n\n\n\n\n\n\n\nVery simple pixel art in R\n\n\n\n2021-06-28\n\n\n\n\n\n\n\n\n\n\n\nGenerate an {emojiscape}\n\n\n\n2021-06-26\n\n\n\n\n\n\n\n\n\n\n\nRecreation Thursday: Hlito with base R\n\n\n\n2021-06-21\n\n\n\n\n\n\n\n\n\n\n\nRecreating Spear’s #CottonViz in base R\n\n\n\n2021-06-08\n\n\n\n\n\n\n\n\n\n\n\nMission Across the Isle of Wight\n\n\n\n2021-05-22\n\n\n\n\n\n\n\n\n\n\n\nEncrypt and host a knitted R Markdown file\n\n\n\n2021-05-07\n\n\n\n\n\n\n\n\n\n\n\nMake the simplest R package with {pico}\n\n\n\n2021-04-18\n\n\n\n\n\n\n\n\n\n\n\nUp-to-date blog stats in your README\n\n\n\n2021-04-14\n\n\n\n\n\n\n\n\n\n\n\nConvert R to cron to English with {dialga}\n\n\n\n2021-04-10\n\n\n\n\n\n\n\n\n\n\n\nMake a {shiny} app README badge\n\n\n\n2021-03-23\n\n\n\n\n\n\n\n\n\n\n\nApple Health and Nike Run Club with {xml2}\n\n\n\n2021-03-23\n\n\n\n\n\n\n\n\n\n\n\nProtect yourself from equals assignment!\n\n\n\n2021-03-13\n\n\n\n\n\n\n\n\n\n\n\nA tiny {shiny} flag challenge\n\n\n\n2021-03-02\n\n\n\n\n\n\n\n\n\n\n\nTypo-shaming my Git commits\n\n\n\n2021-02-27\n\n\n\n\n\n\n\n\n\n\n\nGithubSkyline but hear me out\n\n\n\n2021-02-21\n\n\n\n\n\n\n\n\n\n\n\nWhat does a year of COVID-19 sound like?\n\n\n\n2021-02-02\n\n\n\n\n\n\n\n\n\n\n\nR’s names and values as anchovy pizza\n\n\n\n2021-01-28\n\n\n\n\n\n\n\n\n\n\n\nPlay Pokémon’s Safari Zone in R\n\n\n\n2021-01-04\n\n\n\n\n\n\n\n\n\n\n\nAccessible colour contrasts with {coloratio}\n\n\n\n2020-12-30\n\n\n\n\n\n\n\n\n\n\n\nMapping londonmapbot tweets with {leaflet}\n\n\n\n2020-12-20\n\n\n\n\n\n\n\n\n\n\n\nSending {postcards} with Netlify and Namecheap\n\n\n\n2020-12-08\n\n\n\n\n\n\n\n\n\n\n\nThe US electoral college with {tilegramsR}\n\n\n\n2020-11-21\n\n\n\n\n\n\n\n\n\n\n\nTranslate R to English with {r2eng}\n\n\n\n2020-11-14\n\n\n\n\n\n\n\n\n\n\n\nHit your reproducibility {targets}\n\n\n\n2020-09-27\n\n\n\n\n\n\n\n\n\n\n\nA Twitter bot with {rtweet} and GitHub Actions\n\n\n\n2020-09-21\n\n\n\n\n\n\n\n\n\n\n\nFriendship ended with Google Analytics\n\n\n\n2020-09-16\n\n\n\n\n\n\n\n\n\n\n\nRate my RStudio setup\n\n\n\n2020-09-15\n\n\n\n\n\n\n\n\n\n\n\n{units} of uncleaned herring\n\n\n\n2020-09-12\n\n\n\n\n\n\n\n\n\n\n\nGitHub Actions for R packages\n\n\n\n2020-08-09\n\n\n\n\n\n\n\n\n\n\n\nSet up R on Raspberry Pi for blogging\n\n\n\n2020-07-11\n\n\n\n\n\n\n\n\n\n\n\nTake a {ghdump} to download GitHub repos\n\n\n\n2020-06-14\n\n\n\n\n\n\n\n\n\n\n\nAnimal Crossing Tinder with {shinysense}\n\n\n\n2020-06-06\n\n\n\n\n\n\n\n\n\n\n\nPostcode pandemonium with {data.table}\n\n\n\n2020-05-16\n\n\n\n\n\n\n\n\n\n\n\nMake a README badge with {badgr}\n\n\n\n2020-05-08\n\n\n\n\n\n\n\n\n\n\n\nAGÜEROOOOO with {ggsoccer} and {gganimate}\n\n\n\n2020-05-02\n\n\n\n\n\n\n\n\n\n\n\nOwning the shame of my old R code\n\n\n\n2020-04-17\n\n\n\n\n\n\n\n\n\n\n\nPlotception with {ggpattern}\n\n\n\n2020-04-05\n\n\n\n\n\n\n\n\n\n\n\nRepaying Tom Nook with {R6}\n\n\n\n2020-04-04\n\n\n\n\n\n\n\n\n\n\n\nNinja scaffolding for {xaringan}\n\n\n\n2020-03-22\n\n\n\n\n\n\n\n\n\n\n\nIterate parameterised {xaringan} reports\n\n\n\n2020-03-12\n\n\n\n\n\n\n\n\n\n\n\nDear past self: blog\n\n\n\n2020-02-27\n\n\n\n\n\n\n\n\n\n\n\nA Pokémon sprite carousel with {slickR}\n\n\n\n2020-02-05\n\n\n\n\n\n\n\n\n\n\n\n{orderly} and {drake} at Bioinformatics London\n\n\n\n2020-01-31\n\n\n\n\n\n\n\n\n\n\n\nReproducibility in R: three things\n\n\n\n2020-01-22\n\n\n\n\n\n\n\n\n\n\n\nPackages that Sparked Joy in 2019\n\n\n\n2019-12-27\n\n\n\n\n\n\n\n\n\n\n\nHandle London travel data with {oystr}\n\n\n\n2019-12-23\n\n\n\n\n\n\n\n\n\n\n\n{altcheckr}: check image alt text from R\n\n\n\n2019-12-08\n\n\n\n\n\n\n\n\n\n\n\nA pivotal change to Software Carpentry\n\n\n\n2019-11-27\n\n\n\n\n\n\n\n\n\n\n\nTidyswirl: a tidyverse Swirl course\n\n\n\n2019-11-02\n\n\n\n\n\n\n\n\n\n\n\nBuild an R package with {usethis}\n\n\n\n2019-11-01\n\n\n\n\n\n\n\n\n\n\n\n{blogsnip}: an RStudio Addins package\n\n\n\n2019-10-22\n\n\n\n\n\n\n\n\n\n\n\nGit going: Git and GitHub\n\n\n\n2019-10-21\n\n\n\n\n\n\n\n\n\n\n\nHow do you pronounce {dplyr}?\n\n\n\n2019-09-20\n\n\n\n\n\n\n\n\n\n\n\nThe Carpentries: teach with live coding\n\n\n\n2019-09-12\n\n\n\n\n\n\n\n\n\n\n\n{blogdown}: add metadata to Lithium-themed posts\n\n\n\n2019-09-06\n\n\n\n\n\n\n\n\n\n\n\n{holepunch} a {drake} and put it in a Binder\n\n\n\n2019-08-25\n\n\n\n\n\n\n\n\n\n\n\nCan {drake} RAP?\n\n\n\n2019-07-23\n\n\n\n\n\n\n\n\n\n\n\nThe Mountain Goats with {trelliscopejs}\n\n\n\n2019-06-20\n\n\n\n\n\n\n\n\n\n\n\nA GitHub repo template for R analysis\n\n\n\n2019-06-11\n\n\n\n\n\n\n\n\n\n\n\nMake a {brickr} soccer player\n\n\n\n2019-05-31\n\n\n\n\n\n\n\n\n\n\n\nPackage a {xaringan} template\n\n\n\n2019-05-24\n\n\n\n\n\n\n\n\n\n\n\nTeach a person to {swirl}\n\n\n\n2019-05-10\n\n\n\n\n\n\n\n\n\n\n\nMarkov-chaining my PhD thesis II\n\n\n\n2019-04-30\n\n\n\n\n\n\n\n\n\n\n\nGenerate The Mountain Goats lyrics\n\n\n\n2019-04-25\n\n\n\n\n\n\n\n\n\n\n\nA year of rostrum.blog\n\n\n\n2019-04-14\n\n\n\n\n\n\n\n\n\n\n\nFix leaky pipes in R\n\n\n\n2019-04-07\n\n\n\n\n\n\n\n\n\n\n\nA tidyverse functions quiz with {learnr}\n\n\n\n2019-03-18\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping the {polite} way\n\n\n\n2019-03-04\n\n\n\n\n\n\n\n\n\n\n\nWhat’s your Hadley Number?\n\n\n\n2019-02-27\n\n\n\n\n\n\n\n\n\n\n\nGraphing the Relayverse of podcasts\n\n\n\n2019-02-14\n\n\n\n\n\n\n\n\n\n\n\nGit going: the command line\n\n\n\n2019-02-01\n\n\n\n\n\n\n\n\n\n\n\nMap deer-vehicle colisions with {shiny}\n\n\n\n2019-01-18\n\n\n\n\n\n\n\n\n\n\n\nMotivate yourself with an .Rprofile\n\n\n\n2019-01-04\n\n\n\n\n\n\n\n\n\n\n\nTravel the NBA with {rvest}, {leaflet} and {osrm}\n\n\n\n2018-12-24\n\n\n\n\n\n\n\n\n\n\n\nChange your {blogdown} fonts\n\n\n\n2018-11-29\n\n\n\n\n\n\n\n\n\n\n\nQuantify colour by {magick}\n\n\n\n2018-11-25\n\n\n\n\n\n\n\n\n\n\n\nWaggle dance with {ggbeeswarm} and {emoGG}\n\n\n\n2018-11-21\n\n\n\n\n\n\n\n\n\n\n\nTeaching R with Pokémon Go data\n\n\n\n2018-11-04\n\n\n\n\n\n\n\n\n\n\n\nR session info info\n\n\n\n2018-10-13\n\n\n\n\n\n\n\n\n\n\n\nKnitting Club: R Markdown for beginners\n\n\n\n2018-09-24\n\n\n\n\n\n\n\n\n\n\n\nEARL 2018: {crosstalk} in memes\n\n\n\n2018-09-12\n\n\n\n\n\n\n\n\n\n\n\nEngifification in R with {gifski}\n\n\n\n2018-07-26\n\n\n\n\n\n\n\n\n\n\n\nFootballers are younger than you\n\n\n\n2018-07-17\n\n\n\n\n\n\n\n\n\n\n\nHow accessible is my post about accessibility?\n\n\n\n2018-07-12\n\n\n\n\n\n\n\n\n\n\n\nMarkov-chaining my PhD thesis\n\n\n\n2018-06-30\n\n\n\n\n\n\n\n\n\n\n\nIterative R Markdown reports for Dawson’s Creek\n\n\n\n2018-06-26\n\n\n\n\n\n\n\n\n\n\n\nTid-ye-text with {geniusr}\n\n\n\n2018-06-05\n\n\n\n\n\n\n\n\n\n\n\nCloudy with a chance of pie\n\n\n\n2018-05-25\n\n\n\n\n\n\n\n\n\n\n\nPokéballs in Super Smash Bros\n\n\n\n2018-05-19\n\n\n\n\n\n\n\n\n\n\n\nAccessibility workshop at #Sprint18\n\n\n\n2018-05-12\n\n\n\n\n\n\n\n\n\n\n\nTWO DOGS IN TOILET ELDERLY LADY INVOLVED\n\n\n\n2018-04-27\n\n\n\n\n\n\n\n\n\n\n\nR Trek: exploring stardates\n\n\n\n2018-04-14\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html",
    "href": "posts/2024-01-12-yihui-rap/index.html",
    "title": "Yihui Xie: RAP god",
    "section": "",
    "text": "Taking a moment to thank Yihui, who has unwittingly made possible the rise of Reproducible Analytical Pipelines (RAP)."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#rap",
    "href": "posts/2024-01-12-yihui-rap/index.html#rap",
    "title": "Yihui Xie: RAP god",
    "section": "RAP",
    "text": "RAP\nA Reproducible Analytical Pipeline (RAP) is a code-driven, version-controlled workflow that reads data, processes it and then creates output aretfacts, while ensuring that the process can be re-run in the future and by others.\nRAP was pioneered in the UK government by Dr Matt Upson and the team at the Government Digital Service (GDS), not limited to Dr Matt Gregory1 and Duncan Garmonsway, as well as several early adopters like the Department for Culture, Media and Sport.\nThe primary purpose for RAP has been the production of statistical publications: reports and data files for public consumption, published officially on the government’s website.\nThese days, RAP is so much more: it’s a way of thinking, a community, a movement. It’s spread across the government and public sector and is gaining traction in the wider analytical community through efforts like Bruno Rodrigues’s book."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#r-was-made-for-rap",
    "href": "posts/2024-01-12-yihui-rap/index.html#r-was-made-for-rap",
    "title": "RAP is nothing without Yihui",
    "section": "R was made for RAP",
    "text": "R was made for RAP\nThe primary purpose for RAP was in producing statistical publications: reports and data files for public consumption, published officially on the government’s website.\nR is the lingua franca for statistical production in the UK’s government and public sector.\nWhy? Possibly because R is a data- and stats-first language2. But R covers the whole pipeline: ingestion, digestion and, er, ‘ejection’."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#no-rap-without-knitr",
    "href": "posts/2024-01-12-yihui-rap/index.html#no-rap-without-knitr",
    "title": "Yihui Xie: RAP god",
    "section": "No RAP without {knitr}",
    "text": "No RAP without {knitr}\nR is the lingua franca for statistical production in the UK’s government and public sector.\nWhy? Possibly because R is a data- and stats-first language2. But R covers the whole pipeline: ingestion, digestion and, er, ‘ejection’.\nIn Matt’s original blog post about RAP, he noted the importance of reproducible reporting, with R Markdown as the weapon of choice for R users.\nWhy is R Markdown so instrumental to the adoption of RAP? Stats publications are usually periodical; often weekly. R Markdown is perfect for literate programming: you can create a skeleton document that uses R code to update dynamically, saving so much time when a new version of the publication must be created with fresh data.\nBut the crucial element is that R Markdown is easy to learn, easy to use, when compared to predecessors. Most R users these days are unliely to have ever encountered Sweave, for example, which is actually built into R.\nWith Sweave you embed R code in a LaTeX document, rather than the plain text of R Markdown. LaTeX is powerful, but is effectively a whole new language you must learn. With R Markdown, you write just some text and mark it up with some simple adornments3.\nR Markdown has minimised the friction required to go from data to publication.\n{knitr}"
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#what-now",
    "href": "posts/2024-01-12-yihui-rap/index.html#what-now",
    "title": "Yihui Xie: RAP god",
    "section": "What now?",
    "text": "What now?\nYou can sponsor Yihui on GitHub4."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#environment",
    "href": "posts/2024-01-12-yihui-rap/index.html#environment",
    "title": "Yihui Xie: RAP god",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-22 17:48:46 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       evaluate_0.23"
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#footnotes",
    "href": "posts/2024-01-12-yihui-rap/index.html#footnotes",
    "title": "Yihui Xie: RAP god",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo the extent that you can use ‘RAP’ as a noun (‘we have many RAPs in our department’) and verb (‘I’m going to RAP this publication’).↩︎\nNot strictly true. We’re talking here about open source languages like R and Python. Your proprietary tool of choice is not RAP compliant, sorry.↩︎\nR has grown beyond statistical analysis, of course. You can build apps and websites and so much more without ever ‘doing stats’. Just ask David Keyes.↩︎\nCompared to what? Most regular R users these days are unlikely to have encountered Sweave, for example, which is actually built into R. Sweave relies on knowledge of document preparation using LaTeX, which most of us barely know how to pronounce, let alone use.↩︎\nThis becomes even easier with, for example, RStudio’s ‘visual’ mode for R Markdown files, which includes a GUI for marking-up to your text without needing to remember how to mark it up in **bold**, for example.↩︎\nRAP was pioneered in the UK government by Dr Matt Upson and the team at the Government Digital Service (GDS), not limited to Dr Mat Gregory (too many Matts, amirite?) and Duncan Garmonsway, as well as several early adopters like the Department for Culture, Media and Sport.↩︎\nDisclaimer: I’m one of these people.↩︎"
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#no-way-yihui",
    "href": "posts/2024-01-12-yihui-rap/index.html#no-way-yihui",
    "title": "Yihui Xie: RAP god",
    "section": "",
    "text": "Yihui Xie is a hero. He was recently laid off from Posit. You can sponsor Yihui on GitHub1 for his epic contributions to the R community."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#r-is-for-rap",
    "href": "posts/2024-01-12-yihui-rap/index.html#r-is-for-rap",
    "title": "Yihui Xie: RAP god",
    "section": "R is for RAP",
    "text": "R is for RAP\nRAP is language agnostic2, but R has emerged as the preferred option for statistical production in the UK’s government and public sector. Why? Possibly because R is a data- and stats-first language3 and therefore a natural choice for statistics professionals.\nOf course, R can easily cover the whole ‘soup-to-nuts’ workflow. Not just ingestion and digestion of data, but also crucially the creation of reports. R Markdown and {knitr} are the obvious tool for this kind of document generation, for which we must thank Yihui for his tireless and humble efforts.\nBut what makes R Markdown so conducive to RAP, in particular? Well, stats publications are generally periodical (often weekly) and R Markdown is perfect for literate programming at pace: you can create a skeleton document that can be updated dynamically with R code, saving so much time when a new version of the publication needs to be created with fresh data.\nCrucially, R Markdown is relatively simple to learn and use4. You write some plain text and mark it up with simple adornments5. This suits perfectly the range of skills and abilities in statistical teams across the public sector, where staff are often ‘numbers-people’ first and ‘coders’ second.\nHence why R Markdown has been a central tenet of RAP since Dr Matt Upson6, RAP’s ‘Founding Father’, noted it in his germinal blog post."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#thats-a-rap",
    "href": "posts/2024-01-12-yihui-rap/index.html#thats-a-rap",
    "title": "Yihui Xie: RAP god",
    "section": "That’s a RAP",
    "text": "That’s a RAP\nPut (far too) simply, a Reproducible Analytical Pipeline (RAP) is any code-driven, version-controlled workflow that reads data, processes it and creates consumable outputs, while ensuring that the process can be re-run in the future and by others.\nRAP was birthed from ‘DataOps’ principles with a focus on the production of statistical publications: reports and data files for public consumption, published officially on the UK government’s website. These files are important for transparency and decision making.\nThese days, RAP is so much more: it’s a way of thinking, a community and a movement1. Its ethos has spread across the UK public sector and is gaining traction globally through efforts like Bruno Rodrigues’s excellent book."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#tldr",
    "href": "posts/2024-01-12-yihui-rap/index.html#tldr",
    "title": "Yihui Xie: RAP god",
    "section": "tl;dr",
    "text": "tl;dr\nTaking a moment to thank Yihui, who has unwittingly made possible the rise of Reproducible Analytical Pipelines (RAP)."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#hooray-for-yihui",
    "href": "posts/2024-01-12-yihui-rap/index.html#hooray-for-yihui",
    "title": "Yihui Xie: RAP god",
    "section": "Hooray for Yihui",
    "text": "Hooray for Yihui\nYihui Xie is an R legend. He was, however, recently laid off by his employers at Posit.\nI’ve personally benefited a great deal from Yihui’s work, from writing reproducible presentations with {xaringan} to producing the original version of this blog with {blogdown}.\nAt a grander scale, Yihui’s contributions to the R ecosystem have had a lasting and transformational impact on how we generate Official Statistics in the UK, where R Markdown and {knitr} are essential and ubiquitous tools in particular.\nSo much so that we have a custom Yihui Slack emoji."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#hooray-for-yihui-1",
    "href": "posts/2024-01-12-yihui-rap/index.html#hooray-for-yihui-1",
    "title": "Yihui Xie: RAP god",
    "section": "Hooray for yihui",
    "text": "Hooray for yihui\nOf course, I’m not alone in this: many others have talked about their appreciation for Yihui and his work, including Eric and Mike’s discussion on the R Weekly podcast and Emily’s thread.\nYou can also take a look at the incredible number of people who have signed up to sponsor Yihui on GitHub, which sits just shy of 300 at the moment7.\nThank you, Yihui, we look forward to what comes next."
  },
  {
    "objectID": "posts/2024-01-12-yihui-rap/index.html#down-but-not-out",
    "href": "posts/2024-01-12-yihui-rap/index.html#down-but-not-out",
    "title": "Yihui Xie: RAP god",
    "section": "Down, but not out",
    "text": "Down, but not out\nOf course, I’m not alone: many others have talked about their appreciation for Yihui and his work, including Eric and Mike’s discussion on the R Weekly podcast and Emily’s thread.\nYou can also take a look at the incredible number of people who have signed up to sponsor Yihui on GitHub, which sits just shy of 300 at the time of writing7.\nThank you, Yihui. We look forward to what comes next."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#tldr",
    "href": "posts/2024-01-20-webr-remote/index.html#tldr",
    "title": "Pseudo-apps in the browser with WebR and Quarto?",
    "section": "tl;dr",
    "text": "tl;dr\nA demo post to test out embedded WebR chunks that source a non-CRAN R package. Readers can edit and re-run code later in this blog post, entirely within the browser."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#world-wide-web-r",
    "href": "posts/2024-01-20-webr-remote/index.html#world-wide-web-r",
    "title": "{webR} with remote packages",
    "section": "World Wide Web R",
    "text": "World Wide Web R\nWeb R lets you run R code in a browser with no need for a server. This means you can write blog posts—like this one!—that readers can interactive with.\nI’ve written about this before, but I couldn’t embed webR chunks at the time. It’s possible now I’ve converted this blog to Quarto.\nBut another thing has happened to make Web R even more irresistible: you can now install remote, non-CRAN packages for use in a Web R session.\nJames Goldie has written a nice how-to on his blog about this."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#example",
    "href": "posts/2024-01-20-webr-remote/index.html#example",
    "title": "{webR} with remote packages",
    "section": "Example",
    "text": "Example\nSo here’s an example of what I mean. My {dialga} package is very focused: its goal is to make it easier to compose cron strings programmatically. Provide numeric values to its arguments, convert them to cron strings and then convert those to an English interpretation.\nThe package is not on CRAN, but I’ve added it to my r-universe. You can add a chunk like this to your post to grab a WebR-ready version of the package compiled by r-universe. A James G noted, the context: setup specification means that the code will run automatically when the page is opened, so the package will load as soon as the user arrives.\n```{webr-r}\n#| context: setup\nwebr::install(\"dialga\", repos = \"https://matt-dray.r-universe.dev\")\n```\nLet’s use the package.\nUse r2cron() to convert values into a cron string. The integer values for each argument below show the full range of possibilities, which you can adjust. The output will be ’* * * * *‘, which means ’every minute’. Start by running the code with the ‘Run Code’ button.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLet’s say you wanted ‘every 12 hours’ instead. Change the hours argument to 12 and press the ‘Run Code’ button again. And so on as you please.\nYou can convert the output above nto English with cron2eng().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSo… if you don’;t want o install {dialga}, you can just visit this page and adjust the WebR chunks! That, or you can use one of the already-existing, excellent apps like crontab.guru. Your call."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#environment",
    "href": "posts/2024-01-20-webr-remote/index.html#environment",
    "title": "Pseudo-apps in the browser with WebR and Quarto?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-01-23 11:49:58 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       evaluate_0.23"
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#world-wide-webr",
    "href": "posts/2024-01-20-webr-remote/index.html#world-wide-webr",
    "title": "Pseudo-apps in the browser with WebR and Quarto?",
    "section": "World Wide WebR",
    "text": "World Wide WebR\nWebR lets you run R code in a browser with no need for a server, thanks in large part to George Stagg’s efforts. And these days you can embed editable R chunks into Quarto documents, thanks to James Balamuta’s quarto-webr extension.\nI’ve written before about how powerful this could be for demonstrating how to use code. Readers can adjust the code themselves to better understand the approach without having to install anything.\nThis blog has been ported to Quarto since I wrote that post, so it’s now possible for me to include WebR chunks in my posts directly.\nEven better, it’s now possible to install remote, non-CRAN packages for use in WebR sessions. Thanks to James Goldie for his excellent blog post on how you can get this set up and running1. That post should be your first port of call; I’m not going to repeat all of his advice here because you should read his post in the first instance.\nSo much of this blog could have benefited from the inclusion of WebR chunks and I hope to use it a lot more in future. The rest of this post is a chance for me to try out the process of using WebR and installing a GitHub-hosted package."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#a-pseudo-app",
    "href": "posts/2024-01-20-webr-remote/index.html#a-pseudo-app",
    "title": "Pseudo-apps in the browser with WebR and Quarto?",
    "section": "A ‘pseudo-app’?",
    "text": "A ‘pseudo-app’?\nIn some cases, WebR helps could help your blog post become a pseudo web app2. Load a package and provide some code that performs basic functionality, which readers can then fiddle with. If the package is simple enough, people may not need to install the package at all; they could just visit your blog post.\nI call it a ‘pseudo’ app because of the lack of control: in a Shiny app I can force you to select certain elements from a dropdown, or only show you certain outputs. With WebR and Quarto I can only demo functions and let you adjust the arguments; if you delete all the code, that’s on you.\n\nExample\nSo here’s an example of what I mean. My {dialga} package is very focused: its goal is to make it easier to compose cron strings programmatically. Provide numeric values to its arguments, convert them to cron strings and then convert those to an English interpretation.\nThe package is not on CRAN, but I’ve added it to my R-universe, thanks to the amazing R-universe project by rOpenSci and particularly the mighty Jeroen Ooms3. This is crucial for sourcing the package with WebR.\n\nSetup\nFollowing James G’s post, I first installed James B’s WebR extension to this blog’s source by running quarto add coatless/quarto-webr in the terminal. Within this post I added filters: [\"webr\"] to the YAML header and specified the webr-r engine for chunks that I wanted to let users interact with.\nI also added the hidden code chunk below, which installs in the background a WebR-ready version of the {dialga} package from R-universe when the page loads (as dictated by the context: setup instruction).\n```{webr-r}\n#| context: setup\nwebr::install(\"dialga\", repos = \"https://matt-dray.r-universe.dev\")\n```\nHow do you know this has worked? You may have noticed when you arrived that ‘WEBR STATUS: 🟡 Loading…’ was shown at the top of the post before changing to ‘🟢 Ready!’ to indicate that the WebR chunks are ready to use.\n\n\nRun\nNow let’s use the {dialga} package.\nUse r2cron() to convert values into a cron string. The integer values for each argument below show the full range of possibilities, which you can adjust. The output will be * * * * *, which means ‘every minute’. Start by running the code with the ‘Run Code’ button.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLet’s say you wanted ‘every minute past hour 12’ instead. Change the hours argument to 12 and press the ‘Run Code’ button again. And so on as you please.\nFor completeness, you can convert the output above into English with cron2eng().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn other words… if you don’t want to install {dialga} you can just visit this page and adjust the WebR chunks!\nThat, or you can use one of the already-existing, excellent sites like crontab.guru, lol. Your call.\nRegardless, I think this is a good indication of how a WebR post can help readers understand—or simply just use—your package in a demonstrative blog post."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#style",
    "href": "posts/2024-01-20-webr-remote/index.html#style",
    "title": "{webR} with remote packages",
    "section": "Style",
    "text": "Style\nOne downside is that the WebR chunks are not automatically styled like the rest of the blog.\nJames has clearly written some CSS on his blog to make the WebR code blocks match the theme of his blog. He’s even adjusted the ‘run code’ button and moved the package loading/‘ready!’ information to the bottom right of the page. I’ve taken a peek at his source code to work out the tweaks needed."
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html",
    "href": "posts/2024-01-20-webr-remote/index.html",
    "title": "{webR} with remote packages",
    "section": "",
    "text": "{fig-alt=“Meme from Super Mario Movie. top panel is the king penguin labelled ‘R Stats’ and saying ‘do you yield?’ Lower panel is Bowser labelled ‘the browser’, laughing and saying ‘I do not”, except the ’not’ has been censored with a black bar.”}"
  },
  {
    "objectID": "posts/2024-01-20-webr-remote/index.html#footnotes",
    "href": "posts/2024-01-20-webr-remote/index.html#footnotes",
    "title": "Pseudo-apps in the browser with WebR and Quarto?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI note also that James G has clearly written some CSS on his blog to make the WebR code blocks match the theme of his blog. I haven’t done this yet at time of writing, so the chunks do a look a bit conspicuous.↩︎\nAlthough these days you can also use {shinylive} to write a Shiny app that can run entirely in the browser! I wrote about this in a previous post.↩︎\nThere really isn’t enough space in this post to talk about the R-universe, but you can learn more on the rOpenSci site.↩︎"
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#tldr",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#tldr",
    "title": "Kill your darlings (but bugfix first)",
    "section": "tl;dr",
    "text": "tl;dr\nAn update about updates to {a11ytables}. Also maybe I should rewrite the whole thing from scratch, lol."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#updates",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#updates",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Updates",
    "text": "Updates\nI’ve done two minor updates that add new features. We’re now on version 0.3, please try to keep up.\nOf course, you can read the package’s NEWS.md file for details on the changes covered by these updates.\nMy tests are weak and I’ve no idea of all edge cases, so please do leave an issue in the repo if you find something bad or embarrassing2 in the package.\n\nVersion 0.2\nThe package was designed to insert a data.frame of data into each sheet. Nice and simple and makes perfect sense for the contents, notes and ‘tables’ sheet types. But not ideal for the cover, actually.\nYou used to have to supply a data.frame for the cover that had a row per section and a column each for the section headers and their content. This is obviously restrictive: what if the sections on your cover sheet need more than one row of information?\nFor example, you might need a section on the cover sheet called ‘Contact us’ that contains three rows: some preamble, a website link and a contact email address.\nVersion 0.2 of the package, which dropped in November 2023, solves this problem. Now you can provide a list object with arbitrary content instead of providing a data.frame. For example:\n\ncover_list &lt;- list(\n  \"Information\" = \"This is a demo spreadsheet cover.\",\n  \"Contact us\" = c(\n    \"Find out more by contacting us.\",\n    \"Website: https://co-analysis.github.io/a11ytables/\",\n    \"Email address: fake.address@a11ytables.com\"\n  )\n)\n\nThis will result in a cover sheet with two sections. The first will have one row and the second will have three. This is way better than in before, when you could only supply one row per section.\nBut wait! This update made hyperlinks available on the cover page as well. The user supplies these in Markdown format—like [{a11ytables}](https://github.com/co-analysis/a11ytables)—and they’re auto-converted so that the resulting spreadsheet cell contains a hyperlink3. For example, the website and email address could be written like this:\n\ncover_list &lt;- list(\n  \"Information\" = \"This is a demo spreadsheet cover.\",\n  \"Contact us\" = c(\n    \"Find out more by contacting us.\",\n    \"[Website](https://co-analysis.github.io/a11ytables/)\",\n    \"[Email address](fake.address@a11ytables.com)\"\n  )\n)\n\nWhile I was adding the hyperlink functionality to the cover, I figured I would make it available to the source argument of create_a11ytable() as well, so users can link to the origin for the tables of data in their publication.\n\n    sources = c(\n      rep(NA_character_, 3),\n      \"[Gorman et al, 2024](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\"\n    ),\n\n\n\nVersion 0.3\nArbitrary content was also the theme for version 0.3, which hit shelves earlier this month. Prior to this version, it was assumed there were only going to be certain rows of information above a table: the sheet title (required, provided by the user), a message about the number of tables in the sheet (autogenerated), a message about the presence of notes (autogenerated) and the data source (optional, if provided by the user).\nBut {a11ytables} users and other spreadsheet publishers made it clear that sometimes they want to put other, arbitrary rows above tables of data. I can’t think of a good reason why extra rows of text above tables of data would necessarily break best practice guidance. In fact, they’ll probably be helpful to provide needed context.\nSo, version 0.3 allows for these arbitrary rows of content. Not just on sheets containing data tables, but also on the contents and notes sheets, just in case. Of course, these can also be provided in the form of Markdown hyperlinks if the user desires.\nThe approach to integrating this functionality is a new argument to create_a11ytables(): custom_rows. You provide a character vector where each element is a sheet and each sub-element is a separate custom row for that sheet. Here’s an example of specifying the list argument where the fourth sheet will contain two custom rows, the first of which is a hyperlink:\n\n    custom_rows = list(\n      rep(NA_character_, 3)\n      c(\n        \"First custom row [with a hyperlink.](https://co-analysis.github.io/a11ytables/)\",\n        \"Second custom row.\"\n      )\n    ),"
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#whats-next",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#whats-next",
    "title": "Kill your darlings (but bugfix first)",
    "section": "What’s next?",
    "text": "What’s next?\nThese are two fixes that were a long time coming. Time now to ramble and navel-gaze4 about the future of the package. You can always take a look at the outstanding issues to see what’s on the to-do list. For now there’s a couple of things I want to mention.\n\nI like those ODS\nA big missing piece of the puzzle is to have the option to write to an open-format ODS file, which is the preferred format for publishing on GOV.UK. I’ve had some great chats with the underground cross-government ‘Spreadsheet Club’5 to consider whether it’s possible to do things like piggyback off a spreadsheet program via the command line6 or even develop some code to generate the necessary XML files. Ideally I need an {openods} package, or to add functionality into {openxlsx}7 to convert the Workbook-class object into the necessary XML for an xlsx file or an ODS file. None of these are ‘easy’.\nAnother thing: there are plenty of bugfixes and outstanding nice-to-haves as well. Much of the development required is to handle cell-level problems, like setting the number of decimal places to show. This is not that hard in principle; {openxlsx} itself has some options() that you can set. The hard part is that numeric columns are often coerced to text columns in {a11ytables} because strings are often used as placeholder values, like ‘[c]’ for confidential values.\nThere’s another reason why this kind of thing is tricky: the ethos of {a11ytables} is to keep the user interface ‘simple’ so an analyst can go from data to spreadsheet as quickly as possible. Adding lots of arguments to control things like decimal places would clutter the interface and could be a headache for backwards-compatibility if more need to be added in future. This makes me think that an options()-led approach would be a decent solution, especially as this is already something that {openxlsx} does.\n\n\nA fateful journey\nI took the train to spend time with my parents over Christmas. High winds caused a tree to fall on the tracks and I could only make it partway. There was a rail replacement service, but the driver got lost and started heading the wrong way.\nThis gave me plenty of time to try out some new ideas for a potential successor to {a11ytables}. I’ve been thinking about building a new package from scratch for a while, now that I know the limitations of the current package and seek to escape the limitations of the skills of me from the past.\nAnyway, while the bus driver was U-turning on a country lane in East Sussex, I fiddled around with alternative input methods. The ‘purity’ of a nice tidy a11ytables-class data.frame is spoiled slightly by having to provide a list rather than a data.frame for the cover sheet and by providing vectors to the new custom_rows argument. This is a minor gripe, but I think it has usability issues and lacks some consistency.\nI was able to spend some time enacting some ideas for an ‘{a11ytables2}’ package. The long and the short of it is that it uses {openxlsx2} (note the ‘2’) and you provide input via a nested list, so that arbitrary arguments and argument lengths are more easily handled.\nI also have some earlier work in that repo to explore the idea of supplying a YAML configuration file that contains all the information required for you to construct a compliant spreadsheet."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#environment",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#environment",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-02-03 17:08:17 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.6.1 rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.7    xfun_0.41        \n[13] digest_0.6.33     rlang_1.1.3       evaluate_0.23"
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html",
    "title": "The latest {a11ytables}",
    "section": "",
    "text": "I made some updates to {a11ytables} that improve the package, but also make me even more sure I want to rewrite the package from scratch."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#footnotes",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#footnotes",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, I don’t work in central government anymore, which means I don’t ‘dogfood’ this work. I can only feed this dogfood (the package) to my dog (package users) and not myself (me), which feels more normal if I’m honest. Weird metaphor.↩︎\nLike, I don’t know, if you spell the name of your own package wrong. I think this highlights how silly this name was in the first place, but there’s no going back now.↩︎\nNote that the text of a spreadsheet cell is either entirely a link or not. So Visit [the site](https://github.com/co-analysis) for more information and [Visit the site for more information](https://github.com/co-analysis) will both result in an output cell that is entirely a hyperlink.↩︎\nThis is a guaranteed recipe for accidentally plummeting off a cliff, I don’t recommend it.↩︎\nu jelly?↩︎\nSee the issue, especially where Fran presents a function she’s already written to do this for the Department for Transport.↩︎\nI tried asking this of the {openxlsx2} author with predictable results.↩︎\nSlightly dramatic: {a11ytables} would continue to exist and would get bugfixes and small feature updates as needed; it’s just the new version would be the successor, probably.↩︎"
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#package",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#package",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Package",
    "text": "Package\nRight so, I made the {a11ytables} R package to help create government statistics publications that meet official best practice standards. You may be interested in a talk I did about it at EARL 2022.\nI originally made it for me and my team so we could publish accessible spreadsheets to GOV.UK. It seems to have been picked up by a number of other government departments, so I’ve continued to develop it even though I don’t use it myself anymore1.\nYou can stop reading now if you aren’t one of those 12 users. Go and water your plants maybe."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#a-christmas-bus-ride",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#a-christmas-bus-ride",
    "title": "The latest {a11ytables}",
    "section": "A Christmas bus ride",
    "text": "A Christmas bus ride\nI took the train to spend time with my parents over Christmas. High winds meant that a tree fell on the tracks and I could only make it partway. There was a rail replacement service, but the driver got lost and started heading the wrong way. This gave me plenty of time to try out some new ideas for a potential successor to {a11ytables}.\nI fiddled around with alternative input methods, mostly. The ‘purity’ of a nice tidy a11ytables-class data.frame is spoiled slightly by having to provide a list rather than a data.frame for the cover sheet and by providing vectors to the new custom_rows argument. This is a minor gripe, but I think it has usability issues and lacks some consistency.\nSo on that fateful bus journey, which was way longer than it needed to be, I was able to spend some time enacting some ideas for an ‘{a11ytables2}’ package. The long and the short of it is that it uses {openxlsx2} (note the ‘2’) and you provide input via a list, so that arbitrary arguments and argument lengths are more easily handled.\nI also have some earlier work in that repo to explore the idea of supplying a YAML configuration file that contains all the information required for you to construct a compliant spreadsheet."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#introspective-conclusion",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#introspective-conclusion",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Introspective conclusion",
    "text": "Introspective conclusion\nSo, a tale as old as time: I’m trying to fix things when I can; please keep submitting bug fixes and feature requests; I’d love to burn the whole thing down and start again8."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#birth",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#birth",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Birth",
    "text": "Birth\nRight so, I made the {a11ytables} R package to help create government statistics publications that meet official best practice standards. You may be interested in a talk I did about it at EARL 2022.\nI originally made it for me and my team so we could publish accessible spreadsheets to GOV.UK. It seems to have been picked up by a number of other government departments, so I’ve continued to develop it even though I don’t use it myself anymore1.\nYou can stop reading now if you aren’t one of those 12 users. Go and water your plants maybe."
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#life",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#life",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Life",
    "text": "Life\nI’ve done two minor updates that add new features. We’re now on version 0.3, please try to keep up.\nOf course, you can read the package’s NEWS.md file for details on the changes covered by these updates.\nMy tests are weak and I’ve no idea of all edge cases, so please do leave an issue in the repo if you find something bad or embarrassing2 in the package.\n\nVersion 0.2\nThe package interface lets you supply a data.frame to insert into each worksheet. Nice and simple and makes perfect sense for the contents, notes and ‘tables’ sheet types. But not ideal for the cover, actually.\nYou used to have to supply a data.frame for the cover that had a row per section and a column each for the section headers and their content. This is obviously restrictive: what if the sections on your cover sheet need more than one row of information?\nFor example, you might need a section on the cover sheet called ‘Contact us’ that contains three rows: some preamble, a website link and a contact email address.\nVersion 0.2 of the package, which dropped in November 2023, solves this problem. Now you can provide a list object with arbitrary content instead of providing a data.frame. For example:\n\ncover_list &lt;- list(\n  \"Information\" = \"This is a demo spreadsheet cover.\",\n  \"Contact us\" = c(\n    \"Find out more by contacting us.\",\n    \"Website: https://co-analysis.github.io/a11ytables/\",\n    \"Email address: fake.address@a11ytables.com\"\n  )\n)\n\nThis will result in a cover sheet with two sections. The first will have one row and the second will have three. This is way better than in before, when you could only supply one row per section.\nBut wait! This update made hyperlinks available on the cover page as well. The user supplies these in Markdown format—like [{a11ytables}](https://github.com/co-analysis/a11ytables)—and they’re auto-converted so that the resulting spreadsheet cell contains a hyperlink3. For example, the website and email address could be written like this:\n\ncover_list &lt;- list(\n  \"Information\" = \"This is a demo spreadsheet cover.\",\n  \"Contact us\" = c(\n    \"Find out more by contacting us.\",\n    \"[Website](https://co-analysis.github.io/a11ytables/)\",\n    \"[Email address](fake.address@a11ytables.com)\"\n  )\n)\n\nWhile I was adding the hyperlink functionality to the cover, I figured I would make it available to the source argument of create_a11ytable() as well, so users can link to the origin for the tables of data in their publication.\n\n    sources = c(\n      rep(NA_character_, 3),\n      \"[Gorman et al, 2024](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\"\n    ),\n\n\n\nVersion 0.3\nArbitrary content was also the theme for version 0.3, which hit shelves earlier this month. Prior to this version, it was assumed there were only going to be certain rows of information above a table: the sheet title (required, provided by the user), a message about the number of tables in the sheet (autogenerated), a message about the presence of notes (autogenerated) and the data source (optional, if provided by the user).\nBut {a11ytables} users and other spreadsheet publishers made it clear that sometimes they want to put other, arbitrary rows above tables of data. I can’t think of a good reason why extra rows of text above tables of data would necessarily break best practice guidance. In fact, they’ll probably be helpful to provide needed context.\nSo, version 0.3 allows for these arbitrary rows of content. Not just on sheets containing data tables, but also on the contents and notes sheets, just in case. Of course, these can also be provided in the form of Markdown hyperlinks if the user desires.\nThe approach to integrating this functionality is a new argument to create_a11ytables(): custom_rows. You provide a character vector where each element is a sheet and each sub-element is a separate custom row for that sheet. Here’s an example of specifying the list argument where the fourth sheet will contain two custom rows, the first of which is a hyperlink:\n\n    custom_rows = list(\n      rep(NA_character_, 3)\n      c(\n        \"First custom row [with a hyperlink.](https://co-analysis.github.io/a11ytables/)\",\n        \"Second custom row.\"\n      )\n    ),"
  },
  {
    "objectID": "posts/2024-01-27-a11ytables-0.3/index.html#death",
    "href": "posts/2024-01-27-a11ytables-0.3/index.html#death",
    "title": "Kill your darlings (but bugfix first)",
    "section": "Death?",
    "text": "Death?\nThese are two fixes that were a long time coming. Time now to ramble and navel-gaze4 about the future of the package. You can always take a look at the outstanding issues to see what’s on the to-do list. For now there’s a couple of things I want to mention.\n\nI like those ODS\nA big missing piece of the puzzle is to have the option to write to an open-format ODS file, which is the preferred format for publishing on GOV.UK. I’ve had some great chats with the underground cross-government ‘Spreadsheet Club’5 to consider whether it’s possible to do things like piggyback off a spreadsheet program via the command line6 or even develop some code to generate the necessary XML files. Ideally I need an {openods} package, or to add functionality into {openxlsx}7 to convert the Workbook-class object into the necessary XML for an xlsx file or an ODS file. None of these are ‘easy’.\nAnother thing: there are plenty of bugfixes and outstanding nice-to-haves as well. Much of the development required is to handle cell-level problems, like setting the number of decimal places to show. This is not that hard in principle; {openxlsx} itself has some options() that you can set. The hard part is that numeric columns are often coerced to text columns in {a11ytables} because strings are often used as placeholder values, like ‘[c]’ for confidential values.\nThere’s another reason why this kind of thing is tricky: the ethos of {a11ytables} is to keep the user interface ‘simple’ so an analyst can go from data to spreadsheet as quickly as possible. Adding lots of arguments to control things like decimal places would clutter the interface and could be a headache for backwards-compatibility if more need to be added in future. This makes me think that an options()-led approach would be a decent solution, especially as this is already something that {openxlsx} does.\n\n\nA fateful journey\nI took the train to spend time with my parents over Christmas. High winds caused a tree to fall on the tracks and I could only make it partway. There was a rail replacement service, but the driver got lost and started heading the wrong way.\nThis gave me plenty of time to try out some new ideas for a potential successor to {a11ytables}. I’ve been thinking about building a new version of the package for a while, now that I’ve had time for its limitations to emerge.\nAnyway, while the bus driver was U-turning on a country lane in East Sussex, I fiddled around with alternative input methods. The ‘purity’ of a nice tidy a11ytables-class data.frame is spoiled slightly by having to provide a list rather than a data.frame for the cover sheet and by providing vectors to the new custom_rows argument. This is a minor gripe, but I think it has usability issues and lacks some consistency.\nI was able to spend some time enacting some ideas for an ‘{a11ytables2}’ package. The long and the short of it is that it uses {openxlsx2} (note the ‘2’) and you provide input via a nested list, so that arbitrary arguments and argument lengths are more easily handled.\nI also have some earlier work in that repo to explore the idea of supplying a YAML configuration file that contains all the information required for you to construct a compliant spreadsheet."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#tldr",
    "href": "posts/2024-02-02-base-args/index.html#tldr",
    "title": "Start an argument with R",
    "section": "tl;dr",
    "text": "tl;dr\nFour useful (lesser-known?) arguments to four common R functions."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#environment",
    "href": "posts/2024-02-02-base-args/index.html#environment",
    "title": "Start an argument with R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-02-03 16:53:13 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lme4_1.1-35.1 Matrix_1.6-0 \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       nlme_3.1-162      cli_3.6.2         knitr_1.45       \n [5] rlang_1.1.3       xfun_0.41         minqa_1.2.6       jsonlite_1.8.7   \n [9] glue_1.7.0        htmltools_0.5.6.1 fansi_1.0.6       rmarkdown_2.25   \n[13] grid_4.3.1        evaluate_0.23     tibble_3.2.1      MASS_7.3-60      \n[17] fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4   compiler_4.3.1   \n[21] Rcpp_1.0.11       htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.15.0\n[25] lattice_0.21-8    digest_0.6.33     nloptr_2.0.3      utf8_1.2.4       \n[29] pillar_1.9.0      splines_4.3.1     magrittr_2.0.3    tools_4.3.1      \n[33] boot_1.3-28.1"
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#footnotes",
    "href": "posts/2024-02-02-base-args/index.html#footnotes",
    "title": "Start an argument with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRasmus recently did some sleuthing to discover the source of this dataset! A great read.↩︎\nNote that package startup messages can also be controlled en masse by wrapping library calls in suppressPackageStartupMessages(), which I’ve talked about before. And also written about the sheer length of this function name.↩︎\nRecall that `[` is actually a function so you can write `[`(mtcars, 1:3, c(\"cyl\", \"hp\")) to achieve the same things as mtcars[1:3, c(\"cyl\", \"hp\"].↩︎\nOf course, three arguments to [` is bread and butter for {data.table} users!↩︎"
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html",
    "href": "posts/2024-02-02-base-args/index.html",
    "title": "Start an argument with R",
    "section": "",
    "text": "Four useful (lesser-known?) arguments to four common R functions."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#based-and-red-pilled",
    "href": "posts/2024-02-02-base-args/index.html#based-and-red-pilled",
    "title": "Start three arguments",
    "section": "Based and red-pilled",
    "text": "Based and red-pilled\nThere’s been a recent glut of posts about useful base-R functions, like the ones by Maëlle, Isabella and Yihui.\nI’m not going to show you three useful base R functions. Instead, a twist: three useful arguments from three everyday functions.\nIt’s time for a post about these because I’ve live- and pair-coded with a handful of people who hadn’t seen them before.\nThese are unlikely to blow your mind. I hope at least you might think ‘sure, okay’.\nThe three commonplace functions are str(), print() and `[`."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#structural-integrity",
    "href": "posts/2024-02-02-base-args/index.html#structural-integrity",
    "title": "Start three arguments",
    "section": "Structural integrity",
    "text": "Structural integrity\nstr() prints an object’s structure. It’s especially helpful for viewing lists in a compact hierarchical fashion. Consider this nested list:\n\nnested_list &lt;- list(\n  x = list(x1 = letters[1:3], x2 = list(x3 = 1:3, x4 = 4:6)),\n  y = list(y1 = list(y2 = list(y3 = \"mtcars\", y4 = mtcars))),\n  z = list(z1 = LETTERS[1:5], z2 = list(z4 = 100), z3 = list(z5 = 1))\n)\n\nHere’s the output we get from a simple str() call:\n\nstr(nested_list)\n\nList of 3\n $ x:List of 2\n  ..$ x1: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ x2:List of 2\n  .. ..$ x3: int [1:3] 1 2 3\n  .. ..$ x4: int [1:3] 4 5 6\n $ y:List of 1\n  ..$ y1:List of 1\n  .. ..$ y2:List of 2\n  .. .. ..$ y3: chr \"mtcars\"\n  .. .. ..$ y4:'data.frame':    32 obs. of  11 variables:\n  .. .. .. ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n  .. .. .. ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n  .. .. .. ..$ disp: num [1:32] 160 160 108 258 360 ...\n  .. .. .. ..$ hp  : num [1:32] 110 110 93 110 175 105 245 62 95 123 ...\n  .. .. .. ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n  .. .. .. ..$ wt  : num [1:32] 2.62 2.88 2.32 3.21 3.44 ...\n  .. .. .. ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ...\n  .. .. .. ..$ vs  : num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n  .. .. .. ..$ am  : num [1:32] 1 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ...\n  .. .. .. ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ...\n $ z:List of 3\n  ..$ z1: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ z2:List of 1\n  .. ..$ z4: num 100\n  ..$ z3:List of 1\n  .. ..$ z5: num 1\n\n\nOof, that’s a little bit too much information to flood my console with.\nLuckily you can use the max.level argument to restrict the depth to which the list is printed. Here’s the top layer only, which has a depth of 1:\n\nstr(nested_list, max.level = 1)\n\nList of 3\n $ x:List of 2\n $ y:List of 1\n $ z:List of 3\n\n\nNow I have a very high-level overview: this is list with three list objects with lengths 2, 1 and 3.\nLet’s go deeper.\n\nstr(nested_list, max.level = 2)\n\nList of 3\n $ x:List of 2\n  ..$ x1: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ x2:List of 2\n $ y:List of 1\n  ..$ y1:List of 1\n $ z:List of 3\n  ..$ z1: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ z2:List of 1\n  ..$ z3:List of 1\n\n\nNow we’ve unpacked the next layer of the onion and can see that the contained objects are made up of vectors and more yet more lists.\nFor me, this is a nice way to get the sense of structure without seeing the entire content."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#carriage-feed",
    "href": "posts/2024-02-02-base-args/index.html#carriage-feed",
    "title": "Start three arguments",
    "section": "Carriage feed",
    "text": "Carriage feed\nprint() is a ubiquitous function across most programming languages. In R, you might just type an object’s name to show it. Here’s a tibble with 21 rows to demonstrate.\n\nchick_tbl &lt;- tibble::as_tibble(ChickWeight[1:21, ])\nchick_tbl\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n# ℹ 11 more rows\n\n\nYou might use head() on a data.frame to prevent printing the whole thing, which defaults to showing 6 rows. Tibbles are truncated by default to 10, but a nice feature is that they’ll show a few more if there’s slightly more than 10 rows total. But what if you want more control?\nWell, in both print() and head() is the n argument. No surprise: it lets you select how many rows of your data.frame or tibble get shown in the console.\nI particularly like this when I have a tibble I’d like to inspect the entirety of, but it gets truncated by default. I’ll often find myself doing this:\n\nprint(chick_tbl, n = Inf)\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n11    199    20 1     1    \n12    205    21 1     1    \n13     40     0 2     1    \n14     49     2 2     1    \n15     58     4 2     1    \n16     72     6 2     1    \n17     84     8 2     1    \n18    103    10 2     1    \n19    122    12 2     1    \n20    138    14 2     1    \n21    162    16 2     1    \n\n\nYou can set an option() to see more tibble rows by default, but I’m usually okay with its normal truncating behaviour."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#drop",
    "href": "posts/2024-02-02-base-args/index.html#drop",
    "title": "Start three arguments",
    "section": "Drop",
    "text": "Drop\n`[` is a function2 for extracting elements out of objects, like rows and columns of a data.frame. So the following will give you the first three rows of the mtcars data.frame for the columns called cyl and hp.\n\nmtcars[1:3, c(\"hp\", \"cyl\")]\n\n               hp cyl\nMazda RX4     110   6\nMazda RX4 Wag 110   6\nDatsun 710     93   4\n\n\nSo what happens when you select a single column? You get one column back, right?\n\nmtcars[1:3, \"hp\"]\n\n[1] 110 110  93\n\n\nHa, lol, no. You get a vector. This might be a problem if you’re programmatically passing column names into `[` and you’re always expecting a data.frame as output.\nLuckily, you can guard against this by ensuring the returned doesn’t drop to the simplest dimension.\n\nmtcars[1:3, \"hp\", drop = FALSE]\n\n               hp\nMazda RX4     110\nMazda RX4 Wag 110\nDatsun 710     93\n\n\nA third argument inside the square brackets may look spooky to people who expect only to pass indices for i (rows) and j (columns), but it’s allowed!3"
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#a-real-pane",
    "href": "posts/2024-02-02-base-args/index.html#a-real-pane",
    "title": "Start an argument with R",
    "section": "A real pane",
    "text": "A real pane\nYou might be wondering why I don’t just use View() to peruse data.frames and lists in RStudio’s script pane."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#shh-in-the-library",
    "href": "posts/2024-02-02-base-args/index.html#shh-in-the-library",
    "title": "Start three arguments",
    "section": "Shh in the library",
    "text": "Shh in the library\nlibrary() calls are a staple of R scripts.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThis is generally useful: you can see the exact package set being attached, as well as a warning about conflicts. But regular tidyverse users may not want to see this in\n\ndetach(\"package:tidyverse\")\nlibrary(tidyverse, warn.conflicts = FALSE)\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nAh, silence.\nNote that package startup messages can also be controlled en masse by wrapping library calls in suppressPackageStartupMessages(), which I’ve talked about before1."
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#based-and-r-pilled",
    "href": "posts/2024-02-02-base-args/index.html#based-and-r-pilled",
    "title": "Start an argument with R",
    "section": "Based and R-pilled",
    "text": "Based and R-pilled\nThere’s been a recent glut of posts about useful base-R functions, like the ones by Maëlle, Isabella and Yihui.\nI’m not going to show you three useful base R functions. Instead, a twist: four useful arguments from four everyday functions that have been under your nose this whole time:\n\nmax.level in str()\nn in print()\ninclude.only in library()\ndrop in `[`\n\nThese are unlikely to blow your mind and might well be known to seasoned users. But I’ve been live-coding with folks who hadn’t seen them before.\nAt worst I want you to come away thinking ‘yeah, sure, I guess’.\n\nStructural integrity\nstr() prints an object’s structure. It’s especially helpful for viewing lists in a compact hierarchical fashion. Consider this nested list:\n\nnested_list &lt;- list(\n  x = list(x1 = letters[1:3], x2 = list(x3 = 1:3, x4 = 4:6)),\n  y = list(y1 = list(y2 = list(y3 = \"mtcars\", y4 = mtcars))),\n  z = list(z1 = LETTERS[1:5], z2 = list(z4 = 100), z3 = list(z5 = 1))\n)\n\nHere’s the output we get from a simple str() call:\n\nstr(nested_list)\n\nList of 3\n $ x:List of 2\n  ..$ x1: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ x2:List of 2\n  .. ..$ x3: int [1:3] 1 2 3\n  .. ..$ x4: int [1:3] 4 5 6\n $ y:List of 1\n  ..$ y1:List of 1\n  .. ..$ y2:List of 2\n  .. .. ..$ y3: chr \"mtcars\"\n  .. .. ..$ y4:'data.frame':    32 obs. of  11 variables:\n  .. .. .. ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n  .. .. .. ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n  .. .. .. ..$ disp: num [1:32] 160 160 108 258 360 ...\n  .. .. .. ..$ hp  : num [1:32] 110 110 93 110 175 105 245 62 95 123 ...\n  .. .. .. ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n  .. .. .. ..$ wt  : num [1:32] 2.62 2.88 2.32 3.21 3.44 ...\n  .. .. .. ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ...\n  .. .. .. ..$ vs  : num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n  .. .. .. ..$ am  : num [1:32] 1 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ...\n  .. .. .. ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ...\n $ z:List of 3\n  ..$ z1: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ z2:List of 1\n  .. ..$ z4: num 100\n  ..$ z3:List of 1\n  .. ..$ z5: num 1\n\n\nOof, that’s a little bit too much information to flood my console with.\nLuckily you can use the max.level argument to restrict the depth to which the list is printed. Here’s the top layer only, which has a depth of 1:\n\nstr(nested_list, max.level = 1)\n\nList of 3\n $ x:List of 2\n $ y:List of 1\n $ z:List of 3\n\n\nNow I have a very high-level overview: this is list with three list objects with lengths 2, 1 and 3.\nLet’s go deeper.\n\nstr(nested_list, max.level = 2)\n\nList of 3\n $ x:List of 2\n  ..$ x1: chr [1:3] \"a\" \"b\" \"c\"\n  ..$ x2:List of 2\n $ y:List of 1\n  ..$ y1:List of 1\n $ z:List of 3\n  ..$ z1: chr [1:5] \"A\" \"B\" \"C\" \"D\" ...\n  ..$ z2:List of 1\n  ..$ z3:List of 1\n\n\nNow we’ve unpacked the next layer of the onion and can see that the contained objects are made up of vectors and more yet more lists.\nFor me, this is a nice way to get the sense of structure without seeing the entire content.\n\n\nCarriage feed\nprint() is a ubiquitous function across most programming languages. In R, you might just type an object’s name to show it. Here’s a tibble with 21 rows to demonstrate.\n\nchick_tbl &lt;- tibble::as_tibble(ChickWeight[1:21, ])\nchick_tbl\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n# ℹ 11 more rows\n\n\nYou might use head() on a data.frame to prevent printing the whole thing, which defaults to showing 6 rows. Tibbles are truncated by default to 10, but a nice feature is that they’ll show a few more if there’s slightly more than 10 rows total. But what if you want more control?\nWell, in both print() and head() is the n argument. No surprise: it lets you select how many rows of your data.frame or tibble get shown in the console.\nI particularly like this when I have a tibble I’d like to inspect the entirety of, but it gets truncated by default. I’ll often find myself doing this:\n\nprint(chick_tbl, n = Inf)\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n11    199    20 1     1    \n12    205    21 1     1    \n13     40     0 2     1    \n14     49     2 2     1    \n15     58     4 2     1    \n16     72     6 2     1    \n17     84     8 2     1    \n18    103    10 2     1    \n19    122    12 2     1    \n20    138    14 2     1    \n21    162    16 2     1    \n\n\nYou can set an option() to see more tibble rows by default, but I’m usually okay with its normal truncating behaviour.\n\n\nLibrary check out\nlibrary() calls are a staple of R scripts. Let’s say I’m attaching the {lme4} package becuase I want to use the famous cake dataset1.\n\nlibrary(lme4, quietly = TRUE)\n\nAha, no, it’s not the quietly argument I want to talk about2, though it is handy for stopping messages from being printed.\nOf course, what library() does is let you access objects, like functions and datasets, from a named package. How many objects did we attach from {lme4}?\n\nlength(ls(\"package:lme4\"))\n\n[1] 102\n\n\nBlimey, all we wanted was cake. But actually, we can be more selective with library() using the include.only argument.\n\ndetach(\"package:lme4\")\nlibrary(lme4, include.only = \"cake\")\nls(\"package:lme4\")\n\n[1] \"cake\"\n\n\nConversely, you can exclude as well.\nWhy would you want to do this? This can keep your environment tidy—if that’s something you care about—but also helps prevent conflicts between objects that might already exist in your environment.\nIt also means you’ve been explicit about the origin of any objects used in your script. If I see cake referenced in your script but can’t see how it was derived, I can take a look at that library call to see that you imported it from {lme4}.\nAt worst, this might be a nice thing for Python users, who love to from x import y.\n\n\nScore a drop goal\nThe square bracket, `[`, is a function3 for extracting elements out of objects, like rows and columns of a data.frame.\nSo the following will give you the first three rows of the cake data.frame for the columns temp and angle.\n\ncake[1:3, c(\"temp\", \"angle\")]\n\n  temp angle\n1  175    42\n2  185    46\n3  195    47\n\n\nSo what happens when you select a single column? You get one column back, right?\n\ncake[1:3, \"temp\"]\n\n[1] 175 185 195\n\n\nHa, lol, no. You get a vector. This might be a problem if you’re programmatically passing column names into `[` and you’re always expecting a data.frame as output.\nLuckily, you can guard against this by ensuring the returned doesn’t drop to its simplest dimension.\n\ncake[1:3, \"angle\", drop = FALSE]\n\n  angle\n1    42\n2    46\n3    47\n\n\nA third argument inside the square brackets may look spooky to people who expect only to pass indices for i (rows) and j (columns), but it’s allowed!4"
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#getting-argumentative",
    "href": "posts/2024-02-02-base-args/index.html#getting-argumentative",
    "title": "Start an argument with R",
    "section": "Getting argumentative",
    "text": "Getting argumentative\nThere’s been a recent glut of posts about useful base-R functions, like the ones by Maëlle, Isabella and Yihui.\nI’m not going to show you three useful base R functions. Instead, a twist. Four useful arguments from four everyday functions:\n\nmax.level in str()\nn in print()\ninclude.only in library()\ndrop in `[`\n\n\nStructural integrity\nstr() prints an object’s structure. It’s especially helpful for viewing lists in a compact hierarchical fashion. Consider this nested list:\n\nnested_list &lt;- list(\n  x = list(x1 = 1:3, x2 = list(x3 = 4:6, x4 = 7:9)),\n  y = list(y1 = list(y2 = list(y3 = mtcars))),\n  z = list(z1 = CO2, z2 = list(z4 = 100, z5 = chickwts), z3 = list(z5 = 1))\n)\n\nHere’s the output we get from a simple str() call:\n\nstr(nested_list)\n\nList of 3\n $ x:List of 2\n  ..$ x1: int [1:3] 1 2 3\n  ..$ x2:List of 2\n  .. ..$ x3: int [1:3] 4 5 6\n  .. ..$ x4: int [1:3] 7 8 9\n $ y:List of 1\n  ..$ y1:List of 1\n  .. ..$ y2:List of 1\n  .. .. ..$ y3:'data.frame':    32 obs. of  11 variables:\n  .. .. .. ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n  .. .. .. ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n  .. .. .. ..$ disp: num [1:32] 160 160 108 258 360 ...\n  .. .. .. ..$ hp  : num [1:32] 110 110 93 110 175 105 245 62 95 123 ...\n  .. .. .. ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n  .. .. .. ..$ wt  : num [1:32] 2.62 2.88 2.32 3.21 3.44 ...\n  .. .. .. ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ...\n  .. .. .. ..$ vs  : num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n  .. .. .. ..$ am  : num [1:32] 1 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ...\n  .. .. .. ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ...\n $ z:List of 3\n  ..$ z1:Classes 'nfnGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame': 84 obs. of  5 variables:\n  .. ..$ Plant    : Ord.factor w/ 12 levels \"Qn1\"&lt;\"Qn2\"&lt;\"Qn3\"&lt;..: 1 1 1 1 1 1 1 2 2 2 ...\n  .. ..$ Type     : Factor w/ 2 levels \"Quebec\",\"Mississippi\": 1 1 1 1 1 1 1 1 1 1 ...\n  .. ..$ Treatment: Factor w/ 2 levels \"nonchilled\",\"chilled\": 1 1 1 1 1 1 1 1 1 1 ...\n  .. ..$ conc     : num [1:84] 95 175 250 350 500 675 1000 95 175 250 ...\n  .. ..$ uptake   : num [1:84] 16 30.4 34.8 37.2 35.3 39.2 39.7 13.6 27.3 37.1 ...\n  .. ..- attr(*, \"formula\")=Class 'formula'  language uptake ~ conc | Plant\n  .. .. .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n  .. ..- attr(*, \"outer\")=Class 'formula'  language ~Treatment * Type\n  .. .. .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n  .. ..- attr(*, \"labels\")=List of 2\n  .. .. ..$ x: chr \"Ambient carbon dioxide concentration\"\n  .. .. ..$ y: chr \"CO2 uptake rate\"\n  .. ..- attr(*, \"units\")=List of 2\n  .. .. ..$ x: chr \"(uL/L)\"\n  .. .. ..$ y: chr \"(umol/m^2 s)\"\n  ..$ z2:List of 2\n  .. ..$ z4: num 100\n  .. ..$ z5:'data.frame':   71 obs. of  2 variables:\n  .. .. ..$ weight: num [1:71] 179 160 136 227 217 168 108 124 143 140 ...\n  .. .. ..$ feed  : Factor w/ 6 levels \"casein\",\"horsebean\",..: 2 2 2 2 2 2 2 2 2 2 ...\n  ..$ z3:List of 1\n  .. ..$ z5: num 1\n\n\nOof, that’s a little bit too much information to flood my console with.\nLuckily you can use the max.level argument to restrict the depth to which the list is printed. Here’s the top layer only, which has a depth of 1:\n\nstr(nested_list, max.level = 1)\n\nList of 3\n $ x:List of 2\n $ y:List of 1\n $ z:List of 3\n\n\nNow I have a very high-level overview: this is list with three list objects with lengths 2, 1 and 3.\nLet’s go deeper.\n\nstr(nested_list, max.level = 2)\n\nList of 3\n $ x:List of 2\n  ..$ x1: int [1:3] 1 2 3\n  ..$ x2:List of 2\n $ y:List of 1\n  ..$ y1:List of 1\n $ z:List of 3\n  ..$ z1:Classes 'nfnGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame': 84 obs. of  5 variables:\n  .. ..- attr(*, \"formula\")=Class 'formula'  language uptake ~ conc | Plant\n  .. .. .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n  .. ..- attr(*, \"outer\")=Class 'formula'  language ~Treatment * Type\n  .. .. .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n  .. ..- attr(*, \"labels\")=List of 2\n  .. ..- attr(*, \"units\")=List of 2\n  ..$ z2:List of 2\n  ..$ z3:List of 1\n\n\nNow we’ve unpacked the next layer of the onion and can see that the contained objects are made up of vectors and more yet more lists.\nFor me, this is a nice way to get the sense of structure without seeing the entire content. I think it beats the interactive list View() in RStudio as well, which can’t be opened to an arbitrary depth in one go.\n\n\nCarriage feed\nprint() is a ubiquitous function across most programming languages. In R, you might just type an object’s name to show it. Here’s a tibble with 21 rows to demonstrate.\n\nchick_tbl &lt;- tibble::as_tibble(ChickWeight[1:21, ])\nchick_tbl\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n# ℹ 11 more rows\n\n\nYou might use head() on a data.frame to prevent printing the whole thing, which defaults to showing 6 rows. Tibbles are truncated by default to 10, but a nice feature is that they’ll show a few more if there’s slightly more than 10 rows total. But what if you want more control?\nWell, in both print() and head() is the n argument. No surprise: it lets you select how many rows of your data.frame or tibble get shown in the console.\nI particularly like this when I have a tibble I’d like to inspect the entirety of, but it gets truncated by default. I’ll often find myself doing this:\n\nprint(chick_tbl, n = Inf)\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n11    199    20 1     1    \n12    205    21 1     1    \n13     40     0 2     1    \n14     49     2 2     1    \n15     58     4 2     1    \n16     72     6 2     1    \n17     84     8 2     1    \n18    103    10 2     1    \n19    122    12 2     1    \n20    138    14 2     1    \n21    162    16 2     1    \n\n\nYou can set an option() to see more tibble rows by default, but I’m usually okay with its normal truncating behaviour.\n\n\nLibrary check out\nlibrary() calls are a staple of R scripts. Let’s say I’m attaching the {lme4} package becuase I want to use the famous cake dataset1.\n\nlibrary(lme4, quietly = TRUE)\n\nAha, no, it’s not the quietly argument I want to talk about2, though it is handy for stopping messages from being printed.\nOf course, what library() does is let you access objects, like functions and datasets, from a named package. How many objects did we attach from {lme4}?\n\nlength(ls(\"package:lme4\"))\n\n[1] 102\n\n\nBlimey, all we wanted was cake. But actually, we can be more selective with library() using the include.only argument.\n\ndetach(\"package:lme4\")\nlibrary(lme4, include.only = \"cake\")\nls(\"package:lme4\")\n\n[1] \"cake\"\n\n\nConversely, you can exclude as well.\nWhy would you want to do this? This can keep your environment tidy—if that’s something you care about—but also helps prevent conflicts between objects that might already exist in your environment.\nIt also means you’ve been explicit about the origin of any objects used in your script. If I see cake referenced in your script but can’t see how it was derived, I can take a look at that library call to see that you imported it from {lme4}.\nAt worst, this might be a nice thing for Python users, who love to from x import y.\n\n\nScore a drop goal\nThe square bracket, `[`, is a function3 for extracting elements out of objects, like rows and columns of a data.frame.\nSo the following will give you the first three rows of the cake data.frame for the columns temp and angle.\n\ncake[1:3, c(\"temp\", \"angle\")]\n\n  temp angle\n1  175    42\n2  185    46\n3  195    47\n\n\nSo what happens when you select a single column? You get one column back, right?\n\ncake[1:3, \"temp\"]\n\n[1] 175 185 195\n\n\nHa, lol, no. You get a vector. This might be a problem if you’re programmatically passing column names into `[` and you’re always expecting a data.frame as output.\nLuckily, you can guard against this by ensuring the returned doesn’t drop to its simplest dimension.\n\ncake[1:3, \"angle\", drop = FALSE]\n\n  angle\n1    42\n2    46\n3    47\n\n\nA third argument inside the square brackets may look spooky to people who expect only to pass indices for i (rows) and j (columns), but it’s allowed!4"
  },
  {
    "objectID": "posts/2024-02-02-base-args/index.html#coming-to-an-agreement",
    "href": "posts/2024-02-02-base-args/index.html#coming-to-an-agreement",
    "title": "Start an argument with R",
    "section": "Coming to an agreement",
    "text": "Coming to an agreement\nThese were unlikely to have blown your mind, especially if you’re a seasoned user. But I’ve live-coded with some folks who hadn’t seen them before.\nAt worst I hope you come away with a distinct sense ‘yeah, sure, I guess’.\nLet me know if you want to argue your case for some other underappreciated arguments."
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#tldr",
    "href": "posts/2024-02-03-base-args/index.html#tldr",
    "title": "Start an argument with R",
    "section": "tl;dr",
    "text": "tl;dr\nSome (lesser-known?) arguments to some common base-R functions."
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#getting-argumentative",
    "href": "posts/2024-02-03-base-args/index.html#getting-argumentative",
    "title": "Start an argument with R",
    "section": "Getting argumentative",
    "text": "Getting argumentative\nThere’s been a recent glut of posts about useful base-R functions, like the ones by Maëlle, Isabella and Yihui.\nI bring you a twist on the theme. Four useful arguments from four everyday base functions:\n\nmax.level in str()\nn in print()\ninclude.only in library()\ndrop in `[`\n\nFeel free to move on if you know all of these.\n\nStructural integrity\nstr() prints an object’s structure. It can be especially helpful for viewing lists in a compact hierarchical fashion. Consider this nested list:\n\nnested_list &lt;- list(\n  x = list(x1 = 1:3, x2 = list(x3 = 4:6, x4 = 7:9)),\n  y = list(y1 = list(y2 = list(y3 = mtcars))),\n  z = list(z1 = beaver1, z2 = list(z4 = 100, z5 = chickwts), z3 = list(z5 = 1))\n)\n\nHere’s the output we get from a simple str() call:\n\nstr(nested_list)\n\nList of 3\n $ x:List of 2\n  ..$ x1: int [1:3] 1 2 3\n  ..$ x2:List of 2\n  .. ..$ x3: int [1:3] 4 5 6\n  .. ..$ x4: int [1:3] 7 8 9\n $ y:List of 1\n  ..$ y1:List of 1\n  .. ..$ y2:List of 1\n  .. .. ..$ y3:'data.frame':    32 obs. of  11 variables:\n  .. .. .. ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n  .. .. .. ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n  .. .. .. ..$ disp: num [1:32] 160 160 108 258 360 ...\n  .. .. .. ..$ hp  : num [1:32] 110 110 93 110 175 105 245 62 95 123 ...\n  .. .. .. ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n  .. .. .. ..$ wt  : num [1:32] 2.62 2.88 2.32 3.21 3.44 ...\n  .. .. .. ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ...\n  .. .. .. ..$ vs  : num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n  .. .. .. ..$ am  : num [1:32] 1 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ...\n  .. .. .. ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ...\n $ z:List of 3\n  ..$ z1:'data.frame':  114 obs. of  4 variables:\n  .. ..$ day  : num [1:114] 346 346 346 346 346 346 346 346 346 346 ...\n  .. ..$ time : num [1:114] 840 850 900 910 920 930 940 950 1000 1010 ...\n  .. ..$ temp : num [1:114] 36.3 36.3 36.4 36.4 36.5 ...\n  .. ..$ activ: num [1:114] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ z2:List of 2\n  .. ..$ z4: num 100\n  .. ..$ z5:'data.frame':   71 obs. of  2 variables:\n  .. .. ..$ weight: num [1:71] 179 160 136 227 217 168 108 124 143 140 ...\n  .. .. ..$ feed  : Factor w/ 6 levels \"casein\",\"horsebean\",..: 2 2 2 2 2 2 2 2 2 2 ...\n  ..$ z3:List of 1\n  .. ..$ z5: num 1\n\n\nOof, that’s a little bit too much information to flood my console with.\nLuckily we can use the max.level argument to restrict the depth to which the list is printed. Here’s the top level only, which has a depth of 1:\n\nstr(nested_list, max.level = 1)\n\nList of 3\n $ x:List of 2\n $ y:List of 1\n $ z:List of 3\n\n\nNow we have a very high-level overview: the object is a list containing three sub-lists of particular lengths.\nLet’s go deeper.\n\nstr(nested_list, max.level = 2)\n\nList of 3\n $ x:List of 2\n  ..$ x1: int [1:3] 1 2 3\n  ..$ x2:List of 2\n $ y:List of 1\n  ..$ y1:List of 1\n $ z:List of 3\n  ..$ z1:'data.frame':  114 obs. of  4 variables:\n  ..$ z2:List of 2\n  ..$ z3:List of 1\n\n\nNow we’ve unpeeled the next layer of the onion and can see that the sub-lists are made up of a vector, a data.frame and yet more lists.\nFor me, this is a nice way to get a sense of structure without seeing the entire content. I also think it beats the interactive list View() in RStudio as well, which can’t be opened to an arbitrary depth in one go1.\n\n\nCarriage feed\nprint() is a ubiquitous function across most programming languages. In R, you might just type an object’s name to show it. Here’s a tibble with 21 rows to demonstrate.\n\nchick_tbl &lt;- tibble::as_tibble(ChickWeight[1:21, ])\nchick_tbl\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n# ℹ 11 more rows\n\n\nYou might use head() on a data.frame to prevent printing the whole thing, which defaults to showing 6 rows. Tibbles are truncated by default to 10, but a nice feature is that they’ll show a few more if there’s slightly more than 10 rows total. But what if you want more control?\nWell, in both print() and head() is the n argument. No surprise: it lets you select n number of data.frame or tibble rows to show in the console.\nI particularly like this for inspecting the entirety of a small tibble that’s been truncated by default. I’ll sometimes find myself doing this:\n\nprint(chick_tbl, n = Inf)\n\n# A tibble: 21 × 4\n   weight  Time Chick Diet \n    &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;fct&gt;\n 1     42     0 1     1    \n 2     51     2 1     1    \n 3     59     4 1     1    \n 4     64     6 1     1    \n 5     76     8 1     1    \n 6     93    10 1     1    \n 7    106    12 1     1    \n 8    125    14 1     1    \n 9    149    16 1     1    \n10    171    18 1     1    \n11    199    20 1     1    \n12    205    21 1     1    \n13     40     0 2     1    \n14     49     2 2     1    \n15     58     4 2     1    \n16     72     6 2     1    \n17     84     8 2     1    \n18    103    10 2     1    \n19    122    12 2     1    \n20    138    14 2     1    \n21    162    16 2     1    \n\n\nYou can set an option() to see more tibble rows by default, but I’m usually okay with its normal truncating behaviour. Using n is a convenience when I need it.\n\n\nLibrary check out\nlibrary() calls are a staple of R scripts. Let’s say I’m attaching the {lme4} package because I want to use the famous cake data set (thanks Rasmus2).\n\nlibrary(lme4, quietly = TRUE)\n\nAha, no, it’s not the quietly argument I want to talk about3, though it is handy for stopping messages from being printed.\nOf course, what library() does is let you access objects—like functions and data sets—from a named package. How many objects did we attach from {lme4}?\n\nlength(ls(\"package:lme4\"))\n\n[1] 102\n\n\nBlimey, all we wanted was cake. But actually, we can be more selective with library() using the include.only argument (note that you can exclude as well).\n\ndetach(\"package:lme4\")\nlibrary(lme4, include.only = \"cake\")\nls(\"package:lme4\")\n\n[1] \"cake\"\n\n\nWhy would you want to do this? This can keep your environment tidy—if that’s something you care about—but also helps prevent conflicts between objects that have the same name. For example, {dplyr}’s filter() function masks stats::filter().\nThis is also more explicit. People reading your script can see all the functions you’ve pulled in from each package by looking at your library() calls 4. If I see cake referenced in your script but can’t see how it was derived, I can look at the library() call to see that you imported it from {lme4}.\nAt worst, this might be a nice thing for Python users, who love to from x import y.\n\n\nScore a drop goal\nThe square bracket, `[`, is a function5 for extracting elements out of objects, like rows and columns of a data.frame. Of course, it’s typically used as a pair of square brackets.\nSo the following will give you the first three rows of the cake data.frame for the columns temp and angle.\n\ncake[1:3, c(\"temp\", \"angle\")]\n\n  temp angle\n1  175    42\n2  185    46\n3  195    47\n\n\nWhat happens when you select a single column? You get one column back, right?\n\ncake[1:3, \"temp\"]\n\n[1] 175 185 195\n\n\nHa, lol, no. You get a vector. This might be a problem if you’re passing column names into `[` programmatically and you’re always expecting a data.frame as output.\nLuckily, you can guard against this by ensuring the returned doesn’t drop to its simplest dimension.\n\ncake[1:3, \"angle\", drop = FALSE]\n\n  angle\n1    42\n2    46\n3    47\n\n\nI can see how a third argument inside the square brackets may look spooky if you thought you could only pass two when working on a data.frame6."
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#coming-to-an-agreement",
    "href": "posts/2024-02-03-base-args/index.html#coming-to-an-agreement",
    "title": "Start an argument with R",
    "section": "Coming to an agreement",
    "text": "Coming to an agreement\nThese were unlikely to have blown your mind, especially if you’re a seasoned user. But I’ve live-coded recently with some folks who hadn’t seen them before.\nAt worst I hope you come away with a distinct sense ‘yeah, sure, I guess’.\nLet me know if you want to argue your case for some other underappreciated arguments."
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#environment",
    "href": "posts/2024-02-03-base-args/index.html#environment",
    "title": "Start an argument with R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2024-02-03 21:25:20 GMT\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lme4_1.1-35.1 Matrix_1.6-0 \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       nlme_3.1-162      cli_3.6.2         knitr_1.45       \n [5] rlang_1.1.3       xfun_0.41         minqa_1.2.6       jsonlite_1.8.7   \n [9] glue_1.7.0        htmltools_0.5.6.1 fansi_1.0.6       rmarkdown_2.25   \n[13] grid_4.3.1        evaluate_0.23     tibble_3.2.1      MASS_7.3-60      \n[17] fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4   compiler_4.3.1   \n[21] Rcpp_1.0.11       htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.15.0\n[25] lattice_0.21-8    digest_0.6.33     nloptr_2.0.3      utf8_1.2.4       \n[29] pillar_1.9.0      splines_4.3.1     magrittr_2.0.3    tools_4.3.1      \n[33] boot_1.3-28.1"
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#footnotes",
    "href": "posts/2024-02-03-base-args/index.html#footnotes",
    "title": "Start an argument with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI generally prefer to use the console for inspecting objects, rather than an IDE. I usually have the RStudio environment pane minimised.↩︎\nRasmus recently did some sleuthing to discover the source of this data set! A great read.↩︎\nNote that package startup messages can also be controlled en masse by wrapping library calls in suppressPackageStartupMessages(), which I’ve talked about before. And also written about the sheer length of this function name.↩︎\nI’m fully aware that you can namespace objects in your scripts, like lme4::cake. That can reduce readability if every object is called in this way, though I do this myself when writing packages, for example.↩︎\nRecall that `[` is actually a function so you can write `[`(mtcars, 1:3, c(\"cyl\", \"hp\")) to achieve the same things as mtcars[1:3, c(\"cyl\", \"hp\")].↩︎\nOf course, three arguments to `[` is bread and butter for {data.table} users!↩︎"
  },
  {
    "objectID": "posts/2024-02-03-base-args/index.html#mutual-agreement",
    "href": "posts/2024-02-03-base-args/index.html#mutual-agreement",
    "title": "Start an argument with R",
    "section": "Mutual agreement",
    "text": "Mutual agreement\nThese were unlikely to have blown your mind, especially if you’re a seasoned user. But I’ve live-coded recently with some folks who hadn’t seen them before. Maybe you haven’t either.\nLet me know if you want to argue your case for some other under-appreciated arguments."
  }
]