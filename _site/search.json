[
  {
    "objectID": "about.html#tldr",
    "href": "about.html#tldr",
    "title": "About",
    "section": "tl;dr",
    "text": "tl;dr\nFun and learning with R, usually off-piste. It’s a bonus if you find any of it useful and/or amusing. All views belong to us.\nCheck out R Weekly for more R content."
  },
  {
    "objectID": "about.html#creators",
    "href": "about.html#creators",
    "title": "About",
    "section": "Creators",
    "text": "Creators\n\nMatt Dray\nPersonal site | Github | Twitter | Mastodon\nI use R professionally for analysis and reproducibility, and as an amateur for memes and ironic trolling. I make R do odd things, often with the aid of important pop-culture references like Pokémon and Dawson’s Creek.\n\n\nAdriana De Palma\nTwitter | academia.edu | Google Scholar | NHM\nI’m a Postdoctoral Researcher at the Natural History Museum, London. I have a PhD in Ecology and an MRes in Entomology from Imperial College London, and a BSc in Biology from the University of Sussex.\nIn terms of my research, I am particularly interested in using large scale ecological datasets to answer policy relevant questions. I work on the PREDICTS project with Andy Purvis, looking at how biodiversity responds over time to land-use change and related pressures. My more general interests lie with science policy, statistics and weird and wonderful invertebrates (my favourite being Collembola – the beautiful springtails)."
  },
  {
    "objectID": "about.html#meta",
    "href": "about.html#meta",
    "title": "About",
    "section": "Meta",
    "text": "Meta\n\nFind the source on GitHub\nMade with Quarto\nDeployed with Netlify\nVisitors counted using GoatCounter by Martin Tournoij"
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html",
    "href": "posts/2023-02-28-getparsedata/index.html",
    "title": "I can’t be parsed, mate",
    "section": "",
    "text": "Image by Keith Johnston from Pixabay. Deep fried by Matt Dray.1"
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#tldr",
    "href": "posts/2023-02-28-getparsedata/index.html#tldr",
    "title": "I can’t be parsed, mate",
    "section": "tl;dr",
    "text": "tl;dr\nR is capable of reading R code. Obviously. You can use getParseData(parse()) to see what’s going on. A very naive intro."
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#at-an-imparse",
    "href": "posts/2023-02-28-getparsedata/index.html#at-an-imparse",
    "title": "I can’t be parsed, mate",
    "section": "At an imparse",
    "text": "At an imparse\nThere’s many things that delight me about R coding.2 One meta thing I like is the idea that R has to recognise the code that you give it as… R code.\nFor example, does x&lt;-1 mean ‘x is less than minus-one’? Hm, actually R recognises &lt;- as a ‘left-assignment operator’—a special ‘token’—that gives the name x the value of 1. Subtle, but important.\nAnother example: the tokens &lt;- and = have an equivalent role in x &lt;- 1 and x = 1. For style reasons, you’ll probably want to replace = with &lt;-.3 But don’t just ‘find and replace’ because = is context dependent. Consider:\n\nx = subset(mtcars, subset = carb == 8)\n\nHere, = is used to assign (=), to set a function argument (=) and as part of the equivalence operator (==). Oof.\nHow can a mere human understand this better?"
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#parsed-tense",
    "href": "posts/2023-02-28-getparsedata/index.html#parsed-tense",
    "title": "I can’t be parsed, mate",
    "section": "Parsed tense",
    "text": "Parsed tense\nThe cool (‘cool’) thing is that R gives you tools to be able to see the world as R sees it.\nThis is sometimes called ‘static code analysis’, in that you can interrogate the code for syntax errors before it executes. Packages like {lintr} can even help tidy up (‘lint’) your code by adjusting or replacing the tokens.4\nI’ve used this approach before to:\n\ncreate the {r2eng} package, which matches tokens against words so an expression can be translated to English (e.g. &lt;- is matched to the word ‘gets’)\nwrite an RStudio addin that auto-labels closing parentheses with the name of the function they belong to (known cutely as a ‘biscuit’)\nidentify and destroy files that contain equals assignment (x = 1), rather than the superior assignment arrow (x &lt;- 1)\n\nHow might you tinker about with this yourself? Read on for a quickstart."
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#parse-the-parcel",
    "href": "posts/2023-02-28-getparsedata/index.html#parse-the-parcel",
    "title": "I can’t be parsed, mate",
    "section": "Parse the parcel",
    "text": "Parse the parcel\nI’ll talk about two main functions: parse() and getParseData(), which are both part of base R.\nYou can pass a string of R code to parse() for it to be recognised as an ‘expression’. Let’s use the equals-rich subset() example from above.\n\ncode_str &lt;- \"x = subset(mtcars, subset = carb == 8)\"\ncode_expr &lt;- parse(text = code_str)\ncode_expr\n\nexpression(x = subset(mtcars, subset = carb == 8))\n\nclass(code_expr)\n\n[1] \"expression\"\n\n\nSo the string is recognised as R code at this point, which will allow us to break it down into its individual tokens. You could jump ahead here and just eval()uate this expression object.\n\neval(code_expr)\nx\n\n              mpg cyl disp  hp drat   wt qsec vs am gear carb\nMaserati Bora  15   8  301 335 3.54 3.57 14.6  0  1    5    8\n\n\nAs a result, the dataframe x is now in our environment and, as expected, contains only rows of the mtcars that have 8 carburetors.5\nSo we have the power to delay code execution, like some kind of wizard. Jeepers! That’s great, but now lets pick apart the frozen expression into its constituent tokens. This is where getParseData() comes in.\nThe function takes an expression object as the input and returns a dataframe with one token per row and several columns of handy information related to positioning and the relatedness between the tokens.\nFor now I’m going to simplify the output to show only the units of text that have been recognised as tokens, along with the name that R gives to each token under the hood (e.g. &lt;- is recognised as LEFT_ASSIGN).6\n\ncode_parsed &lt;- getParseData(parse(text = code_str, keep.source = TRUE))\ncode_parsed[code_parsed$text != \"\", c(\"text\", \"token\")]\n\n     text                token\n1       x               SYMBOL\n2       =            EQ_ASSIGN\n5  subset SYMBOL_FUNCTION_CALL\n6       (                  '('\n8  mtcars               SYMBOL\n9       ,                  ','\n14 subset           SYMBOL_SUB\n15      =               EQ_SUB\n16   carb               SYMBOL\n17     ==                   EQ\n19      8            NUM_CONST\n21      )                  ')'\n\n\nOh neato, so you can see = is indeed recognised as the token EQ_ASSIGN (‘equals assign’), = as EQ_SUB (equals in the context of supplying function arguments) and == as in EQ (the equivalence operator).\nIf you’re wondering, the keep.source = TRUE bit was needed to encourage parse() to return its output, which is a necessary step within this non-interactive blog post."
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#parseltongue",
    "href": "posts/2023-02-28-getparsedata/index.html#parseltongue",
    "title": "I can’t be parsed, mate",
    "section": "Parseltongue",
    "text": "Parseltongue\nWant to take a look at the tokens in a given string of R code yourself? You can use this little function that contains parse() and getParseData() and returns you the simplified dataframe I showed above if simplify = TRUE, otherwise it gives the full read out.7\n\nparse_out &lt;- function(string, simplify = TRUE) {\n  p &lt;- parse(text = string, keep.source = TRUE)\n  pd &lt;- getParseData(p)\n  if (simplify) {\n    keep_cols &lt;- c(\"token\", \"text\")\n    pd &lt;- pd[pd$text != \"\", keep_cols]\n  }\n  pd\n}\n\nSo you could use it like:\n\nparse_out(\n  \"mean(CO2[CO2$Plant == 'Qn1', CO2$uptake]) -&gt; mean_uptake\"\n)\n\n                  token        text\n1  SYMBOL_FUNCTION_CALL        mean\n2                   '('           (\n4                SYMBOL         CO2\n5                   '['           [\n7                SYMBOL         CO2\n8                   '$'           $\n10               SYMBOL       Plant\n12                   EQ          ==\n13            STR_CONST       'Qn1'\n14                  ','           ,\n20               SYMBOL         CO2\n21                  '$'           $\n23               SYMBOL      uptake\n25                  ']'           ]\n30                  ')'           )\n35         RIGHT_ASSIGN          -&gt;\n36               SYMBOL mean_uptake\n\n\n\nℹ️ Update\nSince I wrote this post, it’s become possible to include editable R blocks in a rendered Quarto document, which can be run in the browser thanks to WebR(!). I’ve made a quick demo and post so you can play around with a simplified version of the parsing function above."
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#lateral-parse",
    "href": "posts/2023-02-28-getparsedata/index.html#lateral-parse",
    "title": "I can’t be parsed, mate",
    "section": "Lateral parse",
    "text": "Lateral parse\nI’ll leave you with another interesting thing that shows you the inner workings of R, which you might not realise as you run your code. We can look at how the code is actually executed, not just the tokens that it’s composed of.\nConsider how the {magrittr} pipe %&gt;% is used. Here I’ve slightly adjusted the input to filter for 6 and 8 carburetors; you’ll see why in a second.\n\nparse_out(\"mtcars %&gt;% subset(carb %in% c(6, 8))\")\n\n                  token   text\n1                SYMBOL mtcars\n2               SPECIAL    %&gt;%\n4  SYMBOL_FUNCTION_CALL subset\n5                   '('      (\n7                SYMBOL   carb\n8               SPECIAL   %in%\n10 SYMBOL_FUNCTION_CALL      c\n11                  '('      (\n13            NUM_CONST      6\n15                  ','      ,\n19            NUM_CONST      8\n21                  ')'      )\n26                  ')'      )\n\n\nOkay yeah, %&gt;% is recognised as a token called SPECIAL between the left-hand side of mtcars and the right-hand side of subset(carb %in% c(6, 8)). Notice also that %in% is also recognised as SPECIAL.\nIn fact, this is how R recognises ‘infix operators’ that are bound by percent symbols. This is some special syntactical magic that lets you put the function name between two arguments. So x %&gt;% head is equivalent to `%&gt;%`(mtcars, head). Perhaps SPECIAL instead of a more specific name because infix operators can be created on the fly?\nIf %&gt;% is SPECIAL, how do you think the base pipe is recognised in this simpler example?\n\nparse_out(\"mtcars |&gt; head()\")\n\n                 token   text\n1               SYMBOL mtcars\n2                 PIPE     |&gt;\n4 SYMBOL_FUNCTION_CALL   head\n5                  '('      (\n7                  ')'      )\n\n\nNot that surprising: it’s recognised as PIPE and not a SPECIAL, since it’s a proper base R token in its own right (as of R v4.1) .\nOkay, so we’ve seen how R parses these tokens, what about how it actually executes the code? One way to see this is to look at an ‘abstract syntax tree’ with the {lobstr} package.8 A ‘tree’ to show the nested structure of code and variables and so on.\n\nlibrary(lobstr)    # install from CRAN\nlibrary(magrittr)  # install from CRAN\nast(mtcars %&gt;% head())\n\n█─`%&gt;%` \n├─mtcars \n└─█─head \n\n\nYeah, like I said: x %&gt;% head() is ultimately executed by R like a normal function (block symbol in the output from ast() above), in the form `%&gt;%`(mtcars, head). You can see how the `%&gt;%` is a parent to mtcars and head() below it.\nSo the same happens for the base pipe, right?\n\nast(mtcars |&gt; head())\n\n█─head \n└─mtcars \n\n\nSurprise! mtcars |&gt; head is not executed like `|&gt;`(mtcars, head). It’s literally executed like head(mtcars). The base pipe is so special because it’s baked right into the R source code as a separate type of token that is recognised to have a job distinct from a basic SPECIAL. This should make it a little faster to run compared to %&gt;% as well."
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#parse-away",
    "href": "posts/2023-02-28-getparsedata/index.html#parse-away",
    "title": "I can’t be parsed, mate",
    "section": "Parse away",
    "text": "Parse away\nWell, ‘cool’ I guess. Now it’s up to you: you can either parse on this knowledge, or leave it in the parsed.9"
  },
  {
    "objectID": "posts/2023-02-28-getparsedata/index.html#environment",
    "href": "posts/2023-02-28-getparsedata/index.html#environment",
    "title": "I can’t be parsed, mate",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:17:50 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 lobstr_1.1.2  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         knitr_1.43.1     \n [5] htmltools_0.5.5   rmarkdown_2.22    cli_3.6.1         compiler_4.3.1   \n [9] rstudioapi_0.14   tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[13] rlang_1.1.1       jsonlite_1.8.5    crayon_1.5.2      htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "href": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "title": "Convert a Word table to Markdown",
    "section": "tl;dr",
    "text": "tl;dr\nI made a function that shouldn’t need to exist in an ideal world: it takes a copied Microsoft Word table and outputs a Markdown version (well, a Govspeak version)."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "href": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "title": "Convert a Word table to Markdown",
    "section": "Govspeak when you’re spoken to",
    "text": "Govspeak when you’re spoken to\nI’ve written about three painful things recently:\n\nForcing data scientists to expose their tools so we can all use and learn from them.\n‘Rectangularising’ tables scraped out of a Word document via the {officer} package.\nEasier ways to coerce dataframe columns to their ‘intended’ data type.\n\nToday I bring you a terrible Cerberus with these three heads1.\nThe challenge: sometimes public sector statisticians produce Word documents that need to be converted to a special type of simplified plaintext Markdown, called Govspeak, before they can be uploaded for publication as HTML files on GOV.UK2.\nThis is fine: we have specific publishing specialists who can take care of it. It can be a little tedious, however. What if we could speed up and make more efficient the process of converting from Word to Govspeak?\nThere’s a specific Govspeak converter online that you can paste into. But it doesn’t have full coverage of the things that might appear in a Word doc, including tables. Other online converters exist, but I don’t think we should rely on third parties that are probably intended for producing general Markdown rather than Govspeak, specifically"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "href": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "title": "Convert a Word table to Markdown",
    "section": "Markdown? Word up.",
    "text": "Markdown? Word up.\nI’ve started an R package called {wordup} that aims to take a Word document and convert it to Govspeak. It’s early days in the sense that it doesn’t yet do, well… very much. But I thought the package name was funny (if unoriginal) and worth squatting. Maybe I’ll never get around to developing it, who knows.\nTo install (which is really not worth it right now, unless you want to raise an issue or pull request):\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/wordup\")\nlibrary(wordup)\n\nFor now, the principle is that you can unzip a Word document to expose a bunch of xml files (yet another thing I’ve been writing about recently, lol) that contain all the information needed to build the Word document3. As such, you can read that xml and extract all the information, styles, etc, and massage it programmatically into Govspeak format.\nPart of the process will involve taking a Word table, specifically, and converting it to a Govspeak-friendly form. I figured this might be a nice standalone tool in its itself, so I had a stab at what it could look like."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "href": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "title": "Convert a Word table to Markdown",
    "section": "Fantabulars",
    "text": "Fantabulars\nSo right now the wordup::table_to_govspeak() function (whose name could change at any time) does three things:\n\nHandles inputs.\nGuesses data types.\nApplies extra styles.\n\nYou can either (a) copy-paste a Word table into the function, or (b) simply copy it to the clipboard, where it can be read by the function using the {clipr} package. The function will take the string—which is basically tabs (\\t) to indicate gaps between cells and newlines (\\n) to indicate rows—and reorient it initially into a dataframe.\nOf course, all the columns will be character-class at this point. We can immediately run type.convert() over the whole dataframe to coerce each column to a more appropriate data type, if appropriate. So a character column composed of c(\"10\", \"20\", \"30) will become a numeric column of values c(10, 20, 30). But this doesn’t work for numeric values that have symbols in them, like commas as thousands separators (1,200), per cent symbols (82%) and placeholder markers to indicate things like suppressed values ([c])4. To get around this, we can strip the nuisance characters and then see if what remains looks like a number.\nFinally, there’s some specific features of Govspeak tables that need attention. It’s acceptable to have row labels, where each value in every cell of the first column should be prefaced with an octothorpe (#), and totals columns, where the entire row should be emboldened with double-asterisks (**) either side of the cells’ values.\nWhat results can be sort of… magic really. You copy a Word table in its entirety to your clipboard, run the function, and bang: the Govspeak Markdown is returned. You can see this in action in the gif at the top of this page.\nSo I can literally copy a table like this to my clipboard:\n\n\n\nColumn 1\nColumn 2\nColumn 3\nColumn 4\nColumn 5\n\n\n\n\nX\n100\n1,000\n1%\n15\n\n\nY\n200\n2,000\n2%\n12\n\n\nZ\n300\n3,000\n3%\n[c]\n\n\nTotals\n600\n6,000\n6%\n[c]\n\n\n\nAnd run this:\n\nwordup::table_to_govspeak()\n\nTo print this (and have it copied to your clipboard as the message says):\n\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| X | 100 | 1,000 | 1% | 15 |\n| Y | 200 | 2,000 | 2% | 12 |\n| Z | 300 | 3,000 | 3% | [c] |\n| Totals | 600 | 6,000 | 6% | [c] |\nThe output table has been written to the clipboard.\n\nBoom. Notice that the third, fourth and fifth columns are recognised as numeric and therefore right-aligned (------:). This is entirely due to the argument ignore_regex, which defaults to removing commas, percentage symbols or anything in square brackets before it guesses what data type the column is.\nAnd we can do fancy things like:\n\nwordup::table_to_govspeak(\n  has_row_titles = TRUE,\n  totals_rows = 4L\n)\n\nWhich outputs this thing:\n\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| # X | 100 | 1,000 | 1% | 15 |\n| # Y | 200 | 2,000 | 2% | 12 |\n| # Z | 300 | 3,000 | 3% | [c] |\n| # **Totals** | **600** | **6,000** | **6%** | **[c]** |\nThe output table has been written to the clipboard.\n\nOf course, in practice this might get a little more complicated if you need to manually specify in the function declaration that there’s a column of row titles or some totals rows. Pish-posh. The point is that I think this is probably better than trying to (a) write the Govspeak table by hand or (b) trying to use the Govspeak converter, which just doesn’t work for this task. This also has mild, opinionated, Govspeak-related benefits over using a straightforward knitr::kable().\nIs this perfect? Ahaha, no. There’s a lot to add or improve, but I think this is a decent start and solves a (niche) problem for now5."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#environment",
    "href": "posts/2023-06-21-wordup-tables/index.html#environment",
    "title": "Convert a Word table to Markdown",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 16:21:31 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] wordup_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "title": "Panic! In The Toolshed",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote some slides to tell data scientists in the public sector what they already know: share the tools you’ve developed."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "title": "Panic! In The Toolshed",
    "section": "An axe to grind",
    "text": "An axe to grind\nI’m speaking today at an event for UK government data scientists with a theme of ‘the data science toolshed’. My plea is small: I want public sector workers to share the tools they make1.\nWe should build modular things like R packages that are easy to use and develop; make them available to everyone to minimise duplication and encourage collaboration; and maximise reach by telling everyone about it. This is how we improve quality and build our community. And save money for the taxpayer.\nHandily, this is already expressed in the government’s Technology Code of Practice:\n\nShare, reuse and collaborate: avoid duplicating effort and unnecessary costs by collaborating across government and sharing and reusing technology, data, and services.\n\nI’ve had a small experience with this: I made the {a11ytables} R package to help producers of stats publications automate the creation of best-practice, accessible spreadsheets. It’s now being used in several organisations and is referenced from the government’s best-practice guidance.\nSuccess? Maybe. But also PANIK: I’ve left the organisation where I made it; I was the sole developer; I worry that I should have thought about this sooner; that I should fork and update it; that updating users will be hard; that links to the old package will break; and so on. Hopefully people will learn something from these missteps."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "title": "Panic! In The Toolshed",
    "section": "Burying the hatchet",
    "text": "Burying the hatchet\nThe slides are live on the internet and embedded below, or you can view the source on GitHub. Press s to pop out the speaker notes, o for a slide overview and f for fullscreen.\n\n\n\n\n\n\n\n\nThe slides were made with Revealjs via Quarto, because of course they were."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "title": "Panic! In The Toolshed",
    "section": "Clamp down",
    "text": "Clamp down\nSo, we should sustainabilise (not a word), centralise and advertise the useful things we make. Maybe we could have a list of tools we’ve produced collectively in the public sector? Something like an ‘Awesome’ list or a CRAN task view. Maybe that would make it easier to find and develop existing solutions instead of building from scratch all the time.\nBuild a toolshed. They will come?"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "title": "Panic! In The Toolshed",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 16:13:50 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.22      knitr_1.43.1        jsonlite_1.8.5     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "",
    "text": "new wr — r.oguelike any% tenkeyless noglitch"
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#tldr",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#tldr",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {r.oguelike} package—a toy roguelike microadventure for the R console—now has little sound effects thanks to {sonify}. Pew pew!"
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#the-adventure-continues",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#the-adventure-continues",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "The adventure continues?",
    "text": "The adventure continues?\nApparently this is part 5 of the {r.oguelike} devlog. You can read earlier posts about:\n\nits inception\ncreating simple procedural dungeons\nmaking an enemy chase the player\n3D dungeons and continuous keypress inputs\n\nAlas, this is also probably the last installment.\nYes, the dungeons have been dank (cool, edgy), but also dank (cool, damp, claustrophobic). Time to unspelunk myself.\nThere may be time for a {r.oguelike2} in future. I’d like to try a class-based approach to help limit code spaghetti and make it more extensible. Perhaps it will even have a proper game loop! Call me when you’re ready, Kojima.\nUntil then, one more little feature to tie things up. Beeeeeeep. BOOOOOOOP."
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#hi-sonifi",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#hi-sonifi",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Hi-Sonifi",
    "text": "Hi-Sonifi\nSo, yes: {r.oguelike} now has sound effects with quality as high as its graphics and gameplay. See all these in concert in the video embedded at the top of this page.\nI used the {sonify} package to create a few little beeps and toots that I think fit the game’s retro aesthetic.1 These are fired when the player moves and interacts with things in the dungeon.\nI’ve written about {sonify} before when I sonified data about COVID-19 infections and GitHub activity (incredible juxtaposition), which can offer a more interesting and accessible way of presenting data.\nYou can also demean {sonify} by making funny little honks and parps, which is what I’ve done for {r.oguelike}.\nHow did I arrive at the soundscape for {r.oguelike}? I did the bare minimum of fiddling around with the arguments in sonify::sonify() until the noises amused me."
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#demo-cassette",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#demo-cassette",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Demo cassette",
    "text": "Demo cassette\nSounds are played in the code of the package via functions after each triggering event. The user can prevent these sounds from playing with the logical has_sfx argument in the start_game() function.\nFor example, here’s the function for the simplest sound effect:\n\n.sfx_move &lt;- function(has_sfx) {\n  if (has_sfx) sonify::sonify(1, 1, duration = 0.001)\n}\n\nThe sonify() outputs are {tuneR} objects. I’ve saved these as wav files with tuneR::writeWav() so they can be embedded in this post.\n\n\nClick for illustrative code to create the wav files.\n\n\nlibrary(sonify)\nlibrary(tuneR)\nlibrary(purrr)\n\nsfx &lt;- list(\n  \n  move = sonify(1, 1, duration = 0.001),\n  \n  bump = sonify(1, 1, duration = 0.01, flim = c(100, 110)),\n  \n  gold = bind(\n    sonify(1, 1, duration = 0.05, flim = c(800, 800)),\n    sonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n  ),\n  \n  apple = sonify(0:1, c(0, 1), duration = 0.05),\n  \n  eat = sonify(0:1, c(1, 0), duration = 0.05),\n  \n  win = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n  ),\n  \n  lose = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))\n  )\n  \n)\n\nwalk2(\n  .x = sfx,\n  .y = names(sfx), \n  ~writeWave(.x, paste0(.y, \".wav\"))\n)\n\n\nIn reality, the sounds play a little slower in the game itself, but it was a bit fiddly to reproduce it for these clips. You’ll get the idea.\n\nMove\nStep onto unoccupied floor tile (.) and you’ll hear the very quick tap of your boot.\nClick to play the sound:\n\n\n\n\n\nAnd here’s the corresponding code to reproduce it:\n\nsonify(1, 1, duration = 0.001)\n\nBut bump into the dungeon wall (#) and you’ll get a dull thud, you absolute clod.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.01, flim = c(100, 110))\n\nYes, flim, as in: ‘this post is absolute flimflam’.\n\n\nFood\nWould you pick up an apple (a) you found on the floor of a cave? Here’s what it might sound like as it pops into your inventory.\n\n\n\n\n\n\nsonify(0:1, c(0, 1), duration = 0.05),\n\nMore importantly, would you eat an apple (a) you found on the floor of a cave? Here’s how it would sound as it rolls down your gullet.\n\n\n\n\n\n\nsonify(0:1, c(1, 0), duration = 0.05)\n\n\n\nGold\nCollecting gold ($) grants you a celebratory chirp of excitement. Although there’s not actually anything in the dungeon to spend it on, sorry.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.05, flim = c(800, 800))\nsonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n\n\n\nDefeat enemy\nA powerful victory ditty after you crush your enemies (E).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n\n\n\nLose\nConversely, a sad lament for being crushed by your enemies (E) or running out of turns (T).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))"
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#echo-echo-echo",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#echo-echo-echo",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Echo echo echo",
    "text": "Echo echo echo\nIf you want to try out {r.oguelike}, you can install it from GitHub:\n\ninstall.github(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/r.oguelike\")  # v0.1 currently\nr.oguelike::start_game()\n\nYou can also run {r.oguelike} in an RStudio instance in your browser (!), thanks to the Binder project.\nFree feel to highlight any bugs via the issues, or create a pull request that adds all the things that stop me from calling {r.oguelike} a proper ‘game’.2\n\nMost importantly, don’t forget to wishlist me on Steam and remember that pre-order bonuses will include an apple that’s been left on a dungeon floor for a few months."
  },
  {
    "objectID": "posts/2023-01-03-r.oguelike-sfx/index.html#environment",
    "href": "posts/2023-01-03-r.oguelike-sfx/index.html#environment",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:20:29 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "href": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "title": "R is a game engine, fight me",
    "section": "tl;dr",
    "text": "tl;dr\nR is ‘a free software environment for statistical computing and graphics’. Ahahaha, no it’s not, it’s a game engine. I’ve created a ‘splendid’ list of games you can play—written in R—to prove it. Help expand it."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "title": "R is a game engine, fight me",
    "section": "Stats only!",
    "text": "Stats only!\nR is not a general, multi-purpose programming language. It was written to do statistical analysis and make charts. You are literally not allowed to do anything else with it. You should use &lt;LANGUAGE&gt; instead, which is much more suited to your specific use case. R is a joke language for nerds.\nYou should not read beyond this point if you think, quite rightly, that mirth and frivolity are unsuited to an R session."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "title": "R is a game engine, fight me",
    "section": "Stats only?",
    "text": "Stats only?\nUnity. Unreal. GameMaker. Godot. All of these videogame engines are now obsolete.\nIt is R—humble R!—that represents the future of gaming.\nTo prove it, I’ve created a list of ‘splendid R games’ in a GitHub repo1 that you are welcome to contribute to.2\nYes, R can be used for fun. Do not tell R Core."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "href": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "title": "R is a game engine, fight me",
    "section": "Wait, he’s serious?",
    "text": "Wait, he’s serious?\nI think there’s three kinds of ‘platform’ for games written in R:\n\nFor the console\nIn Shiny\nPorted\n\nGames played in the console are pretty straightforward and probably most common. You can run some code, or a function from a package, to launch some code in the R console that you can interact with. A simple option for this might involve use of readline() to receive user input, for example, like Giora Simchoni’s excellent text-based puzzler, Castle of R.\n\n\n\nGiora’s Castle of R running in the terminal.\n\n\nShiny can give you a little more flexibility when it comes to graphics and user input, at the expense of needing to host the app and maybe some extra JavaScript skills. A great example of this is Pedro Silva’s winning entry (app, source) to the Posit Shiny contest in 2020.\n\n\n\nA still from Pedro’s Shiny Decisions app.\n\n\nThe third category is a little more boundary-pushing. Imagine if R was powerful enough to let you port existing games. Well, surprise, ya boi Mike Cheng (aka coolbutuseless) has pushed hard on expanding the capabilities of R to run fast enough and with realtime user input,3 porting the classic Another World (1991) to R, which was showcased at 2022’s Posit conference (source, video, blog).\n\n\n\nA still from Mike’s rstudio::conf(2022) presentation, featuring Another World.\n\n\nOf course, within these ‘platforms’ are genres like word games, arcade games, puzzle games, etc. Will you be the first to create an MMORPG (a massively-multiplayer online R-powered game)?"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "href": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "title": "R is a game engine, fight me",
    "section": "I am an indie game dev now",
    "text": "I am an indie game dev now\nI’ve always been interested in how videogames are coded,4 wishing that I could do the same myself. Of course I could simply learn ‘real’ programming languages.\nExcept that’s blasphemy. Of course I’d rather break my own mind and spirit in an attempt to make R achieve 0.1% of what might be possible in P*thon.\nCase in point, I’ve made a few R packages containing some little toys (in order of gooddest to baddest):\n\n{r.oguelike} (source, blogs) for a procedural-dungeon explorer with enemy pathfinding and inventory\n{tamRgo} (source, blog) for a cyber pet in your R console that persists between sessions\n{safar6} (source, blog) for a text-based re-make of the Safari Zone from the first generation of Pokémon games\n{ActionSquirrel} (source, blog) for a tile-based, turn-based minigame in the R console\n{hokey} (source, blog) for minigames that use direct keypress inputs with {keypress}\n\n\n\n\nHint when playing {tamRgo}: do not forget about your pet for 138 days. RIP Kevin XVIII.\n\n\nI’ve got something in the pipeline that involves extremely rudimentary physics in the R console. Wow! For release in 2023 (because game launches never go wrong)."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "href": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "title": "R is a game engine, fight me",
    "section": "Ready Player 2",
    "text": "Ready Player 2\nThe splendid list must be missing a bunch of games. Please leave an issue or pull request in the splendid-r-games repo to add more examples.\nNext stop: letting people run R games in the browser without an installed copy of R. This is already possible with a service like Binder, which can spin up an instance of RStudio with packages pre-installed I did this for {r.oguelike}).\n\n\n\nJust like the Nokia N-Gage, amirite?\n\n\nBut soon you might be able to use WebR to play games in the browser without even spinning up RStudio, ooh. So look out for an R version of itch.io in future, lol."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "href": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "title": "R is a game engine, fight me",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 16:44:52 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html",
    "href": "posts/2023-04-20-type-convert/index.html",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "",
    "text": "Confirmed: Unown is character type.1"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#tldr",
    "href": "posts/2023-04-20-type-convert/index.html#tldr",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "tl;dr",
    "text": "tl;dr\nI forgot that the base R function type.convert() exists. Handy for ‘simplifying’ all the columns of a dataframe to appropriate data types."
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#suppression-depression",
    "href": "posts/2023-04-20-type-convert/index.html#suppression-depression",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Suppression depression",
    "text": "Suppression depression\n{a11ytables} is an R package that lets you generate publishable spreadsheets that follow the UK government’s best practice guidance.\nOne requirement is to replace missing values with placeholder symbols. For example, suppressed data can be replaced with the string \"[c]\" (‘confidential’).\nOf course, R’s behaviour means it can store only one data type per column, so a numeric-type column will be automatically converted to character when you introduce at least one string value (i.e. something in \"quotes\").2\nFor example, this vector is type ‘double’ (i.e. decimals and not ‘whole-number’ integers) and has the more general ‘numeric’ class:\n\nnums &lt;- runif(100)\ntypeof(nums); class(nums)\n\n[1] \"double\"\n\n\n[1] \"numeric\"\n\n\nThe whole thing is converted to character type if you append just one character value.\n\ntypeof(c(nums, \"[c]\"))\n\n[1] \"character\"\n\n\nThis is known behaviour, yes, but it causes a minor annoyance in the xlsx files output from an {a11ytables} workflow: Excel puts a warning marker in the corner of any cell in a text column that contains a numeric value.3\n\n\n\nCat left a GitHub issue related to this: columns entirely made of numbers were being marked by Excel with the ‘number in a text column’ warning. In this case, it was because Cat’s suppression process resulted in all columns being converted to character.\nIt would be great to convert back to numeric any columns that did not receive a placeholder symbol during the wrangling process. How can you do this?"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#type-specimen",
    "href": "posts/2023-04-20-type-convert/index.html#type-specimen",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Type specimen",
    "text": "Type specimen\nLet’s consider a demo example. First I’ll attach {dplyr}, which is commonly used by stats producers in the UK government.\n\nsuppressPackageStartupMessages(library(dplyr))\n\nHere’s a very simple dataframe, tbl, to use as a demo. Column x contains values that will need to be suppressed because they’re lower than 5. There are no such values in column y.\n\nset.seed(1337)\n\ntbl &lt;- tibble(\n  id = LETTERS[1:5],\n  x  = round(runif(5, 0, 10), 2),\n  y  = round(runif(5, 6, 10), 2)\n)\n\ntbl\n\n# A tibble: 5 × 3\n  id        x     y\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      5.76  7.33\n2 B      5.65  9.79\n3 C      0.74  7.12\n4 D      4.54  6.98\n5 E      3.73  6.58\n\n\nSo, to borrow and simplify Cat’s approach: for each numeric column in tbl (i.e. x and y), replace any value of less than 5 with the placeholder string \"[c]\", otherwise retain the original value.\n\ntbl_supp &lt;- tbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) if_else(\n        condition = value &lt; 5, \n        true      = \"[c]\",\n        false     = as.character(value)\n      )\n    )\n  )\n\ntbl_supp\n\n# A tibble: 5 × 3\n  id    x     y    \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 A     5.76  7.33 \n2 B     5.65  9.79 \n3 C     [c]   7.12 \n4 D     [c]   6.98 \n5 E     [c]   6.58 \n\n\nSo column x now contains text values and has predictably been converted to character, which you can see as &lt;chr&gt; in the tibble header. But notice that y is also character type despite all the numeric values being retained.\nThis happened because the if_else() we used to create tbl_supp required the true and false arguments to resolve to the same type. The false argument must use as.character() because true resolves to the character value \"[c]\".\nIdeally we’d perform our suppression step but column x would end up as character and y as numeric. How can we achieve this?"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#adjust-my-type",
    "href": "posts/2023-04-20-type-convert/index.html#adjust-my-type",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Adjust my type",
    "text": "Adjust my type\nIn this section are some methods to fix the problem by:\n\nCausing yourself further brainache\nUsing a (relatively little known?) base R function\nDoing it ‘properly’ from the outset\n\n\nType 1: nah\nOf course, we could run tbl_supp |&gt; mutate(y = as.numeric(y)) to convert that specific column back to numeric. But imagine if you have a lot more columns and you can’t be sure which ones need to be converted.\nMaybe you could apply as.numeric() across all columns? Columns of numbers stored as text will then be converted entirely to numeric:\n\nas.numeric(c(\"1\", \"2\", \"3\"))\n\n[1] 1 2 3\n\n\nBut this causes a problem for character columns that contain text, like our placeholder symbol:\n\nas.numeric(c(\"1\", \"[c]\"))\n\nWarning: NAs introduced by coercion\n\n\n[1]  1 NA\n\n\nSo \"1\" becomes 1, but we’re warned that \"[c]\" has been converted to NA (well, NA_real_, which is the numeric form of NA).\nWe could do something convoluted, like see which columns didn’t gain NA values and should be retained as numeric. But that’s bonkers. This approach ultimately makes things worse because we’ve actually lost information!\nReally we want to check each column to see if it contains numbers only and then convert it to numeric. How?\n\n\nType 2: better\nThere’s a handy base R function that I had forgotten about: type.convert().\nIt takes a vector and, in turn, tries to coerce it to each data type. The process stops when coercion occurs without error. As the help file (?type.convert) puts it:\n\nGiven a vector, the function attempts to convert it to logical, integer, numeric or complex, and when additionally as.is = FALSE… converts a character vector to factor. The first type that can accept all the non-missing values is chosen.\n\nAnd handily:\n\nWhen the data object x is a data frame or list, the function is called recursively for each column or list element.\n\nSo we can pass our entire dataframe to type.convert() and it’ll check them all for us:\n\ntbl_supp_conv &lt;- type.convert(tbl_supp, as.is = TRUE)\n\ntbl_supp_conv\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nAs we wanted, our character column y has become numeric type (&lt;dbl&gt;) while x remains as character. Neato.\n\n\nType 3: betterer\nThere are probably better approaches to this problem from the outset, rather than after-the-fact application of type.convert().\nAs Tim has pointed out, you could actually just use the base R form of ifelse():\n\ntbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) ifelse(\n        test = value &lt; 5, \n        yes  = \"[c]\",\n        no   = value\n      )\n    )\n  )\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nI think people use dplyr::if_else() for (a) consistency if they’re already using tidyverse in the script and (b) it’s ‘strictness’ compared to ifelse(). if_else() will force you to declare the true and false arguments so they resolve to the same type, whereas ifelse() will silently force type coercion, which may be undesirable in some cases.\nAnother method would be to iterate the suppression over only the columns that need it. For example, you could do that with a simple for and if:\n\ncols_numeric &lt;- names(select(tbl, where(is.numeric)))\n\nfor (col in cols_numeric) {\n  if (any(tbl[col] &lt; 5)) {\n    tbl[col] &lt;- ifelse(\n      tbl[col] &lt; 5,\n      \"[c]\",\n      as.character(tbl[[col]])\n    )\n  }\n}\n\ntbl\n\n# A tibble: 5 × 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nThis reads as ‘for each numeric column that contains at least one value less than 5, replace those values with the placeholder symbol \"[c]\".’"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#preach-to-the-converted-types",
    "href": "posts/2023-04-20-type-convert/index.html#preach-to-the-converted-types",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Preach to the converted types",
    "text": "Preach to the converted types\nIt’s almost like this post could have just been a tweet saying ‘😮 yo, type.convert() is 🪄magic🪄 y’all’. But this post is now a handy reference in case anyone has the same problems with Excel’s handling of {a11ytables} outputs in future.\nAlso I needed to hit my pun quota for the month.4"
  },
  {
    "objectID": "posts/2023-04-20-type-convert/index.html#environment",
    "href": "posts/2023-04-20-type-convert/index.html#environment",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 12:30:02 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     utf8_1.2.3        R6_2.5.1          fastmap_1.1.1    \n [5] tidyselect_1.2.0  xfun_0.39         magrittr_2.0.3    glue_1.6.2       \n [9] tibble_3.2.1      knitr_1.43.1      pkgconfig_2.0.3   htmltools_0.5.5  \n[13] generics_0.1.3    rmarkdown_2.22    lifecycle_1.0.3   cli_3.6.1        \n[17] fansi_1.0.4       vctrs_0.6.3       withr_2.5.0       compiler_4.3.1   \n[21] rstudioapi_0.14   tools_4.3.1       pillar_1.9.0      evaluate_0.21    \n[25] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.5    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-06-10-apple-health-runs/index.html#tldr",
    "href": "posts/2023-06-10-apple-health-runs/index.html#tldr",
    "title": "Extract run data from Apple Health (redux)",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R to extract running details from a downloaded of your Apple Health data. The format of the data has changed since I last tried this, so I re-wrote my code."
  },
  {
    "objectID": "posts/2023-06-10-apple-health-runs/index.html#on-your-marks",
    "href": "posts/2023-06-10-apple-health-runs/index.html#on-your-marks",
    "title": "Extract run data from Apple Health (redux)",
    "section": "On your marks",
    "text": "On your marks\nIn 2021 I extracted my running activities from my Apple Health data using the {xml2} package. You can read there for some theory and background.\nAt that point I’d been running for one year. I’m nearly at 500 runs, so I thought I would re-execute my code with the latest data. Alas, the original code no longer works because Apple seems to have updated the format of the XML file they provide.\n\n❗️ Update\nI have since re-rendered this post after passing 500 runs.\n\n\nSo I’ve written a new function that takes a path to the zipped download of my Apple Health data and outputs a dataframe of time and distance data, with one row per run."
  },
  {
    "objectID": "posts/2023-06-10-apple-health-runs/index.html#get-set",
    "href": "posts/2023-06-10-apple-health-runs/index.html#get-set",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Get set",
    "text": "Get set\nI followed the same steps as before to get my Apple Health data off my phone.\nI smashed together a quick function to unzip the file to a temporary location and then extract workout data using the the {xml2} package. There’s a bit of base R wrangling to output a dataframe with a row per run workout, focusing on total time and distance.\n\n\nClick to expand the function definition\n\n\nget_run_distances &lt;- function(zip_path) {\n  \n  # Unzip Apple Health export to temporary location\n  message(\"Unzipping and reading XML\")\n  temp &lt;- tempdir()\n  unzip(zipfile = zip_path, exdir = temp)\n  xml_in &lt;- xml2::read_xml(file.path(temp, \"apple_health_export\", \"export.xml\"))\n  unlink(temp)\n  \n  # Isolate workouts only and convert to an R list object\n  message(\"Isolating workouts from XML\")\n  wo_in &lt;- xml2::xml_find_all(xml_in, \"//Workout\") |&gt; xml2::as_list()\n  \n  # Pre-allocate a list to be filled with output data\n  wo_total &lt;- length(wo_in)\n  wo_out &lt;- vector(\"list\", wo_total)\n  \n  # For each viable workout, extract the details\n  message(\"Iterating over workouts to extract run data\")\n  for (wo_n in seq(wo_total)) {\n    \n    # Extract details for current workout\n    wo &lt;- wo_in[[wo_n]]\n    wo_attrs &lt;- attributes(wo)  # the data is stored as attributes\n    is_run &lt;- \n      wo_attrs[[\"workoutActivityType\"]] == \"HKWorkoutActivityTypeRunning\"\n    \n    # If the workout wasn't a run, then skip to the next workout\n    if (!is_run) next\n    \n    # if it is a run, then extract the data to a single-row dataframe\n    if (is_run) {\n      \n      # There can be more than one element named 'WorkoutStatistics'. We want to \n      # get the one with distance information and extract the details.\n      wo_stats &lt;- wo[grep(\"WorkoutStatistics\", names(wo))]\n      wo_stats_types &lt;- lapply(wo_stats, \\(x) attr(x, c(\"type\")))\n      dist_type &lt;- \"HKQuantityTypeIdentifierDistanceWalkingRunning\"\n      dist_index &lt;- which(wo_stats_types == dist_type)\n      wo_dist &lt;- wo_stats[[dist_index]]\n      \n      # Prepare single-row dataframe and add to the pre-allocated list\n      wo_details &lt;- data.frame(\n        source = wo_attrs[[\"sourceName\"]],\n        start = as.POSIXct(wo_attrs[[\"startDate\"]]),\n        end = as.POSIXct(wo_attrs[[\"endDate\"]]),\n        distance_km = attr(wo_dist, \"sum\") |&gt; as.numeric() |&gt; round(2)\n      )\n      wo_details[[\"duration_s\"]] &lt;- \n        as.numeric(wo_details[[\"end\"]] - wo_details[[\"start\"]], units = \"secs\")\n      wo_out[[wo_n]] &lt;- wo_details\n      \n    }\n    \n  }\n  \n  # Convert to dataframe, select columns\n  message(\"Combining data\")\n  wo_out_df &lt;- do.call(rbind, wo_out)\n  wo_out_df[, c(\"source\", \"start\", \"end\", \"duration_s\", \"distance_km\")]\n  \n}\n\n\nI won’t go through it line by line, but there’s some commentary to explain what’s happening at each step. It does what I need it to do for now, but no doubt there’s some refactoring to be done.\nThere’s a few things to note:\n\nI’m more comfortable handling R objects, so I converted early to a list with xml2::as_list(). Awkwardly, the data in the list object was stored as attributes to each element.\nThe distance data is stored in an element called ‘WorkoutStatistics’, but more than one element will have this name. We first have to isolate the element that is of the correct type, which has the name ‘HKQuantityTypeIdentifierDistanceWalkingRunning’.\nI converted the start and end variables to datetime class (POSIXct) and subtracted one from the other to get the duration of the run. This yields the ‘difftime’ class that can be converted to seconds with as.numeric() and the argument units = \"secs\".\nThere’s no input handling, because this was quick and for ‘fun’, lol."
  },
  {
    "objectID": "posts/2023-06-10-apple-health-runs/index.html#go",
    "href": "posts/2023-06-10-apple-health-runs/index.html#go",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Go",
    "text": "Go\nSo, to use the function you pass a path to where your zipped Apple Health export lives. Mine is in my ‘Documents’ folder.\n\nruns &lt;- get_run_distances(\"~/Documents/data/export.zip\")\n\nUnzipping and reading XML\n\n\nIsolating workouts from XML\n\n\nIterating over workouts to extract run data\n\n\nCombining data\n\n\nI recorded all my runs with the Nike Run Club app, so I’ll filter out duplicates where I dual-recorded with Apple’s Workout app. I think I accidentally started the app by mistake a couple of times, so we’ll only grab runs of over 1 km. I’ll also convert the seconds to a friendlier-looking ‘period’ class using {lubridate}1.\nHere’s the most recent few:\n\nruns &lt;- runs[runs$source == \"Nike Run Club\" & runs$distance_km &gt; 1, ]\nruns$duration &lt;- lubridate::seconds_to_period(runs$duration_s)\nruns &lt;- runs[, c(\"start\", \"distance_km\", \"duration\")]\nrow.names(runs) &lt;- NULL\ntail(runs)\n\n                  start distance_km duration\n497 2023-06-15 08:45:46        6.39  30M 36S\n498 2023-06-17 11:07:03       10.52  50M 58S\n499 2023-06-18 10:36:58       10.42  51M 29S\n500 2023-06-22 08:14:51        6.34  30M 43S\n501 2023-06-24 08:47:05       10.13  48M 43S\n502 2023-06-25 09:20:20       12.12  59M 48S\n\n\nFor my own tracking purposes, I’ve run:\n\n502 times\nfor a total distance of 4119 km\nfor a total duration of about 14 days\n\nAnd I can recreate one of the plots from the old post while we’re here:\n\nplot(\n  x = runs$start, \n  y = runs$distance_km, \n  las = 1,  # rotate y-axis labels\n  main = \"Runs captured with Nike Run Club in Apple Health\",\n  xlab = \"Date\",\n  ylab = \"Distance (km)\"\n)\n\n\n\n\nSome patterns are obvious. For example, there’s lots of 5 km runs until about mid-2021, when it hops to more like 7 km. That’s when I started running for 30 mins at a time, rather than for 5 km specifically.\nI’m pretty happy at these two distances, obviously, but maybe I should do more 21.1 km half-marathons. Or a full marathon? No no, that’s foolish: it would expand my y-axis too much and make it harder to observe patterns at shorter distances, amirite."
  },
  {
    "objectID": "posts/2023-06-10-apple-health-runs/index.html#environment",
    "href": "posts/2023-06-10-apple-health-runs/index.html#environment",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 16:26:51 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lubridate_1.9.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         knitr_1.43.1     \n [5] htmltools_0.5.5   timechange_0.2.0  rmarkdown_2.22    generics_0.1.3   \n [9] xml2_1.3.4        cli_3.6.1         compiler_4.3.1    rstudioapi_0.14  \n[13] tools_4.3.1       evaluate_0.21     yaml_2.3.7        rlang_1.1.1      \n[17] jsonlite_1.8.5    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-01-07-petrov/index.html#tldr",
    "href": "posts/2023-01-07-petrov/index.html#tldr",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "tl;dr",
    "text": "tl;dr\nIn which I prove wrong a tweeted Opta football statistic, using R and Transfermarkt data. Oh wait, actually Opta were right. Ah, heck."
  },
  {
    "objectID": "posts/2023-01-07-petrov/index.html#petrov-rescue",
    "href": "posts/2023-01-07-petrov/index.html#petrov-rescue",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Petrov Rescue",
    "text": "Petrov Rescue\nBasically, for little reason, I dislike the style of the tweets on the Twitter feed for Opta1 (the company who do all the football stats).\nWhat is so outrageous? Each tweet always ends in a single, summary word that makes me cringe.\nWait, what? Let’s take a look at their most recent tweet at time of writing:\n\n14 - Harry Kane has scored 14 goals in his last 14 appearances in the FA Cup, averaging a goal every 63 minutes in the competition in this period. Guarantee.\n\n‘Guarantee’. Gah.\nOr this tweet:\n\n16 - Since his first appearance in the competition in January 2016, Leicester’s Kelechi Iheanacho has scored more FA Cup goals than any other player (16). Specialist.\n\n‘Specialist’. Sigh.\nA completely small and pointless thing to be annoyed by, right?\nBut here’s the scenario. Over the yuletide period (on Christmas day!) they ran this tweet:\n\n1 - Stiliyan Petrov (@StanPetrov19) is the only player to have played in the Premier League whose name contains all the letters in the word ‘Nativity’. Star.\n\nObviously, I have absolutely nothing against ‘Big Stan’. He’s a legend; a ‘star’, if you will. Captain of Aston Villa! Bulgaria! Battled leukaemia and still made it to nearly 600 games. One of the best Bulgarian/Premier League ‘Petrovs’, along with cult legend Martin.\nBut could this stat possibly be true? Surely there’s at least one other player. Perhaps a window of opportunity for me to avenge my feelings of cringe?\nOh, and obviously you can ignore the candid dismissals in the tweet’s replies, for example:\n\nWhat are we supposed to do with this information? [Picture of wryly-smiling duck.]\n\nNo, this is more important than any Opta tweet ever: what if it’s… wrong?"
  },
  {
    "objectID": "posts/2023-01-07-petrov/index.html#stan-in-r-but-not-rstan",
    "href": "posts/2023-01-07-petrov/index.html#stan-in-r-but-not-rstan",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Stan in R, but not {rstan}",
    "text": "Stan in R, but not {rstan}\nSo I looked into it using R, of course.\nTurns out it’s pretty straightforward with the excellent {worldfootballR} package by Jason Zivkovic, which helps fetch player data from Transfermarkt (among other suppliers).\nBasically, we can fetch data about footballers from every team in a given league’s season since its inception. So, aha, you cannot escape, Opta!\nMy little {soccercolleagues} package that I wrote about in early 2022 is built heavily (heavily!) around {worldfootballR} and has a convenience function we can use.\nThe niche2 primary objective of {soccercolleagues} is to let you find pairs of football players that were colleagues at some point. Like: ‘which current Premier League footballer has been team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?’3\nFollow along. As ever, you can install the {soccercolleagues} package from GitHub:\n\nif(!require(remotes)) install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/soccercolleagues\")\n\nWe’ll also use the {tidyverse} for wrangling.\n\nlibrary(soccercolleagues)\nlibrary(tidyverse)\n\nSo we can ask Transfermarkt for all the years of the English Premier League, which began in 1992:\n\n# This will take quite a long time...\nepl_players &lt;- soccercolleagues::get_players(\n  seasons = 1992:2022,\n  country = \"England\"\n)\n\nAnd now we can look for the players whose names contain the letters in ‘nativity’:\n\nepl_players |&gt;\n  distinct(player_name) |&gt;\n  mutate(\n    player_name = str_remove_all(tolower(player_name), \" \"),\n    n_count = str_count(player_name, \"n\"),\n    a_count = str_count(player_name, \"a\"),\n    t_count = str_count(player_name, \"t\"),\n    i_count = str_count(player_name, \"i\"),\n    v_count = str_count(player_name, \"v\"),\n    y_count = str_count(player_name, \"y\")\n  ) |&gt;\n  filter(\n    n_count &gt;= 1 &\n      a_count &gt;= 1 &\n      t_count &gt;= 2 &\n      i_count &gt;= 2 &\n      v_count &gt;= 1 &\n      y_count &gt;= 1\n  )\n\n# A tibble: 1 × 7\n  player_name    n_count a_count t_count i_count v_count y_count\n  &lt;chr&gt;            &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n1 stiliyanpetrov       1       1       2       2       1       1\nOof… they were right. He is the only one.\nWow, this humble pie is so delicious, thank you so much Opta for unintentionally spoonfeeding it to me.\nTo be clear: Opta’s data analysts have a good track record, as far as I know. But I’ve got my eye on you! You’ll slip up one day!\n…But wait. Opta were misnaming Stan as ‘Stylian Petrov’ in tweets as late as 2012. Get rekt! You missed the extra ‘i’ you need in ‘nativity’, fools! Put respect on Stiliyan’s name!\n‘Result’.4"
  },
  {
    "objectID": "posts/2023-01-07-petrov/index.html#environment",
    "href": "posts/2023-01-07-petrov/index.html#environment",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:10:28 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "tl;dr",
    "text": "tl;dr\n{officer} is an R package that lets you extract elements of a Word document, including tables, into a tidy dataframe. I’ve written a function to ‘re-rectangularise’ extracted Word tables into a list of R dataframes.\n\nℹ️ Update\nTurns out that Eli Pousson has written the {officerExtras} package (install it from GitHub), which already contains this functionality in the officer_tables() and officer_table() functions. At least this proves my idea wasn’t too far-fetched!\nAlso you can just use docxtractr::docx_extract_all_tbls() by Bob Rudis to extract all the tables in one go, lol."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "href": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "What’s the officer, problem?",
    "text": "What’s the officer, problem?\nSomeone on Slack asked about some difficulty with scraping a table from a Word document. We’ve all been there.\nMy mind immediately went to {officer} by David Gohel, which is part of the ‘officeverse’ for reading, creating and manipulating common Microsoft documents with R1.\nIn particular, the function officer::docx_summary() extracts all the elements of a Word doc into a tidy dataframe2. Each row of that dataframe is a heading, or a paragraph, or the contents of a table cell3.\nThis means tables are ‘unstacked’, with a row per ‘cell’ of the original Word table. How could you convert these tidy Word tables into dataframes for further use in R? There’s a suggestion in the docs, but I drew the rest of the heckin’ owl by creating a slightly overengineered function to do it4."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "href": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "’Allo ’allo",
    "text": "’Allo ’allo\nFirst, you can download the {officer} package from CRAN:\n\ninstall.packages(\"officer\") # if not yet installed\nlibrary(officer)\n\nLet’s create a Word document to test with and save it to a temporary location:\n\n# Create a test docx file\ndoc_test &lt;- read_docx() |&gt;\n  body_add_par(\"This is a test\", style = \"heading 1\") |&gt;\n  body_add_par(\"Below is a table.\", style = \"Normal\") |&gt;\n  body_add_table(mtcars[1:3, 1:5]) |&gt; \n  body_add_par(\"Below is another table\", style = \"Normal\") |&gt;\n  body_add_table(airquality[1:3, 1:5])\n\n# Save docx to temp location\ntemp_docx &lt;- tempfile(fileext = \".docx\")\nprint(doc_test, target = temp_docx)\n\nThe package has a nice system of pipeable functions for building up document. This code created a file with a heading, followed by two tables that each have a line of text above them.\nWe can read the document with read_docx() and extract the contents into a tidy dataframe:\n\n# Read the file from temp path\ndoc_path &lt;- list.files(tempdir(), pattern = \".docx$\", full.names = TRUE)\ndoc_in &lt;- read_docx(doc_path)\n\n# Get the content of the document as a dataframe\ndoc_tidy &lt;- docx_summary(doc_in)\nstr(doc_tidy)\n\n'data.frame':   43 obs. of  11 variables:\n $ doc_index   : int  1 2 3 3 3 3 3 3 3 3 ...\n $ content_type: chr  \"paragraph\" \"paragraph\" \"table cell\" \"table cell\" ...\n $ style_name  : chr  \"heading 1\" \"Normal\" NA NA ...\n $ text        : chr  \"This is a test\" \"Below is a table.\" \"mpg\" \"21.0\" ...\n $ level       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ num_id      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ row_id      : int  NA NA 1 2 3 4 1 2 3 4 ...\n $ is_header   : logi  NA NA TRUE FALSE FALSE FALSE ...\n $ cell_id     : num  NA NA 1 1 1 1 2 2 2 2 ...\n $ col_span    : num  NA NA 1 1 1 1 1 1 1 1 ...\n $ row_span    : int  NA NA 1 1 1 1 1 1 1 1 ...\n\n\nThe doc_in object has ‘rdocx’ class that carries the extracted elements and associated style information. Running docx_summary() converts this to the single tidy dataframe that we’re after.\nYou can see we have information here about the content of our doc. For purposes of this post, we care about:\n\ntext, which is the actual written content\ncontent_type, which can tell us if we’re looking at table cells\ndoc_index, which assigns an ID value so document elements stay together (e.g. cells of a table will all carry the same doc_index)\ncell_id and row_id, which tell us the x and y cell locations in tables\nis_header, which can tell us if the row contains a table header.\n\nNow to extract the table elements and ‘re-rectangularise’ back into a dataframe."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "href": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Cop a load of this",
    "text": "Cop a load of this\nI’ve made two functions using base R:\n\nrectangularise_tables() (note the plural) takes the dataframe provided by docx_summary() and outputs a list of dataframes, one per table in the original Word file\n.rectangularise_table() (not pluralised and starts with a dot for disambiguation), which runs inside rectangularise_tables() to reformat the tidy representation of a single Word table into an R dataframe\n\nYou’ll need to copy both of these into your session and run them. For convenience, I’ve added them to a GitHub gist. I’ve added commentary so you can see what’s happening in each bit.\n\n\nClick to expand the rectangularise_tables() definition.\n\n\nrectangularise_tables &lt;- function(\n    docx_summary,  # output dataframe from docx_summary\n    assume_headers = TRUE,  # assume headers in first row?\n    type_convert = TRUE  # try to coerce columns to most likely data type?\n) {\n  \n  # Check inputs\n  \n  is_data.frame &lt;- inherits(docx_summary, \"data.frame\")\n  \n  docx_summary_names &lt;- c(\n    \"doc_index\", \"content_type\", \"style_name\", \"text\", \"level\", \"num_id\", \n    \"row_id\", \"is_header\", \"cell_id\", \"col_span\", \"row_span\"\n  )  # column names we can expect in the output from docx_summary\n  \n  is_docx_summary &lt;- all(names(docx_summary) %in% docx_summary_names)\n  \n  if (!is_data.frame | !is_docx_summary) {\n    stop(\n      paste(\n        \"Argument 'docx_summary' must be a data.frame created with\",\n        \"'officer::docx_summary'.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Get only the rows that relate to Word tables\n  docx_summary_tables &lt;- \n    docx_summary[docx_summary[[\"content_type\"]] %in% \"table cell\", ]\n  \n  # Get the ID value for each Word table\n  doc_indices &lt;- unique(docx_summary_tables[[\"doc_index\"]])\n  \n  # Initiate an empty list to hold dataframe representations of the Word tables\n  tables_out &lt;- vector(mode = \"list\", length = length(doc_indices))\n  names(tables_out) &lt;- paste0(\"doc_index_\", doc_indices)\n  \n  # For each Word table, 'rectangularise' into a dataframe and add to the list\n  for (doc_index in doc_indices) {\n    \n    docx_summary_table &lt;- \n      docx_summary_tables[docx_summary_tables[[\"doc_index\"]] == doc_index, ]\n    \n    extracted_table &lt;- .rectangularise_table(docx_summary_table, assume_headers)\n    \n    list_element_name &lt;- paste0(\"doc_index_\", doc_index)\n    tables_out[[list_element_name]] &lt;- extracted_table\n    \n  }\n  \n  # Optionally convert columns to appropriate type (integer, etc)\n  if (type_convert) {\n    tables_out &lt;- lapply(tables_out, type.convert, as.is = TRUE)\n  }\n  \n  return(tables_out)\n  \n}\n\n\n\n\nClick to expand the .rectangularise_table() definition.\n\n\n.rectangularise_table &lt;- function(\n    table_cells,  # docx_summary output filtered for 'table cells' only\n    assume_headers = TRUE  # assume headers in first row?\n) {\n  \n  # Check inputs\n  \n  is_table_cells &lt;- all(table_cells[[\"content_type\"]] == \"table cell\")\n  is_one_table &lt;- length(unique(table_cells[[\"doc_index\"]])) == 1\n  \n  if (!is_table_cells | !is_one_table) {\n    stop(\n      paste(\n        \"Argument 'table_cells' must be a dataframe created with\",\n        \"'officer::docx_summary' where 'content_type' is filtered for\",\n        \"'table cell' only.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Split each Word table into a list element, isolate headers and cell contents\n  cell_id_split &lt;- split(table_cells, table_cells[[\"cell_id\"]])\n  headers &lt;- lapply(cell_id_split, function(x) x[x[[\"is_header\"]], \"text\"])\n  content &lt;- lapply(cell_id_split, function(x) x[!x[[\"is_header\"]], \"text\"])\n  table_out &lt;- as.data.frame(content)\n  \n  # Column headers are identified by TRUE in the is_header column, but may not\n  # be marked up as such. Use them as dataframe headers if they exist.\n  has_headers &lt;- length(unlist(headers)) &gt; 0\n  if (has_headers) {\n    names(table_out) &lt;- headers\n  }\n  \n  # If headers are not identified by is_header, assume that the first row of the\n  # Word table contains the headers. The user can control this behaviour with\n  # the argument assume_headers.\n  if (!has_headers & assume_headers) {\n    headers &lt;- table_out[1, ]  # assume first row is headers\n    table_out &lt;- table_out[2:nrow(table_out), ]  # rest of table is content\n    names(table_out) &lt;- headers\n  }\n  \n  return(table_out)\n  \n}\n\n\nYou’ll notice the assume_headers argument. The headers for a Word table are marked by TRUE in the is_header column of the output from docx_summary(). Except when they aren’t. It’s possible that you’ll read a Word doc where the table headers aren’t identified. Set assume_headers to TRUE (the default) to allow rectangularise_table() to instead use the first row of the table as headers. The setting will apply to all tables; I reckon that it’s all or nothing whether table headers will be marked up in a given Word document.\nYou may also have seen the type_convert argument5. By default, the text column in the output from docx_summary() will be character class, but the actual data might be integers, for example. As explained in a recent blog post, the type.convert() function attempts to coerce a column to the appropriate data type if possible.\nAnd now we can see that the dataset works using our test document:\n\ndf_list &lt;- rectangularise_tables(doc_tidy)\nstr(df_list)\n\nList of 2\n $ doc_index_3:'data.frame':    3 obs. of  5 variables:\n  ..$ mpg : num [1:3] 21 21 22.8\n  ..$ cyl : int [1:3] 6 6 4\n  ..$ disp: int [1:3] 160 160 108\n  ..$ hp  : int [1:3] 110 110 93\n  ..$ drat: num [1:3] 3.9 3.9 3.85\n $ doc_index_5:'data.frame':    3 obs. of  5 variables:\n  ..$ Ozone  : int [1:3] 41 36 12\n  ..$ Solar.R: int [1:3] 190 118 149\n  ..$ Wind   : num [1:3] 7.4 8 12.6\n  ..$ Temp   : int [1:3] 67 72 74\n  ..$ Month  : int [1:3] 5 5 5\n\n\nSmashing. We have a list of two dataframes: one for each of the tables in the test document. I took the liberty of naming the list elements like doc_index_* so you can trace which doc_index they were in the original output from docx_summary()."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "PrisonR",
    "text": "PrisonR\nTo summarise, this is absolutely not the worst code-related crime I’ve committed on this blog. Sorry guv! I’ll definitely be sentenced to the most severe punishment if caught and tried: several minutes of hard labour, or ‘refactoring’ as they call it on the inside.\nAt worst I’ll build an Andy-Dufresne-style tunnel out of my prison cell and hide the entrance behind years of accumulated hex stickers.\n\nℹ️ Update\nAs a bonus, I later wrote a quick reproducible example that part-solves the original reason for this post. Here I’ve used {docxtractr} to extract tables from docx files in separate subfolders and then combine them.\n\n\nClick to expand code.\n\n\n# Attach packages (all are available from CRAN)\nlibrary(docxtractr)  # to extract tables from docx files\nlibrary(officer)  # to create dummy docx files\nlibrary(charlatan)  # to generate fake data\n\n# Create multiple dummy docx files in separate temporary folders\n\nmy_folder &lt;- tempdir()  # temporary locations to store the files\nn_files &lt;- 5  # the number of dummy files to generate\n\nfor (i in seq(n_files)) {\n  \n  # Create subfolders\n  subfolder_name &lt;- paste0(\"subfolder_\", i)\n  dir.create(file.path(my_folder, subfolder_name))\n  \n  # Create dummy dataframe\n  \n  n_fake &lt;- 10  # number of fake data items to generate\n  \n  temp_df &lt;- data.frame(\n    name = ch_name(n_fake),\n    job = ch_job(n_fake),\n    phone = ch_phone_number(n_fake)\n  )\n  \n  # Add dummy dataframe to a docx file and save it\n  path &lt;- file.path(my_folder, subfolder_name, paste0(\"df_\", i, \".docx\"))\n  officer::read_docx() |&gt; body_add_table(temp_df) |&gt; print(target = path)\n  \n}\n\n# Get the file paths to all the docx files\ndocx_paths &lt;- list.files(\n  my_folder,\n  pattern = \".docx$\",\n  full.names = TRUE,  # return full filepaths\n  recursive = TRUE  # look in all subfolders\n)\n\n# Preallocate a list to be filled with extracted tables, one element per file\nextracted_tables &lt;- vector(\"list\", n_files)\n\n# Extract tables and add to the list (not tested: I think that read_docx will\n# read .doc files, but only if you have LibreOffice installed.\nfor (i in docx_paths) {\n  tables &lt;- docxtractr::read_docx(i) |&gt; docx_extract_all_tbls()\n  extracted_tables[basename(i)] &lt;- tables\n}\n\n# In this simple demo, the dataframes in each list element can be appended\n# because they all have the same column names and types.\ndo.call(rbind, extracted_tables)"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "href": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:16:59 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] officer_0.6.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.22    xml2_1.3.4       \n [9] cli_3.6.1         zip_2.3.0         askpass_1.1       openssl_2.0.6    \n[13] textshaping_0.3.6 systemfonts_1.0.4 compiler_4.3.1    rstudioapi_0.14  \n[17] tools_4.3.1       ragg_1.2.5        evaluate_0.21     yaml_2.3.7       \n[21] rlang_1.1.1       jsonlite_1.8.5    htmlwidgets_1.6.2 uuid_1.1-0"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\n\n\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n\nConsiderations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.\nConsiderations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor’s permission is not necessary for any reason–for example, because of any applicable exception or limitation to copyright–then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.\n\n\n\n\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html",
    "href": "posts/2023-01-06-remorse/index.html",
    "title": ".-././–/—/.-./…/.",
    "section": "",
    "text": "You may not believe it, but I am releasing this art under CC0."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#tldr",
    "href": "posts/2023-01-06-remorse/index.html#tldr",
    "title": ".-././–/—/.-./…/.",
    "section": "tl;dr",
    "text": "tl;dr\nOn a whim, I’ve written {remorse}: a tiny R package that converts text to Morse Code to audio."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "href": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "title": ".-././–/—/.-./…/.",
    "section": "Beat a dead morse",
    "text": "Beat a dead morse\nIn the last post I mentioned {sonify} for making R do little audible beeps and boops.\nIt reminded me of one (of many) unwritten micro-projects I’ve got kicking around in my brain: obviously you could use {sonify} to communicate Morse Code. And why not translate from text to Morse (and back) while you’re at it?1\nTo be honest this was a classic case of name-driven development (NDD): I thought {remorse} was a funny name for a package and worked backwards from there.\nObviously it says ‘Morse’ in the name, but also ‘remorse’ is usually what I feel after putting together a small pointless package; pointless-package existentialism (PPE) is something I have a track history with.\nBut of course, the true remorse is that I didn’t find the better package-name pun: {morseinspector}. But maybe that’s too long of a name and maybe non-Brits wouldn’t understand the reference. Maybe I’m thinking too hard.2"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "href": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "title": ".-././–/—/.-./…/.",
    "section": "Oh dit-dit-dahling",
    "text": "Oh dit-dit-dahling\nConsider this highly plausible scenario: it’s 20XX, the apocalypse has come, and the remaining humans on planet Earth communicate by Morse Code. For some reason.3\nWow, wouldn’t it be handy to have a text-to-Morse translator?\nWell friend, if you’ve managed to find an electronic thinking box in the apocalyptic barren wastelands (assuming electricity is still available (and the machine has R installed (and the {remorse} package was downloaded before the world’s internet cut out (and you know how to use R (and you don’t own a simpler, more portable Morse Code translation pamphlet))))), then you will have this incredible power at your fingertips.\nOr maybe you’d rather risk it? Pfft."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "href": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "title": ".-././–/—/.-./…/.",
    "section": "Use the Morse…",
    "text": "Use the Morse…\nThat’s an awful lot of build-up for a very simple package. Let’s take a look at what little it does.\nAs usual, {remorse} lives on GitHub4, so it can be downloaded with a little help from the typographically-adjacent {remotes} package:\n\ninstall.github(\"remotes\")\nremotes::install_github(\"matt-dray/remorse\")  # v0.1.1 here\n\nThat’ll install {sonify} as well, which is needed for the audio.\nRight so: text to Morse Code.\n\ntext_in &lt;- \"Ahoy pal!\"\nmorse &lt;- remorse::txt2morse(text_in)\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nSo each letter has been translated to the relevant string of ‘dits and dahs’ (‘dots’ and ‘dashes’) that make up Morse Code. I’ve used a period (.) and hyphen (-) to represent these in {remorse}, with forward slashes (/) between Morse groups that represent individual characters, and a space for the spaces between words.\nNote that not all characters can be converted to Morse Code. I did some research (Wikipedia) to discover the mappings from letters, numbers and punctuation to Morse Code. This information is used internally as a lookup, but is also exported in morse_lookup:\n\nremorse::morse_lookup\n\n       A        B        C        D        E        F        G        H \n    \".-\"   \"-...\"   \"-.-.\"    \"-..\"      \".\"   \"..-.\"    \"--.\"   \"....\" \n       I        J        K        L        M        N        O        P \n    \"..\"   \".---\"    \"-.-\"   \".-..\"     \"--\"     \"-.\"    \"---\"   \".--.\" \n       Q        R        S        T        U        V        W        X \n  \"--.-\"    \".-.\"    \"...\"      \"-\"    \"..-\"   \"...-\"    \".--\"   \"-..-\" \n       Y        Z        0        1        2        3        4        5 \n  \"-.--\"   \"--..\"  \"-----\"  \".----\"  \"..---\"  \"...--\"  \"....-\"  \".....\" \n       6        7        8        9        &        '        @        ) \n \"-....\"  \"--...\"  \"---..\"  \"----.\"  \".-...\" \".----.\" \".--.-.\" \"-.--.-\" \n       (        :        ,        =        !        .        -        * \n \"-.--.\" \"---...\" \"--..--\"  \"-...-\" \"-.-.--\" \".-.-.-\" \"-....-\"   \"-..-\" \n       +        \"        ?        /          \n \".-.-.\" \".-..-.\" \"..--..\"  \"-..-.\"      \" \" \n\n\nOf course, this means we can map backwards from Morse Code to letters, numbers and punctuation:\n\ntext_out &lt;- remorse::morse2txt(morse)\ntext_out\n\n[1] \"AHOY PAL!\"\n\n\nMorse Code has no sense of case, so it just converts it all to uppercase. Like you’re shouting; the most clear form of communication.\nSo, you can argue justifiably that txt2morse(\"yo\") |&gt; morse2txt() is just a worse version of toupper() that strips out certain unmappable characters.\nBut of course it does so much more. Well, one thing more. Let’s go from Morse to audio.\nFirst a reminder of the code from earlier:\n\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nAnd to generate audio you just:\n\nremorse::morse2sfx(morse)\n\nThe output sounds like this:\n\n\n\n\n\nWow. It plays audible dits (one ‘time unit’, default is dit_length = 0.05 in seconds), dahs (three), spaces between dits and dahs (one), spaces between Morse character groupings (three) and spaces between words (seven). Tell all your friends.\nSo, do I still feel remorse for writing {remorse}, even after demonstrating its incredible power? Yes. All I ask is that you think of me in those apocalyptic wastelands.\n\nℹ️ Update\nI just realised you can turn Morse Code into… Morse Code. Mind blown.\n\nremorse::txt2morse(\"hi\") |&gt;\n  remorse::txt2morse()\n\n[1] \".-.-.-/.-.-.-/.-.-.-/.-.-.-/-..-./.-.-.-/.-.-.-\"\n\n\n‘Morsest Code’. Why? Absolutely.\nMaybe I’ve been watching too much Tom7 recently."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#environment",
    "href": "posts/2023-01-06-remorse/index.html#environment",
    "title": ".-././–/—/.-./…/.",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:19:21 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   remorse_0.1.1     rstudioapi_0.14  \n [9] yaml_2.3.7        rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5   \n[13] xfun_0.39         digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "title": "London from space via botsin.space",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve (finally) ported the londonmapbot Twitter bot to Mastodon. Like a mammoth rising from the ashes."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "title": "London from space via botsin.space",
    "section": "TOOOOOOOT",
    "text": "TOOOOOOOT\nTwitter is burning to the ground, yada yada.\nFor example, it appears that the free API tier will disappear soon. Soon like… today. Oh wait, maybe not yet?1 Cool customer communication, brah.\nAnyway, this news will obviously devastate contributors and fans of the mapbotverse Twitter list.\nYou don’t know what the mapbotverse is? Oof. It’s a collection of 25 bot accounts that take some inspiration from my londonmapbot account, which uses GitHub Actions and the {rtweet} package to tweet on schedule a picture of a random spot in Greater London via MapBox.\nAnd so it’s time to update the code behind londonmapbot so that it continues to post to Twitter for as long as it survives. But also so that it lives on by posting to Mastodon via the {rtoot} package as well.\nMastowhat? Something something federated Twitter-replacement sort of thing. Tooooooot tooooooot."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "title": "London from space via botsin.space",
    "section": "Masto-do or masto-do-not",
    "text": "Masto-do or masto-do-not\nI’m slightly behind the curve on this: Matt Kerlogue has already ported his narrowbotR (‘narrow boater’) bot from Twitter to Mastodon and written about it.\nThe fix was fairly rudimentary in the end, thanks to standing on the shoulder of mammoths. Particularly the creators of the {rtoot} R package.\n{rtoot} lets you interact with the Mastodon API. It’s a sort-of analogue to the {rtweet} package for the Twitter API. {rtoot} was stood up very quickly by David Schoch (with co-author Chung-hong Chan and contributor Johannes Gruber) when it became clear that Mastodon was becoming the platform-du-jour for nerds.\n\nSet up Mastodon\nIt’s easier to set yourself up with API access for Mastodon compared to Twitter:\n\nSet up a Mastodon account on the dedicated bot server botsin.space (londonmapbot is @londonmapbot@botsin.space).2\nInstall the {rtoot} package.\nAuthorise yourself with Mastodon and get an API token.\n???\nAbsolutely do not profit whatsoever.\n\nSteps 2 and 3 look like this:\n\ninstall.packages(\"rtoot\")  # on CRAN\n\nrtoot::auth_setup(\n  instance  = \"botsin.space\",  # the Mastodon server the account is on\n  type      = \"user\",          # i.e. for posting from R\n  name      = \"londonmapbot\",  # name the token file\n  clipboard = TRUE             # copy to clipboard\n)\n\nThis process interrupts you to interactively authorise the {rtoot} package in a browser window and copy a big long code to a dialogue box that appears in your R session.\n\nIt’ll then return:\nToken of type \"user\" for instance botsin.space is valid\nToken (in environment variable format) has been copied to clipboard.\n&lt;mastodon bearer token&gt; for instance: botsin.space of type: user \nI pasted this API token to a safe place and also stored it as a GitHub repo secret in the londonmapbot GitHub repo so it could be referred to while the GitHub Action was running.\n\n\nPost to Mastodon\nNow we can use the post_toot() function to… toot a post. Publish a toot? Entoot a noote. It requires a token argument that takes a special ‘bearer token’ with a particular structure that’s not too dissimilar from what the rtweet package expects of the object passed to its own token function.\nAside: token setup is made easy in {rtweet} thanks to the rtweet_bot() function, to which you can pass your API keys and secrets. It’s a little less obvious in {rtoot}, which was initially built with the intention of running API calls from your personal machine, so you could just store your keys in your .Renviron file or whatever.\nBut actually you can just mimic how {rtweet} accepts the token. To do this, I did not use my brain at all and simply ripped-off Matt Kerlogue’s post.3 My updated R script now contains this:4\n\nmastodon_token &lt;- structure(\n  list(  # it's just a list\n    bearer   = Sys.getenv(\"RTOOT_DEFAULT_TOKEN\"),\n    type     = \"user\",  # i.e. to post from R\n    instance = \"botsin.space\"  # the server\n  ),\n  class = \"rtoot_bearer\"  # special token class\n)\n\nWhere RTOOT_DEFAULT_TOKEN is that API token from earlier, which is required for accessing Mastodon. As mentioned, it’s stored as a GitHub repo secret and called into the GitHub Action environment thanks to the env: RTOOT_DEFAULT_TOKEN: ${{ secrets.RTOOT_DEFAULT_TOKEN }} call in the YAML file.\nThis object can be passed quite happily to the post_toot() function.\n\nrtoot::post_toot(\n  status   = latlon_details,\n  media    = temp_file,\n  alt_text = alt_text,\n  token    = mastodon_token\n)\n\nWhere the status (body text), media (image file) and alt_text (alternative text for the image) objects have been generated already (see the R script for details).\nThis is then executed on schedule according to the cron string5 specified in the YAML file (currently twice a day at 0914 and 1714) to publish stuff like this:\n\n\n\nAwait Twitter implosion\nI want the bot to keep posting to Twitter for as long as I’m allowed to. In other words, we should try to post a tweet and catch any error silently, without disrupting the GitHub Action. So naturally I wrapped post_tweet() in a tryCatch() statement, yes? No, actually I used purrr::possibly() instead.\nWhy? Basically because the syntax is easy to remember, lol. And what difference does it make to have one extra dependency for this task? To use it, you wrap your function of interest in possibly() and then it can fail without erroring-out the whole function.\n\npossibly_post_tweet &lt;- purrr::possibly(rtweet::post_tweet)\n\npossibly_post_tweet(\n  status         = latlon_details,\n  media          = temp_file,\n  media_alt_text = alt_text,\n  token          = twitter_token\n)\n\n\n\nFiddle while Frisco burns\nWhile I was messing about with the londonmapbot code, I made a few things in the repo a bit more generic. For example, I altered the name of the GitHub Actions YAML file and the R script to be called ‘post-image’. This is more descriptive and it removes the need for someone forking the repo to have to manually change the name away from ‘londonmapbot’. You are so welcome."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "title": "London from space via botsin.space",
    "section": "Parp",
    "text": "Parp\nFarewell, until the next time we have to port londonmapot to another API-enabled microblogging site. We’ve had bird- and mammal-themed sites; my prediction is that the next site will be called ‘Seacucumber’ and we won’t ‘tweet’ or ‘toot’, we’ll ‘eviscerate’.6\nI mean, inverting one’s stomach is a daily reaction on Twitter anyway, amirite?"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "title": "London from space via botsin.space",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:53:00 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#tldr",
    "href": "posts/2023-03-16-webr-test/index.html#tldr",
    "title": "Playgrounds with WebR and Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nWebR lets you run R in the browser(!). Now you can make WebR chunks in Quarto that render to editable, executable blocks(!)."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#sliding-into-tedium",
    "href": "posts/2023-03-16-webr-test/index.html#sliding-into-tedium",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Sliding into tedium",
    "text": "Sliding into tedium\nI wrote recently a simple introduction to how R parses code. I provided a function that I said the reader could go away and run themselves.\nAs in… copy-paste it into an instance of R running on their machine. Gross.\nWouldn’t it be better if people could just tinker with the code right there in the post? This kind of ‘playground’ could be great for explaining concepts and teaching.1"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#i-seesaw-a-solution",
    "href": "posts/2023-03-16-webr-test/index.html#i-seesaw-a-solution",
    "title": "Playgrounds with WebR and Quarto",
    "section": "I seesaw a solution",
    "text": "I seesaw a solution\nWebR lets you run R in the browser. Read that again! This is a landmark piece of work from George Stagg and Lionel Henry.\nI won’t go into technicals and limitations here. For more information, see:\n\nthe docs\nthe v0.1 launch post\nan ‘awesome’ list of resources\n\nCrucially for my needs, you can now run WebR chunks in a Quarto document, thanks to James J Balamuta. This renders interactive blocks of R code that the reader can adjust and execute with button-click:\n\n\n\nBeware: this is a gif, not an embedded demo!\n\n\nCheck out James’s coatless/quarto-webr GitHub repo for the source. There’s also a live demo and its source."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#swinging-into-action",
    "href": "posts/2023-03-16-webr-test/index.html#swinging-into-action",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Swinging into action",
    "text": "Swinging into action\nTo have a go yourself, do follow the setup steps in James’s quarto-webr README and look at the source of his demo.\nUltimately you can:\n\nInstall the extension to your project folder by running quarto add coatless/quarto-webr in the terminal\nSet filter: webr in the YAML of your qmd file2\nWrite code chunks in the qmd using the {webr} engine\n\nThis made it straightforward to prepare a little Quarto doc with chunks powered by the ‘webr’ engine, which I deployed to the web via Netlify.3\nYou can visit that live page or see the underlying source on GitHub.4\nSo now you can tinker with the example I gave in the original blogpost about parsing R code. Unfortunately I can’t add this directly to the post, since this blog is not made with Quarto."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#a-blog-platform-merry-go-round",
    "href": "posts/2023-03-16-webr-test/index.html#a-blog-platform-merry-go-round",
    "title": "Playgrounds with WebR and Quarto",
    "section": "A blog-platform merry-go-round",
    "text": "A blog-platform merry-go-round\nI’ve written this quick demo and post because I was excited about what George & Lionel and James have put together. There’s so many system-independent applications of this approach that could help with teaching and learning, or explaining simple ideas in a blog post.\nIn fact, this blog may eventually switch from {blogdown} to Quarto to take advantage of WebR. It’ll be a pain to convert old posts, but luckily I already missed the earlier {blogdown}-to-{distill} bandwagon, lol.5"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#environment",
    "href": "posts/2023-03-16-webr-test/index.html#environment",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 13:19:28 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#tldr",
    "href": "posts/2023-01-30-trapinch-begin/index.html#tldr",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve used the {httr2} R package to create {trapinch}, a package that wraps PokéAPI for fetching Pokémon data.\n\nℹ️ Update\nI had found a couple of older, non-{httr2} PokéAPI wrappers for R (see footnotes), but had somehow missed one that already uses {httr2}: see Ash Baldry’s {pokeapi} package, which he wrote months ago!"
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#httr-me-baby-one-more-time",
    "href": "posts/2023-01-30-trapinch-begin/index.html#httr-me-baby-one-more-time",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "{httr} me baby one more time",
    "text": "{httr} me baby one more time\nThe {httr2} package lets you talk to the internet. Or, if you’re fancy, it ‘helps you deal programmatically with HTTP requests and responses’ so you can use it to fetch data from Application Programming Interfaces (APIs).\n{httr2} has functions that are prefixed consistently (req_*(), resp_()*, etc), are narrow in scope, pipeable (|&gt;) and which return nice errors and messages. These are neat improvements on the original {httr} package.\nI’ve used {httr} before to explore R package startup messages and detect linkrot. It’s time to try out {httr2}. What simple API can I wrap into an R package?1"
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#poke-an-api",
    "href": "posts/2023-01-30-trapinch-begin/index.html#poke-an-api",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Poke an API",
    "text": "Poke an API\nRegular readers will be unsurprised that I’ve chosen the PokéAPI API for fetching all sorts of information related to the Pokémon game franchise.2\nPokéAPI provides a relatively simple API. You don’t need to sign-up or use API tokens, you can only read (‘GET’) data from it’s not rate-limited.\nURL paths for fetching data are also straightforward: you append an endpoint and a resource of interest to the base URL in the form https://pokeapi.co/api/v2/{endpoint}/{resource}.3\nIn other words, you could type https://pokeapi.co/api/v2/pokemon/lotad in your browser and the API would respond with a JSON file containing data about Lotad, the best Pokémon.\n{httr2} lets us do this programmatically and can return a more R-friendly list object."
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#its-a-trapinch",
    "href": "posts/2023-01-30-trapinch-begin/index.html#its-a-trapinch",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "It’s a trapinch",
    "text": "It’s a trapinch\nSo, I’ve created the {trapinch} package.\nIt’s a proof of concept; a work in progress. There’s probably bugs. I’m sharing it in case I don’t take it any further, or if you want to contribute an issue or pull request.\nYou can download it from GitHub. It depends on {httr2} (obviously), {rcurl} and R version 4.1 or higher4 and can be downloaded from GitHub:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/trapinch\")  # v0.0.1 in this post\nlibrary(trapinch)\n\nDon’t be surprised if function names or general functionality change in future. In particular, I’d like to look at throttling (limiting the number of API calls to prevent misuse) and to provide sensible errors for timeouts or if the service is down.\n\nGotta GET ’em all\nThere’s a generic low-level function, get_pokeapi(), to which you pass the endpoint and resource ID (numeric) or name (character) of interest. Each endpoint also has its own dedicated function, like get_item() or get_move() that calls get_pokeapi() under the hood.\nYou can look at the inbuilt resource_lookups list to get a dataframe of resource IDs and names for each endpoint, as well as the full URL needed to query the API. Here’s the first few:\n\nhead(names(resource_lookups))\n\n[1] \"ability\"        \"berry\"          \"berry-firmness\" \"berry-flavor\"  \n[5] \"characteristic\" \"contest-effect\"\nSo here’s the first few rows of the resource dataframe for the ‘pokemon’ endpoint:\n\nhead(resource_lookups[[\"pokemon\"]])\n\n  id       name                                  url\n1  1  bulbasaur https://pokeapi.co/api/v2/pokemon/1/\n2  2    ivysaur https://pokeapi.co/api/v2/pokemon/2/\n3  3   venusaur https://pokeapi.co/api/v2/pokemon/3/\n4  4 charmander https://pokeapi.co/api/v2/pokemon/4/\n5  5 charmeleon https://pokeapi.co/api/v2/pokemon/5/\n6  6  charizard https://pokeapi.co/api/v2/pokemon/6/\nOne of these resource names is ‘mew’, the legendary first-generation Pokémon.5 You could use get_pokeapi(\"pokemon\", \"mew\") to retrieve its data, or more simply:\n\nmew &lt;- get_pokemon(\"mew\")\n\nThe function returns a list of lists, which is parsed from the JSON response returned by the API. So for the ‘pokemon’ endpoint we get 18 different elements of various classes:\n\nstr(mew, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nI’ve shown only the top level structure to hide some of the complexity. For example, the ‘moves’ item contains all the moves a Pokémon can learn, at what level it can learn them, in which game it learns them, and so on. Grabbing the first of the 363 ‘moves’ items (!) listed for Mew looks like this (oof):\n\nmew[[\"moves\"]][[1]][[\"move\"]][[\"name\"]]\n\n[1] \"pound\"\nA future task might be to simplify some of this complexity by collapsing deep lists into dataframes where possible.\n\n\nThumbing the Pokédex\nThe API responses are ‘paged’, meaning that you must make successive requests of a set size to retrieve all the data for a given endpoint. The get_*() functions automatically expand the request to ask for all the items in one go.\nWe know the maximum number of items to be returned from an endpoint because the stored in the resource_lookups object, so this can be appended automatically to the request string.\n\n\nBILL’s PC\nResponses are cached, which means that the data is saved on your computer. If you make the same request, the data will be retrieved first from the cache rather than calling the API again. That means there’s one less request for the API to deal with.\nThe cache is the path resolved by R_user_dir(\"trapinch\", \"cache\"). This function was introduced in R v4.0 for platform-independent storage of package-related data on a user’s machine.6 You can delete everything from the cache with clear_cache().\n\n\nSubstitute\n{httptest2} is a handy package that lets you test code written with {httr2}, specifically.\nWhy would you need special testing for API calls? The idea is that you should be able to test your package without the need for an active internet connection. {httptest2} ‘records’ the calls you make when you run your tests, then chooses when testing between this ‘mock’ response and a ‘live’ response.\nThe approach is pretty simple if you’ve tested before with {testthat}: you wrap your normal test_that() call with httr2::with_mock_dir(). Here’s an example of a test that make sure we get a list back from the API when we use get_pokeapi():\n\nwith_mock_dir(\"endpoint\", {\n  test_that(\"a list is returned\", {\n    expect_type(get_pokeapi(\"move-battle-style\"), \"list\")\n  })\n})\n\nBy wrapping the test in with_mock_dir(), {httptest2} creates the directory tests/endpoint/ that stores a copy of the JSON returned for this call when an internet connection was live.\nAs an aside, I learnt about curl::has_internet() in Colin’s blogpost, which can stop() the get_*() functions if there’s no internet connection. But has_internet() will trigger if you’re offline when you test, defeating the purpose of {httptest2}! Luckily, I saw a timely post by Maëlle about integrating this type of check into an ‘escape hatch’ so your unit tests can be run successfully in this scenario.\nThe rOpenSci HTTP Testing book is a good general port of call as well."
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#inside-the-poké-ball",
    "href": "posts/2023-01-30-trapinch-begin/index.html#inside-the-poké-ball",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Inside the Poké Ball",
    "text": "Inside the Poké Ball\nThe user-facing functions of {trapinch} are therefore pretty simple. I could leave it at that.\nBut how daunting does the underlying {httr2} code look in the back-end? Turns out that it’s not that scary, thanks to those friendly and modular functions of {httr2}.\nWe can walk through that earlier get_pokemon(\"mew\") call using bare {httr2} functions by:\n\nStarting with the base API URL\nAppending the endpoint and resource as extensions (i.e. in the form /pokemon/mew)\nAdding a query for the maximum number of items in this endpoint-resource combo (i.e. ?limit=1279)\nAnnouncing to the API, as courtesy, who has made the call (i.e. who is the ‘user agent’)\nSpecifying the cache location for results to be saved\n\nFirst some variables:\n\nendpoint &lt;- \"pokemon\"\nresource &lt;- \"mew\"\nbase_url &lt;- \"https://pokeapi.co/api/v2/\"\nuser_agent &lt;- \"trapinch (http://github.com/matt-dray/trapinch)\"\nresource_count &lt;- nrow(trapinch::resource_lookups[[endpoint]])\ncache_dir &lt;- tools::R_user_dir(\"trapinch\", which = \"cache\")\n\nAnd now we can build our request with {httr2} functions prefixed with req:\n\nlibrary(httr2)\n\nmew_request &lt;- request(base_url) |&gt;\n  req_url_path_append(endpoint, resource) |&gt;\n  req_url_query(limit = resource_count) |&gt;\n  req_user_agent(user_agent) |&gt;\n  req_cache(cache_dir)\n\nPrinting the object summarises the request:\n\nmew_request\n\n&lt;httr2_request&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nBody: empty\nOptions:\n• useragent: 'trapinch (http://github.com/matt-dray/trapinch)'\nPolicies:\n• cache_path: '/Users/mattdray/Library/Caches/org.R-project.R/R/trapinch'\n• cache_use_on_error: FALSE\n• cache_debug: FALSE\nThen we can actually execute the request:\n\nmew_perform &lt;- req_perform(mew_request)\n\nAgain, we can peek at the object to get some extra information about the processing of the request:\n\nmew_perform\n\n&lt;httr2_response&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nStatus: 200 OK\nContent-Type: application/json\nBody: In memory (561317 bytes)\nWe can see the request was successful, since the HTTP status was 200 OK. Other status values are possible and may require us to try again later, for example.\nA couple of functions to mention here are last_request() and last_response(), which will also (surprise!) spit out info about the last request you made and the response received.\nFinally we can parse the JSON returned by the API. Again, I’m presenting the top-level structure only, given its complexity:\n\nmew_response &lt;- resp_body_json(mew_perform)\nstr(mew_response, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nBoom: this matches the information we retrieved earlier with get_pokemon(\"mew\")."
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#whos-that-pokémon",
    "href": "posts/2023-01-30-trapinch-begin/index.html#whos-that-pokémon",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Who’s that Pokémon?",
    "text": "Who’s that Pokémon?\nI know you’re thinking ‘why trapinch?’ In short, it’s the name of a Pokémon that contains the letters ‘R API’, which is cute. It also makes for an easy hex sticker with the Pokémon’s characteristic zigzag mouth and colour palette of orange and grey.\nSo why not ‘rapidash’, which starts with ‘R API’? Easy, lol: trapinch isn’t taken yet on Repokémon, a page by Chee Aun that lists GitHub repositories that are named after Pokémon.7\n\nJoin me next time as I continue my quest to write (sometimes) useful R packages that help me squat all the remaining spots on Repokémon (I call this ‘RDD’).8"
  },
  {
    "objectID": "posts/2023-01-30-trapinch-begin/index.html#environment",
    "href": "posts/2023-01-30-trapinch-begin/index.html#environment",
    "title": "Wrapping PokéAPI with {trapinch}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:16:05 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html",
    "href": "posts/2023-05-09-spear-ggplot2/index.html",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "",
    "text": "They’re the same picture. Nearly."
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#tldr",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#tldr",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "tl;dr",
    "text": "tl;dr\nTwo years ago I won a data-viz recreation competition run by the Royal Statistical Society (RSS) using base R’s plotting. I wrote a short {ggplot2} how-to for RSS’s ‘Significance’ magazine that was never published1, so here it is now."
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#recreate",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#recreate",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Recreate",
    "text": "Recreate\nThis short code walkthrough will get you started on recreating Mary Eleanor Spear’s cotton plot (1952), as used in the Royal Statistical Society’s #CottonViz challenge. We’ll concentrate on the line chart for now.\n\nThe {ggplot2} package in R is a good choice, since we can build up the chart in steps: first, we’ll build a basic line chart, remove unneeded elements, fix the axes and finally add the labels. It won’t look perfectly like Spear’s original, but we’ll get close.\nThis isn’t a guide to learn {ggplot2}, so you may want to learn the basics first. Alternatively, I wrote a blog post about building Spear’s entire visualisation using base R only."
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#requirements",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#requirements",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Requirements",
    "text": "Requirements\nFirst, some preparation. If you haven’t already, install the {ggplot2} package for plotting, {tidyr} data reshaping and {extrafont} for font handling.\n\ninstall.packages(\"ggplot2\", \"tidyr\", \"extrafont\")\n\nYou can download for free the Routed Gothic font by Darren Embry, which is a good approximation of the stencil lettering used by Spear. Installation will depend on your system, but in macOS you can simply drag the font files to the Font Book app. When you attach {extrafont} it’ll fetch automatically your installed fonts (including Routhed Gothic) so you can use them in R.\n\nlibrary(extrafont)"
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#tidying-up",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#tidying-up",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Tidying up",
    "text": "Tidying up\nThe cotton dataset is quite small, so we can create the dataframe ourselves. It provides information on the supply of cotton in the USA in the 1940s.\n\ncotton_raw &lt;- data.frame(\n  year           = 1942:1948,\n  us_consumption = c(11160, 9993,  9693,  9423,  10072, 9374,  7833),\n  exports        = c(1480,  1139,  2007,  3613,  3545,  1968,  4785),\n  stocks         = c(10657, 10744, 11164, 7326,  2530,  3080,  5283),\n  total_supply   = c(23297, 21876, 22864, 20362, 16147, 14422, 17901)\n)\n\nIt’s preferable to make the data ‘tidy’ so that there’s one row per year and consumption type, and one column for each variable. The {tidyr} package can help us pivot the data to ‘long’ format from this ‘wide’ format.\n\nlibrary(tidyr)\n\ncotton &lt;- cotton_raw %&gt;% \n  pivot_longer(\n    c(us_consumption, exports, stocks), \n    names_to = \"consumption_type\", values_to = \"boles\"\n  )\n\nhead(cotton, 4)  # preview first few rows\n\n# A tibble: 4 × 4\n   year total_supply consumption_type boles\n  &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  1942        23297 us_consumption   11160\n2  1942        23297 exports           1480\n3  1942        23297 stocks           10657\n4  1943        21876 us_consumption    9993"
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#how-to",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#how-to",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "How-to",
    "text": "How-to\n\nStep 1: line chart\nNow we can create a basic line chart of the data with geom_line() and set with scale_linetype_manual() a unique dashed line per group. Further arguments set the title and the typeface to be used throughout the plot, while a small tweak to theme() adjusts the title’s position.\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot() +\n  geom_line(\n    data = cotton,\n    aes(x = year, y = boles / 1000, linetype = consumption_type),\n    linewidth = 1.5\n  ) +\n  scale_linetype_manual(values = c(\"longdash\", \"dashed\", \"solid\")) +\n  labs(title = \"Millions of Boles\") +\n  theme(\n    plot.title = element_text(hjust = -0.05),\n    text = element_text(family = \"Routed Gothic\")\n  )\n\np1\n\n\n\n\n\n\nStep 2: remove features\nLet’s clear away the unneeded features: the background panel, the axes titles and the legend. You can empty these with element_blank() in the theme() function.\n\np2 &lt;- p1 + \n  theme(\n    panel.background = element_blank(),\n    axis.title = element_blank(),\n    legend.position = \"none\"\n  )\n\np2\n\n\n\n\n\n\nStep 3: correct the axes\nNow we can address the axes. Use the scale_*_continuous() functions to set the axes values, limits, origin and labels. With sec.axis you can create a secondary y-axis that mirrors the first, then remove the tick labels in the theme() function. You can also put a box around the chart area with the panel.border argument.\n\np3 &lt;- p2 +\n  scale_x_continuous(\n    breaks = seq(1942, 1948, 1),\n    labels = c(\"1942\", paste0(\"'\", 43:48)),\n    expand = c(0, 0)\n  ) +\n  scale_y_continuous(\n    breaks = seq(0, 12, 2),\n    limits = c(0, 12),\n    expand = c(0, 0),\n    sec.axis = dup_axis()\n  ) +\n  theme(\n    axis.ticks = element_line(linewidth = c(0, rep(0.5, 5), 0)),\n    axis.ticks.length = unit(-0.5, \"lines\"),\n    axis.text.y.right = element_blank(),\n    panel.border = element_rect(fill = NA, linewidth = 1)\n  )\n\np3\n\n\n\n\n\n\nStep 4: labels\nThe only missing features are the labels and arrows, which can be added with the annotate() and geom_segment(), respectively. A bit of trial-and-error will help you find the correct coordinates to place these elements.\n\np4 &lt;- p3 +\n  annotate(\n    geom = \"text\",\n    x = c(1946.1, 1945.9, 1943.75),\n    y = c(10.8, 7.1, 3.2),\n    label = c(\"U. S. Consumption\", \"Carry – over\\nStocks\", \"Exports\"),\n    family = \"Routed Gothic\"\n  ) +\n  geom_segment(\n    aes(\n      x = c(1945.2, 1945.3, 1944.2),\n      y = c(10.5, 7.4, 3.1),\n      xend = c(1945, 1945.1, 1944.4), \n      yend = c(9.7, 7.1, 2.8)\n    ),\n    arrow = arrow(\n      length = unit(2, \"mm\"),\n      type = \"closed\"\n    )\n  )\n\np4"
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#next-steps",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#next-steps",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Next steps",
    "text": "Next steps\nFinally we’ve got a lineplot that looks pretty close to Spear’s visualisation. What subtle differences do you notice, though? Try to find ways to improve them.\nNext, try to recreate the stacked-barchart from Spear’s original and then arrange the plots with a main title and surrounding text labels. The {ggpattern} package may help you recreate the hatchlines on the bars and {patchwork} could help with the arrangement of the plot and text elements."
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#full-base-r-alternative",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#full-base-r-alternative",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Full base R alternative",
    "text": "Full base R alternative\nFor the original challenge I used only base R’s plotting system rather than {ggplot2}. This is what my submitted image looked like:\n\nYou can read more about it in the accompanying blog post and you can find the original code on GitHub."
  },
  {
    "objectID": "posts/2023-05-09-spear-ggplot2/index.html#environment",
    "href": "posts/2023-05-09-spear-ggplot2/index.html#environment",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 16:30:46 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.2 tidyr_1.3.0  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.5   \n [9] labeling_0.4.2    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5  \n[13] scales_1.2.1      fansi_1.0.4       rmarkdown_2.22    grid_4.3.1       \n[17] munsell_0.5.0     evaluate_0.21     tibble_3.2.1      fastmap_1.1.1    \n[21] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2      \n[25] htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.14   farver_2.1.1     \n[29] digest_0.6.31     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3       \n[33] pillar_1.9.0      magrittr_2.0.3    gtable_0.3.3      tools_4.3.1      \n[37] withr_2.5.0"
  },
  {
    "objectID": "posts/2023-03-11-in-a-dungeon/index.html",
    "href": "posts/2023-03-11-in-a-dungeon/index.html",
    "title": "Fun and learning. In a dungeon!",
    "section": "",
    "text": "Learn hard and you too can be a mobile gamedev like me."
  },
  {
    "objectID": "posts/2023-03-11-in-a-dungeon/index.html#tldr",
    "href": "posts/2023-03-11-in-a-dungeon/index.html#tldr",
    "title": "Fun and learning. In a dungeon!",
    "section": "tl;dr",
    "text": "tl;dr\nToday I spoke at a public sector1 event for data scientists2. I said that learning is best when focused into little projects that are fun."
  },
  {
    "objectID": "posts/2023-03-11-in-a-dungeon/index.html#to-the-point",
    "href": "posts/2023-03-11-in-a-dungeon/index.html#to-the-point",
    "title": "Fun and learning. In a dungeon!",
    "section": "To the point",
    "text": "To the point\nThe abstract sums it up, obviously:\n\nEver done a technical training module and then immediately forgot what you learnt? Do you sometimes feel like you’re ticking boxes instead of actually developing your skills? Yeah, me too. Luckily, more active styles of learning are available. Maybe you can try working on a small, focused project where you can make mistakes and have fun. I’ve had success with this and, as a bonus, accidentally learnt more than I had planned to. I’ll give you an example of my experience and some ideas for how you might be able to do it yourself. The talk will involve a detour to an underground cave, but you won’t need any extra equipment.3\n\nYes, a cheeky teaser there to pique the interest. But everyone came to my talk anyway because it was the only one at that timeslot.\nYou can just look at the slides below if you want (direct link, source). Press ‘s’ to pop out the speaker notes.\n\n\n\n\n\n\n\n\nThese were made with Revealjs via Quarto, of course."
  },
  {
    "objectID": "posts/2023-03-11-in-a-dungeon/index.html#on-my-soapbox",
    "href": "posts/2023-03-11-in-a-dungeon/index.html#on-my-soapbox",
    "title": "Fun and learning. In a dungeon!",
    "section": "On my soapbox",
    "text": "On my soapbox\nSo what incredible insight did I bring to the event?\nBasically, I think ‘module-based’ learning—often passive video walkthroughs with comprehension exercises—are too generic and I usually struggle to remember anything from them.\nI think ‘project-based’ learning is preferable. Think about what you actually want to learn and develop a small-scope, discrete project around it. Make the subject matter fun. Fail meaningfully by be being open, recording what you’ve found, and involving your community.\nMy contrived soundbite is that module-based is done to you and project-based is done by you.\nIs this a new thought technology? No. Is it always true and applicable to everyone in every conceivable scenario and with every learning need? No. What’s my expertise? None, really. I’ve just spent a long time in lots of different departments and I can tell you what has worked for me4 as someone who entered the public sector with little computing or coding ability.\nAm I all too aware of how self-indulgent this all sounds? Yes. Did I need a whole talk to explain this? No, probably not. I’m happy if just one person stops to think about this next time they want to learn something. I’m also content if one person panicked slightly when they realised that R is a game engine now."
  },
  {
    "objectID": "posts/2023-03-11-in-a-dungeon/index.html#environment",
    "href": "posts/2023-03-11-in-a-dungeon/index.html#environment",
    "title": "Fun and learning. In a dungeon!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:09:04 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.22      knitr_1.43.1        jsonlite_1.8.5     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html",
    "href": "posts/2023-05-07-bd2q/index.html",
    "title": "Automate {blogdown} to Quarto",
    "section": "",
    "text": "gRaPhIc DeSiGn Is My PaSsIoN."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#tldr",
    "href": "posts/2023-05-07-bd2q/index.html#tldr",
    "title": "Automate {blogdown} to Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nI’ve written a quick R package, {bd2q}, to help me convert my {blogdown} blog to Quarto. Whether I’ll actually complete the conversion is another story."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "href": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "title": "Automate {blogdown} to Quarto",
    "section": "Upside blogdown",
    "text": "Upside blogdown\nIt is destiny: no-one is ever completely happy with their blog.\nThis site was built five years ago1 with {blogdown}, which lets you write R Markdown files and have them knitted into a blog. I ignored the newer {distill} package2, but Quarto may be worth the switch. It’ll let me simplify the blog’s structure3 and take advantage of Quarto’s snazzy features4.\nBut I didn’t fancy transferring and editing ~150 posts by hand, so I’ve written a few functions to help out."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "href": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "title": "Automate {blogdown} to Quarto",
    "section": "When in doubt, make a package",
    "text": "When in doubt, make a package\nAnd so the {bd2q} R package5 is available from GitHub. It does what I need it to do for now, but note it only has basic error checking, has no unit tests, etc. Use at own risk, etc. It’s likely to remain unpolished forever, but feel free to add issues or pull requests. To install:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/bd2q\")\n\nThree things were in scope for this package:\n\nCreate a template Quarto blog.\nCreate the necessary Quarto folder structure for posts, then transfer posts and resources from the old {blogdown} blog.\nTweak the posts to remove or replace selected lines.\n\n\n1. Quarto blog template\nI assume someone has already written a version of usethis::create_project() for creating a Quarto blog. Regardless, I’ve written bd2q::create_template() to generate a folder with the minimal structure required, which makes my life easier for testing purposes.\n\nbd2q::create_template(q_path = \"~/new-quarto-blog\")\n\n✔ Created template Quarto blog at /Users/mattdray/new-quarto-blog\nThe skeleton content is opinionated and differs a bit to the one generated through RStudio’s ‘new project’ menu, for example, but the structure is the same:\nblog\n├── about.qmd\n├── index.qmd\n├── posts/\n│   └── metadata.yml\n├── styles.css\n└── blog.rproj\nOf course, now we need to pull in the posts from the old {blogdown} blog.\n\n\n2. Transfer posts and resources\nTypically in a {blogdown} blog, all R Markdown posts and their rendered HTML files are stored together in content/post/ in the form YYYY-MM-DD-post-name.Rmd and YYYY-MM-DD-post-name.html. Resources, like images, live separately in static/post/ with a folder per post in the form YYYY-MM-DD-post-name_files/.\nHere’s a simplified folder structure that focuses on a single post and its resources:\nblog/\n├── content/\n│   └── post/\n│       ├── YYYY-MM-DD-post-name.Rmd\n│       └── YYYY-MM-DD-post-name.html\n└── static/\n    └── post/\n        └── YYYY-MM-DD-post-name_files/\n            └── image.png\nQuarto simplifies this structure. Each post gets its own folder in posts/, like YYYY-MM-DD-post-name, which contains the post as index.qmd and a folder of resources. This means the post and all its content are stored together in one containing folder.\nblog/\n└── posts/\n    └── YYYY-MM-DD-post-name/\n        ├── index.qmd\n        └── resources/\n            └── image.png\nTo do the conversion, bd2q::transfer_posts() copies posts from a {blogdown} blog structure to a Quarto blog structure, setting up the required folders and renaming each post to index.qmd.\n\ntransfer_posts(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\"\n)\n\n✔ Created posts/ directory structure.\nℹ Copying posts.\n✔ Copied 148 posts to /Users/mattdray/new-quarto-blog.\nOnce that’s been run, bd2q::transfer_resources() can copy each post’s resources into an accompanying subfolder, which defaults to the name ‘resources’. You can choose which file types you want transfer with the exts_keep argument.\n\ntransfer_resources(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  exts_keep = c(\"gif\", \"jpg\", \"jpeg\", \"png\", \"svg\", \"wav\"),\n)\n\nℹ Copying resources.\n✔ Copied 455 resources to each post's resources/ folder in Users/mattdray/new-quarto-blog/posts.\nOf course this doesn’t account for everything, like bits of JavaScript and CSS related to the use of htmlwidgets. I’m not really bothered about this, because these should be recreated when I re-render each post.\nNote that you can use bd2q::create_and_transfer() if you want to run create_template(), transfer_posts() and transfer_resources() all at once. Regardless, once you’ve got the structure sorted, you can begin to adjust the posts if you need to.\n\n\n3. Tweak post content\nThere’s content in the body of each post that I want to get rid of or make more Quarto-like. I made a few functions that iterate over all the index.qmd files and replace or remove certain content.\nOne obvious necessity is to rebuild the resource paths (to images, sound files, etc), which can be done specifically with bd2q::update_resource_paths(). It defaults to creating paths to each post’s ‘resources’ subfolder, as generated by bd2q::transfer_resources(). For example, you could use a regular expression to match rows you know will contain a resource path and have them updated for the new Quarto folder structure (I tend to insert images with HTML rather than Markdown, hence the &lt;img&gt; tag in the example below).\n\nupdate_resource_paths(\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  resource_rx = \"&lt;img src=\"\n)\n\nℹ Updating posts.\n✔ 148 posts updated.  \nI also added two replace/remove functions that are a little more generic.\nThe first is bd2q::remove_line(), which deletes a single line from each post based on a provided regular expression. When I was messing around with converting the blog to Quarto manually, I found that the presence of the ‘draft’ status in the YAML header would prevent the post from appearing on the homepage, even if was set to ‘no’. As a result, you can run something like this to find and remove the lines that start with ‘draft’:\n\nbd2q::remove_line(\n  q_path = \"~/new-quarto-blog\",\n  detect_rx = \"^draft:\"\n)\n\nℹ Making corrections.\n✔ Removed lines matching the regular expression '^draft:' from 128 out of 148 posts.\nThat’s fine for individual lines, but what if you have a sequence of consecutive lines that you want to find and remove, or replace with some other text?\nThat’s what bd2q::replace_lines() does. Provide a vector of strings that exactly match some consecutive lines in each post, then provide a vector of strings to replace them with (or NULL to simply remove them)6.\nThis addresses another specific problem I was having. I wanted to update my custom session-info blocks at the bottom of each post so that they instead appear as a Quarto ‘appendix’. That can be done like this:\n\nold_lines &lt;- c(\n  \"---\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r eval=TRUE, sessioninfo, echo=FALSE}\",\n  \"sessioninfo::session_info()\",\n  \"```\",\n  \"&lt;/details&gt;\"\n)\n\nnew_lines &lt;- c(\n  \"## Details {.appendix}\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r}\",\n  \"#' eval = TRUE,\",\n  \"#' echo = FALSE\",\n  'cat(\"Date:\", cat(format(Sys.time(), format = \"%Y-%m-%d\")), \"\\n\\n\"); sessionInfo()',\n  \"```\"\n)\n\nbd2q::replace_lines(\n  q_path = \"~/new-quarto-blog\",\n  match_str = old_lines,\n  replacement_str = new_lines\n)\n\nℹ Making corrections.\n✔ Removed lines matching the provided string vector from 9 out of 148 posts.   \nHaha, uhoh, I was expecting to have fixed more posts than that! Looks like I might have written my custom session-info block slightly differently in each post (maybe an extra space or empty line?), so I’ll have to run the bd2q::replace_lines() multiple times to make sure I can replace it in each post that it appears."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "href": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "title": "Automate {blogdown} to Quarto",
    "section": "Actually use the package? Pfft!",
    "text": "Actually use the package? Pfft!\nSo, is {bd2q} objectively good? No. Does it do what I personally want it to do? Absolutely. Mostly. Yeah?\nOf course, transferring files into a new structure is the easy part. The hard part is to see if each post will still re-render after all these years. It’s unlikely! There’s no dependency management in this blog because there was no easy easy to do it. Quarto, meanwhile, has the ability to ‘freeze’ posts and link each post to a {renv} lockfile (thanks Albert) that captures each post’s package dependencies.\nThere are some other dependencies outside of packages though. For example, I have posts that use the {rtweet} package to fetch tweets from Twitter, but Twitter is a garbage fire and I may never be able to fetch tweets from the API in future. I may have to just copy-paste the outputs that were created when the post was originally rendered, oh well.\nTo be clear: this is hard work. I may not be brave enough to do it any time soon. I’ve set up a GitHub repo for ‘rostrum-blog-2’ where I’ve been experimenting with styles and structure, so if I ever get round to this task then that’s where the fireworks will be happening.\nAnd hey, at worst I got more familiar with the {fs} and {cli} packages when making {bd2q}, which are for ‘tidy’ path handling and nice user interfaces. A convoluted way to learn!\nBut that’s what this blog is all about, amirite."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#environment",
    "href": "posts/2023-05-07-bd2q/index.html#environment",
    "title": "Automate {blogdown} to Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:25:33 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] bd2q_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#tldr",
    "href": "posts/2023-02-23-nook-s7/index.html#tldr",
    "title": "Repaying Tom Nook with {S7}",
    "section": "tl;dr",
    "text": "tl;dr\nThe R7 S7 object-oriented system is coming to R. I’ve done a little R6-to-S7 translation on an old project to get a very cursory feel for it, featuring Animal Crossing New Horizons.\n\n❗️ Warning\nThe S7 system and package are under development and could change at any time, rendering everything in this post useless.1 Heck, last time I checked, the system was called ‘R7’. There’s also a chance that S7 elements may have been integrated into base R itself by the time you read this."
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#again-oh-no",
    "href": "posts/2023-02-23-nook-s7/index.html#again-oh-no",
    "title": "Repaying Tom Nook with {S7}",
    "section": "2020 again, oh no",
    "text": "2020 again, oh no\nAnimal Crossing New Horizons (ACNH) was the perfect pandemic game. And the pandemic was the perfect time to build an ersatz version of the ACNH in-game banking system to solve an exercise in the Advanced R book using the {R6} package for object-oriented programming (OOP) in R.\nThe exercise helped me fantasize about defeating the game’s main boss, the predatory loanshark (loanraccoon?) Tom Nook, via endless wire transfers of hard-earned in-game currency, called ‘Bells’.\nOf course, a lot has changed since 2020. Most importantly, a new OOP system for R is being developed. Conversely, Tom Nook has not changed. He is still a scourge.\nAnyway, maybe this is a chance to twitch my OOP muscles with this new system."
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#oop-they-did-it-again",
    "href": "posts/2023-02-23-nook-s7/index.html#oop-they-did-it-again",
    "title": "Repaying Tom Nook with {S7}",
    "section": "OOP they did it again",
    "text": "OOP they did it again\nThe R Consortium’s OOP working group has been beavering (raccooning?) away to develop a new OOP system from the ground up: S72 (S3 + S4, geddit?).\nThe idea is to take the best elements of the existing and in-built S3 and S4 systems, interface with them and improve on them.\nYou can read various design docs and meeting minutes on their documentation site, which is housed in their ‘OOP-WG’ GitHub repo, and try out the current iteration of the associated package, fittingly called {S7}.\nYou should refer to their docs in the first instance, or a useful third party review. For example, Jumping Rivers have… jumped the river on this one and produced a handy intro."
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#a-new-horizon-for-oop",
    "href": "posts/2023-02-23-nook-s7/index.html#a-new-horizon-for-oop",
    "title": "Repaying Tom Nook with {S7}",
    "section": "A new horizon for OOP",
    "text": "A new horizon for OOP\nNaturally, I should revisit my post on Repaying Tom Nook with {R6} by replicating it with {S7}. Naturally.\nAha, but actually the {S7} package is more like a development of S3 and S4 objects, and is not a ‘new version’ of {R6}! Ah well. I’m noodling around with {S7} for my own devices and thought I’d post it here so I can refer back to it later.\nBasically I’m recycling content from a previous post to get a feel for the new system. But only in the most superficial, basic way. I spent about 15 minutes on this. Look elsewhere for actually-usefully material. You have been warned."
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#install",
    "href": "posts/2023-02-23-nook-s7/index.html#install",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Install",
    "text": "Install\nFor now, the {S7} package is in the R Consortium’s OOP-WG GitHub repo.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"RConsortium/OOP-WG\")\n\nAnd for some glamour we’ll also use the quintessential {emoji} package3\n\ninstall.packages(\"emoji\")  # if not yet installed\nlibrary(emoji)"
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#that-is-class",
    "href": "posts/2023-02-23-nook-s7/index.html#that-is-class",
    "title": "Repaying Tom Nook with {S7}",
    "section": "That is class",
    "text": "That is class\nA new class is constructed with… new_class()\nWe can give it a name. We can also give it properties: fields that contain data and can be provided a type check and default value. It’s possible to build validators for these as well, which ensure that certain conditions are met when the properties are adjusted. I’ll keep this simple for now: I just want the values to remain equal or greater than zero.\n\nABD &lt;- new_class(\n  name = \"ABD\",\n  properties = list(\n    savings = new_property(class_integer, default = 0L),\n    loan = new_property(class_integer, default = 2498000L)\n  ),\n  validator = function(self) {\n    if (self@savings &lt; 0L) {\n      \"@savings must be zero or more\"\n    } else if (self@loan &lt; 0L) {\n      \"@loan must be zero or more\"\n    }\n  }\n)\n\nFor new methods, you can create a new ‘generic’ and define a function for it. For example, the ‘deposit’ method is pretty straightforward: it just adds an amount to the current savings value.\n\ndeposit &lt;- new_generic(\"deposit\", \"x\")\n\nmethod(deposit, ABD) &lt;- function(x, amount) {\n  x@savings &lt;- x@savings + amount\n  x\n}\n\nI specified some other methods, but I hid them because they’re not much more complicated.\n\n\nClick for more methods\n\nThe ‘withdraw’ method subtracts a specified amount from the savings property. You’re warned if you specify an amount greater than the amount available.\n\nwithdraw &lt;- new_generic(\"withdraw\", \"x\")\n\nmethod(withdraw, ABD) &lt;- function(x, amount) {\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Withdrew all savings: \", x@savings, \" Bells.\\n\", \n      call. = FALSE\n    )\n    x@savings &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n  }\n  \n  x\n  \n}\n\nThe ‘pay’ method moves funds from savings to loan. You’re warned if the loan is already paid, if you specify a greater amount than there are savings, or if you pay a greater amount than the loan remaining. You’ll get a victory message if you pay off the whole loan.\n\npay &lt;- new_generic(\"pay\", \"x\")\n\nmethod(pay, ABD) &lt;- function(x, amount) {\n  \n  if (x@loan == 0L) {\n    stop(\"You already finished paying your loan!\\n\", call. = FALSE)\n  }\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Paid total amount from savings instead: \", x@savings, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@loan &lt;- x@loan - x@savings\n    x@savings &lt;- 0L\n  } else if (x@loan - amount &lt; 0L) {\n    warning(\n      \"Paid total remaining loan instead: \", x@loan, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@savings &lt;- x@savings - x@loan \n    x@loan &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n    x@loan &lt;- x@loan - amount\n  }\n  \n  if (x@loan == 0L) {\n    cat(\n      emoji(\"smiley\"),\n      \"Sweet! I finally finished paying off my very last home loan!\",\n      emoji(\"tada\"), \"\\n\\n\"\n    )\n  }\n  \n  x\n  \n}\n\nThe check method is basically a print method. It reports the loan and savings amounts currently stored in the bank.\n\ncheck &lt;- new_generic(\"check\", \"x\")\n\nmethod(check, ABD) &lt;- function(x) {\n\n  loan_formatted &lt;- format(x@loan, big.mark = \",\", scientific = FALSE)\n\n  savings_formatted &lt;- format(x@savings, big.mark = \",\", scientific = FALSE)\n\n  cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")\n  cat(emoji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n  cat(emoji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n  cat(\n    \"Please make a selection from the menu below\\n\\n\",\n    emoji(\"house\"), \"pay()\\n\",\n    emoji(\"arrow_up\"), \"deposit()\\n\",\n    emoji(\"arrow_down\"), \"withdraw()\"\n  )\n\n}\n\n\nYou can start a new instance of the ABD class by, y’know, calling it.\n\nbank &lt;- ABD()\n\nWhen you check the class of this object, you’ll see both the custom class name and a reminder that it has the ‘S7’ class.\n\nclass(bank)\n\n[1] \"ABD\"       \"S7_object\"\n\n\nThe vanilla print method exposes the properties and their startup values:\n\nbank\n\n&lt;ABD&gt;\n @ savings: int 0\n @ loan   : int 2498000\n\n\nNote that the properties are prepended with @. This indicates that we can use the ‘at’ symbol to access these ‘slots’ (like S4) from the object, like:\n\nbank@loan\n\n[1] 2498000\n\n\nWhile we’re printing stuff, we can use the check() method (that I’ve pre-specified) to see the properties in a manner that more closely resembles the game.\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 2,498,000 Bells\n🐖 Savings Balance: 0 Bells\n\nPlease make a selection from the menu below\n\n 🏠 pay()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nYou can easily and directly change the properties. To add 10 Bells:\n\nbank@savings &lt;- 9.99\n\nError: &lt;ABD&gt;@savings must be &lt;integer&gt;, not &lt;double&gt;\nHaha, whoops. Remember I specified that the property can only be an integer, so we need to provide an integer value instead of a double value. In other words, we can only provide whole numbers of Bells. Remember that the L suffix is used in R to signify an integer.4\n\nbank@savings &lt;- 10L\n\nIs there an overdraft? Tom Nook would probably love that and would ask for massive overdraft fees, but it’s not programmed into the game. This is where our validator comes in handy. We specified that you can’t have a negative amount of savings, so this causes an error:\n\nbank@savings &lt;- -11L\n\nError: &lt;ABD&gt; object is invalid:\n- @savings must be zero or more\nThat’s fine, but I have sometimes I have extra logic I want to evaluate when I adjust the properties. That’s why I created new methods earlier on. It means I can use a function to add to the savings property instead, for example.\n\nbank &lt;- deposit(bank, 10L)\nbank@savings\n\n[1] 10\n\n\nWe can retrieve Bells in this fashion too:\n\nbank &lt;- withdraw(bank, 10L)\nbank@savings\n\n[1] 0\n\n\nWhat if we deposit enough Bells to pay the loan?\n\nbank &lt;- deposit(bank, 2500000L)\nbank &lt;- pay(bank, 2500000L)\n\nWarning: Paid total remaining loan instead: 2498000 Bells.\n\n\n😃 Sweet! I finally finished paying off my very last home loan! 🎉 \n\n\nThe method warns us when we try to pay off a value greater than the remaining loan and prints a nice congratulatory message if we’ve cleared the whole debt.\nAnd so we end up with this view:\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\n🔔 Loan Balance: 0 Bells\n🐖 Savings Balance: 2,000 Bells\n\nPlease make a selection from the menu below\n\n 🏠 pay()\n ⬆️ deposit()\n ⬇️ withdraw()\n\n\nHuzzah. Get rekt, raccoon dog. More like Tom Crook amirite."
  },
  {
    "objectID": "posts/2023-02-23-nook-s7/index.html#environment",
    "href": "posts/2023-02-23-nook-s7/index.html#environment",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:14:39 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emoji_15.0    S7_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         magrittr_2.0.3   \n [5] glue_1.6.2        stringr_1.5.0     knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.22    lifecycle_1.0.3   cli_3.6.1         compiler_4.3.1   \n[13] rstudioapi_0.14   tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[17] rlang_1.1.1       jsonlite_1.8.5    htmlwidgets_1.6.2 stringi_1.7.12"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rostrum.blog (test)",
    "section": "",
    "text": "Convert a Word table to Markdown\n\n\n\n2023-06-21\n\n\n\n\n\n\n\n\n\n\n\nPanic! In The Toolshed\n\n\n\n2023-06-13\n\n\n\n\n\n\n\n\n\n\n\nExtract run data from Apple Health (redux)\n\n\n\n2023-06-11\n\n\n\n\n\n\n\n\n\n\n\nRectangularise Word tables extracted by {officer}\n\n\n\n2023-06-07\n\n\n\n\n\n\n\n\n\n\n\nRecreating a dataviz with {ggplot2}\n\n\n\n2023-05-10\n\n\n\n\n\n\n\n\n\n\n\nAutomate {blogdown} to Quarto\n\n\n\n2023-05-07\n\n\n\n\n\n\n\n\n\n\n\nMatt Dray Teaches (Data) Typing\n\n\n\n2023-04-23\n\n\n\n\n\n\n\n\n\n\n\nR is a game engine, fight me\n\n\n\n2023-04-02\n\n\n\n\n\n\n\n\n\n\n\nPlaygrounds with WebR and Quarto\n\n\n\n2023-03-16\n\n\n\n\n\n\n\n\n\n\n\nFun and learning. In a dungeon!\n\n\n\n2023-03-15\n\n\n\n\n\n\n\n\n\n\n\nI can’t be parsed, mate\n\n\n\n2023-03-03\n\n\n\n\n\n\n\n\n\n\n\nRepaying Tom Nook with {S7}\n\n\n\n2023-02-26\n\n\n\n\n\n\n\n\n\n\n\nLondon from space via botsin.space\n\n\n\n2023-02-09\n\n\n\n\n\n\n\n\n\n\n\nWrapping PokéAPI with {trapinch}\n\n\n\n2023-02-02\n\n\n\n\n\n\n\n\n\n\n\nStiliyan Petrov: Jesus?\n\n\n\n2023-01-08\n\n\n\n\n\n\n\n\n\n\n\n.-././–/—/.-./…/.\n\n\n\n2023-01-06\n\n\n\n\n\n\n\n\n\n\n\nDing! Sound effects in {r.oguelike}\n\n\n\n2023-01-04\n\n\n\n\n\n\n\n\nNo matching items"
  }
]