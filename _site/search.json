[
  {
    "objectID": "about.html#tldr",
    "href": "about.html#tldr",
    "title": "About",
    "section": "tl;dr",
    "text": "tl;dr\nFun and learning with R, usually off-piste. Itâ€™s a bonus if you find any of it useful and/or amusing. All views belong to us.\nCheck out R Weekly for more R content."
  },
  {
    "objectID": "about.html#creators",
    "href": "about.html#creators",
    "title": "About",
    "section": "Creators",
    "text": "Creators\n\nMatt Dray\nPersonal site | Github | Mastodon\nI use R professionally for analysis and reproducibility, and as an amateur for memes and ironic trolling. I make R do odd things, often with the aid of important pop-culture references like PokÃ©mon and Dawsonâ€™s Creek.\n\n\nAdriana De Palma\nacademia.edu | Google Scholar | NHM\nIâ€™m a Postdoctoral Researcher at the Natural History Museum, London. I have a PhD in Ecology and an MRes in Entomology from Imperial College London, and a BSc in Biology from the University of Sussex.\nIn terms of my research, I am particularly interested in using large scale ecological datasets to answer policy relevant questions. I work on the PREDICTS project with Andy Purvis, looking at how biodiversity responds over time to land-use change and related pressures. My more general interests lie with science policy, statistics and weird and wonderful invertebrates (my favourite being Collembola â€“ the beautiful springtails)."
  },
  {
    "objectID": "about.html#meta",
    "href": "about.html#meta",
    "title": "About",
    "section": "Meta",
    "text": "Meta\n\nFind the source on GitHub\nMade with Quarto\nDeployed with Netlify\nVisitors counted using GoatCounter by Martin Tournoij"
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html",
    "href": "posts/2021-04-14-gha-readme/index.html",
    "title": "Up-to-date blog stats in your README",
    "section": "",
    "text": "Yesterdayâ€™s render of the GitHub README for this blog."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#tldr",
    "href": "posts/2021-04-14-gha-readme/index.html#tldr",
    "title": "Up-to-date blog stats in your README",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use a scheduled GitHub Action to render up-to-date stats about your blog into its README."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#happy-blogday",
    "href": "posts/2021-04-14-gha-readme/index.html#happy-blogday",
    "title": "Up-to-date blog stats in your README",
    "section": "Happy blogday",
    "text": "Happy blogday\nThis blog has been knocking around for three years now. I wrote a post on its first birthday with a simple, interactive 2D plot of the posts to date.\nOnly now, two years later, have I thought to put this info into the blogâ€™s README on GitHubâ€”along with some other little stats, like total number of postsâ€”and have it update automatically on a schedule using a GitHub Action.1\nThis is useful for me so I can keep track of things without counting on my fingers, but it also signals activity on the blog to any curious visitors. I may change its content at some point, but it does what I want it to do for now."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#unwrap-your-github-action",
    "href": "posts/2021-04-14-gha-readme/index.html#unwrap-your-github-action",
    "title": "Up-to-date blog stats in your README",
    "section": "Unwrap your GitHub Action",
    "text": "Unwrap your GitHub Action\nIâ€™ve scheduled a GitHub Action for the early hours of each day. The YAML file for it reads like â€˜at the specified time2, set up a remote environment with R and some dependencies, then render the R Markdown file and push the changes to GitHub.â€™\nIâ€™ve modified r-libâ€™s pre-written YAML for this, which can be generated in the correct location in your project with usethis::use_github_action(\"render-rmarkdown.yaml\").\n\n\nClick for the GitHub Action YAML\n\nname: Render README\n\non:\n  schedule:\n    - cron: '09 05 * * *'\n\njobs:\n  render:\n    name: Render README\n    runs-on: macOS-latest\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@v1\n      - uses: r-lib/actions/setup-pandoc@v1\n      - name: Install CRAN packages\n        run: Rscript -e 'install.packages(c(\"remotes\", \"rmarkdown\", \"knitr\", \"tidyverse\"))'\n      - name: Install GitHub packages\n        run: Rscript -e 'remotes::install_github(\"hadley/emo\")'\n      - name: Render README\n        run: Rscript -e 'rmarkdown::render(\"README.Rmd\")'\n      - name: Commit results\n        run: |\n          git config --local user.email \"actions@github.com\"\n          git config --local user.name \"GitHub Actions\"\n          git commit README.md README_files/ -m 'Re-build README.Rmd' || echo \"No changes to commit\"\n          git push origin || echo \"No changes to commit\"\n\nBasically, the action knits the repoâ€™s README.Rmd (R Markdown format containing R code) to a counterpart README.md (GitHub-flavoured markdown), which is displayed when you visit the repo."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#party-time",
    "href": "posts/2021-04-14-gha-readme/index.html#party-time",
    "title": "Up-to-date blog stats in your README",
    "section": "PaRty time",
    "text": "PaRty time\nThe real magic is in some R code chunks at the top of the README.Rmd file itself. Thereâ€™s some R code there that uses {rvest} to scrape the archive page of the blog and create a dataframe of the titles, links and publish dates of each post.\n\n\nClick for the scraping code\n\n\n# Attach packages\nlibrary(tidyverse) # CRAN v1.3.0\nlibrary(rvest)     # CRAN v1.0.0\n\n# Scrape the rostrum.blog home page\nhtml &lt;- read_html(\"https://rostrum.blog/\")\n\n# Extract the post titles\ntitle &lt;- html %&gt;%\n  html_nodes(\".archive-item-link\") %&gt;%  # extract title node\n  html_text()                           # extract text\n\n# Extract the post URLs\nlink &lt;- html %&gt;% \n  html_nodes(\".archive-item-link\") %&gt;%  # extract title node\n  html_attr(\"href\")                     # extract href attribute\n\n# Extract the post dates\ndate &lt;- html %&gt;%\n  html_nodes(\".archive-item-date\") %&gt;%  # extract date nodes only\n  html_text() %&gt;%                       # extract text\n  str_replace_all(\"[:space:]\", \"\")      # remove newline/space\n\n# Dataframe of titles and dates\nposts &lt;- tibble(date, title link), %&gt;% \n  transmute(\n    n = nrow(.):1,             # number starting from first post\n    publish_date = ymd(date),  # convert to date class\n    title,                     # title text\n    link = paste0(\"https://www.rostrum.blog\", link)  # create full URL\n  )\n\n\nThat information can be cajoled to show some basic stats. The README includes inline R code that renders to show:\n\nthe total number of posts\nposting rates (posts per month and days per post)\nthe number of days since since the last post and a link to it\na clickable details block containing a table of all the posts to date\na simple 2D plot showing the distribution of posts over time3 (preview below)\n\n\n\nClick for plot code\n\n\n# Create plot object\np &lt;- posts %&gt;%\n  ggplot(aes(x = publish_date, y = 1)) +\n  geom_point(shape = \"|\", size = 10, stroke = 1, color = \"#1D8016\") + \n  theme_void()\n\n\n\nI also added a call to lubridate::today() at the bottom of the README.Rmd so itâ€™s obvious when the stats were last updated."
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#until-next-year",
    "href": "posts/2021-04-14-gha-readme/index.html#until-next-year",
    "title": "Up-to-date blog stats in your README",
    "section": "Until next year",
    "text": "Until next year\nFinally, and most importantly, I included a tiny Easter egg: an emoji balloon ðŸŽˆ will appear on the page when the README is rendered on the anniversary of the blogâ€™s inception.4"
  },
  {
    "objectID": "posts/2021-04-14-gha-readme/index.html#environment",
    "href": "posts/2021-04-14-gha-readme/index.html#environment",
    "title": "Up-to-date blog stats in your README",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 20:34:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html",
    "href": "posts/2021-02-02-sonify-covid/index.html",
    "title": "What does a year of COVID-19 sound like?",
    "section": "",
    "text": "Landing page of coronavirus.data.gov.uk dashboard."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#tldr",
    "href": "posts/2021-02-02-sonify-covid/index.html#tldr",
    "title": "What does a year of COVID-19 sound like?",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {sonify} package in R to represent a year of the UKâ€™s COVID-19 data in audio format. You can jump straight to the audio."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#listen-to-your-data",
    "href": "posts/2021-02-02-sonify-covid/index.html#listen-to-your-data",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Listen to your data",
    "text": "Listen to your data\nI watched an excellent talk at the rstudio::global(2021) conference by JooYoung Seo titled â€˜Accessible Data Science Beyond Visual Models: Non-Visual Interactions with R and RStudio Packagesâ€™. You can access the video or his blog on the subject.\nIn the talk he mentioned the {sonify} package for R, which lets you represent data with sound rather than with visuals. For example, values of x and y that increase linearly can be represented by a sound that rises in pitch.\nI wondered: what would COVID-19 data sound like, given itâ€™s been a year since the UKâ€™s first cases?"
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#covid-19-data",
    "href": "posts/2021-02-02-sonify-covid/index.html#covid-19-data",
    "title": "What does a year of COVID-19 sound like?",
    "section": "COVID-19 data",
    "text": "COVID-19 data\nGOV.UK, the UK governmentâ€™s website, has a â€˜daily dashboardâ€™ of COVID-19 statistics. There are four prominent statistics:\n\nCases (people tested positive)\nDeaths (deaths within 28 days of a positive test)\nHealthcare (patients admitted to hospital)\nTesting (virus tests conducted)\n\nThe downloads page contains these data and more, both UK-wide and at local levels. This post isnâ€™t an analysis, but I implore you to take a look a the data yourself and read the details about how the data were collected.\nHelpfully, you can generate a permanent API link from which to fetch data1. Here Iâ€™m grabbing the UK-wide stats mentioned above:\n\ndata &lt;- read.csv(\n  paste0(\n    \"https://api.coronavirus.data.gov.uk/v2/data\",\n    \"?areaType=overview\", # UK wide\n    \"&metric=newCasesBySpecimenDate\",  # cases\n    \"&metric=newDeaths28DaysByDeathDate\",  # deaths\n    \"&metric=newAdmissions\",  # healthcare\n    \"&metric=newVirusTests\",  # testing\n    \"&format=csv\"  # CSV output\n  ),\n  stringsAsFactors = FALSE\n)\n\nIâ€™ll apply some minor cleaning to order by date and isolate the first 365 days, which takes us to 28 January 2021.\n\ndata &lt;- data[order(data$date), ]  # order by date\ndata &lt;- data[1:365, ]  # first year\nrange(data$date)\n\n[1] \"2020-01-30\" \"2021-01-28\"\nI read this into R as a data.frame object with one row per day.\n\ntail(data[, c(1, 5:8)])\n\n         date newCasesBySpecimenDate newDeaths28DaysByDeathDate\n18 2021-01-23                  21851                       1151\n17 2021-01-24                  17191                       1134\n16 2021-01-25                  29976                       1152\n15 2021-01-26                  27036                       1044\n14 2021-01-27                  25720                       1093\n13 2021-01-28                  24092                       1083\n    newAdmissions newVirusTests\n18           3100        484485\n17           3109        412204\n16           2925        542893\n15           3136        596845\n14           3050        771710\n13           3039        753031\nHow quickly a year goes."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#av-functions",
    "href": "posts/2021-02-02-sonify-covid/index.html#av-functions",
    "title": "What does a year of COVID-19 sound like?",
    "section": "AV functions",
    "text": "AV functions\nYou can skip to the next section if you arenâ€™t interested in the code that will be producing the audio and plots.\n\nAudio\nIâ€™ve written a small function using sonify::sonify() to generate audio clips that represent each COVID-19 variable over time.\nYou pass sonify() your x and y points as you would the plot() function. It has a number of audio-related arguments that let you modify things like the waveform and interpolation, but Iâ€™m sticking to the defaults here. This produces a five-second clip in stereo, so youâ€™ll hear the sound move from left to right as you listen.\nThe {tuneR} package has the function tuneR::writeWav() to write out the audio to a local .wav file (my desktop in this case).\n\nsonify_covid &lt;- function(y, out_dir = \"~/Desktop\") {\n\n    tuneR::writeWave(\n      sonify::sonify(\n        x = as.Date(data$date), y = data[[y]],\n        play = FALSE  # suppress audio from playing\n      ),\n      file.path(out_dir, paste0(y, \".wav\"))\n    )\n  \n}\n\n# Apply the function each variable\npurrr::walk(names(data[5:8]), sonify_covid)\n\nThese clips are embedded above the plots in the section below. A download link is included on the player. If you have trouble playing or downloading any of the clips, you can also access them in a playlist on SoundCloud.\n\n\nVisual\nIâ€™m including plots so you can follow how the visuals map to the sound. The plots are going to be intentionally sparse because the focus of the post is the sound the data make. The function takes a COVID-19 variable from our dataset and plots it over time with {ggplot2}.\n\nlibrary(ggplot2)  # attach plotting package\n\nplot_covid &lt;- function(y) {\n\n  ggplot() +\n    geom_point(\n      aes(as.Date(data$date), data[[y]] / 1000),\n      shape = 21  # empty-circle character\n    ) +\n    labs(\n      caption = \"Data: https://coronavirus.data.gov.uk/\",\n      x = \"Date\", y = \"Count (thousands)\"\n    ) +\n    theme_minimal()\n  \n}\n\nYou can then pass in the variable like plot_covid(newAdmissions), although Iâ€™ve hidden this code in the next section."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#sonified",
    "href": "posts/2021-02-02-sonify-covid/index.html#sonified",
    "title": "What does a year of COVID-19 sound like?",
    "section": "COVID-19 sonified",
    "text": "COVID-19 sonified\nIn each clip, a higher pitch indicates a higher value; a more continuous tone indicates that the points are tightly distributed; and the sound moving from the left to right audio channel indicates change over time.\nAll of these datasets start on the same date, 30 January 2020, which is when the first cases were recorded according to the newCasesBySpecimenDate variable. They all end 365 days later on 28 January 2021.\nThese data are quite well suited to sonification, given the peaks and troughs. In particular, the death and healthcare variables spike quickly, fall back down, rise again, drop slightly and then peak once more. You wonâ€™t notice that initial spike for the cases variable, given the relatively lower testing rate at the time.\n\nCases\nThis audio and plot show the number of people who have tested positive over time.\n\n\n\n\n\n\n\n\nDeath\nThis audio and plot show the number of recorded deaths within 28 days of a positive test over time.\n\n\n\n\n\n\n\n\nHealthcare\nThis audio and plot show the number of patients admitted to hospital over time.\n\n\n\n\n\n\n\n\nTesting\nThis audio and plot show the number of virus tests conducted over time."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#coda",
    "href": "posts/2021-02-02-sonify-covid/index.html#coda",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Coda",
    "text": "Coda\nSonification has been used for a variety of applications during the pandemic as an alternate means of conveying the data.\nFor example, Jan Willem Tulp has created a page that â€˜dingsâ€™ each time thereâ€™s a new case around the world. For something more complex, Mark D. Temple has published in the BMC Bioinformatics journal a paper about sonifying the COVID-19 genome (!). Meanwhile, Pedro Pereira Sarmento has sonified data to investigate the impacts of COVID-19 on air pollution.\nIâ€™m probably not the first to sonify coronavirus data in this way, and probably not even the first to do it with R, but it seemed a good time to take a look (listen?) back on things. Iâ€™m interested to hear more about what approaches others have taken."
  },
  {
    "objectID": "posts/2021-02-02-sonify-covid/index.html#environment",
    "href": "posts/2021-02-02-sonify-covid/index.html#environment",
    "title": "What does a year of COVID-19 sound like?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 21:41:22 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "href": "posts/2023-06-21-wordup-tables/index.html#tldr",
    "title": "Convert a Word table to Markdown",
    "section": "tl;dr",
    "text": "tl;dr\nI made a function that shouldnâ€™t need to exist in an ideal world: it takes a copied Microsoft Word table and outputs a Markdown version (well, a Govspeak version)."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "href": "posts/2023-06-21-wordup-tables/index.html#govspeak-when-youre-spoken-to",
    "title": "Convert a Word table to Markdown",
    "section": "Govspeak when youâ€™re spoken to",
    "text": "Govspeak when youâ€™re spoken to\nIâ€™ve written about three painful things recently:\n\nForcing data scientists to expose their tools so we can all use and learn from them.\nâ€˜Rectangularisingâ€™ tables scraped out of a Word document via the {officer} package.\nEasier ways to coerce dataframe columns to their â€˜intendedâ€™ data type.\n\nToday I bring you a terrible Cerberus with these three heads1.\nThe challenge: sometimes public sector statisticians produce Word documents that need to be converted to a special type of simplified plaintext Markdown, called Govspeak, before they can be uploaded for publication as HTML files on GOV.UK2.\nThis is fine: we have specific publishing specialists who can take care of it. It can be a little tedious, however. What if we could speed up and make more efficient the process of converting from Word to Govspeak?\nThereâ€™s a specific Govspeak converter online that you can paste into. But it doesnâ€™t have full coverage of the things that might appear in a Word doc, including tables. Other online converters exist, but I donâ€™t think we should rely on third parties that are probably intended for producing general Markdown rather than Govspeak, specifically"
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "href": "posts/2023-06-21-wordup-tables/index.html#markdown-word-up.",
    "title": "Convert a Word table to Markdown",
    "section": "Markdown? Word up.",
    "text": "Markdown? Word up.\nIâ€™ve started an R package called {wordup} that aims to take a Word document and convert it to Govspeak. Itâ€™s early days in the sense that it doesnâ€™t yet do, wellâ€¦ very much. But I thought the package name was funny (if unoriginal) and worth squatting. Maybe Iâ€™ll never get around to developing it, who knows.\nTo install (which is really not worth it right now, unless you want to raise an issue or pull request):\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/wordup\")\nlibrary(wordup)\n\nFor now, the principle is that you can unzip a Word document to expose a bunch of xml files (yet another thing Iâ€™ve been writing about recently, lol) that contain all the information needed to build the Word document3. As such, you can read that xml and extract all the information, styles, etc, and massage it programmatically into Govspeak format.\nPart of the process will involve taking a Word table, specifically, and converting it to a Govspeak-friendly form. I figured this might be a nice standalone tool in its itself, so I had a stab at what it could look like."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "href": "posts/2023-06-21-wordup-tables/index.html#fantabulars",
    "title": "Convert a Word table to Markdown",
    "section": "Fantabulars",
    "text": "Fantabulars\nSo right now the wordup::table_to_govspeak() function (whose name could change at any time) does three things:\n\nHandles inputs.\nGuesses data types.\nApplies extra styles.\n\nYou can either (a) copy-paste a Word table into the function, or (b) simply copy it to the clipboard, where it can be read by the function using the {clipr} package. The function will take the stringâ€”which is basically tabs (\\t) to indicate gaps between cells and newlines (\\n) to indicate rowsâ€”and reorient it initially into a dataframe.\nOf course, all the columns will be character-class at this point. We can immediately run type.convert() over the whole dataframe to coerce each column to a more appropriate data type, if appropriate. So a character column composed of c(\"10\", \"20\", \"30) will become a numeric column of values c(10, 20, 30). But this doesnâ€™t work for numeric values that have symbols in them, like commas as thousands separators (1,200), per cent symbols (82%) and placeholder markers to indicate things like suppressed values ([c])4. To get around this, we can strip the nuisance characters and then see if what remains looks like a number.\nFinally, thereâ€™s some specific features of Govspeak tables that need attention. Itâ€™s acceptable to have row labels, where each value in every cell of the first column should be prefaced with an octothorpe (#), and totals columns, where the entire row should be emboldened with double-asterisks (**) either side of the cellsâ€™ values.\nWhat results can be sort ofâ€¦ magic really. You copy a Word table in its entirety to your clipboard, run the function, and bang: the Govspeak Markdown is returned. You can see this in action in the gif at the top of this page.\nSo I can literally copy a table like this to my clipboard:\n\n\n\nColumn 1\nColumn 2\nColumn 3\nColumn 4\nColumn 5\n\n\n\n\nX\n100\n1,000\n1%\n15\n\n\nY\n200\n2,000\n2%\n12\n\n\nZ\n300\n3,000\n3%\n[c]\n\n\nTotals\n600\n6,000\n6%\n[c]\n\n\n\nAnd run this:\n\nwordup::table_to_govspeak()\n\nTo print this (and have it copied to your clipboard as the message says):\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| X | 100 | 1,000 | 1% | 15 |\n| Y | 200 | 2,000 | 2% | 12 |\n| Z | 300 | 3,000 | 3% | [c] |\n| Totals | 600 | 6,000 | 6% | [c] |\nThe output table has been written to the clipboard.\nBoom. Note the crucial feature that the third, fourth and fifth columns are recognised as numericâ€”despite containing the strings ,, % and [c]â€”and therefore right-aligned (------:). This is entirely due to the argument ignore_regex, which defaults to removing commas, percentage symbols or anything in square brackets before it guesses what data type the column is5.\nAnd we can do fancy things like:\n\nwordup::table_to_govspeak(\n  has_row_titles = TRUE,\n  totals_rows = 4L\n)\n\nWhich outputs this thing:\n| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |\n| ------- | ------: | ------: | ------: | ------: |\n| # X | 100 | 1,000 | 1% | 15 |\n| # Y | 200 | 2,000 | 2% | 12 |\n| # Z | 300 | 3,000 | 3% | [c] |\n| # **Totals** | **600** | **6,000** | **6%** | **[c]** |\nThe output table has been written to the clipboard.\nOf course, in practice this might get a little more complicated if you need to manually specify in the function declaration that thereâ€™s a column of row titles or some totals rows. Pish-posh. The point is that I think this is probably better than trying to (a) write the Govspeak table by hand or (b) trying to use the Govspeak converter, which just doesnâ€™t work for this task. This also has mild, opinionated, Govspeak-related benefits over using a straightforward knitr::kable().\nIs this perfect? Ahaha, no. Thereâ€™s a lot to add or improve, but I think this is a decent start and solves a (niche) problem for now6."
  },
  {
    "objectID": "posts/2023-06-21-wordup-tables/index.html#environment",
    "href": "posts/2023-06-21-wordup-tables/index.html#environment",
    "title": "Convert a Word table to Markdown",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-04 09:56:28 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] wordup_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#tldr",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#tldr",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "tl;dr",
    "text": "tl;dr\nVersion 1.0 of the {rtweet} package has been released with breaking changes. Iâ€™ve updated the R script of londonmapbot so that its scheduled GitHub Action doesnâ€™t fail.\n\n Note\nlondonmapbot no longer posts to Twitter due to API changes. It can be found on Mastodon instead at botsin.space/@londonmapbot. You can read about that in a more recent post."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#new-hymn-sheet",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#new-hymn-sheet",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "New hymn sheet",
    "text": "New hymn sheet\nI wrote a Twitter bot a while ago called londonmapbot. See the recent talk at LondonR or the blogpost about its inception.\nBasically, an R script runs on schedule via a GitHub Action. It generates a random point in Greater London and pulls a corresponding satellite image from MapBox. The picture, the coordinates and an OpenStreetMap link are then posted to Twitter with the {rtweet} package.\nI updated recently the R script in the londonmapbot source code due to some breaking changes in {rtweet}, which LluÃ­s Revilla Sancho recently bumped to the landmark version 1.0. Congratulations!"
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#change-your-tune",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#change-your-tune",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Change your tune",
    "text": "Change your tune\nI made two major changes to the londonmapbot R script given {rtweet} v1.0:\n\nI used rtweet_bot() to authorise with the Twitter API, instead of create_token()\nI provided alt text with the media_alt_text argument to post_tweet()\n\nOther folks who use the same approach as londonmapbot will likely need to make these fundamental changes as well.1\nI also made a third changeâ€”to specify the filetype of the downloaded MapBox imageâ€”that will only be relevant if you forked londonmapbot or if your tweets use a downloaded image.\n\n1. Authentication\nYou need to authenticate with the Twitter API before a tweet can be posted.\nPrior to {rtweet} v1.0 you provided your tokens and keys in the create_token() function, but this will now fail with the error create_token() was deprecated in rtweet 1.0.0..\nThere are now three options for passing tokens and keys, depending on the need: rtweet_app(), rtweet_user() and rtweet_bot(). The last of these is what we need, because:\n\n[It] authenticates a bot that takes actions on behalf of an app [which] is most appropriate if you want to create a Twitter account that is run by a computer, rather than a human\n\nAs with create_token(), we still need to provide the api_key, api_secret, access_token and access_secret. As outlined in the first londonmapbot blogpost, these can be stored as named secrets in the GitHub repo itself and called into the environment with Sys.getenv().\nSo, I changed the R code to this:\n\nlondonmapbot_token &lt;- rtweet::rtweet_bot(\n  api_key       = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  api_secret    = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token  = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\nWhere it was previously this:\n\nlondonmapbot_token &lt;- rtweet::create_token(\n  app = \"londonmapbot\",\n  consumer_key    = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  consumer_secret = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token    = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret   = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\nNote that you no longer need to pass the app name as an argument and that you use api_* rather than consumer_* in the arguments.\n\n\n2. Alt text\nYou can no longer post an image without alt text, which is a positive move for the package. If you try to upload without alt text, youâ€™ll get Error: Media and alt_text must be character vectors.\nTo add alt text, you must add the argument media_alt_text to the post_tweet() function.\nSince the sampled location is different in every londonmapbot tweet, itâ€™s not ideal to provide a single blanket statement for all images that are returned from MapBox. Sometimes the image will contain an airport, sometimes the Thames, usually a golf course.\nFor now Iâ€™ve settled on a fixed string that will be posted as the alt text for every image. This is better than nothing, but should be improved so that itâ€™s more dynamic.\nMaybe we could infer something from the average colour of the image (I wrote about this before) or maybe predict what the terrain is, given thereâ€™s plenty of training data from old londonmapbot tweets.\nRegardless, I added alt text to the code like this:\n\nalt_text &lt;- paste(\n  \"A satellite image of a random location in Greater London,\",\n  \"provided by MapBox. Typically contains a residential or\",\n  \"industrial area, some fields or a golf course.\"\n)\n\nrtweet::post_tweet(\n  status         = latlon_details,\n  media          = temp_file,\n  media_alt_text = alt_text,\n  token          = londonmapbot_token\n)\n\nWhere it was previously like this:\n\nrtweet::post_tweet(\n  status = latlon_details,\n  media  = temp_file,\n  token  = londonmapbot_token\n)\n\nSee the image at the top of this blogpost for an example of the alt text now provided to each londonmapbot tweet.\n\n\n3. File extension\nThe R script behind londonmapbot downloads a MapBox satellite image to a temporary file created with tempfile(). It was always bad practice to omit the argument fileext = \".jpeg\" from this function, which is used to provide a file extension to the temporary filepath of the downloaded image.\nI noticed that the absence of an explicit file extension seemed to be causing an error in the execution of the R script, so I made sure to change the code to this:\n\ntemp_file &lt;- tempfile(fileext = \".jpeg\")\ndownload.file(img_url, temp_file)\n\nFrom this:\n\ntemp_file &lt;- tempfile()\ndownload.file(img_url, temp_file)\n\nA subtle change, but a necessary one. You may need to do this too if you followed what londonmapbot was doing previously."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#rest",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#rest",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Rest",
    "text": "Rest\nThis post may not have impacted you if you arenâ€™t the in niche user group of â€˜people who may have forked or used a repo template for londonmapbot to adapt and make their own Twitter bot based on {rtweet} and GitHub Actions, or otherwise used it as inspiration to create their own botâ€™.2\nBut itâ€™s worth recording this in long-form in case you ever come across the sorts of {rtweet} errors Iâ€™m talking about here."
  },
  {
    "objectID": "posts/2022-07-22-mapbot-rtweet-v1/index.html#environment",
    "href": "posts/2022-07-22-mapbot-rtweet-v1/index.html#environment",
    "title": "Fixing londonmapbot for {rtweet} v1.0",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:12:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html",
    "href": "posts/2021-06-28-sprite-grid/index.html",
    "title": "Very simple pixel art in R",
    "section": "",
    "text": "Itâ€™s dangerous to code aloneâ€¦"
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#tldr",
    "href": "posts/2021-06-28-sprite-grid/index.html#tldr",
    "title": "Very simple pixel art in R",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use Râ€™s image() function to convert a matrix to a pixelly graphic.\n\n Note\nIâ€™ve now written a little R package called {pixeltrix}, which lets you click on squares in a plot window to generate a matrix of â€˜pixelsâ€™. This means you donâ€™t have to type out any vectors by hand. You can read more in some other blog posts."
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#pixel-fixation",
    "href": "posts/2021-06-28-sprite-grid/index.html#pixel-fixation",
    "title": "Very simple pixel art in R",
    "section": "Pixel fixation",
    "text": "Pixel fixation\nMy last post was about the {emojiscape} package, which makes a little scene out of sampled emojis.\nFollowing a similar approach, you could write a matrix by hand and plot it via the base function image(). Hereâ€™s a very basic example with a â€˜gliderâ€™ from Conwayâ€™s Game of Life. Values of 0 are â€˜deadâ€™ cells and values of 1 are â€˜liveâ€™.\n\nglider_v &lt;- c(0,0,0,0,0, 0,0,1,0,0, 0,0,0,1,0, 0,1,1,1,0, 0,0,0,0,0)\nglider_m &lt;- matrix(glider_v, 5)           # convert to matrix\nglider_m &lt;- glider_m[, ncol(glider_m):1]  # reverse cols\npar(mar = rep(0, 4))                      # ensure no margins\nimage(glider_m)                           # plot it\n\n\n\n\nNote that I input the vector values from what would become the top left to bottom right of the output matrix. The image() function doesnâ€™t read them in this order, however, so Iâ€™ve added a step to reverse the column order so the plot output appears as I intended.\nAlso, image() normally outputs with labelled axes, but we can effectively hide those by minimising the margins par()ameter of the plot to 0."
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#reprologoducibility",
    "href": "posts/2021-06-28-sprite-grid/index.html#reprologoducibility",
    "title": "Very simple pixel art in R",
    "section": "Reprologoducibility",
    "text": "Reprologoducibility\nBut really my motivation is to make a reproducible version of this blogâ€™s logo: an insect composed of â€˜pixelsâ€™ in a 16-by-16 square.\nSo, Iâ€™ve hand-coded a binary vector of length 256 (i.e.Â 16 * 16). The 0s and 1s here represent background and insect pixels, respectively. Iâ€™ve used line breaks to make it easier to create and edit the vector manually.\nHereâ€™s the vector that represents the logo:\n\nlogo_v &lt;- c(\n  \n  0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,\n  0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,\n  0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,\n  0,0,1,0,0,1,0,1,1,0,1,0,0,1,0,0,\n  \n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,0,\n  0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,\n  0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,\n  \n  0,0,1,0,1,1,0,1,1,0,1,1,0,1,0,0,\n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,0,0,1,0,1,1,0,1,0,0,0,0,0,\n  0,0,0,0,1,1,0,1,1,0,1,1,0,0,0,0,\n  \n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,0,1,0,1,0,1,1,0,1,0,1,0,0,0,\n  0,0,1,0,0,1,0,1,1,0,1,0,0,1,0,0,\n  0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0\n\n)\n\nI might as well make a (non-generic) function to matrixify (definitely a word) and plot the vector, so I can then tweak a few parameters as I please.\n\nplot_logo &lt;- function(\n  x = logo_v,           # vector\n  px = 16,              # width/length of output (square)\n  col_0 = \"black\",      # colour for values of 0\n  col_1 = \"#1e8016\",    # colour for values of 1\n  lwd = 8               # to separate the squares\n) {\n  \n  par(mar = rep(0, 4))  # set margins outside plot region\n  \n  m &lt;- matrix(x, px)    # create a matrix from the vector\n  m &lt;- m[, ncol(m):1]   # reverse cols\n  \n  image(m, col = c(col_0, col_1))  # plot matrix, colour by number\n  \n  # If line width provided, draw lines between squares\n  if (!is.null(lwd)) {\n    px_half &lt;- px * 2\n    s &lt;- seq(-1 / px_half, 1 + (1 / px_half), 1 / (px - 1))\n    abline(h = s, v = s, col = col_0, lwd = lwd)\n  }\n  \n}\n\nNote that I added a line width argument (lwd). If specified, horizontal and vertical lines are drawn to give the impression that the squares are â€˜separatedâ€™ from each other.\nHereâ€™s the logo.\n\nplot_logo(lwd = 2)\n\n\n\n\nAnd hereâ€™s what happens if we remove the lines and swap the colours, for example.\n\nplot_logo(col_0 = \"#1e8016\", col_1 = \"black\", lwd = NULL)\n\n\n\n\nAnd given itâ€™s Pride Month:\n\nfor (i in rainbow(7)) {\n  plot_logo(lwd = 1, col_0 = \"white\", col_1 = i)\n}"
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#sprite-delight",
    "href": "posts/2021-06-28-sprite-grid/index.html#sprite-delight",
    "title": "Very simple pixel art in R",
    "section": "Sprite delight",
    "text": "Sprite delight\nThis approach is basically pixel-art-by-numbers, right?\nSo Iâ€™ve written and animated two frames of a classic videogame character, Link from The Legend of Zelda on the NES, using the {magick} package to create a gif.\nThereâ€™s four colours in this one, so the vectors are no longer binary: thereâ€™s 0 for the background, 1 for green, 2 for skin and 3 for the darker spots.\nThe top part of the sprite doesnâ€™t change between frames, but the bottom does. To avoid repetition, we can store the top part as a separate vector, then combine it with each frameâ€™s lower section. Itâ€™s still a bit of a slog to input these by hand!\n\nlink_v_top &lt;- c(\n  0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,\n  0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,\n  0,0,2,0,1,3,3,3,3,3,3,1,0,2,0,0,\n  0,0,2,0,3,3,3,3,3,3,3,3,0,2,0,0,\n  \n  0,0,2,2,3,2,1,2,2,1,2,3,2,2,0,0,\n  0,0,2,2,3,2,3,2,2,3,2,3,2,2,0,0,\n  0,0,0,2,2,2,2,2,2,2,2,2,2,3,0,0\n)\n\nlink_v_b1 &lt;- c(\n  0,0,0,1,1,2,2,3,3,2,2,1,1,3,0,0,\n  \n  0,3,3,3,3,3,2,2,2,2,1,1,3,3,3,0,\n  3,3,2,3,3,3,3,1,1,1,1,1,2,3,3,0,\n  3,2,2,2,3,3,2,3,3,1,1,2,2,2,3,0,\n  3,3,2,3,3,3,2,1,3,3,3,3,2,2,2,0,\n  \n  3,3,2,3,3,3,2,3,3,1,1,1,1,2,0,0,\n  3,3,3,3,3,3,2,1,1,1,1,1,0,0,0,0,\n  0,2,2,2,2,2,3,0,0,3,3,3,0,0,0,0,\n  0,0,0,0,3,3,3,0,0,0,0,0,0,0,0,0\n)\n\nlink_v_b2 &lt;- c(\n  0,0,0,0,1,2,2,3,3,2,2,1,3,3,0,0,\n  \n  0,0,3,3,3,3,3,2,2,2,1,1,1,2,0,0,\n  0,3,3,2,3,3,3,3,1,1,1,1,1,2,0,0,\n  0,3,2,2,2,3,3,2,3,3,1,1,3,0,0,0,\n  0,3,3,2,3,3,3,2,1,3,3,3,1,0,0,0,\n  \n  0,3,3,2,3,3,3,2,3,3,1,1,1,0,0,0,\n  0,3,3,3,3,3,3,2,1,1,1,3,0,0,0,0,\n  0,0,2,2,2,2,2,0,0,3,3,3,0,0,0,0,\n  0,0,0,0,0,0,0,0,0,3,3,3,0,0,0,0\n)\n\n# Combine vectors to get frames\nlink_f1 &lt;- c(link_v_top, link_v_b1)\nlink_f2 &lt;- c(link_v_top, link_v_b2)\n\nNow we have the vectors representing Link for each frame of the animation. The approach now is like before: convert this to a 16 by 16 matrix and plot it. This time Iâ€™ve got a function that also saves the plots by first opening a png() graphics device and closing it at the end with dev.off(). Iâ€™ve saved these to a temporary directory for the purposes of the post, rather than my local disk.\n\ntmp &lt;- tempdir()  # store temporary folder path\n\n# Function to write frame to temporary folder\nwrite_link &lt;- function(vec) {\n  write_path &lt;- file.path(tmp, paste0(substitute(vec), \".png\"))\n  png(write_path, width = 160, height = 160)\n  link_m &lt;- matrix(vec, 16)\n  link_m &lt;- link_m[, ncol(link_m):1]\n  par(mar = rep(0, 4))\n  link_cols &lt;- c(\"white\", \"#7bc702\", \"#cc8f2d\", \"#6c430a\")\n  image(link_m, col = link_cols)\n  dev.off()\n}\n\n# Write the frames\nwrite_link(link_f1); write_link(link_f2)\n\nquartz_off_screen \n                2 \n\n\nquartz_off_screen \n                2 \n\n\nWe get a couple of messages to say that the devices have been closed, confirming the save.\nNow we can use the {magick} package to create a gif: image_read() to load both PNG frames into a single object from their save location, and then image_animate() to combine the images into an output that flips between the two frames. You could also use image_write() to save this object to gif format.\n\n# Generate a gif from the saved frames\npng_paths &lt;- list.files(tmp, \"*.png$\", full.names = TRUE)     # get file paths\nframes &lt;- magick::image_read(png_paths)                       # load the files\nmagick::image_animate(frames, fps = 2, dispose = \"previous\")  # combine frames\n\n\n\n\nIâ€™m not sure Iâ€™ll be coding the graphics for the whole game anytime soonâ€¦"
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#hip-to-be-square",
    "href": "posts/2021-06-28-sprite-grid/index.html#hip-to-be-square",
    "title": "Very simple pixel art in R",
    "section": "Hip to be square",
    "text": "Hip to be square\nIâ€™m not the first person to think or do this in R, Iâ€™m sure.\nI did come across a really neato {pixelart} package and Shiny app by Florian PrivÃ© where you upload an image and it gets converted into a pixel form. As Florian said in his blogpost:\n\nKids and big kids can quickly become addicted to this\n\nYes. And thatâ€™s exactly why this post exists.\nLet me know if you know of any more packages or whatever that do this sort of thing.\n\n Note\nTurns out that mikefc, aka coolbutuseless, (who else?) wrote a great blog post with a method for grabbing, plotting and animating sprites with the packages {png}, {raster}, {ggplot2} and {gganimate}. Slightly less painful than writing vectors by hand!\nIf you want to design your own sprites rather than copy others, try my little {pixeltrix} package for interactive pixel selection from a plot window, which returns a matrix."
  },
  {
    "objectID": "posts/2021-06-28-sprite-grid/index.html#environment",
    "href": "posts/2021-06-28-sprite-grid/index.html#environment",
    "title": "Very simple pixel art in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:34:30 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7        magick_2.7.4     \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html",
    "href": "posts/2021-03-07-xml-health/index.html",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "",
    "text": "Run barcode: one year of runs, darker bands are longer distances."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#tldr",
    "href": "posts/2021-03-07-xml-health/index.html#tldr",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can export your Apple Health data as an XML file. This includes workouts linked from other apps, like Nike Run Club. I used the R packages {xml2} and the tidyverse to extract and clean my step counts and running activity.\n\n Note\nI revisited the theme of this post in 2023, but the format of the Apple Health download had changed. I updated the code needed to analyse the data and wrote a new post."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#app-storage",
    "href": "posts/2021-03-07-xml-health/index.html#app-storage",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "App storage",
    "text": "App storage\nMy healthcare provider peeks at the Apple Health app and rewards me if I meet daily step-count targets. I know my usual pattern of steps has been disrupted since the start of COVID-19 lockdowns, which began in the UK a year ago today.\nTo keep the step counter ticking over, I took up a new hobby on lockdown day one: running. Iâ€™ve recorded this activity on the Nike Run Club app, which Iâ€™ve linked to Apple Health.\nIâ€™ve in excess of 99 problems and at least two of them are related specifically to these health data:\n\nI donâ€™t think my healthcare supplier is rewarding my step counts correctly and I need evidence1\nItâ€™s not easy to get data out of the Nike Run Club app for further analysis\n\nLuckily, you can export the dataâ€”which is stored locally on your iPhoneâ€”including any workouts linked from other apps. Itâ€™s provided as XML, which is a sensible, structured storage format, but not necessarily that familiar to the general R user.\nThis post looks at how to extract the data of interest and do something useful with it."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#warm-up",
    "href": "posts/2021-03-07-xml-health/index.html#warm-up",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Warm up",
    "text": "Warm up\nTo export activity data from the Health app (iOS 14.4):\n\nOpen the Health app and tap your icon in the top right corner\nScroll down and tap â€˜Export All Health Dataâ€™\nTap â€˜Exportâ€™ in the pop-up and the sharing tray will slide up for you to choose where to send the data\n\nYouâ€™ll get a zipped folder containing two XML files, export_cda.xml and export.xml, the latter of which contains your data. I stored and unzipped my folder locally for the purposes of this post.\n\ntemp &lt;- tempdir()\nunzip(zipfile = \"~/Downloads/export.zip\", exdir = temp)\n\nMy unzipped folder was about 140 MB and contained about 5 years of data.\nWeâ€™ll also need a few R packages. The {xml2} package is on CRAN2 and has the tools you need to read and reshape XML files. It may be familiar if youâ€™ve ever done any webscraping with R.3\nWeâ€™ll also iterate to accumulate with the {purrr} package and do the olâ€™ wrangle-jangle with some other tidyverse packages.\n\nlibrary(xml2)       # read and wrangle XML\nlibrary(tidyverse)  # {purrr}, {dplyr}, {ggplot2}, {forcats}\nlibrary(lubridate)  # date/time handling"
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#x-tract",
    "href": "posts/2021-03-07-xml-health/index.html#x-tract",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "X-tract",
    "text": "X-tract\nThe aptly named xml2::read_xml() function will let you read your export.xml file.\n\nxml_in &lt;- read_xml(file.path(temp, \"apple_health_export/export.xml\"))\n\nHereâ€™s a truncated view of the fileâ€™s structure:\n\nxml_in\n\n{xml_document}\n&lt;HealthData locale=\"en_GB\"&gt;\n [1] &lt;ExportDate value=\"2021-03-21 17:03:31 +0000\"/&gt;\n [2] &lt;Me HKCharacteristicTypeIdentifierDateOfBirth=\"\" HKCharacteristicTypeIde ...\n [3] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MDâ€™s phone\" ...\n [4] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MDâ€™s phone\" ...\n [5] &lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MDâ€™s phone\" ...\n....\n\n\nThe object has the class xml_document. You can see metadata in the first few rows and then you can see the actual data is stored in a series of â€˜nodesâ€™. Each record is an individual entry in our activity log and has attributes like type (e.g.Â step count), sourceName (i.e.Â the device name) and unit (e.g.Â a count).\nWeâ€™re interested in extracting data from two types of node:\n\nRecord for the step counts, as previewed above\nWorkouts, which is where the Nike Run Club app data is stored\n\nYou can extract specific parts of an XML file by reference to their xpaths, which are special regex-like strings that point to specific places in the document. The function xml2::xml_find_all() takes an xpath and returns the matching information.\nWe need only supply the simple high-level xpaths //Record and //Workouts for our needs. The forward slashes read like â€˜select all the nodes in the document with the following nameâ€™.\nOnce extracted, we can get the attributesâ€”like type, sourceName, etcâ€”of each node using xml2::xml_attr()."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#step-to-it",
    "href": "posts/2021-03-07-xml-health/index.html#step-to-it",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Step to it",
    "text": "Step to it\nSo, letâ€™s grab all the â€˜recordâ€™ nodes and preview the first one.\n\nrecords &lt;- xml_find_all(xml_in, \"//Record\")\nrecords[[1]]\n\n{xml_node}\n&lt;Record type=\"HKQuantityTypeIdentifierStepCount\" sourceName=\"MDâ€™s phone\" unit=\"count\" creationDate=\"2015-06-21 16:57:31 +0000\" startDate=\"2015-06-21 16:31:17 +0000\" endDate=\"2015-06-21 16:33:00 +0000\" value=\"28\"&gt;\n\n\nEach record is a single â€˜boutâ€™ of activity as perceived by the app. You can see the first record is a step count from my phone on 21 June 2015, which lasted about two minutes and consisted of 28 steps.\nFor my purposes I only care about three attributes: the date4, the type of activity and the associated value. We can pass a named vector of each attribute to xml2::xml_attr() using purrr::map_dfr() to collate the output into a tidy rectangle.\n\nrecords_df &lt;- map_dfr(  # rowbind to dataframe\n  c(date = \"creationDate\", type = \"type\", steps = \"value\"),\n  ~xml_attr(records, .x)\n)\n\nglimpse(records_df)  # preview\n\nRows: 487,590\nColumns: 3\n$ date  &lt;chr&gt; \"2015-06-21 16:57:31 +0000\", \"2015-06-21 16:57:31 +0000\", \"2015-â€¦\n$ type  &lt;chr&gt; \"HKQuantityTypeIdentifierStepCount\", \"HKQuantityTypeIdentifierStâ€¦\n$ steps &lt;chr&gt; \"28\", \"15\", \"44\", \"69\", \"80\", \"95\", \"1\", \"33\", \"41\", \"15\", \"24\",â€¦\n\n\nSo what type of activity has been logged in the Record nodes?\n\npull(distinct(records_df, type))\n\n [1] \"HKQuantityTypeIdentifierStepCount\"                     \n [2] \"HKQuantityTypeIdentifierDistanceWalkingRunning\"        \n [3] \"HKQuantityTypeIdentifierActiveEnergyBurned\"            \n [4] \"HKQuantityTypeIdentifierFlightsClimbed\"                \n [5] \"HKQuantityTypeIdentifierHeadphoneAudioExposure\"        \n [6] \"HKQuantityTypeIdentifierWalkingDoubleSupportPercentage\"\n [7] \"HKQuantityTypeIdentifierWalkingSpeed\"                  \n [8] \"HKQuantityTypeIdentifierWalkingStepLength\"             \n [9] \"HKQuantityTypeIdentifierWalkingAsymmetryPercentage\"    \n[10] \"HKCategoryTypeIdentifierSleepAnalysis\"                 \n[11] \"HKCategoryTypeIdentifierMindfulSession\"                \n\n\nIâ€™m interested in step counts, so Iâ€™ll isolate HKQuantityTypeIdentifierStepCount, convert the date to datetime class and then summarise the number of steps per day.\n\nrecords_out &lt;- records_df %&gt;% \n  filter(type == \"HKQuantityTypeIdentifierStepCount\") %&gt;%\n  mutate(date = as.Date(date), steps = as.integer(steps)) %&gt;%\n  group_by(date) %&gt;%\n  summarise(steps = sum(steps), .groups = \"drop\") %&gt;% \n  mutate(\n    points = case_when(\n      steps &gt; 12500 ~ 8L, steps &gt; 10000 ~ 5L, steps &gt; 7000 ~ 3L,\n      TRUE ~ 0L\n    )\n  )\n\nglimpse(records_out)\n\nRows: 2,094\nColumns: 3\n$ date   &lt;date&gt; 2015-06-21, 2015-06-22, 2015-06-23, 2015-06-24, 2015-06-25, 20â€¦\n$ steps  &lt;int&gt; 647, 11273, 10071, 3586, 5206, 10362, 19036, 3980, 11850, 15937â€¦\n$ points &lt;int&gt; 0, 5, 5, 0, 0, 5, 8, 0, 5, 8, 3, 5, 5, 0, 0, 5, 5, 3, 0, 8, 8, â€¦\n\n\nI also created a new column that generates a â€˜pointsâ€™ value that my healthcare provider assigns to meeting certain step-count thresholds. Now I, tiny David, can sling this evidence into the eye of the behemoth cyclops that is my healthcare provider.\nI recommend checking first if the data look sensible, because my highest step count was apparently 10,692,175. I donâ€™t recall walking to Chicago and back to London on that day.\n\nOn a walkabout\nThereâ€™s so many ways you could investigate the step count data, like how frequency changes by day of the week or time of year, for example.\nHereâ€™s a quick exploration: how did my step-count frequency change in the year up to 23 March 2020â€”the announcement of the UKâ€™s first lockdownâ€”and in the year since?\n\nrecords_out %&gt;% \n  mutate(\n    covid_year = case_when(\n      date &gt;= \"2020-03-23\" & date &lt; \"2021-03-23\" ~ \"Year post-lockdown\",\n      date &gt;= \"2019-03-23\" & date &lt; \"2020-03-23\" ~ \"Year pre-lockdown\", \n      TRUE ~ NA_character_\n    )\n  ) %&gt;% \n  filter(!is.na(covid_year)) %&gt;% \n  ggplot() + \n  geom_histogram(aes(steps / 1000), binwidth = 1) + \n  facet_grid(~fct_rev(covid_year)) +\n  labs(x = \"Steps (thousands)\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\nHa, not a surprise, but interesting to see it visually: thereâ€™s been a far higher proportion of days with a very small number of steps in the lockdown year. The second peak of the bimodal distribution has also fallen to a lower value with a more gradual tail. This is understandable: I used to walk on parts of my commute and lunchtimes, whereas my lockdown days have involved running or basically nothing."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#jog-on",
    "href": "posts/2021-03-07-xml-health/index.html#jog-on",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Jog on",
    "text": "Jog on\nNow letâ€™s look at the yearâ€™s worth of running data from the Workout nodes of the XML.\n\nworkouts &lt;- xml_find_all(xml_in, \"//Workout\")\nworkouts[[1]]\n\n{xml_node}\n&lt;Workout workoutActivityType=\"HKWorkoutActivityTypeRunning\" duration=\"24.81425000031789\" durationUnit=\"min\" totalDistance=\"5.043024469383905\" totalDistanceUnit=\"km\" totalEnergyBurned=\"384.382\" totalEnergyBurnedUnit=\"kcal\" sourceName=\"Nike Run Club\" sourceVersion=\"2003161908\" creationDate=\"2020-03-23 08:01:39 +0000\" startDate=\"2020-03-23 07:36:45 +0000\" endDate=\"2020-03-23 08:01:39 +0000\"&gt;\n[1] &lt;MetadataEntry key=\"HKIndoorWorkout\" value=\"0\"/&gt;\n[2] &lt;WorkoutEvent type=\"HKWorkoutEventTypePause\" date=\"2020-03-23 08:01:34 +0 ...\n\n\nThe attributes are slightly different for workouts compared to records. This time I care about the activity type (just runs), the date, the distance and the time taken. Unfortunately there isnâ€™t any data on split times in this file, which means I canâ€™t calculate record times, nor is there other detail like altitude gained.\n\nworkouts_df &lt;- map_dfr(\n  c(date = \"creationDate\", type = \"workoutActivityType\",\n    km = \"totalDistance\", dur = \"duration\"),\n  ~xml_attr(workouts, .x)\n) \n\nglimpse(workouts_df)\n\nRows: 215\nColumns: 4\n$ date &lt;chr&gt; \"2020-03-23 08:01:39 +0000\", \"2020-03-25 08:14:38 +0000\", \"2020-0â€¦\n$ type &lt;chr&gt; \"HKWorkoutActivityTypeRunning\", \"HKWorkoutActivityTypeRunning\", \"â€¦\n$ km   &lt;chr&gt; \"5.043024469383905\", \"5.0160254470843\", \"5.014558848776319\", \"5.0â€¦\n$ dur  &lt;chr&gt; \"24.81425000031789\", \"24.46356666882833\", \"24.37278333504995\", \"2â€¦\n\n\nWe can do a bit of light wrangling to convert â€˜decimal minutesâ€™ to seconds, compute a rough pace, and round the values for readability. I used lubridate::seconds_to_period() to generate a period-class value that presents the data in days, hours, minutes and seconds.\n\nworkouts_out &lt;- workouts_df %&gt;% \n  filter(type == \"HKWorkoutActivityTypeRunning\", km &gt; 1) %&gt;% \n  mutate(\n    date = as.Date(date),\n    across(c(dur, km), as.numeric), dur = round(dur, 3)\n  ) %&gt;% \n  separate(col = dur, into = c(\"mins\", \"mins_dec\"), sep = \"\\\\.\") %&gt;% \n  transmute(\n    date, km,\n    s = (as.numeric(mins) * 60) + ((as.numeric(mins_dec) / 1000) * 60),\n    mins = seconds_to_period(round(s)),\n    avg_pace = seconds_to_period(round(s / km)),\n    s = round(s), km = round(km, 2)\n  )\n\nglimpse(workouts_out)\n\nRows: 164\nColumns: 5\n$ date     &lt;date&gt; 2020-03-23, 2020-03-25, 2020-03-27, 2020-03-29, 2020-03-31, â€¦\n$ km       &lt;dbl&gt; 5.04, 5.02, 5.01, 5.03, 5.03, 5.02, 5.02, 5.02, 5.01, 5.02, 5â€¦\n$ s        &lt;dbl&gt; 1489, 1468, 1462, 1545, 1476, 1435, 1414, 1468, 1410, 1366, 1â€¦\n$ mins     &lt;Period&gt; 24M 49S, 24M 28S, 24M 22S, 25M 45S, 24M 36S, 23M 55S, 23M â€¦\n$ avg_pace &lt;Period&gt; 4M 55S, 4M 53S, 4M 52S, 5M 7S, 4M 53S, 4M 46S, 4M 42S, 4M â€¦\n\n\n\nHigh-vis apparel\nThe data are now quite rich and thereâ€™s many ways to explore it. As a starter, hereâ€™s some basic summaries for the year to 23 March 2021:\n\nworkouts_out %&gt;% \n  summarise(\n    `Total runs` = n(),\n    `Total distance (km)` = round(sum(km)),\n    `Total time` = seconds_to_period(sum(s)),\n    `Days per run` = round((max(date) - min(date)) / `Total runs`, 1),\n    `Best average pace` = seconds_to_period(min(round(s / km))),\n    `Total runs of 5 to 10 km` = nrow(filter(., km &gt;= 5 & km &lt; 10)),\n    `Total runs of 10 to 21.1 km` = nrow(filter(., km &gt;= 10 & km &lt; 21.1)),\n    `Total runs of over 21.1 km` = nrow(filter(., km &gt; 21.1))\n  ) %&gt;% \n  mutate(across(everything(), as.character)) %&gt;% \n  pivot_longer(everything(), names_to = \"Summary\", values_to = \"Value\") %&gt;% \n  knitr::kable()\n\n\n\n\nSummary\nValue\n\n\n\n\nTotal runs\n164\n\n\nTotal distance (km)\n1306\n\n\nTotal time\n4d 14H 39M 15S\n\n\nDays per run\n2.2\n\n\nBest average pace\n4M 22S\n\n\nTotal runs of 5 to 10 km\n98\n\n\nTotal runs of 10 to 21.1 km\n62\n\n\nTotal runs of over 21.1 km\n3\n\n\n\n\n\nIn terms of visualisation, Iâ€™m interested in what my pattern of run distance looks like. The code below produces plots for run distances by date (top left), cumulative distance by date (bottom left), and a histogram of run distances in 1 km bins (right).\n\np1 &lt;- ggplot(workouts_out) + \n  geom_point(aes(date, km), shape = 1) +\n  labs(x = \"\", y = \"Distance (km)\") +\n  theme_light()\n\np2 &lt;- workouts_out %&gt;% \n  mutate(km_cum = cumsum(km)) %&gt;% \n  ggplot() +\n  geom_line(aes(date, km_cum)) +\n  labs(x = \"\", y = \"Cumulative distance (km)\") +\n  theme_light()\n\np3 &lt;- ggplot(workouts_out) +\n  geom_histogram(aes(km), binwidth = 1) +\n  labs(x = \"Distance (1 km bins)\", y = \"Frequency\") +\n  theme_light()\n\nlibrary(patchwork)  # easy plot layouts\n(p1 / p2) | p3\n\n\n\n\nYou can see I started with a lot of 5 km runs in April and May 2020, before branching out to 10 km or more. Iâ€™ve been pretty consistent in running every two or three days and thatâ€™s reflected in the chart of cumulative distance. The histogram shows that most runs have been just above 5 km, with another peak just above 10 km. That makes sense: I intentionally set out to run at least these distances.\nAnother idea is that you you could use the {calendR} package to plot a calendar of your activity.5 Or you could do something more abstract: hereâ€™s a â€˜run barcodeâ€™ with a line per run for the full year. The darker the line, the further the distance travelled.\n\nrun_days &lt;- left_join(\n  tibble(date = as_date(ymd(\"2020-03-23\"):ymd(\"2021-03-22\"))),\n  workouts_out %&gt;% \n    filter(date &gt;= \"2020-03-23\" & date &lt; \"2021-03-23\") %&gt;%\n    group_by(date) %&gt;% summarise(km = sum(km), .groups = \"drop\"),\n  by = \"date\"\n) %&gt;% replace_na(list(run = 0))\n\npar(mar = rep(0, 4))\nimage(matrix(run_days$km), col = grey.colors(11, 0.8, 0))\nbox(col = \"white\")\n\n\n\n\nA few things stick out to me when scanning this barcode. The three black bands are the half-marathons; the white space (i.e.Â no runs) after the first of these indicates the rest my knees needed afterwards. Thereâ€™s a thick grey band after halfway, which is when I tried to run seven days in a row (the app is gamified and you get a special badge for doing that). You can also see how the pattern was more regular at the start, but Iâ€™ve since settled into a routine of just trying to fit in three runs and about 25 km per week."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#cool-down",
    "href": "posts/2021-03-07-xml-health/index.html#cool-down",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Cool down",
    "text": "Cool down\nSo the premise was quite simple: download your Apple Health data, read the XML file, extract the nodes of interest, wrangle lightly and present it. Iâ€™ve only done a basic exploration of the data, but thereâ€™s so much more you could do.\nAfter starting this post, I noticed that Mark Koester has written an in-depth post about Apple Health data, with a focus on Python code for achieving a similar goal. It notes third-party tools like QS Access for extracting data into a friendlier CSV format, for example.\nItâ€™ll be interesting to revisit this in another yearâ€™s time to see how a â€˜return to normalityâ€™ (whatever that means) might impact these patterns of activity."
  },
  {
    "objectID": "posts/2021-03-07-xml-health/index.html#environment",
    "href": "posts/2021-03-07-xml-health/index.html#environment",
    "title": "Apple Health and Nike Run Club with {xml2}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 20:46:53 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] patchwork_1.1.2 lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [5] dplyr_1.1.2     purrr_1.0.1     readr_2.1.4     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.2   tidyverse_2.0.0 xml2_1.3.5     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    compiler_4.3.1    tidyselect_1.2.0 \n [5] scales_1.2.1      yaml_2.3.7        fastmap_1.1.1     R6_2.5.1         \n [9] labeling_0.4.2    generics_0.1.3    knitr_1.43.1      htmlwidgets_1.6.2\n[13] munsell_0.5.0     pillar_1.9.0      tzdb_0.4.0        rlang_1.1.1      \n[17] utf8_1.2.3        stringi_1.7.12    xfun_0.39         timechange_0.2.0 \n[21] cli_3.6.1         withr_2.5.0       magrittr_2.0.3    digest_0.6.31    \n[25] grid_4.3.1        rstudioapi_0.15.0 fontawesome_0.5.1 hms_1.1.3        \n[29] lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21     glue_1.6.2       \n[33] farver_2.1.1      fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[37] tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-09-12-punct-lit/index.html",
    "href": "posts/2021-09-12-punct-lit/index.html",
    "title": "Extract punctuation from books with R",
    "section": "",
    "text": "The start of â€˜Moby Dickâ€™ by Herman Melville"
  },
  {
    "objectID": "posts/2021-09-12-punct-lit/index.html#tldr",
    "href": "posts/2021-09-12-punct-lit/index.html#tldr",
    "title": "Extract punctuation from books with R",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote an R function to extract only the punctuation marks from a provided text. It prints prettily to the console, but you can also take a character vector away for further analysis."
  },
  {
    "objectID": "posts/2021-09-12-punct-lit/index.html#punct-rock",
    "href": "posts/2021-09-12-punct-lit/index.html#punct-rock",
    "title": "Extract punctuation from books with R",
    "section": "Punct rock",
    "text": "Punct rock\nA few years ago Adam J Calhoun did a small but really neat thing: extracted and presented only the punctuation from some books. It appeared again recently in my Twitter timeline.\nI love the aesthetic of the neatly printed characters, but it also tells us something (obvious?) about writing styles.\nLong story short: old-timey folk often wrote convoluted sentences; literature and essays from a hundred or more years ago are especially rich with semi-colons, commas, more commas and of course, as the audience is well-aware, even more commas, which to modern eyes can be a little tiring; certainly itâ€™s a style that is out of fashion, but was pretty hip for, letâ€™s say, Herman Melville, when writing his behemoth of a novel, Moby Dick; Or, The Whale.\nWhereas Hemingway was terse."
  },
  {
    "objectID": "posts/2021-09-12-punct-lit/index.html#youve-been-punct",
    "href": "posts/2021-09-12-punct-lit/index.html#youve-been-punct",
    "title": "Extract punctuation from books with R",
    "section": "Youâ€™ve been punct",
    "text": "Youâ€™ve been punct\nSo I wrote a small, opinionated R function called extract_punct() that grabs the punctuation characters for a given text.\nSomeone has probably done this in R before. I saw that Julia Silge wrote a post on quantifying punctuation like Calhounâ€™s original, but it doesnâ€™t involve printing the characters.\nThe purpose of this post is just to show how to do the extraction and print it nicely to the console, though the function allows you to take away a character vector for further analysis.\n\nFunctuation\nBelow is the definition for extract_punct(). You supply your content to text, and then you set the arguments:\n\nsort = FALSE to return the punctuation in the order it appears in the text, or TRUE to order it â€˜alphabeticallyâ€™\nvec_only = TRUE to early-return the punctuation characters as a vector for you to do with as you please\nvec_only = FALSE to print the results to the console with cat()\nwidth to decide where the line breaks will go in the printed output (defaults to 80)\ncolour = TRUE to have each punctuation character returned in colour thanks to the {crayon} package by GÃ¡bor CsÃ¡rdi1, or FALSE to return without colour\n\n\nextract_punct &lt;- function(\n    text,              # input text\n    sort = FALSE,      # order the characters?\n    vec_only = FALSE,  # return as char vector?\n    width = 80,        # width of output\n    colour = TRUE      # colour output?\n) {   \n  \n  # Extract punctuation with regular expression\n  punct_rx  &lt;- \"[\\\\.,:;!?\\\"\\'\\\\()]\"\n  matches   &lt;- regexpr(punct_rx, text)\n  punct_vec &lt;- regmatches(text, matches)\n  \n  # Sort alphabetically?\n  if (sort) punct_vec &lt;- punct_vec[order(punct_vec)]\n  \n  # Early return of character vector\n  if (vec_only) return(punct_vec)\n  \n  # Colour the characters\n  punct_vec &lt;- sapply(\n    punct_vec, switch,\n    \".\"  = crayon::blue(\".\"),\n    \"!\"  = crayon::blue(\"!\"),\n    \"?\"  = crayon::blue(\"?\"),\n    \",\"  = crayon::yellow(\",\"),\n    \";\"  = crayon::yellow(\";\"),\n    \":\"  = crayon::yellow(\":\"),\n    \"\\\"\" = crayon::red(\"\\\"\"),\n    \"'\"  = crayon::red(\"'\"),\n    \"(\"  = crayon::silver(\"(\"),\n    \")\"  = crayon::silver(\")\")\n  )\n  \n  # Print without colour\n  if (!is.null(width) & !colour) {\n    cat(names(punct_vec), sep = \"\", fill = width)\n  }\n  \n  # Convoluted colour printing, requires flattening a matrix\n  if (!is.null(width) & colour) {\n    div_size &lt;- length(punct_vec) %/% width * width\n    mat_flat &lt;- c(rbind(\"\\n\", matrix(punct_vec[1:div_size], nrow = width)))\n    leftover &lt;- c(\"\\n\", punct_vec[div_size:length(punct_vec)])\n    cat(mat_flat[2:length(mat_flat)], leftover, sep = \"\")\n  }\n  \n}\n\nThereâ€™s no defensive programming or testing here; this is just for fun for the purposes of this blog post. Maybe itâ€™ll work on your machine?\nNote that Iâ€™ve selected a subset of possible punctuation marks. Thereâ€™s no reason why you couldnâ€™t update the punct_rx object, which contains a regular expression, to include more marks. You could even use Râ€™s built-in \"[[:punct:]]\" declaration to capture them all.\nI decided to colour by â€˜typeâ€™ of mark: terminal (period, exclamation and question), â€˜continuingâ€™ marks (comma, semi-colon and colon), parenthetical (open and close) and quote signifiers (quotation marks and apostrophes, recognising that apostrophes are more likely to be used for contractions).\nThere were a couple of technical annoyances to deal with in the function definition; let me know what you would improve.2\n\n\n{gutenbergr}, dead ahead!\nLetâ€™s inspect the punctuation from some books on Project Gutenberg, â€˜a volunteer effort to digitize, archive, and distribute literary worksâ€™.\nHelpfully, we can interact with Project Gutenbergâ€™s library via the {gutenbergr} package by David Robinson.3\n\nlibrary(gutenbergr)\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(stringr)\n\nsample_n(gutenberg_metadata, 5) %&gt;% select(1:3)\n\n# A tibble: 5 Ã— 3\n  gutenberg_id title                                                      author\n         &lt;int&gt; &lt;chr&gt;                                                      &lt;chr&gt; \n1         8484 \"Scientific American Supplement, No. 430, March 29, 1884\"  Varioâ€¦\n2        49536 \"Syyn sovitus: MurhenÃ¤ytelmÃ¤ yhdessÃ¤ nÃ¤ytÃ¶ksessÃ¤\"          KÃ¶rneâ€¦\n3        32143 \"The Romantic Analogue\"                                    Skupeâ€¦\n4         5129 \"The Prodigal Judge\"                                       Kesteâ€¦\n5        22791 \"King Henry the Fifth\\nArranged for Representation at theâ€¦ Shakeâ€¦\n\n\nYou could filter for a particular author or title, like Franz Kafka.\n\ngutenberg_metadata %&gt;% \n  filter(str_detect(author, \"Kafka\")) %&gt;%\n  select(1:3) %&gt;%\n  slice(1:5)\n\n# A tibble: 5 Ã— 3\n  gutenberg_id title                    author      \n         &lt;int&gt; &lt;chr&gt;                    &lt;chr&gt;       \n1         5200 Metamorphosis            Kafka, Franz\n2         7849 The Trial                Kafka, Franz\n3        16304 Der Heizer: Ein Fragment Kafka, Franz\n4        19638 Auf der Galerie          Kafka, Franz\n5        20045 GroÃŸer LÃ¤rm              Kafka, Franz\n\n\nIâ€™ve chosen Edwin A Abbottâ€™s Flatland (1884) as our example text. Itâ€™s relatively short, so we can get the gist of the output from extract_punct() without printing hundreds of lines. Also itâ€™s a really fun little book that blew my mind.4\nYou can get a Gutenberg book by finding its â€˜Gutenberg IDâ€™ to input into extract_punct()? One way is to look at the URL for a given book on the Project Gutenberg website, another is to search the gutenberg_metadata()5 dataframe. Iâ€™ll also load {dplyr} and {stringr} for wrangling.\n\nid &lt;- gutenberg_works() %&gt;% \n  filter(str_detect(title, \"^Flatland: A Romance of Many Dimensions$\")) %&gt;%\n  pull(gutenberg_id)\n\nbook &lt;- gutenberg_download(id, verbose = FALSE)\n\nbook %&gt;% filter(!is.na(text)) %&gt;% sample_n(5) %&gt;% select(text)\n\n# A tibble: 5 Ã— 1\n  text                                                                   \n  &lt;chr&gt;                                                                  \n1 Chief Clerk of the High Council. It was found recorded on each occasion\n2 with the hinder half green. Look at her from one side. Obviously you   \n3 investigations indirectly by making them liable to a heavy tax, the    \n4 there could not be a doubt of it. Then followed a dialogue, which I    \n5 _I_. â€œMore merciful, more loving!â€ But these are the qualities of      \n\n\nRight so, we can pass the text to the extract_punct() function to return all the punctuation in the order it appears, with linebreak every 70 characters so the text fits the width of this blog.\n\nextract_punct(book$text, width = 70, colour = FALSE)\n\n,,...,,,,,,,,.,,,,.:.,;,..,.;,,(),(),,,,..;,;(..,(),.,.;;,.:.,.,,,;.;.\n),,.,..,,,,.,,,.:,,,?.,,,;;!.,,;;,(,(,:,,,.,.,.;,.....,(.(;.;..(),,,,,\n;,.;,,,.(.,.,,(..,,.?,?.;;..,,.,,,,,,,,.,,,.,,).,,.!,!,,..,;,,;.,;,,,;\n.,.,,,,,....,,.,,;,..;;;;?,,,,,.:.;.,,).,.,,,,;,;.,.,;.,,.,.,,..,,.,,,\n.;..,.,,,..,,..;,,.,..,,,..;;,..,;.;,,.,,,;.;.;,,.,,;.;.,,.,,,,?.,,,.;\n,,,,,,..,,,.,,,,,.,,.,..,;.,.,,,.;,..;.,...,,....!,,,,,.,,,,,.,,..,,,,\n,,?,.,,..,(,,,,.,,,,.;,.,,.;,,.,,,,,.,,..;.,,,..;:.,..;.,,,..,;.,,;,..\n.,?,,((.(,;,;,((,:,.,,.,,,.,,,,,,()..,,,,,,,.,.,,,.,.,,.,,,,,,.,..,,..\n,.(;,,...,,;,,,...,,.,,,,;,,,.,.,;;,...,,...,,..;,;;,?,,,,.,:,:?.;.;,,\n.:.,,,.,,,,;,;;,!,,.;.,?,???!,!,,.(,.,:.,.;,,.,.,;,,.;,,,,?.,.,,,.,,.;\n;,..,...;.,..,...,,(),;,.,,,..;;.,;,,;,,,,..;..,;,..,,,.,,,,,,,,,.,,,,\n,(),,;.,,,,..,,.,,,(.,,(;(((,;,.;;,...,;,,.,,....,,,.,,.,,,.,..,.;.,.,\n.;,...;,,.,,(.,;,,...,,.;.;,.,.;,,,.,,,,,,,.,.,.,;..;;,,,.,,,,;.,,;,,;\n,.,,..,,,.;...,,.;,,..,.,..,,;.,..,..,,;,,;,;,,,,.,,:,.,,,,,,.;,.:,.,.\n,,.,.,.,,.;,;,;,.,,,,,...,,..,;,,,,,,.,,,;,;,,;.,,,;;.,,.,??,.,,,.,;,,\n,,,;.;,;,,.,.,,,:,..,.;,,.,...,,;,;;,,,.,;.,,.,,,,;.,,.,;..,.,,,,,;,;;\n,;:..,,,..;.,.,!,.,.(),.,;,,,.,,,,?,.,;.;.:,,.,,,.,,;.,;,.;...,,...,,.\n,,;.(,,,,??,;.,....,.,.?.,??;.;,.,,,.,,;,.!?!,?;.,.,,..,;.,..,,,.,,.?,\n;,;,;.,.,;,,,.,,.,..,..,,???,;.!,,,.,;,.,?,,,,,:!,.,.,..!!!!;,.,,,,.,,\n.,...,.........,.....,?,,.?.,..,,,,,,.;,,,?.,,.,..;,,..,,!.!;,..:,,.;,\n,.;,...;,,,;,.,,.,.;.,,.,,,,,:.;:;,.,,,.,,,,,,(.,,;,;..;,.,.;,??,.;,,.\n!;,.,.,.?.?,,.,.,,,?,;.,;,,,..,:..,,,,),,,,.,..,,...?.,,,.?..,...;,.,.\n..,...,...,;...,.(),...,,,.,,..,.?....?.,,,,,,....,.,;..?...,,?.:..,.,\n.....,,,,,.,..,,,,,,,,..,;,..;..??..,.,,,,,,.,.,,.,.,..,....,.?.....,.\n.,..,,;..,,?..,,.,...:.....?.,..,?.,,;,?....,,,..,.,:;,...,:...,,;.,..\n...,.,:,;....,,;;,,.,,.,,,,,,?..!,.,.,,..:.,....!!.!.,.;;..,.,,.:;,,,,\n,,.,,..,,,...,!,,,.!,;.,.,,,,.,,,,...,,,,,.,::.,..,.,?.!,...,.?,,,.,.,\n,,.,.:,,,,,,,,.,..,,.,.(,,,.!,;,..,...,,,,,,;,,,.,...,.,..,.,;,,.,;..,\n,;,.;.,,.,,,,,:,,;,.!,.,.,,.,.,;....?.,.,,.,,,,,,,,.....,,..;?..,,,,,.\n......,;,.,,,,,,...,,,,,,,,.?,?,?,,?,,?,??,,?,,:,,;.;.,,,?..(..,....,,\n?(.;..,.,,,,,.,,.,,.,...,.!..;,..,,,.,,;,,..;,.;,,.,.,.,.,,,.,;;,,..;,\n;;.,..;,,!,,,,,,,,?,,,,:,,,,.,,.!,!,!,,.:.,,,;.,,,.,,...,..,,,..,,.,;,\n.,,,,,,.,?,;,.,,.,,.,,,.,,.,.,,.!.,.,,,;;,,,!,,,,,,,,..,;.,;..,,,,,:,,\n;(..,,.,,.,;(.;,.?,.,,.,,;,.,,,,,.,;,.?,,.;,,.,;.,,:.,.)?,,,.,.,,.,.,,\n.;.,,,.,.,,,.,,..,;,,;;,,,,,,,,,,,.,,,,,,((,),,.,,,,..,,;..,(,.;,,;,:,\n;(,,,..??.,(),,,?,.!,,.,()..(.;,..,,.(.(,;..,,,,,,,.;,,,,,.\n\n\nI passed colour = FALSE because the blog canâ€™t render the colours. Set colour = TRUE to have the characters returned in your console with a different colour for each type of mark. That looks like this:\n\n\n\nAll punctuation from â€˜Flatlandâ€™ by Edward A Abbott\n\n\nFor fun, we can also get the same output as before, but ordered by character.\n\nextract_punct(book$text, sort = TRUE, width = 70, colour = FALSE)\n\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;;;;;;;;;;;;;;;;;;::::::::::::::::::::::::::::::::::::::!!!!!!!!!!!!!\n!!!!!!!!!!!!!!!!!!!!!!!???????????????????????????????????????????????\n??????????????????????????............................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n......................................................................\n..................................................................((((\n(((((((((((((((((((((((((((((((((((((((((()))))))))))))))))\n\n\n\n\nFull stop\nSo thatâ€™s the general gist.\nHereâ€™s a few more books from Project Gutenberg. Expand to see the punctuation for each one:\n\n\nPride and Prejudice by Jane Austen (1813)\n\n\nextract_punct(\n  gutenberg_download(1342, verbose = FALSE)$text,\n  width = 70\n)\n\n::..,:...:,:.,..;,.,.,.,,,.,.,,;.,;.,,;);,;,,,;,.,);,,,,,.;.,;,,,,,,.,\n,,.;,,.,,,,,,;,.,.,,,.,,.,.,;.,.,..,,,.,.,;,,..;),.,,,,,,,,.,,.,.,,;.,\n,..,.;.,,.:.,.,,,.;.,.;,,.,.;.,;)(),.,.,.,.;,...,,,,,,,,,,,....,.,,.(,\n.,.,.,,.,.,.;.,,?,,.,,,.;.,,..,,.(;,,.,,(,)().;..;.,..,,..,,.,,,,.,,..\n;,,.,.;,,,,,..;,..,,,.;,,,,,.,,,,,,.,?.;,.,.,...:.........,...........\n?,.....!......,..:.,.,,..?.,..?,:..,;,.,.?.?,.?..??,..,,.,.,,,.,..;.,,\n;..:.,;...,..,,.,.,..,..,.::.:....,;..,..,,,...,..,,.,.,,.,;.,.,;...,,\n..!?,,?,,,..;,...;,.,..,.,,,.,,.,.,,..::..,.,;,..,.;.,.,..,;,,;.,,,.;,\n.:.;..;,.,,.,.;,,,,.,;,,,..:,...,,.,..,;..,......,!;.,,,,.:.?,:.,..,,.\n..,.;,.,.,.;.,,,;.;.;,..,,,!.,!....,,,;.!!,.,..,,!,...?.?.,.!,..;.:,!.\n,,,,.;.,;,,.;;;;,;.;..,.;,,,.;,;,.,.;,,.,,.,,;,.;..;,;.,,...,.;.:..,.,\n;,,,,,,,.,.,.;.,,;,,..?,,,:!,,.?,..:.,.,;.,..,,;....,.,,,,..,,,,,,,,.;\n.,,,;.;;....,.;,,,,,;,,,..,;.,.,;..,,,.,,,,,,...,;,;,.;...;.:,,,,.,,.;\n.,,..:;,..,;,:,.;,...?.,.,:.,,,,,,?;..,,!!,.,.,.,,,,,.;,,.,,,,..,,,,.,\n:.,,,,.,?.,.,;.:;,,,.,,,,,..,.,;,..,;?,,,..,.,!,..,...!??.;,,..,;,:...\n,,,...,.;,,.,,,;,.;.....,.,,.,,,..,,,.,.,,;,,....,;,.,;.;.,,,,,,;..,.!\n.,?,;,.,..,,:.,.;....,,,.:,,...,,,,,.,.,.,:.,,..,?,;,;.,,.,,:,,,,.,,,;\n......,.;,,,..,,.,,,,.;.,.,.,.::.,.,..,,;,.,.;..,,,,.,,,,..,!,,,.,...,\n..,,?.,.,.,,,,,.?;,,.,;,.,,,,.,,,,?,,,,,.,.;;..,.,,...!...,.:,,.,;,,??\n..!.!,.!,.,.,.;..,,.;,.,,,.,...?.,.,,.,.,;;,...,.;,.;...,.:..,..,..,,;\n,.,;.,..,..!,,..,,,,....,,,.,,.;,..,.,.;.,..,.,..;.,,,,,,,,,.,.,.,,...\n,.,,!;.?,,;,.;,,,;..,.,,,,!,,..;.,.,,,,..;..,;.,,,,,..,,..;.,..,.,...,\n,..,..,.,,,.!...!,.,...?.,,.?.,,;.,.,,..,.;.,,..?;,,.,.,,,,,.,..;.;,,,\n,..,.;,..?,.,.,,,...,.,..,.,,,,?,,,,,,;..,,.,..,;,..,.,,..,,.,.,,..,;,\n,?,.,.;,.;..,;,.,.,.,,,,,,.,.:,.?....,,,...,,,...,..,,,..,..:..,,;..,.\n,,.;,..;,.,...,..,..,..,,,.,,!!!..;,,,?;.,,,.,;..,.,.,,,,..,:.,,,..,,.\n,,.,.,,:;.,.,.,..;,..,..,,.,.,.....,...?..,,..,...,..,,.,.,..,;..,,.,,\n.,;,.;,.,;;;.,;....;,.:,,,,,,,..,,,;,,.,;..;;.,,.,;...,!!....;.,:;.,.,\n.,;..:;,,.,.,,.?,,,,;,:.;,,,,.,;,,.,,;,,,,,,.,,.,.,,.,,.,,.,.,.?,,..,.\n..,.,...,,.,.,,.;,,;.,,.,.,,..;.,.,..,,.;.,,,,,,.;,..,.,;,.,,,,,..,,,.\n,.,,;.,,,..?.;,.;.;,..,.,;,..;,,.,,:..;)...,,,?.,;,,,.,..,;,,...;;.;,,\n.;,,,,,;,.;,..,;..,,,,,;,..,.;,:;.;,,,.;,,.;,.,,.,,,,,...;,,,.,,..:,;,\n,.,...,;,.,.?..,..,,..,,,.,,.,,,.;,,,.,,,.,,.,,,,,;,...,,,.,..,,;,..,,\n,;;,,,,.,,,;,,.,,.:,,,;,,,:..,;,,,..,;..,,,;,..,;,,,,,...;.,,.,.,.,,.,\n,.,...,.,..,,;,,,..,.;....,,,,..;,.,;.,,.,.,,.,.,.;,.!...;.!?.,,,,,,.,\n.,!.,,.,?,.,,..,,,!,,,.,.,,!.,,.,:,,;..,;,,.!.,.,;.;.?;,.,,,,;.?.;.;.,\n,.,,.,?..,.;...;,.,,...,,.,,.,,..,.,.,;,..,.,.,..;,,,;,;,,.,,.....;,,;\n.,,.:.,..;.;,.,,.,.,?.,..,.,?..;,,.;,,.,,;,.,...,..,..,.,.,,,,.,.;.,..\n,;,,.,,;,;,,.;!,,.,,,,,,;,.,.,,;,.,..,..,...,,.,,,.,,,.,;,,.,,.;,;,,.:\n,,..,,,,,,,:.!!.,,,.,..;,,,..,,,,.;;.,.;,.,?,.,,.,.,.;,.,..,,,.;.,,.,,\n;,.,..:,)!,:..;,,,,....?!.;.;.?.,,,;.?,?.,.?,.?..,;,.,.,,;,,.,,,,;,.;,\n,..;,.,.;,,,.,,;!....,.;,.,,,.,.,.,.;,,..;..,....,,,.,.,.;,,.,.,.!,...\n...;.,,,,,,,;.,.,;,.,,,.;.,;,.,.,..,..,;.,.;(...,;,.,;,,.,;.,.,;....,.\n.,...;..,,.;,.,,,;,.,;.,.,,,.,,.,,;.,..,,.,;.,.,,,,,,;,.;,,..,.,.;;..,\n..,,..;.,.,..,.,...,.,!,;.,.;,..,,.,;,.:...,,..,,?,,!.,,,..,,,.;,,.,,,\n;.,;.,,,.,,,,(;;,.!,,.,,.,,.;,.;,.,(,,...,;.,,..,..,.,,,;.,,.(.,..,.,,\n,,.,,,,,,,,;,.,.,.,.:,.,;,.,.,,,..,..,.!;,.,,,...;,,,.,,,.,,.,.,.,,,.,\n,,,..,,,,.;..,.,...?.....,...?,..,,...;.,,.,,;.,..,;,,.;..,.,!,:,;,,.,\n..,,.,..,.....,.,.,,.,,.,,.:,,,,:,,;,.,,,.,;.,;,..,,,.;,,...,.,,,,,..,\n.,.;,,,:;.:.,,,,,;,;.,:,;.,,,.,;,.;:.,.,.,,?..,;,,,.:,.,.,..?..;.,.,,.\n;;,.,,?,;;(!?,...,..,;.,:,,;.,,;,,..;..:,,?,,,,?,.;.,..;,.,,;,,.,,.,.;\n,..;,.,,.;:..,.;,.,,;,.,,...;,;,.;,.;.,;.:.,,,...;...,,.:,,.,.,.;,;,.,\n,,.,;,.,,.;,,?.,,..;,.,;.,,.,.,:;,,....:;,,.;,,.?;,,.,,,..,.;.;..;,.!,\n.:...,,,.,;,,!.:;,.,,;,,,,..;.;;;,;;...:;..;,,!:;.,;..,..;.,,,,..,.,,,\n,,,....;.,....;,..,,.,,.,:;.,,....,.,.:.,...,.,..,,,,..,.,?..,;?,.,,.,\n,,.,...,..,.;,,,.,;.,;,,;,,;,,!...,.,...,,,.,;..,.,,,,.,;,..!,..,;,.,;\n,.,;..,,.,;..,......,..;,,.?;.,,.;..:,,,.;..,?;,.,.,;..;,.,,;,,.,,....\n.,.,,....,;..:,..,.,,.;,.,,.,,..,,...,..,.,....,..,,.,..,,.,,..,,:.,..\n,,,.;,,;.?,!..?.,.,.,,.;,!,,..?.,,,,.,.;,,.;,.,.,.,,;,...,.;,....,,..,\n;..:?..:,,;.,.:,..,,,,,.,....;,;,,,,?..,.,,...,.;,..;,;,,,,,.,,..,..,.\n,..:,.:.;,.:,,;.,.,.;,,;....,,,,,.,.:,...,;.,;,.:,,.,,,;,.,,,,,.,;.,.,\n,,.,,,,..,.,..,...,;,..;,,..,..,,,.;,,,,..,;,.,,.;,,..,.:.,,,.;,.,;,.;\n...,.,,,..,,,,,,;,..,,..;,,.,,,.,,.,.;,,.,,...,.,??;,.,.,??,,?..?..,,,\n.,;.,.,,,.,;,.,.?,..,,..:.;,.,,...,.,,..,,:;.,,,.;,,.,;.,,..,,,,.;,.,,\n.,.,,.,,,,,,.,.,,..,,,,.....,,,,.,;,,,.,..,,;,,,:.,!,;,;.?,!!....?,.,.\n..;,,.;.,.:,...,,.,..(?,,...,,,,,....,,.,;.,.,.,.,,.,.,,,,,,,..,,,,,.,\n,.:,;.,.,..,,,,.,,.,.,,.,,.,,.,,.,..,,,.,;,...,,.,,,?,,.,..?..,..?,?,,\n...,?.!!.,.?.,.,.,,.,..,,.?,,,!!?,.,...,.,.;.,..,.;..,,..,,,..,,,.;,,,\n,,...;,.,,;,,.;:,;.,.,,.,..;,..;,,.,,,.,,.:;,,..,:,.,,,..,,.;,,,,,.;,:\n..;,.,,,.,,,.,.,.,,,,,,,.,.;.?:;.,.:.,.,;,,..,.,.,;,.:;,,,;,.;,,,?,.!,\n,,,...,;.,..,,.,,,....,;.,,.,,...,;,,.,,,,.,,.,,.,,,!,...;,,,?.,?,.,.,\n,,.,..,..,.,,,.,,,:;,,,.;..,.,.;,,,,,.,.,,,,.;.,;,.?;..,,.,.,..;.,....\n,,...,.??.,..,,;,..,......;,?,,.,,:.?..,,,,.,;,.,.,;,,,...;,.,;,:,,.,.\n,,;,,,.,,,:.,.;,.,,,.,;,.,.?.,.,,,,,.,,?,,.?..,..,.,..,.??.,.,.,.,;?,,\n,,..;.,.,?;.,,...,...,,!.,..?,...,;,...?,.,..,.??.;.,,.,.,.,.,......,,\n;.,;,.,,,,,.,.,;,.;.,,;..,..,,,,,,..,,,;,.,;,,,,.,...,....,.,.,,,.,,,;\n.,;...;,,,.,,.....,..,..!,,,,,,.,,,?,,,..,,,,.,..?,,.,,,...??,,?!.,...\n!.,!.,,,.,,,,.??;,,,.;.;.,,,,,;.,,,.,..,,..,,!.,,.,.,:..:;.,,.,.,,.,.,\n:.,...,,.,.,,,,.,,,,,,,,.;.,,,,,.,,,,,.,,.,,,,...,,.,;.,;,.,.,.,.;.,;.\n,,.,,,:.,.,,.,,.:,...,,,,...,,.,.;,.,,,,.,.;..,;.;,.,,..,,,,..,.;,,...\n,,..;..,,.,,,.,.,.,,.,..,..,..,.;;,.;,,.,,.;,..;.,;..;,.,,....,,,.,;,.\n..,,.,.;,,,.;,.;,.;..,,.,,!,,,,,;,.;,.,;,.,,,.,....,,.:...,,,.,..,,..,\n;.,,....,.,..;.,;,,.!;,:,.;.;,,;;,;,;..,,!!,.!..,,.,.;.,?;..,,.,.;,,..\n;,,,.,,,,;,.,;,,.;.:.;,,.;,.,,;.?..,.;!;,...,;,,.,,;.,....:.,.,,,,,.,.\n.....,,.,..;..!.,.;;,:;,..;.:,;,;.,,.,;,;?,;.,,.;,.,.,,,,..;,,,,,.:...\n;.,;..,,;..;,.,.,,.,..,,,;,.,,.;.....,..!,.,,,,.,,.,,.:,,.:.!!!,,!,,.,\n,,..,,,,,,,,.:.,,,,,,,.,,?,,,;,.,,,.,.,;!.,!,.,,,..,.,,..:!;!.,,..?,,!\n,;,,!,,..?.!!.;!.!,;:;,,,;,..,,,.,.;,,,;:,,,;,.,,;;,,..!,,....,,..,,,.\n.,,.;,,.;,..;.;.,;.,.,!?.,.,.!,,,,..;.,,,!.!!.,..;.!!....,,;.,.,.,,...\n..,.,...;,,,..,.....,.,..;.,.!,..,,;,,.,?...;,:.,;,,..,,.,.,,,...,.;.,\n.:...,..,,.!.?;.,.,!!.,...;.;.,,,.,..,,..,,,.,;,.,.,.,.,,,.!?..,,,,.,,\n;;;;,..,,?.,,;,..;....,.;,,;,.,..,.,,,.:.,,..;,..,;,.,,,;,,,,,,,.,,,;.\n,?.?,.,!,??,,.,.,,;,;,,,.,.,,.,,.,.,.,;.,..;,,;,.:.,.,.,..;..;.,.,,,,,\n,,.,.;,;,,,,.,,.;,,,:;,,,,,.;.;.,,;,,;,.,,.,;,,,,.;..,;,,,,;,,,,:;;.,.\n,....,,,,.;,.,,..,,;,;,.,,?...,:..,..;..,.,.,,,?,;,,.,:.,;,,,.,.,,,.,;\n,.,.;!,,..;.;,.,.,,;,,;.;,,.,!,.,;.,;,.!..,.,.,..,..,;....,,,;,,....?,\n!:..:,.?,;,,,..,,,,,.,.:,..,.,,..,,.,.,.,,,,.....!,..;,,;,.,...,.,.;,,\n.,...,.,..,..?!!!;,,:.,;,,;,.;,,.;,.;.,.,,,.,;,.,,,.,,.,;,.!!!,,;..,!!\n.,!.,,:;,,.,.,.;.,.,,,;,,,,..;,,:,,.,,.,,,,,,,,,,.,,.;,;;,,....;,,,.,,\n;.:,...,,,;,,,.,..;?...,,,.,..,,;,..,,..;.,,,?;.,,;.;;..,.,,.,...;.;.;\n.,,;,..;.,,.?:,.,.,.,.,.,..!.,.;,,;,,,,.,;,.,.;,,..;.;.,,,.,,.,,..,.;;\n.,,.,..,..,,.,...;,,;,.,...,.,.;.,,;,.,.:.,.,,,,..;,,,,,;,,;,.;..,,,,.\n;,,,.,,,,,.;,.,,.,,,,,,.,,,,.,,....,.,;,,.,,,..;.,,;,,,,;;,.,.,;,..,,.\n,,,,,,,,,;,,,,,,;.,.,.:.,,.,.,,.,..,,.,.,.,;,;,,,.,;::,,,,.,,;.,;,.,.;\n,..,.;,,.,;.,,,;,,.:;;,.,,,,;,,,..,,,.,.,,,.;,.;,:;..,.!..,,.,.;;,,.;,\n,;;.,,;,!,.,;.,..,..,;,..;;,,..;,..,,,,;.,,;.,,,),.,;,......,,,.,,.,.,\n,.,.,,..;,,.,,,....,;,,!:,,,.;.;,,,,.,..,.;,!,;,,,,..!;,;;.,,.,,,.?,..\n,.:,..;....,!,,.,,,,.,,,;?..,,..;.;,;,,;,,,;;,,,,,,!,,.,..,,,,,;,,,.,.\n,,,,,,.;,....,;.,,,.,;.,.,!!,,;;,,.,,,.,.,.,,.?;;.?.?;.,;,,.,;,,:.,;.,\n.?,.?,.,.?...?,.,!.,,;,,??,..,?,.,;,,,.,?,,..;,.,,,,?..,,?,?.;.?.,.,.;\n,,.??,...,;,,...,.,,.;.,.:;,,,,,.,.;,.,,,,,;,,,,.,.?,?.,.,?,..!?!,,,.,\n,,.,;,,.,,,.,,.?,.;!,?;.;,,.,,.;,.,.,.;.,..;,,,.!.,;,,,;,,,.,.,,,.,,,,\n.,,:,,.,..,;.,,,.??,,.,:,??;,,.,,?,..,..?,??.,.,!,,,.?.,:,,,.,,,,,..,,\n.;..,.,..,...!,?:.,.....,,,.,.:,.,,..,,,..;,,,.;,.:..,,;,;.,;.,..,..,,\n,.,,,,;.,;,,,..:,.;,,,;,,.:,,.,,...;.,,,;,;..;..,,;,:,,,,.,,,,;,.,:.;,\n,..,:,?,;.,,.,.;,;,..,;..,;.;.,,.,.!.,...,.,;.,,.;,,,....;;.,;,..,.!..\n?;,,.,,,,.,!,,,,!!.,,,.,,,...,,,,,,,,.,,;;,,,.,,.,,,,,,?;.,.,,,,,.::.,\n:;,,,;,,,,,,.,,,,.;..,...??,.?;.!.,.,,?.!!,:;.!,.,.!.,:.!?..,!..,,,,,,\n?,,...,.!!!,:,.,.,,.,.,.?,,.,..,...,,!,.,..,!,.,..,?,.,!,.;,,,.;.,,.,?\n?..,,,.,,,:...,,.,..;,..;,.,,......,.,,,.,.;,,.,;.,.;.;.;..,,.,,,..,..\n,,,.;,.,,.,.,,.,;;...,,.,.,,;,.,;.;.,...,,....,.,!,.,,,:,,..,..,.,;.,.\n,.,.;.,.;,,.,.,,..;....,.,,,,.!..,,.,,,,,,,.;,,,.:..;.,,,,...;,;.;,...\n..,;,,,.;,,,;,...;,,...,,.!.,;,,;,,,..,.,,,...,;.,,?..;.,,,.!,;.,..,..\n,.;.;,;,;,..;;.,,,,?,.!,...,,.,.,.,;.,.,,.,,.,.,..,!!,.,.,,,,;..,,;,;,\n,.,,,.,;.,;,.;:,:...,,;.,,,,.;,...,,,;..,,,..,..,..;;..,..,,.,.;...,,,\n..;.,,,.;.;.,..,.,,..;,,.;,,..,.:.,..;)..,,;,,...,,.,,,.;.,,.,;,.;.,;,\n,,.,.,;.,,.,),;,..,....,.,.,,,,!;,,,..;,,....;;,...,!..,.,,.,.,.,.....\n.,,,.,?,..,;..,....;?.,..;?..!.?..,,!?,,!,,;,.!,,;,,..:,:...,;.;,,.,,,\n....,,,...,.,....,,.,.,,),.,..,:;,,,.;,;...;,.,;,,.,,!,,.,,,.,,,,,.,..\n,..,.,;..,;.,.,.,..,..,,.;..,,.!.!...,,.....,,.;,,,.,.,,;,.,,.,,,,,,.,\n..,,.,.,,.,.:..;,,.,.?;.,,..;.....,,,.,..,;.,.,!.,.,;.,...,!,..,.!!,,.\n.;,,;.,,.,,..,..;,.:.,,..,?.,;,.,.,..,.,.,.;,,.;,,,,..;.,;,..,,,,;..,.\n,.;,,.;,.,,.,.;;,,.,,?.,,!!??.,;?;?..;,,,,;,,.;,,.;,,?.,.;;..?!,:..;,,\n,,..,.,.,,,.!!?.,;.:,.,,..,,,,.?,.,.,,.,.,,!,,..,,,.,?,;,,,,,.,..,,..,\n.;,.;,,,;,..;,.,;...,,.,,.,;,,.;,,,;,!?,,.,,,,.!,,,,.,!,,.?.,..;,,,,.;\n,..,,..,;,,,.,..,,...!?.!.!,.!,..;.,,;,.;:,.;,,!.,?.,.,,.,..,,?,.,.;,.\n!.?!.,.,.,.;..,,,;..;,,,.,,:;,.,,,..,,,?.,,.,,,.,,:.,..,,,.:;,..,.;.,,\n,.;.:.?.,:,...,.,.,;,.,,,,,,.,,..,,.!??.,...,.;...,,..;..,.,.,..,;,,??\n??;,..,?,,,,;.,,.,??;..;.!.,,.;?,!.,...?.,,,,,,..?.,.....;?,?.,,;..,..\n,?,?,,...,,?,?.,,.,,,,.,,.!..;,,.;,.,.,!!,,,;.:.;.,..,,,,..,,.,.,;.,;,\n,.,,,,,.;.,,..,.,,..,,,;.,.,,...,,,.;..,,,...,.,;.,,.,,.,:,..,?,!,..?,\n,;,.,,.,,.,.;.,.!,,,,?,!,;!,.,.?;,....,,:..,..,,.,...;;,;.;,.....,,,..\n;.,,.,,...,,;.,,,,.;.,:;,..,,,;,,.,,.,.,.,.?,..,,..,,,.,,...,,.,..??,.\n,.,..,;,.,;.,.,....,,.,,,..,,,,.,!...?.,,..!..,.,.,,,.,.,;,,.,.,,...;.\n?.,,.,,..,;,.,,.;,..,.,,....;..,..:..,,.,.,,;;,;.:;..,,:,,.....;...,!.\n?..?,.?.?,.?,.,.?,.,;..,.;,,!,.;:..!,!?,,.;.,,,?...,..,.,,;,;,:.;;,;,.\n,..,,,,,;,.,,?,;,.,,?,?..,.;.,,..,,.....,,,,,,,.,.,,.,,!.;.,.,,;,.,,.,\n.,.,,.,!?!!.!.!!;,..,,.,,;,,;,,.;.,;.:...,.?;?,..,,.;..,.,,:,.,..,?!.;\n;?,,,....,!,!.,,?.....,.??,.,,?,;.,,,.,;,,:,,,;,.....,,.,...,....,.,.,\n..,..,..,,.,,..,,.,.;;..,,;,,......,,,,...,.,:;,,.,;,,;,,;..;,.,.;,.,,\n,:,.,;.;.;.,,.,,.,,;.,.,:,.,.;,,.;,;,.;.,;,.,..,.;,,,.,,,;,,..,,,::,\n\n\n\n\n\nThe Metamorphosis by Franz Kafka (1915)\n\n\nextract_punct(\n  gutenberg_download(5200, verbose = FALSE)$text,\n  width = 70\n)\n\n,.,,.,?,.,,..,,,.,,,.,.,,,.!;;..,.,.;,,,!,....,!,.;.?,?,.,.,?.,.?,.,,.\n.?,.,,.,:,,.,,,,::?,.:,,.,,.,.,.;.,;,,;,.,,;;,,,,.,.,..,,,,..,.,.,,.:.\n,...,.,.,.;,,,?...,..,,.?,?,,?,,,,.;.,.;.,.:..,...,,.!;...,;.;;,,.,,,.\n?,;.?.?,?..,.,,.,.,?,.,,,.,...,.;,,,,,,...!,.!.;..,,!,,,.,;..,,.,;...?\n,,....?.,,,.?;.,,,,.,,.,,..,..,..,;,,.,;:!,.,,.,:..,.,.,,..,,..,.,.,.;\n;.;,.,..,,.,.,,,,.,.,...,,.,,,,,.!,.,..,,,..;,.,!!.;.,,,;,,,,;,;..,:,,\n;;;.,,..;;.;;.,,,,(),.,.,,,,.,.,,.,;,.,.!,.,,....,;;,.,,,.,...,..,,,.,\n.;..,,.;.,,.,.,,.,,.,.?,.,;;.,;.,,,.,,.;.,,.,,,..,,,,,,,,,.,.,.,,?,,..\n.,,.,;;;.,,,..,.,,.,;,.,.,.,.,.,.,,,.,,..,,.,,,.,,,.,.,,;..,.,;.,,.,.,\n,,,....,,.,.,..,,,,,..,.,.,.,,,.,,.,.,..,,,.,,.,;,;...?,.,,,.,,.,.,,,,\n,;,,,.,.;,,..,.,.;,.,,,.,,..,.,.,...,.,.,,,,...:?,,,,..,,,,,.;;,.,,,,,\n.;,;.,,;..,.,.,,.,,.;,.(,,?.,,.,?,.,,;;.,,.,,,,,,,....,.,,.,,,,.,.,.,,\n,.,.;;,,.,.,,.,.,..;.,.,,,,.!.,,,:.,.;,;;;;;;;.,,;,,.,,,.?.:.,,.,.,,,.\n,!..;.,,;,,,,;,.,;;,.,,,,,.,,.,.,.,.,,..;;,,,.;.,.,.,,;,,(),,.,.,,,.,,\n.,(.,,,.,,..;;;,.!.,;,..,,.,,.,..,,..,!,.,?;;.,,.,,.,;,.,,,..,;,,.,,;,\n,,,,,,,,,,,,,.,..,;..,,,,,.;,,;;,,.,,.,.,.,...,,,.!,.,.,.,..,,,.,.,.,.\n,.,,...,.,,.,,,.,.,,,,.,..,,,,.,..,.,,,.,.,,.,,..,?,,?..,.;,;;.;,..;,.\n,.,;,,,.,...,..?.,,,;;,?.,,,.,.,.,...,..,,,,..,.,,.,,..:..,,.,.,...,,.\n.,.,,...,,.,,,,,,?,,.,,.,....,.!,.,.,.,,...,.,....,.,.,,..,...,!,...,.\n,....,.,.,.,.,.,:,.....;,.,.,,......,,.,,...,;?....;...,.,....,;...,.;\n;.;;,,,;.,.,.,..,.,,..,,.;,.,,,,...,..,,.,.,;,,.,,...,.\n\n\n\n\n\nMoby Dick; Or, The Whale by Herman Melville (1851)\n\n\nextract_punct(\n  gutenberg_download(2489, verbose = FALSE)$text,\n  width = 70\n)\n\n'.(.,,..;,;,,'.;.,.,.,,..,?.;!,;,?!.;...,,?.,,.,,,,...,.,;.,.'.?!?,,?,\n,,?,.,,,;,,,..',,,.,.,,,;,,.,.,,,,.,,,,.,..,?,,??,;,,.,,....,,,.!,.().\n.,,;,.,..:\"\"\",,,,;,,,...;,.;..,.,,,,,,,,.,,,,,,,,,;.,?,,?,,.,.,,,,,,\",\n,,,,,.,.?.,.!,,.,.;.,?\",..;.'.,,,,,\"?..,,,,,,',.,\",,.,,,.;.,,,.(;;.???\n;?,,.,,,.,,,.,,,,.,,,,,,,,..,,.....'.??,.;;,..;;.,..,.,,,,.,.,,,.,'''.\n,(,..,.,,,.,,,.'';,(,,'\"',.,.'.'..,;,.\".\"\".'\"?\",\",.,,..,;';,,,.,',.,,,\n.,,.,,.(,.,.,.,.,,.,,?',....,,.,,,,,.,,,.?\"'\",.,;,..,,.,,.,;,.,,,,.,,?\n.,,,'..',,\"?,.,,,,\"?,,?\",\"\"\"'\"''\"'\"\"\"\"\",;.,,,.,.,,;.\".,,(''''.,,,?\"\",.\n;,.,,;,,;;,,,.\";;,,,;,,.,'.,.?,.,..,?,,.,..,,,..,',,.,,.,,.,..,,,.,',,\n.;.,,..,.,,.,.;';.,.,.,....,.,..,,.,.,.,;,,.,..,,.,,,..,,,,..,.,;,.,);\n.;,,.,.,,,.,,,,,,;,,,.\".\".\",.,,\".\"?\"?,\".\"....',.\";..,'\",,..;,,,,.,;..,\n,.,;,,.,,...,,,,,:.,,,;,.;;,,.,,.;,..,,'.,.,.\";.',,,,;,,,.,,,,,,,,;,,,\n.'.,,.,;;,....,;.,,,.,,,,,.,;,,,.,,,,,.,.,,',..,;,,.,,;,,;..';.;,;?',\"\n.,,,;,,,..,;..;,.!,,.,;,.'.',,,,,.,..;..;;.,,,,,.,..!,',.,.,.,,,...,,;\n;,;.?,,..,,;,.,.,.;',;.,,,.',.,..,,..,.,.:,,,,.,,,',,,.,,,.,,..;,.,;,,\n.!,.!!,..,,,,,;;,;;;.,.,,,..,..?.,...,;,.,.,,;,',,,.,,.,,,,,,,,,,,.,,,\n.,,,,.,,,..,.;,,?,,.,',.,;'',;..',.?;.,.,.,.!,'.;,.,;,,,'.,;,,,.,;,.,,\n.,.,,'.\".'!',;?;.,,.,.,.;.\",.'..,,.,;,,!,.,,.,.;,,.;.,;'.',,;,...,,\"'!\n.,;,,...?,',\",,;.,'..,.;'.,',.,','\"',,;,.,..,!!\",;,,,''\",.!..,,'.,,.,.\n,,,.,,.,,.\",;,,..?,,,,.\"!!;,,,;.,.\",,.;,',..,,.,,...,,';;,.,;,,,:\".;,,\n,,.,,.,,,,.''.,,;;,'!\".!!!,,,!;,,,.?,.,.,.,,.,!..?,,.,;.,;,.,,;,.;,,..\n..;,.,..,,;.,,,.,,,.,,...,..;.,;;..,.,,;,;,;.....,..,;'.,,,..,,.',.;,;\n;,,.,.,;,,',.;,.;.?,??.?.;;;,.;.;.',,;,,,,;,,,,.,.,,,,.,...,;,,.;,.'.,\n;.,.,,...,,,,,.,,.,.,;..;.'.,.,.,.,,;;,.;;.,.,,,,.,;,;.;,..,,,,;.;..,,\n.,.,,.,,;.,,,,',,.,,''.,,\".,,.,.,,,.,,,,.,.,;;,.,,;.,,'.',,,,,,,;.,,;.\n\",.,,,;,,;;..,,.!;.,;.;,;,,,;.,...,;,,.\"\"\",?\"\".\",;\";,.,,,;.,.;.,,,,,,,\n.,.,.,,,...;?.;,,\".;,!;.;.,';;;,,,,......,,,!;,,;';,!,,;,,,';.;.,.;;;,\n,,;,,;,.,,,,,.,,;,,.,,.,,.,,.;,;'!?,,,.\"\";.,,,,\"\"\",,,\",\"?,.,.,!.,,:..\"\n,,;,'\"',;,..;.,',',,;,;\"'',;.).,\"..,,,,,,,;,,';,.,;'.,,.,;,,,,,'.,;;,.\n,;;.;.,'..,.,.,,,,'....,,..,,.,..,,;,.,.,,',.,;'.;.,;,,,..\".\"?\"\"?\"\"\"'\"\n?..,??.,,,.\".\"\"\"\"\"\".,.,,,.\"\",!,,,,.\".?\"\"\"'!?\"\"'\",\",?,.,,'.,,.;.\"?\"'\",'\n,..\"...;,;,.,.,,,..;,;,,,,;,,;,,'.,..,,,,,,,,,,..,;,.,,'.,;,,.,,.,,.,,\n,,,,,..,,,.;,;;.\",.,,,\"\"\"\"\".,,,'..;,';,,.,,,.,,,.,,.,:;,,',,.,;,,\"?\"',\n,!,,,,,;\"!\";.\",,\",,.\".\",.\",,;,\".',.!,,,,,.,.,,.',.'.\"?\"\".\"?\"\",'.,;,,;,\n,,...\".\"\"';;,.,',,;.!,\"?\"....,,.;,.;,,,.',.,:?!,,.,.;;;,,.',',;,,.,,,.\n;,.,,.,,.\"!.;;.,.',;,,\"!,..;..!..,,.\"!!,,\"\"!\";??,.,.,''!?,,.,,.\",,..\",\n;.,,!;..\"?\",,,,,\",,;,,.,.,',..,(,',.;;,.\"..,,,;..,.,,;.,;;,,,';;..,,,,\n,;.,,.;..,;.;.',\".,,;,;'.,.,;,,.,.;,,,,,,,\",\"\"',?\",.\"',,,.\",\"'\"''\";.\",\n,,,;;;.\"\";',',;,?,,;,\",''\";\",.,,.,',,?,,,;',,,\"',;;,.;!'.\".'.;.,.\",;.,\n?\",!?;,.;;,..,.\",,,.;.,,\"\".\",.\"\"\"\"\"''\"\",.\";\",\".\"\"\"'\".\".;\"\"\",\"..,??,,?,\n,'\"'.,.\"\",,,?;';,.\",;\".!'\".\"\".\"!',,,.,,..,,,;;;;.,..,,,,',:;.'',.,,.,.\n,,.',,.,,,,.,.,;,,',,.''',,,,,.,..,.,,.,,.,;.,,,.,.,..'.\",!\",,,\"\"\"\"\",\"\n,.\",.\"\"\".\",,?,;\";,?\"\",;..,,,,,,...\".,,;;.;.\"\".\",,,',.,,,,;,,;;,,,,\"\",,\n,.;.\"\"\".\"\",.\";,.;;..,,,,,,,\",'\",!,.;,,,,.,,.,.,\".\";,.\".,.,,,,,.,;',.;,\n,.,;,..\"\",;,,..,,,,;,.,,,,\".,...,,,,,..,,,;;;;,;;;;;;,,\",,.,,,!!,'.\",,\n,;.'.',.,.,\",;;,.,,',!,,.;.,.;,.;,.'';,;;,,,,,!!,;;,.,,.,,,.).,;...,,.\n;'','.!,;!,;;'?,?,;;,,.?;,,,,,,,...,,,.,,,,,.,.,'!,,.,,.,.,;.,.,,,.,;,\n,,.,.,??,,?,.?.,,.;.?,,.?',,.,.?.,,..,;;;,,;,.,,?,,..?,,,,,,..?,,,,!,.\n,..,..,,..,,,,..,.,.,;,.,,,,,.,.,.\"'\",;;.,,.;.,;'?,,,.;,,,,,,,.,';.;;,\n.,;..,.;,!!,,;,';,!!,,;;!;!.,;;,.,.,.,,...,,,,.,,,;...,,;.,,;,;,;,.,,;\n,;;,,.,;'.;;;,;,.,',,;,,,,,;'.,.,',..,,,,;.,.,,,,..,;;,.;.,.,,,,.,,..,\n,,,,,.!,'.,',,;,.,;,.,.,;,.',..,,.,,.,,.,,;,,;,.,,,,.,.,.,,,,,,,,,,,.,\n',,,,,,.,,,,.';..',.;',,;,,,;.,,,.,,.,,.;,,,,.,,.,,,,.,;,,.,,,,,..,;.'\n;..,,',.,,,,;,;,.,,,,.,,,,;,,.\"?,.,\",\".\",\"',,\",.,?.,.!.;'',,?;..,,?.,,\n,';',,,...?;.,;,.,,,,?.,,,.!;,.?,..;..\",,,.,,,,.,,,,,,.;,.,,,,.,?,,,,,\n.'.,'.',,?,;,;,;',.,\"\",,.\",\",'';.';.,.,.\",\".(\"\"\".,.,,,,;;;;;,.;.,.,...\n,,;,..,,.,.;,.,,,,.,;.,...;.;,!.?;;.:,.,.,,.,,,.,,..,,,..;:..,.,,,,,.,\n;,...,(.,,;.:(,.;;.;;..,,.;;,..,,;,..,..,;...,.\".:;.?;;;,,..;.,.,..,,,\n,,,.,,,.,.,,,...;;,,.,,,,;,\",,,,,?,.,,;.;,..,,.'.,.,;,....,..,...,,...\n,.,.;.,..:;.,,,,..,,.,.,.,..',..,,...,,,,,,..,.,,,.,.,.;.;,,..,..',..,\n,;,,.,.,,,..,...,.,.;..';.,...,,,,,....;.,..,..,....,.....,,,.;.,.,;.)\n.,',,..,..,,;,,,,;;;,,;,:,.,.;,..,,,.',,,.,,;,.,.;.,,),,;.,,,,.'.(),,,\n;;,,,.;,.;,;,,,.,,.,.,,,,',,.,.,;.,,.,;,;.,!;,,;,.,,,,',,,,,,,.,;,,',,\n,,,,,,;',;?;.,;',.,,.,,...'.,.,';,;,,,;,...,.;,,,,,,,!....,,,;.,,,..,.\n:',,,,',.,..',.,.;.,,.,,.',.,;.,',,,.,',;,..,;.,,,.,,,,;;.,,.,,,,,;,.,\n,',.;,.;,,.,,,!,.',.,,,.,,.;,,;,'.,,:;,,,.,;;,,;;.,;,,,.,;;,,;,,.;,,,,\n,,,.,;(.:.,,,.,;.;;;,,,.,,,,.'('',;;,,(,.,.,,.,,;,'.,,(.;.,.,,,.'(,;,.\n,','\"'';,,,,,'.,,,';.,,,,.,.'.,!;.,;,.,,.,:\".,\",.;;.\",.;;,,,,,,.;'.,;.\n,.,,.(,,.,.,,,,,,.,,,,.\".;,.,,.\".\"',,,;.,;..\"\".\".\"\"\"\",;,.,,,\".\"?,,,,.,\n,,;,,,\".\":;,,.\".\"\".\",\",\"\"\";,;.!\",.,?\";.,\"!:,',,..\":!\"\"'!\",,,?\".,,,\",\"!\n,\".,.,?,',;,,,,,.!...,.;,?.,;,,.,(..\",;;,.;;.,,.,\",.,,;.,!\".,....\",;.!\n..\".,;;,...\",..,??.,,,,\"?.,.\",!.'!;.,;,;;..,.;,;;',,!?,;,!!',.;!',!!.,\n,;...!,,'!;;,,;,.;!,,...'..,!.!,,,,!,,!,,!(!,',..,,.,,!!?'',,.?(,,(,,,\n',,,,.,,',,!',!,.,!,';'';'.,.!(',',!'..;,!;,,!(,!(.(,!,,!!'.,!'..!,(.!\n!('.!!,(!!!((,,!;!'?!'!.,!,,,,!!!!!,.,;,?'((.(..''';(,(!!('!!!.,'!!(?!\n,?'!,!!',!,;,,..,.;;,;,,,;;,.,,,;,.,;;,,..,;,.,,;;,.,.,,,,,.;;,,,;,.,,\n,.,,..,,,,,,,,,;,,.,.;,.'.,\".;,,,,,,;,...,;,,.,,;.,.,;,;,,.,,,..,,,()(\n).,,;;,);,,.,.,,,;,,,;,,.,,,,,.,,,..,;,,.,,,',,;,.,',.,,,.,.;;;;,;;;,.\n;,.,;,,,,;;,,,,,,,,,',;;;.,.;,,;..,;,.;,,,',,,,.,;.,,,;,.,,,.,,,,,,.,;\n.,.,.,!,..,',,,,,.',;,,,,,,??;.,,,',;,..;,,,,;\";;;,,;,,,,,;,,;;;,;,,;,\n,,,;,,;,,.,,,,;?,..,,,;,;,.,.,,..\",,,,,?,.,,,,,.,,.,,.,,;!'',...,;,;.?\n;;,.,,;,,,..,.,,,.,,;.,;,..,,..?,,...,,!,.,,;,,.;,,.,,.,?,,;?..,,,.,,,\n,?,,(,,,,,,,,,?,,,?,;;,(,,'.;;.,;,..:,;,,;;;,,?:,,.,,.;,,,.,;,,,,,,?,;\n?;.,,,;;!;.,.,;,,'.,,?;;,?,;,;,,;,,,,,,..?!\":,..,.,.,,,\"\"\".\"\",\".!\"\"'.\"\n;.,.\",,,,;.,,,,,,,.,,;.,.,.,',;,.,',,..,,,;.;;;,,,,,,.',,('.,.,,,,...,\n,,;.,,,,;,.,,.,,,,..,,.;;.,,;.,.,..,.;,,,,.,';,,,?,.,,,,!...,,,,;,,,;;\n,.,.,,.;,,,.,,;,.,.,,,.;;.;,,;,,.;,,.:,(,,;;,,,,.;;,.;,.,',,.:,.;,,.,,\n.,,,.,,,;,'?!??!,..,,,,,,.,,,.,,,,:,,,,,,,'?.?,,'!':;,;,..,,;:.,;,.\".,\n,,;,.,;;.';,,.:,,,.,...,'.'?.',,.:\",,..,,,,.,.,;.',.,,,...:.,,',,,.',;\n,;,,.,,,,.,.,,,,.;,,!.,,;,,.;,,(.,,.,,.,,,..,,..,,..,.,.,,,,.,,,.,;;'.\n,.,,.,,;,,,;.',',.'.,;(),.;,,,..;,,,,,,,,.,.,,,..';,,,,.,,.,,,;.,,.,,,\n.,,.,,,,;,,,.,,.;.',;,;,.,;,,,.,,.,,.,'',,,.\"\"\".,..\".\",.,.,.,,;,.,.;,.\n,.'..,,.,',.,.,.,;,,.',,\"\"\"\",;,,,.',,,,,.\"\",\".!\"\"',\",.?..;,,,:,.'',,'.\n!',...,,,.,,.,.,',\"!\";'\"\"!,..,!\",,..',';,.;,;'.,.,,.;,.,,;';.,..,,\"!,,\n.,,.',,..,.,,.\".,,.\"\".,',.,.,.,;,..,;',.,.;,..;,,,,!,;,,.,,,,...\";,.,,\n..,'.!,;'\",,,,,?;',;.,,,\"',.,;,!;,;,;;;;,,;,;;,,.,.;;.,,.;.\";.,;:,,,;.\n,.\";.,;..;,,.,.;,,!.;.,,;,..,.,.,,,.,,.,';.,..,,,',,,.,;,.,,,.,,.\",;?.\n\",,,,'\".\";,'\"'.!,.,;;',;'',.,,..,.;.;,.,,.'\",.\"\";,\",,.,..;;;?.,,,,.,.,\n,;,,:,,;,,;,';.;.'.,;;,,,.,,,.,';;.,,,,,',,,;,,,;;;,,,,.;.,,,.,;,;,,!;\n,,.,'.,,,;,.'.,.,,,,,;.,,,,.,,,;,;,,,.,,,,,,,,;,,,.,;,,,,.,.,;,,,.;,.,\n,.,..,,.,;,,.,.;;..',;,..,.,,.!,,,.,,,.,..,.,,;,,.\",,;..';,,,,!\",,,,',\n.\",.,,,!?,,,,,.,;.:,,.,.,,,;,,;:,',,.,,;.,;.,.',,;..,.;,.,.,.;,,,,,;.,\n.',,;',,.,.'\"?,',!?;\".';....,.?,;,.,,.;',..,,'.,.;',,.,.;,.,;,.,',;',,\n,,,'(,,.,..',,.,,..,,,,.,,',.,.','.;,\",,..,.,;,,,,;,,,.\",,,;,,,,.\",\",,\n;.,,'.,,,;,;,;,;,;,,;;,.,;,;,;,,'.;,\",,.,;,,,,!,.,,\",;,.,,,,.,;,.\";,;'\n.,,',,,,\",.\",,.;,',',...\"'',,'.\",,.,;,,.\";.;.,.,,;,.\",.;.,;,,,.\",,,;.;\n'.\";,,,.\",.,;.;,:\".,;;,,(..;.\".\",?\".\",\";.\";;,;;;;,.;,,,,\",\",\",.:,,;!.\"\n,.,,.;.;.;;,,,;,,.,,.\".'..\",,,,,;,,.,.;,,.\",,\";,.,.\".\",!\",..\",;';;?;;.\n\"\"',;;'\"\",,,\"'\";,\",,.,,,\",,.;,.\";,;.;,,.,.,..\"\"\"\",,;,;(),,.;,.,,,;..\",\n,,.,,,;;\".,,.;,.'\",,,,,\"',,,\",,\",,!\".\"\"\",,,,,,,.;,.\"\".,.,.\";,,'.',,,,,\n,,;,.\",).',,.,\",,,,.'.,.\"\"\"';,\"\"\"\",,;,'.',,\"...\",,!\"?\".\"\",\";\",,.',;,,.\n,.,,,,,,.,,;,.,,,,;;.\",,,;,.,\".;,\".,,,.;;,,,.\".;,.,,.\"\"'\"\",.\",,!\",\",,;\n.,\",,,\",;.\"\"\"?!.\"'\"?\"..\"\";..\".',\".\",;.,.,.,.,,,',,.,',,,..,,.,.,,'..?\"\n,,,.,.',.'.,;,.,,,\".,,.,\",,,,.,,,.\",.,,.!,.,\";,.,,.,(,.,..,.,(,,,,',.,\n:..;,.,.,;,,,;,',.,,..',,;'.,,,..,,,,.,..,;..,,,.;'.;',.,...,.,,.,,,..\n,,.,',,..;;.,.,,.,.,,.,.;,,,.,,..,,;,?,.,,.,,.,,,,.(.,,\",;,,..:,(;.;;,\n;,.;;,(,;).,..,.,,,,,,,,,.;,.,.,;,,,,,;.,,,,,,.,,...,.;\".,,,.,;.,,,,,,\n.,,..,.',!,,..,,,,.,;,.\",,,,.,.,,,.,...;,,?.,;;;',,,,,.,.;..,?;.,;;.,,\n.,.;,.,.;,;;?,,.,,;,,..,,,;.,,,,..,\"!,.,,.,;;,.;.,,,.,,,.;;.,,\",\"\".;.,\n,.,;.,;,;.;,.,,.,,,,,,,,;,;;'.;,(,,..,;..,,\"\".,.,,.;.;,,;,.,.;,.,.,.',\n,,;,,,';,,,,;,,;,.,.;,.,,,;.?,,',,,,,,,,;,,.:,,,,,..;,.,,,.\",,,.;,,;,.\n,;.,.,.,;;;,,,,,.';,,.\".;,,,,.,.,.\"'.,,...,.,\".',..,,.\";,,,,,!\";..!.\"'\n.,.\"...,,.;',,,.\")....,,;,.,,.;,.,,.,.\",.,;'...,,,,;(,.\".',,,..\",,,.,!\n,,,.\"\";..,,,,;,.,;,;'..,\",,.,;;;;,,!,,,.,.,.;,.;,.,,.,,.,,,..,,;;,.,,,\n.,,.,(..:,,,,.,,,,..,,.'';.,,;;.,;,.;;.,,,.,,,,;,,';,,,',,..,;(,,.,,,;\n,.,,.,.,..\"!,,();;,,',,,')..,.,.,',;',,;,,,,;,,,,,,,,.\",,;,,,,;,,,',,,\n\",,,,!,..;,;,,,,\".,!\",',,\"\".\",!'\"'.\",.;..'?.;;,.\"\",';;'\",,,\"'\",.\".\"\",\"\n\"\",,,.\"\",\"\";.\".\",?.,,\"?\"\",,\"\"\"'\",.\"?\".\"??\"\".',,.?'!,\",.\";',.;,;,,\"'!\"'\n;,,.,,.,.,...,,,,..,..\",'.,..'.;,.,...,),;,,'.'.,,;:,;;;.'?;,,.,,,????\n.,,,.;;,,,.,;,,,,,,.',,.,;,,,,,,,;.';,..,.'.;';,.,,\";;,.;.,,,',,;,,.,,\n.;;.,;;,.,.,\",,;,,,.,,.,,.,,;,.,,,..;,,.,.,;,.,.,';',,,,;,,,,.,.,,;.;,\n;,,,.,',.,.,.,,;,.,.,..,,,.,.;..,.;,,,,,;,;,;,,;,,,.,.,,.!..,.!.!!.;.,\n,,.,,..,,.',.;....,,,',,,.;,!,,.,,.,,:;,,,,,,;,.?,..;,,'.''.,,;'',..,.\n,.,',,.;,,,,.',;.'.;,;;,,\"\",.\"!\"!;,.',,,.,..,;,,,';,;''.,,',;,..,,),;.\n,.',.,.;.,\"!,.,.:,,;,,,,''...;,,,.,,',,.,,.,;.;,,.,,;,..\",.\"!\",.\".\"!\".\n,'.,;,.,,,,,,;,,,,;,.,.,,;.,,.,,,,',,,.,..;,,..,,\",\"!;;,,.,..,.,\";,,.,\n(,\".\".\"\",.',,,.,.,,.,.,;..'.?,',..,,.,,,'('.,,..,;.;,...,,;'.;.,,;,.,,\n.,.,;.,.,..,.;.,.,,..,..,,.,,,,?,,!;?!\"\",,,???,.\",..,,,?\"\";,,\";.\",..\"\"\n;?\",.;.;''.,,,,.;,;,,..,,.,.,.;,,,',,.;,..;,,,,.,,.,,,',,.,.,,.\",.\"\",'\n?\"\"''.'\",,\".?',,\".\",\"\"\"\",,'\"\",,,,,.,,,'.\",\",\",?\";?'?\"\";'''\",',?\"\"\"\"?\"'\n,,,,,;,\"\";,,',;,.\"\"\"\",.\"',',.;;..,,;,,.,.,.;,,.',,,...;',:?,.'',,,\",,,\n,'.,,.',.;.,,.,,,,;',;.,;..,,'...;.,,,;.,,,.,,,,,..,;,,..,,;.,.,,,,'';\n?.,',,..,.,,,,!.,,;',,,.,,,;,.;,.;..',''().',.,,,.,,\",',;\",..!'.,.,.,,\n!,;,,,.,,.,,',..,.\":\",,,..,\"..,,;;.,',,?,..;.,.;';,.,;.',.,''?;.,,,,.,\n,.,;,;,.;;;.'.,,;..,,.,:,,,'..,?,,...,,,,,;;,,.,.,,,;.;;,,,..;??..',,;\n.,,...,.,,,..,.,;,.,;.,,,.,,,';,,,',;,.,,,.,',,.,.,.,.,..,,,,,.,,,,',.\n.,,.,;.,;;,;;!,,!\".,,..,;.,;,,.,;.\",;,,\"??\".,,,;',!,..,.,.\";;.\",.,,,,,\n,.,,,;..,,,;.,',','',,;.,,,,.,,,,,;;.,,,,?,;.,.,,..,,;,.;;,.,;.',,,.,.\n.,,.,..'.,.',',.,.;,,,.,'.?,..,.;,.,;;..'..','.,...,.;';,.,.,.,',,.,,.\n);,,,.',.,...,,...,...;,,,.;,,.',.,,',...,,,;,.,,,.\".\",?,\"',,;.,;;,,;(\n.,';,.,,',,..,,,,,.,,,.,,,.\"','?,;,.,\",\".,,,.;'.,.,.\"!!\";',?''.?\",,,',\n,!,'.\".;?\",;.,,,!,,.,,,,.'.,,;.,,,,,,;,,.',,,,,;.!,,.\";..!!,;.!!'.;,;,\n,.,,,;;.,;,.;,!.,.,;,,,!.?\"?,;!.,,,,'!\",,.,,.\",,,'.,,.,,,;,.,;,.,,,,.,\n,,,..,,.,,.,.\"\".,,,,.,;;;,,.,.,,.,,,.,,,;.,.?..,,,;,;,..,.,,,.\"!.,.\",.\n,,,;.,.,;,.,,.,..;;.,,.;.,,,.';,.'..,,!.,;,,,.,,.,,;,,,.;.;,,.,.,,.;,.\n,,.,.,.;,,,';.,,.,,;,.,,.(),.,:,,,.;.,;.?,.,.,,;,.,,,,,;,.?,!?..,,;,':\n,'(),,,'.'.;.(,',,,,,;\",..,,''.?.,,,,.,.,.,,..,,.,;;,;;.,,,'..;,,,,,,.\n,,.,,.,.,.;,,.,,;,,.;,.;.,,,',,.,,,\";,,!,.,.,.,,;,,'),.,.,;,.,..,';..,\n,,,;,,..,(;.,.,,.;,,.,.,;,,.,.;,,,.,.!,;,.;,;;,...,,,(,,.,.,,,;.;,,.;.\n.,.,.?;?..,;,,.,;,,',..,,,,.,,,.,..,:,;,,.,,,.;,.,;.,;,,,'.,.,,,.,;.',\n,,,.,..,.;,,;.,,,.,,,;.,,;..,,,,,,.,;,,,.,,,'.;,:...,,.:,,,.,.;,,,.,,:\n;',;.,',.;,.:,,.!.;,.:,;,,.'...,,.,,.,.,..,,,,.,.,',.,;;,,,.,.,;.,.,,,\n,;,,,,,.;.,;,,:,,,,,.,,,,,.,,,.,;,,,;,,,.,;,,.??,'.;,';',,.,,;.;!,,,;,\n.,,.,,.,,,,,.,,,;.,,.,,,.',,,,,,,;;,;,.,.,!,;.,.;;.,;,,,,,.,;.,,;;',.;\n,,,.,;.,,,,.,',,,,;,.,,,,.,..,.,,,.,.,..,,',.,.,,,.',.,;.,.,;,;,,.,;,,\n,...,.!.,,,',,..;.,,.,..,,,.,,,,;,,;,,.,,.,.,,;,,,,.;.;,,,,..,;;;,.,;.\n;.,.,,.;,;;,,,,,.;,,'.\"!\"\",;;,.,,..,,,;:,.'.;..,,;.,,.,,;,.,,.,(,;,,.,\n,,.,;;,,.,,..,;;..,,;\",!!!,.;,,,,',.,;,.,.;,,.,.,.,.,,,.,,,,.,.;,.,...\n.,,.,,.,,.,,!;,;;,,.,,'.,.,;,,;,,,;;;;;,,,.,.,,,,,,,.,..;,.,,,,,,..,,.\n,,.!,,.,,,,;,,;,,,.,.,.''.,..,.:,,,.;,.;.,..,;;,.,.,,,.,,..,,,,.,,,;,'\n..,,,;,;,;.;,.,,;,;,.',.,??;,,;'(,?,,,,..,??.???,\",,,,.,.;,,,,,.,,.,,.\n;.,,,;,;,',,;,.,\"\"\"\"\"'?\"\"?\"\".\"\"\",.,,,.(,(),,...,.,,\",'';.?;'.,,.,\",.,,\n'..\"..,,.;,,,.;.,.,.,;.,.,.,.\"';,,';,.!',.,',...;,.',,,;.,,.,,.\";,,;,\"\n?\".\"\"\"\"\",,\",,,.\"\",.\"?,\".\"',?.\";,.\"...,...,.,.',.,',.,,,.,.,,,.,,,..,,.\n,.\"\",'\",,.,\"\",..\";,,,.\".\"'.\".,(.\"\"'\",,',,,',,.;,',,.,;,.,.,,,,,,,\",,,;\n;,;,'.,,.,.,,,,,,,..,,!,,'',,',;.,.,.,,,',,.?,,,;,;,.,,,.,,,,,(,,.;,,;\n,;,,,;,'.,,?,';.,,.,',.,,.,,.,,;,'',,,,;,,,;.,;,,.;,.,,,,,;,,,,,,,,,,;\n,...,,,,\".,.,,.,.;,,;,,.,,,.;;;,.,,.....,,,..,.?,,,,;;,.,,',.;,,,;,,,.\n,',;..;.'',,,,,,,,,...;,,,;,,;,,;;,;,.!;;'.;,,,;;.!,,;;;.,.,,.,,...'.,\n,,...,,.,,.,,,,.,.,,...',,,,,.,,,,,'.,,,.',,?;,,,';,,,;;,,.,,,.,.,;,,,\n..,.;,,';!!.,,,,...,.,,,,.,.,.,,.,,,.,,,.,.,..'..\"....,..,.,.,;..;.,,.\n.,,.,.,,,.,,,,,,,.,;,,;,,,;,,.,.,,,,.,..,,;.,,..,.,,,.',,,!,!;.;,,',.,\n.,.'.',;;,,.,\".,;,.;,',.,.,.,,'',,,;.,,.;;;);,,;,,:.,;,,,;,.,,.,,.;',;\n;.,!,...;,....,;;',;,.,,;.,.,:,,.,;,,,;,,,\",,';,;,'!,,,,,,,.,,;,,,,,.,\n,,.,,.,,.,,.;,',..,;,,.:,;.';,,.,.\";.,;,.;;,!,,\",,';,.,.,.,,,\";.,'..,,\n,?!,'.;:!'.,,,,,',;!;,!,;!,;,,,',;,,.,,,;\",?,,;\";.,;;'.\".;.;?.\",.?,,,'\n;.,,;.,,,!\"\"!\"\"\"\"\",!;.\",,,\".,'!,;?,.'.,,\",.,,,,;'\"\",.\"\",,.,,,',',.,,;.\n,,,,,,;.,,.,,,,(,,,.,,,)!,?\",;\",\"\"\".,;'.,,\".\",\",,\".\";;,',,.,',,',.,',.\n,,,,.,.,;\",;,(,.,,.;;,.,\",\",\".;\",',,,!,.\",;,,;\";.\",,,...\"',,.,,\";\".?,\"\n.\"'',.\"\"\"\"?.\".\",'';,,,;,,,,,\",..;,.\",'?\",!!'\"?\"\"?,'''.,.,,,;,.,;;(,.;.\n,,,.,',.:,,.,.,\".,,;.,.,..,,;.;),;,,;,,.,;,,,..;.,.';;.,,;;..,,,;.;,,,\n.,,.,\"..,,;,,;:,,,,,,,,.,;,,,,,;,.,,,,.,,,,,,,,,'.,;;;;.,,.,;.,,,.,,?;\n?,?;;,;.,;.,,.,?,,,,,,.,,;,,,,,,.,,.;,,;,..,',,;;,.!?!;;;.;,.;.,,,;.,,\n,,..,,;;,.,!,;,.,.,,.,\".,,,',,.,',.;.;;.,,.,;.',,.,';,,,;.,,,,.;;,,.,:\n;.,.,.,,,,,.;,,,....,,.,,;..,,,,,,,;;..,',.,,.,.,.',..;,.,;,.,,....,;'\n.,.?.!,,,,,.!.,,,,,,;,,;,.,,.,,,,,,;,..,,..,,.,.;,.,,;,,.,;,''.?.,,.,;\n,.,,,.,.,,\";.,.,,','),,.,,',,,.,().,,...,;,,,,!,().,).?',,,;,,,'.;.,';\n;,,,.,,,,;,..,;;.,,,(,,,,,,(,,.,,,,,,;,.:,.;,,,,,.,,;.,,,.,,,,,.:,,.,,\n;.,,;,',,,',..,(,,,,,,.',;,,.,;;.,.:,';,.,,;.,;,.,.,,,,,;,';..,,;,.,,,\n';,,;,,(,,,;.;,.,;,,,,,,,;.,,.:,,;,.,;,,.:,.,,..;,..,;,,.;,.,;,;,,,;,;\n',;?;;,;,,;..,,;,,,,,,,,.,.,;,,.(,..,,..,(.'(;(;.,.',,,;;((,,,!!,,,;,,\n,.!,.,,;.';?;.,;,?.,?',,,.,?,??',,'?,,,;,?,,,.,;.,,,;,!;,!;',?,,,!.;(.\n,.(,''.''.,',,,,.,,.,.,,,!;.,,;;..,,;,;,.,,.;,,,,.\".\".\"?\".,\"\"\"!,';,.\"\"\n?,,'\",;;,\"!\",(',.,.,,;,\",',;,\":,.,,,,.;,,,;.;,,,,,;,...,,.,;.,;,,.,!,,\n,.;;'.,.,;,,,,,.,,,.,,,,.;.,,;,;,,;,,.,,:,;.,'.,,.,,'.\".,,,.,,,.,,,;,.\n,.,.;,;,,,,,...,,;\"?,?';..\",,.,.;\"?!;!''!,!.,,;,',;,:..,,,,,,,(),,.,,,\n;,.,,;;;;,,\"!;,;.,;..',,,;.,.,,,,,';,',(;.,,;;,!,,,,',,;.,,...,..,,.;.\n,,,..,',',;,.,,,',,,,',;.,,,;,,,.?;;;;;;;!;;,,,,,,,;;!,,!,,.,,,,,,,,.\"\n;;\";.\"..?,?\"\"?\"\",\"\"',;,'\"\"'!.,,...\".\".,.',,!,,,,,,.\",;,,,\"\"\"?\",.,.\"!,,\n,,\"!?,,\",.,,.,,,\",;;'.,;,,.,.,,,;.,;,;,',.,,;,,'.;,,.;.,.,.,,,,.:,;:,,\n.,??:.,,\",.;.,:\"!,,,,,.;;.,;,;.,;.,,,';,,;,;;,,.,;,,,.;,,.,.,,.,',.,;,\n.\".\"\".\"\",,\",,!,;,;.,,,.,,,.;;;;,,,,,,.,,.\",;.!;;,'!.\";,,,,\"!,,,;,\".,;;\n;;;',,'',,,,.\"?\"\";;.\"..\"\"\"\",?.\"\"\",,'.;,,,;.;.,.';',,,.,',.;.':??.;,,,\"\n;,,:;!',,'.!;;.;!,,,,\";,,.,,\";,,\",',;:.:.,,,.,.,,;.,.',\"\",,,;!,',,''',\n,,,',,\";.\".,..\"\"?\",,??,!\"\",..;;,,.\"\";.,;,,;,,'',,\",,\".,,\";,,.\",,\"!,,,;\n'\",;,.,.,;,.;.,..\",?.;',''..\",';,,,,,.\"!;;,;.\",;.;.;,,;,,;;',.,;.\";.,;\n,.,,!...;..,..,,;!\"',;;,',;,,.',,',,\",:!.,,,;..,.\".\"\"\"\".!.,..!.,.,.?,,\n?\",;?,,.?,,;,?,?,,.,''?\"\".,.,,,;,,,,.,,;;,,..\"?.,.,,,';.,,,.,;;,..,!!,\n!.,,,.,.,,,..,,.\";.,;..'.;.???,'?,,..,.;...?';;,;.?..,?\"'\",!',?!\"',.',\n,\".,',.;.,,,,',,.\".!,,\"\"\";;.,;.,,,.,\".,.';,,,;'.;,;,,,,.,.,,.,.;'.,.\",\n.;!,,,.,,,\",;.,;.,,,,,,,,,.;,,,!,,.,.,.',;,,.,.;.,,.;\".\",,,,,,.,,,.\".\"\n'\"',\";?\"\"\"\"';,!.,,.\"!.\".,.\".!.\"';.!!\"\"\"\"\"\".!\";!\".,,..\",,;;,\".,;,,'\"\"',\n'''.,,.,,,',,,.,.,.,;..,,,.,,,.,.;(),,,,.,;,,,,,..;,.;;,,,,.\"\"\".\"..\"\"\"\n.\"\".!.\".;'?;';.,,;....;..;',.'!,,,.',.'!,,;..;.!\"!\"\"\"?\"\"\"'\",,?.\"\"?;.\",\n.\"',.,\"\"\".\"\"\"!\".,,,.,(\"!,.!'.!,',.?,!!,,;,,.\",,\"\",,,.'..\"\",',,,;.,.;;,\n,;,.,;.;;,;.,.;,\"''?'\"\",.,,,\"?\";,,'',,;',,.,';'.,,;''.,,.\".,,,\"\",,,;,.\n;,;,,;;,,,,..(,,....;\";.\"!;\",,.\";\"\",.,;.(\",,...,.,..,!?!,...;.,,,;;;,;\n,,,.,,.,..,',;';,;;,',..,,,;,;,;,;,.;;.;:,,;'.;,;.,,;.,,;,..,,,'!,;';.\n,,\"!;,;,,,,,,,;.,,,,,.,;,,.;,;;',;;.;.,;,.\",,.':.',..;,,;;,,,;',,,\"\".\"\n\",.\",!;,\"\";;\";\"\";,.,'\"\"!.;,,.,;,,,,;.,;,,,;;;;.,!',;.,,.,,,,,.;.;.,..\"\n\"\"!!!,!.;',!,!,,,?,,,!,,?,?.!,.!,?;.,,.!\"!!';,!!,\".;;.\",'!,',\",;,,??;;\n;,,,!,?,,.,;!';,.,,,'.,,,,,,,,,\",,.\"\"\",;,,.!,.,,',,..\".\",\"..!,'!,!!;.\"\n;\"!';.;,.;,,,,..,,,;.,;,',,.,.;;;!.,,.,;.,.,,,,;,,,,.,,\"'..;\",',..,,,,\n.,;.,'.,,.,,.;,,,',.,'.,;,,,,,;,.,,,.,.,';.',,.,,;,;.,..(,,.,;,.'.','.\n;,.,.,,,.,',;,,.,!'.,';,,.,.,';,;.\"\"\"\"\".\"!!;,,.,,,,,.,.,,;,;,,,'.;,,,,\n,.,';,';!\",(.\".\",';;,?!;,\"\"\"\",;!,.,;,,!,,.,\".\"\";.,,.,;,,.,,;,,:,,,',.,\n,,,,;,.,'?,.;,.\"'!,!\".\",!!.,.;,.;;,;.;.,,;,;,,...,,;.!\",\",;,;,.,,!,;.,\n,.,.\".,,,\"!.,,;.\".,,,.,,'.',,;,.;;,,,,;,.;!!,,'.,,;;,;,,,.,,,;;';,,,,,\n,;,;,.,,',,,.;;;.';,,,\";\".\"\",,,.?\"\"..\"\"!\"\".!'.\"\"!.\".\",,,!!,!;!\"\",;:???\n!\"',,'..,;',;,,,,.,\"\":,'!':!,,;,.',;;,,\"\";!,.;'.;.,,;,.;.,,!,.?,,.;,,!\n',,,,.;,!\"\",'..!,,.\",,.\"\"\".;.,.\"!,!;.,!.,..!'';,..,,',;,,.;.;,,\"\"\"\"\"!\"\n\";.;\";\"\".\";\";.;,,;.;.;,,.\"\"?,;,.,,;,.;;?!!!\"!!,,,;,.\"!:;,.;,.;.,,.\";,.\n,,;'';,;',,;..\"...;,,,?;,,;,.,.\",!,,,,,,;,.,.;.,,,';:';.;;,.\"!.\"\"\"?!.,\n',;,,.,,,,.,;,,,,,.,,,\"!,;;;;,;.\"\",:,,;.,;,;,.\",'?,!,!\";!?;!.,,,!!\"','\n,,,,.,,'..,\"\",;,,\".;,??.,,;;.,,!;;;,,',.,?,;,.,,,.,,,;,.,;,;,,,,;;.\".'\n.,';,,,,.,,,,,,,.,,,(,.,..\",,,\";'\";',,,,,,,,,,,,(,,,,,,,',.,,;;,,,,!!;\n,,,!\".\"..\".\"..\",;\"',.\",.'\",,,.\",.,.'.\"',,.\"..\"'\".'\"...\"..\".\",','.\"..\",\n...\".'.'\"('\".'\",..\",,;,.\".'\",,.'\",;'\",..\".'\".',,..,\",).'\",,'.\"'.\",.'\",\n'\",,'.\",..\"..\",.,\",,,.'\",'\"'.\".\",,.\"','\",.\",,.,\",'.\",'\".\",'.\",,,;:',,,\n,'\"';,.'\",'.\",'\",.\".'\".'\".\",.,,\";,,..\",.\",..\";;;,,,),,.\"\",,...\"\"\"\"\"\"!\"\n\"!\"\"\".\",.\",;;..\".,.'.\".\"'..\".(,.\",,'\";.\".,,.\",,..\",..\"(..\"..\",..\",'.\",\n,;.\"!.\",..\n\n\n\nFeel free to experiment with extract_punct() and let me know how it goes. Maybe include en and em dashes, or interrobang or something."
  },
  {
    "objectID": "posts/2021-09-12-punct-lit/index.html#environment",
    "href": "posts/2021-09-12-punct-lit/index.html#environment",
    "title": "Extract punctuation from books with R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-08 13:11:39 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] stringr_1.5.0    dplyr_1.1.2      gutenbergr_0.2.3\n\nloaded via a namespace (and not attached):\n [1] bit_4.0.5         jsonlite_1.8.7    compiler_4.3.1    crayon_1.5.2     \n [5] Rcpp_1.0.10       tidyselect_1.2.0  urltools_1.7.3    parallel_4.3.1   \n [9] triebeard_0.4.1   yaml_2.3.7        fastmap_1.1.1     readr_2.1.4      \n[13] R6_2.5.1          generics_0.1.3    curl_5.0.1        knitr_1.43.1     \n[17] htmlwidgets_1.6.2 tibble_3.2.1      pillar_1.9.0      tzdb_0.4.0       \n[21] rlang_1.1.1       utf8_1.2.3        stringi_1.7.12    xfun_0.39        \n[25] lazyeval_0.2.2    bit64_4.0.5       cli_3.6.1         withr_2.5.0      \n[29] magrittr_2.0.3    digest_0.6.31     vroom_1.6.3       rstudioapi_0.14  \n[33] hms_1.1.3         lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21    \n[37] glue_1.6.2        fansi_1.0.4       purrr_1.0.1       rmarkdown_2.23   \n[41] tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#tldr",
    "title": "Panic! In The Toolshed",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote some slides to tell data scientists in the public sector what they already know: share the tools youâ€™ve developed."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#an-axe-to-grind",
    "title": "Panic! In The Toolshed",
    "section": "An axe to grind",
    "text": "An axe to grind\nIâ€™m speaking today at an event for UK government data scientists with a theme of â€˜the data science toolshedâ€™. My plea is small: I want public sector workers to share the tools they make1.\nWe should build modular things like R packages that are easy to use and develop; make them available to everyone to minimise duplication and encourage collaboration; and maximise reach by telling everyone about it. This is how we improve quality and build our community. And save money for the taxpayer.\nHandily, this is already expressed in the governmentâ€™s Technology Code of Practice:\n\nShare, reuse and collaborate: avoid duplicating effort and unnecessary costs by collaborating across government and sharing and reusing technology, data, and services.\n\nIâ€™ve had a small experience with this: I made the {a11ytables} R package to help producers of stats publications automate the creation of best-practice, accessible spreadsheets. Itâ€™s now being used in several organisations and is referenced from the governmentâ€™s best-practice guidance.\nSuccess? Maybe. But also PANIK: Iâ€™ve left the organisation where I made it; I was the sole developer; I worry that I should have thought about this sooner; that I should fork and update it; that updating users will be hard; that links to the old package will break; and so on. Hopefully people will learn something from these missteps."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#burying-the-hatchet",
    "title": "Panic! In The Toolshed",
    "section": "Burying the hatchet",
    "text": "Burying the hatchet\nThe slides are live on the internet and embedded below, or you can view the source on GitHub. Press s to pop out the speaker notes, o for a slide overview and f for fullscreen.\n\n\n\n\n\n\n\n\nThe slides were made with Revealjs via Quarto, because of course they were."
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#clamp-down",
    "title": "Panic! In The Toolshed",
    "section": "Clamp down",
    "text": "Clamp down\nSo, we should sustainabilise (not a word), centralise and advertise the useful things we make. Maybe we could have a list of tools weâ€™ve produced collectively in the public sector? Something like an â€˜Awesomeâ€™ list or a CRAN task view. Maybe that would make it easier to find and develop existing solutions instead of building from scratch all the time.\nBuild a toolshed. They will come?"
  },
  {
    "objectID": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "href": "posts/2023-06-13-panic-in-the-toolshed/index.html#environment",
    "title": "Panic! In The Toolshed",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:03:30 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#tldr",
    "href": "posts/2022-03-31-hastings-half/index.html#tldr",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "tl;dr",
    "text": "tl;dr\nI made a small R Markdown site that contains interactive maps of the route of the Hastings Half Marathon."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#half-distance-double-delay",
    "href": "posts/2022-03-31-hastings-half/index.html#half-distance-double-delay",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Half distance, double delay",
    "text": "Half distance, double delay\nI signed up for the Hastings Half Marathon in March 2019 and finally got to run it in March 2022 after two years of pandemic-related cancellations.\nI managed a time of 1:44:151 in terrific conditions and raised money for Sands, the stillbirth and neonatal death charity (at time of writing you can still donate).\nAs a nice bonus, the finisherâ€™s medal featured Alan Turing, who spent some of his childhood in the area."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#running-or-climbing",
    "href": "posts/2022-03-31-hastings-half/index.html#running-or-climbing",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Running or climbing?",
    "text": "Running or climbing?\nThe Hastings Half is a popular and an interesting course, mostly because of the third dimension: there are two short, sharp early climbs, then a long sweeping one, later returning downhill to finish along the seafront of the town.2\nThere are precious few resources online that illustrate the course, however. You can find a low-quality map on the official website and get an elevation profile elsewhere, but I thought it might be useful to create a quick and tiny webpage with the x, y and z dimensions in an interactive format."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#run-route-run-code",
    "href": "posts/2022-03-31-hastings-half/index.html#run-route-run-code",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Run route, run code",
    "text": "Run route, run code\nSo, I recorded the route with my Apple Watch and downloaded the data as a GPX file, which contains geospatial data in an XML-like format. Iâ€™ve talked about Apple Health data before, and also about a small package I made to read GPX data, called {gpx3d}, which came in handy.\nWith that data I made three interactive maps using R:\n\nA birds-eye view with {leaflet}, which allows zooming and panning and has markers for each of the kilometres\nAn elevation profile with {plotly}, which shows the distance and elevation on hover\nA 3D trace of the course with {ggrgl}, which can be dragged to show relative distance and elevation\n\nI embedded these maps in three separate tabs of a {flexdashboard}, an R Markdown format that lets you create simple, single page dashboards. I used {bslib}, {thematic}, {emo} and Google Fonts for styles and embellishment.\nI pushed the files to a GitHub repo and served the HTML via GitHub Pages to a dedicated webpage at matt-dray.github.io/hastings-half/.\nHere are some screenshots of each page:\n\n\n\nScreenshot of the interactive route map, made with {leaflet}\n\n\n\n\n\nScreenshot of the interactive elevation profile, made with {plotly}\n\n\n\n\n\nScreenshot of the interactive 3D trace, made with {ggrgl}"
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#see-you-in-2023",
    "href": "posts/2022-03-31-hastings-half/index.html#see-you-in-2023",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "See you in 2023",
    "text": "See you in 2023\nUltimately the webpage is a very quick demo, but I hope others will be able to use to get a sense of the course.\nThe next step will be to add fourth and fifth dimensions: smell and sound. As soon as you reach the bottom of All Saints Street you hit the historic Old Town seafront, where youâ€™re immediately perked up by the scent of frying chips and the screech of extremely raucous seagulls.\nThereâ€™s no place like home."
  },
  {
    "objectID": "posts/2022-03-31-hastings-half/index.html#environment",
    "href": "posts/2022-03-31-hastings-half/index.html#environment",
    "title": "Interactive maps of Hastings Half Marathon",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 15:43:15 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#tldr",
    "href": "posts/2022-03-15-renv-profiles/index.html#tldr",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "tl;dr",
    "text": "tl;dr\nI think you can use the {renv} package to create separate reproducible environment profiles for each of your {distill} blog posts."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#profiled",
    "href": "posts/2022-03-15-renv-profiles/index.html#profiled",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Profiled",
    "text": "Profiled\nFunctionality comes and goes in R packages. How do you deal with that in the context of a blog built with R? What if you need to go back and change something in a post from four years ago?1\nI built a demo {distill} blog to test whether the {renv} package might be a viable solution for reproducibility on a post-by-post basis.\n{renv} is a package by Kevin Ushey that records your dependencies in a text â€˜lockfileâ€™. It typically works on the scale of a whole project, but since version 0.13.0 you can have multiple profiles within a given project.\nI think this means that each post can have its own profile with its own distinct set of packages and package versions.\nThat means you can easily recreate a specific environment for a given post at a given time if you need to alter and re-render it in future."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#example",
    "href": "posts/2022-03-15-renv-profiles/index.html#example",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Example",
    "text": "Example\nIâ€™m presenting this here as a theory, really, but Iâ€™ve also made a demo blog to try it out. It seems to work.\nThere are two posts on the demo blog. They both use the {dplyr} package, but one depends on an old version (0.8.5) and one depends on the current version (1.0.8).\nUsing {renv} profiles means that these package versions donâ€™t interfere with each other.\nThe post depending on the older {dplyr} version canâ€™t access the across() function, but the post depending on the newer {dplyr} version can use across().\nIn other words, the environments associated with the profiles for each post are totally isolated from each other."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#how-to",
    "href": "posts/2022-03-15-renv-profiles/index.html#how-to",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "How to",
    "text": "How to\nOf course, you first need a blog. I used {distill}2 for the demo, a package by JJ Allaire, Rich Iannone, Alison Presmanes Hill and Yihui Xie. You can follow the guidance from RStudio, but basically:\n\nCreate your blog with distill::create_blog()\nBuild it with rmarkdown::render_site() (or â€˜Build Websiteâ€™ from the Build pane of RStudio)\nInitiate a reproducible environment for the blog as a whole with renv::init()\n\nAnd then a new-post workflow could look like this:\n\nCreate a new post with distill_create_post()\nActivate a profile for the new post with renv::activate(), providing a unique name to the profile argument (I suggest the postâ€™s folder name as seen in the blogâ€™s _posts/ folder)\nInstall the packages you need for the post with renv::install()\nCapture the dependencies in the profileâ€™s lockfile with renv::snapshot()\n\nIn code, that might look a bit like this:\n\ndistill::create_post(\"new-post\")\n\nrenv::activate(profile = \"YYYY-MM-DD-new-post\")\n\nrenv::install(\n  \"distill\",\n  \"rmarkdown\",\n  \"palmerpenguins\",\n  \"dplyr\"\n)\n\nrenv::snapshot()\n\nFor the demo blog, I called the two profiles â€˜2022-03-14-dplyr-085â€™ and â€˜2022-03-14-dplyr-108â€™, which you can see in the renv/profiles/ folder of the project repo.\nThese are named uniquely for the two separate folders in the _posts/ directory that contain each postâ€™s files. This naming structure should make it easy to remember the profile associated with each post.\nAs I worked on the posts, I switched between the two profiles with renv::activate(), passing the relevant profile name to the profile argument.\nNote that passing NULL as the profile argument means you switch to the default profile associated with the project as a whole, i.e.Â when you ran renv::init()."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#yeah-but",
    "href": "posts/2022-03-15-renv-profiles/index.html#yeah-but",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Yeah, but?",
    "text": "Yeah, but?\nThere are obvious pros and cons to this approach.\nFor example, maybe itâ€™s a bit too dependent on the user: they have to remember to switch between the profiles, etc.\nAnd I donâ€™t think you can properly rebuild the site again with rmarkdown::render_site(), because this function will run based only the currently active {renv} profile, rather than rendering each post in the context of its own specific profile.\nBut ultimately isnâ€™t it worthwhile to be able to rebuild a post in future if you need to change or update something? Maybe.\nIâ€™d be interested to hear other criticisms, especially before I try and use this approach for real.\nMeanwhile, I know that Danielle Navarro has approached this with a more thought-out and sophisticated approach and has created a work-in-progress package called {refinery} to help build a separate environment for each post in a {distill} blog.\nIn general, Danielleâ€™s blog does a brilliant job of explaining the problem of blog reproducibility and the technicals behind it. I suggest you read that post if you want to know more."
  },
  {
    "objectID": "posts/2022-03-15-renv-profiles/index.html#environment",
    "href": "posts/2022-03-15-renv-profiles/index.html#environment",
    "title": "Reproducible {distill} posts with {renv} profiles",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#tldr",
    "href": "posts/2021-03-23-shiny-badge/index.html#tldr",
    "title": "Make a {shiny} app README badge",
    "section": "tl;dr",
    "text": "tl;dr\nUse the {badgr} package to make a clickable README badge for a repo that contains an R Shiny app:"
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#badgr-badgr-badgr",
    "href": "posts/2021-03-23-shiny-badge/index.html#badgr-badgr-badgr",
    "title": "Make a {shiny} app README badge",
    "section": "Badgr badgr badgr",
    "text": "Badgr badgr badgr\nI made the {badgr} R package to take advantage of the full flexibility of shields.ioâ€”a service that builds README badges from a supplied URL stringâ€”from within R itself.1 You can find the source for the package on GitHub, visit its site built with {pkgdown}, or read a blog post about its inception.\nWait, whatâ€™s a README badge? Itâ€™s one of those little clickable buttons that provides at-a-glance info about a code repository, like its test coverage or build status.\nTurns out you can make custom badges by building a special URL to shields.io. For example, I use custom badges to tell people that a repo has an associated blog post. This one goes to the post about {badgr}:\n\n\n\n\n\nRecently I added a badge to each of my GitHub repositories that contain a Shiny app. The purpose is to let visitors:\n\nknow that the repo contains a Shiny app\nknow whether the app is hosted on the internet\nclick the badge to go directly to the live app\n\nI put out a tweet about this that got a little traction, so I figured it would be worthwhile to record the idea more permanently."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#install",
    "href": "posts/2021-03-23-shiny-badge/index.html#install",
    "title": "Make a {shiny} app README badge",
    "section": "Install",
    "text": "Install\nFirst, you can install the {badgr} package from GitHub using the {remotes} package.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/badgr\")\n\nAt time of writing, the package should â€˜just workâ€™, though itâ€™s dependent ultimately on the shields.io service, of course. Leave an issue if you find something wrong."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#template",
    "href": "posts/2021-03-23-shiny-badge/index.html#template",
    "title": "Make a {shiny} app README badge",
    "section": "Template",
    "text": "Template\nThe code is in a GitHub Gist, should you want to access or bookmark it there. Itâ€™s a call to the get_badge() function:\n\nbadgr::get_badge(\n  \n  # Badge label\n  label = \"Shiny\",  # left-side text\n  label_color = \"white\",  # left-side colour\n  \n  # Badge message\n  message = \"shinyapps.io\",  # right-side text\n  color = \"blue\",  # right-side colour\n  \n  # Logo\n  logo_simple = \"RStudio\",  # named icon from simpleicons.org\n  logo_color = \"blue\",  # colour of simpleicons.org icon\n  \n  # Markdown link\n  md_link = \"https://matt.dray.shinyapps.io/randoflag/\",  # clickable link URL\n  \n  # Convenience arguments\n  browser_preview = TRUE, # preview badge in your browser\n  to_clipboard = TRUE  # copies markdown to paste into readme\n  \n)\n\n# Opening browser to display badge preview\n# Badge Markdown added to clipboard\n# [1] \"[![](https://img.shields.io/badge/Shiny-shinyapps.io-blue?style=flat&labelColor=white&logo=RStudio&logoColor=blue)](https://matt.dray.shinyapps.io/randoflag/)\"\nThe output is a Markdown string that you can paste into your README. You can see the string is actually a link within a link: the URL to the shields.io badge is wrapped by a link to the Shiny app itself.\nConveniently, the to_clipboard = TRUE argument copies the string to your clipboard and browser_preview = TRUE opens a browser window with a preview of your badge in a new tab. Youâ€™ll notice these outcomes are referenced in the output from the function.\nPasting that string into your Markdown or R Markdown README results in this badge when rendered:\n\n\n\n\n\nIn this example, the badge is from the repo for â€˜randoflagâ€™, which is a guessing-game Shiny app hosted on shinyapps.io, which serves a random emoji flag. You can read about that app in an earlier blog post.\nNote also that {badgr} is capable of incorporating bespoke icons, but we didnâ€™t need to provide a custom RStudio logo because shields.io can easily display any icon thatâ€™s already part of simpleicons.org."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#variants",
    "href": "posts/2021-03-23-shiny-badge/index.html#variants",
    "title": "Make a {shiny} app README badge",
    "section": "Variants",
    "text": "Variants\nI think the badge is a useful at-a-glance recognition that the repo contains a Shiny app, whether itâ€™s hosted or not, and a convenient clickable link to the app itself.\nI think the wording on the right-hand side of the badge is a good place to indicate the appâ€™s status. Text variants could, for example, be:\n\nshinyapps.io (the app is live on RStudioâ€™s shinyapps.io service)\nnot hosted (the repo contains a Shiny app, but itâ€™s not hosted online)\nnot yet hosted (the Shiny app in the repo is in development, but not yet live on the internet)\n\nIâ€™ve used all three of these so far, but you can use whatever text you want, really.\nIâ€™ve already got use out of custom Shiny badges for my repos. I look forward to seeing some more in the wild."
  },
  {
    "objectID": "posts/2021-03-23-shiny-badge/index.html#environment",
    "href": "posts/2021-03-23-shiny-badge/index.html#environment",
    "title": "Make a {shiny} app README badge",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:43:27 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] badgr_0.1.1\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     base64enc_0.1-3   fastmap_1.1.1     xfun_0.39        \n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       clipr_0.8.0      \n[13] evaluate_0.21     yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7   \n[17] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#tldr",
    "href": "posts/2022-09-24-pixeltrix/index.html#tldr",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve written {pixeltrix}, an R package that lets you select â€˜pixelsâ€™ interactively from a plot window and returns your final image as a matrix. You could use it to design sprites, for example."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#pixel-perfect",
    "href": "posts/2022-09-24-pixeltrix/index.html#pixel-perfect",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Pixel perfect",
    "text": "Pixel perfect\nIâ€™ve written before about creating very simple pixel art in R. To create a sprite of Link from The Legend of Zelda I had to write out by hand a vector that encoded its pixel values. It was tedious.\nThere are, however, a couple of options in R to take an image and extract the pixels from it: see Florian PrivÃ©â€™s Shiny app in the {pixelart} package and Mike Chengâ€™s (AKA coolbutuseless) blog post that also describes how to animate them.1\nBut what if you want to create a sprite from scratch? It would be great if you could click pixels interactively and be returned a matrix encoding your image.\nI couldnâ€™t find an R package to do this, so I decided to make a very simple one: {pixeltrix} (as in â€˜pixelâ€™ and â€˜matrixâ€™, but also as in â€˜tricksâ€™2, lol).\nItâ€™s written entirely in base R (no Shiny or server needed) and can be run in the R console. Itâ€™s basically a repeat loop that runs image() to plot squares3 (hereafter â€˜pixelsâ€™) and locator()4 to let you click those pixels on and off. The coordinates of each click are matched to the nearest pixel centre, the pixelâ€™s value is incremented by 1 (or wrapped back to zero) and the image is redrawn.\nThe package is still in development, but I think itâ€™s reached a useable state for my own purposes.\n\nâ„¹ï¸ Update\nI lied. The package has been updated since this post. You can read about the changes in a more recent blogpost. Highlight: you can make animations now."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#enter-the-matrix",
    "href": "posts/2022-09-24-pixeltrix/index.html#enter-the-matrix",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Enter the matrix",
    "text": "Enter the matrix\nThe package is available for download from GitHub. I have some ideas on how to improve it; go ahead and add your own ideas to the issues tracker.\n\n# install.packages(remotes)  # if not yet installed\nremotes::install_github(\"matt-dray/pixeltrix\") # v0.1 in this post\nlibrary(pixeltrix)\n\nThe main function is click_pixels(), to which you pass plot dimensions (how many pixels tall and wide), the number of pixel â€˜statesâ€™ (the number of values a pixel can take, so binary would be 2) and whether you want to put a grid over the plot (makes it easier to see where the pixels are).\n\nclick_pixels(\n  n_rows   = 3,\n  n_cols   = 3,\n  n_states = 2,\n  grid = TRUE\n) -&gt; x\n\nThis opens a plot window. Repeatedly click a pixel to cycle it through the number of states you asked for. For example, n_states = 4 means you cycle it through values of 0, 1, 2 and 3 (wrapping back to 0), which will be manifested in the plot as different shades of grey.\nNote that you can only click one pixel at a time, so youâ€™ll have to do a lot of clicking if your n_states value is high. Colouring stuff in really slowly is called â€˜mindfulnessâ€™, I believe; good for your wellbeing.\nWhen youâ€™re done, you press the Esc key, or the â€˜Finishâ€™ button in the plot window of RStudio. I saved all the images below via the â€˜Exportâ€™ button in RStudio.\n\nYouâ€™re returned a matrix that contains the value of each pixel in your image. So if you had set n_states = 3, a twice-clicked pixel gets the value 2, an unclicked pixel defaults to a value of 0, etc.\n\nx\n\n     [,1] [,2] [,3]\n[1,]    1    0    1\n[2,]    0    1    0\n[3,]    1    0    1\nThis matrix is basically a blueprint of the image you created. You can take this and do other things with it. Maybe youâ€™ll make art by passing it to ggplot() to match each of the pixel-state values to a colour. Maybe youâ€™ll use it to plan your crochet or cross-stitch5, or to teach spatial epidemiology (!).\nIf you want to edit your matrix, you can pass it into edit_pixels(). This means you donâ€™t have to start over from scratch with click_pixels() if you only want to change something small. Note that you can provide a higher n_states value to edit_pixels() than the current maximum in the matrix you provided."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#sprite-club",
    "href": "posts/2022-09-24-pixeltrix/index.html#sprite-club",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Sprite club",
    "text": "Sprite club\nMy main purpose for the package is to create simple sprites.\nI used {pixeltrix} to make each of the sprites below. They took about a minute each. It wouldâ€™ve taken much longer to write their matrices by hand and to keep passing them to image() to visuliase them and make sure there werenâ€™t any mistakes.\n\nTamagotchi\nHereâ€™s a 1-bit original kuchipatchi sprite from the original 90s Tamagotchi digital pets. It uses the default of two pixel states (binary): so 0 for white and 1 for grey.\n\nclick_pixels(14, 14) -&gt; tam_sprite\n\n\n\n\nClick to expand matrix\n\n\ntam_sprite\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n [1,]    0    0    0    0    1    1    1    1    1     1     0     0     0     0\n [2,]    0    0    0    1    0    0    0    0    0     0     1     0     0     0\n [3,]    0    1    1    0    1    0    0    0    0     1     0     1     0     0\n [4,]    1    0    0    0    0    0    0    0    0     0     0     0     1     0\n [5,]    0    1    1    1    0    0    0    0    0     0     0     0     1     0\n [6,]    1    0    0    0    0    0    0    0    0     0     0     0     1     0\n [7,]    0    1    1    1    0    0    0    0    0     0     0     0     1     0\n [8,]    0    0    0    1    0    0    0    0    1     0     1     0     0     1\n [9,]    0    0    0    1    0    0    0    0    1     0     1     0     0     1\n[10,]    0    0    0    1    0    0    0    0    0     1     0     0     0     1\n[11,]    0    0    0    0    1    0    0    0    0     0     0     0     1     0\n[12,]    0    0    0    0    0    1    0    1    1     1     0     1     0     0\n[13,]    0    0    0    0    0    1    0    1    0     1     0     1     0     0\n[14,]    0    0    0    0    0    0    1    0    0     0     1     0     0     0\n\n\nPokÃ©mon\nHereâ€™s the player character from the first generation of PokÃ©mon games on the Game Boy. It uses three states (n_states = 3): value 0 is white, 1 is light grey and 2 is dark grey.\n\nclick_pixels(14, 16, 3) -&gt; poke_sprite\n\n\n\n\nClick to expand matrix\n\n\npoke_sprite\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n [1,]    0    0    0    0    2    2    2    2    2     2     0     0     0     0\n [2,]    0    0    0    2    1    1    1    1    1     1     2     0     0     0\n [3,]    0    0    2    1    1    1    1    1    1     1     1     2     0     0\n [4,]    0    0    2    1    1    1    1    1    1     1     1     2     0     0\n [5,]    0    2    2    2    1    0    0    0    0     1     2     2     2     0\n [6,]    0    2    2    0    2    2    2    2    2     2     0     2     2     0\n [7,]    2    0    2    0    0    0    0    0    0     0     0     2     0     2\n [8,]    2    0    0    0    0    2    0    0    2     0     0     0     0     2\n [9,]    0    2    2    0    0    2    0    0    2     0     0     2     2     0\n[10,]    0    2    2    2    0    0    1    1    0     0     2     2     2     0\n[11,]    2    0    0    2    2    2    2    2    2     2     2     0     0     2\n[12,]    2    0    0    2    2    2    2    2    2     2     2     0     0     2\n[13,]    0    2    2    2    1    1    2    2    1     1     2     2     2     0\n[14,]    0    0    2    1    2    2    1    1    2     2     1     2     0     0\n[15,]    0    0    2    1    1    1    2    2    1     1     1     2     0     0\n[16,]    0    0    0    2    2    2    0    0    2     2     2     0     0     0"
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#why",
    "href": "posts/2022-09-24-pixeltrix/index.html#why",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Why?",
    "text": "Why?\nTurns out the {pixeltrix} package is actually yak-shaving for another package Iâ€™m developing: {tamRgo}.\n{tamRgo} is a (very much work-in-progress) conceptual package for a Tamagotchi-like experience in the R console. You get a persistent interactive digital pet on your computer whose stats update in â€˜real timeâ€™ while youâ€™re away.\nI want to print a largeish canvas of pixels to visualise multiple pet â€˜speciesâ€™ and for the various interactions you can have (playing, feeding, cleaning). {pixeltrix} makes it much easier to design these scenes and returns matrices that I can add directly to {tamRgo}.\n\nâ„¹ï¸ Update\nIâ€™ve now written a post about {tamRgo}, where you can see how {pixeltrix} was used for the character sprites."
  },
  {
    "objectID": "posts/2022-09-24-pixeltrix/index.html#environment",
    "href": "posts/2022-09-24-pixeltrix/index.html#environment",
    "title": "Interactive pixel art in R with {pixeltrix}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 18:52:13 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] pixeltrix_0.2.1.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html",
    "href": "posts/2023-04-23-type-convert/index.html",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "",
    "text": "Confirmed: Unown is character type.1"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#tldr",
    "href": "posts/2023-04-23-type-convert/index.html#tldr",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "tl;dr",
    "text": "tl;dr\nI forgot that the base R function type.convert() exists. Handy for â€˜simplifyingâ€™ all the columns of a dataframe to appropriate data types."
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#suppression-depression",
    "href": "posts/2023-04-23-type-convert/index.html#suppression-depression",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Suppression depression",
    "text": "Suppression depression\n{a11ytables} is an R package that lets you generate publishable spreadsheets that follow the UK governmentâ€™s best practice guidance.\nOne requirement is to replace missing values with placeholder symbols. For example, suppressed data can be replaced with the string \"[c]\" (â€˜confidentialâ€™).\nOf course, Râ€™s behaviour means it can store only one data type per column, so a numeric-type column will be automatically converted to character when you introduce at least one string value (i.e.Â something in \"quotes\").2\nFor example, this vector is type â€˜doubleâ€™ (i.e.Â decimals and not â€˜whole-numberâ€™ integers) and has the more general â€˜numericâ€™ class:\n\nnums &lt;- runif(100)\ntypeof(nums); class(nums)\n\n[1] \"double\"\n\n\n[1] \"numeric\"\n\n\nThe whole thing is converted to character type if you append just one character value.\n\ntypeof(c(nums, \"[c]\"))\n\n[1] \"character\"\n\n\nThis is known behaviour, yes, but it causes a minor annoyance in the xlsx files output from an {a11ytables} workflow: Excel puts a warning marker in the corner of any cell in a text column that contains a numeric value.3\n\nCat left a GitHub issue related to this: columns entirely made of numbers were being marked by Excel with the â€˜number in a text columnâ€™ warning. In this case, it was because Catâ€™s suppression process resulted in all columns being converted to character.\nIt would be great to convert back to numeric any columns that did not receive a placeholder symbol during the wrangling process. How can you do this?"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#type-specimen",
    "href": "posts/2023-04-23-type-convert/index.html#type-specimen",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Type specimen",
    "text": "Type specimen\nLetâ€™s consider a demo example. First Iâ€™ll attach {dplyr}, which is commonly used by stats producers in the UK government.\n\nsuppressPackageStartupMessages(library(dplyr))\n\nHereâ€™s a very simple dataframe, tbl, to use as a demo. Column x contains values that will need to be suppressed because theyâ€™re lower than 5. There are no such values in column y.\n\nset.seed(1337)\n\ntbl &lt;- tibble(\n  id = LETTERS[1:5],\n  x  = round(runif(5, 0, 10), 2),\n  y  = round(runif(5, 6, 10), 2)\n)\n\ntbl\n\n# A tibble: 5 Ã— 3\n  id        x     y\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A      5.76  7.33\n2 B      5.65  9.79\n3 C      0.74  7.12\n4 D      4.54  6.98\n5 E      3.73  6.58\n\n\nSo, to borrow and simplify Catâ€™s approach: for each numeric column in tbl (i.e.Â x and y), replace any value of less than 5 with the placeholder string \"[c]\", otherwise retain the original value.\n\ntbl_supp &lt;- tbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) if_else(\n        condition = value &lt; 5, \n        true      = \"[c]\",\n        false     = as.character(value)\n      )\n    )\n  )\n\ntbl_supp\n\n# A tibble: 5 Ã— 3\n  id    x     y    \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 A     5.76  7.33 \n2 B     5.65  9.79 \n3 C     [c]   7.12 \n4 D     [c]   6.98 \n5 E     [c]   6.58 \n\n\nSo column x now contains text values and has predictably been converted to character, which you can see as &lt;chr&gt; in the tibble header. But notice that y is also character type despite all the numeric values being retained.\nThis happened because the if_else() we used to create tbl_supp required the true and false arguments to resolve to the same type. The false argument must use as.character() because true resolves to the character value \"[c]\".\nIdeally weâ€™d perform our suppression step but column x would end up as character and y as numeric. How can we achieve this?"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#adjust-my-type",
    "href": "posts/2023-04-23-type-convert/index.html#adjust-my-type",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Adjust my type",
    "text": "Adjust my type\nIn this section are some methods to fix the problem by:\n\nCausing yourself further brainache\nUsing a (relatively little known?) base R function\nDoing it â€˜properlyâ€™ from the outset\n\n\nType 1: nah\nOf course, we could run tbl_supp |&gt; mutate(y = as.numeric(y)) to convert that specific column back to numeric. But imagine if you have a lot more columns and you canâ€™t be sure which ones need to be converted.\nMaybe you could apply as.numeric() across all columns? Columns of numbers stored as text will then be converted entirely to numeric:\n\nas.numeric(c(\"1\", \"2\", \"3\"))\n\n[1] 1 2 3\n\n\nBut this causes a problem for character columns that contain text, like our placeholder symbol:\n\nas.numeric(c(\"1\", \"[c]\"))\n\nWarning: NAs introduced by coercion\n\n\n[1]  1 NA\n\n\nSo \"1\" becomes 1, but weâ€™re warned that \"[c]\" has been converted to NA (well, NA_real_, which is the numeric form of NA).\nWe could do something convoluted, like see which columns didnâ€™t gain NA values and should be retained as numeric. But thatâ€™s bonkers. This approach ultimately makes things worse because weâ€™ve actually lost information!\nReally we want to check each column to see if it contains numbers only and then convert it to numeric. How?\n\n\nType 2: better\nThereâ€™s a handy base R function that I had forgotten about: type.convert().\nIt takes a vector and, in turn, tries to coerce it to each data type. The process stops when coercion occurs without error. As the help file (?type.convert) puts it:\n\nGiven a vector, the function attempts to convert it to logical, integer, numeric or complex, and when additionally as.is = FALSEâ€¦ converts a character vector to factor. The first type that can accept all the non-missing values is chosen.\n\nAnd handily:\n\nWhen the data object x is a data frame or list, the function is called recursively for each column or list element.\n\nSo we can pass our entire dataframe to type.convert() and itâ€™ll check them all for us:\n\ntbl_supp_conv &lt;- type.convert(tbl_supp, as.is = TRUE)\n\ntbl_supp_conv\n\n# A tibble: 5 Ã— 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nAs we wanted, our character column y has become numeric type (&lt;dbl&gt;) while x remains as character. Neato.\n\n\nType 3: betterer\nThere are probably better approaches to this problem from the outset, rather than after-the-fact application of type.convert().\nAs Tim has pointed out, you could actually just use the base R form of ifelse():\n\ntbl |&gt; \n  mutate(\n    across(\n      where(is.numeric),\n      \\(value) ifelse(\n        test = value &lt; 5, \n        yes  = \"[c]\",\n        no   = value\n      )\n    )\n  )\n\n# A tibble: 5 Ã— 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nI think people use dplyr::if_else() for (a) consistency if theyâ€™re already using tidyverse in the script and (b) itâ€™s â€˜strictnessâ€™ compared to ifelse(). if_else() will force you to declare the true and false arguments so they resolve to the same type, whereas ifelse() will silently force type coercion, which may be undesirable in some cases.\nAnother method would be to iterate the suppression over only the columns that need it. For example, you could do that with a simple for and if:\n\ncols_numeric &lt;- names(select(tbl, where(is.numeric)))\n\nfor (col in cols_numeric) {\n  if (any(tbl[col] &lt; 5)) {\n    tbl[col] &lt;- ifelse(\n      tbl[col] &lt; 5,\n      \"[c]\",\n      as.character(tbl[[col]])\n    )\n  }\n}\n\ntbl\n\n# A tibble: 5 Ã— 3\n  id    x         y\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     5.76   7.33\n2 B     5.65   9.79\n3 C     [c]    7.12\n4 D     [c]    6.98\n5 E     [c]    6.58\n\n\nThis reads as â€˜for each numeric column that contains at least one value less than 5, replace those values with the placeholder symbol \"[c]\".â€™"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#preach-to-the-converted-types",
    "href": "posts/2023-04-23-type-convert/index.html#preach-to-the-converted-types",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Preach to the converted types",
    "text": "Preach to the converted types\nItâ€™s almost like this post could have just been a tweet saying â€˜ðŸ˜® yo, type.convert() is ðŸª„magicðŸª„ yâ€™allâ€™. But this post is now a handy reference in case anyone has the same problems with Excelâ€™s handling of {a11ytables} outputs in future.\nAlso I needed to hit my pun quota for the month.4"
  },
  {
    "objectID": "posts/2023-04-23-type-convert/index.html#environment",
    "href": "posts/2023-04-23-type-convert/index.html#environment",
    "title": "Matt Dray Teaches (Data) Typing",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:06:53 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     utf8_1.2.3        R6_2.5.1          fastmap_1.1.1    \n [5] tidyselect_1.2.0  xfun_0.39         magrittr_2.0.3    glue_1.6.2       \n [9] tibble_3.2.1      knitr_1.43.1      pkgconfig_2.0.3   htmltools_0.5.5  \n[13] generics_0.1.3    rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1        \n[17] fansi_1.0.4       vctrs_0.6.3       withr_2.5.0       compiler_4.3.1   \n[21] rstudioapi_0.15.0 tools_4.3.1       pillar_1.9.0      evaluate_0.21    \n[25] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "",
    "text": "new wr â€” r.oguelike any% tenkeyless noglitch"
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#tldr",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#tldr",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {r.oguelike} packageâ€”a toy roguelike microadventure for the R consoleâ€”now has little sound effects thanks to {sonify}. Pew pew!"
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#the-adventure-continues",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#the-adventure-continues",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "The adventure continues?",
    "text": "The adventure continues?\nApparently this is part 5 of the {r.oguelike} devlog. You can read earlier posts about:\n\nits inception\ncreating simple procedural dungeons\nmaking an enemy chase the player\n3D dungeons and continuous keypress inputs\n\nAlas, this is also probably the last installment.\nYes, the dungeons have been dank (cool, edgy), but also dank (cool, damp, claustrophobic). Time to unspelunk myself.\nThere may be time for a {r.oguelike2} in future. Iâ€™d like to try a class-based approach to help limit code spaghetti and make it more extensible. Perhaps it will even have a proper game loop! Call me when youâ€™re ready, Kojima.\nUntil then, one more little feature to tie things up. Beeeeeeep. BOOOOOOOP."
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#hi-sonifi",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#hi-sonifi",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Hi-Sonifi",
    "text": "Hi-Sonifi\nSo, yes: {r.oguelike} now has sound effects with quality as high as its graphics and gameplay. See all these in concert in the video embedded at the top of this page.\nI used the {sonify} package to create a few little beeps and toots that I think fit the gameâ€™s retro aesthetic.1 These are fired when the player moves and interacts with things in the dungeon.\nIâ€™ve written about {sonify} before when I sonified data about COVID-19 infections and GitHub activity (incredible juxtaposition), which can offer a more interesting and accessible way of presenting data.\nYou can also demean {sonify} by making funny little honks and parps, which is what Iâ€™ve done for {r.oguelike}.\nHow did I arrive at the soundscape for {r.oguelike}? I did the bare minimum of fiddling around with the arguments in sonify::sonify() until the noises amused me."
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#demo-cassette",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#demo-cassette",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Demo cassette",
    "text": "Demo cassette\nSounds are played in the code of the package via functions after each triggering event. The user can prevent these sounds from playing with the logical has_sfx argument in the start_game() function.\nFor example, hereâ€™s the function for the simplest sound effect:\n\n.sfx_move &lt;- function(has_sfx) {\n  if (has_sfx) sonify::sonify(1, 1, duration = 0.001)\n}\n\nThe sonify() outputs are {tuneR} objects. Iâ€™ve saved these as wav files with tuneR::writeWav() so they can be embedded in this post.\n\n\nClick for illustrative code to create the wav files.\n\n\nlibrary(sonify)\nlibrary(tuneR)\nlibrary(purrr)\n\nsfx &lt;- list(\n  \n  move = sonify(1, 1, duration = 0.001),\n  \n  bump = sonify(1, 1, duration = 0.01, flim = c(100, 110)),\n  \n  gold = bind(\n    sonify(1, 1, duration = 0.05, flim = c(800, 800)),\n    sonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n  ),\n  \n  apple = sonify(0:1, c(0, 1), duration = 0.05),\n  \n  eat = sonify(0:1, c(1, 0), duration = 0.05),\n  \n  win = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n  ),\n  \n  lose = bind(\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600)),\n    sonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))\n  )\n  \n)\n\nwalk2(\n  .x = sfx,\n  .y = names(sfx), \n  ~writeWave(.x, paste0(.y, \".wav\"))\n)\n\n\nIn reality, the sounds play a little slower in the game itself, but it was a bit fiddly to reproduce it for these clips. Youâ€™ll get the idea.\n\nMove\nStep onto unoccupied floor tile (.) and youâ€™ll hear the very quick tap of your boot.\nClick to play the sound:\n\n\n\n\n\nAnd hereâ€™s the corresponding code to reproduce it:\n\nsonify(1, 1, duration = 0.001)\n\nBut bump into the dungeon wall (#) and youâ€™ll get a dull thud, you absolute clod.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.01, flim = c(100, 110))\n\nYes, flim, as in: â€˜this post is absolute flimflamâ€™.\n\n\nFood\nWould you pick up an apple (a) you found on the floor of a cave? Hereâ€™s what it might sound like as it pops into your inventory.\n\n\n\n\n\n\nsonify(0:1, c(0, 1), duration = 0.05),\n\nMore importantly, would you eat an apple (a) you found on the floor of a cave? Hereâ€™s how it would sound as it rolls down your gullet.\n\n\n\n\n\n\nsonify(0:1, c(1, 0), duration = 0.05)\n\n\n\nGold\nCollecting gold ($) grants you a celebratory chirp of excitement. Although thereâ€™s not actually anything in the dungeon to spend it on, sorry.\n\n\n\n\n\n\nsonify(1, 1, duration = 0.05, flim = c(800, 800))\nsonify(1, 1, duration = 0.05, flim = c(1000, 1000))\n\n\n\nDefeat enemy\nA powerful victory ditty after you crush your enemies (E).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(800, 800))\n\n\n\nLose\nConversely, a sad lament for being crushed by your enemies (E) or running out of turns (T).\n\n\n\n\n\n\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(600, 600))\nsonify(0:1, rep(1, 2), duration = 0.1, flim = c(400, 400))"
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#echo-echo-echo",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#echo-echo-echo",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Echo echo echo",
    "text": "Echo echo echo\nIf you want to try out {r.oguelike}, you can install it from GitHub:\n\ninstall.github(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/r.oguelike\")  # v0.1 currently\nr.oguelike::start_game()\n\nYou can also run {r.oguelike} in an RStudio instance in your browser (!), thanks to the Binder project.\nFree feel to highlight any bugs via the issues, or create a pull request that adds all the things that stop me from calling {r.oguelike} a proper â€˜gameâ€™.2\n\nMost importantly, donâ€™t forget to wishlist me on Steam and remember that pre-order bonuses will include an apple thatâ€™s been left on a dungeon floor for a few months."
  },
  {
    "objectID": "posts/2023-01-04-r.oguelike-sfx/index.html#environment",
    "href": "posts/2023-01-04-r.oguelike-sfx/index.html#environment",
    "title": "Ding! Sound effects in {r.oguelike}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:33 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#tldr",
    "href": "posts/2021-11-04-kanto-locate/index.html#tldr",
    "title": "Get coordinates from fictitious maps",
    "section": "tl;dr",
    "text": "tl;dr\nUse the locator() function in R to interactively extract arbitrary coordinates from images of imaginary maps. I extracted points of interest from Kanto in the original PokÃ©mon games."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#on-the-road-to-viridian-city",
    "href": "posts/2021-11-04-kanto-locate/index.html#on-the-road-to-viridian-city",
    "title": "Get coordinates from fictitious maps",
    "section": "On the road to Viridian City",
    "text": "On the road to Viridian City\nThere are lots of interesting fictitious maps. For example, Middle Earth from Lord of the Rings, Hyrule from The Legend of Zelda and Sodor from Thomas the Tank Engine.\nThis is excellent fodder for fan-made recreations. Iâ€™ve thought before about how I would do this programmatically, but thereâ€™s one particularly awkward thing: how can you grab location coordinates from an image of your chosen map?\nThis post outlines a pretty low-effort method for doing this in R. Basically thereâ€™s two steps: (1) read and plot an image of a map and (2) click locations interactively to record their coordinates. Iâ€™m going to do this with a PokÃ©mon example for simplicity, but also because have you ever visited this blog before?"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#get-map",
    "href": "posts/2021-11-04-kanto-locate/index.html#get-map",
    "title": "Get coordinates from fictitious maps",
    "section": "Get map",
    "text": "Get map\nFor my own convenience, Iâ€™ve written a function that downloads a PNG of a map from the web and plots it. This requires {png} and {grid} packages.\n\nplot_map &lt;- function(png_path) {\n  \n  # Return to user's par settings once done\n  original_par &lt;- par()[\"mar\"]\n  on.exit(par(original_par))\n  \n  # Download and read image\n  tmp &lt;- tempfile(fileext = \".png\")\n  download.file(png_path, tmp, quiet = TRUE)\n  img &lt;- png::readPNG(tmp)\n  unlink(tmp)  # clean up\n  \n  # Set up canvas and plot\n  par(mar = rep(0, 4))  # remove margins\n  plot.new()  # start new plot frame\n  grid::grid.raster(img, x = 0.5, y = 0.5)\n  \n}\n\nTo be specific, Iâ€™m using the in-game â€˜town mapâ€™ of the fictitious Kanto region from the first generation of PokÃ©mon Red and Blue for the Nintendo GameBoy,1 downloaded from Bulbapedia. This is good for a demo: the locations are pretty discrete, obvious and clickable.\n\nkanto_path &lt;- \n  \"https://cdn2.bulbagarden.net/upload/8/86/Kanto_Town_Map_RBY.png\"\n\nplot_map(kanto_path)\n\n\n\n\nYou might be thinking that it looks like a schematic mapâ€”an abstraction of actual geographyâ€”like the London underground map. In fact, the town map is pretty similar to the actual in-game world layout, as demonstrated by folks who have stitched together all the overworld screens."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#get-points",
    "href": "posts/2021-11-04-kanto-locate/index.html#get-points",
    "title": "Get coordinates from fictitious maps",
    "section": "Get points",
    "text": "Get points\nWith the Kanto map drawn in our active plot window, we can run a function to prompt the user to click on points and record their coordinates.\n\nlocate_points &lt;- function(places) {\n  \n  places_list &lt;- vector(\"list\", length(places)) |&gt; \n    setNames(places)\n  \n  for (i in places) {\n    cat(paste0(\"Click on \", i, \"... \"))\n    places_list[[i]] &lt;- locator(1, type = \"p\")\n    cat(\"found.\\n\")\n  }\n  \n  places_df &lt;- do.call(rbind, places_list) |&gt;\n    data.frame()\n  \n}\n\nThis is not magic. It is merely powered by the locator() function, which records the x and y location of a point clicked on a plot by the user.2\nHereâ€™s a simplified version of whatâ€™s going on when you use locator(). If you make a plot and call the function, then the top of the plotting window in RStudio says â€˜locator activeâ€™ and your cursor becomes crosshairs. Clicking on the plot returns a list of the x and y coordinates within the plotting space. The first argument is the number of clicks to collect before the locator is deactivated automatically.\n\nFor our bespoke locate_points() function, we can pass a character vector of place names. For this demo, thatâ€™ll be Kantoâ€™s towns, cities and other places of interest. The function loops through the locations and requests you to click the corresponding point on the map. The console will read like Click on Pallet Town... and then found once youâ€™ve clicked it.\n\nkanto_names &lt;- c(\n  \"Pallet Town\", \"Viridian City\", \"Viridian Forest\", \"Pewter City\", \n  \"Mt Moon\", \"Cerulean City\", \"Rock Tunnel\", \"Vermilion City\", \n  \"Lavender Town\", \"Celadon City\", \"Fuchsia City\", \"Saffron City\", \n  \"Seafoam Islands\", \"Cinnabar Island\", \"Victory Road\",\n  \"Indigo Plateau\"\n)\n\nkanto_pts &lt;- locate_points(kanto_names)  # initiates clicking prompts\n\nClick on Pallet Town...\nDuring the clickfest, the locate_points() function has assembled the points lists into a data.frame with one row per location. The locations vector was passed as the rownames of the dataframe as well. Hereâ€™s the full list of collected coordindates.\n\nkanto_pts\n\n                        x          y\nPallet Town     0.2470187 0.30648777\nViridian City   0.2451179 0.50103940\nViridian Forest 0.2451179 0.75868886\nPewter City     0.2470187 0.81652853\nMt Moon         0.4275933 0.88225543\nCerulean City   0.6100688 0.87962636\nRock Tunnel     0.7944450 0.81915761\nVermilion City  0.6100688 0.43794158\nLavender Town   0.7963458 0.69296196\nCeladon City    0.4751130 0.69296196\nFuchsia City    0.5207318 0.18292120\nSaffron City    0.6100688 0.69559103\nSeafoam Islands 0.3838752 0.05672554\nCinnabar Island 0.2451179 0.05672554\nVictory Road    0.1538802 0.75343071\nIndigo Plateau  0.1519794 0.87962636\n\n\nThe coordinate values are between 0 to 1 because those are the default x- and y-axis limits that were set up in plot_map(). Theyâ€™re remarkably precise, but the resolution on the image wasnâ€™t great and my hand-eye coordination is bad, so take these with a grain of salt."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#plot",
    "href": "posts/2021-11-04-kanto-locate/index.html#plot",
    "title": "Get coordinates from fictitious maps",
    "section": "Plot",
    "text": "Plot\nSo! You can now plot the coordinates independently. To demonstrate, Iâ€™ve plotted the points and added a label whose style is dependent on the type of location. Iâ€™ve added lines to join the locations in the order they appear in a normal playthrough.\n\nkanto_pts$city &lt;- ifelse(\n  grepl(\"Town|City|Island$\", rownames(kanto_pts)), \n  TRUE, FALSE\n)\n\npar(mar = rep(0, 4))\nwith(kanto_pts, plot(x, y, axes = FALSE))\nwith(kanto_pts, lines(x, y, col = \"grey95\", lwd = 5))\n\npoints(\n  kanto_pts$x, kanto_pts$y,\n  pch = 16,\n  cex = ifelse(kanto_pts$city, 2, 1),\n  col = ifelse(kanto_pts$city, \"red\", \"blue\")\n)\n\ntext(\n  kanto_pts$x, kanto_pts$y,\n  gsub(\" \", \"\\n\", row.names(kanto_pts)),\n  cex = ifelse(kanto_pts$city, 0.7, 0.4),\n  pos = c(1, 1, 1, 4, 1, 1, 2, 1, 2, 1, 1, 1, 3, 3, 1, 1),\n  family = \"Press Start 2P\"  # installed locally from Google Fonts\n)\n\n\n\n\nIt might also be fun to do a minimal map of the cities where the points are coloured according to the name of the city. You may have noticed that the city names are all fancy colour names (viridian, fuchsia, etc), so letâ€™s use them. Well, except Pallet, for which can just use a mix of all colours, i.e.Â white.\n\nkanto_colour &lt;- \n  kanto_pts[kanto_pts$city | \n              rownames(kanto_pts) == \"Indigo Plateau\", ]\n\nkanto_colour$city_col &lt;- c(  # close-enough named R colours\n  \"white\", \"aquamarine4\", \"grey57\", \"royalblue3 \",\n  \"red3 \", \"lavender\", \"darkseagreen2\", \"magenta\",\n  \"tomato2\", \"orangered2\", \"blue\"\n) \npar(mar = rep(0, 4))\nwith(kanto_colour, plot(x, y, axes = FALSE))\nwith(kanto_colour, points(x, y, pch = 22, cex = 4, bg = city_col))\n\n\n\n\nIâ€™ll admit I struggled to make this given my colourblindness, but also because I had no prior notions of what colours like â€˜vermilionâ€™ and â€˜celadonâ€™ are. Actually they kind of sound more like PokÃ©mon names.\nAnyway, these â€˜mapsâ€™ are the first steps to create something more exciting. For now they demonstrate the point (literally, lol). Plus they fulfil my belated submission for day one of the #30DayMapChallenge (â€˜pointsâ€™)."
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#distances",
    "href": "posts/2021-11-04-kanto-locate/index.html#distances",
    "title": "Get coordinates from fictitious maps",
    "section": "Distances",
    "text": "Distances\nBut wait, thereâ€™s more.\nSo, obviously, why not work out the distances between towns? Not in arbitrary units, but in actual metres. Thereâ€™s a few ways we could do this, but basically Iâ€™m going to peg a pixel to a known length.3\nFirst, we can create a lookup table of the straight-line â€˜distancesâ€™ between locations, given our arbitrary 0 to 1 dimensions. We want to avoid being precise with these values (theyâ€™re only as good as my ability to click a tiny square on a computer screen), so Iâ€™m multiplying and rounding them.\n\nkanto_dist &lt;- raster::pointDistance(\n  kanto_pts[, c(\"x\", \"y\")],\n  lonlat = FALSE\n) |&gt;\n  as.data.frame() |&gt;\n  round(2) * 100\n\nThe legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\nwhich was just loaded, will retire in October 2023.\nPlease refer to R-spatial evolution reports for details, especially\nhttps://r-spatial.org/r/2023/05/15/evolution4.html.\nIt may be desirable to make the sf package available;\npackage maintainers should consider adding sf to Suggests:.\nThe sp package is now running under evolution status 2\n     (status 2 uses the sf package in place of rgdal)\n\nnames(kanto_dist) &lt;- kanto_names\nrownames(kanto_dist) &lt;- kanto_names\n\nkanto_dist[1:3, 1:3]  # first few\n\n                Pallet Town Viridian City Viridian Forest\nPallet Town               0            19              45\nViridian City            19             0              26\nViridian Forest          45            26               0\n\n\nThese values are the number of arbitrary distance units between pairs of locations, which are given by the row and column headers. So, Pallet Town to Viridian City is 19 arbitrary units.\nBased on my own measurements, the centre of Pallet to the centre of Viridian is 64 in-game â€˜blocksâ€™, where a block is a 16- by 16-pixel square.4\nIt just so happens that the player-character sprite fills a single block5 and we know that the character is probably about 140 cm tall.6\nThat means Pallet to Viridian is about 64 * 140 cm = 8960 cm. So, one of our arbitrary units equals 8960 cm / 19 = 472 cm. Now we can correct our distance lookup.\n\nkanto_dist_m &lt;- round(kanto_dist * 472 / 100)\nkanto_dist_m[1:3, 1:3]  # first few\n\n                Pallet Town Viridian City Viridian Forest\nPallet Town               0            90             212\nViridian City            90             0             123\nViridian Forest         212           123               0\n\n\nOnce again Iâ€™ve removed some precision by calculating the result as a rounded distance in metres. Coward.\n\nSo this means we can now say some really profound things like itâ€™s about 90 m from Pallet Town to Viridian City. Maybe thatâ€™s true in the context of the gameâ€™s dimensions, but itâ€™sâ€¦ underwhelming.\nWas this scuffed distance-conversion exercise worthwhile? No.Â \nBut it might strengthen my belated submission to day two of the #30DayMapChallenge (â€˜linesâ€™)?"
  },
  {
    "objectID": "posts/2021-11-04-kanto-locate/index.html#environment",
    "href": "posts/2021-11-04-kanto-locate/index.html#environment",
    "title": "Get coordinates from fictitious maps",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:26:56 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     codetools_0.2-19  fastmap_1.1.1     xfun_0.39        \n [5] lattice_0.21-8    knitr_1.43.1      raster_3.6-20     htmltools_0.5.5  \n [9] png_0.1-8         rmarkdown_2.23    cli_3.6.1         terra_1.7-39     \n[13] grid_4.3.1        compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[17] sp_2.0-0          evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7       \n[21] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html",
    "href": "posts/2022-02-04-soccercolleagues/index.html",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "",
    "text": "Lee Bowyer and Kieran Dyer: â€˜team matesâ€™ (BBC via Giphy)"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#tldr",
    "href": "posts/2022-02-04-soccercolleagues/index.html#tldr",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a quick R package called {soccercolleagues} that for a given player, or players, lets you (a) find all their former team mates in common and (b) sample from them for quiz-based purposes."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#lord-of-the-ings",
    "href": "posts/2022-02-04-soccercolleagues/index.html#lord-of-the-ings",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Lord of the Ings",
    "text": "Lord of the Ings\nQuiz question:\n\nWhich current Premier League footballer has been team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?\n\nIâ€™ve seen this type of question in pub quizzes, on social media and forwarded on by assorted football nerds. Some are harder than a Roy Keane challenge\nBut why use your brain when you could backwards-engineer it programmatically?\nI figured I could use R and the {worldfootballR} package by Jason Zivkovic to fetch squad data from the Transfermarkt website, then isolate team mates that these players have in common.\nAnd why not make it an R package in the process?"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#announce-soccercolleagues",
    "href": "posts/2022-02-04-soccercolleagues/index.html#announce-soccercolleagues",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Announce {soccercolleagues}!",
    "text": "Announce {soccercolleagues}!\nIâ€™m pleased to announce the signing of the promising young {soccercolleagues}1 package on a free. Will it live up to the hype?\nThe package is available via GitHub, which you can install with help from {remotes}.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/soccercolleagues\")\nlibrary(soccercolleagues)\n\nIn a departure from my usual package production, Iâ€™ve made use of the tidyverse in this one. It also uses the native R pipe, so youâ€™ll need R v4.1 or above.2 It works on my computer, which is good enough for me.\nAs with many packages showcased on this blog, you should consider this a low-effort artisanal meme. Definitely a proof of concept. Iâ€™m not sure if Iâ€™ll ever come back and improve it. Feel free to add issues or submit pull requests."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#get-stuck-in",
    "href": "posts/2022-02-04-soccercolleagues/index.html#get-stuck-in",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Get stuck in",
    "text": "Get stuck in\n{soccercolleageus} has three main functions:\n\nget_players() to fetch squad data from Transfermarkt\nget_colleagues() to return all the players by season who have been team mates with a named set of players\nsample_colleagues() to select a random set of team mates for a named player or players\n\nThereâ€™s also a secret tiny Shiny app, accessed with open_colleagues_quiz(), but it (literally) only presents five player names with buttons to (a) reveal a sampled team mate in common, and (b) generate a new set of player names. Youâ€™ll need to install {shiny} and {shinyjs} separately if you want to use it (donâ€™t use it).\nLetâ€™s talk through the main functions.\n\n1. Get squads by league and season\nFirst, letâ€™s get all the players from all teams in a given league for a given set of seasons.\nI designed the package entirely with the English Premier League in mind because thatâ€™s the league Iâ€™m most accustomed to and because Transfermarkt has data for all its seasons, which began in 1992.3\nYou pass to get_players() the seasons you want and the country that the league is from. Beware: this could take several minutes.\n\nepl_players &lt;- get_players(\n  seasons = 1992:2020,\n  country = \"England\"\n)\n\nglimpse(epl_players)\n\nRows: 20,643\nColumns: 11\n$ player_name    &lt;chr&gt; \"Paul Gerrard\", \"Jon Hallworth\", \"John Keeley\", \"Ian Gray\", \"Craigâ€¦\n$ player_pos     &lt;chr&gt; \"Goalkeeper\", \"Goalkeeper\", \"Goalkeeper\", \"Goalkeeper\", \"Centre-Baâ€¦\n$ player_age     &lt;dbl&gt; 19, 26, 30, 17, 20, 19, 19, 40, 29, 26, 27, 24, 26, 26, 26, 25, 26â€¦\n$ nationality    &lt;chr&gt; \"England\", \"England\", \"England\", \"England\", \"England\", \"England\", â€¦\n$ in_squad       &lt;dbl&gt; 27, 16, 29, 12, 35, 1, 35, 1, 40, 9, 33, 36, 41, 37, 6, 42, 15, 32â€¦\n$ appearances    &lt;dbl&gt; 25, 16, 1, 0, 24, 0, 33, 0, 40, 5, 33, 31, 41, 32, 6, 42, 14, 32, â€¦\n$ goals          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 3, 0, 5, 9, 0, 3, 3, 6, 0, 3, 3, 2, â€¦\n$ minutes_played &lt;dbl&gt; 2250, 1440, 90, 0, 2114, 0, 2953, 0, 3600, 341, 2799, 2522, 3647, â€¦\n$ team_url       &lt;chr&gt; \"https://www.transfermarkt.com/oldham-athletic/startseite/verein/1â€¦\n$ team_name      &lt;chr&gt; \"oldham-athletic\", \"oldham-athletic\", \"oldham-athletic\", \"oldham-aâ€¦\n$ season         &lt;chr&gt; \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1992\", \"1â€¦\nA dataframe is returned with lots of handy stuff like the player name, team name, season and a bunch of player data. Obviously you could take this data away and do whatever you like with it, itâ€™s quite a neat dataset for other, less esoteric analysis of the history of the Premier League.\n\n\n2. Find team mates\nNow to filter this information for a given focus player or players.\nYou provide the dataframe output of get_players() to get_colleagues() as the all_players() argument, along with a vector of players names. The function filters the dataframe down to just the team mates of the selected player or players for the teams and seasons in which they played together.\n\nteammates &lt;- get_colleagues(\n  all_players = epl_players,\n  players = c(\"Kolo TourÃ©\", \"Yaya TourÃ©\")\n)\n\nRows: 348\nColumns: 12\n$ focus_name     &lt;chr&gt; \"Kolo TourÃ©\", \"Kolo TourÃ©\", \"Kolo TourÃ©\", \"Kolo TourÃ©\", \"Kolo Tourâ€¦\n$ player_name    &lt;chr&gt; \"Stuart Taylor\", \"Richard Wright\", \"Patrick Vieira\", \"Stuart Tayloâ€¦\n$ player_pos     &lt;chr&gt; \"Goalkeeper\", \"Goalkeeper\", \"Defensive Midfield\", \"Goalkeeper\", \"Dâ€¦\n$ player_age     &lt;dbl&gt; 20, 23, 25, 21, 26, 22, 17, 27, 23, 18, 28, 19, 21, 20, 22, 21, 24â€¦\n$ nationality    &lt;chr&gt; \"England\", \"England\", \"France\", \"England\", \"France\", \"England\", \"Fâ€¦\n$ in_squad       &lt;dbl&gt; 21, 43, 54, 20, 42, 4, 31, 44, 7, 26, 44, 14, 13, 40, 45, 50, 41, â€¦\n$ appearances    &lt;dbl&gt; 15, 22, 54, 13, 42, 0, 22, 44, 0, 24, 44, 11, 13, 40, 44, 49, 40, â€¦\n$ goals          &lt;dbl&gt; 0, 0, 3, 0, 4, 0, 0, 3, 0, 0, 7, 0, 4, 0, 12, 0, 1, 30, 1, 0, 7, 1â€¦\n$ minutes_played &lt;dbl&gt; 1220, 1929, 4702, 1081, 3563, 0, 1347, 3822, 0, 1456, 3926, 728, 1â€¦\n$ team_url       &lt;chr&gt; \"https://www.transfermarkt.com/fc-arsenal/startseite/verein/11/saiâ€¦\n$ team_name      &lt;chr&gt; \"fc-arsenal\", \"fc-arsenal\", \"fc-arsenal\", \"fc-arsenal\", \"fc-arsenaâ€¦\n$ season         &lt;chr&gt; \"2001\", \"2001\", \"2001\", \"2002\", \"2002\", \"2003\", \"2003\", \"2003\", \"2â€¦\nYou can see how this could be used to solve our original problem: you can take a named playerâ€™s unique team mates and find how many are in common with other named players.\nWhile get_colleagues() effectively returns a filtered dataframe, thereâ€™s another function to whittle this down to simpler output.\n\n\n3. Sample from common team mates\nGiven a named player or players, the sample_colleagues() function returns a vector of team mates of size n. These are sampled with a weighting by the total number of Premier League minutes played (a very rough way of outputting more well-known players).\nYou could apply the function to a single named player if you want, which outputs five sampled team mates.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = \"Craig Bellamy\"\n)\n\n[1] \"Jordan Henderson\"   \"Rob Lee\"  \"Freddie Ljungberg\"\n[4] \"Patrick Vieira\"   \"Celestine Babayaro\"\nOf course, if your chosen player is the only common team mate for the set of output players, then youâ€™ve got a decent quiz question to test your pals with!\nTo check, we can feed these names back into sample_colleagues(). Iâ€™ve set the argument n = 2: if we get two names then we know the player isnâ€™t the only one in common for these five.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = c(\n    \"Jordan Henderson\",\n    \"Rob Lee\",\n    \"Freddie Ljungberg\",\n    \"Patrick Vieira\",\n    \"Celestine Babayaro\"\n  ),\n  n = 2 \n)\n\n[1] Craig Bellamy\nLegend, journeyman."
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#theres-only-one-insert-player",
    "href": "posts/2022-02-04-soccercolleagues/index.html#theres-only-one-insert-player",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Thereâ€™s only one [insert player]",
    "text": "Thereâ€™s only one [insert player]\nSo whatâ€™s the answer to the original question?4\n\nWhich current Premier League footballer was team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?\n\nNow we can answer programmatically.\n\nsample_colleagues(\n  all_players = epl_players,\n  players = c(\n    \"Kevin Phillips\",\n    \"Mark Viduka\",\n    \"Dejan Lovren\",\n    \"Danny Ings\",\n    \"Nicky Butt\"\n  ),\n  n = 1\n)\n\n\n\nClick for answer!\n\n[1] James Milner\n\nDid you get it? Was it too easy, too boring?5"
  },
  {
    "objectID": "posts/2022-02-04-soccercolleagues/index.html#environment",
    "href": "posts/2022-02-04-soccercolleagues/index.html#environment",
    "title": "Introduce me to your {soccercolleagues}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:32 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] soccercolleagues_0.0.0.9001\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html",
    "href": "posts/2021-06-21-recreate-hlito/index.html",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "",
    "text": "I used base R to replicate some art as part of #RecreationThursday."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#tldr",
    "href": "posts/2021-06-21-recreate-hlito/index.html#tldr",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "",
    "text": "I used base R to replicate some art as part of #RecreationThursday."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#rando-hlito",
    "href": "posts/2021-06-21-recreate-hlito/index.html#rando-hlito",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "Rando-Hlito",
    "text": "Rando-Hlito\nThe first #RecreationThursday challenge involved Alfredo Hlitoâ€™s Curves and Straight Series (1948), held by New Yorkâ€™s MoMA.\nMy recreation uses only base R functions:\n\nMy remix is a 10 by 10 grid where the elemental geometry is randomised:\n\nI also made a gif remix thatâ€™s composed of 10 â€˜rando-Hlitosâ€™:"
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#approach",
    "href": "posts/2021-06-21-recreate-hlito/index.html#approach",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "Approach",
    "text": "Approach\nYou can find all the commented code and the outputs in my matt-dray/viz-recreation GitHub repo.\n\nRecreate\nI chose to use base R plotting functions for this project. Largely for the simplicity and for the lack of dependencies, but also due to success I had recently when recreating another artwork.1\nThe overall principle was relatively straightforward: use trial-and-error to place elements made with the line() and segments() functions. Itâ€™s not perfect, but itâ€™s close enough.\nTo summarise the code, it first opens the png() graphics device; sets par()ameters to exclude margins and set the background colour; plot()s an empty plot; builds lines with x and y coordinates; builds circle segments with x, y, radius and theta; and finally closes the device with dev.off().\n\n\nRemix\nThereâ€™s some great remixes on the #RecreationThursday hashtag in Twitter and I particularly liked the ones that went for slight variations in stroke and placement, as well as those with an animated approach.\nIn this vein, I chose to vary randomly the elements of the plot using a custom function, vary_hlito().\nThe randomisation was relatively simplistic: vary the y-axis location of each of the horizontal lines, but maintain their widths and colours; provide different segment lengths for each of the two circles while retaining their radii and centres; vary the length and placement of the diagonal line running top-left to bottom-right.\nThereâ€™s a number of ways to present these â€˜rando-Hlitosâ€™. I thought it would be interesting to do two things: create a large grid of many recreations (i.e.Â create a â€˜metaâ€™ rando-Hlito) and create an animation (i.e.Â a sequential reveal of many recreations). I think these are interesting in different ways.\nIn particular, I think the 10 by 10 grid echoes two completely different styles: the repeating nature is a bit like a moquette pattern from the London Underground, while the colours and shapes arenâ€™t far off a 90s Memphis Style.\nTo summarise the code, the grid was created by setting a 10 by 10 panel with mfrow = c(10, 10) passed to par() and then different seeds were passed into vary_hlito() with purrr::walk() to dictate the randomness. The animation was generated by looping over randomly-selected seeds and saving each output as a PNG, before stitching these frames into a gif with the {magick} package."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#get-involved",
    "href": "posts/2021-06-21-recreate-hlito/index.html#get-involved",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "Get involved",
    "text": "Get involved\nCheck out #RecreationThursday on Twitter. Itâ€™s a community challenge to recreate an art piece selected each fortnight by a rotating curator. The subject for the second week has been released already.\nThe timetable, art pieces, curators and example alt-text are available in Sharla Gelfandâ€™s RecreationThursday repo on GitHub."
  },
  {
    "objectID": "posts/2021-06-21-recreate-hlito/index.html#environment",
    "href": "posts/2021-06-21-recreate-hlito/index.html#environment",
    "title": "#RecreationThursday: Hlito with base R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 20:44:35 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html",
    "href": "posts/2021-05-07-encrypt-rmd/index.html",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "",
    "text": "An attempted knitting/padlock visual pun with stitch markers."
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html#tldr",
    "href": "posts/2021-05-07-encrypt-rmd/index.html#tldr",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "tl;dr",
    "text": "tl;dr\nYou can knit an R Markdown file to an encrypted HTML with {encryptedRmd} and put it online with GitHub Pages. Users must enter the decryption key to download and view the content."
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html#tinkr-tailr",
    "href": "posts/2021-05-07-encrypt-rmd/index.html#tinkr-tailr",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "TinkR TailR",
    "text": "TinkR TailR\nIâ€™m working on a personal project that outputs an HTML document rendered from an R Markdown file. I want to password-protect and share it with a specific person somehow. Also, sharing a hard copy by email is tedious; Iâ€™d rather they always had the latest version from a URL.\nMore importantly, I watched Tinker Tailor Soldier Spy1 over the weekend and I wanted to feign top-secret document handling."
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html#invest-in-encrypto",
    "href": "posts/2021-05-07-encrypt-rmd/index.html#invest-in-encrypto",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "Invest in encrypto",
    "text": "Invest in encrypto\nIâ€™m a simple fellow. I donâ€™t want to download or handle any extra software; I donâ€™t want to configure anything; I like â€˜freeâ€™ as in â€˜I donâ€™t have to pay for itâ€™; I want minimal friction for the person accessing the content; I want the file to be standalone and self-contained.\nThereâ€™s probably many ways to achieve this with R, but I decided to try out Dirk Schumacherâ€™s {encryptedRmd} package, which I starred on GitHub a while ago and then forgot about.2 Iâ€™ve used GitHub Pages for hosting a bunch of stuff at no cost; might as well pop it there.\n\nExample\nI made a simple GitHub repo containing a demo of this approach. The encrypted HTML output is available online. Iâ€™ve embedded it below as well.\nYouâ€™ll be asked for a key to decrypt it. For this demo, the key is: 9ebf5d40b061c59330b9fce16703e4c2fb2fbf90a773996e43e49d562ea17039.\n\n\nYour browser will prompt you to save and view the decrypted document if you enter the correct key. Prepare to see some extremely top secret information when you open that file.\n\n\nHow to\nHow was this created? In short, you knit an R Markdown as usual, but replace the output type in the YAML header. Hereâ€™s the steps:\n\nInstall {encryptedRmd} from CRAN if you havenâ€™t already, using install.packages(\"encryptedRmd\")\nWrite an R Markdown file (i.e.Â extension .Rmd) where the output: field in the YAML header is set to encryptedRmd::encrypted_html_document\nKnit the file to render (i) an unencrypted â€˜normalâ€™ version HTML, (ii) an encrypted HTML version, and (iii) a text file containing a randomised decryption key, all of which are generated by default in the same folder that the Rmd is in\nTo serve, commit and push only the encrypted file to GitHub and then activate GitHub Pages for the repo (go to â€˜Settingsâ€™ &gt; â€˜Pagesâ€™)\n\nOf course, you should add the R Markdown file, the unencrypted HTML and the decryption key to your .gitignore file, otherwise the content will be available for people to see.\nIâ€™ve retained all the output files in the demo repo so you can see them all. You can find them in the docs/ folder:\ndocs/\nâ”œâ”€â”€ encrypt-test.Rmd\nâ”œâ”€â”€ encrypt-test.html\nâ”œâ”€â”€ encrypt-test.enc.html\nâ””â”€â”€ encrypt-test.enc.html.key\nI told GitHub Pages to serve this docs/ folder from the main branch, so that the URL ends up as https://matt-dray.github.io/encrypt-rmd-test/encrypt-test.html.enc.html.3\nNow I can share the URL with someone and send them the key via a separate means of communication, like via a fax or a pigeon."
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html#get-a-job-in-cyber",
    "href": "posts/2021-05-07-encrypt-rmd/index.html#get-a-job-in-cyber",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "â€˜Get a job in cyberâ€™",
    "text": "â€˜Get a job in cyberâ€™\nSurprise, I am not a cyber security expert. You can read more about the libsodium encryption method underlying {encryptedRmd} if youâ€™re wondering how it works, etc.\nAs noted by Dirk in the {encryptedRmd} README: use at your own risk.\nFor me, the outlined approach does what I need and does it painlessly. I have no intention to share actually-sensitive information via this method, so I have little to worry about. Iâ€™m Smiley as George Smiley in Tinker Tailor Soldier Spy.4"
  },
  {
    "objectID": "posts/2021-05-07-encrypt-rmd/index.html#environment",
    "href": "posts/2021-05-07-encrypt-rmd/index.html#environment",
    "title": "Encrypt and host a knitted R Markdown file",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 13:25:08 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html",
    "href": "posts/2021-02-21-skyphone/index.html",
    "title": "#GithubSkyline but hear me out",
    "section": "",
    "text": "My skyline clearly has a Central Business District with development in the suburbs."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#tldr",
    "href": "posts/2021-02-21-skyphone/index.html#tldr",
    "title": "#GithubSkyline but hear me out",
    "section": "tl;dr",
    "text": "tl;dr\nI made the R package {skyphone} to get GitHub contributions data from GitHub Skyline and sonify it.\n\n Note\nThe GitHub Skyline APIâ€“on which the {skyphone} package dependsâ€“stopped responding (i.e.Â it 404s) soon after this post was published. I may fix {skyphone} in future to work via {gh} instead; feel free to contribute."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#reach-for-the-skyline",
    "href": "posts/2021-02-21-skyphone/index.html#reach-for-the-skyline",
    "title": "#GithubSkyline but hear me out",
    "section": "Reach for the skyline",
    "text": "Reach for the skyline\nSkyline is an online curio from GitHub that lets you input a userâ€™s name and get a 3D rendering of that userâ€™s contributions to the platform. You can even download the object to 3D print it, I guess?\nItâ€™s basically the contributions heatmap from your profile, but with a bonus third dimension. And itâ€™s on a plinth! That spins! And itâ€™s happening inside Tron!\n\n\n\nContributions in only two dimensions? Sad!\n\n\nWhy does it exist? Think Spotify Wrappedâ€”a summary of usersâ€™ listening habits at the end of each year1â€”which results in lots of social-media shares and free marketing.2"
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#sounds-of-the-city",
    "href": "posts/2021-02-21-skyphone/index.html#sounds-of-the-city",
    "title": "#GithubSkyline but hear me out",
    "section": "Sounds of the city",
    "text": "Sounds of the city\nI wrote recently about expressing a yearâ€™s worth of COVID-19 data in audio form. This process, called sonification, is made simple in R thanks to the {sonify} package.\nObviously itâ€™s far lower stakes, but thereâ€™s no reason we canâ€™t take a userâ€™s GitHub contributions data and sonify that too.3 Is that useful? Maybe. Is it it much effort? Not really.\nIt turns out that Skyline has a simple API. Provide a URL in this form to get a JSON back:\nhttps://skyline.github.com/api/contributions?username=username&year=2020\nThis lends itself nicely to a simple R function that grabs the data for a given user in a given year. The counts over time can then be passed to sonification and plotting functions.\nSoâ€¦ {skyphone}."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#pick-up-the-skyphone",
    "href": "posts/2021-02-21-skyphone/index.html#pick-up-the-skyphone",
    "title": "#GithubSkyline but hear me out",
    "section": "Pick up the {skyphone}",
    "text": "Pick up the {skyphone}\nYou can install the package from GitHub. Itâ€™s never going on CRAN.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/skyphone\")\n\nThereâ€™s three functions: one to get the data, one to sonify it, and one to plot it. All functions are prefaced by sky_ for easy tab completion.\n\nGet a dial tone\nThe sky_get() function takes a username and a year, which are used to generate an API string. The function fetches and tidies the resulting JSON from the call, generating a tidy tibble with a row of contributions per day.\n\nlibrary(skyphone)\nmd &lt;- sky_get(user = \"matt-dray\", year = 2020)\nmd\n\n## # A tibble: 366 x 6\n##    user       year  week   day date       count\n##    &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;int&gt;\n##  1 matt-dray  2020     1     1 2020-01-01     5\n##  2 matt-dray  2020     1     2 2020-01-02     5\n##  3 matt-dray  2020     1     3 2020-01-03     8\n##  4 matt-dray  2020     1     4 2020-01-04     3\n##  5 matt-dray  2020     2     5 2020-01-05     0\n##  6 matt-dray  2020     2     6 2020-01-06     7\n##  7 matt-dray  2020     2     7 2020-01-07    10\n##  8 matt-dray  2020     2     8 2020-01-08     2\n##  9 matt-dray  2020     2     9 2020-01-09     6\n## 10 matt-dray  2020     2    10 2020-01-10     0\n## # â€¦ with 356 more rows\nBy itself, this is a useful little function for the casual R user who doesnâ€™t want to handle the JSON.\n\n\nHello?\nThe output from sky_get() can be passed to sky_sonify(), which converts the count of contributions over time to audio form: a WaveMC object.\n\nsky_sonify(md, play = FALSE)\n\n## \n## WaveMC Object\n##  Number of Samples:      220500\n##  Duration (seconds):     5\n##  Samplingrate (Hertz):   44100\n##  Number of channels:     2\n##  PCM (integer format):   TRUE\n##  Bit (8/16/24/32/64):    16\nIf you set the play argument to TRUE then you will hear the sonified result over your speakers. You can also provide a directory path to the out_dir argument to save the audio file as a .wav to a specified location.\nThe data I collected sound like this:\n\n\n\n\n\nFor amusementâ€™s sake, 2016 is the year I joined GitHub and, well, thatâ€™s all that happened. We can fetch that year with sky_get() and then pipe that into sky_sonify(). Iâ€™ve saved the output file to my dekstop in this example.\n\nlibrary(magrittr)  # to demo pipes in {skyphone}\n\nsky_get(\"matt-dray\", 2016) %&gt;% \n  sky_sonify(play = FALSE, out_dir = \"~/Desktop\")\n\n\n\n\n\n\nDid you hear the momentous day on April 2?\n\n\nVideophone\nWeâ€™ve seen what a 3D skyline plot looks like; what about a good old fashioned 2D chart?\nThereâ€™s a simple, opinionated plotting function in the package that you are welcome to use, called sky_plot(). Again, you can pass the earlier object from sky_get().\n\np &lt;- sky_plot(md)\np\n\n\nSee how this looks like a skyline, but in 2D this time? Admittedly the â€˜buildingsâ€™ are a little weird. Radio towers? Use your imagination, buddy.\nFor a final flourish, we can apply a ridiculous vaporwave-inspired theme to the plot. This retro aesthetic has been rinsed to death of late, so naturally it was used in the Skyline interface.4\nThe {vapoRwave} package has a number of themes we can choose.\n\n# remotes::install_github(\"moldach/vapoRwave\")\nlibrary(vapoRwave)\np + new_retro()\n\n\nSoâ€¦ thatâ€™s it. But do join me in waiting for the first hospital admission of someone who trod on their 3D-printed skyline. Itâ€™s the risk you take."
  },
  {
    "objectID": "posts/2021-02-21-skyphone/index.html#environment",
    "href": "posts/2021-02-21-skyphone/index.html#environment",
    "title": "#GithubSkyline but hear me out",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 21:29:23 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "href": "posts/2023-04-02-splendid-r-games/index.html#tldr",
    "title": "R is a game engine, fight me",
    "section": "tl;dr",
    "text": "tl;dr\nR is â€˜a free software environment for statistical computing and graphicsâ€™. Ahahaha, no itâ€™s not, itâ€™s a game engine. Iâ€™ve created a â€˜splendidâ€™ list of games you can playâ€”written in Râ€”to prove it. Help expand it."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only",
    "title": "R is a game engine, fight me",
    "section": "Stats only!",
    "text": "Stats only!\nR is not a general, multi-purpose programming language. It was written to do statistical analysis and make charts. You are literally not allowed to do anything else with it. You should use &lt;LANGUAGE&gt; instead, which is much more suited to your specific use case. R is a joke language for nerds.\nYou should not read beyond this point if you think, quite rightly, that mirth and frivolity are unsuited to an R session."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "href": "posts/2023-04-02-splendid-r-games/index.html#stats-only-1",
    "title": "R is a game engine, fight me",
    "section": "Stats only?",
    "text": "Stats only?\nUnity. Unreal. GameMaker. Godot. All of these videogame engines are now obsolete.\nIt is Râ€”humble R!â€”that represents the future of gaming.\nTo prove it, Iâ€™ve created a list of â€˜splendid R gamesâ€™ in a GitHub repo1 that you are welcome to contribute to.2\nYes, R can be used for fun. Do not tell R Core."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "href": "posts/2023-04-02-splendid-r-games/index.html#wait-hes-serious",
    "title": "R is a game engine, fight me",
    "section": "Wait, heâ€™s serious?",
    "text": "Wait, heâ€™s serious?\nI think thereâ€™s three kinds of â€˜platformâ€™ for games written in R:\n\nFor the console\nIn Shiny\nPorted\n\nGames played in the console are pretty straightforward and probably most common. You can run some code, or a function from a package, to launch some code in the R console that you can interact with. A simple option for this might involve use of readline() to receive user input, for example, like Giora Simchoniâ€™s excellent text-based puzzler, Castle of R.\n\n\n\nGioraâ€™s Castle of R running in the terminal.\n\n\nShiny can give you a little more flexibility when it comes to graphics and user input, at the expense of needing to host the app and maybe some extra JavaScript skills. A great example of this is Pedro Silvaâ€™s winning entry (app, source) to the Posit Shiny contest in 2020.\n\n\n\nA still from Pedroâ€™s Shiny Decisions app.\n\n\nThe third category is a little more boundary-pushing. Imagine if R was powerful enough to let you port existing games. Well, surprise, ya boi Mike Cheng (aka coolbutuseless) has pushed hard on expanding the capabilities of R to run fast enough and with realtime user input,3 porting the classic Another World (1991) to R, which was showcased at 2022â€™s Posit conference (source, video, blog).\n\n\n\nA still from Mikeâ€™s rstudio::conf(2022) presentation, featuring Another World.\n\n\nOf course, within these â€˜platformsâ€™ are genres like word games, arcade games, puzzle games, etc. Will you be the first to create an MMORPG (a massively-multiplayer online R-powered game)?"
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "href": "posts/2023-04-02-splendid-r-games/index.html#i-am-an-indie-game-dev-now",
    "title": "R is a game engine, fight me",
    "section": "I am an indie game dev now",
    "text": "I am an indie game dev now\nIâ€™ve always been interested in how videogames are coded,4 wishing that I could do the same myself. Of course I could simply learn â€˜realâ€™ programming languages.\nExcept thatâ€™s blasphemy. Of course Iâ€™d rather break my own mind and spirit in an attempt to make R achieve 0.1% of what might be possible in P*thon.\nCase in point, Iâ€™ve made a few R packages containing some little toys (in order of gooddest to baddest):\n\n{r.oguelike} (source, blogs) for a procedural-dungeon explorer with enemy pathfinding and inventory\n{tamRgo} (source, blog) for a cyber pet in your R console that persists between sessions\n{safar6} (source, blog) for a text-based re-make of the Safari Zone from the first generation of PokÃ©mon games\n{ActionSquirrel} (source, blog) for a tile-based, turn-based minigame in the R console\n{hokey} (source, blog) for minigames that use direct keypress inputs with {keypress}\n\n\n\n\nHint when playing {tamRgo}: do not forget about your pet for 138 days. RIP Kevin XVIII.\n\n\nIâ€™ve got something in the pipeline that involves extremely rudimentary physics in the R console. Wow! For release in 2023 (because game launches never go wrong)."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "href": "posts/2023-04-02-splendid-r-games/index.html#ready-player-2",
    "title": "R is a game engine, fight me",
    "section": "Ready Player 2",
    "text": "Ready Player 2\nThe splendid list must be missing a bunch of games. Please leave an issue or pull request in the splendid-r-games repo to add more examples.\nNext stop: letting people run R games in the browser without an installed copy of R. This is already possible with a service like Binder, which can spin up an instance of RStudio with packages pre-installed I did this for {r.oguelike}).\n\n\n\nJust like the Nokia N-Gage, amirite?\n\n\nBut soon you might be able to use WebR to play games in the browser without even spinning up RStudio, ooh. So look out for an R version of itch.io in future, lol."
  },
  {
    "objectID": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "href": "posts/2023-04-02-splendid-r-games/index.html#environment",
    "title": "R is a game engine, fight me",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:50:56 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#tldr",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#tldr",
    "title": "GitHub Actions for R packages",
    "section": "tl;dr",
    "text": "tl;dr\nYou can trigger GitHub Actions to build and test your R package after a push or pull request. Create .github/workflows/ in your repo and add pre-prepared actions by the r-lib team with usethis::use_github_action()."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#shortcut",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#shortcut",
    "title": "GitHub Actions for R packages",
    "section": "Shortcut",
    "text": "Shortcut\nI refer back to this post a lot, so hereâ€™s some jump-links to the sections with the code I need:\n\nBuild check\nTest coverage\nBuild {pkgdown} site\n\nOtherwise read on for a more thorough explanation of GitHub Actions in the context of R packages."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#lights-camera",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#lights-camera",
    "title": "GitHub Actions for R packages",
    "section": "Lights, cameraâ€¦",
    "text": "Lights, cameraâ€¦\nGitHub Actions is a service that can be triggered to run workflows that build, test and deploy your code on GitHub. In other words, a continuous integration platform baked right into GitHub.\nBefore you start, I recommend checking out Jim Hesterâ€™s talk from rstudio::conf 2020 and reading the GitHub Actions with R book.\nGitHub Actions can be really helpful for developing R packages.1 For example, you can trigger actions with a push or pull request (PR) that:\n\nrun an R CMD build check of your package on multiple platforms\nrun your {testthat} unit tests\ncheck test coverage with {covr} and Codecov\nrebuild your {pkgdown} website\n\nChecking the build and coverage are standard practices for package development. They help ensure that your package works and is stable. GitHub Actions provides the icing on the cake by doing these things automatically.\nThese are all important for users of your package too. Build and coverage results show the robustness of the code and a website makes your documentation much easier to access.\nI wrote this post to remind me how to do it."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#actions",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#actions",
    "title": "GitHub Actions for R packages",
    "section": "â€¦Actions",
    "text": "â€¦Actions\nHow are actions stored, recognised and triggered?\nActions are expressed in YAML script files that read like a recipe for what to run and when to run it. You put these files in your repo at the path .github/workflows/, where GitHub recognises them. The information is interpreted and the actions are run remotely given the specified trigger.\nYou can learn more about the content of these YAML files from the GitHub actions with R book.\nYou could set these up manually, but actually you can shortcut the process with the {usethis} package and some pre-written examples."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#usethis-and-r-lib",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#usethis-and-r-lib",
    "title": "GitHub Actions for R packages",
    "section": "{usethis} and r-lib",
    "text": "{usethis} and r-lib\n{usethis} helps to shortcut the tedious setup steps of R packages and projects. It also includes functions to add GitHub Actions to your R package for you.\nIn particular, usethis::use_github_action() will add a YAML file to .github/workflows/ where GitHub Actions will find it; you just supply the name of a pre-written action.\nWhere do these pre-written actions come from? Well, the kind folks at r-lib have made a repo of R-focused examples that you can use.\n\nExample: {r2eng} package\nI recently used this method to set up GitHub Actions for the in-development {r2eng} package.\n{r2eng} has three actions in the workflow folder:\n\nR-CMD-check.yaml (see the YAML file) to run a build check\ntest-coverage.yaml (YAML) to assess how much of the code is protected by testing\npkgdown.yaml (YAML) to build the packageâ€™s website with {pkgdown}\n\nThis is a typical, minimal set of actions that suit me when developing R packages. Letâ€™s talk them through.\n\n1. Build check\nAn R CMD check2 runs a bunch of tests on your package (including your own unit tests) and returns errors, notes and warnings. Youâ€™re aiming for a passing build to prove the package is up to scratch.\n{usethis} has three actions-related functions specifically for setting up the build check. The standard one will run the R CMD check on macOS, Linux and Windows to make sure it passes across all these platforms.3\nRun this line to add the R-CMD-check.yaml action to the .github/workflows/ folder:\n\nusethis::use_github_action_check_standard()\n\nNote that this function will create .github/workflows/ if it doesnâ€™t already exist.\nFolllowing a push or PR, GitHub Actions will now automatically set up and run a build check on each OS to make sure the package meets the requirements.\n\n\n2. Test coverage\nThe R CMD check runs your unit tests, but it doesnâ€™t calculate how much of your code is actually covered by testing. Ideally you want this to be 100%, but also bear in mind that the metric doesnâ€™t take account of the volume or quality of tests.\nI use another r-lib package, {covr}, to interactively check how much of my code is tested. (In particular, the covr::report() function provides an interactive HTML report showing the total percentage and a line-by-line breakdown of where tests are missing.)\nYou can set up the free services Codecov or Coveralls to make your results public. Youâ€™ll need to have signed up for these services and granted their access to the repo you want to report on.\n{usethis} makes it easy to set up these services for your repo: it adds the relevant YAML files, a line to the â€˜Suggestsâ€™ section of your DESCRIPTION, and a badge to your README.\n\nusethis::use_coverage(\"codecov\")\n\nYou can see an example in action on the Codecov page for {r2eng}, which shows the percentage of coverage, a breakdown of the lines â€˜hitâ€™ and â€˜missedâ€™, and the commits that led to checks.\nOf course, you can automate this. Run this line to add the test-coverage.yaml action to the .github/workflows/ folder\n\nusethis::use_github_action(\"test-coverage\")\n\nThe â€˜test-coverageâ€™ GitHub Action will recheck coverage when you next push to the repo, with the results being updated on your coverage service of choice.\n\n\n3. Build {pkgdown} site\n{pkgdown}, also from r-lib, can automatically and painlessly generate a simple website from your packageâ€™s documentation, which you are free to customise. You can serve the site on the web via GitHub Pages so users can access the docs easily online.\nFor example, hereâ€™s the {pkgdown} website for the {r2eng} package, which uses default settings at time of writing. You can see that the README has become the home page and there are â€˜Referenceâ€™ and â€˜Changelogâ€™ tabs that autopoulate with the function documentation and NEWS file. Additional tabs are added here depending on the contents of your repo; for example, vignettes are added to an â€˜Articlesâ€™ tab if they exist.\nThe GitHub Actions with R book has a section on {pkgdown}. In short, the steps are:\n\nSet-up an empty â€˜gh-pagesâ€™ branch in your repo (the book has some code to do this from the command line)4\nBack in the main branch, run the {usethis} usethis::use_pkgdown() to activate {pkgdown} for your package repo\nRun usethis::use_github_action(\"pkgdown\") to add the YAML file that tells GitHub Actions to build the website on push\nPush to your repo and GitHub Actions will generate the website files in the gh-pages branch\nFrom your repo settings, set GitHub Pages to serve from the root of the gh-pages branch\nWait a few minutes and navigate to your site (in the form â€˜username.github.io/reponameâ€™)\n\nGitHub Actions will now rebuild the site automatically every time you make changes and push them."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#tickety-boo",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#tickety-boo",
    "title": "GitHub Actions for R packages",
    "section": "Tickety-boo",
    "text": "Tickety-boo\nYouâ€™ll get the full results of the actions in the â€˜Actionsâ€™ tab of your repo on GitHub. A successful check gets a satisfying tick next it. A failing test gets a cross. You can select a result and expand the results to trace exactly what the error was.\n\n\n\nSuccessful builds in the â€˜pkgdownâ€™ workflow.\n\n\nThis is handy because you and your users can check the results of your checks from the â€˜Actionsâ€™ tab of you repo without leaving GitHub.\nIt also means you can spot a failing PR and provide more commits to fix it before it gets merged.\n\n\n\nTicks! Ticks! Ticks!\n\n\nYou can also generate Markdown badges5 for your README that display the results of these actions and automatically update when theyâ€™re re-run. These are great for an at-a-glance understanding of a packageâ€™s development state. {usethis} adds these to your README automatically, but itâ€™s useful to know that you can get these badges from GitHub itself.\n\n\n\nMore easily obtained than having to defeat a PokÃ©mon gym leader.\n\n\nFor example, you can see badges in the {r2eng} README, like this one showing the percentage of test coverage:\n\n\n\n\n\nClicking them takes you to the relevant codecov.io page for the full breakdown of results."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#other-platforms-are-available",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#other-platforms-are-available",
    "title": "GitHub Actions for R packages",
    "section": "Other platforms are available",
    "text": "Other platforms are available\nSo, I think a combo of {usethis} and r-libâ€™s pre-prepared YAML files is the simplest route to auto-checking your R package and rebuilding its site.\nThere are many other YAML examples from r-lib though, and you can write your own. Thereâ€™s also an â€˜awesome listâ€™ of more general-purpose actions to explore.\nItâ€™s important to note that there are several other platforms for continuous integration, like Travis CI and Appveyor (see Roger Pengâ€™s book for an overview), but this requires you to setup multiple accounts and configuration files. At time of writing, GitHub Actions has the benefit of testing across all the major operating systems and is easier to set up (learn more in Jim Hesterâ€™s talk).\nAnyway, good luck in putting a GitHub Action in action on GitHub."
  },
  {
    "objectID": "posts/2020-08-09-ghactions-pkgs/index.html#environment",
    "href": "posts/2020-08-09-ghactions-pkgs/index.html#environment",
    "title": "GitHub Actions for R packages",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:21:21 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#tldr",
    "href": "posts/2023-03-16-webr-test/index.html#tldr",
    "title": "Playgrounds with WebR and Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nWebR lets you run R in the browser(!). Now you can make WebR chunks in Quarto that render to editable, executable blocks(!)."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#sliding-into-tedium",
    "href": "posts/2023-03-16-webr-test/index.html#sliding-into-tedium",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Sliding into tedium",
    "text": "Sliding into tedium\nI wrote recently a simple introduction to how R parses code. I provided a function that I said the reader could go away and run themselves.\nAs inâ€¦ copy-paste it into an instance of R running on their machine. Gross.\nWouldnâ€™t it be better if people could just tinker with the code right there in the post? This kind of â€˜playgroundâ€™ could be great for explaining concepts and teaching.1"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#i-seesaw-a-solution",
    "href": "posts/2023-03-16-webr-test/index.html#i-seesaw-a-solution",
    "title": "Playgrounds with WebR and Quarto",
    "section": "I seesaw a solution",
    "text": "I seesaw a solution\nWebR lets you run R in the browser. Read that again! This is a landmark piece of work from George Stagg and Lionel Henry.\nI wonâ€™t go into technicals and limitations here. For more information, see:\n\nthe docs\nthe v0.1 launch post\nan â€˜awesomeâ€™ list of resources\n\nCrucially for my needs, you can now run WebR chunks in a Quarto document, thanks to James J Balamuta. This renders interactive blocks of R code that the reader can adjust and execute with button-click:\n\n\n\nBeware: this is a gif, not an embedded demo!\n\n\nCheck out Jamesâ€™s coatless/quarto-webr GitHub repo for the source. Thereâ€™s also a live demo and its source."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#swinging-into-action",
    "href": "posts/2023-03-16-webr-test/index.html#swinging-into-action",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Swinging into action",
    "text": "Swinging into action\nTo have a go yourself, do follow the setup steps in Jamesâ€™s quarto-webr README and look at the source of his demo.\nUltimately you can:\n\nInstall the extension to your project folder by running quarto add coatless/quarto-webr in the terminal\nSet filter: webr in the YAML of your qmd file2\nWrite code chunks in the qmd using the {webr} engine\n\nThis made it straightforward to prepare a little Quarto doc with chunks powered by the â€˜webrâ€™ engine, which I deployed to the web via Netlify.3\nYou can visit that live page or see the underlying source on GitHub.4\nSo now you can tinker with the example I gave in the original blogpost about parsing R code. Unfortunately I canâ€™t add this directly to the post, since this blog is not made with Quarto."
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#a-blog-platform-merry-go-round",
    "href": "posts/2023-03-16-webr-test/index.html#a-blog-platform-merry-go-round",
    "title": "Playgrounds with WebR and Quarto",
    "section": "A blog-platform merry-go-round",
    "text": "A blog-platform merry-go-round\nIâ€™ve written this quick demo and post because I was excited about what George & Lionel and James have put together. Thereâ€™s so many system-independent applications of this approach that could help with teaching and learning, or explaining simple ideas in a blog post.\nIn fact, this blog may eventually switch from {blogdown} to Quarto to take advantage of WebR. Itâ€™ll be a pain to convert old posts, but luckily I already missed the earlier {blogdown}-to-{distill} bandwagon, lol.5"
  },
  {
    "objectID": "posts/2023-03-16-webr-test/index.html#environment",
    "href": "posts/2023-03-16-webr-test/index.html#environment",
    "title": "Playgrounds with WebR and Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 13:19:28 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html",
    "href": "posts/2022-08-11-more-addins/index.html",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "",
    "text": "I made a couple of packages that contain RStudio Addins: {quartostamp} inserts little divs and classes into your Quarto documents, while {snorkel} inserts Rd tags into your {roxygen2} function documentation."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#tldr",
    "href": "posts/2022-08-11-more-addins/index.html#tldr",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "",
    "text": "I made a couple of packages that contain RStudio Addins: {quartostamp} inserts little divs and classes into your Quarto documents, while {snorkel} inserts Rd tags into your {roxygen2} function documentation."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#al-addin",
    "href": "posts/2022-08-11-more-addins/index.html#al-addin",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Al Addin",
    "text": "Al Addin\nRStudio Addins let you access R functions interactively at the click of a button (or with a keyboard shortcut, or via the RStudio command palette). I particularly like them for easy sharing of insertable pre-written code.\nSee Dean Attaliâ€™s {addinslist} package for examples or the {shrtcts} package by Garrick Aden-Buie for an alternative approach to â€˜make anything an RStudio shortcutâ€™.\nOn my part:\n\nI wrote about the little {backtick} Addin package that inserts backticks (`) and backtick constructions1\nI wrote about the {r2eng} package, which has an Addin that lets you highlight some R code and then speak that expression out loud in English\nI wrote about the {blogsnip} Addin package that can manipulate code used to write this blog\nthe {a11ytables} package has an Addin to insert code skeletons for creating publishable best-practice spreadsheets\n\nRStudio Addins are kinda straightforward to put into in an R package. Put your functions in R/ as usual, then write an inst/rstudio/addins.dcf file to declare your functions (e.g.Â see {backtick}â€™s .dcf). Learn more from Sharon Machlis and Jozef Hajnala.\nThe user can then select the functions from the â€˜Addinsâ€™ dropdown in the RStudio IDE.\nOf late Iâ€™ve written two packagesâ€”{quartostamp} and {snorkel}â€”that contain RStudio Addins to help me write code structures that I struggle to remember when writing Quarto documents and function documentation.\nOthers seem to have found these useful, so I thought Iâ€™d â€˜officiallyâ€™ signal that they exist."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#package-quartostamp",
    "href": "posts/2022-08-11-more-addins/index.html#package-quartostamp",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Package {quartostamp}",
    "text": "Package {quartostamp}\n\nQuartoâ€”â€˜new R Markdownâ€™â€”is all the rage right now, having been officially launched at the recent rstudio::conf(2022) conference. Folks are going bonkers for tools and techniques to learn and implement it. A good place to begin is the Awesome Quarto List by MickaÃ«l Canouil.\nFeatured there is {quartostamp}, a little R package I made that contains an RStudio Addin to insert into your Quarto doc a number of useful divs and classes. As the README puts it:\n\nWhy â€˜quartostampâ€™? You could physically stamp some pre-prepared type into a literal quarto document; you can digitally stamp some pre-written elements into your qmd file.\n\n\n\n\nHex logo for {quartostamp}.\n\n\nYou can install it from GitHub like:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/quartostamp\")\n\nAs an example, did you forget how to insert speaker notes into a presentation? Go to Addins &gt; Insert Speaker Notes and this will be inserted to your doc:\n::: {.notes}\nSpeaker notes go here.\n:::\nThatâ€™s a straightforward one; a two-column layout is more complex. Go to Addins &gt; Insert Column Layout and you get this:\n:::: {.columns}\n\n::: {.column width='40%'}\nLeft column\n:::\n\n::: {.column width='60%'}\nRight column\n:::\n\n::::\nThese elements are basically lifted from the docs, so big shoutout to the authors JJ Allaire, Charles Teague, Carlos Scheidegger, Yihui Xie and Christophe Dervieux.\nGo to the package website to see the current list of functions available in the Addin. Click them to learn more, including a preview of the actual text that will be inserted into your document.\nI think the limits of the package are the content that you would insert in the body of your Quarto doc, or to places like Revealjs slide headings. In other words, not Quarto YAML nor chunk options. These are autocompleted in RStudio, or otherwise dealt with already elsewhere.\nDo submit your ideas for {quartodown} as issues or pull requests in the GitHub repo.\n\n Note\nThe package was updated in June 2023 to version 0.1.0, which lets you highlight some text and run the addin so that the selected text becomes the body of the stamp. A simple dummy skeleton is inserted if you use the addin without highlighting any text, as described above.\nFor example, you can write some bullets, highlight them, select â€˜Insert Speaker Notesâ€™ and youâ€™ll get the appropriate markup for those bullets to be rendered as speaker notes in your Quarto presentation."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#package-snorkel",
    "href": "posts/2022-08-11-more-addins/index.html#package-snorkel",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Package {snorkel}",
    "text": "Package {snorkel}\n\nThe {snorkel} package2 is another solution to storing syntax outside of my own brain. In this case, it helps out with formatting text in {roxygen2} function documentation.3\nThe reason for the name should be obvious.4 As the package README puts it:\n\nYou put a snorkel in your mouth to help you breathe oxygen; you put a {snorkel} in your addins to help you write with {roxygen2}.\n\nYes, this is package-name-driven development; I thought of the name before writing anything.\nInstall from GitHub like:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/snorkel\")\n\nSo, how would you embolden a word in your function documentation? Highlight the word and then go to Addins &gt; Format Bold and you get:\n#' I am a \\strong{bold} boy.\nHereâ€™s something more complex: how can you link to a function in an external package? Write the package function in the form package::function, highlight it and then select Addins &gt; Link To Function (Another Package) and you get:\n#' When the crowd say 'Bo \\code{\\link[dplyr]{select}}a'.\nThe functions in the Addin insert code mentioned in the {roxygen2} docs, so big shoutout to the authors Hadley Wickham, Peter Danenberg, Gabor CsÃ¡rdi, Manuel Eugster and RStudio.\nThe package website has a list of the functions available in the Addin,5 which you can click to see previews of what each one will insert.\nFor now I think the functions in the package should focus just on the Rd tags that format the documentation, rather than the {roxygen2} tags (like @description, @params, etc). The latter are already autocompleted in RStudio, so I feel like thereâ€™s less need. Similarly, the package doesnâ€™t include functions to insert Markdown into function documentation, but perhaps it could be expanded in future.\nNew functionality is always welcome; please raise an issue or pull request in the GitHub repo."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#addin-your-suggestions",
    "href": "posts/2022-08-11-more-addins/index.html#addin-your-suggestions",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Addin your suggestions",
    "text": "Addin your suggestions\nI made these primarily for myself; Iâ€™m really bad at remembering syntax. I always need â€˜a brain outside my brainâ€™. Maybe theyâ€™ll be useful for you too.\nPerhaps you can help out by expanding the list of functions in these packages. Please add any suggestions or features in an issue or pull request in either GitHub repo.\nSo, donâ€™t be a cad, it would be maddeninâ€™ and saddeninâ€™ if you hadnâ€™t added in your Addin ideas, so be a rad chad and add your addins in the Addins."
  },
  {
    "objectID": "posts/2022-08-11-more-addins/index.html#environment",
    "href": "posts/2022-08-11-more-addins/index.html#environment",
    "title": "Two RStudio Addins: {quartostamp} and {snorkel}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:00:05 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#tldr",
    "href": "posts/2020-09-21-londonmapbot/index.html#tldr",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "tl;dr",
    "text": "tl;dr\nI made @londonmapbot: a simple Twitter bot that uses the R package {rtweet}, GitHub Actions and the Mapbox API. Find the source on Github.\n\n Note\nTwitter changed its API terms in 2023. As a result, you probably canâ€™t re-run the code in this blog. Read about how I moved londonmapbot to Mastodon at botsin.space/@londonmapbot because of these changes."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#london-from-socially-distant-space",
    "href": "posts/2020-09-21-londonmapbot/index.html#london-from-socially-distant-space",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "London from (socially-distant) space",
    "text": "London from (socially-distant) space\nIâ€™ve wanted to make a Twitter bot for a while, but it seemed like Hard Work. Spoiler: itâ€™s not.\nSo, Iâ€™ve made @londonmapbot: a completely unsophisticated proof-of-concept Twitter bot.\nWhat does it do? It posts a satellite image from random coordinates in Greater London (well, from a bounding box roughly within the M25 motorway) on schedule. Below is an example image from an existing @londonmapbot tweet. Can you guess where it is?1\n\nThe code for this runs remotely. You can set it up, let it run and never think about it again.\nSo how does it work? A scheduled GitHub Action runs R code to generate random latitude and longitude values, which are sent to the Mapbox API to retrieve a satellite picture. The image is then posted via the Twitter API that is accessed using the {rtweet} package. A link to the coordinates on OpenStreetMap is also included so you can find out exactly where the image is from.\nThe main purpose was to learn more about GitHub Actions, building on my previous posts about using actions for continuous integration, but I think incidentally that the tweets are quite pleasing to look at and to guess where they are."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#the-components",
    "href": "posts/2020-09-21-londonmapbot/index.html#the-components",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "The components",
    "text": "The components\nThe source code is quite simple. Thereâ€™s two files, basically:\n\na single YAML file containing the action2\na single R script that generates the tweet and posts it\n\nLetâ€™s look at the GitHub Actions code in the YAML file and the use of {rtweet} and Mapbox in the R file.\n\nGitHub Actions\nGitHub Actions is a platform for automating workflows remotely. In short, you write a small YAML file in the .github/workflows/ subfolder of your repo, which contains instructions for the code you want to run and when to run it.3 Iâ€™ve written before about using GitHub Actions for continuous integration of R packages, for example.\nAn action can be triggered by an event, like a git push to your repo. You can also schedule it with a cron job, to run every hour, once a day, or whatever.\nHereâ€™s what the YAML file looks like for the londonmapbot action:\nname: londonmapbot\n\non:\n  schedule:\n    - cron: '0,30 * * * *'\n\njobs:\n  londonmapbot-post:\n    runs-on: macOS-latest\n    env:\n      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}\n      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}\n      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n      MAPBOX_PUBLIC_ACCESS_TOKEN: ${{ secrets.MAPBOX_PUBLIC_ACCESS_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@master\n      - name: Install rtweet package\n        run: Rscript -e 'install.packages(\"rtweet\", dependencies = TRUE)'\n      - name: Create and post tweet\n        run: Rscript londonmapbot-tweet.R\nItâ€™s interpreted like so:\n\nthis action is called â€˜londonmapbotâ€™\nrun this code at :00 and :30 past each hour4\nthe first (and only) job in this action is called londonmapbot-post\nstart up a remote machine with the latest macOS operating system installed (this is where your code will be run)\nset some environmental variables, in this case keys that will be used to access the Twitter and Mapbox APIs (see the â€˜Secretsâ€™ section later in this post)\nthe steps of the job are to:\n\nuse some pre-written code by GitHub to check out the repo\nuse some prewritten code from r-lib that sets up R\ninstall the {rtweet} package and its dependencies\nrun the named R script from the repo\n\n\nI would recommend changing your GitHub notification alerts once the bot is up and running, otherwise youâ€™ll get a message every time the action executes. You can change this under Settings &gt; Notifications &gt; GitHub Actions, where you can uncheck the boxes under â€˜Notifications for workflow runs on repositories set up with GitHub Actionsâ€™."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#rtweet",
    "href": "posts/2020-09-21-londonmapbot/index.html#rtweet",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "{rtweet}",
    "text": "{rtweet}\nThe action runs an R script that generates content for a tweet and then posts it. This script makes use of the package {rtweet} by Mike Kearney, which lets you interact with the Twitter API with R functions.\nYou need a Twitter account, of course, and also to sign up as a Twitter developer to access the API.\n\n Note\nTwitter has moved to version 2.0 of their API since this post was written. As things stand in February 2022 (hello from the future), you will need to ask for â€˜elevatedâ€™ access in Twitterâ€™s Developer Portal to ensure you can reach version 1.1 of the API, which is what {rtweet} is set up to communicate with.\nHuge thanks to Oscar Baruffa, who learnt about this hard way when setting up a Twitter bot for the excellent Big Book of R (an index of 250+ free books for R programming).\n\n\nAs a developer, you can create â€˜appsâ€™ to obtain keys: private alphanumeric passcodes that grant you access to the API.\nTypically, when working locally, you would either provide these keys as bare strings, or put them in your .Renviron file. With the latter, you can then use Sys.getenv() to call them from your .Renviron, which stops you exposing the raw keys in your code.\nBelow is an example of how you can use {rtweet} to post a tweet from R if youâ€™ve added the keys to your .Renviron.\n\n# Install the package from CRAN\ninstall.packages(\"rtweet\")\n\n# Create a token containing your Twitter keys\nrtweet::rtweet_bot(\n  api_key       = Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n  api_secret    = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n  access_token  = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\n# Example: post a tweet via the API\n# The keys will are in your environment thanks to create_token()\nrtweet::post_tweet(status = \"This is a test tweet.\")\n\n\n Note\n{rtweet} version 1.0 was released with breaking changes in July 2022 and so Iâ€™ve changed the code above to use the function rtweet_bot() instead of create_token(). You can read a separate blogpost about these changes.\n\n\nThis is basically what happens in the londonmapbot R script too. When writing an action, the keys arenâ€™t fetched from your .Renviron file, however. Instead, you can encrypt them on GitHub and provide them in the env call of your actionâ€™s YAML file. See the â€˜Secretsâ€™ section below for more detail on this.\n\nMapbox\nMapbox is a company with services for mapping, geocoding and navigation, which developers can use for integrating into their apps for things like asset tracking, route optimisation or anything that requires a map interface for users.\nAgain, youâ€™ll need to set up a Mapbox account to get a key for using the API. While the target audience is largely commercial, there appears to be a generous free allowance of 1250 requests per minute for the static image API.\nYou can then pass parameters to the Mapbox API via a URL. This is well explained in the Mapbox Documentation, which has an excellent â€˜playgroundâ€™ interface for you to test out your call.\nYou basically modify a particular URL string to ask the API for what you want. For example, you can ask for a 300x200 pixel satellite image of the coordinates of -0.1709 and 51.5065 with zoom level 12, which is Hyde Park:\nhttps://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/-0.1709,51.5065,12,0/300x200?access_token=YOUR_MAPBOX_ACCESS_TOKEN\nVisiting the URL in your browser returns the requested image as a JPEG:\n\n\n\nThe Serpentine is so aptly named.\n\n\nOf course, youâ€™ll need to replace the access-token placeholder (YOUR_MAPBOX_ACCESS_TOKEN) in that URL with your own Mapbox key. Rather than provide this as a bare string, the londonmapbot R script calls it from the environment (like we saw in the {rtweet} code in the last section).\nHereâ€™s the code used by londonmapbot to fetch the satellite image from Mapbox:\n\n# Generate random coordinates\nlon &lt;- round(runif(1, -0.5, 0.27), 4)\nlat &lt;- round(runif(1, 51.3, 51.7), 4)\n\n# Build URL and fetch from Mapbox API\nimg_url &lt;- paste0(\n    \"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/\",\n    paste0(lon, \",\", lat),\n    \",15,0/600x400@2x?access_token=\",\n    Sys.getenv(\"MAPBOX_PUBLIC_ACCESS_TOKEN\")\n)\n\n# Download the image to a temporary location\ntemp_file &lt;- tempfile(fileext = \".jpeg\")\ndownload.file(img_url, temp_file)\n\nThe code shows a paste0() statement that builds the URL with random latitude and longitude and the Mapbox key. The image from that URL is then downloaded into a temporary file, where it can be supplied to the media argument of rtweet::create_tweet() for posting to Twitter."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#secrets",
    "href": "posts/2020-09-21-londonmapbot/index.html#secrets",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "Secrets",
    "text": "Secrets\nIâ€™ve mentioned in this post about keeping your keys secure. You donâ€™t want others to copy and use your keys nefariously, so itâ€™s a good idea not to simply paste them into your code as bare strings for the world to see.\nGithub lets you store secrets securely in the â€˜Secretsâ€™ section of the â€˜Settingsâ€™ tab in your repo. No-one can see these, but they can be called into your code when it runs.\n\n\n\nKeep it secretâ€¦ keep it safe.\n\n\nLetâ€™s use the londonmapbot Twitter consumer API key as an example. First, I saved the string as a GitHub secret with the name TWITTER_CONSUMER_API_KEY. I then called this in the env section of my YAML file in the form ${{ secrets.TWITTER_CONSUMER_API_KEY }}. Running the action results in the string being pulled from the secrets stash and decrypted, where itâ€™s available in the environment. Then the R code can call it with Sys.getenv() when access to the API is needed."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#it-does-the-job",
    "href": "posts/2020-09-21-londonmapbot/index.html#it-does-the-job",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "It does the job",
    "text": "It does the job\nSo, you can:\n\ntake a look at the @londonmapbot profile\nfind the source on GitHub\ninspect the YAML file that runs the action\nsee the R script that generates and posts the image\n\nThe GitHub README also lists a few other map botsâ€”which Iâ€™ve christened the â€˜mapbotverseâ€™â€”that have taken inspiration from londonmapbot; take a look at those too.\nOf course, you should fork the repo, or use it as a template, to create your own bot. Let me know what you get up to.\nDo give me suggestions and pull requests, or tell me how good you are at identifying the granular location in each image."
  },
  {
    "objectID": "posts/2020-09-21-londonmapbot/index.html#environment",
    "href": "posts/2020-09-21-londonmapbot/index.html#environment",
    "title": "A Twitter bot with {rtweet} and GitHub Actions",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:27:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html",
    "href": "posts/2020-12-08-postcard/index.html",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "",
    "text": "Sleek. Minimal. Bearded."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#tldr",
    "href": "posts/2020-12-08-postcard/index.html#tldr",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "tl;dr",
    "text": "tl;dr\n\nDearest ma and pa,\nThe food here is okay. Mostly Iâ€™ve been setting up a single-page personal site with the {postcards} package for R, deploying it with Netlify and setting up a custom domain with Namecheap. More rain is forecast for tomorrow.\nWish you were here,\nMatthew"
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#domain-driven-development",
    "href": "posts/2020-12-08-postcard/index.html#domain-driven-development",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Domain-driven development",
    "text": "Domain-driven development\nA hobby of mine is to look for funny domain names and to not buy them.\nEventually I realised that matt-dray.com wasnâ€™t taken, so I figured I might as well squat it and do something pseudo-useful with it.1\nYes, I could write some HTML2 and CSS to make a complicated shrine to self-absorption, but why bother trying to center divs when Sean Kross has just announced the {postcards} R package to create nice, minimal landing pages?\nThis post is a short self-reminder of how to:\n\nGenerate a webpage with {postcards}\nDeploy it with Netlify\nPoint to it with a custom domain from Namecheap\n\nThis post isnâ€™t about the tubes and wires of the internet. Itâ€™s more the how than the why."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#write-a-postcard",
    "href": "posts/2020-12-08-postcard/index.html#write-a-postcard",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Write a postcard",
    "text": "Write a postcard\n{postcards} provides some R Markdown templates that contain space for a photo, a mini-bio and some buttons to link out to your profiles elsewhere. See the packageâ€™s readme for examples.\nYou can install the development version from GitHub:\n\nremotes::install_github(\"seankross/postcards\")\n\nI generated an R Markdown file with the â€˜Jollaâ€™ template using the following line:\n\nrmarkdown::draft(\"index.Rmd\", \"Jolla\", package = \"postcards\")\n\nNote that the file is called index.Rmd and will thus render to index.html. This is the default file that gets read when a site is visited.\nIn the YAML header of the template you can specify a title, which is likely to be your name; the output format, which is the name for our chosen {postcards} template; links, where you specify the wording and underlying links for the pageâ€™s buttons; image for your bokeh-rich professional headshot and favicon for the little image that will appear alongside your page title in a browser tab. \n---\ntitle: \"Matt Dray\"\nimage: \"matt.jpg\"\nlinks:\n  - Blog: \"https://www.rostrum.blog/\"\n  - Twitter: \"https://twitter.com/mattdray/\"\n  - GitHub: \"https://github.com/matt-dray/\"\noutput:\n  postcards::jolla\nfavicon: favicon.gif\n---\nYou can then write your mini bio in the body text of the document. I garnished mine with emoji via Hadley Wickhamâ€™s {emo} package.\nThe {postcards} templates are ready to go out of the box but you can still tinker with the style. I decided to pull in a font, Fantasque Sans Mono by Jany Belluz3, and put a CSS chunk in the R Markdown to specify it.\n\n\n\nA preview of the â€˜Jollaâ€™ template. Tobi seems nice.\n\n\nThe content and design of my page may change at any time, but I purposefully want it to be minimal and have a clean and simple appearance. The {postcards} package is also in development, so I look forward to testing out any new features that appear in future."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#pop-it-in-the-post",
    "href": "posts/2020-12-08-postcard/index.html#pop-it-in-the-post",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Pop it in the post",
    "text": "Pop it in the post\nYou could put your siteâ€™s files in a GitHub repo and serve it with GitHub Pages. Upside: itâ€™s free. Downside: your URL will be in the form username.github.io/your-postcard-repo, which isnâ€™t particularly sleek.\nInstead you could use a free service like Netlify to deploy a site from a GitHub/GitLab/BitBucket repository and set up a custom domain to point at it. Iâ€™ve had prior success with Netlify for this blog, so thatâ€™s why Iâ€™m using it here.\nA bonus of this approach is continuous deployment: pushing changes to your repo causes Netlify to rebuild and deploy your site automatically, so you donâ€™t need to worry about it.\nTo set up my page, I signed into Netlify and I:\n\nclicked the â€˜New site from Gitâ€™ button\nclicked â€˜GitHubâ€™ in section â€˜1. Connect to Git providerâ€™, because thatâ€™s where my {postcards} repo is stored\nselected my github.com/matt-dray/postcard/ repo in section â€˜2. Pick a repositoryâ€™ after authorising Netlify to connect to to it\nleft the â€˜build commandâ€™ empty in section â€˜3. Build options and deploy!â€™ and set the â€˜publish directoryâ€™ to â€˜/â€™ (because I want to serve index.html from the root of the repo)\nclicked â€˜deploy siteâ€™\n\nNetlify takes a moment to build and serve the site after you click â€˜deploy siteâ€™. Itâ€™s served automatically from a URL in the form random-name.netlify.app4 but, as mentioned, you can configure a privately-owned domain name instead.\nFor more on these steps, including screenshots, see Netlifyâ€™s step-by-step guidance on deploying static and single-page sites.\nItâ€™s also worth mentioning Netlify Drop: a service that lets you simply drag and drop your siteâ€™s files to deploy them, rather than needing to authorise Netlify to connect to your Git-based repo. This is quick and technically easier, but youâ€™ll have to drag and drop each time you want to update the site."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#address-it-properly",
    "href": "posts/2020-12-08-postcard/index.html#address-it-properly",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Address it properly",
    "text": "Address it properly\nThereâ€™s a whole bunch of domain-name providers. Iâ€™m focusing here on Namecheap, which is what I used to for this blog. After buying a domain, thereâ€™s a little bit of back-and-forth required between Netlify and Namecheap.\nIn brief:\n\nIn your Namecheap account, click the â€˜Manageâ€™ button for your domain and set the dropdown in the â€˜Nameserversâ€™ section to â€˜Custom DNSâ€™\nIn your Namecheap account, click â€˜Set up a custom domainâ€™, type it in and confirm\nClick â€˜Set up Netlify DNSâ€™ alongside the domain and click through until youâ€™re provided a handful of nameserver strings\nBack on Namecheap, copy-paste each of these into the â€˜Nameserversâ€™ section from step 1 and click the check mark to confirm\nWait.\n\nItâ€™ll take a short while, but thereâ€™ll be a sort of high-five between your domain and your site and then itâ€™ll be ready for viewing.\nSee Ezekiel Ekunolaâ€™s excellent blog post for a more thorough guide, which includes screenshots.\nNote also that Netlify provides HTTPS for free too, which is good for a number of reasons, though the certificate can take a few hours to generate.\nYou can check your domain settings in Netlify at any time by clicking the site name in your account and then clicking the â€˜Domain settingsâ€™ button.\n\n\n\nNetlifyâ€™s domain settings after successful set-up."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#post-postcard-postscript",
    "href": "posts/2020-12-08-postcard/index.html#post-postcard-postscript",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Post-postcard postscript",
    "text": "Post-postcard postscript\nSo this is a relatively quick way of generating up a single-page site with {postcards}; hosting the source on GitHub; deploying it with Netlify; and serving it via a custom domain bought from from Namecheap.\nThis seems to work fine for me for now. Let me know if you have a better approach to generating and deploying simple single-page sites."
  },
  {
    "objectID": "posts/2020-12-08-postcard/index.html#environment",
    "href": "posts/2020-12-08-postcard/index.html#environment",
    "title": "Sending {postcards} with Netlify and Namecheap",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 19:03:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#tldr",
    "href": "posts/2021-06-08-recreate-spear/index.html#tldr",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "tl;dr",
    "text": "tl;dr\nFor a competition I recreated a data visulisation using base R.\n\n Note\nI won the â€˜most accurateâ€™ prize, lol."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#cottonviz",
    "href": "posts/2021-06-08-recreate-spear/index.html#cottonviz",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "#CottonViz",
    "text": "#CottonViz\nThe Young Statisticianâ€™s and History of Stats sections of the Royal Statistical Society (RSS) have challenged people to recreate1 or remix Mary Eleanor Spearâ€™s visualisation of cotton supplies in the United States in the 1940s:2\n\nI thought it would be interesting to recreate it using only Râ€™s built-in base graphics. This might be a nice demo of zero-dependency plotting for R users who are more familiar with {ggplot2}.3\nLong-story short, hereâ€™s what popped out at the end of my scripting:\n\nItâ€™s certainly not an identical match to the original, but it gets most of the way there.4\nYou can find the scripts for both the recreation and gif in my matt-dray/viz-recreation GitHub repo.\nThe rest of this post is a walkthrough of the code used to create the final output. Itâ€™s in five sections: (1) set-up, (2) line plot, (3) bar plot, (4) margin labels and (5) saving, with a closing section reflecting on tricky parts and potential improvements."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#set-up",
    "href": "posts/2021-06-08-recreate-spear/index.html#set-up",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "1. Set-up",
    "text": "1. Set-up\n\nData\nThe dataset is available to download from the RSS website, but itâ€™s small enough that I can just recreate it here exactly.\n\ncotton &lt;- data.frame(\n  Year = 1942:1948,\n  `US consumption` = c(11160, 9993,  9693,  9423,  10072, 9374,  7833),\n  Exports          = c(1480,  1139,  2007,  3613,  3545,  1968,  4785),\n  Stocks           = c(10657, 10744, 11164, 7326,  2530,  3080,  5283),\n  `Total supply`   = c(23297, 21876, 22864, 20362, 16147, 14422, 17901),\n  check.names = FALSE  # allows for spaces in variable names\n)\n\n\n\nFonts\nIâ€™ve used two font families that werenâ€™t pre-installed on my system:\n\nRouted Gothic, a very close match for the general text of the plot\nHussar Bold Condensed, a not-that-great match for the main title, but itâ€™ll do\n\nIt was sufficient for me to install these fonts on my system (macOS Big Sur running R v4.0.5) and invoke them by name, as youâ€™ll see through the rest of this walkthrough. Your mileage may vary.\n\n\nConstants\nIâ€™ve set a few values as objects so they can be reused and changed more easily without having to copy-paste in the body of the script. Note that Iâ€™ve used the convention here that constants are ALL_CAPS, so theyâ€™re easier to spot in the plotting code.\n\n\nClick for constants (I hid this because itâ€™s dull)\n\n\n# Constants: general\nCEX       &lt;- 0.8      # font size\nYDIV      &lt;- 1000     # division for y-axis\nBLACK     &lt;- \"black\"  # easy to supply off-black instead\nWHITE     &lt;- \"white\"\nXTICK_LEN &lt;- 0.02     # x axis tick length\nYTICK_LEN &lt;- 0.03\n\n# Constants: lineplot (LP)\nLP_YLIM      &lt;- c(0, 12)  # y-axis limite\nLP_WIDTH     &lt;- 3         # width of lines\nLP_YTICK_SEQ &lt;- seq(2, 10, 2)  # y tick locations \nLP_YLAB_SEQ  &lt;- seq(0, 12, 2)  # y label locations\n\n# Constants: barplot (BP)\nBP_YLIM        &lt;- c(0, 25)\nBP_YTICK_SEQ   &lt;- seq(5, 20, 5)\nBP_YLAB_SEQ    &lt;- seq(0, 25, 5)\nBP_SPACE       &lt;- 0.5  # space between bars\nBP_HATCH_ANGLE &lt;- 45   # hatchmark angle\nBP_HATCH_HI    &lt;- 25   # hatchmark density\nBP_HATCH_MID   &lt;- 22\nBP_HATCH_LO    &lt;- 12\n\n\n\n\nStart a graphics device\nWith base plotting you first open a new â€˜deviceâ€™ so that your plotting calls can be captured. You specify things here like the write path and dimensions. When youâ€™ve finished your plotting code, you run dev.off() to close the device and save the output.\nHere Iâ€™m using png() so the output is a PNG file. This function is part of the suite of in-built graphics devices from the {grDevices} package, which also includes things like the lossless tiff() format.\n\npng(\n  \"~/Desktop/cottonviz.png\",  # set to a path of your choice\n  width  = 20,\n  height = 12.2,\n  units  = \"cm\",\n  res    = 1200\n)\n\nYou can think of this as setting up a canvas and then youâ€™re going to layer plot objects over the top of it (perhaps not too dissimilar to {ggplot2}). Beware: things like units and placement of elements will be related to the height and width that youâ€™ve declared here.\nThat means you shouldnâ€™t necessarily rely on the graphics windows opened by R or RStudio when previewing the final output; you should rely only on a saved output.\n\n\nPlotting parameters\nWith base R you can set various par()ameters that apply to your plot as a whole. The chart weâ€™re recreating is one row of two plots, so we can use mfrow = c(1, 2), for example. We can also set some global things like the font family.\n\n# Set plotting parameters\npar(\n  mgp = c(0, 0.2, 0),   # gap to tick labels\n  mar = c(3, 2, 4, 1),  # margins\n  mfrow = c(1, 2),      # plot layout\n  ann = FALSE,          # annotation\n  cex.axis = CEX,       # axis font size\n  family = \"Routed Gothic\"  # font family\n)\n\nIâ€™ve selected â€˜Routed Gothicâ€™ as the font family and I think itâ€™s a great match. Itâ€™s based on the Leroy lettering set that was often used for hand-labelling technical drawings."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#line-plot",
    "href": "posts/2021-06-08-recreate-spear/index.html#line-plot",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "2. Line plot",
    "text": "2. Line plot\nSo, hereâ€™s the first â€˜hackâ€™. Iâ€™m going to set up a â€˜fakeâ€™ scatter plot with no content and then weâ€™re going to add our desired content to it sequentially. This provides the correct plot dimensions to which we can add bespoke details.\n\n# Dummy x-y scatter plot\nplot(\n  x = cotton$Year,\n  y = cotton$`US consumption` / YDIV,\n  axes = FALSE,    # no axes\n  pch = \"\",        # expunge axes/points\n  ylim = LP_YLIM,  # y-axis min/max limits\n  xaxs = \"i\",      # set 'absolute origin'\n  yaxs = \"i\"\n)\n\nNote the use of yaxs and xaxs = \"i\" which ensures that the axis limits are exactly at the minimum and maximum values for the axis (e.g.Â it forces [0,0] to be in the extreme lower-left.)\nNow we can build up the plot axes with manual calls to axis().\nIn short, we supply to axis() the side (1 is the x-axis) and the locations for things like labels and tck (ticks). Iâ€™ve used separate calls for ticks and labels on the primary y-axis (side = 2) because the min and max values (0 and 12) are actually set just above and below the ticks. Iâ€™ve copied the primary y-axis call for a secondary y-axis (side = 4) too.\n\n# Manual x-axis\naxis(\n  side = 1,\n  at = 1942:1948,\n  labels = c(1942, paste0(\"'\", 43:48)),  # i.e. 1942, '43, '44, etc\n  tck = XTICK_LEN,   # tick length\n  col = WHITE,       # i.e. axis isn't visible\n  col.ticks = BLACK  # i.e. axis ticks are visible\n)\n\n# Manual y-axis (just ticks)\naxis(\n  side = 2,\n  at = LP_YTICK_SEQ,  # no ticks needed for origin/max\n  labels = FALSE, \n  tck = YTICK_LEN, \n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# Manual y-axis (just labels)\naxis(\n  side = 2,\n  at = c(0.2, LP_YTICK_SEQ, 11.8),  # min/max labels above/below tick\n  labels = LP_YLAB_SEQ, \n  las = 1,\n  tck = 0,\n  col = WHITE, \n  col.ticks = BLACK\n)\n\n# Manual secondary y-axis (just ticks)\naxis(\n  side = 4,\n  at = LP_YTICK_SEQ,\n  labels = FALSE,\n  tck = YTICK_LEN,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\nI donâ€™t know of a way to make the y-axis label appear horizontally at the top of the axis, so Iâ€™ve used mtext() to place a label in the margin (hence the â€˜mâ€™ in mtext) space above the plot.\n\n# Y-axis label: horizontal at top of axis\nmtext(\"Millions of Boles\", side = 3, cex = CEX - 0.1, adj = -0.07)\n\nThis gives us all the ticks and labels, but weâ€™re missing the axes themselves. Spear used a box around the whole plot; you can do this in R with a call to box().\n\n# Bounding box around plot boundary\nbox()\n\nHereâ€™s what the plot looks like at this point:\n\nNext we need to actually plot some data! We can use mapply() to pass the parameters to a custom function that contains calls to lines() and text(), which lay down the trace and label for each group iteratively.\n\n# Generate lines and labels for each group iteratively\nmapply(\n  function(type, lty, x, y, label) { \n    lines(cotton$Year, cotton[[type]] / YDIV, lty = lty, lwd = LP_WIDTH)\n    text(x, y, label, cex = CEX)\n  },\n  type = c(\"US consumption\", \"Exports\", \"Stocks\"),\n  lty = c(\"solid\", \"longdash\", \"dashed\"),\n  x = c(1946.5, 1943.7, 1946.2), \n  y = c(11, 3.2, 6.8),\n  label = c(\"U. S. Consumption\", \"Exports\", \"Carry â€“ over\\nstocks\")\n)\n\nI would normally do iterative things with the map() family of functions from the {purrr} package by Lionel Henry and Hadley Wickham, so I welcome suggestions on appropriate use of the various base *apply() functions in this scenario.\nFinally we can add the arrows that point to the lines from the labels. Base R has a handy arrows() function to which you supply start and end coordinates and parameters for the arrowhead. I used an advanced-coder technique called â€˜trial-and-errorâ€™ for this.\n\n# Add arrows from labels to lines\narrows(\n  x0 = c(1945.4, 1944.2, 1945.5),  # arrow origin\n  y0 = c(10.8, 3.2, 7.1),\n  x1 = c(1945, 1944.4, 1945.2),    # arrowhead\n  y1 = c(9.6, 3, 6.8),\n  angle = 12,    # 'pointy-ness'\n  length = 0.07  # arrowhead length\n)\n\nExcellent, thatâ€™s the line plot completed. The plot now looks like this:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#bar-plot",
    "href": "posts/2021-06-08-recreate-spear/index.html#bar-plot",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "3. Bar plot",
    "text": "3. Bar plot\nThe barplot() function is a little different to the plot() function.\nIt doesnâ€™t take the data as x and y arguments; we can instead pass it a single object that contains our data with each column corresponding to columns in the plot.\n\n# Convert dataframe structure for passing to barplot()\ncotton_transpose &lt;- t(cotton)[2:4,] / YDIV\ncolnames(cotton_transpose) &lt;- c(\"\", paste0(\"'\", 43:48))\ncotton_transpose\n\n                         '43    '44   '45    '46   '47   '48\nUS consumption 11.160  9.993  9.693 9.423 10.072 9.374 7.833\nExports         1.480  1.139  2.007 3.613  3.545 1.968 4.785\nStocks         10.657 10.744 11.164 7.326  2.530 3.080 5.283\n\n\nNote that Iâ€™ve supplied column names here in the form theyâ€™ll appear on the plot (e.g.Â '43), except for the first column, which Iâ€™ve left blank because the axis label needs to be applied separately for that one case (1942).\nSpearâ€™s cotton barplot uses hatching (i.e.Â parallel lines in one direction) and crosshatching (i.e.Â perpendicular lines laid over each other) to â€˜shadeâ€™ the bars. This approach was used a lot in manual charting because colour wasnâ€™t necessarily available, and it was easy enough to achieve with a set square and rule.\nR lets you control the density and angle of shading in a barplot(), but the angle can only take one value. To create a crosshatch, you need to lay down a separate barplot() layer that is composed only of hatching in one direction. You can then supply a second barplot() call with the hatching in the other direction.\n\n# Barplot layer with hatching only (allows for crosshatching)\nbarplot(\n  cotton_transpose, \n  axes = FALSE,      # suppress axes\n  xaxt = \"n\",        # suppress x-axis bar labels\n  ylim = BP_YLIM,\n  space = BP_SPACE,  # space between bars\n  border = WHITE,    # border around bars\n  col = BLACK,\n  density = rep(c(BP_HATCH_HI, 0, BP_HATCH_LO), 7),  # line 'closeness'\n  angle = 360 - BP_HATCH_ANGLE  # top-left to bottom-right\n)\n\nThis is the bar plot with only the first layer of hatching:\n\nNote that this layer of hatching is only required in the bottom and top bars of the stack because they will end up being crosshatched, specifically. The middle bar will only be hatched, not crosshatched, so itâ€™s blank in this first layer.\nNow we can apply the rest of the bar plot. Since we want to add this barplot() call on top of the previous one, we need to use the argument add = TRUE.\n\n# Barplot layer with features\nbarplot(\n  cotton_transpose, \n  axes = FALSE,\n  ylim = BP_YLIM,\n  space = BP_SPACE,\n  col = BLACK,\n  density = rep(c(BP_HATCH_HI, BP_HATCH_MID, BP_HATCH_LO), 7),\n  angle = BP_HATCH_ANGLE, # bottom-left to upper-right\n  add = TRUE              # add as layer on top of existing plot\n)\n\nAnd now we have both layers of hatching, the bar boundaries and the x-axis bar labels:\n\nYouâ€™ll notice I suppressed the axes again. The approach to building the bespoke bar plot axes is very similar to that of the line plot, using axis(), box() and mtext().\n\n# Manual y-axis (just ticks)\naxis(\n  side = 2,\n  at = BP_YTICK_SEQ,\n  tck = YTICK_LEN,\n  labels = FALSE,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# Manual y-axis (just labels)\naxis(\n  side = 2,\n  at = c(0.4, BP_YTICK_SEQ, 24.6), \n  tck = 0, \n  labels = BP_YLAB_SEQ, \n  las = 1, \n  col = WHITE\n)\n\n# Manual secondary y-axis (just ticks)\naxis(\n  side = 4,\n  at = BP_YTICK_SEQ,\n  labels = FALSE,\n  tck = YTICK_LEN,\n  col = WHITE,\n  col.ticks = BLACK\n)\n\n# X-axis label: horizontal at top of axis\nmtext(\"Millions of Boles\", side = 3, adj = -0.09, cex = CEX - 0.1)\n\n# The first label is at the origin\nmtext(\"1942\", side = 1, line = 0.2, adj = -0.06, cex = CEX)\n\n# Bounding box around plot boundary\nbox()\n\nAwkwardly, the first x-axis label in the bar plot (1942) has to be created manually because itâ€™s placed under the origin point in the original chart, rather than under the bar itself, which is the default.\nFinally we can add the labels over the top of the bars. Iâ€™ve done this in a similar iterative manner as the line plot, where thereâ€™s a call to create a white box with rect(), over which a text() label can be applied.\n\n# Apply labels iteratively\nmapply(\n  function(x, y, xleft, ybottom, xright, ytop, label) { \n    rect(xleft, ybottom, xright, ytop, col = WHITE, border = NA)\n    text(x, y, label, cex = CEX)\n  },\n  xleft   = c(4.4,  4.3,  3.2),\n  ybottom = c(14.4, 10.4, 6.4),\n  xright  = c(6.6,  6.7,  7.8),\n  ytop    = c(15.6, 11.6, 7.6),\n  x = 5.5,\n  y = c(15, 11, 7),\n  label = c(\"STOCKS*\", \"EXPORTS\", \"U. S. CONSUMPTION\")\n)\n\nAnd hereâ€™s our visualisation with both plots completed:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#margin-labels",
    "href": "posts/2021-06-08-recreate-spear/index.html#margin-labels",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "4. Margin labels",
    "text": "4. Margin labels\nWith both charts completed, we can add with mtext() the titles and captions that exist for the plot as a whole.\nThe main title uses a different font family than was specified in par(), so we override it with the family argument.\nI couldnâ€™t find a good (free) approximation of the font family that Spear used, so Iâ€™ve used one that has a similar â€˜feelâ€™, even if many of the typographical features are wrong (e.g.Â single-storey â€˜aâ€™). Here Iâ€™ve settled with â€˜Hussar Bold Condensedâ€™. Let me know if you recognise Spearâ€™s actual font.\n\n# Main title\nmtext(\n  text = \"Distribution   of   United   States   Cotton\",\n  outer = TRUE,  # outer plot margin\n  side = 3,      # i.e. the top\n  line = -3,     # relative to outside to plot limit\n  cex = CEX + 0.5,\n  family = \"Hussar Bold Condensed\",\n  font = 2       # bold type\n)\n\nI left extra spaces between the words in the title text to approximate their placement in Spearâ€™s image.\nThe remaining labels were just a case of fiddling with the line and at arguments to get them in the right place.\n\n# 'Subtitle' for line plot\nmtext(\n  text = \"MULTIPLE CURVE\",\n  outer = TRUE,\n  side = 3,\n  line = -1,\n  adj = 0.06,  # nudge\n  cex = CEX,\n  font = 3  # italic\n)\n\n# 'Subtitle' for bar plot\nmtext(\n  text = \"COMPONENT COLUMN\",\n  outer = TRUE,\n  side = 3,\n  line = -1,\n  adj = 0.68,\n  cex = CEX,\n  font = 3\n)\n\n# Caption: source\nmtext(\n  text = \"Source: U. S. Department of Agriculture\",\n  outer = TRUE,\n  side = 1,  # bottom\n  line = -1,\n  adj = 0.02,\n  cex = CEX\n)\n\n# Caption: stocks asterisk\nmtext(\n  text = \"*END OF SEASON, JULY 31\",\n  outer = TRUE,\n  side = 1,\n  line = -2,\n  adj = 0.94,\n  cex = CEX - 0.2,\n)\n\n# Caption: US cotton\nmtext(\n  text = \"U. S. Supply of U. S. Cotton\",\n  outer = TRUE,\n  side = 1,\n  line = -1,\n  adj = 0.97,\n  cex = CEX\n)\n\nAnd so the final output looks like this:\n\nAnd a gif of the steps of the chartâ€™s creation, ending with the original image:"
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#saving",
    "href": "posts/2021-06-08-recreate-spear/index.html#saving",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "5. Saving",
    "text": "5. Saving\nHaving opened a graphics device earlier with png() and then added out plotting elements, we can now close the graphics device and save the output.\n\ndev.off()\n\nYouâ€™ll want to run all the code from start to finish to encompass the png() call at the start and the dev.off() call at the end. Iâ€™ve put all the code in a GitHub repo should you want to use it."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#reflections",
    "href": "posts/2021-06-08-recreate-spear/index.html#reflections",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "Reflections",
    "text": "Reflections\nThe final output certainly isnâ€™t a perfect match for the original, but I think it gets 90% of the way there without the need for endless tweaking. There were some particularly tricky things I was able to deal with, but also some things that I need to improve to make the recreation identical to the original.\n\nTricky parts\nThere were a few non-standard plot elements that needed to be dealt with, but are relatively trivial with base R functions. To review:\n\nthe minimum and maximum labels on the y axis are not on the ticks, theyâ€™re slightly above and below them, respectively\nhatching can only be done in one direction, so it requires an â€˜under-layerâ€™ of hatching in the opposite direction to that of the main plot itself\nthereâ€™s no function in base to apply a text label with a filled box under it; you need to use text() and rect() together\nthe x-axis labels arenâ€™t all the same: the first is 1942 and the rest are in the form '43\nthe first x-axis label on the bar chart, 1942 is not actually under the bar, but under the origin\n\n\n\nImprovements\nThereâ€™s a lot of things I could do, but there would be a few things to prioritise:\n\nIâ€™ve used a lot of manual adjustments to get the chart elements in roughly the right place; thatâ€™s fine for a one-off chart like this, but isnâ€™t that useful for making this code more generic\nI didnâ€™t get the ruler out and measure everything, so there are slight differences when the original and recreation are overlaid\nI havenâ€™t really optimised the code or tried to tidy it up; there may be some unnecessary lines that were part of development that donâ€™t need to be in the final script\nIâ€™ve tried to match the font families as best I can, but the font used in the main title is particularly difficult to find a (free) match for\nRâ€™s built-in line dashes arenâ€™t quite the same as Spearâ€™s, but I think theyâ€™re close enough\n\nAnd finally a bonus improvement, though it requires you to download a package. We can save our plot with maximum resolution, etc, but for fun we can invoke some of the artefacts that are present in Spearâ€™s plot with some help from the {magick} image-processing package via Jeroen Ooms and rOpenSci (e.g.Â see below for how to add blur).\n\nlibrary(magick)  # install from CRAN\n\n# Read the plot PNG\ncottonviz &lt;- image_read(\"~/Desktop/cottonviz.png\")  # set to your path\n\n# Apply blurring parameters\ncottonviz_blur &lt;- image_blur(\n  cottonviz,\n  radius = 14, sigma = 7  # blur parameters\n)\n\n# Save the image\nimage_write(\n  cottonviz_blur,\n  \"~/Desktop/cottonviz_blur.png\"  # set to your path\n)\n\nThat would end up looking like this:\n\nWith a bit more tweaking and addition of some noise, you could probably do a good job of mimicking the â€˜agedâ€™ look of the original."
  },
  {
    "objectID": "posts/2021-06-08-recreate-spear/index.html#environment",
    "href": "posts/2021-06-08-recreate-spear/index.html#environment",
    "title": "Recreating Spearâ€™s #CottonViz in base R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:36:08 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.7.4\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.11       yaml_2.3.7        rlang_1.1.1      \n[17] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-06-28-isocubes-dungeon/index.html#tldr",
    "href": "posts/2022-06-28-isocubes-dungeon/index.html#tldr",
    "title": "An isometric dungeon chase in R",
    "section": "tl;dr",
    "text": "tl;dr\nI made an interactive isometric-dungeon demo in R, thanks to {r.oguelike} for dungeon building and mikefcâ€™s {isocubes} for drawing isometric cube graphics and {eventloop} for continuous keypress inputs."
  },
  {
    "objectID": "posts/2022-06-28-isocubes-dungeon/index.html#a-new-dimension",
    "href": "posts/2022-06-28-isocubes-dungeon/index.html#a-new-dimension",
    "title": "An isometric dungeon chase in R",
    "section": "A new dimension",
    "text": "A new dimension\nMike (AKA mikefc, AKA coolbutuseless) is well known for off-label R creations that desecrate the assumption that â€˜R is a language for statistical computingâ€™.\nMike revealed the {isocubes} package recently, which lets you print objects made of isometric cubes to a graphics device. I immediately thought of the toy {r.oguelike} package Iâ€™ve been developing recently, which has the goal of creating (really) basic features of a roguelike game in R.1 The dungeons are currently ASCII tiles printed to the console. How would it look in isometric?\nIn a frenzied series of tweets, I built up a little toy that creates a procedural isometric dungeon and adds a user-controlled player character and a pathfinding enemy. The steps were to:\n\nBuild an isometric dungeon (tweet)\nAdd a player (tweet)\nAccept continuous input (tweet)\nAdd a pathfinding enemy (tweet)\n\nThis post talks through those steps. You can find the code for the final product in a GitHub Gist. It is absolutely not polished and really is just a Frankensteinâ€™s monster of code that I stapled together.\n\n1. Build an isometric dungeon\n{r.oguelike} creates procedural dungeons in the form of a matrix where # symbols are non-traversable wall tiles and . indicates traversable floor tiles. I wrote about the inception of the package in a recent blog post.\nWe can swap the characters for height values, where the floor is 1 and the walls are 2, and {isocubes} will project the walls one cube above the plane of the floor. We can also use this information to provide colours; black for the floor and brown for the walls, for example, so it looks like a cavern.\nHereâ€™s a few examples:\n\nI think that looks pretty good (ignore the graphical artefacts from the gif compression). I didnâ€™t time how long it took for each image to be rendered because it was near-instantaneous.\nBut we donâ€™t want to just look at pictures of dungeons, we want to explore them.\n\n\n2. Add a player\n{r.oguelike} lets a user move a character around the the floor tiles. The player is represented by @ in the dungeon matrix, which we can again substitute with a height value of 1 so itâ€™s one cube higher than the floor. Of course, we should colour it to distinguish it from the walls; I chose blue.\nThe userâ€™s keyboard input is accepted by readline() and this determines the characterâ€™s movement. Typing W then Enter will make the player move north one tile, for example. In {r.oguelike}, a keypress input causes the current location to be overwritten with a floor tile (.); the tile above to be replaced with the player symbol (@); and then the updated matrix is re-printed to the console.\nAgain, this all takes place inside the matrix that represents the dungeon, so we can also just lift this functionality into the {isocubes} version. Here you can see a series of user inputs to the console that result in the player moving around the floor tiles.\n\nIt was really pleasing when I got this to work, but itâ€™s also quite tedious to tap in a key and hit enter for each movement.\n\n\n3. Accept continuous input\n{r.oguelike} simply prints the dungeon matrix to the console at the end of each turn, whereas our {isocubes} version takes place in a graphics window thatâ€™s refreshed with every turn.\nMike also has a package called {eventloop},2 which he suggested might be useful for continuous input from the user. The package contains:\n\na framework for rendering interactive graphics and handling mouse+keyboard events from the user at speeds fast enough to be considered interesting for games and other realtime applications\n\nBear in mind that it doesnâ€™t work on Windows. Read more about it in Mikeâ€™s blog.\nHere you can see the result of incorporating {eventloop}. The user is pressing the arrow keysâ€”which you can see being printed to the consoleâ€”to move the player. This is way more seamless than the previous readline() method.\n\nThis is a nice demo, but it would be great to make this more of a â€˜gameâ€™.\n\n\n4. Add a pathfinding enemy\n{r.oguelike} has an enemy character, represented in the dungeon matrix as E. Again, we can replace this with a height of 1 and colour it yellow, for example.\nI wrote recently about implementing simple breadth-first pathfinding so that the enemy can head toward wherever the player currently is. At time of writing I havenâ€™t fully implemented the pathfinding into {r.oguelike}, but that didnâ€™t stop me adding it into the code for this isometric demo.\nHere you can see the enemy cube (yellow) hunting down the player-controlled cube (blue). I was motivated to add a capture condition and decided to have fun with it.\n\nI hope you enjoyed the victory dance at the end of the gif (it was the best I could do with the limited graphics).3\n\n Note\nAfter this post was published, the {oblicubes} package was published by Trevor L Davies. It allows you to use oblique projections. So obviously I had a go with {r.oguelike}.\n\n\n\nClick for the required code changes.\n\nIn the code I wrote, you pretty much replace:\n\ncoords &lt;- isocubes::coords_heightmap(dungeon_h, col = dungeon_c)\n\ncubes  &lt;- isocubes::isocubesGrob(\n  coords,\n  max_y = ncol(dungeon_h) + 0.1 * ncol(dungeon_h),\n  fill = coords$col,\n  xo = 0.7\n)\n\ngrid::grid.newpage()  # 'clear'\ngrid::grid.draw(cubes)  # render\n\nWith:\n\ncoords &lt;- oblicubes::xyz_heightmap(\n  dungeon_h,\n  col = dungeon_c,\n  scale = 0.3,\n  ground = \"xy\"\n)\n\ngrid::grid.newpage()  # 'clear'\noblicubes::grid.oblicubes(coords)  # render"
  },
  {
    "objectID": "posts/2022-06-28-isocubes-dungeon/index.html#the-fourth-dimension",
    "href": "posts/2022-06-28-isocubes-dungeon/index.html#the-fourth-dimension",
    "title": "An isometric dungeon chase in R",
    "section": "The fourth dimension",
    "text": "The fourth dimension\nI need to tie up some loose ends in the current version of {r.oguelike}, but Iâ€™m considering the possibilities for {isocubes} and {eventloop} in future. Maybe the start_game() function could have an argument where the user can choose 2D or 3D (isometric or oblique) representations of the game.\nI also have a few ideas of how I can use my basic {r.oguelike} â€˜engineâ€™ with {isocubes} to develop some other, non-roguelike games. For example, Dmytro (AKA Deemah) suggested {rsokoban}. Sokoban is a game where you solve small tile-based puzzles by pushing crates onto designated spots. I was also reminded of Q*bert, where you try and touch all the floor tiles to change their colour.\nSo many ideas for off-label R use, so little time."
  },
  {
    "objectID": "posts/2022-06-28-isocubes-dungeon/index.html#postscript",
    "href": "posts/2022-06-28-isocubes-dungeon/index.html#postscript",
    "title": "An isometric dungeon chase in R",
    "section": "Postscript",
    "text": "Postscript\nI lied a bit earlier. The actual first thought I had when seeing {isocubes} was pixel art. I wrote a post (exactly) one year ago where I converted some vectors into little pixel drawings using Râ€™s image() function.\nItâ€™s fairly straightforward to convert those vectors into a format accepted by {isocubes}, which means you can have an isometric sprite of Link from The Legend of Zelda, or a rainbow version of the insect logo for this blog.\n\nI wrote a GitHub Gist with the code for these images, so feel free to steal. Let me know what you end up making."
  },
  {
    "objectID": "posts/2022-06-28-isocubes-dungeon/index.html#environment",
    "href": "posts/2022-06-28-isocubes-dungeon/index.html#environment",
    "title": "An isometric dungeon chase in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:13:13 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#tldr",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#tldr",
    "title": "The most popular Animal Crossing villagers",
    "section": "tl;dr",
    "text": "tl;dr\nI once wrote an R Shiny app to run a popularity contest for Animal Crossing villagers. Surprise: cute ones are favourites."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#swiping-shinyswipe-code",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#swiping-shinyswipe-code",
    "title": "The most popular Animal Crossing villagers",
    "section": "Swiping {shinyswipe} code",
    "text": "Swiping {shinyswipe} code\nA while back I wrote a Shiny app (site, source, blogpost) for TidyTuesday to replicate a Tinder-like experience using villagers from Nintendoâ€™s Animal Crossing New Horizons game. It uses the swipe mechanic from Nick Strayerâ€™s {shinysense} package to gauge popularity: left for a â€˜dislikeâ€™, right for a â€˜likeâ€™.\nAfter exceeding 3000 total swipes, itâ€™s time to take a look at the results.\n\n Note\nI re-rendered this post in July 2023 when there were about 6000 swipes(!)."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#oh-sheet",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#oh-sheet",
    "title": "The most popular Animal Crossing villagers",
    "section": "Oh sheet",
    "text": "Oh sheet\nData from each swipe in the app is automatically appended to a public Google Sheets sheet that can be read with {googlesheets4}. Public sheets donâ€™t require authentication to download, so run gs4_deauth() before read_sheet() to prevent it.\n\nlibrary(googlesheets4)\ngs4_deauth()\n\nraw &lt;- read_sheet(\n  ss = \"1kMbmav6XvYqnTO202deyZQh37JeWtTK4ThIXdxGmEbs\",\n  col_types = \"Tcc\"  # datetime, char, char\n)\n\nâœ” Reading from \"acnh-swipe_results\".\n\n\nâœ” Range 'Sheet1'.\n\n\nFirst thing is to isolate the left and right swipes only. The {shinysense} package also allows for up and down swipes by default and I wasnâ€™t sure how to remove this capability from my app (and was too lazy to work it out).\n\ndat &lt;- raw[raw$swipe %in% c(\"left\", \"right\"), ]\ndat[sample(rownames(dat), 5), ]  # random sample\n\n# A tibble: 5 Ã— 3\n  date                name     swipe\n  &lt;dttm&gt;              &lt;chr&gt;    &lt;chr&gt;\n1 2021-12-01 01:09:52 Wart Jr. left \n2 2022-12-03 00:41:01 Dora     left \n3 2022-01-09 22:38:01 Pango    left \n4 2021-05-14 22:58:52 Bertha   right\n5 2022-12-03 00:41:42 Rosie    left \n\n\nThe data are one row per swipe, with columns for date (datetime of when the swipe happened), name (the villagerâ€™s name) and swipe (the swipe direction).\nBut what weâ€™re really after is a grouped table with a row per villager, plus new columns for the total number of swipes, the difference between right and left swipes and the percentage of swipes that were to the right (pc_right). These will let us better rank the characters.\n\ndf &lt;- with(dat, table(name, swipe)) |&gt;  # like dplyr::count()\n  as.data.frame(responseName = \"n\") |&gt;\n  reshape(  # like tidyr::pivot_*()\n    v.names   = \"n\",      # values_from\n    idvar     = \"name\",   # id_cols\n    timevar   = \"swipe\",  # names_from\n    direction = \"wide\",   # i.e. pivot_wider()\n    sep       = \"_\"       # names_sep\n  ) |&gt; \n  transform(  # like dplyr::mutate()\n    total    = n_left + n_right,\n    diff     = n_right - n_left,\n    pc_right = 100 * round(n_right / (n_right + n_left), 2)\n  )\n\nhead(df)\n\n     name n_left n_right total diff pc_right\n1 Admiral     14       4    18  -10       22\n2 Agent S     10       4    14   -6       29\n3   Agnes     14       8    22   -6       36\n4      Al     13       3    16  -10       19\n5 Alfonso      6       7    13    1       54\n6   Alice      8       8    16    0       50\n\n\n\n\nClick to expand code explanation\n\nI think most readers of this blog are probably {tidyverse} users, so Iâ€™ll explain some of the base R approach I took here:\n\nIâ€™ve used the base pipe (|&gt;) introduced in R v4.1 to chain the functions, which is analogous to {magrittr}â€™s pipe (%&gt;%) in this example\nwith() allows the bare column names in table() to be evaluated as columns of dat, which means you only write the name of the data object once\na table() coerced with as.data.frame() is equivalent to dplyr::count(), basically\nreshape() can be used like tidyr::pivot_wider() (Iâ€™ve added comments in the code block above to show how the arguments are used)\nturns out that transform() can be used like dplyr::mutate() to create new columns, thought the help files say it should only be used for interactive and that â€˜you deserve whatever you get!â€™\n\n\nWe can also bring in some additional villager data collected for TidyTuesday and join it to the swipe data. This will come in useful later.\n\ntt &lt;- read.csv(\n  paste0(\n    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/\",\n    \"2e9bd5a67e09b14d01f616b00f7f7e0931515d24/data/\",\n    \"2020/2020-05-05/villagers.csv\"\n  )\n)\n\ndf &lt;- merge(df, tt, by = \"name\")"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#new-horizons-scanning",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#new-horizons-scanning",
    "title": "The most popular Animal Crossing villagers",
    "section": "New Horizons scanning",
    "text": "New Horizons scanning\nThere are 391 villagers represented in these data, with a combined total of 5950 legitimate swipes.\nThe total swipes per villager ranged from 7 to 29, with a mean of 15.2Â±3.9, so some characters didnâ€™t really get enough swipes for proper assessment. Youâ€™d better go to the app and add some more swipes, eh?\n\npar(bg = \"lightgreen\")\nhist(\n  df$total,\n  main = \"Distribution of total swipes per villager\",\n  xlab = \"Total swipes\",\n  col = \"lightblue\",\n  las = 1\n)\n\n\n\n\nWhat if we look now at right swipes (i.e.Â â€˜likesâ€™), adjusted for the total swipes per character?\n\npar(bg = \"lightgreen\")\nhist(\n  df$pc_right,\n  main = \"Distribution of right swipes per villager\",\n  xlab = \"Right swipes (%)\",\n  col = \"lightblue\",\n  las = 1\n)\n\n\n\n\nYou can see that the distribution isnâ€™t quite normal. The frequency of swipes below 50% is 297 and above 50% is 83. This implies that the majority of characters were disliked in a binary sense.\nThe bins at 0 and 100% tell you that there were some characters that were met with universal disapproval and approval, while the bin at 50% tells us that same characters split peopleâ€™s opinions. Which were they?"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#drumroll-please",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#drumroll-please",
    "title": "The most popular Animal Crossing villagers",
    "section": "Drumroll, please",
    "text": "Drumroll, please\nSo, onto the villager rankings.\nIâ€™ve written a little function to output an HTML table where each characterâ€™s name links to their profile on the Animal Crossing Wiki and exposes their photo from VillagerDB.\n\nentable &lt;- function(df) {\n  df$url &lt;- paste0(\n    \"&lt;img src='\", df$url, \"' \",\n    \"width=50 \",\n    \"alt='Animal Crossing villager \", df$name,\"'&gt;\"\n  )\n  df$name &lt;- paste0(\n    \"&lt;a href='https://animalcrossing.fandom.com/wiki/\",\n    df$name, \"'&gt;\", df$name, \"&lt;/a&gt;\"\n  )\n  df &lt;- df[, c(\"name\", \"url\", \"pc_right\", \"total\")]\n  names(df) &lt;- c(\"Name\", \"Picture\", \"Right swipes (%)\", \"Total swipes\")\n  rownames(df) &lt;- NULL\n  knitr::kable(df)\n}\n\n\nLeast popular\nTo build tension, weâ€™ll start with the least-liked villagers.\n\nbot &lt;- df[order(df$pc_right, -df$n_left), ] |&gt; head()\nentable(bot)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nPinky\n\n0\n23\n\n\nCashmere\n\n0\n17\n\n\nLeonardo\n\n0\n16\n\n\nWalt\n\n0\n16\n\n\nHarry\n\n0\n14\n\n\nBenedict\n\n0\n13\n\n\n\n\n\nSorry Pinky. You are simplyâ€¦ too pink? Seems harsh.\n\n\nMost polarising\nTo build even more tension, letâ€™s look at the characters who had a 50:50 ratio of likes to dislikes.\n\nmeh &lt;- subset(df[order(-df$total), ], diff == 0) |&gt; head()\nentable(meh)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nAlice\n\n50\n16\n\n\nHopkins\n\n50\n16\n\n\nHornsby\n\n50\n16\n\n\nMelba\n\n50\n16\n\n\nCherry\n\n50\n14\n\n\nGoose\n\n50\n14\n\n\n\n\n\nIâ€™m not sure why these villagers are so controversial Perhaps theyâ€™re too â€˜plainâ€™ for some people?\n\n\nMost popular\nAnd finally, what youâ€™ve all been waiting for.\n\ntop &lt;- df[order(-df$pc_right, -df$n_right), ] |&gt; head()\nentable(top)\n\n\n\n\n\n\n\n\n\n\nName\nPicture\nRight swipes (%)\nTotal swipes\n\n\n\n\nKiki\n\n89\n9\n\n\nFrobert\n\n85\n20\n\n\nBea\n\n85\n13\n\n\nZell\n\n83\n23\n\n\nJulia\n\n82\n17\n\n\nFauna\n\n80\n15\n\n\n\n\n\nSo: Kiki, the grandad-jumper-wearing black-void cat, has the best ratio of right to left-swipes! The rest of the list are pretty conventionally cute (though Zell looks pretty aloof)."
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#speciesism",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#speciesism",
    "title": "The most popular Animal Crossing villagers",
    "section": "Speciesism!",
    "text": "Speciesism!\nI know what youâ€™re thinking: the results are on a villager-by-villager basis, but which species are the most popular? We can aggregate swipes and take a look.\n\nsp_l &lt;- aggregate(n_left ~ species, sum, data = df)\nsp_r &lt;- aggregate(n_right ~ species, sum, data = df)\nsp_n &lt;- with(df, table(species)) |&gt; \n  as.data.frame(responseName = \"n_villagers\")\n\nsp &lt;- sp_n |&gt; \n  merge(sp_l, by = \"species\") |&gt; \n  merge(sp_r, by = \"species\") |&gt; \n  transform(\n    total = n_right + n_left,\n    pc_right = 100 * round(n_right / (n_right + n_left), 2)\n  )\n\n\n\nClick to expand code explanation\n\nA couple more base functions here for those not used to them:\n\naggregate() is like dplyr::group_by() followed by dplyr::summarise() and it allows for compact â€˜formula syntaxâ€™, so we can say â€˜aggregate y by xâ€™ with y ~ x\nmerge() is just like the dplyr::*_join() family\n\n\nSo, firstly, the species ranked by lowest proportion of right swipes.\n\nsp_bot &lt;- sp[order(sp$pc_right, -sp$n_left), ]\nrownames(sp_bot) &lt;- NULL\nhead(sp_bot)\n\n   species n_villagers n_left n_right total pc_right\n1    mouse          15    172      24   196       12\n2    hippo           7     86      19   105       18\n3   monkey           8    110      26   136       19\n4 kangaroo           8    114      29   143       20\n5      pig          15    178      46   224       21\n6     bear          15    172      47   219       21\n\n\nI can see how monkeys and hippos might not be that â€˜cuteâ€™, per se, but what about the mice? Although â€˜cuteâ€™ is probably not the best term for the cranky mouse Limberg (sorry Limberg).\nWhat about the most liked species?\n\nsp_top &lt;- sp[order(-sp$pc_right, sp$n_right), ]\nrownames(sp_top) &lt;- NULL\nhead(sp_top)\n\n  species n_villagers n_left n_right total pc_right\n1    deer          10     85      96   181       53\n2     dog          16    104     115   219       53\n3 octopus           3     22      24    46       52\n4     cat          23    190     191   381       50\n5 ostrich          10     79      72   151       48\n6     cub          16    133     104   237       44\n\n\nDeer (all-around solid designs) and dogs (generally friend-shaped) top the table.\nOctopuses are up there too, although thereâ€™s relatively few octopus villagers. Personally, I like Zucker, an octopus who looks like takoyaki and therefore delicious.\nThis wasnâ€™t meant to be about villager tastiness, was it? We may need a new app to rank by apparent edibilityâ€¦"
  },
  {
    "objectID": "posts/2022-01-07-acnh-swipe-results/index.html#environment",
    "href": "posts/2022-01-07-acnh-swipe-results/index.html#environment",
    "title": "The most popular Animal Crossing villagers",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:18:03 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] googlesheets4_1.1.1\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       httr_1.4.6        cli_3.6.1         knitr_1.43.1     \n [5] rlang_1.1.1       xfun_0.39         purrr_1.0.1       generics_0.1.3   \n [9] jsonlite_1.8.7    glue_1.6.2        gargle_1.5.1      htmltools_0.5.5  \n[13] fansi_1.0.4       rmarkdown_2.23    cellranger_1.1.0  evaluate_0.21    \n[17] tibble_3.2.1      fontawesome_0.5.1 fastmap_1.1.1     yaml_2.3.7       \n[21] lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2       fs_1.6.2         \n[25] pkgconfig_2.0.3   htmlwidgets_1.6.2 rstudioapi_0.15.0 digest_0.6.31    \n[29] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        curl_5.0.1       \n[33] pillar_1.9.0      magrittr_2.0.3    tools_4.3.1       googledrive_2.1.1"
  },
  {
    "objectID": "posts/2020-09-12-units-of-uncleaned-herring/index.html",
    "href": "posts/2020-09-12-units-of-uncleaned-herring/index.html",
    "title": "{units} of uncleaned herring",
    "section": "",
    "text": "The hex sticker is better than the package."
  },
  {
    "objectID": "posts/2020-09-12-units-of-uncleaned-herring/index.html#tldr",
    "href": "posts/2020-09-12-units-of-uncleaned-herring/index.html#tldr",
    "title": "{units} of uncleaned herring",
    "section": "tl;dr",
    "text": "tl;dr\nI made the tiny R package {cran} to convert volumes to an antiquated measurement of fish. Why? To test out the {units} package and to resolve a joke about the Comprehensive R Archive Network (CRAN)."
  },
  {
    "objectID": "posts/2020-09-12-units-of-uncleaned-herring/index.html#units",
    "href": "posts/2020-09-12-units-of-uncleaned-herring/index.html#units",
    "title": "{units} of uncleaned herring",
    "section": "{units}",
    "text": "{units}\nThe {units} package by Edzer Pebesma, Thomas Mailund and James Hiebert (site, source, R Journal) helps you set and create units, convert between them and raise an error where that isnâ€™t possible.\nIâ€™ve used the package to solve a trivial unit conversion question and to create my own units. This post shows how.\n\nA 12 gallon hat?\nHereâ€™s a really simple example of the {units} package in action.\nA colleague bought a 1 gallon water bottle, only to realise later that it was US gallons rather than UK gallons (viva litres!). Whatâ€™s the relationship between the two gallon units?\nFirst install and attach the {units} package, which is available on CRAN. It will print the location where the units dataset is stored. These units are derived from the comprehensive UNIDATA udunits database, which has all the relevant SI units and some that are a little moreâ€¦ nonstandard.\n\n# install.packages(\"units\")  # install if you haven't already\nlibrary(units)\n\nudunits database from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/units/share/udunits/udunits2.xml\n\n\nIâ€™ll also load a few other packages for the purposes of this post.\n\nsuppressPackageStartupMessages({\n  library(dplyr)\n  library(stringr)\n  library(purrr)\n})\n\nYou can inspect the valid_units() dataframe to find out what units you can work with. Hereâ€™s five random units from the dataframe:\n\nvalid_udunits() %&gt;% \n  filter(symbol != \"\" & name_singular != \"\") %&gt;% \n  sample_n(5) %&gt;% \n  select(symbol, name_singular, definition)\n\n# A tibble: 5 Ã— 3\n  symbol name_singular            definition                                    \n  &lt;chr&gt;  &lt;chr&gt;                    &lt;chr&gt;                                         \n1 sr     steradian                standard unit of solid angle measure, it is tâ€¦\n2 bbl    barrel                   unit of volume used by US and Canadian petrolâ€¦\n3 u      unified_atomic_mass_unit standard unit for indicating mass on an atomiâ€¦\n4 Hz     hertz                    unit of frequency meaning one cycle per second\n5 cd     candela                  The candela is the luminous intensity, in a gâ€¦\n\n\nWe can filter the name_singular column to find the available gallon units.\n\ndplyr::filter(\n  valid_udunits(),\n  str_detect(name_singular, \"gallon\")\n) %&gt;% \n  select(name_singular)\n\n# A tibble: 4 Ã— 1\n  name_singular         \n  &lt;chr&gt;                 \n1 Canadian_liquid_gallon\n2 US_dry_gallon         \n3 US_liquid_gallon      \n4 UK_liquid_gallon      \n\n\nWeâ€™re interested in UK_liquid_gallon and US_liquid_gallon, but wow, thereâ€™s two more, including a â€˜dryâ€™ one.\nWe can supply a unit to a value with as_units(), so we can create 1 UK gallon with the following:\n\nuk_gal &lt;- as_units(1, \"UK_liquid_gallon\")\n\nThat gives us an object with class units and the print method adds the unit in square brackets:\n\nclass(uk_gal)\n\n[1] \"units\"\n\nuk_gal\n\n1 [UK_liquid_gallon]\n\n\nWe can also do maths with these objects:\n\nuk_gal + uk_gal\n\n2 [UK_liquid_gallon]\n\n\nAnd to convert it, we can take set the units of our unit-class object and specify a different unit. The units need to be compatible though, so you canâ€™t convert a gallon to a parsec, for example.\n\n# Using purrr::safely() to capture the error\nsafe_set_units &lt;- safely(set_units)\nsafe_set_units(uk_gal, \"parsec\")$error\n\n&lt;simpleError: cannot convert UK_liquid_gallon into parsec&gt;\n\n\nThis prevents you from combining non-compatible units, which is a real danger if your data is stored as bare numeric values with no unit information.\nAnd now weâ€™ll set the new units for the gallon-to-gallon conversion.\n\nus_gal &lt;- set_units(uk_gal, \"US_liquid_gallon\")\nus_gal\n\n1.20095 [US_liquid_gallon]\n\n\nSo a UK liquid gallon is about 20% larger than a US one. But I thought everything was meant to be larger in the US!"
  },
  {
    "objectID": "posts/2020-09-12-units-of-uncleaned-herring/index.html#herring-aid",
    "href": "posts/2020-09-12-units-of-uncleaned-herring/index.html#herring-aid",
    "title": "{units} of uncleaned herring",
    "section": "Herring aid",
    "text": "Herring aid\nWho doesnâ€™t like getting lost in the Wikipedia rabbithole? I came upon the page for â€˜cranâ€™ and found it amusing that the Comprehensive R Archive Network (CRAN) package database had a rival.\nWhatâ€™s a cran, then? Well, an antiquated legal unit for measuring the volume of landed, uncleaned herring in the North Sea fishing industry. Also used as the name for a basket that could carry that volume.1\nIt sounds like the initial 18th-century measurement was volumetric and inexact, equalling something like 1200 fish. Later this was made official in terms of â€˜wine gallonsâ€™, with Wikipedia pegging it to 170.5 litres in more modern units. For confirmation, simply read the Second Report of the Commissioners Appointed by His Majesty to Consider the Subject of Weights and Measures, 1820:\n\nNaturally, I checked valid_udunits()â€¦ and cran isnâ€™t in there. So obviously I needed to make it.\nYou can basically do this in three steps with {units}: define a new unit based on known units; create a unit object; convert it to the newly-defined unit.\nSo, you can â€˜installâ€™ a new unit with reference to another unit by multiplying or offsetting by some constant. In our case, our new unit is equal to 170.5 litres.\n\ninstall_unit(\"cran\", \"170.5 L\")\n\nNow we can work with the cran unit. Letâ€™s first create a unit-class object to convert. For example, we can confirm that 170.5 litres is equal to one cran.\n\none_litre &lt;- as_units(170.5, \"L\")\none_litre\n\n170.5 [L]\n\n\nWe can supply this to the set_units() function and specify we want it converted to cran.\n\nset_units(one_litre, \"cran\")\n\n1 [cran]\n\n\n\nCRANâ€¦ no, {cran}\nSo I created a package called {cran} that contains this conversion. You can install it from GitHub using the {remotes} package. Except, you know, donâ€™t, because you have no need for it unless youâ€™re an 18th century fisherman.\n\nremotes::install_github(\"matt-dray/cran\")\n\nAnd then when you load the package it asks if you want to create the cran unit. Answering â€˜yesâ€™ results in the cran unit being available in your session.\n\nlibrary(cran)\n\nCreate the 'cran' unit of measurement for this session? yes/no: yes\nYou're ready to measure uncleaned herring.\nNow you can use cran for setting and converting units. So we can revisit our check that 170.5 litres equals 1 cran:\n\ncran::cran_convert(170.5, \"L\")\n\n1 [cran]\n\n\nâ€¦And thatâ€™s it, basically. You can remove and reinstall the unit at any point with cran_remove() and cran_install().\n\ncran::cran_remove()\n\nRemove the 'cran' unit of measurement for this session? yes/no: yes\nYou're done measuring uncleaned herring."
  },
  {
    "objectID": "posts/2020-09-12-units-of-uncleaned-herring/index.html#environment",
    "href": "posts/2020-09-12-units-of-uncleaned-herring/index.html#environment",
    "title": "{units} of uncleaned herring",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 08:43:07 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1   stringr_1.5.0 dplyr_1.1.2   units_0.8-2  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         stringi_1.7.12    generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     tibble_3.2.1      fastmap_1.1.1     yaml_2.3.7       \n[17] lifecycle_1.0.3   compiler_4.3.1    htmlwidgets_1.6.2 Rcpp_1.0.11      \n[21] pkgconfig_2.0.3   cran_0.0.0.9001   rstudioapi_0.15.0 digest_0.6.33    \n[25] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0     \n[29] magrittr_2.0.3    withr_2.5.0       tools_4.3.1       xml2_1.3.5"
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html",
    "href": "posts/2022-05-01-dungeon/index.html",
    "title": "Simple procedural dungeons in R",
    "section": "",
    "text": "Three iterations to expand four randomly-placed floor tiles into a cavern."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#tldr",
    "href": "posts/2022-05-01-dungeon/index.html#tldr",
    "title": "Simple procedural dungeons in R",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a (very!) basic procedure to generate randomised ASCII-character tile-based dungeons for {r.oguelike}, an in-development roguelike-game-in-a-package for R."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#generate-to-accumulate",
    "href": "posts/2022-05-01-dungeon/index.html#generate-to-accumulate",
    "title": "Simple procedural dungeons in R",
    "section": "Generate to accumulate",
    "text": "Generate to accumulate\nI wrote recently about the {r.oguelike} R package, which contains the beginnings of a roguelike game written entirely in R.\n\nA key element of roguelike games is that the dungeons should be procedurally generated1 so that the player gets a different one each time they play.\nThere are many algorithmic systems for dungeon creation, like wave function collapse, perlin noise, binary space partitioning, cellular automata, etc.2 See the talk by Herbert Wolverson at Roguelike Celebration, for example.\nI plan to take a look at these approaches in future, but I wanted to start with something a bit moreâ€¦ naÃ¯ve. I just want a simple interconnected space that spawns with randomised rooms, corridors and galleries."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#excavations",
    "href": "posts/2022-05-01-dungeon/index.html#excavations",
    "title": "Simple procedural dungeons in R",
    "section": "Excavations",
    "text": "Excavations\n\n Note\nThe {r.oguelike} package is a work in progress and is developing at pace. Many things explained below may have been superseded or changed by the time you read this.\n\n\nInstall/launch\nYou can install the (currently work-in-progress) {r.oguelike} package from GitHub, via {remotes}.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r.oguelike\")\n\nYou can also launch RStudio in the browser with {r.oguelike} preinstalled, thanks to Binder3 (may take a couple of minutes to load):\n\n\n\n\n\n\n\nPrepare\nBefore we begin, note that we can talk about generative â€˜dungeonsâ€™ in the context of connected rooms, like in The Binding of Isaac, or more freeform structures, like world maps in Dwarf Fortress. Weâ€™re going for the latter, which amounts to interconnected caverns.\nThe function weâ€™ll be using is called generate_dungeon(), which prints to the console a cavern that differs each time you run it.4 You can alter the output using the arguments:\n\niterations is the number of times to â€˜growâ€™ the caverns\nn_row and n_col give the map dimensions\nn_rooms is the number of rooms to spawn\nis_snake for a cavern that is continuous from left to right and wiggly\nis_organic for a more freeform vs â€˜squareâ€™ look to the caverns\ncolour to print the output in colour\n\nYou can always run set.seed() before generate_dungeon() to create the same dungeon every time you run the function with the same parameters.\n\n\nDemo\nSo hereâ€™s a smallish dungeon with 3 growth iterations for 4 starting rooms, on a map with tile dimensions of 20 rows by 30 columns.\n\ndungeon &lt;- r.oguelike::generate_dungeon(3, 20, 30, 4)\n\nHereâ€™s a screenshot of the output so you can see it in colour.\n\n\n\nClick for the actual console output.\n\n| - - - - - - - - - - - - - - - - - - - - - - - - - - - - | \n| # # # # # # . # # # # # # # # # # # # # # # # # # # # # | \n| # # . # . . . . # # # # # . # # # # # # # # # # # # # # | \n| # . . . . # . . # # # . . . . # # # # # # # # # # # # # | \n| # . . . . . . . . . . . . . . . # # # # # # # # # # # # | \n| . . . # . . # . . # # . . . . . # # # # # # # # # # # # | \n| . . . . # # # . # # # # # . . # # # # # # # # # # # # # | \n| . . # # # # # # # # # # # . # # # # # # # # # # # # # # | \n| . . . . # # # # # # # # . . . # # # # # # # # # # # # # | \n| . . . . # # # # # # # # # . . # # # # # # # # # # # # # | \n| . . . # # # # # # # . # . . . # # # # # # # # # # # # # | \n| . . . # # # # # # . . . . . . . # # # # # # # # # # # # | \n| . . . # # . . # . . # . . . . . . . . . # . . . # # # # | \n| . . . . . . . . . . . . . . . . . . . . . . . . # # # # | \n| . . # # . . . # . # . . . # . . . # # . . # . . # # # # | \n| # # # # . . . # . # # # # # . # . # # # # . . . # # # # | \n| # # # # # # # # # # # # # # # # # # # # . . . . # # # # | \n| # # # # # # # # # # # # # # # # # # # # . . . # # # # # | \n| # # # # # # # # # # # # # # # # # # # # # # . # # # # # | \n| - - - - - - - - - - - - - - - - - - - - - - - - - - - - | \n\nSo, in this example you can see we have a little cavern with some interconnected areas and a dead-end in the lower right. The tiles represent:\n\ncavern-floor tiles (black periods), which is where the character can traverse\ncave wall tiles (red hashmarks, which canâ€™t be passed through)\na boundary around the edge (yellow hyphens and pipe symbols)\n\nNote that the actual output from the functionâ€”a matrix that represents the dungeon tilesâ€”is returned invisibly.\n\n\nClick for a preview of the returned matrix.\n\n\n# Preview first 10 rows and columns\ndungeon[1:10, 1:10]\n\n[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,] \"|\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \"-\"  \n[2,] \"|\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \".\"  \"#\"  \"#\"  \n[3,] \"|\"  \"#\"  \"#\"  \".\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \n[4,] \"|\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \"#\"  \n[5,] \"|\"  \"#\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \".\"  \n[6,] \"|\"  \".\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \"#\"  \".\"  \".\"  \n[7,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \".\"  \"#\"  \n[8,] \"|\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n[9,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n[10,] \"|\"  \".\"  \".\"  \".\"  \".\"  \"#\"  \"#\"  \"#\"  \"#\"  \"#\"  \n\n\n\nMore examples\nI think this process works best with a larger map grid (i.e.Â higher n_row and n_col values), more randomly-selected room start-points (higher n_rooms) and more growth steps (higher iterations).\nHereâ€™s a larger maze-like dungeon:\n\nThis one came out more like a doughnut, with a central â€˜pillarâ€™ of rock-wall tiles:\n\nAnd this one is the result of using is_snake = TRUE, which creates a single, long snaking cavern:\n\nHereâ€™s what happens if we set is_organic = FALSE and is_snake = TRUE. You get much obvious â€˜roomsâ€™ connected by small corridors:\n\nAnd if we set is_organic = FALSE and is_snake = FALSE we get something interconnected, but looks more â€˜artificialâ€™ or manmade with its mostly square walls:\n\nYou can see how the shape of these dungeons can be used as part of the storytelling. Is the player in a big cavern, hollowed out long ago by natural processes? Or perhaps in an underground city, chiselled-out by dwarves?"
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#proceed-the-procedure",
    "href": "posts/2022-05-01-dungeon/index.html#proceed-the-procedure",
    "title": "Simple procedural dungeons in R",
    "section": "Proceed the procedure",
    "text": "Proceed the procedure\nWhatâ€™s the actual process for generating these maps? The procedure is very simple: lay a map made entirely of wall tiles; select random sites for rooms5 and replace with floor tiles; connect them with floor-tile corridors; expand the floor tiles generatively.\nThe corridors are particularly important. Laying corridors is a cheap way of making all areas of the dungeon accessible, which maximises the opportunity for exploration. Vanilla implementations of some other approaches, like using perlin noise, would need post-processing to make sure isolated caves are connected up.\n\n Note\nAfter publishing this post, I had a quick play around with perlin noise for seeding dungeons. I put code and an example output in a small GitHub Gist. It uses noise_perlin() from the {ambient} package.\n\n\nFunctions\nThese steps are handled in the generate_dungeon() function by a few sub-functions, which looks a bit like this:\n\nm &lt;- .create_dungeon(n_row, n_col, n_rooms)\n\nm &lt;- .connect_dungeon(m, is_snake)\n\ni &lt;- 0\n\nwhile (i &lt; iterations) {\n  m &lt;- .grow_dungeon(m)\n  i &lt;- i + 1\n}\n\n.draw_dungeon(m, colour)\n\nNot much right? But whatâ€™s actually happening?\n\nFirst, .create_dungeon():\n\nprepares a matrix with dimensions n_row and n_col\nfills the matrix with tiles that represent non-traversable rocky cave walls (#)\nselects randomly an n_rooms number of non-edge tiles in that map and replaces them with traversable cavern-floor tiles (.)\n\nThen .connect_dungeon() (this function is run now if is_organic = TRUE, otherwise after .grow_dungeon() in the next step):\n\nconnects rooms with straight, right-angled corridors made of floor tiles (connected from lowest to highest if is_snake = TRUE, otherwise randomly)\n\nNow the iterative bit, .grow_dungeon(), which happens in a while-loop whose iterations are determined, which:\n\nspawns randomly with sample() a new cavern-floor tile to the north, south, east or west or current floor tiles\nperforms one round of spawning for the number of iterations provided\n\nFinally, .draw_dungeon():\n\nprints to the console, using cat(), each line of the matrix in turn\ncolours the output with the {crayon} package, if requested\n\n\nAnd we can look at the output at each step to see whatâ€™s going on:\n\nSo, the map started with four randomly-selected floor tiles; these were joined with straight, right-angled corridors; then three iterations expanded out the floor space from the existing floor tiles.\n\n\nSampling\nWhat does it mean to â€˜expand out the floor spaceâ€™? Letâ€™s focus on the little bit of the .grow_dungeon() function that actually does this.\nHereâ€™s a tiny example matrix of wall tiles with a floor tile in the middle:\n\nm &lt;- matrix(\"#\", 3, 3)  # wall tiles\nm[2, 2] &lt;- \".\"  # floor tiles\nm\n\n     [,1] [,2] [,3]\n[1,] \"#\"  \"#\"  \"#\" \n[2,] \"#\"  \".\"  \"#\" \n[3,] \"#\"  \"#\"  \"#\" \n\n\nNow we find the adjacent tiles and sample a random number of them to also become floor tiles.\n\nstart_tile &lt;- which(m == \".\")\n\nadjacent_tiles &lt;- c(\n  start_tile - 1,        # north\n  start_tile + 1,        # south\n  start_tile - ncol(m),  # east \n  start_tile + ncol(m)   # west \n)\n\nchange_to_floor &lt;- sample(\n  adjacent_tiles,\n  sample(1:length(adjacent_tiles), 1)\n)\n\nm[change_to_floor] &lt;- \".\"\n\nm\n\n     [,1] [,2] [,3]\n[1,] \"#\"  \"#\"  \"#\" \n[2,] \".\"  \".\"  \"#\" \n[3,] \"#\"  \".\"  \"#\" \n\n\nSo one, two, three, or all of the adjacent tiles could be turned to a floor tile.\nThis is then repeated for the number of iterations provided by the user."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#going-deeper",
    "href": "posts/2022-05-01-dungeon/index.html#going-deeper",
    "title": "Simple procedural dungeons in R",
    "section": "Going deeper",
    "text": "Going deeper\nSo! I encourage you to play with this. Mess around with the arguments and see what you can come up with.\nWhat now for developing the package? Well, the {r.oguelike} package already has the rudiments of gameplay in the start_game() function, so the next step is to place the player, enemies and items into these dungeon spaces and let the player explore them.\nIdeally we can also create a system to place certain objects in certain spaces, like treasure in the far reaches of a dead-end, or a monster thatâ€™s in a narrow corridor and must be defeated to advance. Stuff like locked doors would be great too.\nThatâ€™s much more roguelike-like, like, amirite?\n\n Note\nJust after writing this post, I added code from generate_dungeon() into start_game(), so new games will now start with a procedural dungeon. It seems to work pretty well."
  },
  {
    "objectID": "posts/2022-05-01-dungeon/index.html#environment",
    "href": "posts/2022-05-01-dungeon/index.html#environment",
    "title": "Simple procedural dungeons in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:15:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] r.oguelike_0.1.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-11-apple-health-runs/index.html#tldr",
    "href": "posts/2023-06-11-apple-health-runs/index.html#tldr",
    "title": "Extract run data from Apple Health (redux)",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R to extract running details from a downloaded of your Apple Health data. The format of the data has changed since I last tried this, so I re-wrote my code."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-runs/index.html#on-your-marks",
    "href": "posts/2023-06-11-apple-health-runs/index.html#on-your-marks",
    "title": "Extract run data from Apple Health (redux)",
    "section": "On your marks",
    "text": "On your marks\nIn 2021 I extracted my running activities from my Apple Health data using the {xml2} package. You can read there for some theory and background.\nAt that point Iâ€™d been running for one year. Iâ€™m nearly at 500 runs, so I thought I would re-execute my code with the latest data. Alas, the original code no longer works because Apple seems to have updated the format of the XML file they provide.\n\n Note\nI have since re-rendered this post after passing 500 runs.\n\n\nSo Iâ€™ve written a new function that takes a path to the zipped download of my Apple Health data and outputs a dataframe of time and distance data, with one row per run."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-runs/index.html#get-set",
    "href": "posts/2023-06-11-apple-health-runs/index.html#get-set",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Get set",
    "text": "Get set\nI followed the same steps as before to get my Apple Health data off my phone.\nI smashed together a quick function to unzip the file to a temporary location and then extract workout data using the the {xml2} package. Thereâ€™s a bit of base R wrangling to output a dataframe with a row per run workout, focusing on total time and distance.\n\n\nClick to expand the function definition\n\n\nget_run_distances &lt;- function(zip_path) {\n  \n  # Unzip Apple Health export to temporary location\n  message(\"Unzipping and reading XML\")\n  temp &lt;- tempdir()\n  unzip(zipfile = zip_path, exdir = temp)\n  xml_in &lt;- xml2::read_xml(file.path(temp, \"apple_health_export\", \"export.xml\"))\n  unlink(temp)\n  \n  # Isolate workouts only and convert to an R list object\n  message(\"Isolating workouts from XML\")\n  wo_in &lt;- xml2::xml_find_all(xml_in, \"//Workout\") |&gt; xml2::as_list()\n  \n  # Pre-allocate a list to be filled with output data\n  wo_total &lt;- length(wo_in)\n  wo_out &lt;- vector(\"list\", wo_total)\n  \n  # For each viable workout, extract the details\n  message(\"Iterating over workouts to extract run data\")\n  for (wo_n in seq(wo_total)) {\n    \n    # Extract details for current workout\n    wo &lt;- wo_in[[wo_n]]\n    wo_attrs &lt;- attributes(wo)  # the data is stored as attributes\n    is_run &lt;- \n      wo_attrs[[\"workoutActivityType\"]] == \"HKWorkoutActivityTypeRunning\"\n    \n    # If the workout wasn't a run, then skip to the next workout\n    if (!is_run) next\n    \n    # if it is a run, then extract the data to a single-row dataframe\n    if (is_run) {\n      \n      # There can be more than one element named 'WorkoutStatistics'. We want to \n      # get the one with distance information and extract the details.\n      wo_stats &lt;- wo[grep(\"WorkoutStatistics\", names(wo))]\n      wo_stats_types &lt;- lapply(wo_stats, \\(x) attr(x, c(\"type\")))\n      dist_type &lt;- \"HKQuantityTypeIdentifierDistanceWalkingRunning\"\n      dist_index &lt;- which(wo_stats_types == dist_type)\n      wo_dist &lt;- wo_stats[[dist_index]]\n      \n      # Prepare single-row dataframe and add to the pre-allocated list\n      wo_details &lt;- data.frame(\n        source = wo_attrs[[\"sourceName\"]],\n        start = as.POSIXct(wo_attrs[[\"startDate\"]]),\n        end = as.POSIXct(wo_attrs[[\"endDate\"]]),\n        distance_km = attr(wo_dist, \"sum\") |&gt; as.numeric() |&gt; round(2)\n      )\n      wo_details[[\"duration_s\"]] &lt;- \n        as.numeric(wo_details[[\"end\"]] - wo_details[[\"start\"]], units = \"secs\")\n      wo_out[[wo_n]] &lt;- wo_details\n      \n    }\n    \n  }\n  \n  # Convert to dataframe, select columns\n  message(\"Combining data\")\n  wo_out_df &lt;- do.call(rbind, wo_out)\n  wo_out_df[, c(\"source\", \"start\", \"end\", \"duration_s\", \"distance_km\")]\n  \n}\n\n\nI wonâ€™t go through it line by line, but thereâ€™s some commentary to explain whatâ€™s happening at each step. It does what I need it to do for now, but no doubt thereâ€™s some refactoring to be done.\nThereâ€™s a few things to note:\n\nIâ€™m more comfortable handling R objects, so I converted early to a list with xml2::as_list(). Awkwardly, the data in the list object was stored as attributes to each element.\nThe distance data is stored in an element called â€˜WorkoutStatisticsâ€™, but more than one element will have this name. We first have to isolate the element that is of the correct type, which has the name â€˜HKQuantityTypeIdentifierDistanceWalkingRunningâ€™.\nI converted the start and end variables to datetime class (POSIXct) and subtracted one from the other to get the duration of the run. This yields the â€˜difftimeâ€™ class that can be converted to seconds with as.numeric() and the argument units = \"secs\".\nThereâ€™s no input handling, because this was quick and for â€˜funâ€™, lol."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-runs/index.html#go",
    "href": "posts/2023-06-11-apple-health-runs/index.html#go",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Go",
    "text": "Go\nSo, to use the function you pass a path to where your zipped Apple Health export lives. Mine is in my â€˜Documentsâ€™ folder.\n\nruns &lt;- get_run_distances(\"~/Documents/data/export.zip\")\n\nUnzipping and reading XML\n\n\nIsolating workouts from XML\n\n\nIterating over workouts to extract run data\n\n\nCombining data\n\n\nI recorded all my runs with the Nike Run Club app, so Iâ€™ll filter out duplicates where I dual-recorded with Appleâ€™s Workout app. I think I accidentally started the app by mistake a couple of times, so weâ€™ll only grab runs of over 1 km. Iâ€™ll also convert the seconds to a friendlier-looking â€˜periodâ€™ class using {lubridate}1.\nHereâ€™s the most recent few:\n\nruns &lt;- runs[runs$source == \"Nike Run Club\" & runs$distance_km &gt; 1, ]\nruns$duration &lt;- lubridate::seconds_to_period(runs$duration_s)\nruns &lt;- runs[, c(\"start\", \"distance_km\", \"duration\")]\nrow.names(runs) &lt;- NULL\ntail(runs)\n\n                  start distance_km duration\n497 2023-06-15 08:45:46        6.39  30M 36S\n498 2023-06-17 11:07:03       10.52  50M 58S\n499 2023-06-18 10:36:58       10.42  51M 29S\n500 2023-06-22 08:14:51        6.34  30M 43S\n501 2023-06-24 08:47:05       10.13  48M 43S\n502 2023-06-25 09:20:20       12.12  59M 48S\n\n\nFor my own tracking purposes, Iâ€™ve run:\n\n502 times\nfor a total distance of 4119 km\nfor a total duration of about 14 days\n\nAnd I can recreate a couple of the plots from the old post while weâ€™re here. Hereâ€™s the â€˜run barcodeâ€™, with one vertical line per run (the darker it is the greater the distance):\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tidyr)\n\nrun_days &lt;- left_join(\n  data.frame(date = as_date(ymd(\"2020-03-23\"):ymd(\"2023-06-25\"))),\n  runs |&gt;\n    transmute(date = ymd(as_date(start)), km = distance_km, duration) |&gt;\n    filter(date &gt;= \"2020-03-23\" & date &lt;= \"2023-06-25\") |&gt;\n    group_by(date) |&gt; \n    summarise(km = sum(km), .groups = \"drop\"),\n  by = \"date\"\n) |&gt;\n  replace_na(list(run = 0))\n\npar(mar = rep(0, 4))\nimage(matrix(run_days$km), col = grey.colors(11, 0.8, 0))\nbox(col = \"white\")\n\n\n\n\nAnd of course, a simple distance over time plot:\n\nplot(\n  x = runs$start, \n  y = runs$distance_km, \n  las = 1,  # rotate y-axis labels\n  main = \"Runs captured with Nike Run Club in Apple Health\",\n  xlab = \"Date\",\n  ylab = \"Distance (km)\"\n)\n\n\n\n\nSome patterns are obvious. For example, thereâ€™s lots of 5 km runs until about mid-2021, when it hops to more like 7 km. Thatâ€™s when I started running for 30 mins at a time, rather than for 5 km specifically.\nIâ€™m pretty happy at 5 and 10 km, obviously, but maybe I should do more 21.1 km half-marathons. Or a full marathon? No no, thatâ€™s foolish: it would expand my y-axis too much and make it harder to observe patterns at shorter distances, amirite."
  },
  {
    "objectID": "posts/2023-06-11-apple-health-runs/index.html#environment",
    "href": "posts/2023-06-11-apple-health-runs/index.html#environment",
    "title": "Extract run data from Apple Health (redux)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 21:04:06 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tidyr_1.3.0     dplyr_1.1.2     lubridate_1.9.2\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.7   \n [9] glue_1.6.2        htmltools_0.5.5   fansi_1.0.4       rmarkdown_2.23   \n[13] evaluate_0.21     tibble_3.2.1      fontawesome_0.5.1 fastmap_1.1.1    \n[17] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    htmlwidgets_1.6.2\n[21] timechange_0.2.0  pkgconfig_2.0.3   rstudioapi_0.15.0 digest_0.6.31    \n[25] R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0     \n[29] magrittr_2.0.3    tools_4.3.1       xml2_1.3.5"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html",
    "href": "posts/2021-02-27-typos/index.html",
    "title": "Typo-shaming my Git commits",
    "section": "",
    "text": "The author at work (CC BY-SA 3.0 by KaterBegemot)"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#tldr",
    "href": "posts/2021-02-27-typos/index.html#tldr",
    "title": "Typo-shaming my Git commits",
    "section": "tl;dr",
    "text": "tl;dr\nNearly 10 per cent of the commits to this blogâ€™s source involve typo fixes, according to a function I wrote to search commit messages via the {gh} package.\n\n Note\nGreat news everyone, I improved. I re-rendered this post in July 2023 and the percentage had basically halved to 5%."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#not-my-typo",
    "href": "posts/2021-02-27-typos/index.html#not-my-typo",
    "title": "Typo-shaming my Git commits",
    "section": "Not my typo",
    "text": "Not my typo\nIâ€™m sure youâ€™ve seen consecutive Git commits from jaded developers like â€˜fix problemâ€™, â€˜actually fix problem?â€™, â€˜the fix broke something elseâ€™, â€˜burn it all downâ€™. Sometimes a few swear words will be thrown in for good measure (look no further than â€˜Developers Swearingâ€™ on Twitter).\nThe more obvious problem from reading the commits for this blog is my incessant keyboard mashing; I think a lot of my commits are there to fix typos.1\nSo Iâ€™ve prepared a little R function to grab the commit messages for a specified repo and find the ones that contain a given search term, like â€˜typoâ€™.2"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#search-commits",
    "href": "posts/2021-02-27-typos/index.html#search-commits",
    "title": "Typo-shaming my Git commits",
    "section": "Search commits",
    "text": "Search commits\n{gh} is a handy R package from GÃ¡bor CsÃ¡rdi, Jenny Bryan and Hadley Wickham that we can use to interact with GitHubâ€™s REST API.3 We can also use {purrr} for iterating over the returned API object.\n\nlibrary(gh)    # CRAN v1.2.0\nlibrary(purrr) # CRAN v0.3.4\n\nSo, hereâ€™s one way of forming a function to search commit messages:\n\nsearch_commits &lt;- function(owner, repo, string = \"typo\") {\n  \n  commits &lt;- gh::gh(\n    \"GET /repos/{owner}/{repo}/commits\",\n    owner = owner, repo = repo,\n    .limit = Inf\n  )\n\n  messages &lt;- purrr::map_chr(\n    commits, ~purrr::pluck(.x, \"commit\", \"message\")\n  )\n  \n  matches &lt;- messages[grepl(string, messages, ignore.case = TRUE)]\n  \n  out &lt;- list(\n    meta = list(owner, repo),\n    counts = list(\n      match_count = length(matches),\n      commit_count = length(messages),\n      match_ratio = length(matches) / length(messages)\n    ),\n    matches = matches,\n    messages = messages\n  )\n  \n  return(out)\n  \n}\n\nFirst we pass a GET request to the GitHub API via gh::gh(). The API documentation tells us the form needed to get commits for a given ownerâ€™s repo.\nBeware: the API returns results in batches of some maximum size, but the .limit = Inf argument automatically creates additional requests until everything is returned. That might mean a lot of API calls.\nNext we can use {purrr} to iteratively pluck() out the commit messages from the list returned by gh::gh(). Itâ€™s then a case of finding which ones contain a search string of interest (defaulting to the word â€˜typoâ€™).\nThe object returned by search_commits() is a list with four elements: meta repeats the user and repo names; counts is a list with the commit count, the count of messages containing the search term, and their ratio; and the messages and matches elements contain all messages and the ones containing the search term, respectively."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#fniding-my-typoes",
    "href": "posts/2021-02-27-typos/index.html#fniding-my-typoes",
    "title": "Typo-shaming my Git commits",
    "section": "Fniding my typoes",
    "text": "Fniding my typoes\nHereâ€™s an example where I look for commit messages to this blog that contain the word â€˜typoâ€™. Since the function contains the .limit = Inf argument in gh::gh(), weâ€™ll get an output message for each separate request thatâ€™s been made to the API.\n\nblog_typos &lt;- search_commits(\"matt-dray\", \"rostrum-blog\")\n\nâ„¹ Running gh query\n\n\nâ„¹ Running gh query, got 100 records of about 1900\n\n\nâ„¹ Running gh query, got 200 records of about 1900\n\n\nâ„¹ Running gh query, got 300 records of about 1900\n\n\nâ„¹ Running gh query, got 400 records of about 1900\n\n\nâ„¹ Running gh query, got 500 records of about 1900\n\n\nâ„¹ Running gh query, got 600 records of about 1900\n\n\nâ„¹ Running gh query, got 700 records of about 1900\n\n\nâ„¹ Running gh query, got 800 records of about 1900\n\n\nâ„¹ Running gh query, got 900 records of about 1900\n\n\nâ„¹ Running gh query, got 1000 records of about 1900\n\n\nâ„¹ Running gh query, got 1100 records of about 1900\n\n\nâ„¹ Running gh query, got 1200 records of about 1900\n\n\nâ„¹ Running gh query, got 1300 records of about 1900\n\n\nâ„¹ Running gh query, got 1400 records of about 1900\n\n\nâ„¹ Running gh query, got 1500 records of about 1900\n\n\nâ„¹ Running gh query, got 1600 records of about 1900\n\n\nâ„¹ Running gh query, got 1700 records of about 1900\n\n\nâ„¹ Running gh query, got 1800 records of about 1900\n\n\nHereâ€™s a preview of the structure of the returned object. You can see how itâ€™s a list that contains the values and other list elements that we expected.\n\nstr(blog_typos)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"matt-dray\"\n  ..$ : chr \"rostrum-blog\"\n $ counts  :List of 3\n  ..$ match_count : int 95\n  ..$ commit_count: int 1870\n  ..$ match_ratio : num 0.0508\n $ matches : chr [1:95] \"Improve text, correct typos, add cheatcode to hiscore post\" \"Fix typo that also made it into a Mastodon post, lol\" \"Correct typo in games post\" \"Improve readability of parse post, add renkun post, fix typos\" ...\n $ messages: chr [1:1870] \"Re-build README.Rmd\" \"Remove non-existent anchor from hiscore post\" \"Improve text, correct typos, add cheatcode to hiscore post\" \"Re-build README.Rmd\" ...\n\n\nYou can see there were 1870 commit messages returned, of which 95 contained the string â€˜typoâ€™. Thatâ€™s 5 per cent.\nHereâ€™s a sample4 of those commit messages that contained the word â€˜typoâ€™:\n\nset.seed(1337)\nsample(blog_typos$matches, 5)\n\n[1] \"Fix potatypos\"                                         \n[2] \"Merge pull request #72 from maelle/patch-1\\n\\ntypo fix\"\n[3] \"Correct typos\"                                         \n[4] \"Correct typo\"                                          \n[5] \"add gapminder example, fix typo\"                       \n\n\nIt seems the typos are often corrected with general improvements to a postâ€™s copy. This usually happens when I read the post the next day with fresh eyes and groan at my ineptitude.5"
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#exposing-others",
    "href": "posts/2021-02-27-typos/index.html#exposing-others",
    "title": "Typo-shaming my Git commits",
    "section": "Exposing others",
    "text": "Exposing others\nI think typos are probably most often referenced in repos that involve a lot of documentation, or a book or something.\nTo make myself feel better, I had a quick look at the repo for the {bookdown} project R for Data Science by Hadley Wickham and Garrett Grolemund.\n\ntypos_r4ds &lt;- search_commits(\"hadley\", \"r4ds\")\n\nThe result:\n\nstr(typos_r4ds)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"hadley\"\n  ..$ : chr \"r4ds\"\n $ counts  :List of 3\n  ..$ match_count : int 450\n  ..$ commit_count: int 2137\n  ..$ match_ratio : num 0.211\n $ matches : chr [1:450] \"fix: typo (add missing `to`) (#1529)\" \"Fix typos in subsection \\\"6.3.2 How does pivoting work?\\\" (#1534)\\n\\n* Add missing word\\r\\n\\r\\n* Fix typo\" \"typo fix in communication.qmd (#1523)\" \"Typo: \\\"a new\\\" instead of \\\"an new\\\" (#1515)\" ...\n $ messages: chr [1:2137] \"Small format for column (#1522)\\n\\nspecies column name is missing back ticks in this reference\" \"fix: typo (add missing `to`) (#1529)\" \"Use dplyr 1.1 'default' parameter in 'case_when()' (#1525)\\n\\n* Use dplyr 1.1 'default' parameter in 'case_when\"| __truncated__ \"Update arrow chapter code to avoid errors (#1517)\\n\\n* Add in `col_types` to specify schema\\r\\n\\r\\n* Just use open_dataset()\" ...\n\n\nSurprise: typos happen to all of us. Iâ€™m guessing the percentage is quite high because the book has a lot of readers scouring it, finding small issues and providing quick fixes."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#in-other-words",
    "href": "posts/2021-02-27-typos/index.html#in-other-words",
    "title": "Typo-shaming my Git commits",
    "section": "In other words",
    "text": "In other words\nOf course, you can change the string argument of search_commits() to find terms other than the default â€˜typoâ€™. Use your imagination.\nHereâ€™s a meta example: messages containing emoji in the commits to the {emo} package by Hadley Wickham, Romain FranÃ§ois and Lucy Dâ€™Agostino McGowan.\nEmoji are expressed in commit messages like :dog:, so we can capture them with a relatively simple regular expression like \":.*:\" (match wherever there are two colons with anything in between).\n\nemo_emoji &lt;- search_commits(\"hadley\", \"emo\", \":.*:\")\n\nâ„¹ Running gh query\n\n\nâ„¹ Running gh query, got 100 records of about 200\n\nstr(emo_emoji)\n\nList of 4\n $ meta    :List of 2\n  ..$ : chr \"hadley\"\n  ..$ : chr \"emo\"\n $ counts  :List of 3\n  ..$ match_count : int 21\n  ..$ commit_count: int 112\n  ..$ match_ratio : num 0.188\n $ matches : chr [1:21] \"need emo:: prefix in that case, bc ji_glue might be called without emo being attached. ping @batpigandme\" \"rm emoji keyboard (saved in separate branch) but eventually might just go in a separate :package:\" \"emo::ji_rx a meta regex to catch all emojis. closes #14\" \"bring in some extra modules (for emo::ji_rx)\" ...\n $ messages: chr [1:112] \"Imports CRAN glue (#54)\" \"no longer importing dplyr. #24\" \"less dependency on dplyr\" \"clock no longer depends on dplyr\" ...\n\n\nOnly 19 per cent? Son, I am disappoint."
  },
  {
    "objectID": "posts/2021-02-27-typos/index.html#environment",
    "href": "posts/2021-02-27-typos/index.html#environment",
    "title": "Typo-shaming my Git commits",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 22:22:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] purrr_1.0.1 gh_1.4.0   \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 magrittr_2.0.3    rappdirs_0.3.3    glue_1.6.2       \n [9] knitr_1.43.1      gitcreds_0.1.2    htmltools_0.5.5   rmarkdown_2.23   \n[13] lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3       compiler_4.3.1   \n[17] rstudioapi_0.15.0 tools_4.3.1       curl_5.0.1        evaluate_0.21    \n[21] httr2_0.2.3       yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7   \n[25] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#tldr",
    "href": "posts/2021-06-26-emojiscape/index.html#tldr",
    "title": "Generate an {emojiscape}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can print a little emoji scene to your R console with the {emojiscape} package."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#really",
    "href": "posts/2021-06-26-emojiscape/index.html#really",
    "title": "Generate an {emojiscape}",
    "section": "Really?",
    "text": "Really?\nRegular readers will know that this blog is where I implement whimsical R daydreams. Today is no exception: Iâ€™ve made a tiny package to print a little randomised emoji scene to my console.\nWhy? Iâ€™ve seen people make cute emoji-based bots, which Iâ€™ve been interested in after making the @londonmapbot Twitter bot (post, source, BotWiki). I also enjoyed the fun of mild randomisation in my last post about #RecreationThursday.\nIâ€™ve made this completely for my own amusement, so no guarantees whatsoever."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#play-god",
    "href": "posts/2021-06-26-emojiscape/index.html#play-god",
    "title": "Generate an {emojiscape}",
    "section": "Play god",
    "text": "Play god\n\nInstall\nYou can install {emojiscape} from GitHub.\n\n## remotes::install_github(\"matt-dray/emojiscape\")\nlibrary(emojiscape)\n\nThe package has one dependency: the GitHub-hosted {emo} package1 by Hadley Wickham. It implements emoji in R like emo::ji(\"sauropod\") ðŸ¦•.\nThereâ€™s no guarantee that these particular emoji will display correctly on your device and they may have different designs if youâ€™re using another operating system.\n\n\nGenerate\nLetâ€™s generate() a scene.\nThe first one is nuts, lol: a classic deciduous woods.2\n\ngenerate(\"woods\")\n\nðŸŒ³ ðŸ¿ ðŸŒ° ðŸŒ° ðŸŒ³ ðŸ¿ ðŸŒ° ðŸŒ³ ðŸ¿ ðŸŒ° \nðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ³ \nðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ \nðŸŒ° ðŸ¿ ðŸŒ° ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸ¿ \n\n\nHold your breath, weâ€™re going to space. You can resize the output, but space is basically infinite and my console is not.\n\ngenerate(\n  terrain = \"space\",\n  grid_size = 7  # i.e. a 7x7 grid\n)\n\nâ¬› â¬› â¬› â¬› â¬› â¬› â¬› \nâ­ â¬› â¬› â¬› â­ â¬› â¬› \nâ­ â­ â¬› â­ â¬› â¬› â¬› \nâ¬› â¬› â­ â¬› â­ â¬› â¬› \nâ¬› â¬› â¬› â¬› â¬› â¬› â¬› \nâ¬› â¬› â¬› â­ ðŸ›° â¬› â¬› \nâ¬› â¬› â­ â­ â¬› â¬› â­ \n\n\nHereâ€™s a little raccoon city. Perhaps the residents are evil. (That is a gamer joke, gg.)\n\ngenerate(\"city\", 5)\n\nðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¬ ðŸ¬ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¦ ðŸ¢ ðŸ¢ \n\n\nI have a PhD in dead leaves, so I had to add undergrowth. Ant you glad I included it?\n\ngenerate(\"undergrowth\", 5)\n\nðŸ‚ ðŸœ ðŸ‚ ðŸœ ðŸ‚ \nðŸœ ðŸ„ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸœ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ \n\n\nHere endeth the puns.\n\n\nTerrains\nSo what are all the available terrain options?\n\npaste(as.list(args(generate))$terrain)[-1]\n\n [1] \"arable\"      \"city\"        \"desert\"      \"forest\"      \"garden\"     \n [6] \"liminal\"     \"mountains\"   \"ocean\"       \"pastoral\"    \"polar\"      \n[11] \"rainforest\"  \"sky\"         \"space\"       \"suburbs\"     \"traffic\"    \n[16] \"undergrowth\" \"woods\"      \n\n\nThis list may go out of date if more options are added in future.\nExpand the sections below to see each terrainâ€™s emoji set and previews of the output for each one.\n\n\nClick for all emoji sets\n\n\n\n\nterrain = \"arable\"\n  terrain        name emoji     freq\n1  arable ear_of_corn    ðŸŒ½   common\n2  arable     tractor    ðŸšœ uncommon\n3  arable       mouse    ðŸ­     rare\n\nterrain = \"city\"\n  terrain             name emoji     freq\n1    city  office_building    ðŸ¢   common\n2    city department_store    ðŸ¬ uncommon\n3    city          raccoon    ðŸ¦     rare\n\nterrain = \"desert\"\n  terrain   name emoji     freq\n1  desert desert     ðŸœ   common\n2  desert cactus    ðŸŒµ uncommon\n3  desert  camel    ðŸ«     rare\n\nterrain = \"forest\"\n  terrain           name emoji     freq\n1  forest evergreen_tree    ðŸŒ²   common\n2  forest       squirrel     ðŸ¿ uncommon\n3  forest christmas_tree    ðŸŽ„     rare\n\nterrain = \"garden\"\n  terrain          name emoji     freq\n1  garden          rose    ðŸŒ¹   common\n2  garden      seedling    ðŸŒ± uncommon\n3  garden wilted_flower    ðŸ¥€     rare\n\nterrain = \"liminal\"\n  terrain               name emoji     freq\n1 liminal white_large_square    â¬œ   common\n2 liminal               door    ðŸšª uncommon\n3 liminal         light_bulb    ðŸ’¡     rare\n\nterrain = \"mountains\"\n    terrain                 name emoji     freq\n1 mountains             mountain     â›°   common\n2 mountains snow_capped_mountain     ðŸ”ï¸ uncommon\n3 mountains                 goat    ðŸ     rare\n\nterrain = \"ocean\"\n  terrain          name emoji     freq\n1   ocean    water_wave    ðŸŒŠ   common\n2   ocean desert_island     ðŸ uncommon\n3   ocean       dolphin    ðŸ¬     rare\n\nterrain = \"pastoral\"\n   terrain           name emoji     freq\n1 pastoral        rooster    ðŸ“   common\n2 pastoral            egg    ðŸ¥š uncommon\n3 pastoral hatching_chick    ðŸ£     rare\n\nterrain = \"polar\"\n  terrain            name emoji     freq\n1   polar cloud_with_snow     ðŸŒ¨   common\n2   polar       snowflake     â„ï¸ uncommon\n3   polar         penguin    ðŸ§     rare\n\nterrain = \"rainforest\"\n     terrain           name emoji     freq\n1 rainforest deciduous_tree    ðŸŒ³   common\n2 rainforest          snake    ðŸ uncommon\n3 rainforest        gorilla    ðŸ¦     rare\n\nterrain = \"sky\"\n  terrain            name emoji     freq\n1     sky cloud_with_rain     ðŸŒ§   common\n2     sky         rainbow    ðŸŒˆ uncommon\n3     sky        airplane     âœˆï¸     rare\n\nterrain = \"space\"\n  terrain               name emoji     freq\n1   space black_large_square    â¬›   common\n2   space               star    â­ uncommon\n3   space              orbit     ðŸ›°     rare\n\nterrain = \"suburbs\"\n  terrain              name emoji     freq\n1 suburbs    deciduous_tree    ðŸŒ³   common\n2 suburbs house_with_garden    ðŸ¡ uncommon\n3 suburbs     person_biking    ðŸš´     rare\n\nterrain = \"traffic\"\n  terrain       name emoji     freq\n1 traffic automobile    ðŸš—   common\n2 traffic       taxi    ðŸš• uncommon\n3 traffic      truck    ðŸšš     rare\n\nterrain = \"undergrowth\"\n      terrain        name emoji     freq\n1 undergrowth fallen_leaf    ðŸ‚   common\n2 undergrowth         ant    ðŸœ uncommon\n3 undergrowth    mushroom    ðŸ„     rare\n\nterrain = \"woods\"\n  terrain           name emoji     freq\n1   woods deciduous_tree    ðŸŒ³   common\n2   woods       chestnut    ðŸŒ° uncommon\n3   woods       chipmunk     ðŸ¿     rare\n\n\n\n\n\nClick for all previews\n\n\n\n\nterrain = \"arable\"\nðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ \nðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸšœ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ \nðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸšœ \nðŸŒ½ ðŸ­ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸ­ ðŸŒ½ ðŸšœ ðŸŒ½ \nðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸ­ ðŸŒ½ ðŸŒ½ \nðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸšœ \nðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸ­ ðŸŒ½ ðŸŒ½ ðŸ­ \nðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ \nðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ \nðŸŒ½ ðŸ­ ðŸŒ½ ðŸšœ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ ðŸŒ½ \n\nterrain = \"city\"\nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¬ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¦ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¦ ðŸ¬ ðŸ¢ ðŸ¦ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ \nðŸ¬ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¦ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¬ ðŸ¢ ðŸ¢ \nðŸ¢ ðŸ¢ ðŸ¢ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¦ ðŸ¬ \nðŸ¢ ðŸ¬ ðŸ¬ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ ðŸ¢ \n\nterrain = \"desert\"\nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ ðŸœ ðŸœ ðŸŒµ \nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ ðŸœ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ \nðŸœ ðŸŒµ ðŸœ ðŸœ ðŸŒµ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸ« ðŸœ ðŸœ \nðŸŒµ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸŒµ ðŸœ ðŸœ ðŸœ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸ« ðŸœ ðŸŒµ ðŸŒµ ðŸœ ðŸŒµ ðŸœ \nðŸœ ðŸœ ðŸœ ðŸ« ðŸ« ðŸœ ðŸœ ðŸŒµ ðŸŒµ ðŸ« \n\nterrain = \"forest\"\nðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŽ„ ðŸŒ² \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŒ² \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² \nðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŒ² \nðŸ¿ ðŸŒ² ðŸŒ² ðŸŒ² ðŸŽ„ ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŽ„ \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² ðŸŒ² ðŸŽ„ ðŸŒ² ðŸŒ² \nðŸ¿ ðŸŒ² ðŸ¿ ðŸŒ² ðŸŽ„ ðŸŒ² ðŸ¿ ðŸŒ² ðŸ¿ ðŸŒ² \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² \nðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸŒ² ðŸ¿ ðŸŒ² \n\nterrain = \"garden\"\nðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± \nðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸ¥€ ðŸŒ¹ \nðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸ¥€ ðŸŒ± \nðŸ¥€ ðŸŒ± ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ \nðŸŒ± ðŸ¥€ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸ¥€ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ \nðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸ¥€ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ \nðŸŒ± ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ \nðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ \nðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ \nðŸŒ± ðŸŒ¹ ðŸŒ± ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ¹ ðŸŒ± \n\nterrain = \"liminal\"\nâ¬œ â¬œ â¬œ â¬œ â¬œ ðŸšª â¬œ â¬œ â¬œ ðŸšª \nâ¬œ â¬œ â¬œ â¬œ â¬œ â¬œ ðŸšª â¬œ â¬œ â¬œ \nâ¬œ â¬œ â¬œ â¬œ â¬œ â¬œ â¬œ â¬œ ðŸšª â¬œ \nâ¬œ â¬œ â¬œ â¬œ ðŸšª â¬œ â¬œ â¬œ â¬œ â¬œ \nâ¬œ ðŸšª â¬œ â¬œ ðŸšª ðŸšª â¬œ ðŸšª â¬œ â¬œ \nâ¬œ ðŸšª â¬œ â¬œ ðŸ’¡ â¬œ â¬œ ðŸšª â¬œ â¬œ \nâ¬œ ðŸšª ðŸšª ðŸšª â¬œ â¬œ â¬œ â¬œ â¬œ â¬œ \nâ¬œ â¬œ â¬œ â¬œ â¬œ â¬œ â¬œ ðŸšª â¬œ â¬œ \nâ¬œ â¬œ ðŸšª â¬œ ðŸšª â¬œ ðŸšª â¬œ â¬œ â¬œ \nâ¬œ ðŸšª ðŸšª â¬œ ðŸšª â¬œ â¬œ â¬œ â¬œ â¬œ \n\nterrain = \"mountains\"\nâ›° â›° â›° ðŸ â›° â›° ðŸ”ï¸ â›° â›° â›° \nâ›° â›° â›° ðŸ”ï¸ â›° â›° ðŸ”ï¸ â›° â›° â›° \nâ›° ðŸ”ï¸ â›° â›° ðŸ”ï¸ â›° â›° â›° â›° â›° \nâ›° â›° â›° â›° â›° â›° â›° â›° ðŸ”ï¸ â›° \nâ›° â›° â›° â›° â›° â›° ðŸ â›° â›° ðŸ \nâ›° ðŸ ðŸ”ï¸ â›° â›° â›° â›° â›° ðŸ”ï¸ ðŸ”ï¸ \nâ›° â›° â›° ðŸ”ï¸ ðŸ â›° ðŸ”ï¸ ðŸ”ï¸ â›° â›° \nâ›° ðŸ”ï¸ ðŸ â›° â›° â›° â›° â›° â›° â›° \nðŸ”ï¸ â›° â›° â›° â›° ðŸ”ï¸ ðŸ”ï¸ â›° ðŸ”ï¸ ðŸ \nðŸ ðŸ”ï¸ â›° â›° â›° â›° â›° ðŸ”ï¸ â›° ðŸ”ï¸ \n\nterrain = \"ocean\"\nðŸ¬ ðŸŒŠ ðŸ ðŸ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ \nðŸ¬ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ¬ ðŸŒŠ ðŸŒŠ ðŸŒŠ \nðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ ðŸ ðŸŒŠ ðŸŒŠ \nðŸŒŠ ðŸ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ¬ ðŸŒŠ \nðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ \nðŸŒŠ ðŸŒŠ ðŸ¬ ðŸŒŠ ðŸ¬ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ \nðŸŒŠ ðŸ ðŸ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ \nðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ¬ ðŸŒŠ ðŸŒŠ \nðŸ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ ðŸ¬ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ \nðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸŒŠ ðŸ ðŸŒŠ ðŸŒŠ ðŸ ðŸ ðŸŒŠ \n\nterrain = \"pastoral\"\nðŸ“ ðŸ¥š ðŸ¥š ðŸ¥š ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ \nðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ£ ðŸ“ ðŸ¥š ðŸ“ ðŸ“ ðŸ£ \nðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ£ ðŸ“ \nðŸ“ ðŸ“ ðŸ¥š ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ£ \nðŸ“ ðŸ£ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ \nðŸ¥š ðŸ“ ðŸ¥š ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ£ ðŸ£ \nðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ¥š ðŸ¥š ðŸ“ ðŸ£ ðŸ“ \nðŸ“ ðŸ“ ðŸ“ ðŸ¥š ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ ðŸ“ \nðŸ¥š ðŸ“ ðŸ“ ðŸ“ ðŸ¥š ðŸ¥š ðŸ¥š ðŸ“ ðŸ“ ðŸ“ \nðŸ¥š ðŸ“ ðŸ¥š ðŸ¥š ðŸ¥š ðŸ£ ðŸ“ ðŸ¥š ðŸ“ ðŸ¥š \n\nterrain = \"polar\"\nðŸŒ¨ â„ï¸ â„ï¸ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ \nðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ \nðŸŒ¨ ðŸŒ¨ ðŸ§ ðŸŒ¨ â„ï¸ ðŸ§ ðŸŒ¨ â„ï¸ â„ï¸ ðŸŒ¨ \nâ„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ â„ï¸ ðŸŒ¨ \nðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸ§ â„ï¸ â„ï¸ â„ï¸ ðŸŒ¨ ðŸŒ¨ â„ï¸ \nðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ \nðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ \nðŸŒ¨ ðŸŒ¨ ðŸ§ â„ï¸ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ \nðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ \nðŸŒ¨ â„ï¸ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸŒ¨ ðŸ§ â„ï¸ ðŸŒ¨ \n\nterrain = \"rainforest\"\nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ ðŸ ðŸ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸ \nðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸ ðŸŒ³ ðŸ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¦ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸ \nðŸ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸŒ³ ðŸ ðŸŒ³ ðŸŒ³ ðŸŒ³ \n\nterrain = \"sky\"\nðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒˆ \nðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ \nðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ âœˆï¸ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ âœˆï¸ \nðŸŒ§ ðŸŒ§ ðŸŒ§ âœˆï¸ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ \nðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ \nðŸŒˆ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒ§ \nðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ \nðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒ§ âœˆï¸ ðŸŒˆ ðŸŒˆ \nâœˆï¸ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒˆ \nðŸŒˆ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒ§ ðŸŒˆ ðŸŒ§ ðŸŒˆ ðŸŒ§ \n\nterrain = \"space\"\nâ¬› â¬› â¬› â¬› â¬› â¬› â¬› â¬› â¬› â­ \nâ¬› â¬› â­ â¬› â¬› â¬› â¬› â­ â¬› â¬› \nâ¬› â¬› â¬› â­ â­ â¬› â­ â­ â¬› â¬› \nâ­ â¬› â¬› â­ â¬› ðŸ›° â¬› ðŸ›° â¬› â­ \nâ¬› â¬› â¬› ðŸ›° â­ â¬› â¬› ðŸ›° â¬› â­ \nâ­ â¬› â­ â¬› â¬› â¬› â¬› â¬› â­ â¬› \nâ¬› â¬› â­ â¬› â¬› â¬› â¬› â¬› â¬› â­ \nâ­ â­ â¬› â¬› â­ â¬› â¬› â¬› â­ â¬› \nâ¬› â¬› â¬› â¬› â­ â¬› â¬› â¬› â­ â­ \nâ­ â¬› â­ â¬› ðŸ›° â¬› â¬› â¬› â¬› â¬› \n\nterrain = \"suburbs\"\nðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸš´ ðŸ¡ \nðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸš´ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¡ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ \nðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸ¡ ðŸŒ³ ðŸ¡ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸš´ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸš´ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ¡ ðŸŒ³ ðŸ¡ ðŸŒ³ ðŸŒ³ ðŸ¡ ðŸ¡ ðŸŒ³ ðŸŒ³ \n\nterrain = \"traffic\"\nðŸš— ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— ðŸš— ðŸš• ðŸš— ðŸš• \nðŸš— ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— ðŸš— ðŸšš ðŸš— ðŸš— \nðŸš— ðŸš• ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— \nðŸš— ðŸš— ðŸšš ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— \nðŸš— ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— \nðŸš— ðŸš— ðŸšš ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— ðŸš• ðŸš— \nðŸš• ðŸš— ðŸš• ðŸš— ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— ðŸš• \nðŸš• ðŸš• ðŸš• ðŸš• ðŸš— ðŸš— ðŸš• ðŸš— ðŸš— ðŸš— \nðŸš• ðŸš• ðŸš— ðŸš— ðŸšš ðŸš— ðŸš— ðŸš— ðŸš• ðŸš— \nðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸš— ðŸšš \n\nterrain = \"undergrowth\"\nðŸ‚ ðŸœ ðŸœ ðŸœ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ \nðŸ‚ ðŸœ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸœ ðŸ„ ðŸ‚ \nðŸ‚ ðŸ„ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸœ ðŸ‚ ðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ \nðŸ‚ ðŸ‚ ðŸ‚ ðŸœ ðŸ„ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸœ \nðŸœ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ ðŸ‚ \n\nterrain = \"woods\"\nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ \nðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ \nðŸŒ° ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ° ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ° \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \n\n\n\n\n\nFrequencies\nUse get_set() to see each terrainâ€™s emoji set and their â€˜suggested frequencyâ€™ slot. In general, the most common emoji is the one that defines the background or vegetation and the rarer ones are creatures or whatever.\n\nget_set(\"mountains\")\n\n    terrain                 name emoji     freq\n1 mountains             mountain     â›°   common\n2 mountains snow_capped_mountain     ðŸ”ï¸ uncommon\n3 mountains                 goat    ðŸ     rare\n\n\nBut you can totally mess with these emoji sampling probabilities in generate().\nAny The Mountain Goats fans?\n\ngenerate(\n  terrain = \"mountains\",\n  prob_common = 0.1,\n  prob_uncommon = 0.2,\n  prob_rare = 0.7  # INCREASE GOAT FREQUENCY\n)\n\nðŸ ðŸ”ï¸ ðŸ â›° ðŸ ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ \nðŸ”ï¸ ðŸ â›° ðŸ ðŸ ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ \nðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ ðŸ â›° ðŸ ðŸ ðŸ \nðŸ ðŸ ðŸ ðŸ â›° ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ \nðŸ ðŸ ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ ðŸ â›° ðŸ \nðŸ ðŸ ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ”ï¸ ðŸ ðŸ ðŸ \nðŸ”ï¸ ðŸ â›° ðŸ”ï¸ ðŸ ðŸ â›° ðŸ â›° ðŸ \nðŸ ðŸ ðŸ â›° ðŸ â›° ðŸ ðŸ”ï¸ ðŸ ðŸ”ï¸ \nðŸ”ï¸ ðŸ ðŸ ðŸ ðŸ ðŸ ðŸ”ï¸ ðŸ”ï¸ ðŸ”ï¸ ðŸ”ï¸ \nðŸ”ï¸ ðŸ”ï¸ â›° ðŸ ðŸ ðŸ”ï¸ ðŸ ðŸ ðŸ”ï¸ ðŸ"
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#approach",
    "href": "posts/2021-06-26-emojiscape/index.html#approach",
    "title": "Generate an {emojiscape}",
    "section": "Approach",
    "text": "Approach\nThe generate() function is pretty simple. What it does is:\n\nCreates a vector of emojis with a length of grid_size() squared, sampled from the specified terrain set with frequencies from the prob_* arguments\nCoerces this vector to a matrix of length and width grid_size() (i.e.Â a square)\nLoops over each row of the matrix with cat() to print the output to the console\n\nIt works."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#expansion",
    "href": "posts/2021-06-26-emojiscape/index.html#expansion",
    "title": "Generate an {emojiscape}",
    "section": "Expansion",
    "text": "Expansion\nIf you really want, you can add a terrain option by raising a new issue or pull request in the {emojiscape} GitHub repo. These are specified in the .get_emoji() function in the /R/utils.R script."
  },
  {
    "objectID": "posts/2021-06-26-emojiscape/index.html#environment",
    "href": "posts/2021-06-26-emojiscape/index.html#environment",
    "title": "Generate an {emojiscape}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:35:09 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emojiscape_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     assertthat_0.2.1  lubridate_1.9.2   fastmap_1.1.1    \n [5] xfun_0.39         magrittr_2.0.3    glue_1.6.2        stringr_1.5.0    \n [9] knitr_1.43.1      htmltools_0.5.5   timechange_0.2.0  generics_0.1.3   \n[13] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         vctrs_0.6.3      \n[17] compiler_4.3.1    purrr_1.0.1       emo_0.0.0.9000    rstudioapi_0.15.0\n[21] tools_4.3.1       evaluate_0.21     yaml_2.3.7        crayon_1.5.2     \n[25] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2 stringi_1.7.12"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html",
    "href": "posts/2020-07-11-raspberry/index.html",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "",
    "text": "Raspberry Pi 2 Model B (rostrum.blog limited edition)"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#tldr",
    "href": "posts/2020-07-11-raspberry/index.html#tldr",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "tl;dr",
    "text": "tl;dr\nI installed R on a Raspberry Pi and set it up to use {blogdown}. This post was written from my Pi.\n\n Note\nSince I wrote this post itâ€™s become much easier to get started with R on the Raspberry Pi with r4pi.org by Mark Sellors, along with VS Code. Read on for a more terminal-based experience."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#a-delicious-raspberry-pi",
    "href": "posts/2020-07-11-raspberry/index.html#a-delicious-raspberry-pi",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "A delicious Raspberry Pi",
    "text": "A delicious Raspberry Pi\n\nThe hardware\nThe Raspberry Pi is a small, inexpensive, single-board computer designed to make computing and coding accessible to all. Itâ€™s also popular in the maker community given its support for various peripherals like cameras and sensors.\nThe Pi was first released in 2012 and is now in its fourth generation of hardware. I was gifted a Pi 2 Model B in 2015 and have used it intermittently as a secondary computer and a video game emulation machine.\nI decided to pull my Pi out of retirement to explore how well it could run R, and more specifically, be used as a machine for blogging.\n\n\nRaspberry Pi OS\nThe Raspberry Pi is capable of running a large number of operating systems. The go-to is Raspberry Pi OS (formerly Raspbian), built on the open-source Debian Linux distribution.\nYou need to install the OS onto a micro-SD card1 via a second computer and then insert it into your Pi. Installing the Raspberry Pi Imager to your second computer will help you format (clean) the card and install the OS. At the time of writing, this was the May 2020 release.\nThereâ€™s a full walkthrough for setting up your machine on the Raspberry Pi website."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#installing-software",
    "href": "posts/2020-07-11-raspberry/index.html#installing-software",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Installing software",
    "text": "Installing software\nWith the Pi set up, we can get on with installing the software we need to get blogging. Things may change over time, but the sections below describe what worked at time of writing. Iâ€™ve added software version numbers below for posterity.\nYou can click to jump to each section:\n\n1. Install R and an IDE\n\n1a. Install R\n1b. Install Neovim\n1c. Install Nvim-R\n\n2. Install blogging requirements\n\n2a. Install {blogdown}\n2b. Install Pandoc\n2c. Install Hugo\n\n\nIn each case, weâ€™ll be running commands from the Terminal to install what we need.2\nBefore installing things, itâ€™s a good idea to run the update command so that the latest package versions are installed\nsudo apt-get update\n\n1. Install R and an IDE\nItâ€™s not too tricky to get hold of R, but what coding environment can we use?\nI typically use the RStudio integrated development environment (IDE), but it isnâ€™t available on this platform3. You could just run R from the Terminal, but itâ€™s tedious to work entirely from the command line or copy-paste commands to it from a text editor.\nThis is where Nvim-R comes in. It turns your Terminal into an IDE.4\n\n1a. Install R\nR can be installed from the command line with:\nsudo apt-get install r-base r-base-core r-base-dev\nThis grabs the latest R version thatâ€™s available for the platform, which is 3.5. At time of writing, version 4.0 has been released on other platforms, so weâ€™ll miss out on the latest advancements like stringsAsFactors=FALSE by default, sadly.\n\n\n1b. Install Neovim\nA prerequisite for Nvim-R is either Vim or Neovim. Nvim-R is a plugin for these tools.\nBut what are they, actually? Vim is a powerful text editor for the command line and Neovim is effectively a more extensible version of it.\nIâ€™ve been using Neovim, which can be installed with:\nsudo apt install neovim\nAt time of writing, this installs version 0.3.4. You can enter Neovim by opening a terminal and running nvim. This puts you into a text editor interface.\n\n\n1c. Install Nvim-R\n\n\n\nNvim-R running in Terminal. Script up top, console below.\n\n\nThere are a whole bunch of plugins available for Neovim to help extend it. You can see these at the VimAwesome site.\nNvim-R by Jakson Alves de Aquino is one such plugin.\nAt the simplest level, Nvim-R turns your terminal into an R IDE by allowing for a concurrent script editor and console (along with many other features). This means you can write R code and send it to the console without having to copy-paste or write directly into the console. This is analagous to something like RStudio without the point-and-click features.\n\nvim-plug and Nvim-R\nWe can install a plugin manager to help install and manage Nvim-R and other Neovim extensions: vim-plug by Junegunn Choi.\nHaving installed Neovim, you can get vim-plug by running this via Terminal:\nsh -c 'curl -fLo \"${XDG_DATA_HOME:-$HOME/.local/share}\"/nvim/site/autoload/plug.vim --create-dirs \\\n       https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim'\nYou specify your plugins in a special init.vim file. Run the following line to create the file and open it in Neovim in the Terminal so you can begin editing:\nnvim ~/.config/nvim/init.vim\nYou can then toggle into Neovimâ€™s â€˜insertâ€™ mode (press i) and paste (ctrl + shift + V) this in:\n\" Specify a directory for plugins\n\" - Avoid using standard Vim directory names like 'plugin'\ncall plug#begin('~/.vim/plugged')\n\n\" List of plugins.\n\" Make sure you use single quotes\n\n\" Shorthand notation\nPlug 'jalvesaq/Nvim-R', {'branch': 'stable'}\n\n\" Initialize plugin system\ncall plug#end()\nWhere Plug 'jalvesaq/Nvim-R' is the part where the Nvim-R plugin is specified.\nThis is a super minimal init.vim example. You can add a whole bunch of other plugins to this list that will allow for things like code autocompletion and themes. You can also add lines to this file to modify various settings within Neovim.\nEnter â€˜normalâ€™ mode (press Esc) and then type the following and hit Enter:\n:PluginInstall\nThis triggers the installation of the plugins you specified in the init.vim file. For me, this installed the latest Nvim-R version, 0.9.14.\nI found a YouTube video and a GitHub gist by Rohit Farmer really useful for doing these steps. Rohit provides some good examples of additional plugins that will improve your experience of Nvim-R.\n\n\nUsing Nvim-R\nA full run-through of how to use Neovim and Nvim-R are out of scope for this post, but itâ€™s worth a quick aside here.\nTo open an .R or .Rmd script for editing in Nvim-R, you can:\n\ntype nvim and the path to your file, like nvim ~/path/to/file.R, from a Terminal\nright-click the file in the explorer and select â€˜Nvim-Râ€™, which will open that file in Nvim-R in a Terminal window\n\nThe important thing to know is that Neovim and Nvim-R are keyboard-driven; thereâ€™s no pointing-and-clicking like in RStudio. Youâ€™ll need to remember a bunch of non-obvious key presses to get around, although these are all configurable.\nSee Neovimâ€™s docs for its key bindings (i.e.Â key presses that result in something happening), but hereâ€™s some useful ones:\n\ni to enter â€˜insertâ€™ mode and begin typing text\nEsc to exit insert mode and enter â€˜normalâ€™ mode\n:w and Enter to write (save)\n:q and Enter to quit (the most searched-for command in history?) or :q! to quit without saving\n:wq and Enter to save and quit\n^W and one of l, k, j or h to move focus around the â€˜panesâ€™ (e.g.Â script to console)\n\nAs for Nvim-R, see Section 4 of the docs for a full set of key bindings. Hereâ€™s some important default ones:\n\n\\rf opens a console\n\\l sends the current line to the console\n\\cc to send the current R Markdown chunk\n\\ro to open and close the object browser\n\n\n\n\n\n2. Install blogging requirements\nNow weâ€™ve got everything we need to use R on the Raspberry Pi. My use case involves blogging, so now to install the requirements for that.\n\n2a. Install {blogdown}\nI used Yihui Xieâ€™s {blogdown} package to build this blog and post to it.\nYou can install the package (currently v0.20) from CRAN. I found that I had to install {httpuv} separately first to prevent errors.\nYou can run this from Nvim-R or you can run R to start R from a Terminal window.\n\ninstall.packages(c(\"httpuv\", \"blogdown\"))\n\nOf course, you can go ahead and install any other packages you might need to write your posts.\nBut we also need two further things that arenâ€™t R packages: Pandoc and Hugo.\n\n\n2b. Install Pandoc\n{blogdown} is based on turning R Markdown files into HTML files to be served as a website. A crucial element of this conversion process is a document converter called Pandoc. It can be installed via the Terminal with:\nsudo apt-get install pandoc\nThis installed version 2.2.1 at time of writing.\n\n\n2c. Install Hugo\nHugo is a static-site generator that builds your posts into a website, like the one youâ€™re looking at now.\nYou can install Hugo from within R with blogdown::install_hugo(), but this failed for me because it tries to install a 64-bit version and Raspberry Pi OS is 32-bit.\nInstead, I used snapcraft, which describes itself as â€˜the app store for Linuxâ€™. It bundles up everything you need for a given installation, including dependencies. This is great for a noob like me.\nTo enable the installation of â€˜snapsâ€™, you first need to run:\nsudo apt install snapd\nAfter a reboot, install the Hugo snap:\nsudo snap install hugo\nThis installed version 0.73.0 for me at time of writing."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#a-blogging-workflow",
    "href": "posts/2020-07-11-raspberry/index.html#a-blogging-workflow",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "A blogging workflow",
    "text": "A blogging workflow\nSo now we have everything installed, whatâ€™s the workflow for blogging?\nSetting up a blog is out of scope for this post, but you can find instructions for this in the blogdown companion book by Yihui Xie, Amber Thomas and Alison Presmanes Hill.\nThe flow could be something like:\n\nCreate a new YYYY-MM-DD-post-name.Rmd file for the post in content/post/\nOpen this file with Neovim-R and begin writing, including the YAML metadata and R Markdown chunks as usual (remembering that you can send R Markdown chunks to the console with the \\\\cc default key binding)\nUse blogdown::serve_site() from the console to render the site and serve it locally (itâ€™ll open in your browser)\nCommit and push your changes to GitHub as normal (Git is preinstalled with Raspberry Pi OS5)\n\nFor images or other files you wan to embed in your post, create static/post/YYYY-MM-DD-post-name_files and refer to it from your post in the form /post/2020-07-07-post-name_files/image.jpg.\nTypically I would use the {blogdown} RStudio addin to help set up the YAML and put the files in the right place, but it isnâ€™t a big deal to do this â€˜manuallyâ€™.\nThis approach works for me: youâ€™re currently looking at a post made from my Raspberry Pi!"
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#blow-a-raspberry",
    "href": "posts/2020-07-11-raspberry/index.html#blow-a-raspberry",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Blow a raspberry",
    "text": "Blow a raspberry\nI set up my Pi before thinking about writing a post about it, so I may have missed or misremembered a step here or there. Let me know if Iâ€™ve made an obvious error or if you run into problems if youâ€™re following along.\nBear in mind that I have very little experience of Linux and Vim, but eager to learn. Iâ€™d also be grateful for any useful plugins or anything else youâ€™d like to share.\nUltimately Iâ€™ve written this post so I can remember what to do when the time comes to upgrade to a newer, more delicious Raspberry Pi."
  },
  {
    "objectID": "posts/2020-07-11-raspberry/index.html#environment",
    "href": "posts/2020-07-11-raspberry/index.html#environment",
    "title": "Set up R on Raspberry Pi for blogging",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:31:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html",
    "href": "posts/2022-11-13-tamRgo/index.html",
    "title": "Tamagotchi in R?",
    "section": "",
    "text": "Development of a {tamRgo} digital pet."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#tldr",
    "href": "posts/2022-11-13-tamRgo/index.html#tldr",
    "title": "Tamagotchi in R?",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve written the concept R package {tamRgo} to simulate a persistent digital pet in your R console, lol."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#had-an-oeuf",
    "href": "posts/2022-11-13-tamRgo/index.html#had-an-oeuf",
    "title": "Tamagotchi in R?",
    "section": "Had an oeuf?",
    "text": "Had an oeuf?\nR is a game engine1. Donâ€™t @ me2.\nTurns out that R can keep a â€˜save stateâ€™: developers can write a persistent file to the platform-independent path on a userâ€™s machine resolved by tools::R_user_dir()3.\nOf course, Iâ€™ve used this to make a concept R package. {tamRgo} saves locally a â€˜blueprintâ€™ for a Tamgotchi-like digital pet4, which is read and updated when you interact with it in the R console.\nTamago (egg) + uotchi (â€˜watchâ€™) = Tamagotchi. Tamago + R = {tamRgo}."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#nuovo-uovo",
    "href": "posts/2022-11-13-tamRgo/index.html#nuovo-uovo",
    "title": "Tamagotchi in R?",
    "section": "Nuovo uovo",
    "text": "Nuovo uovo\n\nInstall\nUse {remotes} to install the package from GitHub. Thereâ€™s also an accompanying documentation website.\n\n# install.packages(\"tamRgo\")  # if not yet installed\nremotes::install_github(\"matt-dray/tamRgo\")\nlibrary(tamRgo)\n\nWelcome to {tamRgo}, a digital pet in the R console!\n - Docs: &lt;https://matt-dray.github.io/tamRgo&gt;\n - New pet: lay_egg()\n - Then: get_stats(), see_pet(), play(), feed(), clean()\nIt has no package dependencies, but youâ€™ll need to be running a version of R greater than 4.0.\nOf course, itâ€™s just a toy to demonstrate a concept. Iâ€™ve built out a bit of a â€˜game loopâ€™, but itâ€™s just for fun and the code is not optimised. Bugs guaranteed, so suggestions and code contributions are always welcome.\n\n\nNew pet\nTo begin, youâ€™ll need to generate you new cyberpet5 by laying an egg. Youâ€™ll be asked to confirm itâ€™s okay to save a blueprint file onto your computer, which is just a small list object stored as an RDS file.\n\nlay_egg(pet_name = \"KEVIN\")\n\nSave pet blueprint? y/n: y\nSaved pet blueprint.\nYou have a new egg... it hatched!\nYou can get_stats(), see_pet(), play(), feed(), clean().\nThe blueprint will be saved at the location resolved by tools::R_user_dir(\"tamRgo\", \"data\"). You can always release() your pet into the wild, which will delete the blueprint file.\nSo, you have a new pet. Now what? The hint suggests to check the stats, so letâ€™s do that.\n\nget_stats()\n\nCharacteristics\n Name:    KEVIN\n Species: Z\n Age:     0\n Level:   0 (newborn)\n Alive:   TRUE\nStatus\n Happy:   â– â– â– â–¡â–¡  \n Hungry:  â– â– â– â–¡â–¡  \n Dirty:   â–¡â–¡â–¡â–¡â–¡  \nYou can see some characteristics: the name you provided, the petâ€™s species (X, Y or Z) and their age (days since â€˜birthâ€™). You can see the petâ€™s level (whatever that means) and whether they are currently alive. Thereâ€™s also status values, which are followed by five-point gauges, some of which are filled.\nLetâ€™s quickly check what our pet looks like with see_pet(). Its appearance depends on the species and the level; newborns are pretty much a blob, but your pet will grow and develop as it levels.\nThe rendering of the sprite, which is built with unicode block elements, will depend on the settings in your console. Your browser may also bork the the sprites as they appear in this post. See the packageâ€™s hex logo at the top of the page to get truer examples of the intended designs.\n\nsee_pet()\n\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–ˆâ–‘â–ˆâ–‘â–ˆâ–‘\nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\nâ–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nCongratulations! KEVIN is a beautiful little chap.\n\n\nFeed\nHaving just been born, KEVIN is a bit peckish. You can tell because the â€˜Hungryâ€™ gauge is partially filled. Letâ€™s lower the value by using feed().\n\nfeed()\n\n'Hungry' status value is now 2/5\nSee how the â€˜Hungryâ€™ counter decreased by 1 to 2?\n\nget_stats()\n\nCharacteristics\n  Name:    KEVIN\n  Species: Z\n  Age:     0\n  Level:   0 (newborn)\n  Alive:   TRUE\nStatus\n  Happy:   â– â– â– â–¡â–¡  \n  Hungry:  â– â– â–¡â–¡â–¡  \n  Dirty:   â–¡â–¡â–¡â–¡â–¡  \n\n\nPlay\nYou can increase the â€˜Happyâ€™ value, which is currently 0, with play(). This begins a game of â€˜higher or lowerâ€™ with user input. Yes, itâ€™s not much of a skill-based game, but thereâ€™s a rumour that itâ€™s easier under some circumstances and that a higher score is better for your petâ€™s wellbeing.\n\nplay()\n\nHigher or lower than 4? Type h or l: h\nWrong! It was 1. Score: 0/5.\nHigher or lower than 1? Type h or l: h\nCorrect! It was 8. Score: 1/5.\nHigher or lower than 4? Type h or l: h\nCorrect! It was 6. Score: 2/5.\nHigher or lower than 6? Type h or l: l\nCorrect! It was 5. Score: 3/5.\nHigher or lower than 7? Type h or l: l\nWrong! It was 10. Score: 3/5.\nResult: you scored 3/5!\n'Happy' status value is now 4/5\n\n\nClean\nAfter some time, your pet will become â€˜dirtyâ€™, represented by a small pile of filth underneath their sprite.\n\nsee_pet()\n\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–ˆâ–‘â–ˆâ–‘â–ˆâ–‘\nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\nâ–‘â–ˆâ–ˆâ–‘â–ˆâ–ˆâ–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nWhich is almost as big as KEVIN himself, wow. Youâ€™ll just need to clean() it away.\n\nclean()\n\n'Dirty' status value is now 0/5\n\n\nPersistence\nPerhaps the most important thing to know is that you can end your R session and come back later and your pet will still be available. In fact, it will continue to live and grow on your computer while youâ€™re away.\nMaybe you come back five days later. Hereâ€™s what you might see if you check your petâ€™s stats from any R session on your computer.\n\nget_stats()\n\nCharacteristics\n  Name:    KEVIN\n  Species: Z\n  Age:     5\n  Level:   2 (youngling)\n  Alive:   TRUE\nStatus\n  Happy:   â–¡â–¡â–¡â–¡â–¡ !\n  Hungry:  â– â– â– â– â–  !\n  Dirty:   â– â– â– â– â–  !\nAha, so KEVINâ€™s age and level have increased since youâ€™ve been away, even though you havenâ€™t interacted with him for a while. But uh-oh, looks like his status values are at their worst.\nPay attention to these status values. Look after your pet! Apparently thereâ€™s a chance it might becomeâ€¦ â€˜unaliveâ€™. Rumour has it that good owners have longer-living petsâ€¦\nAnyway, letâ€™s quickly check KEVINâ€™s appearance now heâ€™s level 2.\n\nsee_pet()\n\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–‘â–ˆâ–‘â–ˆâ–ˆâ–‘â–ˆâ–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nâ–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘\nâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘  \nâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ \nâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nErm, well, cool antennae, bro. Totally distracts from the mess. Might need to clean() him."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#under-the-shell",
    "href": "posts/2022-11-13-tamRgo/index.html#under-the-shell",
    "title": "Tamagotchi in R?",
    "section": "Under the shell",
    "text": "Under the shell\nThe underlying logic is pretty simple. I donâ€™t want to give away too many spoilers, but itâ€™s worth explaining some of the main components a bit.\n\nBlueprint\nThe whole system is dependent on a â€˜blueprintâ€™ file, which is what gets stored at the tools::R_user_dir() location. Itâ€™s a list object with elements like the petâ€™s name, species (randomly generated), â€˜date of birthâ€™, accumulated XP, status values (happy, hungry, dirty) and some other things.\nThe blueprint is read and updated whenever you use a function from {tamRgo}. The current datetime is compared to the datetime of last interaction (stored in the blueprint) and the difference is used to calculate things like the petâ€™s age, XP accumulation and level and status values.\nThis gives the impression that the pet has been â€˜aliveâ€™ on the playerâ€™s machine while theyâ€™ve been away. A trick6!\n\n\nExperience\nThe main goal is to accumulate XP and keep your pet alive. XP:\n\nis accumulated passively every hour\nis gained from the minigame in play(), where a higher score means more XP\nwill result in the pet levelling up when certain thresholds have been met, which alters their appearance\n\nAt a certain point, the pet will become â€˜unaliveâ€™7. The chance of this happening is based on the petâ€™s accumulated XP. Basically:\n\nXP is â€˜frozenâ€™ at a certain age and the value is stored in the blueprint\nthe chance of becoming unalive is tied to the frozen XP value, where more XP means a lower chance\nthe number of days since the XP was frozen is used as a multiplier, so the chance of becoming unalive increases with time\n\nThe current XP count is stored in the blueprint, but is hidden from the user. This moves focus away from tracking and improving a single number and hopefully towards a more general goal of keeping your pet happy, well-fed and clean.\n\n\nSprites\nThere are character â€˜spritesâ€™ that change with age and species (see the image at the top of this post). The sprite for a newborn, mature and unalive pet are the same regardless of species, but the other levels are dependent on whether the pet is species X, Y or Z. Of course, these are pixellated to mimic the original Tamagotchi style.\nThe sprites are called by see_pet() as binary matrices of filled and unfilled â€˜pixelsâ€™. I wrote the package {pixeltrix}, which I wrote about in my last blog post for a simple interactive way to design sprites by turning pixels â€˜onâ€™ and â€˜offâ€™ in a plotting window. Hereâ€™s a preview of a totally original little cyberfriend being incepted."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#practical-yolk",
    "href": "posts/2022-11-13-tamRgo/index.html#practical-yolk",
    "title": "Tamagotchi in R?",
    "section": "Practical yolk",
    "text": "Practical yolk\nThe package is not feature complete, lol8. To improve it, I could maybe9:\n\nanimate the pixel graphics\nallow blueprints to be transferred between machines, so your pet can live across multiple devices10\nadd a battle system like Digimon\nmake the play() minigame actually fun and so it grants more XP for greater skill\nmake more meaningful use of â€˜hungryâ€™ and â€˜dirtyâ€™ statuses, perhaps include a hidden HP gauge that is reduced when these statuses are at their maximum for an extended period\n\nThe main point of this toy was for me to work out how to store data on a userâ€™s machine. Should you actually do that? It depends. Can you use it in a silly R package for purposes of fun? Well, yes, if you ask me.\nYou can probably think of other ways to use tools::R_user_dir() for games in R, particularly for save states. Let me know when youâ€™ve made a new triple-A game for R and Iâ€™ll add it to the list."
  },
  {
    "objectID": "posts/2022-11-13-tamRgo/index.html#environment",
    "href": "posts/2022-11-13-tamRgo/index.html#environment",
    "title": "Tamagotchi in R?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:05 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] tamRgo_0.1.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#tldr",
    "href": "posts/2021-12-30-gpx3d/index.html#tldr",
    "title": "Your workout route (in three dimensions!)",
    "section": "tl;dr",
    "text": "tl;dr\nYou can use R to extract coordinate and elevation data from a GPX file and then plot it as an interactive 3D object. I put some functions in the tiny R package {gpx3d} to help do this."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#elevate-to-accumulate",
    "href": "posts/2021-12-30-gpx3d/index.html#elevate-to-accumulate",
    "title": "Your workout route (in three dimensions!)",
    "section": "Elevate to accumulate",
    "text": "Elevate to accumulate\nIâ€™ve seen recently on Twitter some people using Marcus Volzâ€™s {strava} R package to create pleasing visualisations of their running routes as small-multiples.\nI donâ€™t use Strava, but I downloaded my Apple Health data this week and it contained a folder of GPX files; one for each â€˜workoutâ€™ activity recorded via my Apple Watch.1 GPX files are basically just a type of XML used for storing GPS-related activity.\nBut rather than try to emulate {strava}, I thought it might be â€˜funâ€™ to incorporate the elevation data from a GPX as a third dimension. Iâ€™ve also had mikefcâ€™s {ggrgl} packageâ€”â€˜a 3D extension to ggplotâ€™â€”on my to-do list for a while now."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#an-alternate-dimension",
    "href": "posts/2021-12-30-gpx3d/index.html#an-alternate-dimension",
    "title": "Your workout route (in three dimensions!)",
    "section": "An alternate dimension",
    "text": "An alternate dimension\nCut to the chase: I made a tiny package called {gpx3d}. For now it does what I want it to do and it works on my machine.\nYou can download it from GitHub with help from the {remotes} package.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/gpx3d\")\n\nThere are a number of dependencies, including many that are not available on CRAN; see the README for {ggrgl} for details. You must also install XQuartz, if you havenâ€™t already.\nThe package does two things and has two exported functions:\n\nextract_gpx3d() gets the data out of a GPX file (i.e.Â it reads a GPX file; parses the XML; extracts datetime, latitude, longitude and elevation; converts to sf-class; and calculates the distance covered)\nplot_gpx3d() plots the data as an interactive 3D object (i.e.Â it takes the output from extract_gpx3d(), generates a â€˜3D ggplotâ€™ using {ggrgl} and renders it as an interactive object to an external device)\n\nThere are also two demo datasets:\n\nsegment.gpx, a GPX file containing a shorter, edited version of the route used in this blogpost, which you can access with system.file(\"extdata\", \"segment.gpx\", package = \"gpx3d\") after installing the package\ngpx_segment, an sf-class data.frame thatâ€™s the result of using the extract_gpx3d() on the built-in segment.gpx file\n\nRead on for an explanation and examples.\n\nExtract\nThere are already functions that can help read GPX files into R, like gpx::read_gpx() and plotKML::readGPX(), but I decided to do it by hand with {xml2} to get a custom output format (and to practice handling XML).\nIn short, the extract_gpx3d() function uses read_xml() to read the GPX file, then as_list() to convert it to a deeply nested list. A little wrangling is then required to create a data.frame: datetime and elevation can be hoisted out of the list okay, but the longitude and latitude are actually extracted from the attributes.\nAfter this, the data.frame is converted to the â€˜geography-awareâ€™ sf-class.2 Iâ€™ve done this for two reasons: (1) the output object can be taken away and will play nicely with various {sf} functions, letting you create various maps and perform further processing, and (2) it allowed me to calculate the distance between each recorded point, which could be summed for total distance.\nTo use extract_gpx3d(), simply pass a path to a GPX file. Iâ€™ve chosen a 10 km run I took on Christmas morning,3 which I downloaded from Apple Health and stored locally.4\n\nfile &lt;- \"~/Documents/data/apple_health_export/workout-routes/route_2021-12-25_10.31am.gpx\"\nroute &lt;- gpx3d::extract_gpx3d(file)\nroute[2000:2004, ]\n\nSimple feature collection with 5 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0.559015 ymin: 50.85109 xmax: 0.559273 ymax: 50.85109\nGeodetic CRS:  WGS 84\n                    time      ele      lon      lat                  geometry\n2000 2021-12-25 09:13:29 8.406136 0.559273 50.85109 POINT (0.559273 50.85109)\n2001 2021-12-25 09:13:30 8.498508 0.559209 50.85109 POINT (0.559209 50.85109)\n2002 2021-12-25 09:13:31 8.599027 0.559144 50.85109 POINT (0.559144 50.85109)\n2003 2021-12-25 09:13:32 8.721706 0.559079 50.85109 POINT (0.559079 50.85109)\n2004 2021-12-25 09:13:34 8.858613 0.559015 50.85109 POINT (0.559015 50.85109)\n         distance\n2000 4.564465 [m]\n2001 4.494285 [m]\n2002 4.564465 [m]\n2003 4.564465 [m]\n2004 4.492909 [m]\n\n\nYou can see the rows are basically a measurement per second (time) of the coordinates (lon and lat) and elevation (ele), and that the sf-class metadata and geometry column are present, along with the distance in metres from the previous to current point.\nYou can take this dataset away and do other stuff with it, like create a lat-long plot of the route (below left), or the elevation over time (below right).\n\npar(mfrow = c(1, 2), mar = rep(0, 4))\nwith(route, plot(lon, lat, type = \"l\", axes = FALSE))\nwith(route, plot(time, ele, type = \"l\", axes = FALSE))\n\n\n\n\nIf youâ€™re wondering about the little â€˜tailâ€™ in the bottom right of the route, I accidentally joined the back of a Parkrun, so quickly did a hairpin turn to escape. Except the Parkrun route is a â€˜there-and-backâ€™ course, so the confused stewards thought I was now in the lead with a pace of about two minutes per kilometre. Whoops!\nThe elevation plot is pretty dramatic: roughly, it goes downhill to a small plateau, down again to a flatter plateau, then the inevitable (steep!) climb. The lowest plateau is along the seafront, so basically sea level.\nBut boo! Only two dimensions? You can instead use the plotting function built in to {gpx3d} for something a bit more exciting.\n\n\nPlot\nAll the hard work of plotting is done primarily by {ggplot2} and {ggrgl}. The former is probably well-known to readers; the latter is an extension written by mikefc to introduce a third dimension to ggplot objects. In other words, you can extrude your plot along some third variable to generate a z-axis.\nThereâ€™s a whole bunch of specialised 3D geoms in {ggrgl}. For my purposes, I wanted to extend a geom_path() line plot into the third dimension. This is achieved by adding a z argument to the aes() call of the geom_path_3d() function, where z is our elevation data.\nAnd so the plot_gpx3d() function in {gpx3d} renders the plot as an interactive 3D object with {rgl} to an external devoutrgl::rgldev() graphics device.5 You can then click and drag it with your mouse and use the scrollwheel to zoom. Iâ€™ve embedded a gif of the output at the top of this thread.6\n\ngpx3d::plot_gpx3d(route)\n\nYou can see why I chose this particular route for the demo; it really shows off the power of the elevation data. I ran anti-clockwise downhill to the seafront, where it was almost entirely flat, before running back up a relatively sharp ascent.\nMight have made a nice print if Iâ€™d been gifted a 3D printer for Christmas!"
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#a-romance-of-many-dimensions",
    "href": "posts/2021-12-30-gpx3d/index.html#a-romance-of-many-dimensions",
    "title": "Your workout route (in three dimensions!)",
    "section": "A romance of many dimensions",
    "text": "A romance of many dimensions\nIâ€™ve made {gpx3d} entirely for my own amusement, so your kilometreage may vary. At this point I canâ€™t make any guarantees about whether it will even work on your machine, but hopefully Iâ€™ll find time in future to make sure it does. It might also be nice to include more user options for adjusting the output so you arenâ€™t stuck with â€˜ggplot greyâ€™ and the same defaults mikefc used in a vignette showing a {ggrgl} version of Minardâ€™s famous visulisation of Napoleonâ€™s march.7\nIâ€™ll also be thinking about developing {gpx4d} and functions like geom_tesseract(), but I might need physics to catch up first."
  },
  {
    "objectID": "posts/2021-12-30-gpx3d/index.html#environment",
    "href": "posts/2021-12-30-gpx3d/index.html#environment",
    "title": "Your workout route (in three dimensions!)",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-04 19:50:41 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        cli_3.6.1          knitr_1.43.1       rlang_1.1.1       \n [5] xfun_0.39          DBI_1.1.3          KernSmooth_2.23-21 generics_0.1.3    \n [9] sf_1.0-13          jsonlite_1.8.7     glue_1.6.2         htmltools_0.5.5   \n[13] e1071_1.7-13       fansi_1.0.4        rmarkdown_2.23     grid_4.3.1        \n[17] tibble_3.2.1       evaluate_0.21      classInt_0.4-9     fastmap_1.1.1     \n[21] lifecycle_1.0.3    yaml_2.3.7         compiler_4.3.1     dplyr_1.1.2       \n[25] pkgconfig_2.0.3    htmlwidgets_1.6.2  Rcpp_1.0.10        rstudioapi_0.14   \n[29] digest_0.6.31      wk_0.7.3           R6_2.5.1           tidyselect_1.2.0  \n[33] utf8_1.2.3         class_7.3-22       pillar_1.9.0       magrittr_2.0.3    \n[37] tools_4.3.1        proxy_0.4-27       s2_1.1.4           gpx3d_0.0.0.9002  \n[41] units_0.8-2        xml2_1.3.4"
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html",
    "href": "posts/2022-09-07-earl22/index.html",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "",
    "text": "Please donâ€™t sue me for my fan art, Microsoft."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#tldr",
    "href": "posts/2022-09-07-earl22/index.html#tldr",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "tl;dr",
    "text": "tl;dr\nI presented some slides at the EARL 2022 conference about {a11ytables}: an R package that helps automate the production of reproducible and accessible spreadsheets, with a focus on publication of government statistics."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#counting-sheets",
    "href": "posts/2022-09-07-earl22/index.html#counting-sheets",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Counting sheets",
    "text": "Counting sheets\nThe UK government publishes a lot of spreadsheets that contain statistical tables. Compared to each otherâ€”and to themselves over timeâ€”these files are often:\n\ninconsistent in structure (e.g.Â cover or contents sheets are missing)\ninconsistent in style (e.g.Â different fonts, different shorthand codes for suppressed values)\ninaccessible to users of assistive technology (e.g.Â they contain blank columns or unannounced footnotes)\n\nLuckily, the governmentâ€™s Analysis Function released some excellent guidance for releasing statistics in spreadsheets, with particular attention to accessibility.\nThe governmentâ€™s grassroots Reproducible Analytical Pipelines (RAP) movement is also growing at pace. RAPâ€™s purpose is to overcome a legacy of fragmented point-and-click processes into code-driven end-to-end pipelines that improve speed, accuracy and reproducibility; including workflows that generate statistical spreadsheets for publication.\nIt will take time for these approaches to become 100% embedded across government, due to factors like the inevitable inertia that comes with trying to leave legacy processes behind.1\nHow can we grease the wheels?"
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#spreadsheet-socialism",
    "href": "posts/2022-09-07-earl22/index.html#spreadsheet-socialism",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Spreadsheet socialism",
    "text": "Spreadsheet socialism\nI work in a government team that publishes data2 and I wanted to make it easier for us to:\n\ngenerate spreadsheets via R (the most commonly used language here)\nbe able to reproduce outputs in future (i.e.Â we produce files monthly, quarterly, annually)\napply accessible styles and structure (so we donâ€™t have to spend ages with checklists and point-and-click interfaces)\n\nFirst I looked for existing code-based solutions and found the Python package gptables, written by the Analysis Function Core Team. At the time, the package created spreadsheets in accordance with an older version of the best-practice guidance. There was no R-native solution either, though gptables could be accessed in R via {reticulate}.\nAs a result, I created {a11ytables}: an R package to generate spreadsheets that meet the latest best-practice guidance for releasing statistics in spreadsheets.\n\nIt can be downloaded from GitHub (currently v0.1), which also installs {openxlsx} (which does all the hard work of building a workbook) and {pillar} (for prettier printing).\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"co-analysis/a11ytables\")\nlibrary(a11ytables)\n\nDo submit issues or pull requests to the repo if you have ideas or solutions."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#easy-does-it",
    "href": "posts/2022-09-07-earl22/index.html#easy-does-it",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Easy does it",
    "text": "Easy does it\nA major aim of {a11ytables} is to make it easy for stats producers to more easily complete the last mile of their â€˜data-in to spreadsheet-outâ€™ pipeline. As such, the workflow is relatively simple and is composed of only three functions (arguments ignored for brevity):\n\ncreate_a11ytable() |&gt; \n  generate_workbook() |&gt;\n  openxlsx::saveWorkbook()\n\nBasically:\n\nPass information and data as arguments to create_a11ytable(), which creates a special a11ytables-class dataframe representation of your spreadsheet content\nPass that object to generate_workbook() to convert it to a Workbook-class object that applies the required structure and styling\nUse saveWorkbook() from the {openxlsx} package to write the spreadsheet output to an xlsx file\n\nI recommend that you read the vignettes and function documentation on the package website to better understand how to use {a11ytables} and to learn about its caveats3; I wonâ€™t go into depth in this post."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#over-easy-does-it",
    "href": "posts/2022-09-07-earl22/index.html#over-easy-does-it",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Over-easy does it",
    "text": "Over-easy does it\nI wrote some slides about the package and presented it at the EARL 2022 conference4 in London. Yes, to expose the package, but also to make a wider point about the general importance of reproducibility, accessibility and the power of reusable tools.\nYou can access the slides for my talk on the web, or find the source on GitHub.\nThe slides show an example of some tables published by the UK governmentâ€”the latest UK egg statistics5â€”and walks through how they might be developed using {a11ytables}.\n\n\n\n\n\n\n\n\nI wrote the slides in Quarto and made heavy use of {quartostamp}â€”my package of Quarto helpers exposed as an RStudio Addinâ€”which I wrote about recently. Click â€˜settingsâ€™ in the hamburger menu (lower left) to go fullscreen, see presenter notes, or get a slide overview."
  },
  {
    "objectID": "posts/2022-09-07-earl22/index.html#environment",
    "href": "posts/2022-09-07-earl22/index.html#environment",
    "title": "EARL 22: {a11ytables} for better spreadsheets",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-01-try-r-v4-2/index.html#tldr",
    "href": "posts/2022-06-01-try-r-v4-2/index.html#tldr",
    "title": "Try R v4.2 in your browser",
    "section": "tl;dr",
    "text": "tl;dr\nI made it so you can launch RStudio in the browser with R v4.2 installedâ€”thanks to the Binder serviceâ€”so you can try out the new pipe |&gt; and anonymous-function \\() syntax."
  },
  {
    "objectID": "posts/2022-06-01-try-r-v4-2/index.html#just-browsering",
    "href": "posts/2022-06-01-try-r-v4-2/index.html#just-browsering",
    "title": "Try R v4.2 in your browser",
    "section": "Just browsering",
    "text": "Just browsering\nWant to try R v4.2 from the safety of your browser without installing any software?\nMaybe your organisation hasnâ€™t yet moved to version 4.1 or higher, but you want a chance to noodle around with its cool new syntax that all the hip young trendsetters are yakking about.\nClick the â€˜launch binderâ€™ badge below to launch R v4.2 and RStudio in your browser, thanks to the Binder project and {holepunch} package.1 You may need to wait a few moments for it to build.\n\n\n\n\n\nOnce loaded, click on the get-started.R file in the â€˜filesâ€™ pane for a very simple introductory script with some basic introductions to the new syntax.\nTwo packages are also installed with the Binder instance:\n\nThe {dplyr} package, authored by Hadley Wickham, Romain FranÃ§ois, Lionel Henry and Kirill MÃ¼ller, so you can compare the base pipe against the {magrittr} pipe (%&gt;%), which was created by Stefan Milton-Bache and made popular by the tidyverse.\nThe {pipebind} package by Brenton Wiernik, so you can explore some methods for extending the functionality of the base pipe"
  },
  {
    "objectID": "posts/2022-06-01-try-r-v4-2/index.html#untaxing-syntax",
    "href": "posts/2022-06-01-try-r-v4-2/index.html#untaxing-syntax",
    "title": "Try R v4.2 in your browser",
    "section": "Untaxing syntax",
    "text": "Untaxing syntax\nThere are two major new features to try: the base pipe |&gt; and anonymous-function syntax \\() (sometimes referred to as â€˜lambdasâ€™), which were both introduced in R v4.1 (May 2021). From R news:\n\nR now provides a simple native forward pipe syntax |&gt;. The simple form of the forward pipe inserts the left-hand side as the first argument in the right-hand side call. The pipe implementation as a syntax transformation was motivated by suggestions from Jim Hester and Lionel Henry.\n\n\nR now provides a shorthand notation for creating functions, e.g.Â (x) x + 1 is parsed as function(x) x + 1.\n\nAn underscore placeholder _ for the right-hand side of a base pipe was introduced in R v4.2 (April 2022). From R news:\n\nIn a forward pipe |&gt; expression it is now possible to use a named argument with the placeholder _ in the rhs [right-hand side] call to specify where the lhs [left-hand side] is to be inserted. The placeholder can only appear once on the rhs."
  },
  {
    "objectID": "posts/2022-06-01-try-r-v4-2/index.html#whos-been-piping-up",
    "href": "posts/2022-06-01-try-r-v4-2/index.html#whos-been-piping-up",
    "title": "Try R v4.2 in your browser",
    "section": "Whoâ€™s been piping up?",
    "text": "Whoâ€™s been piping up?\nThis post isnâ€™t about how to use the new syntax or the motivation behind it.\nThis post exists, at best, to help you play with R v4.2 and the latest features without installing anything. At worst, it might make you aware that the base pipe exists, or that Binder is magic.\nI suggest you take a look at the following materials for more information:\n\nHadley Wickhamâ€™s â€˜Pipesâ€™ chapter in the work-in-progress second edition of R for Data Science (R4DS), which talks about why to use it and how it compares to %&gt;%\nMichael Barrowmanâ€™s post about the speed of the new base pipe and what itâ€™s doing under the hood\nSharon Machlisâ€™s post that provides an introduction and also points to materials for running different R versions in a Docker container\nIsabella VelÃ¡squezâ€™s post, with a story about solving a plotting problem with the base pipe\nElio Campitelliâ€™s post that covers a number of things, including implications for {data.table}\nMiles McBainâ€™s post on the awkward â€˜dog ballsâ€™ syntax for constructing anonymous functions on the right-hand side of a base pipe, which is partially fixed by the introduction of the underscore placeholder in R v4.22\nBrenton Wiernikâ€™s Twitter thread about the {pipebind} package to help address some of the base pipeâ€™s shortcomings, including use of the placeholder multiple times on the right-hand side\nAdolfo Ãlvarezâ€™s charming post on the history of pipes in R, including the inception of the base pipe\n\nAnd thereâ€™s probably loads more Iâ€™m missing. Let me know about them.\nRegardless, this all very exciting for me because I have strong feelings about symbols in R. Do read my theory about how $ notation is an INTERNATIONAL CONSPIRACY and YOU ARE COMPLICIT. Or my method for avoiding scripts that use the equals symbol for assignment, yuck!"
  },
  {
    "objectID": "posts/2022-06-01-try-r-v4-2/index.html#environment",
    "href": "posts/2022-06-01-try-r-v4-2/index.html#environment",
    "title": "Try R v4.2 in your browser",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-01 15:26:17 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html",
    "href": "posts/2021-01-04-safar6/index.html",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "",
    "text": "An original Nintendo Game Boy playing PokÃ©monâ€¦ if you squint."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#tldr",
    "href": "posts/2021-01-04-safar6/index.html#tldr",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "tl;dr",
    "text": "tl;dr\nI created the R package {safar6}, which contains an R6-class object to simulate a simplified, text-based version of the Safari Zone sub-area from PokÃ©mon Blue.\nI also made the â€˜gameladâ€™ RStudio theme to mimic the screen of a pukey-green original Game Boy. Pair with a blocky monospace font like VT323 for that 8-bit experience.1"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#kangaskhan-you-believe-it",
    "href": "posts/2021-01-04-safar6/index.html#kangaskhan-you-believe-it",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "Kangaskhan you believe it?",
    "text": "Kangaskhan you believe it?\nDid you know you can play games in R?\nI particularly like the text adventures The Secret of Landusia by Peter Prevos and Castle of R by Giora Simchoni\nThe latter uses object-oriented programming (OOP) for handling game elements, thanks to the {R6} package. So, a room in the castle is an R6-class object with specific fields (variables), like whether the door is open, and methods (functions) like openDoor() that can change the door state.\nThis is interesting because R is better known for being a function- rather than an object-oriented language. You can learn more about OOP in R from Hadley Wickhamâ€™s Advanced R book and more about the R6-class from the {R6} website."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#a-chansey-to-learn",
    "href": "posts/2021-01-04-safar6/index.html#a-chansey-to-learn",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "A Chansey to learn",
    "text": "A Chansey to learn\nI wrote a post about using {R6} to simulate an Automatic Bell Dispenser (an ATM, basically) from Nintendoâ€™s Animal Crossing: New Horizons (2020) game. Fields include savings and methods include withdraw(), for example.\nObviously my next step was to use {R6} for a game, but I wanted to start small. The original PokÃ©mon2 games were effectively text adventures with some random-number generation and simple calculations going on in the background. Would it be possible to simulate some aspects of it?\n\n\n\nWould you like to join the hunt?â€™ Via bulbapedia.bulbagarden.net.\n\n\nLuckily, thereâ€™s an in-game sub-area thatâ€™s self-contained and much simpler than the mechanics in the rest of the world. In the The Safari Zone youâ€™re only allowed to take 500 steps, you can only use a special type of ball to capture wild PokÃ©mon (of which you only have 30) and you canâ€™t reduce a wild PokÃ©monâ€™s health (hit points, HP).\nSo I went ahead and wrote an R6-class object to mimic the Safari Zone and bundled it in the {safar6} R package.3"
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#a-quick-tauros-of-the-game",
    "href": "posts/2021-01-04-safar6/index.html#a-quick-tauros-of-the-game",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "A quick Tauros of the game",
    "text": "A quick Tauros of the game\nYou can install the package from GitHub. Loading the package provides a reminder of how to play.\n\n# Install first the the {remotes} package\nremotes::install_github(\"matt-dray/safar6\")\n\nlibrary(safar6)\n\n# {safar6}\n# Start game: x &lt;- safari_zone$new()\n# Take a step: x$step()\nBasically, the package contains an R6-class object SafariZone, which you initialise like safari_zone$new(). Make sure to assign a name to it (x in these examples). This starts a routine with some text from the game and some interactive elements. Sometimes youâ€™ll be prompted for a response; type a value and hit enter to make a choice.\nHereâ€™s the opening sequence, which asks for your name and invites you to play:\n\nx &lt;- safari_zone$new()\n\nFirst, what is your name?\n------------------------\nNEW NAME (1)\nBLUE (2)\nGARY (3)\nJOHN (4)\n------------------------\nSelect 1, 2, 3 or 4:\n&gt; 1\nYour name: \n&gt; THEW\nWelcome to the SAFARI ZONE!\nFor just P500, you can catch all the\nPokemon you want in the park!\nWould you like to join the hunt?\n------------------------\nMONEY: P500\nYES (1) or NO (2)\n------------------------\nSelect 1 or 2: \n&gt; 1\nThat'll be P500 please!\n------------------------\nMONEY: P0\n------------------------\nWe only use a special POKe BALL here.\nTHEW received 30 SAFARI BALLs!\nWe'll call you on the PA when you run out of time or SAFARI BALLs!\nYou can then â€˜move aroundâ€™ by using the step() method on your SafariZone object. This method does most of the hard work in {safar6}, since it contains all the logic required for a wild PokÃ©mon encounter.\nThe underlying values and calculations in step() are all true to the original game. That includes the encounter rate, which is less than 1, so youâ€™ll likely have to step() a number of times before you find a PokÃ©mon.\nFor convenience, the step method prints the number of steps remaining:\n\nx$step()\n\n499/500\nEach step is treated as though youâ€™re walking through the tall grass, which is where you find wild PokÃ©mon. Thereâ€™s a weighted chance of encountering certain PokÃ©mon at certain levels, but each wild PokÃ©mon also has (hidden) randomised individual variation in its stats (HP, speed, etc) that impact your ability to catch it.\nHereâ€™s an encounter:\n\nx$step()\n\n497/500\nWild VENONAT L22 appeared!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \nAt the prompt, you can throw a Safari ball straight away to attempt a catch, or you can run away from the encounter. You can also influence the PokÃ©monâ€™s state: throw a rock to raise the catch chance (but youâ€™ll also increase the flee chance) or throw bait to reduce the chance of fleeing (but thatâ€™ll also decrease the catch chance).\nWild VENONAT L22 appeared!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 3\nTHEW threw a ROCK.\nWild VENONAT is angry!\nThe PokÃ©mon will be angry or eating for one to five turns.\nWhen you throw a ball, the success of a capture attempt is determined by several factors, like the PokÃ©monâ€™s HP, its level and its catch rate (possibly modified by rocks and bait). It may also run away given factors like its speed.\nTHEW threw a ROCK.\nWild VENONAT is angry!\n------------------------\nBALLx30 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 1\nTHEW used SAFARI BALL!\nWobble...\nDarn! The POKeMON broke free!\nYou may want to change your strategy. More rocks, or some bait? While itâ€™s still angry, you could take advantage of its heightened catch rate by throwing another ball.\nWild VENONAT is angry!\n------------------------\nBALLx29 (1)     BAIT (2)\nTHROW ROCK (3)  RUN (4)\n------------------------\nSelect 1, 2, 3 or 4: \n&gt; 1\nTHEW used SAFARI BALL!\nWobble... Wobble... Wobble...\nAll right!\nVENONAT was caught!\nSuccess! You can choose to give your â€˜captured friendâ€™ a nickname.\n------------------------\nDo you want to give a nickname to VENONAT?\nYES (1) or NO (2)\n------------------------\nSelect 1 or 2:\n&gt; 1\nNickname: \n&gt; Tajiri\nTajiri was transferred to BILL's PC!\nTry to catch as many as you can before you run out of steps or balls. You can x$pause() the game at any point to see your remaining stats and you can check out x$bills_pc to see what youâ€™ve captured4.\n\nx$pause()\n\n497/500\nBALLx28\nBILL's PC: 1\n\nx$bills_pc\n\n  nickname species level\n1   Tajiri VENONAT    22\nWhen the game is over, youâ€™ll see an endscreen with your results.\n------------------------\nPA: Ding-dong!\nTime's up!\nPA: Your SAFARI GAME is over!\nDid you get a good haul?\nCome again!\n------------------------\nResult: 1 transferred to BILL's PC\n  nickname species level\n1   Tajiri VENONAT    22\nThe Safari Zone in the original game was pretty tricky. The PokÃ©mon were flighty and it was especially hard to trap rare encounters like Chansey, Pinsir and Scyther.\nThe most captures Iâ€™ve made on a playthrough of {safar6} is three (!), so use that as a yardstick."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#exeggcute-ing-the-class",
    "href": "posts/2021-01-04-safar6/index.html#exeggcute-ing-the-class",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "Exeggcute-ing the class",
    "text": "Exeggcute-ing the class\nI tried to keep things simple, so thereâ€™s a number of omissions compared to the original game. For example, thereâ€™s no visuals or sounds; Iâ€™ve simulated only the â€˜Centerâ€™ hub area of the Safari Zone; you walk around as though youâ€™re always in tall grass; you canâ€™t fish or use different rod types; youâ€™re restricted to the catch rates and PokÃ©mon identities of the Blue game (not Red or Yellow, which are different).\nOn the flipside, I tried to maintain some subtle true-to-the-original elements. For example, youâ€™ll be prompted to enter your name; you can nickname your PokÃ©mon; thereâ€™s â€˜wobble logicâ€™ for deciding how many times the ball should shake before a capture; and the majority of the text is as it appears in the game. Iâ€™ve also made it so the text is progressively revealed, character by character.\n\n\n\nProgressive text reveal. Takes longer to print but is more authentic.\n\n\nIn particular, Iâ€™ve tried to keep the various hidden and non-hidden PokÃ©mon stats and calculations true to PokÃ©mon Blue. For example, I built in:\n\noriginal encounter rates, both for the Safari Zone and the wild PokÃ©mon in it\nwild PokÃ©mon base statistics and calculation of randomised individual values\ncatch rates based on factors like ball type and HP, and any modifications during the encounter\ntracking of â€˜eatingâ€™ and â€˜angerâ€™ statuses and the effects on catch rates\nthe calculation for whether a wild PokÃ©mon will flee\n\nThereâ€™s no guarantee Iâ€™ve got these things completely right, but the gameplay appears similar to the original, so I think itâ€™s close enough."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#disen-tangela-ing-game-mechanics",
    "href": "posts/2021-01-04-safar6/index.html#disen-tangela-ing-game-mechanics",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "Disen-Tangela-ing game mechanics",
    "text": "Disen-Tangela-ing game mechanics\nInformation about game mechanics and values were relatively tricky to come by. The following resources were really important:\n\nBulbapedia is the Bible of PokÃ©mon and hosts various stats and formulae\nThe Cave of Dragonflies has some excellent breakdowns of game mechanics, particularly in capture and Safari Zone logic\nthe PokÃ©mon Slots website is a convenient lookup for base encounter rates for wild PokÃ©mon by area\nthe pret/pokered GitHub repo contains a disassembly of the games, where you can see the raw game mechanics and stats5\n\nI later saw on YouTube some interesting attempts at building small text-based PokÃ©mon games like {safar6}. For example, one in Python by Rylan Fowers6 and one for the TI-84 calculator (of course) by Aeri."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#dont-marowak-living-creatures",
    "href": "posts/2021-01-04-safar6/index.html#dont-marowak-living-creatures",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "Donâ€™t Marowak living creatures",
    "text": "Donâ€™t Marowak living creatures\nObviously this is for fun and learning. Play at your own risk. Feel free to report any bugs (as in code problems, not bug-type PokÃ©mon) as GitHub issues.\nAnd do not, I repeat, do not throw rocks at animals IRL."
  },
  {
    "objectID": "posts/2021-01-04-safar6/index.html#environment",
    "href": "posts/2021-01-04-safar6/index.html#environment",
    "title": "Play PokÃ©monâ€™s Safari Zone in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 22:01:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] safar6_0.1.1\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tldr",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve (finally) ported the londonmapbot Twitter bot to Mastodon. Like a mammoth rising from the ashes."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#tooooooot",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "TOOOOOOOT",
    "text": "TOOOOOOOT\nTwitter is burning to the ground, yada yada.\nFor example, it appears that the free API tier will disappear soon. Soon likeâ€¦ today. Oh wait, maybe not yet?1 Cool customer communication, brah.\nAnyway, this news will obviously devastate contributors and fans of the mapbotverse Twitter list.\nYou donâ€™t know what the mapbotverse is? Oof. Itâ€™s a collection of 25 bot accounts that take some inspiration from my londonmapbot account, which uses GitHub Actions and the {rtweet} package to tweet on schedule a picture of a random spot in Greater London via MapBox.\nAnd so itâ€™s time to update the code behind londonmapbot so that it continues to post to Twitter for as long as it survives. But also so that it lives on by posting to Mastodon via the {rtoot} package as well.\nMastowhat? Something something federated Twitter-replacement sort of thing. Tooooooot tooooooot.\n\n Note\nI finally turned off londonmapbot on Twitter in May 2023."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#masto-do-or-masto-do-not",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Masto-do or masto-do-not",
    "text": "Masto-do or masto-do-not\nIâ€™m slightly behind the curve on this: Matt Kerlogue has already ported his narrowbotR (â€˜narrow boaterâ€™) bot from Twitter to Mastodon and written about it.\nThe fix was fairly rudimentary in the end, thanks to standing on the shoulder of mammoths. Particularly the creators of the {rtoot} R package.\n{rtoot} lets you interact with the Mastodon API. Itâ€™s a sort-of analogue to the {rtweet} package for the Twitter API. {rtoot} was stood up very quickly by David Schoch (with co-author Chung-hong Chan and contributor Johannes Gruber) when it became clear that Mastodon was becoming the platform-du-jour for nerds.\n\nSet up Mastodon\nItâ€™s easier to set yourself up with API access for Mastodon compared to Twitter:\n\nSet up a Mastodon account on the dedicated bot server botsin.space (londonmapbot is @londonmapbot@botsin.space).2\nInstall the {rtoot} package.\nAuthorise yourself with Mastodon and get an API token.\n???\nAbsolutely do not profit whatsoever.\n\nSteps 2 and 3 look like this:\n\ninstall.packages(\"rtoot\")  # on CRAN\n\nrtoot::auth_setup(\n  instance  = \"botsin.space\",  # the Mastodon server the account is on\n  type      = \"user\",          # i.e. for posting from R\n  name      = \"londonmapbot\",  # name the token file\n  clipboard = TRUE             # copy to clipboard\n)\n\nThis process interrupts you to interactively authorise the {rtoot} package in a browser window and copy a big long code to a dialogue box that appears in your R session.\n\nItâ€™ll then return:\nToken of type \"user\" for instance botsin.space is valid\nToken (in environment variable format) has been copied to clipboard.\n&lt;mastodon bearer token&gt; for instance: botsin.space of type: user \nI pasted this API token to a safe place and also stored it as a GitHub repo secret in the londonmapbot GitHub repo so it could be referred to while the GitHub Action was running.\n\n\nPost to Mastodon\nNow we can use the post_toot() function toâ€¦ toot a post. Publish a toot? Entoot a noote. It requires a token argument that takes a special â€˜bearer tokenâ€™ with a particular structure thatâ€™s not too dissimilar from what the rtweet package expects of the object passed to its own token function.\nAside: token setup is made easy in {rtweet} thanks to the rtweet_bot() function, to which you can pass your API keys and secrets. Itâ€™s a little less obvious in {rtoot}, which was initially built with the intention of running API calls from your personal machine, so you could just store your keys in your .Renviron file or whatever.\nBut actually you can just mimic how {rtweet} accepts the token. To do this, I did not use my brain at all and simply ripped-off Matt Kerlogueâ€™s post.3 My updated R script now contains this:4\n\nmastodon_token &lt;- structure(\n  list(  # it's just a list\n    bearer   = Sys.getenv(\"RTOOT_DEFAULT_TOKEN\"),\n    type     = \"user\",  # i.e. to post from R\n    instance = \"botsin.space\"  # the server\n  ),\n  class = \"rtoot_bearer\"  # special token class\n)\n\nWhere RTOOT_DEFAULT_TOKEN is that API token from earlier, which is required for accessing Mastodon. As mentioned, itâ€™s stored as a GitHub repo secret and called into the GitHub Action environment thanks to the ${{ secrets.RTOOT_DEFAULT_TOKEN }} call in the YAML file.\nThis object can be passed quite happily to the post_toot() function.\n\nrtoot::post_toot(\n  status   = latlon_details,\n  media    = temp_file,\n  alt_text = alt_text,\n  token    = mastodon_token\n)\n\nWhere the status (body text), media (image file) and alt_text (alternative text for the image) objects have been generated already (see the R script for details).\nThis is then executed on schedule according to the cron string5 specified in the YAML file (currently twice a day at 0914 and 1714) to publish stuff like this:\n\n\n\nAwait Twitter implosion\nI want the bot to keep posting to Twitter for as long as Iâ€™m allowed to. In other words, we should try to post a tweet and catch any error silently, without disrupting the GitHub Action. So naturally I wrapped post_tweet() in a tryCatch() statement, yes? No, actually I used purrr::possibly() instead.\nWhy? Basically because the syntax is easy to remember, lol. And what difference does it make to have one extra dependency for this task? To use it, you wrap your function of interest in possibly() and then it can fail without erroring-out the whole function.\n\npossibly_post_tweet &lt;- purrr::possibly(rtweet::post_tweet)\n\npossibly_post_tweet(\n  status         = latlon_details,\n  media          = temp_file,\n  media_alt_text = alt_text,\n  token          = twitter_token\n)\n\n\n\nFiddle while Frisco burns\nWhile I was messing about with the londonmapbot code, I made a few things in the repo a bit more generic. For example, I altered the name of the GitHub Actions YAML file and the R script to be called â€˜post-imageâ€™. This is more descriptive and it removes the need for someone forking the repo to have to manually change the name away from â€˜londonmapbotâ€™. You are so welcome."
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#parp",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Parp",
    "text": "Parp\nFarewell, until the next time we have to port londonmapot to another API-enabled microblogging site. Weâ€™ve had bird- and mammal-themed sites; my prediction is that the next site will be called â€˜Seacucumberâ€™ and we wonâ€™t â€˜tweetâ€™ or â€˜tootâ€™, weâ€™ll â€˜eviscerateâ€™.6\nI mean, inverting oneâ€™s stomach is a daily reaction on Twitter anyway, amirite?"
  },
  {
    "objectID": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "href": "posts/2023-02-09-londmapbotstodon/index.html#environment",
    "title": "Porting a Twitter bot to Mastodon",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:09:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html",
    "href": "posts/2023-03-03-getparsedata/index.html",
    "title": "I canâ€™t be parsed, mate",
    "section": "",
    "text": "Image by Keith Johnston from Pixabay. Deep fried by Matt Dray.1"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#tldr",
    "href": "posts/2023-03-03-getparsedata/index.html#tldr",
    "title": "I canâ€™t be parsed, mate",
    "section": "tl;dr",
    "text": "tl;dr\nR is capable of reading R code. Obviously. You can use getParseData(parse()) to see whatâ€™s going on. A very naive intro."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#at-an-imparse",
    "href": "posts/2023-03-03-getparsedata/index.html#at-an-imparse",
    "title": "I canâ€™t be parsed, mate",
    "section": "At an imparse",
    "text": "At an imparse\nThereâ€™s many things that delight me about R coding.2 One meta thing I like is the idea that R has to recognise the code that you give it asâ€¦ R code.\nFor example, does x&lt;-1 mean â€˜x is less than minus-oneâ€™? Hm, actually R recognises &lt;- as a â€˜left-assignment operatorâ€™â€”a special â€˜tokenâ€™â€”that gives the name x the value of 1. Subtle, but important.\nAnother example: the tokens &lt;- and = have an equivalent role in x &lt;- 1 and x = 1. For style reasons, youâ€™ll probably want to replace = with &lt;-.3 But donâ€™t just â€˜find and replaceâ€™ because = is context dependent. Consider:\n\nx = subset(mtcars, subset = carb == 8)\n\nHere, = is used to assign (=), to set a function argument (=) and as part of the equivalence operator (==). Oof.\nHow can a mere human understand this better?"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parsed-tense",
    "href": "posts/2023-03-03-getparsedata/index.html#parsed-tense",
    "title": "I canâ€™t be parsed, mate",
    "section": "Parsed tense",
    "text": "Parsed tense\nThe cool (â€˜coolâ€™) thing is that R gives you tools to be able to see the world as R sees it.\nThis is sometimes called â€˜static code analysisâ€™, in that you can interrogate the code for syntax errors before it executes. Packages like {lintr} can even help tidy up (â€˜lintâ€™) your code by adjusting or replacing the tokens.4\nIâ€™ve used this approach before to:\n\ncreate the {r2eng} package, which matches tokens against words so an expression can be translated to English (e.g.Â &lt;- is matched to the word â€˜getsâ€™)\nwrite an RStudio addin that auto-labels closing parentheses with the name of the function they belong to (known cutely as a â€˜biscuitâ€™)\nidentify and destroy files that contain equals assignment (x = 1), rather than the superior assignment arrow (x &lt;- 1)\n\nHow might you tinker about with this yourself? Read on for a quickstart."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parse-the-parcel",
    "href": "posts/2023-03-03-getparsedata/index.html#parse-the-parcel",
    "title": "I canâ€™t be parsed, mate",
    "section": "Parse the parcel",
    "text": "Parse the parcel\nIâ€™ll talk about two main functions: parse() and getParseData(), which are both part of base R.\nYou can pass a string of R code to parse() for it to be recognised as an â€˜expressionâ€™. Letâ€™s use the equals-rich subset() example from above.\n\ncode_str &lt;- \"x = subset(mtcars, subset = carb == 8)\"\ncode_expr &lt;- parse(text = code_str)\ncode_expr\n\nexpression(x = subset(mtcars, subset = carb == 8))\n\nclass(code_expr)\n\n[1] \"expression\"\n\n\nSo the string is recognised as R code at this point, which will allow us to break it down into its individual tokens. You could jump ahead here and just eval()uate this expression object.\n\neval(code_expr)\nx\n\n              mpg cyl disp  hp drat   wt qsec vs am gear carb\nMaserati Bora  15   8  301 335 3.54 3.57 14.6  0  1    5    8\n\n\nAs a result, the dataframe x is now in our environment and, as expected, contains only rows of the mtcars that have 8 carburetors.5\nSo we have the power to delay code execution, like some kind of wizard. Jeepers! Thatâ€™s great, but now lets pick apart the frozen expression into its constituent tokens. This is where getParseData() comes in.\nThe function takes an expression object as the input and returns a dataframe with one token per row and several columns of handy information related to positioning and the relatedness between the tokens.\nFor now Iâ€™m going to simplify the output to show only the units of text that have been recognised as tokens, along with the name that R gives to each token under the hood (e.g.Â &lt;- is recognised as LEFT_ASSIGN).6\n\ncode_parsed &lt;- getParseData(parse(text = code_str, keep.source = TRUE))\ncode_parsed[code_parsed$text != \"\", c(\"text\", \"token\")]\n\n     text                token\n1       x               SYMBOL\n2       =            EQ_ASSIGN\n5  subset SYMBOL_FUNCTION_CALL\n6       (                  '('\n8  mtcars               SYMBOL\n9       ,                  ','\n14 subset           SYMBOL_SUB\n15      =               EQ_SUB\n16   carb               SYMBOL\n17     ==                   EQ\n19      8            NUM_CONST\n21      )                  ')'\n\n\nOh neato, so you can see = is indeed recognised as the token EQ_ASSIGN (â€˜equals assignâ€™), = as EQ_SUB (equals in the context of supplying function arguments) and == as in EQ (the equivalence operator).\nIf youâ€™re wondering, the keep.source = TRUE bit was needed to encourage parse() to return its output, which is a necessary step within this non-interactive blog post."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parseltongue",
    "href": "posts/2023-03-03-getparsedata/index.html#parseltongue",
    "title": "I canâ€™t be parsed, mate",
    "section": "Parseltongue",
    "text": "Parseltongue\nWant to take a look at the tokens in a given string of R code yourself? You can use this little function that contains parse() and getParseData() and returns you the simplified dataframe I showed above if simplify = TRUE, otherwise it gives the full read out.7\n\nparse_out &lt;- function(string, simplify = TRUE) {\n  p &lt;- parse(text = string, keep.source = TRUE)\n  pd &lt;- getParseData(p)\n  if (simplify) {\n    keep_cols &lt;- c(\"token\", \"text\")\n    pd &lt;- pd[pd$text != \"\", keep_cols]\n  }\n  pd\n}\n\nSo you could use it like:\n\nparse_out(\n  \"mean(CO2[CO2$Plant == 'Qn1', CO2$uptake]) -&gt; mean_uptake\"\n)\n\n                  token        text\n1  SYMBOL_FUNCTION_CALL        mean\n2                   '('           (\n4                SYMBOL         CO2\n5                   '['           [\n7                SYMBOL         CO2\n8                   '$'           $\n10               SYMBOL       Plant\n12                   EQ          ==\n13            STR_CONST       'Qn1'\n14                  ','           ,\n20               SYMBOL         CO2\n21                  '$'           $\n23               SYMBOL      uptake\n25                  ']'           ]\n30                  ')'           )\n35         RIGHT_ASSIGN          -&gt;\n36               SYMBOL mean_uptake\n\n\n\n Note\nSince I wrote this post, itâ€™s become possible to include editable R blocks in a rendered Quarto document, which can be run in the browser thanks to WebR(!). Iâ€™ve made a quick demo and post so you can play around with a simplified version of the parsing function above."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#lateral-parse",
    "href": "posts/2023-03-03-getparsedata/index.html#lateral-parse",
    "title": "I canâ€™t be parsed, mate",
    "section": "Lateral parse",
    "text": "Lateral parse\nIâ€™ll leave you with another interesting thing that shows you the inner workings of R, which you might not realise as you run your code. We can look at how the code is actually executed, not just the tokens that itâ€™s composed of.\nConsider how the {magrittr} pipe %&gt;% is used. Here Iâ€™ve slightly adjusted the input to filter for 6 and 8 carburetors; youâ€™ll see why in a second.\n\nparse_out(\"mtcars %&gt;% subset(carb %in% c(6, 8))\")\n\n                  token   text\n1                SYMBOL mtcars\n2               SPECIAL    %&gt;%\n4  SYMBOL_FUNCTION_CALL subset\n5                   '('      (\n7                SYMBOL   carb\n8               SPECIAL   %in%\n10 SYMBOL_FUNCTION_CALL      c\n11                  '('      (\n13            NUM_CONST      6\n15                  ','      ,\n19            NUM_CONST      8\n21                  ')'      )\n26                  ')'      )\n\n\nOkay yeah, %&gt;% is recognised as a token called SPECIAL between the left-hand side of mtcars and the right-hand side of subset(carb %in% c(6, 8)). Notice also that %in% is also recognised as SPECIAL.\nIn fact, this is how R recognises â€˜infix operatorsâ€™ that are bound by percent symbols. This is some special syntactical magic that lets you put the function name between two arguments. So x %&gt;% head is equivalent to `%&gt;%`(mtcars, head). Perhaps SPECIAL instead of a more specific name because infix operators can be created on the fly?\nIf %&gt;% is SPECIAL, how do you think the base pipe is recognised in this simpler example?\n\nparse_out(\"mtcars |&gt; head()\")\n\n                 token   text\n1               SYMBOL mtcars\n2                 PIPE     |&gt;\n4 SYMBOL_FUNCTION_CALL   head\n5                  '('      (\n7                  ')'      )\n\n\nNot that surprising: itâ€™s recognised as PIPE and not a SPECIAL, since itâ€™s a proper base R token in its own right (as of R v4.1) .\nOkay, so weâ€™ve seen how R parses these tokens, what about how it actually executes the code? One way to see this is to look at an â€˜abstract syntax treeâ€™ with the {lobstr} package.8 A â€˜treeâ€™ to show the nested structure of code and variables and so on.\n\nlibrary(lobstr)    # install from CRAN\nlibrary(magrittr)  # install from CRAN\nast(mtcars %&gt;% head())\n\nâ–ˆâ”€`%&gt;%` \nâ”œâ”€mtcars \nâ””â”€â–ˆâ”€head \n\n\nYeah, like I said: x %&gt;% head() is ultimately executed by R like a normal function (block symbol in the output from ast() above), in the form `%&gt;%`(mtcars, head). You can see how the `%&gt;%` is a parent to mtcars and head() below it.\nSo the same happens for the base pipe, right?\n\nast(mtcars |&gt; head())\n\nâ–ˆâ”€head \nâ””â”€mtcars \n\n\nSurprise! mtcars |&gt; head is not executed like `|&gt;`(mtcars, head). Itâ€™s literally executed like head(mtcars). The base pipe is so special because itâ€™s baked right into the R source code as a separate type of token that is recognised to have a job distinct from a basic SPECIAL. This should make it a little faster to run compared to %&gt;% as well."
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#parse-away",
    "href": "posts/2023-03-03-getparsedata/index.html#parse-away",
    "title": "I canâ€™t be parsed, mate",
    "section": "Parse away",
    "text": "Parse away\nWell, â€˜coolâ€™ I guess. Now itâ€™s up to you: you can either parse on this knowledge, or leave it in the parsed.9"
  },
  {
    "objectID": "posts/2023-03-03-getparsedata/index.html#environment",
    "href": "posts/2023-03-03-getparsedata/index.html#environment",
    "title": "I canâ€™t be parsed, mate",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:08:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 lobstr_1.1.2  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[13] yaml_2.3.7        crayon_1.5.2      rlang_1.1.1       jsonlite_1.8.7   \n[17] htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html",
    "href": "posts/2023-01-06-remorse/index.html",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "",
    "text": "You may not believe it, but I am releasing this art under CC0."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#tldr",
    "href": "posts/2023-01-06-remorse/index.html#tldr",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "tl;dr",
    "text": "tl;dr\nOn a whim, Iâ€™ve written {remorse}: a tiny R package that converts text to Morse Code to audio."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "href": "posts/2023-01-06-remorse/index.html#beat-a-dead-morse",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "Beat a dead morse",
    "text": "Beat a dead morse\nIn the last post I mentioned {sonify} for making R do little audible beeps and boops.\nIt reminded me of one (of many) unwritten micro-projects Iâ€™ve got kicking around in my brain: obviously you could use {sonify} to communicate Morse Code. And why not translate from text to Morse (and back) while youâ€™re at it?1\nTo be honest this was a classic case of name-driven development (NDD): I thought {remorse} was a funny name for a package and worked backwards from there.\nObviously it says â€˜Morseâ€™ in the name, but also â€˜remorseâ€™ is usually what I feel after putting together a small pointless package; pointless-package existentialism (PPE) is something I have a track history with.\nBut of course, the true remorse is that I didnâ€™t find the better package-name pun: {morseinspector}. But maybe thatâ€™s too long of a name and maybe non-Brits wouldnâ€™t understand the reference. Maybe Iâ€™m thinking too hard.2"
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "href": "posts/2023-01-06-remorse/index.html#oh-dit-dit-dahling",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "Oh dit-dit-dahling",
    "text": "Oh dit-dit-dahling\nConsider this highly plausible scenario: itâ€™s 20XX, the apocalypse has come, and the remaining humans on planet Earth communicate by Morse Code. For some reason.3\nWow, wouldnâ€™t it be handy to have a text-to-Morse translator?\nWell friend, if youâ€™ve managed to find an electronic thinking box in the apocalyptic barren wastelands (assuming electricity is still available (and the machine has R installed (and the {remorse} package was downloaded before the worldâ€™s internet cut out (and you know how to use R (and you donâ€™t own a simpler, more portable Morse Code translation pamphlet))))), then you will have this incredible power at your fingertips.\nOr maybe youâ€™d rather risk it? Pfft."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "href": "posts/2023-01-06-remorse/index.html#use-the-morse",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "Use the Morseâ€¦",
    "text": "Use the Morseâ€¦\nThatâ€™s an awful lot of build-up for a very simple package. Letâ€™s take a look at what little it does.\nAs usual, {remorse} lives on GitHub4, so it can be downloaded with a little help from the typographically-adjacent {remotes} package:\n\ninstall.github(\"remotes\")\nremotes::install_github(\"matt-dray/remorse\")  # v0.1.1 here\n\nThatâ€™ll install {sonify} as well, which is needed for the audio.\nRight so: text to Morse Code.\n\ntext_in &lt;- \"Ahoy pal!\"\nmorse &lt;- remorse::txt2morse(text_in)\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nSo each letter has been translated to the relevant string of â€˜dits and dahsâ€™ (â€˜dotsâ€™ and â€˜dashesâ€™) that make up Morse Code. Iâ€™ve used a period (.) and hyphen (-) to represent these in {remorse}, with forward slashes (/) between Morse groups that represent individual characters, and a space for the spaces between words.\nNote that not all characters can be converted to Morse Code. I did some research (Wikipedia) to discover the mappings from letters, numbers and punctuation to Morse Code. This information is used internally as a lookup, but is also exported in morse_lookup:\n\nremorse::morse_lookup\n\n       A        B        C        D        E        F        G        H \n    \".-\"   \"-...\"   \"-.-.\"    \"-..\"      \".\"   \"..-.\"    \"--.\"   \"....\" \n       I        J        K        L        M        N        O        P \n    \"..\"   \".---\"    \"-.-\"   \".-..\"     \"--\"     \"-.\"    \"---\"   \".--.\" \n       Q        R        S        T        U        V        W        X \n  \"--.-\"    \".-.\"    \"...\"      \"-\"    \"..-\"   \"...-\"    \".--\"   \"-..-\" \n       Y        Z        0        1        2        3        4        5 \n  \"-.--\"   \"--..\"  \"-----\"  \".----\"  \"..---\"  \"...--\"  \"....-\"  \".....\" \n       6        7        8        9        &        '        @        ) \n \"-....\"  \"--...\"  \"---..\"  \"----.\"  \".-...\" \".----.\" \".--.-.\" \"-.--.-\" \n       (        :        ,        =        !        .        -        * \n \"-.--.\" \"---...\" \"--..--\"  \"-...-\" \"-.-.--\" \".-.-.-\" \"-....-\"   \"-..-\" \n       +        \"        ?        /          \n \".-.-.\" \".-..-.\" \"..--..\"  \"-..-.\"      \" \" \n\n\nOf course, this means we can map backwards from Morse Code to letters, numbers and punctuation:\n\ntext_out &lt;- remorse::morse2txt(morse)\ntext_out\n\n[1] \"AHOY PAL!\"\n\n\nMorse Code has no sense of case, so it just converts it all to uppercase. Like youâ€™re shouting; the most clear form of communication.\nSo, you can argue justifiably that txt2morse(\"yo\") |&gt; morse2txt() is just a worse version of toupper() that strips out certain unmappable characters.\nBut of course it does so much more. Well, one thing more. Letâ€™s go from Morse to audio.\nFirst a reminder of the code from earlier:\n\nmorse\n\n[1] \".-/..../---/-.-- .--./.-/.-../-.-.--\"\n\n\nAnd to generate audio you just:\n\nremorse::morse2sfx(morse)\n\nThe output sounds like this:\n\n\n\n\n\nWow. It plays audible dits (one â€˜time unitâ€™, default is dit_length = 0.05 in seconds), dahs (three), spaces between dits and dahs (one), spaces between Morse character groupings (three) and spaces between words (seven). Tell all your friends.\nSo, do I still feel remorse for writing {remorse}, even after demonstrating its incredible power? Yes. All I ask is that you think of me in those apocalyptic wastelands.\n\n Note\nI just realised you can turn Morse Code intoâ€¦ Morse Code. Mind blown.\n\nremorse::txt2morse(\"hi\") |&gt;\n  remorse::txt2morse()\n\n[1] \".-.-.-/.-.-.-/.-.-.-/.-.-.-/-..-./.-.-.-/.-.-.-\"\n\n\nâ€˜Morsest Codeâ€™. Why? Absolutely.\nMaybe Iâ€™ve been watching too much Tom7 recently."
  },
  {
    "objectID": "posts/2023-01-06-remorse/index.html#environment",
    "href": "posts/2023-01-06-remorse/index.html#environment",
    "title": ".-././â€“/â€”/.-./â€¦/.",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:10:00 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   remorse_0.1.1     rstudioapi_0.15.0\n [9] yaml_2.3.7        rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7   \n[13] xfun_0.39         digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1\n[17] evaluate_0.21"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#tldr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "tl;dr",
    "text": "tl;dr\n{officer} is an R package that lets you extract elements of a Word document, including tables, into a tidy dataframe. Iâ€™ve written a function to â€˜re-rectangulariseâ€™ extracted Word tables into a list of R dataframes.\n\n Note\nTurns out that Eli Pousson has written the {officerExtras} package (install it from GitHub), which already contains this functionality in the officer_tables() and officer_table() functions. At least this proves my idea wasnâ€™t too far-fetched!\nAlso you can just use docxtractr::docx_extract_all_tbls() by Bob Rudis to extract all the tables in one go, lol."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "href": "posts/2023-06-07-rectangular-officer/index.html#whats-the-officer-problem",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Whatâ€™s the officer, problem?",
    "text": "Whatâ€™s the officer, problem?\nSomeone on Slack asked about some difficulty with scraping a table from a Word document. Weâ€™ve all been there.\nMy mind immediately went to {officer} by David Gohel, which is part of the â€˜officeverseâ€™ for reading, creating and manipulating common Microsoft documents with R1.\nIn particular, the function officer::docx_summary() extracts all the elements of a Word doc into a tidy dataframe2. Each row of that dataframe is a heading, or a paragraph, or the contents of a table cell3.\nThis means tables are â€˜unstackedâ€™, with a row per â€˜cellâ€™ of the original Word table. How could you convert these tidy Word tables into dataframes for further use in R? Thereâ€™s a suggestion in the docs, but I drew the rest of the heckinâ€™ owl by creating a slightly overengineered function to do it4."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "href": "posts/2023-06-07-rectangular-officer/index.html#allo-allo",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "â€™Allo â€™allo",
    "text": "â€™Allo â€™allo\nFirst, you can download the {officer} package from CRAN:\n\ninstall.packages(\"officer\") # if not yet installed\nlibrary(officer)\n\nLetâ€™s create a Word document to test with and save it to a temporary location:\n\n# Create a test docx file\ndoc_test &lt;- read_docx() |&gt;\n  body_add_par(\"This is a test\", style = \"heading 1\") |&gt;\n  body_add_par(\"Below is a table.\", style = \"Normal\") |&gt;\n  body_add_table(mtcars[1:3, 1:5]) |&gt; \n  body_add_par(\"Below is another table\", style = \"Normal\") |&gt;\n  body_add_table(airquality[1:3, 1:5])\n\n# Save docx to temp location\ntemp_docx &lt;- tempfile(fileext = \".docx\")\nprint(doc_test, target = temp_docx)\n\nThe package has a nice system of pipeable functions for building up document. This code created a file with a heading, followed by two tables that each have a line of text above them.\nWe can read the document with read_docx() and extract the contents into a tidy dataframe:\n\n# Read the file from temp path\ndoc_path &lt;- list.files(tempdir(), pattern = \".docx$\", full.names = TRUE)\ndoc_in &lt;- read_docx(doc_path)\n\n# Get the content of the document as a dataframe\ndoc_tidy &lt;- docx_summary(doc_in)\nstr(doc_tidy)\n\n'data.frame':   43 obs. of  11 variables:\n $ doc_index   : int  1 2 3 3 3 3 3 3 3 3 ...\n $ content_type: chr  \"paragraph\" \"paragraph\" \"table cell\" \"table cell\" ...\n $ style_name  : chr  \"heading 1\" \"Normal\" NA NA ...\n $ text        : chr  \"This is a test\" \"Below is a table.\" \"mpg\" \"21.0\" ...\n $ level       : num  NA NA NA NA NA NA NA NA NA NA ...\n $ num_id      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ row_id      : int  NA NA 1 2 3 4 1 2 3 4 ...\n $ is_header   : logi  NA NA TRUE FALSE FALSE FALSE ...\n $ cell_id     : num  NA NA 1 1 1 1 2 2 2 2 ...\n $ col_span    : num  NA NA 1 1 1 1 1 1 1 1 ...\n $ row_span    : int  NA NA 1 1 1 1 1 1 1 1 ...\n\n\nThe doc_in object has â€˜rdocxâ€™ class that carries the extracted elements and associated style information. Running docx_summary() converts this to the single tidy dataframe that weâ€™re after.\nYou can see we have information here about the content of our doc. For purposes of this post, we care about:\n\ntext, which is the actual written content\ncontent_type, which can tell us if weâ€™re looking at table cells\ndoc_index, which assigns an ID value so document elements stay together (e.g.Â cells of a table will all carry the same doc_index)\ncell_id and row_id, which tell us the x and y cell locations in tables\nis_header, which can tell us if the row contains a table header.\n\nNow to extract the table elements and â€˜re-rectangulariseâ€™ back into a dataframe."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "href": "posts/2023-06-07-rectangular-officer/index.html#cop-a-load-of-this",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Cop a load of this",
    "text": "Cop a load of this\nIâ€™ve made two functions using base R:\n\nrectangularise_tables() (note the plural) takes the dataframe provided by docx_summary() and outputs a list of dataframes, one per table in the original Word file\n.rectangularise_table() (not pluralised and starts with a dot for disambiguation), which runs inside rectangularise_tables() to reformat the tidy representation of a single Word table into an R dataframe\n\nYouâ€™ll need to copy both of these into your session and run them. For convenience, Iâ€™ve added them to a GitHub gist. Iâ€™ve added commentary so you can see whatâ€™s happening in each bit.\n\n\nClick to expand the rectangularise_tables() definition.\n\n\nrectangularise_tables &lt;- function(\n    docx_summary,  # output dataframe from docx_summary\n    assume_headers = TRUE,  # assume headers in first row?\n    type_convert = TRUE  # try to coerce columns to most likely data type?\n) {\n  \n  # Check inputs\n  \n  is_data.frame &lt;- inherits(docx_summary, \"data.frame\")\n  \n  docx_summary_names &lt;- c(\n    \"doc_index\", \"content_type\", \"style_name\", \"text\", \"level\", \"num_id\", \n    \"row_id\", \"is_header\", \"cell_id\", \"col_span\", \"row_span\"\n  )  # column names we can expect in the output from docx_summary\n  \n  is_docx_summary &lt;- all(names(docx_summary) %in% docx_summary_names)\n  \n  if (!is_data.frame | !is_docx_summary) {\n    stop(\n      paste(\n        \"Argument 'docx_summary' must be a data.frame created with\",\n        \"'officer::docx_summary'.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Get only the rows that relate to Word tables\n  docx_summary_tables &lt;- \n    docx_summary[docx_summary[[\"content_type\"]] %in% \"table cell\", ]\n  \n  # Get the ID value for each Word table\n  doc_indices &lt;- unique(docx_summary_tables[[\"doc_index\"]])\n  \n  # Initiate an empty list to hold dataframe representations of the Word tables\n  tables_out &lt;- vector(mode = \"list\", length = length(doc_indices))\n  names(tables_out) &lt;- paste0(\"doc_index_\", doc_indices)\n  \n  # For each Word table, 'rectangularise' into a dataframe and add to the list\n  for (doc_index in doc_indices) {\n    \n    docx_summary_table &lt;- \n      docx_summary_tables[docx_summary_tables[[\"doc_index\"]] == doc_index, ]\n    \n    extracted_table &lt;- .rectangularise_table(docx_summary_table, assume_headers)\n    \n    list_element_name &lt;- paste0(\"doc_index_\", doc_index)\n    tables_out[[list_element_name]] &lt;- extracted_table\n    \n  }\n  \n  # Optionally convert columns to appropriate type (integer, etc)\n  if (type_convert) {\n    tables_out &lt;- lapply(tables_out, type.convert, as.is = TRUE)\n  }\n  \n  return(tables_out)\n  \n}\n\n\n\n\nClick to expand the .rectangularise_table() definition.\n\n\n.rectangularise_table &lt;- function(\n    table_cells,  # docx_summary output filtered for 'table cells' only\n    assume_headers = TRUE  # assume headers in first row?\n) {\n  \n  # Check inputs\n  \n  is_table_cells &lt;- all(table_cells[[\"content_type\"]] == \"table cell\")\n  is_one_table &lt;- length(unique(table_cells[[\"doc_index\"]])) == 1\n  \n  if (!is_table_cells | !is_one_table) {\n    stop(\n      paste(\n        \"Argument 'table_cells' must be a dataframe created with\",\n        \"'officer::docx_summary' where 'content_type' is filtered for\",\n        \"'table cell' only.\"\n      ),\n      call. = FALSE\n    )\n  }\n  \n  # Split each Word table into a list element, isolate headers and cell contents\n  cell_id_split &lt;- split(table_cells, table_cells[[\"cell_id\"]])\n  headers &lt;- lapply(cell_id_split, function(x) x[x[[\"is_header\"]], \"text\"])\n  content &lt;- lapply(cell_id_split, function(x) x[!x[[\"is_header\"]], \"text\"])\n  table_out &lt;- as.data.frame(content)\n  \n  # Column headers are identified by TRUE in the is_header column, but may not\n  # be marked up as such. Use them as dataframe headers if they exist.\n  has_headers &lt;- length(unlist(headers)) &gt; 0\n  if (has_headers) {\n    names(table_out) &lt;- headers\n  }\n  \n  # If headers are not identified by is_header, assume that the first row of the\n  # Word table contains the headers. The user can control this behaviour with\n  # the argument assume_headers.\n  if (!has_headers & assume_headers) {\n    headers &lt;- table_out[1, ]  # assume first row is headers\n    table_out &lt;- table_out[2:nrow(table_out), ]  # rest of table is content\n    names(table_out) &lt;- headers\n  }\n  \n  return(table_out)\n  \n}\n\n\nYouâ€™ll notice the assume_headers argument. The headers for a Word table are marked by TRUE in the is_header column of the output from docx_summary(). Except when they arenâ€™t. Itâ€™s possible that youâ€™ll read a Word doc where the table headers arenâ€™t identified. Set assume_headers to TRUE (the default) to allow rectangularise_table() to instead use the first row of the table as headers. The setting will apply to all tables; I reckon that itâ€™s all or nothing whether table headers will be marked up in a given Word document.\nYou may also have seen the type_convert argument5. By default, the text column in the output from docx_summary() will be character class, but the actual data might be integers, for example. As explained in a recent blog post, the type.convert() function attempts to coerce a column to the appropriate data type if possible.\nAnd now we can see that the dataset works using our test document:\n\ndf_list &lt;- rectangularise_tables(doc_tidy)\nstr(df_list)\n\nList of 2\n $ doc_index_3:'data.frame':    3 obs. of  5 variables:\n  ..$ mpg : num [1:3] 21 21 22.8\n  ..$ cyl : int [1:3] 6 6 4\n  ..$ disp: int [1:3] 160 160 108\n  ..$ hp  : int [1:3] 110 110 93\n  ..$ drat: num [1:3] 3.9 3.9 3.85\n $ doc_index_5:'data.frame':    3 obs. of  5 variables:\n  ..$ Ozone  : int [1:3] 41 36 12\n  ..$ Solar.R: int [1:3] 190 118 149\n  ..$ Wind   : num [1:3] 7.4 8 12.6\n  ..$ Temp   : int [1:3] 67 72 74\n  ..$ Month  : int [1:3] 5 5 5\n\n\nSmashing. We have a list of two dataframes: one for each of the tables in the test document. I took the liberty of naming the list elements like doc_index_* so you can trace which doc_index they were in the original output from docx_summary()."
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "href": "posts/2023-06-07-rectangular-officer/index.html#prisonr",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "PrisonR",
    "text": "PrisonR\nTo summarise, this is absolutely not the worst code-related crime Iâ€™ve committed on this blog. Sorry guv! Iâ€™ll definitely be sentenced to the most severe punishment if caught and tried: several minutes of hard labour, or â€˜refactoringâ€™ as they call it on the inside.\nAt worst Iâ€™ll build an Andy-Dufresne-style tunnel out of my prison cell and hide the entrance behind years of accumulated hex stickers.\n\n Note\nAs a bonus, I later wrote a quick reproducible example that part-solves the original reason for this post. Here Iâ€™ve used {docxtractr} to extract tables from docx files in separate subfolders and then combine them.\n\n\nClick to expand code.\n\n\n# Attach packages (all are available from CRAN)\nlibrary(docxtractr)  # to extract tables from docx files\nlibrary(officer)  # to create dummy docx files\nlibrary(charlatan)  # to generate fake data\n\n# Create multiple dummy docx files in separate temporary folders\n\nmy_folder &lt;- tempdir()  # temporary locations to store the files\nn_files &lt;- 5  # the number of dummy files to generate\n\nfor (i in seq(n_files)) {\n  \n  # Create subfolders\n  subfolder_name &lt;- paste0(\"subfolder_\", i)\n  dir.create(file.path(my_folder, subfolder_name))\n  \n  # Create dummy dataframe\n  \n  n_fake &lt;- 10  # number of fake data items to generate\n  \n  temp_df &lt;- data.frame(\n    name = ch_name(n_fake),\n    job = ch_job(n_fake),\n    phone = ch_phone_number(n_fake)\n  )\n  \n  # Add dummy dataframe to a docx file and save it\n  path &lt;- file.path(my_folder, subfolder_name, paste0(\"df_\", i, \".docx\"))\n  officer::read_docx() |&gt; body_add_table(temp_df) |&gt; print(target = path)\n  \n}\n\n# Get the file paths to all the docx files\ndocx_paths &lt;- list.files(\n  my_folder,\n  pattern = \".docx$\",\n  full.names = TRUE,  # return full filepaths\n  recursive = TRUE  # look in all subfolders\n)\n\n# Preallocate a list to be filled with extracted tables, one element per file\nextracted_tables &lt;- vector(\"list\", n_files)\n\n# Extract tables and add to the list (not tested: I think that read_docx will\n# read .doc files, but only if you have LibreOffice installed.\nfor (i in docx_paths) {\n  tables &lt;- docxtractr::read_docx(i) |&gt; docx_extract_all_tbls()\n  extracted_tables[basename(i)] &lt;- tables\n}\n\n# In this simple demo, the dataframes in each list element can be appended\n# because they all have the same column names and types.\ndo.call(rbind, extracted_tables)"
  },
  {
    "objectID": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "href": "posts/2023-06-07-rectangular-officer/index.html#environment",
    "title": "Rectangularise Word tables extracted by {officer}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:05:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] officer_0.6.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] xml2_1.3.5        cli_3.6.1         zip_2.3.0         askpass_1.1      \n[13] openssl_2.1.0     textshaping_0.3.6 systemfonts_1.0.4 compiler_4.3.1   \n[17] rstudioapi_0.15.0 tools_4.3.1       ragg_1.2.5        evaluate_0.21    \n[21] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[25] uuid_1.1-0"
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#tldr",
    "href": "posts/2021-11-27-long-fns/index.html#tldr",
    "title": "R has obscenely long function names",
    "section": "tl;dr",
    "text": "tl;dr\nUse ls() on a package name in the form \"package:base\" to see all the objects it contains. Iâ€™ve done this to find the longest (and shortest) function names in base R and the {tidyverse} suite."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#naming-things",
    "href": "posts/2021-11-27-long-fns/index.html#naming-things",
    "title": "R has obscenely long function names",
    "section": "Naming things",
    "text": "Naming things\nI try to keep to a few rules when creating function names, like:\n\nuse a verb to make clear the intended action, like get_badge() from {badgr}\nstart functions with a prefix to make autocomplete easier, like the dh_*() functions from {dehex}\ntry to be descriptive but succinct, like r2cron() from {dialga}\n\nIt can be tricky to be succinct. Consider the base R function suppressPackageStartupMessages()1: itâ€™s a whopping 30 characters, but all the words are important. Something shortened, like suppPkgStartMsg(), wouldnâ€™t be so clear.\nIt made me wonder: whatâ€™s the longest function name in R?2\nBut! It seems tricky and time consuming to find the longest function name from all R packages. CRAN alone has over 18,000 at time of writing.\nA much easier (lazier) approach is to focus on some package subsets. Iâ€™ll look at base R and the {tidyverse}."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#the-long-and-the-short-of-it",
    "href": "posts/2021-11-27-long-fns/index.html#the-long-and-the-short-of-it",
    "title": "R has obscenely long function names",
    "section": "The long and the short of it",
    "text": "The long and the short of it\n\nBase R\nCertain R packages are built-in and attached by default on startup.\n\nbase_names &lt;- sessionInfo()$basePkgs\nbase_names\n\n[1] \"stats\"     \"graphics\"  \"grDevices\" \"utils\"     \"datasets\"  \"methods\"  \n[7] \"base\"     \n\n\nHow can we fetch all the functions from these packages? We can use ls() to list all their objects, supplying the package name in the format \"package:base\", for example. Note that I said â€˜objectsâ€™, not â€˜functionsâ€™, since it will also return names that refer to things like datasets.\nFor fun, we can use this as an excuse to demo â€˜lambdaâ€™ syntax and the dogâ€™s balls approach to function-writing, both introduced in R v4.1.3\n\nbase_pkgs &lt;- paste0(\"package:\", base_names)\n\nbase_fns &lt;- lapply(base_pkgs, ls) |&gt;\n  setNames(base_names) |&gt; \n  lapply(\\(object) as.data.frame(object)) |&gt; \n  (\\(x) do.call(rbind, x))()  # the balls ()()\n\nbase_fns$package &lt;- gsub(\"\\\\.\\\\d{,4}$\", \"\", row.names(base_fns))\nrow.names(base_fns) &lt;- NULL\nbase_fns$nchar &lt;- nchar(base_fns$object)\n\nbase_fns &lt;- base_fns[order(-base_fns$nchar), ]\n\nOf the 2465 objects across these packages, a quick histogram shows that the most frequent character length is under 10, with a tail stretching out to over 30.\n\nhist(\n  base_fns$nchar,\n  main = \"Character length of base-object names\",\n  xlab = \"Number of characters\",\n  las = 1\n)\n\n\n\n\nHereâ€™s the top 10 by character length.\n\nbase_fns_top &lt;- base_fns[order(-base_fns$nchar), ]\nrownames(base_fns_top) &lt;- seq(length = nrow(base_fns_top))\nhead(base_fns_top, 10)\n\n                                  object package nchar\n1  aspell_write_personal_dictionary_file   utils    37\n2     getDLLRegisteredRoutines.character    base    34\n3       getDLLRegisteredRoutines.DLLInfo    base    32\n4        reconcilePropertiesAndPrototype methods    31\n5         suppressPackageStartupMessages    base    30\n6          as.data.frame.numeric_version    base    29\n7           as.character.numeric_version    base    28\n8            print.DLLRegisteredRoutines    base    27\n9             as.data.frame.model.matrix    base    26\n10            conditionMessage.condition    base    26\n\n\nSo there are four objects with names longer than suppressPackageStartupMessages(), though they are rarely used as far as I can tell. The longest is aspell_write_personal_dictionary_file(), which has 37(!) characters. Itâ€™s part of the spellcheck functions in {utils}.\nItâ€™s interesting to me that it follows some of those rules for function naming that I mentioned earlier. It has a verb, is descriptive and uses a prefix for easier autocomplete; â€˜aspellâ€™ refers to the GNU open-source Aspell spellchecker on which itâ€™s based.\nIâ€™m intrigued that the function uses snake_case rather than camelCase or dot.case, which seem more prevalent in base functions. You could argue then that the underscores have â€˜inflatedâ€™ the length by four characters. Similarly, the prefix adds another six characters. So maybe the function could be simplified to writePersonalDictionaryFile(), which is merely 27 characters.\nWhat about shortest functions? There are many one-character functions in base R.\n\nsort(base_fns[base_fns$nchar == 1, ][[\"object\"]])\n\n [1] \"-\" \":\" \"!\" \"?\" \"(\" \"[\" \"{\" \"@\" \"*\" \"/\" \"&\" \"^\" \"+\" \"&lt;\" \"=\" \"&gt;\" \"|\" \"~\" \"$\"\n[20] \"c\" \"C\" \"D\" \"F\" \"I\" \"q\" \"t\" \"T\"\n\n\nSome of these will be familiar, like c() to concatenate and t() to transpose. You might wonder why operators and brackets are in here. Remember: everything in R is a function, so `[`(mtcars, \"hp\") is the same as mtcars[\"hp\"]. I have to admit that stats::C() and stats::D() were new to me.\n\n\nTidyverse\nHow about object names from the {tidyverse}?\nTo start, we need to attach the packages. Running library(tidyverse) only loads the core packages of the tidyverse, so we need another approach to attach them all.\nOne method is to get the a vector of the package names with the tidyverse_packages() function and pass it to p_load() from {pacman}, which prevents the need for a separate library() call for each one.4\nFirst, hereâ€™s the tidyverse packages.\n\n Note\nI updated this post in July 2023. The {lubridate} package is now installed as part of the tidyverse and many new functions have appeared across the multitude of packages in the metapackage.\n\n\n# install.packages(\"tidyverse\")  # if not installed\nsuppressPackageStartupMessages(  # in action!\n  library(tidyverse)\n)\ntidy_names &lt;- tidyverse_packages()\ntidy_names\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nAnd now to load them all.\n\n# install.packages(\"pacman\")  # if not installed\nlibrary(pacman)\np_load(char = tidy_names)\n\nOnce again we can ls() over packages in the form \"package:dplyr\". Now the {tidyverse} is loaded, we might as well use it to run the same pipeline as we did for the base packages.\n\ntidy_pkgs &lt;- paste0(\"package:\", tidy_names)\n\ntidy_fns &lt;- map(tidy_pkgs, ls) |&gt;\n  set_names(tidy_names) |&gt; \n  enframe(name = \"package\", value = \"object\") |&gt;\n  unnest(object) |&gt; \n  mutate(nchar = nchar(object))\n\nSo weâ€™re looking at even more packages this time, since the whole tidyverse contains 3071 of them.\nThe histogram is not too dissimilar to the one for base packages, though the tail is shorter, itâ€™s arguably more normal-looking and the peak is perhaps slightly closer to 10. The latter could be because of more liberal use of snake_case.\n\nhist(\n  tidy_fns$nchar,\n  main = \"Character length of {tidyverse} object names\",\n  xlab = \"Number of characters\",\n  las = 1\n)\n\n\n\n\nHereâ€™s the top 10 by character length.\n\nslice_max(tidy_fns, nchar, n = 10)\n\n# A tibble: 11 Ã— 3\n   package       object                            nchar\n   &lt;chr&gt;         &lt;chr&gt;                             &lt;int&gt;\n 1 rlang         ffi_standalone_check_number_1.0.7    33\n 2 googlesheets4 vec_ptype2.googlesheets4_formula     32\n 3 googlesheets4 vec_cast.googlesheets4_formula       30\n 4 cli           cli_progress_builtin_handlers        29\n 5 rstudioapi    getRStudioPackageDependencies        29\n 6 rstudioapi    registerCommandStreamCallback        29\n 7 rlang         ffi_standalone_is_bool_1.0.7         28\n 8 dbplyr        supports_star_without_alias          27\n 9 rstudioapi    launcherPlacementConstraint          27\n10 cli           ansi_has_hyperlink_support           26\n11 ggplot2       scale_linewidth_continuous           26\n\n\nWell there you are: ffi_standalone_check_number_1.0.7() from {rlang} wins the prize with 33 characters. What does it do? The full documentation is literally â€˜Internal API for standalone-types-checkâ€™. Okey doke.\nIntriguingly, the next two are both from {googlesheets4}. The help pages say theyâ€™re â€˜internal {vctrs} methodsâ€™. The names of these are long because of the construction: the first part tells us the method name, e.g.Â vec_ptype2, and the second part tells us that they apply to the googlesheets4_formula S3 class.\nSo maybe these donâ€™t really count because they would be executed as as vec_ptype2() and vec_cast()? And theyâ€™re inflated because they contain the package name, {googlesheets4}, which is quite a long one (13 characters). That would leave cli::cli_progress_builtin_handlers() and rstudioapi::getRStudioPackageDependencies() as the next longest (29 characters). The latter uses camelCaseâ€”which is typical of the {rstudioapi} packageâ€”so isnâ€™t bulked out by underscores.\nOn the other end of the spectrum, thereâ€™s only one function with one character: dplyr::n(). I think it makes sense to avoid single-character functions in non-base packages, because they arenâ€™t terribly descriptive. n() can at least be understood to mean â€˜numberâ€™.\nInstead, hereâ€™s all the two-letter functions from the {tidyverse}. Note that many of these are from {lubridate} and are shorthand expressions that make sense in context, like hm() for hour-minute. You can also see some of {rlang}â€™s operators creep in here, like bang-bang (!!) and the walrus (:=).5\n\ndplyr::filter(tidy_fns, nchar == 2)\n\n# A tibble: 16 Ã— 3\n   package   object nchar\n   &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n 1 cli       no         2\n 2 dplyr     do         2\n 3 dplyr     id         2\n 4 lubridate am         2\n 5 lubridate hm         2\n 6 lubridate ms         2\n 7 lubridate my         2\n 8 lubridate pm         2\n 9 lubridate tz         2\n10 lubridate ym         2\n11 lubridate yq         2\n12 magrittr  or         2\n13 rlang     :=         2\n14 rlang     !!         2\n15 rlang     ll         2\n16 rlang     UQ         2\n\n\nMany of these are due to {lubridate} using single letters to represent time periods, like hm is â€˜hour minuteâ€™. You can also see some symbols from {rlang}, like the good olâ€™ :=, or â€˜walrusâ€™ operator.\nBoth the {dplyr} functions here are no longer intended for use. Iâ€™m sad especially for dplyr::do(): the help page says it â€˜never really felt like it belong[ed] with the rest of dplyrâ€™. Sad.\n\nIn memoriam: do()."
  },
  {
    "objectID": "posts/2021-11-27-long-fns/index.html#environment",
    "href": "posts/2021-11-27-long-fns/index.html#environment",
    "title": "R has obscenely long function names",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:19:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] xml2_1.3.5          rvest_1.0.3         rstudioapi_0.15.0  \n [4] rlang_1.1.1         reprex_2.0.2        readxl_1.4.2       \n [7] ragg_1.2.5          pillar_1.9.0        modelr_0.1.11      \n[10] magrittr_2.0.3      jsonlite_1.8.7      httr_1.4.6         \n[13] hms_1.1.3           haven_2.5.2         googlesheets4_1.1.1\n[16] googledrive_2.1.1   dtplyr_1.3.1        dbplyr_2.3.2       \n[19] cli_3.6.1           conflicted_1.2.0    broom_1.0.5        \n[22] pacman_0.5.1        lubridate_1.9.2     forcats_1.0.0      \n[25] stringr_1.5.0       dplyr_1.1.2         purrr_1.0.1        \n[28] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1       \n[31] ggplot2_3.4.2       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      xfun_0.39         htmlwidgets_1.6.2 gargle_1.5.1     \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.1       generics_0.1.3   \n [9] fansi_1.0.4       pkgconfig_2.0.3   data.table_1.14.8 lifecycle_1.0.3  \n[13] compiler_4.3.1    textshaping_0.3.6 munsell_0.5.0     fontawesome_0.5.1\n[17] htmltools_0.5.5   yaml_2.3.7        cachem_1.0.8      tidyselect_1.2.0 \n[21] digest_0.6.31     stringi_1.7.12    fastmap_1.1.1     grid_4.3.1       \n[25] colorspace_2.1-0  utf8_1.2.3        withr_2.5.0       scales_1.2.1     \n[29] backports_1.4.1   timechange_0.2.0  rmarkdown_2.23    cellranger_1.1.0 \n[33] memoise_2.0.1     evaluate_0.21     knitr_1.43.1      glue_1.6.2       \n[37] DBI_1.1.3         R6_2.5.1          systemfonts_1.0.4 fs_1.6.2"
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#tldr",
    "href": "posts/2023-02-26-nook-s7/index.html#tldr",
    "title": "Repaying Tom Nook with {S7}",
    "section": "tl;dr",
    "text": "tl;dr\nThe R7 S7 object-oriented system is coming to R. Iâ€™ve done a little R6-to-S7 translation on an old project to get a very cursory feel for it, featuring Animal Crossing New Horizons.\n\nâ—ï¸ Warning\nThe S7 system and package are under development and could change at any time, rendering everything in this post useless.1 Heck, last time I checked, the system was called â€˜R7â€™. Thereâ€™s also a chance that S7 elements may have been integrated into base R itself by the time you read this."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#again-oh-no",
    "href": "posts/2023-02-26-nook-s7/index.html#again-oh-no",
    "title": "Repaying Tom Nook with {S7}",
    "section": "2020 again, oh no",
    "text": "2020 again, oh no\nAnimal Crossing New Horizons (ACNH) was the perfect pandemic game. And the pandemic was the perfect time to build an ersatz version of the ACNH in-game banking system to solve an exercise in the Advanced R book using the {R6} package for object-oriented programming (OOP) in R.\nThe exercise helped me fantasize about defeating the gameâ€™s main boss, the predatory loanshark (loanraccoon?) Tom Nook, via endless wire transfers of hard-earned in-game currency, called â€˜Bellsâ€™.\nOf course, a lot has changed since 2020. Most importantly, a new OOP system for R is being developed. Conversely, Tom Nook has not changed. He is still a scourge.\nAnyway, maybe this is a chance to twitch my OOP muscles with this new system."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#oop-they-did-it-again",
    "href": "posts/2023-02-26-nook-s7/index.html#oop-they-did-it-again",
    "title": "Repaying Tom Nook with {S7}",
    "section": "OOP they did it again",
    "text": "OOP they did it again\nThe R Consortiumâ€™s OOP working group has been beavering (raccooning?) away to develop a new OOP system from the ground up: S72 (S3 + S4, geddit?).\nThe idea is to take the best elements of the existing and in-built S3 and S4 systems, interface with them and improve on them.\nYou can read various design docs and meeting minutes on their documentation site, which is housed in their â€˜OOP-WGâ€™ GitHub repo, and try out the current iteration of the associated package, fittingly called {S7}.\nYou should refer to their docs in the first instance, or a useful third party review. For example, Jumping Rivers haveâ€¦ jumped the river on this one and produced a handy intro."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#a-new-horizon-for-oop",
    "href": "posts/2023-02-26-nook-s7/index.html#a-new-horizon-for-oop",
    "title": "Repaying Tom Nook with {S7}",
    "section": "A new horizon for OOP",
    "text": "A new horizon for OOP\nNaturally, I should revisit my post on Repaying Tom Nook with {R6} by replicating it with {S7}. Naturally.\nAha, but actually the {S7} package is more like a development of S3 and S4 objects, and is not a â€˜new versionâ€™ of {R6}! Ah well. Iâ€™m noodling around with {S7} for my own devices and thought Iâ€™d post it here so I can refer back to it later.\nBasically Iâ€™m recycling content from a previous post to get a feel for the new system. But only in the most superficial, basic way. I spent about 15 minutes on this. Look elsewhere for actually-usefully material. You have been warned."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#install",
    "href": "posts/2023-02-26-nook-s7/index.html#install",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Install",
    "text": "Install\nFor now, the {S7} package is in the R Consortiumâ€™s OOP-WG GitHub repo.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"RConsortium/OOP-WG\")\n\nAnd for some glamour weâ€™ll also use the quintessential {emoji} package3\n\ninstall.packages(\"emoji\")  # if not yet installed\nlibrary(emoji)"
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#that-is-class",
    "href": "posts/2023-02-26-nook-s7/index.html#that-is-class",
    "title": "Repaying Tom Nook with {S7}",
    "section": "That is class",
    "text": "That is class\nA new class is constructed withâ€¦ new_class()\nWe can give it a name. We can also give it properties: fields that contain data and can be provided a type check and default value. Itâ€™s possible to build validators for these as well, which ensure that certain conditions are met when the properties are adjusted. Iâ€™ll keep this simple for now: I just want the values to remain equal or greater than zero.\n\nABD &lt;- new_class(\n  name = \"ABD\",\n  properties = list(\n    savings = new_property(class_integer, default = 0L),\n    loan = new_property(class_integer, default = 2498000L)\n  ),\n  validator = function(self) {\n    if (self@savings &lt; 0L) {\n      \"@savings must be zero or more\"\n    } else if (self@loan &lt; 0L) {\n      \"@loan must be zero or more\"\n    }\n  }\n)\n\nFor new methods, you can create a new â€˜genericâ€™ and define a function for it. For example, the â€˜depositâ€™ method is pretty straightforward: it just adds an amount to the current savings value.\n\ndeposit &lt;- new_generic(\"deposit\", \"x\")\n\nmethod(deposit, ABD) &lt;- function(x, amount) {\n  x@savings &lt;- x@savings + amount\n  x\n}\n\nI specified some other methods, but I hid them because theyâ€™re not much more complicated.\n\n\nClick for more methods\n\nThe â€˜withdrawâ€™ method subtracts a specified amount from the savings property. Youâ€™re warned if you specify an amount greater than the amount available.\n\nwithdraw &lt;- new_generic(\"withdraw\", \"x\")\n\nmethod(withdraw, ABD) &lt;- function(x, amount) {\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Withdrew all savings: \", x@savings, \" Bells.\\n\", \n      call. = FALSE\n    )\n    x@savings &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n  }\n  \n  x\n  \n}\n\nThe â€˜payâ€™ method moves funds from savings to loan. Youâ€™re warned if the loan is already paid, if you specify a greater amount than there are savings, or if you pay a greater amount than the loan remaining. Youâ€™ll get a victory message if you pay off the whole loan.\n\npay &lt;- new_generic(\"pay\", \"x\")\n\nmethod(pay, ABD) &lt;- function(x, amount) {\n  \n  if (x@loan == 0L) {\n    stop(\"You already finished paying your loan!\\n\", call. = FALSE)\n  }\n  \n  if (x@savings - amount &lt; 0L) {\n    warning(\n      \"Paid total amount from savings instead: \", x@savings, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@loan &lt;- x@loan - x@savings\n    x@savings &lt;- 0L\n  } else if (x@loan - amount &lt; 0L) {\n    warning(\n      \"Paid total remaining loan instead: \", x@loan, \" Bells.\\n\",\n      call. = FALSE\n    )\n    x@savings &lt;- x@savings - x@loan \n    x@loan &lt;- 0L\n  } else {\n    x@savings &lt;- x@savings - amount\n    x@loan &lt;- x@loan - amount\n  }\n  \n  if (x@loan == 0L) {\n    cat(\n      emoji(\"smiley\"),\n      \"Sweet! I finally finished paying off my very last home loan!\",\n      emoji(\"tada\"), \"\\n\\n\"\n    )\n  }\n  \n  x\n  \n}\n\nThe check method is basically a print method. It reports the loan and savings amounts currently stored in the bank.\n\ncheck &lt;- new_generic(\"check\", \"x\")\n\nmethod(check, ABD) &lt;- function(x) {\n\n  loan_formatted &lt;- format(x@loan, big.mark = \",\", scientific = FALSE)\n\n  savings_formatted &lt;- format(x@savings, big.mark = \",\", scientific = FALSE)\n\n  cat(\"Automatic Bell Dispenser (ABD)\\n\\n\")\n  cat(emoji(\"bell\"), \"Loan Balance:\", loan_formatted, \"Bells\\n\")\n  cat(emoji(\"pig2\"), \"Savings Balance:\", savings_formatted, \"Bells\\n\\n\")\n  cat(\n    \"Please make a selection from the menu below\\n\\n\",\n    emoji(\"house\"), \"pay()\\n\",\n    emoji(\"arrow_up\"), \"deposit()\\n\",\n    emoji(\"arrow_down\"), \"withdraw()\"\n  )\n\n}\n\n\nYou can start a new instance of the ABD class by, yâ€™know, calling it.\n\nbank &lt;- ABD()\n\nWhen you check the class of this object, youâ€™ll see both the custom class name and a reminder that it has the â€˜S7â€™ class.\n\nclass(bank)\n\n[1] \"ABD\"       \"S7_object\"\n\n\nThe vanilla print method exposes the properties and their startup values:\n\nbank\n\n&lt;ABD&gt;\n @ savings: int 0\n @ loan   : int 2498000\n\n\nNote that the properties are prepended with @. This indicates that we can use the â€˜atâ€™ symbol to access these â€˜slotsâ€™ (like S4) from the object, like:\n\nbank@loan\n\n[1] 2498000\n\n\nWhile weâ€™re printing stuff, we can use the check() method (that Iâ€™ve pre-specified) to see the properties in a manner that more closely resembles the game.\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\nðŸ”” Loan Balance: 2,498,000 Bells\nðŸ– Savings Balance: 0 Bells\n\nPlease make a selection from the menu below\n\n ðŸ  pay()\n â¬†ï¸ deposit()\n â¬‡ï¸ withdraw()\n\n\nYou can easily and directly change the properties. To add 10 Bells:\n\nbank@savings &lt;- 9.99\n\nError: &lt;ABD&gt;@savings must be &lt;integer&gt;, not &lt;double&gt;\nHaha, whoops. Remember I specified that the property can only be an integer, so we need to provide an integer value instead of a double value. In other words, we can only provide whole numbers of Bells. Remember that the L suffix is used in R to signify an integer.4\n\nbank@savings &lt;- 10L\n\nIs there an overdraft? Tom Nook would probably love that and would ask for massive overdraft fees, but itâ€™s not programmed into the game. This is where our validator comes in handy. We specified that you canâ€™t have a negative amount of savings, so this causes an error:\n\nbank@savings &lt;- -11L\n\nError: &lt;ABD&gt; object is invalid:\n- @savings must be zero or more\nThatâ€™s fine, but I have sometimes I have extra logic I want to evaluate when I adjust the properties. Thatâ€™s why I created new methods earlier on. It means I can use a function to add to the savings property instead, for example.\n\nbank &lt;- deposit(bank, 10L)\nbank@savings\n\n[1] 10\n\n\nWe can retrieve Bells in this fashion too:\n\nbank &lt;- withdraw(bank, 10L)\nbank@savings\n\n[1] 0\n\n\nWhat if we deposit enough Bells to pay the loan?\n\nbank &lt;- deposit(bank, 2500000L)\nbank &lt;- pay(bank, 2500000L)\n\nWarning: Paid total remaining loan instead: 2498000 Bells.\n\n\nðŸ˜ƒ Sweet! I finally finished paying off my very last home loan! ðŸŽ‰ \n\n\nThe method warns us when we try to pay off a value greater than the remaining loan and prints a nice congratulatory message if weâ€™ve cleared the whole debt.\nAnd so we end up with this view:\n\ncheck(bank)\n\nAutomatic Bell Dispenser (ABD)\n\nðŸ”” Loan Balance: 0 Bells\nðŸ– Savings Balance: 2,000 Bells\n\nPlease make a selection from the menu below\n\n ðŸ  pay()\n â¬†ï¸ deposit()\n â¬‡ï¸ withdraw()\n\n\nHuzzah. Get rekt, raccoon dog. More like Tom Crook amirite."
  },
  {
    "objectID": "posts/2023-02-26-nook-s7/index.html#environment",
    "href": "posts/2023-02-26-nook-s7/index.html#environment",
    "title": "Repaying Tom Nook with {S7}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:26:57 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] emoji_15.0    S7_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         magrittr_2.0.3   \n [5] glue_1.6.2        stringr_1.5.0     knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    lifecycle_1.0.3   cli_3.6.1         compiler_4.3.1   \n[13] rstudioapi_0.14   tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2 stringi_1.7.12"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (â€œCreative Commonsâ€) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an â€œas-isâ€ basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\n\n\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n\nConsiderations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.\nConsiderations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensorâ€™s permission is not necessary for any reasonâ€“for example, because of any applicable exception or limitation to copyrightâ€“then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.\n\n\n\n\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (â€œPublic Licenseâ€). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapterâ€™s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor â€“ Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor â€“ Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapterâ€™s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapterâ€™s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapterâ€™s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapterâ€™s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the â€œLicensor.â€ Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark â€œCreative Commonsâ€ or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-noncommercial-sharealike-4.0-international-public-license",
    "title": "Attribution-NonCommercial-ShareAlike 4.0 International",
    "section": "",
    "text": "By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (â€œPublic Licenseâ€). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\n\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapterâ€™s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nNonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\n\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor â€“ Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor â€“ Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapterâ€™s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.\n\n\n\n\n\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapterâ€™s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapterâ€™s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapterâ€™s License You apply.\n\n\n\n\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\n\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\n\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\n\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\n\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the â€œLicensor.â€ Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark â€œCreative Commonsâ€ or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html",
    "href": "posts/2023-03-15-in-a-dungeon/index.html",
    "title": "Fun and learning. In a dungeon!",
    "section": "",
    "text": "Learn hard and you too can be a mobile gamedev like me."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#tldr",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#tldr",
    "title": "Fun and learning. In a dungeon!",
    "section": "tl;dr",
    "text": "tl;dr\nToday I spoke at a public sector1 event for data scientists2. I said that learning is best when focused into little projects that are fun."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#to-the-point",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#to-the-point",
    "title": "Fun and learning. In a dungeon!",
    "section": "To the point",
    "text": "To the point\nThe abstract sums it up, obviously:\n\nEver done a technical training module and then immediately forgot what you learnt? Do you sometimes feel like youâ€™re ticking boxes instead of actually developing your skills? Yeah, me too. Luckily, more active styles of learning are available. Maybe you can try working on a small, focused project where you can make mistakes and have fun. Iâ€™ve had success with this and, as a bonus, accidentally learnt more than I had planned to. Iâ€™ll give you an example of my experience and some ideas for how you might be able to do it yourself. The talk will involve a detour to an underground cave, but you wonâ€™t need any extra equipment.3\n\nYes, a cheeky teaser there to pique the interest. But everyone came to my talk anyway because it was the only one at that timeslot.\nYou can just look at the slides below if you want (direct link, source). Press â€˜sâ€™ to pop out the speaker notes.\n\n\n\n\n\n\n\n\nThese were made with Revealjs via Quarto, of course."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#on-my-soapbox",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#on-my-soapbox",
    "title": "Fun and learning. In a dungeon!",
    "section": "On my soapbox",
    "text": "On my soapbox\nSo what incredible insight did I bring to the event?\nBasically, I think â€˜module-basedâ€™ learningâ€”often passive video walkthroughs with comprehension exercisesâ€”are too generic and I usually struggle to remember anything from them.\nI think â€˜project-basedâ€™ learning is preferable. Think about what you actually want to learn and develop a small-scope, discrete project around it. Make the subject matter fun. Fail meaningfully by be being open, recording what youâ€™ve found, and involving your community.\nMy contrived soundbite is that module-based is done to you and project-based is done by you.\nIs this a new thought technology? No.Â Is it always true and applicable to everyone in every conceivable scenario and with every learning need? No.Â Whatâ€™s my expertise? None, really. Iâ€™ve just spent a long time in lots of different departments and I can tell you what has worked for me4 as someone who entered the public sector with little computing or coding ability.\nAm I all too aware of how self-indulgent this all sounds? Yes. Did I need a whole talk to explain this? No, probably not. Iâ€™m happy if just one person stops to think about this next time they want to learn something. Iâ€™m also content if one person panicked slightly when they realised that R is a game engine now."
  },
  {
    "objectID": "posts/2023-03-15-in-a-dungeon/index.html#environment",
    "href": "posts/2023-03-15-in-a-dungeon/index.html#environment",
    "title": "Fun and learning. In a dungeon!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:26:56 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.14     yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#tldr",
    "href": "posts/2021-07-10-linkrot/index.html#tldr",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a little function to check web pages for link rot and put it in the tiny R package {linkrot} in case you want to use or improve it."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#page-not-found",
    "href": "posts/2021-07-10-linkrot/index.html#page-not-found",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Page not found",
    "text": "Page not found\nYouâ€™ve clicked a link before and been taken somewhere you werenâ€™t expecting. Sometimes itâ€™s because youâ€™ve been rickrolled,1 sure, but content on the internet is constantly being moved or removed and links break all the time.\nA hyperlink that no longer resolves can be considered to have â€˜rottedâ€™. As time marches on, the â€˜rottennessâ€™ of the internet increases. This can be frustrating.\nThis blog is getting on for a hundred posts over three years. It would not be a surprise if link rot has taken hold. How big is the problem?"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#rising-damp",
    "href": "posts/2021-07-10-linkrot/index.html#rising-damp",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Rising damp",
    "text": "Rising damp\nSo, basically I want to visit every link in every post on this blog and see if itâ€™s still working.2\nIâ€™ve written the function detect_rot() to do this for any given web page and Iâ€™ve put it in the {linkrot} package on GitHub. To install:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/linkrot\")\nlibrary(linkrot)\n\nIn short, the detect_rot() function takes the URL of a web page and returns a tibble with details of each link from that page and whether it can be reached.\nIâ€™ve basically built it for my own amusement, so thereâ€™s no guarantees. Feel free to suggest or amend things in the GitHub repo.\n\nCheck one post\nLetâ€™s feed in the first post on this blog, from April 2018:\n\ntrek_url &lt;- \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\"\ntrek_rot &lt;- detect_rot(trek_url)\n\nChecking &lt;https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/&gt; ..............................\nIt can take a short while for the function to visit every link. To let us know itâ€™s working, the URL is printed to the console and then a period (.) is printed for every link thatâ€™s been successfully visited (a bit like a progress bar).\nWeâ€™re returned an object with a bunch of information.\n\nstr(trek_rot)\n\ntibble [30 Ã— 6] (S3: tbl_df/tbl/data.frame)\n $ page             : chr [1:30] \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\" ...\n $ link_url         : chr [1:30] \"https://www.r-project.org/about.html\" \"https://en.wikipedia.org/wiki/Star_Trek:_The_Next_Generation\" \"http://www.st-minutiae.com/resources/scripts/#thenextgeneration\" \"https://github.com/zeeshanu/learn-regex/blob/master/README.md\" ...\n $ link_text        : chr [1:30] \"R statistical software\" \"Star Trek: The Next Generation\" \"Star Trek Minutiae\" \"regex\" ...\n $ response_code    : num [1:30] 200 200 200 200 200 200 200 404 200 200 ...\n $ response_category: chr [1:30] \"Success\" \"Success\" \"Success\" \"Success\" ...\n $ response_success : logi [1:30] TRUE TRUE TRUE TRUE TRUE TRUE ...\nSo, itâ€™s a tibble with six columns and a row for each link on that page thatâ€™s been checked. Basically, the output tells us the URL and text of each link and also whether the page was reachable or not.\nThe tibble includes a special officially-standardised three-digit â€˜status codeâ€™ in the response_code column. These indicate whether contact was successful, with a specific reason. For example, 200 represents a typical success (â€˜OKâ€™), but you may be familiar with 404 (â€˜not foundâ€™) if youâ€™ve visited a broken link before.\nWe can extract any broken links using the logical response_success column.\n\ntrek_rot[!trek_rot$response_success, c(4, 5, 2)]\n\n# A tibble: 1 x 3\n  response_code response_category link_url                                      \n          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;                                         \n1           404 Client error      https://cran.r-project.org/web/packages/rvestâ€¦\nSo, at time of writing, that post has one broken link: an {rvest} package vignette for SelectorGadget thatâ€™s no longer active on the CRAN site. It has status code 404 (â€˜client errorâ€™), which basically means the thing couldnâ€™t be found.\nWe can confirm this by visiting the URL, but you could also use the {webshot} package to go and retrieve an screenshot of the page3.\n\nlibrary(webshot)\ncran_404 &lt;- trek_rot$link_url[!trek_rot$response_success]\nwebshot(cran_404, vheight = 250)\n\n\nSo thatâ€™s CRANâ€™s 404 page to tell us that the page couldnâ€™t be fetched.\n\n\nCheck whole blog\nNow we know how it works for one page, we can apply the function over every post of this blog and see how many links have rotted.\nFirst we need all the post URLs, which are all available from the blogâ€™s homepage. The links returned are internal (like 2021/06/28/pixel-art/), so we need to add on the https://www.rostrum.blog/ bit. We also need to filter out any links that arenâ€™t posts (like the â€˜Aboutâ€™ page).\n\n# Load packages\nsuppressPackageStartupMessages({\n  library(xml2)\n  library(rvest)\n  library(dplyr)\n  library(purrr)\n})\n\n# The URL of this blog's homepage\nblog_url &lt;- \"https://www.rostrum.blog\"\n\n# Fetch all the links from the blog home page\nblog_hrefs &lt;- \n  read_html(blog_url) %&gt;%  # get full homepage HTML\n  html_nodes(\"a\") %&gt;%      # nodes with links, &lt;a&gt;\n  html_attr(\"href\")        # the URL attribute\n\n# Only links to posts\nposts &lt;- paste0(blog_url, blog_hrefs[grepl(\"^/20\", blog_hrefs)])\ntail(posts)  # preview\n\n[1] \"https://www.rostrum.blog/2018/06/05/tid-ye-text/\"                             \n[2] \"https://www.rostrum.blog/2018/05/25/cloud-pie/\"                               \n[3] \"https://www.rostrum.blog/2018/05/19/pokeballs-in-super-smash-bros/\"           \n[4] \"https://www.rostrum.blog/2018/05/12/accessibility-workshop-at-sprint18/\"      \n[5] \"https://www.rostrum.blog/2018/04/27/two-dogs-in-toilet-elderly-lady-involved/\"\n[6] \"https://www.rostrum.blog/2018/04/14/r-trek-exploring-stardates/\"\nNow we can use {purrr} to iterate the detect_rot() function over the pages. By using map_df() we can get a data frame as output rather than a list. Iâ€™ve hidden the printed output from detect_rot() this time because there would be nearly 100 lines of output (one per post).\n\nresults &lt;- map_df(posts, detect_rot)\n\nSo, this results tibble has 23311 links from 95 posts, or about 25 links per post.\nAgain, we can filter the logical response_success column to see which links werenâ€™t successfully resolved.\n\nrotten &lt;- filter(results, !response_success)\nnrow(rotten)\n\n[1] 61\nSo in total there were 61 links out of 2331 that did not return a â€˜successâ€™, which works out to about 3% being unreachable.\nWe can count the reasons for these failures by looking at the status codes.\n\ncount(rotten, response_code, sort = TRUE)\n\n# A tibble: 6 x 2\n  response_code     n\n          &lt;dbl&gt; &lt;int&gt;\n1           404    53\n2           400     4\n3           403     1\n4           406     1\n5           410     1\n6           502     1\nYou can see most of these status codes are in the 4xx range, which is the group of codes that mean â€˜client errorâ€™. Usually this is a problem with the link youâ€™ve provided, like 404 is â€˜not foundâ€™, 403 is â€˜forbiddenâ€™ and 406 is â€˜not acceptableâ€™.\nItâ€™s hard to tell whether this level of link rot is good or bad, but remember that these are links that have failed within the past three years. Imagine how bad this might look in another 10 years. By comparison, a quarter of links on the New York Times website were completely inaccessible, stretching back to 1996.\nIâ€™d be interested to know whether this is comparable to your blog or website."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#surveying-for-rot",
    "href": "posts/2021-07-10-linkrot/index.html#surveying-for-rot",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Surveying for rot",
    "text": "Surveying for rot\nWeâ€™ve seen it in action, but how does the function work? Iâ€™m not claiming the approach is optimal, but it obviously worked for my needs. Youâ€™ll probably find the approach naive if you have any experience in dealing with HTTP requests from R.\n\nValidate, fetch, check\nYou can find the function definition for detect_rot() in the {linkrot} source code. It has three underlying steps, each of which has a helper function:\n\nCheck that the provided URL is valid with .validate_page()\nScrape the links from the page with .fetch_links()\nVisit each link and check its response code with .check_links()\n\nSo, the URL provided by the user is first checked with help from the {httr} package. We GET() the page and then extract the status_code() and check for an http_error(). If all is well (i.e.Â no error), then we can continue.\nTo get the links from the URL, we first scrape the page with xml2::read_html() and then use {rvest} functions: html_nodes() to grab all the nodes with links, then html_attr() and html_text() to extract the URLs and link text from each.\nFinally, each of the URLs is visited with GET() and the http_status() is extracted. The final data frame is converted to tibble (for ease of reading) and returned to the user.\n\n\nLimitations\nOf course, itâ€™s possible that GET() will fail to reach a page for reasons other than it being missing. Sometimes there can be a momentary blip, but detect_rot() is simple and never retries a link.\nAdditionally, there are some links that {httr} struggles to contact. I wrapped functions internal to detect_rot() inside tryCatch() so any failures appear as NA in the response_code column. The printed output for detect_rot() also displays an exclamation point (!) instead of a period (.) when being run. For example, there were 8 links that had this problem for this blog.\nI welcome any thoughts or suggestions, particularly around testing. Iâ€™d like to use this package as a way to learn proper HTTP testing and have found rOpenSciâ€™s HTTP Testing in R book useful so far. Eventually I might convert detect_rot() to use the {httr2} package when itâ€™s released."
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#now-what",
    "href": "posts/2021-07-10-linkrot/index.html#now-what",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Now what?",
    "text": "Now what?\nI could go back and fix the broken links, but maybe itâ€™s not that big a deal. I donâ€™t have any data on what people click on, so I canâ€™t really tell if itâ€™s worth it.\nBut anyway, didnâ€™t I say â€˜decay is inevitableâ€™? I can fix things, but more things will break.\nI wasnâ€™t expecting this to get quite so existential.4"
  },
  {
    "objectID": "posts/2021-07-10-linkrot/index.html#environment",
    "href": "posts/2021-07-10-linkrot/index.html#environment",
    "title": "Decay is inevitable, accept {linkrot}?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 19:23:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#tldr",
    "href": "posts/2022-04-27-tide/index.html#tldr",
    "title": "Turn the {tide} on Râ€™s secret spreadsheet editor",
    "section": "tl;dr",
    "text": "tl;dr\nR has an interactive spreadsheet editor for dataframes that you can access with edit(). I made the function tide::tide() to generate automatically some code that will reproduce the changes you made manually with edit()."
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#edit",
    "href": "posts/2022-04-27-tide/index.html#edit",
    "title": "Turn the {tide} on Râ€™s secret spreadsheet editor",
    "section": "Edit",
    "text": "Edit\nRâ€™s edit() function invokes a text editor so you can amend an R object.1\nSomething special happens If you edit() a data.frame object: a somewhat-janky interactive spreadsheet-like editor appears in a new window.2\nClick in a cell to amend a value, or click in the header for a menu that lets you change the column name, or switch between real and character classes. There are even buttons to copy and paste values.\nClick the â€˜quitâ€™ button to confirm your changes. The edited data is returned to you back in the console.\nBut thatâ€™s not very reproducible. How can anyone recreate the amended dataframe from the original if your clicks and keypresses werenâ€™t recorded?\nCan we make edit() more reproducible?"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#tide",
    "href": "posts/2022-04-27-tide/index.html#tide",
    "title": "Turn the {tide} on Râ€™s secret spreadsheet editor",
    "section": "Tide",
    "text": "Tide\nBasic premise: create a function that accepts a dataframe as input, opens the edit menu, observes the updated values and generates code to reproduce the new object from the old.\nIâ€™ve created the concept package, {tide}, to do this.3 It has only one, eponymous function: tide().\nWhy â€˜tideâ€™? Well, itâ€™s â€˜editâ€™ backwards. And weâ€™re â€˜turning the tideâ€™ on the edit() function to make it reproducible, geddit?4\nYou can install {tide} from GitHub. The {clipr} package, which can copy text to your clipboard, will also be installed.\n\nif (!require(remotes)) install.packages(\"remotes\")\ninstall_github(\"matt-dray/tide\")\n\nSo letâ€™s get our feet wet with an example. Hereâ€™s a thematically-related data.frame of the tide table for London Bridge for May 1 2022.\n\ntide_table &lt;- data.frame(\n  type = c(\"High\", \"Low\", NA_character_, \"Low\"),\n  time_bst = c(\"02:58\", \"09:42\", \"15:20\", \"21:58\"),\n  height_m = c(7.0, 0.5, 6.9, 70)\n)\n\ntide_table\n\n  type time_bst height_m\n1 High    02:58      7.0\n2  Low    09:42      0.5\n3 &lt;NA&gt;    15:20      6.9\n4  Low    21:58     70.0\n\n\nBut whoops: the missing value should be â€˜Highâ€™ and the height is wrong by two orders of magnitude for the 21:58 low tide.\nSo, letâ€™s use tide::tide() on the dataframe to edit those values.\n\nlibrary(tide)\ntide(tide_table)\n\nThis opens a separate data-editor window. Hereâ€™s how it looks when it opens:5\n\nAnd once Iâ€™ve made the adjustments manually:\n\nAnd hereâ€™s whatâ€™s returned to the console once Iâ€™ve clicked the â€˜Quitâ€™ button:\nWrote code to clipboard\n##   type time_bst height_m\n## 1 High    02:58      7.0\n## 2  Low    09:42      0.5\n## 3 High    15:20      6.9\n## 4  Low    21:58      0.7\nYou can see the edits have been successfully returned. This is also what youâ€™d see if you just used edit().\nThe extra feature from tide() is evident in the message Wrote code to clipboard: the function generated some lines of code that will take you from the original to the edited object.\nSo if we now paste from the clipboard we get:\n\ntide_table[3, 1] &lt;- \"High\"\ntide_table[4, 3] &lt;- 0.7\n\nIn other words, â€˜replace the value in row 3, column 1 of the tide_table object with the string value \"High\"â€™, for example.\nAnd if we actually run those lines, we can recreate the amended data.frame from the original:\n\ntide_table\n\n  type time_bst height_m\n1 High    02:58      7.0\n2  Low    09:42      0.5\n3 High    15:20      6.9\n4  Low    21:58      0.7\n\n\nSo, hurrah, we now have a method of manually editing the table and getting some code back that can reproduce it."
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#diet",
    "href": "posts/2022-04-27-tide/index.html#diet",
    "title": "Turn the {tide} on Râ€™s secret spreadsheet editor",
    "section": "Diet",
    "text": "Diet\nTo borrow another anagram of â€˜editâ€™ the capability of the package is quiteâ€¦ lightweight. Some issues are that:\n\nthe function currently only works if you amend individual values (cells), not if you change headers, or add rows and columns\nthe returned code will operate on a cell-by-cell basis, so you might get x[1, 1] &lt;- \"A\" and x[2, 1] &lt;- \"B\" where actually it could have been the more convenient to get x[1:2, 1] &lt;- c(\"A\", \"B\")\nthe returned code refers to columns by index, even though itâ€™s more explicit to refer to them by name, like x[1, \"col1\"] &lt;- \"A\"\nthe returned code will be written in base R and will edit in place by index (i.e.Â [&lt;-), it doesnâ€™t return {data.table}- or tidyverse-compliant code\nyou only get the code in your clipboard, it isnâ€™t returned from the function\n\nI might update the package to handle this stuff in future, or you can do it for me with a pull request in the GitHub repo.\nBut to be honest, the data editor is probably a bit too clunky and simple to be useful for most use cases. So thereâ€™s not much point expanding this package beyond a concept.\nOr maybe the approach will pick up pace like the Severn Estuary tidal bore, who knows? Or maybe you think this post is a bore.6"
  },
  {
    "objectID": "posts/2022-04-27-tide/index.html#environment",
    "href": "posts/2022-04-27-tide/index.html#environment",
    "title": "Turn the {tide} on Râ€™s secret spreadsheet editor",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:36:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#tldr",
    "href": "posts/2021-08-10-dehex/index.html#tldr",
    "title": "Read a hex colour code with {dehex}",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote an R package, {dehex}, that helps you learn to â€˜readâ€™ a hex colour code by eye according to David DeSandroâ€™s method. Check out his mindblowing talk."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#hue-are-you",
    "href": "posts/2021-08-10-dehex/index.html#hue-are-you",
    "title": "Read a hex colour code with {dehex}",
    "section": "Hue are you?",
    "text": "Hue are you?\nHex codes are used in computing to encode a colour as a succinct six-digit alphanumeric string, like #F4D82A.\nThese codes are written in hexadecimal (hence â€˜hexâ€™): they can take the characters 0 to 9 and A to F, which encodes 16 possible values. This encodes 16 million colours total, which are easy for computers to store and interpret.\nEach pair of characters basically encodes red, green and blue. For example, the code #FF000 is â€˜redâ€™. It uses the highest of these hex values, â€˜Fâ€™, in both of the â€˜redâ€™ positions, while the green and blue pairs are zero.\nThatâ€™s easy enough to decipher, but what about #8ACD52 or #C0FFEE?1 You could copy these into a tool that returns colour information (many search engines can do this now) but they often return a sample and not the colourâ€™s name.\nIâ€™m red-green colourblind and have difficulty identifying and talking about colours, so thatâ€™s not always helpful."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#the-desandro-method",
    "href": "posts/2021-08-10-dehex/index.html#the-desandro-method",
    "title": "Read a hex colour code with {dehex}",
    "section": "The DeSandro Method",
    "text": "The DeSandro Method\nDavid DeSandro of Metafizzy gave a talk at the dotCSS conference in 2018 about his superpower: â€˜readingâ€™ a hex colour code by eye.2\nHis talk is comprehensive and has excellent visuals. I strongly recommend that you watch his explanation if you find this topic interesting. You can also find the slides and a great written explanation on his blog. I cannot do justice here to such a powerful thought technology.\nIn short, itâ€™s possible to look at a hex code like #F2D359 and get the rough hue, saturation and lightness of the colour it encodes, which you can speak as an English phrase like â€˜light washed yellowâ€™. David, too, is colourblind and has found success with his method.\nThis post isnâ€™t about colour theory and Iâ€™m definitely not an expert, but the point of the method is that you donâ€™t need to be one."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#introducing-dehex",
    "href": "posts/2021-08-10-dehex/index.html#introducing-dehex",
    "title": "Read a hex colour code with {dehex}",
    "section": "Introducing {dehex}",
    "text": "Introducing {dehex}\n\n\n\nThis is a hex logo, but it has a white background.\n\n\nRight, so Iâ€™ve made a small R package called {dehex} that you can use to:\n\nTrain yourself to read hex codes with the DeSandro Method\nReturn a rough English phrase for a given hex code\n\nAll from your R console.\nThe package is on GitHub and you can install with the help of {remotes}.\n\nremotes::install_github(\"matt-dray/dehex\")\n\nThe reason for the name should be obvious: youâ€™re â€˜dehexingâ€™, i.e.Â converting from hex. But also I like the connotation of removing a â€˜hexâ€™ as in a spell. The colour is cursed; itâ€™s trapped behind a code.\nUsual warnings: the package needs a refactor, thereâ€™s probably some bugs, but it works for me. Drop an issue or PR in the GitHub repo with any ideas or suggestions.\n\nCheat codes\nYou are thinking:\n\nUgh, this sounds like effort, just tell me what colour my hex code is\n\nSo Iâ€™m going to show you immediately how to retrieve an English phrase and a colour sample for a given hex code. Probably this is the most useful bit of the package for users who donâ€™t want to become a hex mentat.3\nSince weâ€™re â€˜solvingâ€™ the hex code, the function is called dh_solve().4 It outputs a text string.\n\ndehex::dh_solve(\"#F2D359\")\n\n[1] \"light washed yellow\"\n\n\nIf you set swatch to TRUE, then youâ€™ll get a plot filled with that colour as well.\n\ndehex::dh_solve(\"#F2D359\", swatch = TRUE)\n\n\n\n\n[1] \"light washed yellow\"\n\n\nHow lovely.\n\n Note\nI later noticed that the package {ColorNameR} exists, which has the express purpose of taking a colour code and returning a name for that colour.\n\n\n\nLearning is fun\nFor the more adventurous, you can use {dehex} to learn how to read a hex code with DeSandroâ€™s method from your R console.\nThereâ€™s five steps:\n\nSimplify from a six- to a three-digit hex code\nCreate a bar chart from the RGB values encoded by the short hex\nAssess hue (red, orange, violet, etc) from the chartâ€™s â€˜shapeâ€™\nAssess saturation (â€˜saturatedâ€™, â€˜washedâ€™, etc) from the range of the RGB values\nAssess lightness (â€˜darkâ€™, â€˜middleâ€™, â€˜lightâ€™) from the total of the RGB values\n\nIâ€™ve incorporated each of these into {dehex}, plus a method for getting the answer.\n\n1. Three-digit code\nTurns out that the first value of each pair is the important one when determining colour, so you can shorten the standard six-digit hex code to just three digits.\nThatâ€™s easy enough to do in your head, but the function dh_shorten() does it for you:\n\nhex_code &lt;- \"#F2D359\"\nshort_code &lt;- dehex::dh_shorten(hex_code)\nshort_code\n\n[1] \"#FD5\"\n\n\nAs it happens, the short code is still recognised by interpreters, but itâ€™s often expanded double up each value to get back to six. So #FD5 is technically #FFDD55 rather than the original #F2D359, but that doesnâ€™t really matter for our purposes.\n\n\n2. RGB graph\nThe values in the shortcode encode an â€˜amountâ€™ of red, green and blue. The lowest value is 0 and the highest is F, which is hexadecimal for 15. The higher the value, the more thatâ€™s â€˜mixedâ€™ into the final colour.\nYou can use dh_graph() to create this for you automatically. Rather than generate a plot though, we can just print a cute bar graph to the console. Weâ€™re only using it for reference, after all.\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = FALSE, adorn_l = FALSE\n)\n\n#FD5\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\n\n\nFor whatever reason, certain browsers struggle to render these graph outputs correctly in this blog post (seems fine in Firefox). In your console, the graphs will appear with neat â€˜continuousâ€™ bars instead of as individual blocks. Example in a dark theme editor:\n\nThe output is a horizontal chart showing the values of red (R), green (G) and blue (B) encoded by the hex short code. Each bar is made from 16 unicode block elements (i.e.Â 0 to 15), which are â€˜filledâ€™ to represent the amount of each colour.\nIf youâ€™re using RStudio, this will print in colour, thanks to the {crayon} package (although you can turn it off with the argument crayon = FALSE). That looks like this using RStudioâ€™s default light theme:\n\nOr, using a dark theme:\n\nPerhaps youâ€™re wondering what the adorn_* arguments do in dh_graph(). They add extra information to the output that will help us in steps 3 to 5. Iâ€™ll switch these on as we go through those next steps.\n\n\n3. Hue\nFor our purposes, hue is basically a name we give a colour, like â€˜orangeâ€™. Weâ€™re going to compare the â€˜profileâ€™ or â€˜shapeâ€™ of our RGB graph to a number of others to determine which one most closely resembles ours.\nFor simplicity, we stick only to the primary, secondary and tertiary colours in the RGB colour system: red, green and blue; yellow, cyan, magenta; orange, chartreuse, aquamarine, azure, violet and rose. We also include a special case: grey.5\nThe {dehex} package has a built in guide that will print RGB graphs for each of these colours. Since this is a guide for hue, you pass the argument \"H\". Iâ€™ve hidden the output, since there are 13 graphs.\n\ndehex::dh_guide(\"H\")\n\n\n\nClick to expand the hue guides\n\n\n\nred\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nG â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\n\ngreen\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\n\nblue\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nG â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\n\nyellow\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\n\ncyan\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\n\nmagenta\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nG â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\n\norange\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\n\nchartreuse\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\n\naquamarine\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\n\nazure\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\n\nviolet\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nG â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\n\nrose\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nG â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\n\ngrey\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 2\n\n\n\nYou can see that Iâ€™ve added a value to the end of each bar, which represents the ranking of the RGB values. This follows the logic of the rank() function in base R: 1 is smallest, 3 is largest and ties are the average of the shared ranks. However, Iâ€™ve increased the tolerance for ties.6\nWhich of the graphs in the hue guide most closely resemble our colour?\nYou might be able to see by eye that itâ€™s probably yellow, but we look at our graph again but this time with adorn_h set to TRUE (the default).\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = TRUE, adorn_s = FALSE, adorn_l = FALSE\n)\n\n#FD5\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ H 2.5\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\n\n\nSo, we have an RGB hue ranking of 2.5-2.5-1, which indeed matches the â€˜yellowâ€™ ranks in the guide, even if the RGB values are not exactly the same.\nI admit this step is quite clunky and it doesnâ€™t help that thereâ€™s so many plots to compare against. Itâ€™s easier I think when you have a colour wheel arrangement to look at, like in DeSandroâ€™s talk. Remember: with {dehex}â€™s help, you just need to look at the ranking values at the end of each bar.\n\n\n4. Saturation\nNow we repeat the process for saturation. This time weâ€™re going to compare the range of RGB values. This is easier because thereâ€™s only three (â€˜saturatedâ€™, â€˜washedâ€™ and â€˜mutedâ€™) plus grey (i.e.Â zero range).\nThis time we pass \"S\" for the saturation guide:\n\ndehex::dh_guide(\"S\")\n\n\n\nClick to expand the saturation guides\n\n\n\nsaturated\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n\nwashed\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\n\nmuted\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘\n\ngrey\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\n\n\n\nThis time thereâ€™s an additional bar for saturation, labelled â€˜Sâ€™, that indicates the range of RGB values covered by each level of saturation. We can compare the saturation of our colour with the adorn_s argument set to TRUE.\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = TRUE, adorn_l = FALSE\n)\n\n#FD5\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n\n\nSo, thatâ€™s roughly the range of the â€˜washedâ€™ category of saturation.\n\n\n5. Lightness\nFinally, we do the same for the lightness of the colour (â€˜lightâ€™, â€˜middleâ€™ and â€˜darkâ€™. You can total up the values, where higher values are lighter, but Iâ€™ve chosen to mark the mean value in {dehex} because I think itâ€™s easier to interpret from the graph format.\nProvide \"L\" for lightness to the dh_guide() function:\n\ndehex::dh_guide(\"L\")\n\n\n\nClick to expand the lightness guides\n\n\n\nlight\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘\n\nmiddle\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\n\ndark\nR â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nL â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\n\n\n\nAnd again, hereâ€™s the chart for our colour showing a column for lightness:\n\ndehex::dh_graph(\n  short_code,\n  adorn_h = FALSE, adorn_s = FALSE, adorn_l = TRUE\n)\n\n#FD5\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘\n\n\nYep, slightly on the higher end, so itâ€™s a lighter colour.\n\n\nSolution\nIf you followed these steps, youâ€™ll have seen that #F2D359 is roughly â€˜light washed yellowâ€™.\nSo, {dehex} can therefore be used as a â€˜training deviceâ€™ to guide you through this process.\nThe idea is that you remember the hue shapes (relatively hard because thereâ€™s lots), the saturation ranges (i.e.Â wider range means more saturated) and lightness averages (i.e.Â higher is lighter) from the guides and compare your colour to those.\nYou can check your answer (or cheat, of course) by using dh_solve(). I showed this earlier in the post, but it also has the option to see all the matching charts for hue, saturation and lightness:\n\ndehex::dh_solve(hex_code, graphs = TRUE)\n\ninput code: #FD5\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ H 2.5\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\nS â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘\n\nhue: yellow\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 2.5\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1\n\nsaturation: washed\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\n\nlightness: light\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘\n\n\n[1] \"light washed yellow\"\n\n\nHere you can see the selected guides that best matched the input.\n\n\n\nTest yourself\nIf youâ€™re really serious about this, youâ€™ll want to practice with random hex codes, of course. Lucky for you Iâ€™ve included a function that will generate them.\nSee if you can work out what this colour is using the guides and method above and then check your answer in the details block below.\n\nset.seed(2021)\nrando_hex &lt;- dehex::dh_random()\nrando_hex\n\n[1] \"#76EA7C\"\n\n\n\n\nClick here for the solution\n\n\ndehex::dh_solve(rando_hex, swatch = TRUE, graphs = TRUE)\n\n\n\n\ninput code: #7E7\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ H 3\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nS â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘\n\nhue: green\nR â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ H 3\nB â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ H 1.5\n\nsaturation: washed\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nS â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘\n\nlightness: middle\nR â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘\nG â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\nB â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\nL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘\n\n\n[1] \"middle washed green\"\n\n\n\nDid you get it right?"
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#dream-of-colourfornication",
    "href": "posts/2021-08-10-dehex/index.html#dream-of-colourfornication",
    "title": "Read a hex colour code with {dehex}",
    "section": "Dream of colourfornication",
    "text": "Dream of colourfornication\nAs ever, this package and post are a Showerthought That Became Real (possible tagline for this blog); something to fill my free time.\nAt very least Iâ€™ve got a better idea of identifying hex-encoded colours without looking them up and getting confused when presented with an unnamed block of colour that my deuteronopic eyes canâ€™t understand.\nIâ€™m developing a Shiny app to make this more of an interactive tool that you can use without even needing access to R. I canâ€™t promise itâ€™ll be ready any time soon.\nAnyway, go and watch/read David DeSandroâ€™s materials and do drop an issue or PR in the {dehex} GitHub repo if you have any contributions."
  },
  {
    "objectID": "posts/2021-08-10-dehex/index.html#environment",
    "href": "posts/2021-08-10-dehex/index.html#environment",
    "title": "Read a hex colour code with {dehex}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:30:19 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] magrittr_2.0.3    knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23   \n [9] lifecycle_1.0.3   cli_3.6.1         grid_4.3.1        vctrs_0.6.3      \n[13] compiler_4.3.1    purrr_1.0.1       rstudioapi_0.15.0 tools_4.3.1      \n[17] evaluate_0.21     yaml_2.3.7        dehex_0.1.2       crayon_1.5.2     \n[21] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#tldr",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#tldr",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve updated the {pixeltrix} package so you can create animated sprite gifs with a simple, interactive pixel editor from within Râ€™s plot window."
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#pix-all-the-right-boxes",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#pix-all-the-right-boxes",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Pix all the right boxes",
    "text": "Pix all the right boxes\nThe {pixeltrix} packageâ€”which Iâ€™ve written about beforeâ€”lets you open an interactive R plot that you can click to turn â€˜pixelsâ€™ on and off.\nI created it for one purpose: to quickly create simple, blocky sprites for my {tamRgo} package, which lets you keep a persistent cyberpet on your computer (yes, really).\nBut wouldnâ€™t it be nice if {pixeltrix} were moreâ€¦ general? Read on for a couple of improvements to the package that might help.\n\n Note\nThe package has been updated again since this post. From version 0.2 you:\n\ncan provide colours as input to click_pixels() and frame_pixels()\nreceive a colours attribute with the output matrices, which encodes the state and colour values"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#pixellate-to-accumulate",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#pixellate-to-accumulate",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Pixellate to accumulate",
    "text": "Pixellate to accumulate\nFirst, you can install the updated package from GitHub:\n\nremotes::install_github(\"matt-dray/pixeltrix\")  # v0.1.2 in this post\nlibrary(pixeltrix)\n\nNow the improvements: plotting with colour, and creating gif animations.\n\n1. Plot\nThe click_pixel() function opens an interactive plot. If n_state = 3, for example, then each pixel will cycle through three states as you keep clicking it. Youâ€™re returned a matrix of these values when you hit Esc.\nThat was enough for {tamRgo}: I turned a binary matrix into a 1-bit sprite. But wouldnâ€™t it be goodâ€”fundamental!â€”to be able to plot the matrix as an image with user-specified colours? So I made draw_pixels().\nIâ€™ve added a three-state matrix, blue, into the package as an example dataset. Letâ€™s plot it with simple colours:\n\ndraw_pixels(\n  m = pixeltrix::blue, \n  colours = c(\"white\", \"#879afb\", \"gray20\")\n)\n\n\nOf course, itâ€™s the subtly-coloured player character from PokÃ©mon Blue (1996) as seen on the Nintendo Game Boy Color.\n\n\n2. Animate\nNaturally, you could use click_pixels() and draw_pixels() to generate several images and combine them as â€˜framesâ€™ of an animation. Why not have a function that does this automatically?\nSo thatâ€™s what I did:\n\nframe_pixels() calls click_pixels() and adds the output as the first element of a list, then it passes that matrix into edit_pixels() as the template for the next frame (and so on until you choose to stop making frames)\ngif_pixels() takes the list of matrices created by frame_pixels() and draws, combines and writes them to a gif\n\nIâ€™ve prepared pixeltrix::mario as an example of an output from frame_pixels(). It contains each of three frames that comprise Marioâ€™s walk cycle from Super Mario Bros on the NES.\nHereâ€™s what the console output looked like when I made mario:\n\nmario &lt;- frame_pixels(\n  n_rows   = 16,\n  n_cols   = 16,\n  n_states = 4  # background + 3 colours\n)\n\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nAdd a frame? y/n: y\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nCurrent frame count: 2\nAdd a frame? y/n: y\nClick squares in the plot window. Press &lt;Esc&gt; to end.\nCurrent frame count: 3\nAdd a frame? y/n: n\nFinal frame count: 3\nYou can see thereâ€™s interactivity; the user is prompted to add another frame with Add a frame? y/n:, where y will let you create a new frame and n will stop the process and return the list of matrices.\nAnd so you can see itâ€™s a list of three matrices:\n\nstr(mario)\n\nList of 3\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 1 1 ...\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 0 0 ...\n $ : int [1:16, 1:16] 0 0 0 0 0 0 0 0 0 0 ...\n\n\nYou can then convert the list to a gif with gif_pixels(), which engifs the frames using {gifski}.1\n\ngif_pixels(\n  frames = mario,\n  colours = c(\n    \"white\",    # background\n    \"#FDA428\",  # skin (yellowish)\n    \"#FC0D1B\",  # overalls/hat (red)\n    \"#A32B2E\"   # hair, eyes, shirt, boots (brown)\n  ),\n  file = \"mario.gif\",\n  delay = 0.15  # passed via dots to gifski::save_gif()\n)\n\nInserting image 3 at 0.30s (100%)...\nEncoding to gif... done!\n[1] \"mario.gif\"\nAnd if we open that file:\n\nYahoooooo, created entirely with R. Noice.\n\n\nPix n mix\nSo {pixeltrix} finally got a couple of nice-to-have (well, must-have) functions. This is enough for me to continue just messing around with it as a novelty2.\nI mean, come on: animated pixelart created in an interactive R plot window? Why? I mean, erâ€¦ wow!"
  },
  {
    "objectID": "posts/2022-12-11-pixeltrix-animate/index.html#environment",
    "href": "posts/2022-12-11-pixeltrix-animate/index.html#environment",
    "title": "Animate sprites in R with {pixeltrix}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:10:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] pixeltrix_0.2.1.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html",
    "href": "posts/2021-03-02-randoflag/index.html",
    "title": "A tiny {shiny} flag challenge",
    "section": "",
    "text": "The gif loops; I promise thereâ€™s more flags than this."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#tldr",
    "href": "posts/2021-03-02-randoflag/index.html#tldr",
    "title": "A tiny {shiny} flag challenge",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a teeny-weeny R Shiny app to serve me a flag challenge whenever I open a new browser tab."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#a-vexatious-request",
    "href": "posts/2021-03-02-randoflag/index.html#a-vexatious-request",
    "title": "A tiny {shiny} flag challenge",
    "section": "A vexatious request",
    "text": "A vexatious request\nI thought it would be fun to set my browser tabs to open with thiscatdoesnotexist.com, which serves a random ersatz â€˜catâ€™ as hallucinated by StyleGAN.1 Itâ€™s kind of terrifying and time for a change.\nWe probably accumulate hours of time looking at fresh browser tabs, so why not exploit that for fun and learning? I wanted something visual, quick and low stakes, soâ€¦ world flags?\nMy needs were simple: show a mystery flag; reveal who it belongs to; refresh.2 So I built a little {shiny} app, put it in a GitHub repo and served it.\nOn the front-end youâ€™re presented one of over 250 (!) emoji flags3 at random. Thereâ€™s a button to reveal the country it represents and another button to refresh the page via {shinyjs}. The back-end just samples a flag from the {emo} package and waits for you to hit refresh. The {bslib} package made it easy to generate a theme that keeps focus on the flag.\nSo now Iâ€™ve set my new tabs to open at https://mattdray.shinyapps.io/randoflag/ (tested on Firefox, Chrome and Safari on iOS 14) and I know what the Guadeloupe flag looks like now."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#hoisting-the-app",
    "href": "posts/2021-03-02-randoflag/index.html#hoisting-the-app",
    "title": "A tiny {shiny} flag challenge",
    "section": "Hoisting the app",
    "text": "Hoisting the app\nThe app is currently hosted online via shinyapps.io and Iâ€™ve embedded it below. Itâ€™s highly likely Iâ€™ll take it down at some point.\n\n\nIf it does get yoinked from the internet, you can install and run the app from your R session:\n\nshiny::runGitHub(\"randoflag\", \"matt-dray\", \"main\")\n\nYouâ€™ll need {shiny}, {bslib} and {shinyjs} installed from CRAN and you can get {emo} using remotes::install_github(\"hadley/emo\")."
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#half-mastery",
    "href": "posts/2021-03-02-randoflag/index.html#half-mastery",
    "title": "A tiny {shiny} flag challenge",
    "section": "Half-mastery",
    "text": "Half-mastery\nBeware: some emoji flags are shared by more than one geographic entityâ€¦\n\n\n\nBof!"
  },
  {
    "objectID": "posts/2021-03-02-randoflag/index.html#environment",
    "href": "posts/2021-03-02-randoflag/index.html#environment",
    "title": "A tiny {shiny} flag challenge",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 21:10:01 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#tldr",
    "href": "posts/2021-04-18-pico-pkg/index.html#tldr",
    "title": "Make the simplest R package with {pico}",
    "section": "tl;dr",
    "text": "tl;dr\nI made {pico}, an R package for creating tiny R packages with the absolute minimum structure and content. The goal: to demystify package making."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#function-in-a-haystack",
    "href": "posts/2021-04-18-pico-pkg/index.html#function-in-a-haystack",
    "title": "Make the simplest R package with {pico}",
    "section": "Function in a haystack",
    "text": "Function in a haystack\nI saw a @WeAreRLadies tweet from last weekâ€™s curator, @ShreyaLouis. The gist was â€˜how can you be more organised when recalling and reusing your own R code?â€™\nSee the thread for ideas, but I had the same thought as Fabio: create a personal package of your frequently-used functions so you can invoke them whenever you want.1"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#whats-the-problem",
    "href": "posts/2021-04-18-pico-pkg/index.html#whats-the-problem",
    "title": "Make the simplest R package with {pico}",
    "section": "Whatâ€™s the problem?",
    "text": "Whatâ€™s the problem?\nPackages are daunting, particularly if you havenâ€™t made one before. Iâ€™ve written a number of packages for fun and learning, but none have been submitted to CRAN and Iâ€™m never quite sure if Iâ€™m doing everything â€˜correctlyâ€™.\nFrom personal experience, I think the esoteric structure and content of R packages are a barrier to beginners. Like, what is the man/ folder and whatâ€™s an .Rd file? Itâ€™s easy to look at a chonky package repo on GitHub, like the popular {dplyr}, and despair.\nYes, you could RTFM (â€˜Read the Hecking Manualâ€™) about R packages, but have you looked at it before? And itâ€™s not even necessary to follow all of these steps if you donâ€™t have dreams of submitting it to CRAN.\nWhat ifâ€”for teaching purposesâ€”we strip back to the absolute barest of requirements with the goal of demystifying packages and to make it easier to get started?"
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#minimalism",
    "href": "posts/2021-04-18-pico-pkg/index.html#minimalism",
    "title": "Make the simplest R package with {pico}",
    "section": "Minimalism",
    "text": "Minimalism\nWhatâ€™s the least we need for a functioning package? Well, following Karl Bromanâ€™s book, all you need is two files and a subfolder. That is all.\nHereâ€™s how it looks for an imaginary package called {mypkg}:\nmypkg/\nâ”œâ”€â”€ R/\nâ”‚   â””â”€â”€ functions.R\nâ””â”€â”€ DESCRIPTION\nThe mypkg/R/functions.R file is a normal R script where you put your function definitions, like:\n\nsay_hi &lt;- function(name = \"buddy\") {\n  paste0(\"Ahoy-hoy \", name, \"!\")\n}\n\nThe DESCRIPTION file (which has no file extension) might not be as familiar, but itâ€™s basically a text file with only two lines: the package name and a version number (typically 0.0.0.9000 indicates a package under development, whereas 0.1 might be a minor release).2\nPackage: mypkg\nVersion: 0.0.0.9000\nThe DESCRIPTION file is like a magic flag that identifies that this folder is special and contains an R package; it isnâ€™t just a boring folder with some R scripts in it.\nâ€¦And thatâ€™s all you need."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#introducing-pico",
    "href": "posts/2021-04-18-pico-pkg/index.html#introducing-pico",
    "title": "Make the simplest R package with {pico}",
    "section": "Introducing {pico}",
    "text": "Introducing {pico}\nSo, you could point-and-click to create a folder with the structure and content outlined above, but Iâ€™ve also created the {pico} package to make the setup even easier.3\nThe basic process for using {pico} is:\n\nInstall {pico} with remotes::install_github(\"matt-dray/pico\")\nCreate your package with e.g.Â pico::create(\"mypkg\", \"~/Documents/\") (the second argument is a filepath for where to put the package folder)\nAdd new function definitions to the mypkg/R/functions.R script file\nInstall the package to your computer with remotes::install_local(\"~/Documents/mypkg\") and attach it like a normal package with library(mypkg)\n\nLater you can add more functions to R/functions.R (or add more script files to the R/ folder) and can reinstall the package with install_local(), using the force = TRUE argument to overwrite the old version.\nLetâ€™s take a look at those steps in a bit more depth.\n\nInstall {pico}\nFirst, you can install {pico} from GitHub with help from the {remotes} package.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/pico\")\n\nYou can look up the help files with ?pico::create() at any time.\nItâ€™s a really small package, but let me know if you find any bugs or you want to contribute.\n\n\nCreate your package\nThereâ€™s only one function in {pico}: create(). It generates a folder with the minimum required content, as outlined above. You supply a package name and a directory (folder on your computer) where you want your package to be generated.\nAs a demonstration, hereâ€™s how to create a pico package called {mypkg} in a temporary folder. You should put yours somewhere more permanent and convenient like ~/Documents on macOS, for example.\n\ntmp &lt;- tempdir()\npico::create(name = \"mypkg\", dir = tmp)\n\nPico package {mypkg} written to:\n  /var/folders/cg/5x7y2f0x6tqb9mqrc13pd8_40000gn/T//RtmpRGhTOc/mypkg\n\n\nThis will output some lines in the R console that confirm your new package has been written to the location you specified (my example path here is convoluted because itâ€™s just a temporary folder).\nThe name will be checked against R-package naming standards: it should contain alphanumeric characters or periods only, must have at least two characters, and canâ€™t start with a number nor end with a period. The provided directory also will be checked for existence and, if it already contains a folder with the proposed name of your package, youâ€™ll be asked interactively if you want to overwrite it.\n\n\nInstall your package\nSo, the package now exists on your computer inside a folder. Now how do you use its functions in an R session?\nNormally, you would use install.packages() to fetch a package from CRAN and install it to your computerâ€™s R package library. We can do something similar, but instead of fetching from CRAN, we can fetch the package â€˜locallyâ€™, i.e.Â from your computer.\nTo do this, we can use the {remotes} package, which we installed earlier. It contains an install_local() function to which you pass the packageâ€™s filepath on your computer.\n\nremotes::install_local(\n  path = file.path(tmp, \"mypkg\")  # change to your packages filepath\n)\n\n\n\nâœ“  checking for file  â€˜private/var/folders/cg/5x7y2f0x6tqb9mqrc13pd8_40000gn/T//RtmpRGhTOc/mypkg â€™ ...\n â”€  preparing â€˜mypkgâ€™:\n âœ“  checking DESCRIPTION meta-information\n â”€  checking for LF line-endings in source and make files and shell scripts\n â”€  checking for empty or unneeded directories\n â”€  creating default NAMESPACE file\n â”€  building â€˜mypkg_0.0.9000.tar.gzâ€™\n \n * installing *source* package â€˜mypkgâ€™ ...\n ** using staged installation\n ** R\n ** byte-compile and prepare package for lazy loading\n ** help\n No man pages found in package  â€˜mypkgâ€™ \n *** installing help indices\n ** building package indices\n ** testing if installed package can be loaded from temporary location\n ** testing if installed package can be loaded from final location\n ** testing if installed package keeps a record of temporary installation path\n * DONE (mypkg)\n\n\nYouâ€™ll see some output that describes the installation process, ending with DONE.\nThe package is now installed into your R package library and can be attached like any other package.\n\nlibrary(mypkg)\n\nNow the functions from the package are available for use. By default, create() added a dummy function called say_hi() to R/functions.R, which we can use now:\n\nsay_hi(\"chums\")\n\n[1] \"Ahoy-hoy chums!\"\n\n\nSo, we created an R package, installed it and used it."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#add-new-functions",
    "href": "posts/2021-04-18-pico-pkg/index.html#add-new-functions",
    "title": "Make the simplest R package with {pico}",
    "section": "Add new functions",
    "text": "Add new functions\nOf course, youâ€™ll want to add your own functions to your package. The basic steps are:\n\nOpen the R/functions.R script\nPaste in your function definitions and save the file\nRerun remotes::install_local() with the argument force = TRUE\nRestart R, so the updated package is recognised\n\nHereâ€™s what this might look like for our example package. First, you might add the function say_bye() by adding these lines to the functions.R file:\n\nsay_bye &lt;- function(name = \"folks\") {\n  paste0(\"Cheerio \", name, \"!\")\n}\n\nAfter you saved the updated file, you can re-run install_local() with the file path and force = TRUE, which will overwrite the old version in the package library.\n\nremotes::install_local(\n path = file.path(tmp, \"mypkg\"),\n force = TRUE\n)\n\nYou must restart R after youâ€™ve done this.\nYour new functions will then be available from your package, much like the dummy say_hi() function was. Hereâ€™s say_bye():\n\nlibrary(mypkg)\nsay_bye(\"friends\")\n\n[1] \"Cheerio friends!\"\n\n\nSo, that means that all those functions you keep forgetting, or that are stored across multiple locations, can be made available to you from one package. And ultimately, all it required was install_github(), create() and install_local().\nNote that it can get unwieldy to add all your functions to the functions.R file provided by {pico}, but you can group them up into several R scripts in the R/ subfolder if you like."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#huge-limitations",
    "href": "posts/2021-04-18-pico-pkg/index.html#huge-limitations",
    "title": "Make the simplest R package with {pico}",
    "section": "Huge limitations",
    "text": "Huge limitations\nSo, I think {pico} is a quick way to get you from â€˜no-packageâ€™ to â€˜packageâ€™ quickly, but more importantly it has none of the esoteric, daunting structure and content of a â€˜normalâ€™ package.\nHowever.\nA pico package doesnâ€™t encourage best practice, nor is it very useful for sharing. Thatâ€™s why I think the only practical applications are for learning the basics of package structure, or for building a small package of functions that you might personally want to use again in future.\nI would absolutely advocate for learning how to make a â€˜realâ€™ package, because that additional structure and content is really powerful and exists for a reason. For example, we havenâ€™t documented any of our functions. What if you add a function to your package but you canâ€™t remember how to use it? We also havenâ€™t tested anything. What if something breaks?\nIâ€™ve written before about the wonders of {usethis}, a package made specifically to help develop your own R packages without thinking too hard. I believe it provides the perfect starting point for developing your own package without worrying about exactly what files are needed and where.\nThereâ€™s a vast array of free web-based resources out there for package building. For example, some that Iâ€™ve found useful are:\n\nHilary Parkerâ€™s Writing an R Package from Scratch post\nTom Westlakeâ€™s update to Hilaryâ€™s post\nFabio Vottaâ€™s fun slides\nEmil Hvitfeldtâ€™s {usethis} workflow\nKarl Bromanâ€™s R Package Primer site, a primer for package development\nHadley Wickhamâ€™s R Packages book\n\nYou should make use of those resources, for sure. Do not use {pico} for any serious work. {pico}â€™s purpose here is to think about how we might demystify package development. At worst I think itâ€™s an interesting curiosity."
  },
  {
    "objectID": "posts/2021-04-18-pico-pkg/index.html#environment",
    "href": "posts/2021-04-18-pico-pkg/index.html#environment",
    "title": "Make the simplest R package with {pico}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 13:41:04 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] mypkg_0.0.9000\n\nloaded via a namespace (and not attached):\n [1] desc_1.4.2        digest_0.6.31     R6_2.5.1          fastmap_1.1.1    \n [5] xfun_0.39         remotes_2.4.2     knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    ps_1.7.5          cli_3.6.1         processx_3.8.1   \n[13] callr_3.7.3       pico_0.0.0.9000   compiler_4.3.1    rprojroot_2.0.3  \n[17] prettyunits_1.1.1 rstudioapi_0.15.0 tools_4.3.1       pkgbuild_1.4.1   \n[21] evaluate_0.21     yaml_2.3.7        crayon_1.5.2      rlang_1.1.1      \n[25] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#tldr",
    "href": "posts/2022-09-13-potato/index.html#tldr",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "tl;dr",
    "text": "tl;dr\nPlay an interactive version of â€˜Potatoâ€™â€”a one-page halfling-themed role-playing game (RPG) by Oliver Darkshire (Twitter, Patreon)â€”in your R console with the {potato} package."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato",
    "href": "posts/2022-09-13-potato/index.html#potato",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato?",
    "text": "Potato?\nIâ€™ve recently put together a GitHub repo to collect together a bunch of neat games that you can play. The twist? They were built using R.\nYes, R: â€˜a FrEe SoFtWaRe EnViRoNmEnT fOr StAtIsTiCaL cOmPuTiNg AnD gRaPhIcSâ€™.\nI think R is best suited to either text-based user-input games on the R console, or via a more dedicated interface, like Shiny.1\nIn this vein, Oliver Darkshire wrote an excellent â€˜one-page role-playing gameâ€™ called Potato that seems ripe for plucking (well, I guess you â€˜pullâ€™ potatoes?) into an R implementation. A simple text interface; updating and tracking variables; clear win conditions. The basic desire to avoid action and simply tend to vegetables.\nSoâ€¦ {potato}."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato-1",
    "href": "posts/2022-09-13-potato/index.html#potato-1",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato!",
    "text": "Potato!\nYou can install the {potato} package from GitHub thanks to {remotes}:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/potato\")\n\nYou start a game with:2\n\npotato::potato()\n\n--- POTATO ---\n\nA (one-page) RPG by Oliver Darkshire (@deathbybadger)\nThese and more at https://www.patreon.com/deathbybadger\n\nYou are a halfling, just trying to exist.\nMeanwhile, the dark lord rampages across the world.\nYou do not care about this. You are trying to farm potatoes.\nBecause what could a halfling possibly do about it anyway?\n\nKeep rolling until DESTINY, POTATO or ORC reach 10/10.\n\n- DESTINY: 0/10\n- POTATO:  0/10\n- ORC:     0/10\n- PAY:     1 POTATO to remove 1 ORC\n\nPress [ENTER] to roll... \nThe console will prompt you for input as you play. Itâ€™s basically luck-based die rolls, though you will have the chance to intervene with an option to hurl a certain number of precious potatoes at an orc to make it clear off.\nYou win when POTATO reaches 10. You lose when ORC reaches 10. You alsoâ€¦ â€˜donâ€™t loseâ€™â€¦ if DESTINY reaches 10.\nPlease see the one-page RPG that David put together and/or support him on Patreon if you like it or any of the other hilarious one-page RPGs that heâ€™s made.\nI cannot stress enough that this is his work and all Iâ€™ve done is put it into an obscure format that literally three people might look at for a laugh."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato-2",
    "href": "posts/2022-09-13-potato/index.html#potato-2",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potatoâ€¦",
    "text": "Potatoâ€¦\nI could just leave it there, but I think the interesting thing for R users are the various little methods required to make the â€˜gameâ€™ function.\nTo display text to the user in the console, we can use cat() or message(). I kinda prefer message() because the user has more control over it in general, like suppressMessages() (which does what you think it does).\n\nmessage(\"Hello world!\")\n\nHello world!\nThereâ€™s a subtlety in presentation too, which is that the two functions return text in different colours.\nThe game loop itself runs inside a repeat, which is maybe uncommon for some R users. Weâ€™re mostly used to for or while loops for iteration with a known set of things to iterate over, whereas repeat will keep going until we specify a break.\n\nrepeat {\n  \n  if (keep_going) {\n    do_something()\n  }\n  \n  if (!keep_going) {\n    break\n  }\n  \n}\n\nYou can imagine a scenario where keep_going is set to TRUE and some actions happen as a result; and that if it becomes FALSE then the game loop ends. In {potato}, we make sure to first print the current values of DESTINY, POTATO and ORC so the user sees them before the game continues or ends.\nWhat are DESTINY, POTATO and ORC? Before we initiate that repeat loop we can specify a bunch of starting values for some important scoring variables. Stylistically, it makes sense to use ALL CAPS for these (thatâ€™s how they were written in the original game, after all), but thereâ€™s also an old-school rule-of-thumb to specify variables this way in R code so you can more easily spot them in your code.\n\nDESTINY &lt;- 0L\nPOTATO  &lt;- 0L\nORC     &lt;- 0L\n\nin addition, we clearly need user input to decide what to do during the game. Most of the time, a userâ€™s hand is forced and they need to roll. But sometimes they have the choice to remove an orc at the cost of one or more potatoes (depending on how the die falls).\nThis is a logical variable that we can keep track of, i.e.Â can the user pay (TRUE or FALSE)?\n\ncan_pay &lt;- FALSE\n\nif (COST &lt;= POTATO) {\n  can_pay &lt;- TRUE\n} else if (COST &gt; POTATO) {\n  can_pay &lt;- FALSE\n}\n\nIf the cost to yeet an orc is equal-to or less-than the number of potatoes, we can elect to make the payment. This is expressed in the options provided to the user on the command line.\nGiven the can_pay value, the user will get the option to either roll the die (FALSE):\n\nevent &lt;- readline(\n  \"Press [ENTER] to roll... \"\n)\n\nOr choose to roll the die or make the payment (TRUE):\n\nevent &lt;- readline(\n  \"Press [ENTER] to roll or [p] to pay 1 POTATO to remove 1 ORC... \"\n)\n\nBoth of which require user input that results in a value stored in the event object. Note that hitting Enter results in an empty string (\"\").\nDie-roll values pass through a series of if statements that are activated based on the number rolled. So if you roll 1 or 2, youâ€™re In the garden...; if 3 or 4, youâ€™ll get A knock on the door...; else the potato cost per orc-yeet increases by 1).\nA second roll is made automatically when in the garden or when a knock is heard. Hereâ€™s what happens if a 1 is rolled when in the garden:\n\nif (rolled_garden == 1L) {\n  \n  message(\n    paste(\n      rolled_garden_msg,\n      \"You happily root about all day in your garden.\"\n    )\n  )\n  \n  message(\"- Result: +1 POTATO\")\n  \n  POTATO &lt;- POTATO + 1L\n  \n}\n\nExcellent, the POTATO variable counter is increased by 1 in this case and confirmed to the user in a message(). The latest DESTINY, POTATO and ORC scores are then printed back to the user at the start of the next repeat loop.\nAnd then you justâ€¦ keep potatoing."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#potato.",
    "href": "posts/2022-09-13-potato/index.html#potato.",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Potato.",
    "text": "Potato.\nOnce again, you can visit Oliver Darkshire on Twitter as @deathbybadger and support him on Patreon.\nYou can find the source code for {potato} on GitHub. Issues and pull requests welcome. Just make sure you can afford the charge of one potato to submit."
  },
  {
    "objectID": "posts/2022-09-13-potato/index.html#environment",
    "href": "posts/2022-09-13-potato/index.html#environment",
    "title": "You are a halfling, trying to harvest {potato}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:50:32 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#tldr",
    "href": "posts/2021-07-25-faxcrayon/index.html#tldr",
    "title": "Make an art gallery with {bs4cards}",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {bs4cards} package by Danielle Navarro to create an effortless online â€˜galleryâ€™ of â€˜artâ€™ on a single R Markdown page: faxcrayon.art.\n\n Note\nI may decide to shutdown this site at some point. The code will always be available on GitHub, but the site may disappear. Câ€™est la vie."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#art-is-a-lie",
    "href": "posts/2021-07-25-faxcrayon/index.html#art-is-a-lie",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Art is a lie",
    "text": "Art is a lie\nTurns out you can just put up some pictures on the internet and call it a gallery. No one is stopping you.\nHere is a foolproof approach: R Markdown with {bs4cards} to write the content, GitHub Pages to serve it, and a totally rad URL to convince people youâ€™re legit."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#bs4cards",
    "href": "posts/2021-07-25-faxcrayon/index.html#bs4cards",
    "title": "Make an art gallery with {bs4cards}",
    "section": "{bs4cards}",
    "text": "{bs4cards}\nThe {bs4cards} package (available on CRAN) is great because it lets you create customisable â€˜cardsâ€™ that you can tile on an R Markdown page.\nTo create a card, you use the card() function with arguments for title, image,1 text, link, etc. You can put these in a list and pass that to card_grid() to make a grid. Of cards. A card grid.\nSo, this format could work well to bring disparate information together in one central location, like a blogâ€™s landing page, where a cardâ€™s content gives you a preview of post that you can click to visit it.\nSo I did just that: I made a single page2 where each card displays an art piece I created with R code for #RecreationThursday, or whatever.\nThe cards contain the creation date in the header; the â€˜nameâ€™ of the piece as the card title, which links out to where the code is hosted for recreating it; and in the card body it states whether the image is a recreation, a remix or something original.\n\nYou can find the source on GitHub.\n\nGitHub Pages\nOne of the easiest ways to serve an R Markdown file on the internet is to store it in a GitHub repository, knit it to HTML and then enable GitHub Pages.\nYou go to the â€˜Pagesâ€™ in your repositoryâ€™s settings to enable it and then your HTML is served so that itâ€™s available to anyone on the internet in the form &lt;username.github.io/repository-name/file.html&gt;.3\n\n\nDomain\nBut that doesnâ€™t make for a terribly exciting URL. Since Iâ€™m going to be an internationally-famous and extremely financially-successful artist, it makes sense to improve my online brand with a rad URL.\nWhere to get inspiration? Iâ€™ve tweeted images for #RecreationThursday using the fax4 ðŸ“  and crayon ðŸ–ï¸ emojis because I was using my rudimentary skills to create facsimile copies of original artworks. Soâ€¦ fax crayon? Like a wax crayon, but, like, fax?\nAnd the &lt;faxcrayon.art&gt; URL only cost two dollars to buy, so.\nThereâ€™s a small dance you have to do to make GitHub Pages link to your domain, while your domain provider may themselves require a particular set of settings.\nIt took half an hour or so for the domain dance to complete, but now the site is available at faxcrayon.art."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#nothing-is-real",
    "href": "posts/2021-07-25-faxcrayon/index.html#nothing-is-real",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Nothing is real",
    "text": "Nothing is real\nSo: {bs4cards}, GitHub Pages and a totally hip URL.\nNow I just need to work out how to integrate NFT5 functionality to the site and quit my day job."
  },
  {
    "objectID": "posts/2021-07-25-faxcrayon/index.html#environment",
    "href": "posts/2021-07-25-faxcrayon/index.html#environment",
    "title": "Make an art gallery with {bs4cards}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:32:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html",
    "href": "posts/2021-07-15-dollar-dollar/index.html",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "",
    "text": "Kiwi by Georgiana Ionescu. Laser embellishment in honour of Lucy Grayâ€™s flag."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#tldr",
    "href": "posts/2021-07-15-dollar-dollar/index.html#tldr",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "tl;dr",
    "text": "tl;dr\nRâ€™s $ data accessor symbol is part of an international ruse. I wrote a function so you can use your local currency symbol instead."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#pull-the-wool-from-your-eyes",
    "href": "posts/2021-07-15-dollar-dollar/index.html#pull-the-wool-from-your-eyes",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Pull the wool from your eyes",
    "text": "Pull the wool from your eyes\nYouâ€™re an R user, so youâ€™ll know how to access the contents of a quoted column name from a dataframe with square-bracket notation.\n\nmtcars[[\"cyl\"]]\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nThe dollar symbol ($) does the same thing, of course, in the form dataframe$column.\n\nmtcars$cyl\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nBut, like basically everything in R, itâ€™s just a function.\nSo you can also use it in the â€˜traditional wayâ€™ by passing the dataframe and column name to it as arguments inside brackets. Youâ€™ll need to use backticks (```) though, because function names canâ€™t start with symbols or numbers.\n\n`$`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#wake-up-sheeple",
    "href": "posts/2021-07-15-dollar-dollar/index.html#wake-up-sheeple",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Wake up sheeple",
    "text": "Wake up sheeple\nBut why the dollar symbol? Something something â€˜compatability with Sâ€™.\nOr perhaps a more sinister ploy by Râ€™s original developers, Ihaka and Gentleman?\nLike a KIWI CONSPIRACY to raise awareness of the NEW ZEALAND DOLLAR (NZD) and INFLUENCE currency markets? Iâ€™m just asking the question.1\nSo, Iâ€™m giving you the FREEDOM to assign the functionality of the dollar symbol to another currency symbol, like, oh, I donâ€™t know, the pound sterling symbol (Â£), as a completely random example.\n\n`Â£` &lt;- `$`\n`Â£`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nYou canâ€™t use it in the dataframe$column form, however. That kind of behaviour is reserved for special symbols in R.2\n\nmtcarsÂ£cyl\n\nError: &lt;text&gt;:1:7: unexpected input\n1: mtcarsÂ£\n          ^\n\n\nShame. R has a little quirk that will make this work though. Sort of.\nYou can make a function do this by putting it between percentage symbols (%). This is called an â€˜infix operatorâ€™ and you may have seen the {magrittr} pipe (%&gt;%) as one example.\n\n`%Â£%` &lt;- `$`\nmtcars %Â£% cyl\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nAs a complete coincidence, I live in Great Britain (GB) where we use pound sterling (Â£, or â€˜GBPâ€™).\nR also knows where I live (another conspiracy?).\n\nSys.getlocale()\n\n[1] \"en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\"\n\n\nThis string is Râ€™s way of keeping track of the location-specific information that influences stuff like the language of error messages.\nYou can specify different locales for different things. Hereâ€™s my locale for â€˜monetaryâ€™ parameters, for example.\n\nSys.getlocale(category = \"LC_MONETARY\")\n\n[1] \"en_GB.UTF-8\"\n\n\nThat particular value impacts parameters like the punctuation mark used for decimals and, wouldnâ€™t you know it, the symbol used for currency.\n\nSys.localeconv()\n\n    decimal_point     thousands_sep          grouping   int_curr_symbol \n              \".\"                \"\"                \"\"            \"GBP \" \n  currency_symbol mon_decimal_point mon_thousands_sep      mon_grouping \n              \"Â£\"               \".\"               \",\"        \"\\003\\003\" \n    positive_sign     negative_sign   int_frac_digits       frac_digits \n               \"\"               \"-\"               \"2\"               \"2\" \n    p_cs_precedes    p_sep_by_space     n_cs_precedes    n_sep_by_space \n              \"1\"               \"0\"               \"1\"               \"0\" \n      p_sign_posn       n_sign_posn \n              \"1\"               \"1\""
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#mutton-dressed-as-lamb",
    "href": "posts/2021-07-15-dollar-dollar/index.html#mutton-dressed-as-lamb",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Mutton dressed as lamb",
    "text": "Mutton dressed as lamb\nSo, that means I can write you a function that gets the currency symbol for your locale and assigns to it the functionality of the dollar symbol, naturally.\n\ncopy_dollar &lt;- function() {\n  \n  # Get currency symbol for locale\n  currency &lt;- Sys.localeconv()[[\"currency_symbol\"]]\n  \n  # Report the locale\n  if (currency == \"$\") stop(\"KIWI CONSPIRATOR!\")\n  locale &lt;- Sys.getlocale(category = \"LC_MONETARY\")\n  cat(paste0(\"Your monetary locale is '\", locale, \"'\\n\"))\n  \n  # Generate and evaluate strings\n  expr_fn &lt;- paste0(\"`\", currency, \"` &lt;&lt;- `$`\")\n  expr_in &lt;- paste0(\"`%\", currency, \"%` &lt;&lt;- `$`\")\n  eval(rlang::parse_expr(expr_fn))  # function form\n  eval(rlang::parse_expr(expr_in))  # infix form\n  \n  # Report to user\n  cat(\n    paste0(\"Try `\", currency, \"`(df, col) and df%\", currency, \"%col\\n\")\n  )\n  \n}\n\nI used a bit of a trick3 there. You canâ€™t use a string on the left-hand side of the assignment operator, but you can build an R expression as a string and eval()uate a parsed version of it (with some help from {rlang} in my example).\nI also used a special double-headed assignment arrow, &lt;&lt;-, that makes the objects available in the global environment.4 That means we can use the new functions outside the scope of the copy_dollar() function.\nAnd now: freeeedooooom.\n\ncopy_dollar()\n\nYour monetary locale is 'en_GB.UTF-8'\nTry `Â£`(df, col) and df%Â£%col\n\n\nWe got a couple of messages5 to confirm our location and let us know how we can use the new currency-symbol functions.\nAnd we can see these in the global environment.\n\nls()\n\n[1] \"%Â£%\"             \"Â£\"               \"copy_dollar\"     \"has_annotations\"\n\n\nAnd we can prove that GBP equals NZD, at least as a function for accessing columns of a dataframe.\n\nall(\n  mtcars %Â£% cyl == mtcars$cyl,\n  `Â£`(mtcars, cyl) == `$`(mtcars, cyl)\n)\n\n[1] TRUE\n\n\nOkay, works for my location. What about when Iâ€™m competing in Japan at the Olympics?6 Well, I can change the monetary locale.\n\nSys.setlocale(\"LC_MONETARY\", \"ja_JP.UTF-8\")\n\n[1] \"ja_JP.UTF-8\"\n\nSys.localeconv()\n\n    decimal_point     thousands_sep          grouping   int_curr_symbol \n              \".\"                \"\"                \"\"            \"JPY \" \n  currency_symbol mon_decimal_point mon_thousands_sep      mon_grouping \n              \"Â¥\"               \".\"               \",\"        \"\\003\\003\" \n    positive_sign     negative_sign   int_frac_digits       frac_digits \n               \"\"               \"-\"               \"0\"               \"0\" \n    p_cs_precedes    p_sep_by_space     n_cs_precedes    n_sep_by_space \n              \"1\"               \"0\"               \"1\"               \"0\" \n      p_sign_posn       n_sign_posn \n              \"1\"               \"4\" \n\n\nSo now you can see the yen symbol (Â¥) as the named currency value for this locale. And you can use the function to activate it for use as a data accessor.\n\ncopy_dollar()\n\nYour monetary locale is 'ja_JP.UTF-8'\nTry `Â¥`(df, col) and df%Â¥%col\n\n`Â¥`(mtcars, cyl)\n\n [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4\n\n\nOh, and thereâ€™s no point trying to do this if your locale already uses the dollar for currency. I know you want as many dollars as possible, but donâ€™t be greedy.\n\nSys.setlocale(\"LC_MONETARY\", locale = \"en_NZ.UTF-8\")\n\n[1] \"en_NZ.UTF-8\"\n\ncopy_dollar()\n\nError in copy_dollar(): KIWI CONSPIRATOR!\n\n\nIâ€™ll reset my settings to the motherland to prevent any accidental borking.\n\nSys.setlocale(locale = \"en_GB.UTF-8\")\n\n[1] \"en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\"\n\n\nNothing ever goes wrong in Britain, after all."
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#separate-your-sheep-from-your-goats",
    "href": "posts/2021-07-15-dollar-dollar/index.html#separate-your-sheep-from-your-goats",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Separate your sheep from your goats",
    "text": "Separate your sheep from your goats\nWhile you go and adjust your locale in an act of defiance, be on the lookout for the next New Zealander conspiracy.\nI heard that they want to replace the ampersand (&) symbol in R version 5 with NEWZEAL&, so stay on your toes.\nHang onâ€¦\nI think I used sheep-related phrases in all the section titles of this post. And arenâ€™t there like 10 sheep per person in New Zealand?\nTheyâ€™ve got to me already!"
  },
  {
    "objectID": "posts/2021-07-15-dollar-dollar/index.html#environment",
    "href": "posts/2021-07-15-dollar-dollar/index.html#environment",
    "title": "EXPOSED: a Kiwi conspiracy built into R!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 18:34:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#tldr",
    "href": "posts/2021-10-03-squirrel/index.html#tldr",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "tl;dr",
    "text": "tl;dr\nI created the {ActionSquirrel} package. It contains an {R6}-powered playable game for the R console, which includes images (well, emoji) and sounds (thanks to the {sonify} package)."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#gamers",
    "href": "posts/2021-10-03-squirrel/index.html#gamers",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "GameRs",
    "text": "GameRs\nIâ€™ve written before about the idea of games that you can play in R. For example, I replicated a text-based version of Pokemon Blueâ€™s Safari Zone. This was made possible by using the {R6} package by Winston Chang, which provides an implementation of object-oriented programming (OOP) in R.\nAn R6 class has â€˜fieldsâ€™ (variables) and â€˜methodsâ€™ (functions) that can adjust the field values. This means you can manipulate the state of the object over time. You can read more in the {R6} documentation or in Hadley Wickhamâ€™s Advanced R book.\nSo you could create a class with a field that provides the location of a character, then let the user apply a method to overwrite that location. If you print the â€˜beforeâ€™ and â€˜afterâ€™ states, youâ€™ll get the impression of movement for the character."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#winter-is-coming",
    "href": "posts/2021-10-03-squirrel/index.html#winter-is-coming",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Winter is coming",
    "text": "Winter is coming\nWith this in mind, I made a game and put it in the {ActionSquirrel} package. Itâ€™s pretty simple; consider it a concept.\nYou play as a squirrel in a woodland, hoarding nuts before winter sets in. You have to collect 8 nuts in 30 moves or you wonâ€™t survive. To make matters worse, thereâ€™s an owl on patrol that wants to eat you.\nThe package contains a single â€˜ActionSquirrelâ€™ class. It has fields for the location of game objectsâ€”emojis for a tree, a squirrel, an owl and a nutâ€”on a grid.1 It has a method to move the squirrel around the grid, which also executes code to assesses and change other field states. For example, it can check how many moves have happened, can adjust the owlâ€™s position and spawn a new nut after the last one was collected."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#demo",
    "href": "posts/2021-10-03-squirrel/index.html#demo",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Demo",
    "text": "Demo\nYou can install from GitHub.\n\ninstall.packages(\"remotes\")  # if not installed already\nremotes::install_github(\"matt-dray/ActionSquirrel\")\n\nNote that Iâ€™ve developed and tested this only in RStudio v1.4.1717 with R v4.1.1 running on macOS Big Sur. I think emoji rendering, console-clearing and the sound effects may not work on all platforms and setups.\nBasic instructions are printed when the package is attached.\n\nlibrary(ActionSquirrel)\n\nWelcome to {ActionSquirrel}!\n* New game: x &lt;- ActionSquirrel$new()\n* Move:     e.g. x$move('up')\n* Info:     x$pause()\n\n\n\nStart\nInitiate an object with the ActionSquirrel class by assigning ActionSquirrel$new() to a name (Iâ€™ll use x for demo purposes). This clears the console and generates a forest grid that contains the squirrel, a nut and an owl, along with tallies for moves and nuts collected.\n\nx &lt;- ActionSquirrel$new()\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 0 \nNuts: 0\n\n\nMethods are applied to your object with the dollar symbol accessor2 in the form object$method(). We can use the pause() method to get game instructions, for example.\n\nx$pause()\n\nP A U S E\n * Aim:       get eight nuts before winter (30 moves)\n * Move:      e.g. x$move('up')\n * Chain:     e.g. x$move('u')$move('r')\n * New game:  x &lt;- ActionSquirrel$new()\n * Info:      x$pause()\n * Source:    github.com/matt-dray/ActionSquirrel\n\n\n\n\nState\nTo understand a little more the mechanics of R6-classes, you could take a peek at the current state of the fields and methods by printing your ActionSquirrel-class object.\nIt isnâ€™t necessary for gameplay purposes to see this information, but for learning purposes it provides a sort-of â€˜metaâ€™ view of the current game state. (It will also help you â€˜hackâ€™ the game, more on that later!)\n\nx\n\n&lt;ActionSquirrel&gt;\n  Public:\n    active: TRUE\n    clone: function (deep = FALSE) \n    initialize: function () \n    move: function (where = c(\"up\", \"down\", \"left\", \"right\")) \n    moves: 0\n    n_loc: 8\n    nuts: 0\n    o_loc: 17\n    overworld: ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ ðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³\n    pause: function () \n    s_loc: 14\n\n\nThe most relevant of these are the moves and nuts counts; the *_loc values that specify the location of the squirrel, owl and nut in the overworld vector; and the move() method for controlling the player.\n\n\nMove\nYou move the squirrel through the forest with the move() method. It has one argument, where, that takes the directions \"up\", \"down\", \"left\" and \"right\" (you can also just supply the first letter of the direction).\n\nx$move(\"up\")\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸ¿ï¸ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 1 \nNuts: 0\n\n\nCongratulations: your move tally has increased by one. You may also have noticed that the owl moved up one space as well; it moves one space vertically or horizontally, or stays still, with equal probability.\nI built in collision detection, so you canâ€™t exceed the limits of the grid by trying to go left if youâ€™re already on the leftmost edge, for example.\nNote that you can also take more than one move at a time (elite gamer tech) by â€˜chainingâ€™ methods, like x$move(\"up\")$move(\"left\"), but this is risky because you might collide with the owl.\nImportantly, the whole R console is cleared before the updated grid is printed. This gives an impression of animated graphics, since the console overwrites the previous state with the current state.\nNow to collect the nut.\n\nx$move(\"left\")\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸ¿ï¸ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 2 \nNuts: 1\n\n\nCongratulations, your nut tally has increased by one and a new nut has spawned in a random location. Collect at least eight nuts, or you wonâ€™t survive winter.\n\n\nOwl\nYouâ€™ll get a game over if the owl eats you (i.e.Â you occupy the same spot). So if you move left and the owl happens to move upâ€¦\n\nx$move(\"left\")\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸ’€ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ° ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 3 \nNuts: 1\nY O U   D I E D ! \nThe owl ate you.\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nThe location of your death is marked with a skull and youâ€™ll get a game over with information about what happened. At this point, the active field of the class is set to FALSE, which prevents you from moving again.\n\n\n\nDefinitely itâ€™s harder than Dark Souls.\n\n\n\n\nWinter\nAfter 30 turns the game will end because youâ€™ve reached winter. Youâ€™ll get a victory screen if you collected 8 nuts, otherwise a failure screen.\nAside: {R6} allows for â€˜publicâ€™ and â€˜privateâ€™ fields and methods. Iâ€™ve used public methods for the ActionSquirrel class, so that users can see the contents and state of the class and manipulate them. I think this is good for learning purposes.\nIt also means that we can â€˜hackâ€™ the game to the end state by overwriting the number of nuts and moves remaining! First, a victory after having collected eight nuts or more:\n\nx &lt;- ActionSquirrel$new()\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 0 \nNuts: 0\n\nx$moves &lt;- 29\nx$nuts &lt;- 10\nx$move()\n\n\fðŸ¿ï¸ ðŸ’¤ ðŸŒ° ðŸŒ° ðŸŒ° \nðŸŒ° ðŸŒ° ðŸŒ° ðŸŒ° ðŸŒ° \nðŸŒ° ðŸŒ° ðŸŽ„ â›„ ðŸŽ„ \nðŸŒ¨ â›„ ðŸŽ„ â›„ ðŸŽ„ \nâ›„ â›„ ðŸŒ¨ ðŸŽ„ ðŸŒ¨ \nMoves: 30 \nNuts: 10\nY O U   S U R V I V E D ! \nSufficient winter nut cache!\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nOur little squirrel friend is hibernating with the nut cache nearby. Meanwhile, the signs of winter fill the rest of the grid. Your success is confirmed in a printed statement.\nAnd what if we end the game with an insufficient nut cache?\n\nx &lt;- ActionSquirrel$new()  # start new game\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 0 \nNuts: 0\n\nx$moves &lt;- 29\nx$nuts &lt;- 4\nx$move()\n\n\fðŸ¿ï¸ ðŸ’€ ðŸŒ° ðŸŒ° ðŸŒ° \nðŸŒ° âŒ âŒ âŒ âŒ \nðŸŽ„ ðŸŽ„ ðŸŒ¨ ðŸŽ„ â›„ \nðŸŽ„ â›„ ðŸŽ„ â›„ ðŸŽ„ \nâ›„ ðŸŽ„ ðŸŒ¨ â›„ â›„ \nMoves: 30 \nNuts: 4\nY O U   D I E D ! \nInsufficient winter nut cache!\nG A M E   O V E R \n* New game: x &lt;- ActionSquirrel$new() \n* Source:   github.com/matt-dray/ActionSquirrel\n\n\nOh dear.\n\n\nSFX\nSo weâ€™ve got a player character, an enemy, collectibles, a goal and â€˜animatedâ€™ visuals. The only thing missing is audio.\nLuckily, you can force your computer to make noise with the {sonify} package. Iâ€™ve used it before in this blog to represent COVID-19 data in audio form. For {ActionSquirrel}, I used it to make short, simple beeps to indicate a move, nut capture, collision with the edge of the grid, a win and a death. Hereâ€™s what those sound like, respectively:\n\n\n\n\n\nThe death sound is a flatline, because of course it is."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#r6-7-8",
    "href": "posts/2021-10-03-squirrel/index.html#r6-7-8",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "R6, 7, 8",
    "text": "R6, 7, 8\nSo, give it a go. Whatâ€™s your high score? How guilty did you feel when the squirrel died?\nThereâ€™s lots of ways this could be improved. Maybe the owl could have â€˜AIâ€™ that encourages it to move towards the player or nut. Maybe there could be another enemy with different movement patterns. I welcome any bug reports or suggestions in the GitHub repo for {ActionSquirrel}, or maybe you can fork it and make it better.\nThis post completes my R6 OOP hattrick alongside posts on Animal Crossing and PokÃ©mon. Next time I might move onto {R7}, a new package for OOP in R thatâ€™s being coordinated and developed in the open by the R Consortium."
  },
  {
    "objectID": "posts/2021-10-03-squirrel/index.html#environment",
    "href": "posts/2021-10-03-squirrel/index.html#environment",
    "title": "{ActionSquirrel}: a game in the R console",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-08 12:34:07 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ActionSquirrel_0.1.0\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     R6_2.5.1          signal_0.7-7      fastmap_1.1.1    \n [5] sonify_0.0-1      xfun_0.39         knitr_1.43.1      htmltools_0.5.5  \n [9] rmarkdown_2.23    tuneR_1.4.4       cli_3.6.1         compiler_4.3.1   \n[13] rstudioapi_0.14   tools_4.3.1       evaluate_0.21     yaml_2.3.7       \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2 MASS_7.3-60"
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#tldr",
    "href": "posts/2021-08-31-paren-label/index.html#tldr",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a novelty R function that inserts comments after closing parentheses with the names of the functions they belong to. (These are called biscuits, apparently.) Itâ€™s available as an RStudio Addin from the {blogsnip} package."
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#matryoshka-functions",
    "href": "posts/2021-08-31-paren-label/index.html#matryoshka-functions",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Matryoshka functions",
    "text": "Matryoshka functions\nShiny apps can involve a lot of nested functions in the UI, which can make them difficult to handle.\nSometimes I comment after a closing parenthesis (â€˜parenâ€™) with the name of the function that itâ€™s closing, which makes it easier to match the pairs.\nDuncan told me these labels are called â€˜biscuitsâ€™, which is charming.\n\nui &lt;- fluidPage(\n  \"hogwash\",\n  sidebarLayout(\n    \"tripe\",\n    mainPanel(\n      \"piffle\",\n      tabsetPanel(\n        \"bilge\",\n        tabPanel(\n          \"twaddle\"\n        )  # tabPanel\n      )  # tabsetPanel\n    )  # mainPanel\n  )  # sidebarLayout\n)  # fluidPage\n\nIdeally you donâ€™t want to write â€˜hadouken codeâ€™1 like this, though. A well-designed Shiny app would be modular and abstract away the functions, making everything a delight to read and understand.2"
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#paren-in-a-codestack",
    "href": "posts/2021-08-31-paren-label/index.html#paren-in-a-codestack",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Paren in a codestack",
    "text": "Paren in a codestack\nThere are a few ways that the RStudio IDE can help with the problem of bracket-buddying in long-winded scripts. In particular:\n\nPut your cursor next to a parenthesis and its partner will be automatically highlighted\nYou can auto-indent with Command + I and expose indent guides with Options &gt; Code &gt; Show indent guides so that paren-pairs are aligned vertically\nColour-match paren-pairs with rainbow colours, which you can activate with Options &gt; Code &gt; Display\nUse the keyboard shortcut Control + P to jump from an opening to a closing parenthesis\n\nYou can see these in action in this gif:\n\nThese go some way to helping, but each is not perfect for me, personally. For example, as someone with colourblindness, I find the rainbow colouring isnâ€™t distinct enough."
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#a-biscuit-recipe",
    "href": "posts/2021-08-31-paren-label/index.html#a-biscuit-recipe",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "A biscuit recipe",
    "text": "A biscuit recipe\nSo what if we want to use those closing-paren labels, or â€˜biscuitsâ€™, instead? There doesnâ€™t seem to be an option in RStudio for that.\nNaturally, I wondered about filling that gap in the market.\nAs a result, consider this post a thought-experiment manifested with some clunky code that is poorly tested and probably doesnâ€™t do exactly what you want it to do. You have been warned.\n\nEasy as A, B, D\nUsing R code, how can you work out the matching parentheses in an expression? Spoiler: itâ€™s not that simple.\nMaybe you could treat an expression as a string, then label the opening and closing parens in forward and reverse order, respectively.\nIn this example, the labels match up the parens for each imaginary function (uppercase for open-parens and lowercase for closing-parens):\n\n\"first(second(third()))\"\n#     A      B     Ccba\n\nBut this simple reversing heuristic doesnâ€™t work for these expressions:\n\n\"first(second(third(), fourth()))\"\n#     A      B     Cd        Dcba\n\n\"first(second(third(')')))\"\n#     A      B     C d cba\n\nIn the first example weâ€™d get the parens for third() and fourth() mixed up. In the second we have a sneaky unopened closing paren inside a string.\nNot forgetting that this doesnâ€™t solve how to extract each function name to use as the biscuit.\n\n\nâ€˜Overengineerâ€™ is my middle name\nRather than the naive approach of chopping up and counting strings, I decided to parse the actual R expressions from them.\nI created a function to do this, add_biscuits(), that contains sub-functions for three steps:\n\n.parse() to interpret the R code from an input\n.label() to match parenthesis pairs by their parent function, grab the parent function name and insert it as a comment after the closing paren\n.format() to stick it all back together and style it\n\nThe rest of the post walks through these functions. Iâ€™m certain thereâ€™s easier ways to do things, but the code here demonstrates the point Iâ€™m trying to reach.\nFor demonstration, we can use one of the trickier examples from above as our input.\n\nstring &lt;- \"first(second(third('x'), fourth('y')))\"\n\n\n1. Parse\nThe .parse() function takes a string containing R code and returns a dataframe of its â€˜syntax treeâ€™. In other words, it breaks the string into â€˜tokensâ€™ that are recognised as units of R code: function calls, assignment arrows, etc.\nIâ€™ve used getParseData(parse()) to do the hard work of parsing the string into a dataframe with one row per token. The downside is that you must provide to it a file rather than a character object, so we first have to write it to a temporary file.\nIâ€™ve then filtered the dataframe to get only the tokens that are R code (i.e.Â they arenâ€™t spaces) and renumbered the rows so theyâ€™re consecutive. This will be useful when we want to extract the function names for each set of parens.\n\n\nExpand the .parse() function definition\n\n\n.parse &lt;- function(string) {\n  \n  file &lt;- tempfile(fileext = \".R\")\n  writeLines(string, file)\n  \n  tokens &lt;- getParseData(parse(file))\n  parsed &lt;- parsed[parsed$terminal == TRUE, ]\n  rownames(parsed) &lt;- as.character(seq(nrow(parsed)))\n  \n  return(parsed)\n  \n}\n\n\nHereâ€™s what the output looks like:\n\ntree &lt;- .parse(string)\ntree[, c(\"line1\", \"col1\", \"parent\", \"token\", \"text\")]\n\n   line1 col1 parent                token   text\n1      1    1      3 SYMBOL_FUNCTION_CALL  first\n2      1    6     40                  '('      (\n3      1    7      6 SYMBOL_FUNCTION_CALL second\n4      1   13     35                  '('      (\n5      1   14      9 SYMBOL_FUNCTION_CALL  third\n6      1   19     16                  '('      (\n7      1   20     12            STR_CONST    'x'\n8      1   23     16                  ')'      )\n9      1   24     35                  ','      ,\n10     1   26     23 SYMBOL_FUNCTION_CALL fourth\n11     1   32     30                  '('      (\n12     1   33     26            STR_CONST    'y'\n13     1   36     30                  ')'      )\n14     1   37     35                  ')'      )\n15     1   38     40                  ')'      )\n\n\nSo each row is a recognised R token, e.g.Â the function name from the first() function is a SYMBOL_FUNCTION_CALL and 'x' is a STR_CONSTANT. Parentheses are recognised as separate special tokens too: '(' and ')'.\nWe also get returned the position of each token in the input (line* and col*) and a variable called parent which tells us something about the association of tokens. In our case, opening- and closing-parens have the same parent value.\n\n\n2. Label\nSo we can tie our paren pairs together with the parent variable and we know where to place the biscuit with the line1 and col1 information. But how to extract the function name and â€˜biscuitiseâ€™ it?\nIâ€™ve written the slightly awkward .label() function for this. It takes the output from .parse() and checks each row to see if itâ€™s a closing-paren token; if so, it finds the position of the matching open-paren by parent; then it looks at the text of the token in the preceding row to get the function name and sticks that in a new column called label.\n\n\nExpand the .label() function definition\n\n\n.label &lt;- function(tree) {\n  \n  tree$label &lt;- NA_character_\n  \n  for (tkn in seq_len(nrow(tree))) {\n    \n    tree$label[tkn] &lt;- ifelse(\n      tree$token[[tkn]] == \"')'\",\n      tree[as.numeric(rownames(\n        tree[tree$parent == tree$parent[[tkn]] & tree$token == \"'('\", ]\n      )) - 1, \"text\"],\n      NA_character_\n    )\n    \n  }\n  \n  return(tree)\n  \n}\n\n\nSo now we have the required biscuit for each closing paren:\n\ntree_lbl &lt;- .label(tree)\ntree_lbl[!is.na(tree_lbl$label), c(\"text\", \"label\")]\n\n   text  label\n8     )  third\n13    ) fourth\n14    ) second\n15    )  first\n\n\n\n\n3. Format\nThe last step needs involves sticking everything back together again. My quick solution is hacky and needs a refactor for sure.\nThe .format() function does a couple of awkward things: recognises and pastes commas to their preceding token (otherwise weâ€™ll get lines in the output that start with a comma, which is valid, but not my style) and pastes in the biscuits with a suffixed # to mark it as a comment. Of course, this blocks downstream code, so we can add a linebreak with \\n.\nThe output is still going to be a bit uggo though, so I employed {styler} to reformat it in tidyverse style. This is very definitely opinionated.\n\n\nExpand the .format() function definition\n\n\n.format &lt;- function(tree_lbl) {\n  \n  tree_lbl$comma &lt;- c(\n    ifelse(tree_lbl$text != \",\", NA_character_, \",\")[-1], NA_character_\n  )  # lag commas\n  \n  tree_lbl &lt;- tree_lbl[tree_lbl$token != \"','\", ]  # remove comma tokens\n  \n  tree_lbl$string &lt;- NA_character_\n  \n  for (tkn in seq_len(nrow(tree_lbl))) {\n    \n    if (!is.na(tree_lbl$comma[tkn])) {  # when there's a comma\n      \n      if (!is.na(tree_lbl$label[tkn])) {  # paste with biscuit\n        \n        tree_lbl$string[tkn] &lt;- paste0(\n          \"\\n\", tree_lbl$text[tkn], tree_lbl$comma[tkn],\n          \"#\", tree_lbl$label[tkn], \"\\n\"\n        ) \n        \n      } else if (is.na(tree_lbl$label[tkn])) {  # paste without biscuit\n        \n        tree_lbl$string[tkn] &lt;- paste0(\n          \"\\n\", tree_lbl$text[tkn], tree_lbl$comma[tkn], \"\\n\"\n        ) \n        \n      }\n      \n    } else if (is.na(tree_lbl$comma[tkn]) & !is.na(tree_lbl$label[tkn])) {\n      \n      tree_lbl$string[tkn] &lt;- paste0(\n        \"\\n\", tree_lbl$text[tkn], \"#\", tree_lbl$label[tkn], \"\\n\"\n      ) \n      \n    } else {  # no comma, no biscuit\n      \n      tree_lbl$string[tkn] &lt;- tree_lbl$text[tkn]\n      \n    }\n    \n  }\n  \n  string_out &lt;- paste0(tree_lbl$string, collapse = \"\")\n  string_out &lt;- gsub(\"\\n\\n\", \"\\n\", string_out)\n  \n  styled &lt;- suppressWarnings(\n    utils::capture.output(styler::style_text(string_out))\n  )\n  \n  paste(styled, collapse = \"\\n\")\n  \n}\n\n\nLetâ€™s hand over to .format() the labelled tree dataframe that was output from .label():\n\nout &lt;- .format(tree_lbl)\nout\n\n[1] \"first(\\n  second(\\n    third(\\\"x\\\"), # third\\n    fourth(\\\"y\\\") # fourth\\n  ) # second\\n) # first\"\n\n\nSo the output is a character vector, with one element per line of our output R file. You can see in the console how this looks.\n\ncat(out)\n\nfirst(\n  second(\n    third(\"x\"), # third\n    fourth(\"y\") # fourth\n  ) # second\n) # first\n\n\nReal noice: weâ€™ve got a comment after each closing bracket that notes which function itâ€™s closing. You can argue that some of these biscuits are redundant, but the goal has been achieved!\nA reminder of the original input:\n\nstring\n\n[1] \"first(second(third('x'), fourth('y')))\"\n\n\n\n\n4. Combined function\nAnd so, we can put these three steps together in one function: add_biscuits(), which is a cuter name than label_parens() or whatever.\n\nadd_biscuits &lt;- function(string) { \n  .parse(string) |&gt; .label() |&gt; .format()\n}\n\nThe output from each sub-function passes to the next, so itâ€™s a nice chance to use the pipe operator (R &gt;= v4.1).\nLetâ€™s try it on that awkward example with the sneaky extra bracket.\n\nstring2 &lt;- \"first(second(third(')')))\"\ncat(add_biscuits(string2))\n\nfirst(\n  second(\n    third(\")\") # third\n  ) # second\n) # first\n\n\nSo only the â€˜realâ€™ closing-paren tokens have been recognised and labelled."
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#bonus-rstudio-addin",
    "href": "posts/2021-08-31-paren-label/index.html#bonus-rstudio-addin",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Bonus: RStudio addin",
    "text": "Bonus: RStudio addin\nYouâ€™re thinking â€˜cool, but how can I use this thing practically?â€™ The answer is an RStudio addin.\nIâ€™ve written before about {blogsnip}, my package of R Markdown-related RStudio addins to help me prepare blog posts. Iâ€™ve put the add_biscuits() function in there for now.\nInstall from GitHub with {remotes} as follows and then restart RStudio. {blogsnip} doesnâ€™t force you to install {styler}, so youâ€™ll have to do that too (if you havenâ€™t already).\n\ninstall.packages(c(\"remotes\", \"styler\"))\nremotes::install_github(\"matt-dray/blogsnip\")\n\nThere should now be a â€˜BLOGSNIPâ€™ section in the â€˜Addinsâ€™ menu (top navigation bar) with an option to â€˜Add closing paren labelsâ€™. Select a full R expression in the script window, then select â€˜Add closing paren labelsâ€™. Your code will be replaced with the same code, but with biscuits inserted.\n\nBeware: your code will be replaced if you use the addin. Of course, you can edit or undo the output as necessary.\nYou can set a keyboard shortcut for this too, if you want. Go to Tools &gt; Modify Keyboard Shortcutsâ€¦. I set mine to Ctrl + Cmd + P, since Ctrl + P is the shortcut that jumps from opening to closing parens."
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#oh-crumbs",
    "href": "posts/2021-08-31-paren-label/index.html#oh-crumbs",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Oh, crumbsâ€¦",
    "text": "Oh, crumbsâ€¦\nLet me be clear: add_biscuits() is half-baked (lol). It works on the simple examples here, but Iâ€™m pretty sure it will break horribly on more complex things. I havenâ€™t really tested it properly.\nIt gets confused if thereâ€™s already some labelled closing parens. It gets confused if you donâ€™t highlight enough code to capture all the opening and closing parens. It gets confused if you run it over more than one expression. It ignores curly and square parentheses. Etc, etc.\nSo, use the function at your own risk, or better yet: improve it by contributing to {blogsnip}.\nOr even better yet, just use a good implementation of this functionality that someone else has probably written and Iâ€™ve been too lazy to search for.\nOr, yâ€™know, donâ€™t write heavily-nested code that requires you to write comments after closing parens."
  },
  {
    "objectID": "posts/2021-08-31-paren-label/index.html#environment",
    "href": "posts/2021-08-31-paren-label/index.html#environment",
    "title": "Auto-label closing parentheses in RStudio",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:09:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        crayon_1.5.2       cli_3.6.1          knitr_1.43.1      \n [5] rlang_1.1.1        xfun_0.39          rex_1.2.1          processx_3.8.2    \n [9] purrr_1.0.1        styler_1.10.1      xmlparsedata_1.0.5 jsonlite_1.8.7    \n[13] rprojroot_2.0.3    htmltools_0.5.5    ps_1.7.5           rmarkdown_2.23    \n[17] R.cache_0.16.0     evaluate_0.21      fastmap_1.1.1      lifecycle_1.0.3   \n[21] yaml_2.3.7         cyclocomp_1.1.0    compiler_4.3.1     lintr_3.0.2       \n[25] htmlwidgets_1.6.2  rstudioapi_0.15.0  R.oo_1.25.0        R.utils_2.12.2    \n[29] digest_0.6.33      R6_2.5.1           magrittr_2.0.3     callr_3.7.3       \n[33] R.methodsS3_1.8.2  tools_4.3.1        withr_2.5.0        lazyeval_0.2.2    \n[37] xml2_1.3.5         remotes_2.4.2      desc_1.4.2"
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html",
    "href": "posts/2021-08-27-dehex-app/index.html",
    "title": "Adding a Shiny app to {dehex}",
    "section": "",
    "text": "Use the {dehex} app to generate a random hex code and learn how to interpret it by eye."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#tldr",
    "href": "posts/2021-08-27-dehex-app/index.html#tldr",
    "title": "Adding a Shiny app to {dehex}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {dehex} package now contains a Shiny app that you can use to walk through the process of reading a colour hex code, as per David DeSandroâ€™s method."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#dehexcellent",
    "href": "posts/2021-08-27-dehex-app/index.html#dehexcellent",
    "title": "Adding a Shiny app to {dehex}",
    "section": "{dehex}cellent",
    "text": "{dehex}cellent\nIn the last post I introduced the R package {dehex}. Its purpose is to help me (you?) look at a colour hex code and be able to â€˜readâ€™ roughly what colour it is without resorting to a lookup.\n\n\n\nI promise this is a hex sticker, but itâ€™s background is white, whoops.\n\n\nSo, the computer-friendly code â€˜#C68738â€™ can be interpreted by your brain as the human-friendly phrase â€˜middle washed orangeâ€™.\nThe package only exists because of a mind-melting talk by David DeSandro and his recommendation of the approach due to his colourblindness. Iâ€™m also colourblind and would prefer to â€˜solveâ€™ a colour than try and guess what it is from a sample."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#an-apportunity",
    "href": "posts/2021-08-27-dehex-app/index.html#an-apportunity",
    "title": "Adding a Shiny app to {dehex}",
    "section": "An apportunity",
    "text": "An apportunity\nThe {dehex} package uses a number of functions to help you through the steps of DeSandroâ€™s method. It prints things to the R console to help you.1\nThereâ€™s dh_shorten() to simplify the code to three digits; dh_graph() to make an RGB chart of your shortened hex code; dh_guide() to preview hue, saturation and lightness profiles to match against your shortened hex code; and dh_solve() to provide you with â€˜the answerâ€™, along with RGB charts for the nearest hue, saturation and lightness (HSL) profiles.\n\n\n\nAn RGB bar chart printed by {dehex} to the console, with guides for hue, saturation and lightness.\n\n\nThe trouble is that you have to know what order to run these functions. The documentation, README and blog post provide this information, as well as DeSandroâ€™s resources, but it would be ideal to have an option to showcase {dehex} and learn stuff without needing to type any functions yourself.\nSo, Iâ€™ve created a simple Shiny app and made it available as the dh_app() function in {dehex}.2 I consider it â€˜in developmentâ€™ (this absolves me of liability if I say this, yes?).\nThe app depends on two packages: {shiny} and {bslib}. Youâ€™ll have to install these separately to {dehex} by using install.packages(c(\"shiny\", \"bslib\")) (if you havenâ€™t already installed them on your machine).\nThese arenâ€™t dependencies3 because you shouldnâ€™t be forced to install them if you have no plans on using the app.4\nAside: whatâ€™s fun is I get to make further use of the Shiny app README badge I invented (?) with my {badgr} package, like so:"
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#lolwat",
    "href": "posts/2021-08-27-dehex-app/index.html#lolwat",
    "title": "Adding a Shiny app to {dehex}",
    "section": "lolwat?",
    "text": "lolwat?\nThe app is pretty simple.\nThereâ€™s a big blue button labelled â€˜Generateâ€™. Click it and a random six-digit colour hex code is generated.\n\n\n\nâ€˜That is the question.â€™\n\n\nYour then proceed through the numbered tabs to learn about each step, get some quick bullets of explanation, and then have the option to reveal help via some outputs from functions in the {dehex} package. Thereâ€™s also a link to the relevant slide of David DeSandroâ€™s talk.\nAs a beginner, youâ€™ll want to reveal the tips to get maximum help. As you get better, you may not need to reveal them anymore.\nThe final tab provides the solution. You should have the answer by the time you get to this tab, but it reveals to you the hue, saturation and lightness RGB profiles that best match the generated hex code, along with the answer as a string, and a sample of the colour itself.\nThe app is purposefully low on interactivity. Itâ€™s just a little sidequest that bundles the steps and relevant {dehex} functions, in case you donâ€™t want to run the functions from R itself.5\nOriginally I was going to just create an app to go on the web for anyone to use, but why would they want to see outputs from {dehex}? I also think that itâ€™s worth reading DeSandroâ€™s blog and watching or reading his talk in the first instance.\nAs ever, send suggestions, issues and pull requests in the GitHub repo for the package."
  },
  {
    "objectID": "posts/2021-08-27-dehex-app/index.html#environment",
    "href": "posts/2021-08-27-dehex-app/index.html#environment",
    "title": "Adding a Shiny app to {dehex}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-08 19:08:45 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-11-14-r2eng/index.html#tldr",
    "href": "posts/2020-11-14-r2eng/index.html#tldr",
    "title": "Translate R to English with {r2eng}",
    "section": "tl;dr",
    "text": "tl;dr\nI created the work-in-progress {r2eng} package (source, site) to help translate R expressions to speakable English. Inspired by Amelia McNamara and with a huge amount of help from Chung-hong Chan."
  },
  {
    "objectID": "posts/2020-11-14-r2eng/index.html#communication-is-hard",
    "href": "posts/2020-11-14-r2eng/index.html#communication-is-hard",
    "title": "Translate R to English with {r2eng}",
    "section": "Communication is hard",
    "text": "Communication is hard\nAmelia McNamara (site, Twitter) gave a talk at the useR! 2020 conference called â€˜Speaking Râ€™. Watch the video on YouTube, or take a look at the slides.\nTo summarise greatly: R code should be speakable so that we can teach, learn and communicate with minimal friction.\nâ€˜Speakableâ€™ means I should be able to read an R expression to you as an English sentence (rather than reading out individual characters) and we should be able to understand each other.\nBut this is all easier said thanâ€¦ said.\nIdeally weâ€™d have an agreed dictionary that maps each R token to an equivalent English phrase. But there will always be variation between users and across communities; between beginners and aficionados; and given differences in spoken language.\nThen thereâ€™s context. We might agree that the operator %&gt;% is called a â€˜pipeâ€™, but you might say the word â€˜thenâ€™ when reading an expression. So data %&gt;% print() might be spoken as â€˜data then printâ€™.\nThe order of parsing may also differ between people. Something as simple as x &lt;- 1 could be â€˜x gets 1â€™, â€˜assign the value 1 to the variable named xâ€™, or something else entirely. Now imagine that on the scale of an entire script.\nI donâ€™t think we can completely â€˜solveâ€™ any of this, but we could probably develop the conversation with the help of a tool accessible from R itself."
  },
  {
    "objectID": "posts/2020-11-14-r2eng/index.html#hello-r2eng",
    "href": "posts/2020-11-14-r2eng/index.html#hello-r2eng",
    "title": "Translate R to English with {r2eng}",
    "section": "Hello {r2eng}",
    "text": "Hello {r2eng}\nThis is where the {r2eng} package comes in. The goal is to take an R expression and translate it to an equivalent speakable, English sentence, from within R itself.\nThe initial focus has been to:\n\nconcentrate on translating to English (Iâ€™m biased)\nmap the most common R operators (e.g.Â assignment, maths, brackets)\nuse commonly-used (but currently opinionated1) English translations for R operators (â€˜getsâ€™ for &lt;-)\nwork on a simple one-to-one, left-to-right mapping of R to English\nkeep the API simple, so you just supply an expression and get a result\nsimply begin an approach to address what was raised in Ameliaâ€™s presentation\n\nObviously the package is not finished, let alone perfect, and it requires more theoretical and practical considerations to make it truly useful. Clearly I donâ€™t have all the answers and Iâ€™m certainly not an arbiter of language, but I think the purpose is defined and it certainly works for simple cases.\nAt worst, I hope the package will encourage discussion. Thereâ€™s been some interest on Twitter and on the RStudio Community site, but do consider contributing thoughts and ideas to the {r2eng} GitHub repo.\nIn this vein, itâ€™s important to highlight Chung-hong Chanâ€™s valuable contributions to the package. Check out his website and find him on Twitter. Chung-hong was responsible for updating {r2eng} to handle non-standard evaluation in the translate() function and for replacing my original simple R-to-English lookup with a proper parsing method for interpreting R expressions.\n\nInstallation\nYou can install the package from GitHub using the {remotes} package. The package is in development version 0.0.0.9005 at the time of writing and this post discusses functionality for that version. Things may change.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r2eng\")\n\n\n\nHow it works\n\nRecognising tokens\nThe secret sauce of the package is that it recognises the â€˜tokensâ€™ that make up an R expression. So the assignment operator, &lt;-, is recognised as a single token rather than the less-than (&lt;) and hyphen (-) characters typed sequentially.\nThis power is brought to {r2eng} thanks to {lintr}, a package by Jim Hester that assesses your code for possible errors and style improvements.\nAn important part of this process is parsing R expressions and recognising tokens using the lintr::get_source_expressions() function. For example, that &lt;- operator is recognised as the special token LEFT_ASSIGN under the hood.\nThis is some deep R magic. You can see a special grammar file file in the R source code that carries these mappings.2\nPut simply, {r2eng} hijacks this process, adds a step that maps each token to English terms, then recombines the text into a sentence.\n\n\nSpeech\nBy default, {r2eng} will translate an R expression and then your computer will speak it out loud.\nThis is relatively straightforward on a Mac: the resulting English text is handed to your machine with a system() call and is vocalised by the built-in VoiceOver text-to-speech converter. This functionality is not built into Windows by default, so the system() call fails silently.\nOf course, this assumes that VoiceOver will do a good job of parsing the English expression from {r2eng}, but that isnâ€™t guaranteed because of issues like localised pronunciation and uncommon words. Iâ€™ve written before about how text-to-speech isnâ€™t necessarily that good at recognising R package names, for example.\nIn theory, and assuming that the translation gets good, {r2eng} could be used as a simple accessibility tool because it can interpret R-specific tokens in a way that VoiceOver cannot.\n\n\n\nUsing {r2eng}\nYou can find further examples in the package README, but Iâ€™ll explain here the main functionality.\nFirst Iâ€™ll attach the package after having installed it.\n\nlibrary(r2eng)\n\n\nThe translate() function\nThere are two main functions in {r2eng}: translate() and translate_string(). They convert from a bare or quoted R expression, respectively, to English.\ntranslate() takes advantage of non-standard evaluation: you pass bare (i.e.Â unquoted) R code to the expression argument and a few things happen.\n\ntranslate(data &lt;- 1 + 1)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nFirst, it prints both the original R expression and the corresponding English translation. Second, and only if you are using macOS, the English string is passed to a system command that vocalises the string.\nHereâ€™s a more complex example using some {dplyr} functions. Note that we donâ€™t need to attach {dplyr} to be able to translate.\n\ntranslate(\n  data %&gt;% select(x, y) %&gt;% dplyr::filter(y == \"example\"),\n  function_call_end = \"\"\n)\n\nOriginal expression: data %&gt;% select(x, y) %&gt;% dplyr::filter(y == \"example\")\nEnglish expression: data then select open paren x , y close paren then dplyr double-colon filter open paren y double equals string \"example\" close paren\n\n\nNote the function_call_end argument in this example. The default is \"of \", which would would have made the translation data then select of open paren x y close paren, etc. Feedback suggested that this was how some users spoke the English translation out loud, so the functionality has been included for now.\nWhile translate() takes a bare expression, translate_string() takes a string.\n\nlibrary(magrittr)  # attach for pipes\n\"data&lt;-1+1\" %&gt;%\n  translate_string(speak = FALSE)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nWe get the same sort of output as the translate() example, but this time I set the speak argument to FALSE to stop the English text from being â€˜spokenâ€™ by my computer and I also eliminated spaces from the input to demonstrate that theyâ€™re ignored.\n\n\nr2eng objects\nOf course, you can assign a translation to an object.\n\nmy_translation &lt;- \n  translate(data &lt;- 1 + 1, speak = FALSE)\n\nThe object is a special r2eng S3 class of object, which is also a list.\n\nclass(my_translation)\n\n[1] \"list\"  \"r2eng\"\n\n\nYou can apply some methods to such an object: print(), speak() and evaluate().\nPrint the object to see that custom console output again:\n\nprint(my_translation)\n\nOriginal expression: data &lt;- 1 + 1\nEnglish expression: data gets 1 plus 1 \n\n\nRe-call the system command that â€˜speaksâ€™ the R expression out loud (again, only on macOS).\n\nspeak(my_translation)\n\nAnd you can actually evaluate the R expression you supplied to translate() in the first place. So the expression we supplied, data &lt;- 1 + 1, is evaluated so that calling data gives us the result of 1 + 1.\n\nevaluate(my_translation)\ndata\n\n[1] 2\n\n\n\n\nr2eng-class list elements\nYou can also access the R expression, the English translation and the mapping between them as elements of your r2eng list object.\nHereâ€™s the R expression again:\n\nmy_translation$r_expression\n\n[1] \"data &lt;- 1 + 1\"\n\n\nAnd the translated output:\n\nmy_translation$eng_expression\n\n[1] \" data gets 1 plus 1 \"\n\n\nAnd a data.frame object that contains the mapping.\n\nmap &lt;- my_translation$translation_map\nmap[map$text != \"\", ]  # filter out text spaces\n\n        token text  eng\n1      SYMBOL data data\n2 LEFT_ASSIGN   &lt;- gets\n4   NUM_CONST    1    1\n6         '+'    + plus\n7   NUM_CONST    1    1\n\n\nThis element is a good summary of what {r2eng} is doing under the hood: it breaks the R expression into recognised tokens and maps words to them where it knows what the corresponding English for that token should be. So &lt;- is recognised as the token LEFT_ASSIGN, which is mapped internally to the English text gets.\n\n\n\nBonus material\n\nRStudio Addin\nThe print() and speak() functions can be accessed via an RStudio addin thatâ€™s installed with the package (you may need to restart RStudio after installation). To use them, highlight an R expression in your script and select from the RStudio addins menu:\n\nâ€˜Speak R Expression In Englishâ€™ to vocalise the expression through your computerâ€™s speakers (macOS only)\nâ€˜Print R Expression In Englishâ€™ to output an English translation to the console\n\nThese can be mapped to keyboard shortcuts so you can highlight and translate quickly without specifically calling translate() and print() or speak().\n\n\nBinder demo\nMaybe you donâ€™t want to install the package. Thatâ€™s fine. Instead, you can try out the package by opening this Binder instance of RStudio with {r2eng} and the tidyverse pre-installed. Click this badge to launch it:\n\n\n\n\n\nThe downside is that you canâ€™t use the speak method. Make sure to set the argument speak = FALSE in translate() or translate_string(), or youâ€™ll get a warning message when you run your code.\nYou can find the source for this at the try-r2eng GitHub repo and you can read one of my posts on how to set up Binder using Karthik Ramâ€™s {holepunch} package."
  },
  {
    "objectID": "posts/2020-11-14-r2eng/index.html#theres-lots-to-do",
    "href": "posts/2020-11-14-r2eng/index.html#theres-lots-to-do",
    "title": "Translate R to English with {r2eng}",
    "section": "Thereâ€™s lots to do",
    "text": "Thereâ€™s lots to do\nAs mentioned, this is really just the beginning.\nThereâ€™s plenty of room for simple improvements, as well as some long term possibilities. For example, we could:\n\nexpand the list of R tokens that can be translated\nallow for context-dependent translation where the same token can be used for more than one application\ndo user-research to find out the most common English terms used\nprovide instructions to make the speak method possible on non-Mac platforms\ninclude full script awareness so that we arenâ€™t limited by left-to-right interpretation\nexpand the package for non-English languages, or create {r2es}, {r2fr}, etc\netc\n\nHopefully we can work on some of these things and this wonâ€™t be the last post about {r2eng} on this blog. In the meantime, do consider contributing to the GitHub repo."
  },
  {
    "objectID": "posts/2020-11-14-r2eng/index.html#environment",
    "href": "posts/2020-11-14-r2eng/index.html#environment",
    "title": "Translate R to English with {r2eng}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:07:14 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3   r2eng_0.0.0.9005\n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3        crayon_1.5.2       cli_3.6.1          knitr_1.43.1      \n [5] rlang_1.1.1        xfun_0.39          rex_1.2.1          processx_3.8.2    \n [9] purrr_1.0.1        xmlparsedata_1.0.5 jsonlite_1.8.7     rprojroot_2.0.3   \n[13] htmltools_0.5.5    ps_1.7.5           rmarkdown_2.23     evaluate_0.21     \n[17] fastmap_1.1.1      lifecycle_1.0.3    yaml_2.3.7         cyclocomp_1.1.0   \n[21] compiler_4.3.1     lintr_3.0.2        htmlwidgets_1.6.2  rstudioapi_0.15.0 \n[25] digest_0.6.33      R6_2.5.1           callr_3.7.3        tools_4.3.1       \n[29] withr_2.5.0        lazyeval_0.2.2     xml2_1.3.5         remotes_2.4.2     \n[33] desc_1.4.2"
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#tldr",
    "href": "posts/2021-10-05-gorilla/index.html#tldr",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "tl;dr",
    "text": "tl;dr\nYou can convert a line drawing to datapoints with a sprinkle of {magick}."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#ape-escape",
    "href": "posts/2021-10-05-gorilla/index.html#ape-escape",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Ape escape",
    "text": "Ape escape\nHave you seen that video where youâ€™re so focused on counting basketball passes that you fail to see the gorilla moving across the screen?\nThis kind of selective attention was studied by two researchers, Yanai and Lercher, who provided subjects with a dataset that looked like a gorilla when plotted. The gorilla was found less often if the subjects were also given a hypothesis to investigate.\nThe study got some attention on Twitter last week. As a result, Isabella VelÃ¡squez wrote a great blogpost where she recreated the dataset using R and Python in tandem via the {reticulate} package.\nI had a go at creating the dataset with base R and the excellent {magick} package for image manipulation."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#point-it-out",
    "href": "posts/2021-10-05-gorilla/index.html#point-it-out",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Point it out",
    "text": "Point it out\nThe jpeg image file used in the original paper can be downloaded from classroomclipart.com to a temporary location on your machine.\n\ndownload.file(\n  paste0(\n    \"https://classroomclipart.com/images/gallery/\",\n    \"Clipart/Black_and_White_Clipart/Animals/\",\n    \"gorilla-waving-cartoon-black-white-outline-clipart-914.jpg\" \n  ),\n  tempfile(fileext = \".jpg\")\n)\n\nWe can read the file into R with {magick}.\n\nimg &lt;- \n  list.files(tempdir(), pattern = \".jpg$\", full.names = TRUE) |&gt;\n  magick::image_read()\n\nimg\n\n\n\n\nWith other {magick} functions we can:\n\nreduce to two distinct colours only (i.e.Â for the lines and background), which makes it easier to filter the data later\nconvert from an image to point data\n\n\ngo &lt;- img |&gt;\n  magick::image_quantize(2) |&gt;  # colour reduction\n  magick::image_raster() |&gt;     # as x-y data\n  as.data.frame()\n\nhead(go)\n\n  x y       col\n1 1 1 #fefefeff\n2 2 1 #fefefeff\n3 3 1 #fefefeff\n4 4 1 #fefefeff\n5 5 1 #fefefeff\n6 6 1 #fefefeff\n\n\nAnd to prove we only have two colours (off-white for the background, grey for the lines):\n\nunique(go$col)\n\n[1] \"#fefefeff\" \"#555555ff\"\n\n\nNow we can:\n\nreverse the order of the y values so the gorilla is right-side up\nfilter to retain only the datapoints that represent lines\nrescale the x and y to create â€˜Body Mass Indexâ€™ (BMI)1 and â€˜stepsâ€™ variables\n\n\ngo$y     &lt;- rev(go$y)\ngo       &lt;- go[go$col != \"#fefefeff\", ]\ngo$bmi   &lt;- go$y / max(go$y) * 17 + 15\ngo$steps &lt;- 15000 - go$x * 15000 / max(go$x)\n\nhead(go)\n\n      x   y       col bmi    steps\n174 174 550 #555555ff  32 8665.049\n175 175 550 #555555ff  32 8628.641\n176 176 550 #555555ff  32 8592.233\n196 196 550 #555555ff  32 7864.078\n198 198 550 #555555ff  32 7791.262\n199 199 550 #555555ff  32 7754.854\n\n\nYou may have noticed that the image has a watermark. We could have removed it earlier with {magick}, but can do it now by filtering out the datapoints in that corner.\n\ngo$logo &lt;- ifelse(go$bmi &lt; 16 & go$steps &lt; 5500, TRUE, FALSE)\ngo      &lt;- go[!go$logo, ]\n\nThis leaves us with 16865 datapoints. We can follow the original study by taking a sample and splitting the results into â€˜femaleâ€™ and â€˜maleâ€™ groups, weighted so that the female group has higher step counts.\n\ngo_smp       &lt;- go[sample(nrow(go), 1768), ]\ngo_smp$rnorm &lt;- rnorm(nrow(go_smp), mean = 0, sd = 10)\ngo_smp$index &lt;- go_smp$steps * (1 + go_smp$rnorm)\ngo_smp$group &lt;- \n  ifelse(go_smp$index &lt; median(go_smp$steps), \"F\", \"M\") |&gt;\n  as.factor()\n\nhead(go_smp[, c(\"bmi\", \"steps\", \"group\")])\n\n            bmi       steps group\n135597 21.83091 13216.01942     F\n85694  25.60182    72.81553     F\n199825 17.00909 14817.96117     F\n43530  28.75455  5169.90291     M\n200308 16.97818 12233.00971     F\n55403  27.85818  7900.48544     F\n\n\nNow finally to plot the datasets side-by-side.\n\npar(mfrow = c(1, 2))\n\nwith(\n  go_smp[go_smp$group == \"F\", ],\n  plot(\n    steps, bmi,\n    xlim = c(0, 15000),\n    pch = 16, cex = 0.5, col = \"blue\",\n    xlab = \"Steps\", ylab = \"BMI\", \n  )\n)\n\nwith(\n  go_smp[go_smp$group == \"M\", ],\n  plot(\n    steps, bmi, \n    xlim = c(0, 15000),\n    pch = 16, cex = 0.5, col = \"red\",\n    xlab = \"Steps\", ylab = \"BMI\"\n  )\n)\n\n\n\n\nI see them!\nThis has been a bit overengineered and could be generalised, but it gives a gist of how you might go about converting an image to a dataframe of x and y positions.\nAt worst, this is a reminder not to trust researchers and to always check for unexpected gorillas."
  },
  {
    "objectID": "posts/2021-10-05-gorilla/index.html#environment",
    "href": "posts/2021-10-05-gorilla/index.html#environment",
    "title": "Reveal a hidden gorilla with {magick}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-07 21:11:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         magrittr_2.0.3   \n [5] knitr_1.43.1      htmltools_0.5.5   png_0.1-8         rmarkdown_2.23   \n [9] cli_3.6.1         compiler_4.3.1    rstudioapi_0.14   tools_4.3.1      \n[13] evaluate_0.21     Rcpp_1.0.10       yaml_2.3.7        magick_2.7.4     \n[17] rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#tldr",
    "href": "posts/2021-08-27-zzz/index.html#tldr",
    "title": "Exploring R package startup messages",
    "section": "tl;dr",
    "text": "tl;dr\nI got curious about R package startup messages, so I grabbed all the special zzz.R files from R packages that are on CRAN and sourced on GitHub. You can jump to the table of results."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#start-me-up",
    "href": "posts/2021-08-27-zzz/index.html#start-me-up",
    "title": "Exploring R package startup messages",
    "section": "Start me up",
    "text": "Start me up\nI learnt recently from Hernando Cortina that his and Amanda Dobbynâ€™s {multicolor} package prints to the console some multicoloured ASCII-art text of the packageâ€™s name when you call it with library(multicolor).\nIt gave me an itch to scratch: how often are these sorts of startup messages used by R packages? What do people put in them? Is there anything funny in them? Anything nefarious?"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#a-strong-attachment",
    "href": "posts/2021-08-27-zzz/index.html#a-strong-attachment",
    "title": "Exploring R package startup messages",
    "section": "A strong attachment",
    "text": "A strong attachment\nA package may need to run additional code before its functions can work, like maybe some options() need to be set.\nThere are two times this kind of code can be run: when the package is loaded, including namespace calls like dplyr::select(), or more specifically when the package is attached with library().\nTo prepare code for running on-load or on-attach, you create the special functions .onLoad() and .onAttach(). These go in a zzz.R file in the R/ directory of your package, becauseâ€¦ convention?\nThe on-attach option is useful for printing messages for the user to see in the console, like the {multicolor} example above. You want this to happen on-attach and not on-load, since you wouldnâ€™t want to print a message every single your script uses the :: namespace qualifier.\nTo specify a message in the body of your .onAttach() function, you use packageStartupMessage(). Why not just cat() or message()? Because it allows the user to quell startup messages using suppressPackageStartupMessages().\nYou can learn more in Hadley Wickhamâ€™s R Packages book.\nAs an example, consider the {tidyverse} package, which has some verbose output on attach:\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.2     âœ” readr     2.1.4\nâœ” forcats   1.0.0     âœ” stringr   1.5.0\nâœ” ggplot2   3.4.2     âœ” tibble    3.2.1\nâœ” lubridate 1.9.2     âœ” tidyr     1.3.0\nâœ” purrr     1.0.1     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nBut you can shush it with the suppressPackageStartupMessages() function:1\n\ndetach(\"package:tidyverse\")  # first detach it\nsuppressPackageStartupMessages(library(tidyverse))\n\nPeace.\nSo the startup messages of {multicolor} and {tidyverse} do two completely different things: one is fun and frivolous and the other is informative. Isnâ€™t it possible that someone could put ads in the startup message or use it in evil ways? Well, perhaps.\nLetâ€™s find out what R package developers put in their startup messages. How many packages even have a zzz.R file and how many of those even contain a packageStartupMessage() call?"
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#catching-some-zs",
    "href": "posts/2021-08-27-zzz/index.html#catching-some-zs",
    "title": "Exploring R package startup messages",
    "section": "Catching some Zs",
    "text": "Catching some Zs\nI understand if all this talk of zzz.R causes you toâ€¦ zzz. In short, if you want to get all the zzz.R files, you can:\n\nGet a list of R packages on CRAN\nIdentify which ones have an associated GitHub repo\nGet the default branch name of each one and construct the possible URL to their zzz.R file\nContact the possible zzz.R file to see if it exists\nIf it exists, download it\nFilter for zzz.R files that contain packageStartupMessage()\n\nWeâ€™ve already attached the tidyverse packages, but weâ€™ll also need two more packages:\n\nlibrary(gh)    # interact with GitHub API\nlibrary(httr)  # requests via the internet \n\n\n Note\nIf youâ€™re thinking this approach is a bit long-winded, youâ€™re right. As Tim pointed out, we could just extract the info via METACRAN, an unofficial CRAN mirror hosted on GitHub. It even has its own API. Iâ€™ll leave that as an exercise for the reader.\n\n\nPackages\nLuckily you can grab info for all current CRAN packages with the very handy CRAN_package_db() function.2\n\ncran_pkgs &lt;- as_tibble(tools::CRAN_package_db())\n\nThis returns a dataframe containing 19865 rows, where each one is a package, along with 67 variables. We get information like the stuff thatâ€™s found in package DESCRIPTION files, but it doesnâ€™t tell us whether a package has a zzz.R file.\nOne way to do this is to visit the GitHub repo associated with the package, if it has one, and see if a zzz.R exists. Of course, many packages are not on GitHub, but weâ€™re going to ignore those for simplicity.\n\n Note\nI re-rendered this post in July 2023, so the output no longer reflects CRAN as it was when this post was published (August 2021).\n\n\n\n\nGithub repos\nA quick way of discovering if a package has a GitHub repo is to check for â€˜github.comâ€™ in the BugReports section of it DESCRIPTION file.3 Again, this doesnâ€™t capture all the possible repos, but is fine for now.\n\nhas_repo &lt;- cran_pkgs %&gt;% \n  select(Package, BugReports) %&gt;% \n  filter(str_detect(BugReports, \"github\")) %&gt;% \n  transmute(\n    Package,\n    owner_repo = str_extract(\n      str_replace_all(paste0(BugReports, \"/x\"), \"//\", \"/\"),\n      \"(?&lt;=github.com/).*(?=/[a-zA-Z])\"\n    )\n  ) %&gt;% \n  separate(owner_repo, c(\"owner\", \"repo\"), \"/\") %&gt;% \n  filter(!is.na(Package), !is.na(owner), !is.na(repo)) %&gt;% \n  distinct(Package, owner, repo) %&gt;% \n  arrange(Package) \n\nsample_n(has_repo, 5)\n\n# A tibble: 5 Ã— 3\n  Package     owner          repo       \n  &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;      \n1 MatrixEQTL  andreyshabalin MatrixEQTL \n2 mitre       motherhack3r   mitre      \n3 path.chain  krzjoa         path.chain \n4 shinyXYpad  stla           shinyXYpad \n5 netdiffuseR USCCANA        netdiffuseR\n\n\nThere were 19865 CRAN packages total and now we have 8152 (41%) that appear to have a GitHub repo.\nIf youâ€™re wondering why we didnâ€™t just use the package name as the repo name, itâ€™s because they sometimes donâ€™t match, e.g.Â {baseballDBR} is in a repo called â€˜moneyballâ€™.\nNow we can use the repo details to build a URL to a potential zzz.R URL. This comes in the form https://raw.githubusercontent.com/&lt;owner&gt;/&lt;repo&gt;/&lt;defaultbranch&gt;/R/zzz.R\".\n\n\nDefault branch\nYouâ€™ll notice we donâ€™t yet know the default branch of the packageâ€™s GitHub repo. Historically, we could probably have just hard-coded â€˜masterâ€™, but the automatic default is now â€˜mainâ€™. And of course, the default branch could be something else entirely.\nWe can grab the default branch for each repo from the GitHub API using the excellent {gh} package by GÃ¡bor CsÃ¡rdi, Jenny Bryan and Hadley Wickham. Youâ€™ll need to do some setup to use it yourself.\nThe key function is gh(), to which you can pass a GET request for the information we want: GET /repos/{owner}/{repo}. We can iterate for each repo by passing each owner and repo name in turn. It returns a list object with lots of information about the repo.\nIâ€™ve created â€˜possiblyâ€™ function variants with {purrr} so that any errors in the process are handled by returning NA, rather than breaking the loop, which would kill the process.\n\n# Create 'try' function versions\nmap2_possibly &lt;- possibly(map2, NA_real_)\ngh_possibly &lt;- possibly(gh, NA_real_)\n\n# Function: fetch repo details, print message on action\nget_repo &lt;- function(owner, repo) {\n  cat(paste0(\"[\", Sys.time(), \"]\"), paste0(owner, \"/\", repo), \"\\n\")\n  gh_possibly(\"GET /repos/{owner}/{repo}\", owner = owner, repo = repo) \n}\n\nmaybe_zzz &lt;- has_repo %&gt;%\n  mutate(\n    repo_deets =  map2_possibly(\n      has_repo$owner, has_repo$repo, get_repo\n    )\n  ) %&gt;% \n  mutate(\n    default_branch = map(\n      repo_deets, ~pluck(.x, \"default_branch\")\n    ),\n    default_branch = pluck(default_branch, 1),\n    zzz_url = paste0(\n      \"https://raw.githubusercontent.com/\",\n      owner, \"/\", repo, \"/\", default_branch, \"/R/zzz.R\"\n    )\n  )\n\nSo now we have a column with the returned repo information, the extracted default branch name and a URL that points to a potential zzz.R file in that repo.\n\nhead(maybe_zzz)\n\n# A tibble: 6 Ã— 6\n  Package      owner           repo         repo_deets default_branch zzz_url   \n  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;        &lt;list&gt;     &lt;chr&gt;          &lt;chr&gt;     \n1 AATtools     Spiritspeak     AATtools     &lt;gh_rspns&gt; master         https://râ€¦\n2 ABHgenotypeR StefanReuscher  ABHgenotypeR &lt;gh_rspns&gt; master         https://râ€¦\n3 ABM          junlingm        ABM          &lt;gh_rspns&gt; master         https://râ€¦\n4 ACEP         agusnieto77     ACEP         &lt;gh_rspns&gt; master         https://râ€¦\n5 ACNE         HenrikBengtsson ACNE         &lt;gh_rspns&gt; master         https://râ€¦\n6 ACWR         JorgeDelro      ACWR         &lt;gh_rspns&gt; master         https://râ€¦\n\n\n\n\nStatus codes\nNow we can check the status code for each of the URLs weâ€™ve built. A return of 200 tells us that the file exists and 404 means it doesnâ€™t.4 Again, we can prevent the loop breaking on error by creating a â€˜possiblyâ€™ version of map().\n\nlibrary(httr)  # for status_code()\n\nmap_possibly &lt;- possibly(map, NA_character_)\n\nmaybe_zzz_status &lt;- maybe_zzz %&gt;% \n  mutate(\n    status = map_possibly(\n      zzz_url, ~status_code(GET(.x))\n    )\n  ) %&gt;% \n  unnest(status)\n\ncount(maybe_zzz_status, status)\n\n# A tibble: 2 Ã— 2\n  status     n\n   &lt;int&gt; &lt;int&gt;\n1    200  1519\n2    404  6631\n\n\nOkay, great, weâ€™ve got over a thousand zzz.R files.\n\n\nRead content\nNow we know which packages have a zzz.R file, we can use readLines() to grab their content from their URL, which again we can protect from errors with purrr::possibly().\nNote that Iâ€™ve created a special version of readLines() that reports to the user the path being checked, but also has a random delay. This is to dampen the impact on GitHubâ€™s servers.\n\n# Function: readLines() but with a pause and message\nreadLines_delay &lt;- function(path) {\n  sample(1:3, 1)\n  cat(paste0(\"[\", Sys.time(), \"]\"), path, \"\\n\")\n  readLines(path, warn = FALSE)\n}\n\nreadLines_delay_possibly &lt;- possibly(readLines_delay, NA_character_)\n\nfosho_zzz &lt;- maybe_zzz_status %&gt;% \n  select(-repo_deets) %&gt;% \n  filter(status == 200) %&gt;%  # just the \n  mutate(lines = map_possibly(zzz_url, readLines_delay_possibly))\n\ndim(fosho_zzz)\n\nSo now we have a dataframe with a row per package and a list-column containing the R code in the zzz.R file.\n\n\nStartup messages\nFinally, we can find out which packages have a packageStartupMessage() call inside their zzz.R.\n\nhas_psm &lt;- fosho_zzz %&gt;% \n  select(Package, lines) %&gt;%\n  unnest(lines) %&gt;%\n  filter(str_detect(lines, \"packageStartupMessage\")) %&gt;% \n  mutate(lines = str_remove_all(lines, \" \")) %&gt;%\n  distinct(Package) %&gt;% \n  pull()\n\nfosho_psm &lt;- filter(fosho_zzz, Package %in% has_psm)\n\nSo we started with 19865 CRAN packages and have winnowed it to down to 579 (3%) that have a call to packageStartupMessage() in their zzz.R.\n\n\nTable of results\nI could provide a table with all the zzz.R content, but I donâ€™t want to break any licenses by reproducing them all here. Instead, hereâ€™s an interactive table that links to the GitHub page for each zzz.R file that appears to have a package startup message.\n\n\nClick for table code\n\n\nlibrary(reactable)\n\nreactable(\n  data = fosho_psm %&gt;% \n    select(package = Package, owner, url = zzz_url),\n  searchable = TRUE,\n  paginationType = \"jump\",\n  defaultPageSize = 10,\n  columns = list(\n    url = colDef(cell = function(value) {\n      htmltools::tags$a(href = value, target = \"_blank\", \"zzz.R\")\n    })\n  )\n)\n\n\n\n\n\n\n\n\n\n Note\nI re-rendered this post in July 2023, so the table above may contain different packages to when it was first published. The section below relates to the originally-published post and may no longer reflect the content of the zzz.R files listed in the table above.\n\n\n\nPatterns\nI had a scan through the scripts and found some frequent uses of packageStartupMessages() to:\n\nshow a basic salutation (e.g.Â {afex})\nshow the version number, a check to see if the user has the latest version, sometimes a prompt to download the latest version for them (e.g.Â {vistributions}), sometimes a note that the package has been superseded by another (e.g.Â {drake})\nlinks to guidance, examples, documentation (e.g.Â {bayesplot})\nprovide a citation or author names (e.g.Â {unvotes})\nlink to issue tracking or bug reporting (e.g.Â {timeperiodsR})\ncheck for required supplementary software (e.g.Â {DALY})\nremind of the need for credentials or keys for packages that access APIS, for example (e.g.Â {trainR})\nprovide terms of use, warranties, licenses, etc (e.g.Â {emmeans})\n\nI was also interested to see:\n\na random tip, so you get something new each time you attach the package (e.g.Â {shinyjs})\nappeals for GitHub stars (e.g.Â {sigminer})\nlinks to purchasable course materials (e.g.Â {anomalise})\n\nAnd perhaps the most self-aware were several packages that reminded the user that they can turn off startup messages with suppressPackageStartupMessages() if the messages get too annoying (e.g.Â {dendextend}).\nA few interesting specifics (possible spoiler alerts!):\n\n{bayestestR} and {sjmisc} have displays a special Star Wars message on a certain day of the yearâ€¦\n{SHT} and {symengine} load ASCII art, as does {BetaBit}, which also prompts the user for a game theyâ€™d like to play\n{depigner} says â€˜Welcome to depigner: we are here to un-stress you!â€™\n{mde} has a friendly â€˜Happy Exploration :)â€™ salutation and {manymodelr} says â€˜Happy Modelling! :)â€™\n{sjPLot} says â€˜#refugeeswelcomeâ€™\n\nYou can use the interactive table above to reach each of the zzz.R files for these packages, or have a sift through yourself to see what you can find."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#buy-my-stuff",
    "href": "posts/2021-08-27-zzz/index.html#buy-my-stuff",
    "title": "Exploring R package startup messages",
    "section": "Buy my stuff?",
    "text": "Buy my stuff?\nIs there a line somewhere? Is it okay to advertise something? You could argue that someone has gone out of their way to release a package for free, so what harm is it in trying to get something back? or does this approach undermine the whole â€˜openâ€™ process?\nI know some people find startup messages a bit annoying, but I think itâ€™s easy enough for users to opt out of seeing them with a call to suppressPackageStartupMessages().\nMostly Iâ€™m kind of surprised by the lack of abuse of packageStartupMessage() in this sample. Let me know of any cheeky business you might have come across."
  },
  {
    "objectID": "posts/2021-08-27-zzz/index.html#environment",
    "href": "posts/2021-08-27-zzz/index.html#environment",
    "title": "Exploring R package startup messages",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:29:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reactable_0.4.4 httr_1.4.6      gh_1.4.0        tidyverse_2.0.0\n [5] lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.2    \n [9] purrr_1.0.1     readr_2.1.4     tidyr_1.3.0     tibble_3.2.1   \n[13] ggplot2_3.4.2  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3      jsonlite_1.8.7    compiler_4.3.1    tidyselect_1.2.0 \n [5] scales_1.2.1      yaml_2.3.7        fastmap_1.1.1     R6_2.5.1         \n [9] generics_0.1.3    knitr_1.43.1      htmlwidgets_1.6.2 munsell_0.5.0    \n[13] pillar_1.9.0      tzdb_0.4.0        rlang_1.1.1       utf8_1.2.3       \n[17] stringi_1.7.12    reactR_0.4.4      xfun_0.39         timechange_0.2.0 \n[21] cli_3.6.1         withr_2.5.0       magrittr_2.0.3    crosstalk_1.2.0  \n[25] digest_0.6.31     grid_4.3.1        fontawesome_0.5.1 rstudioapi_0.15.0\n[29] hms_1.1.3         lifecycle_1.0.3   vctrs_0.6.3       evaluate_0.21    \n[33] glue_1.6.2        fansi_1.0.4       colorspace_2.1-0  rmarkdown_2.23   \n[37] ellipsis_0.3.2    tools_4.3.1       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html",
    "href": "posts/2020-06-06-acnh-swipe/index.html",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "",
    "text": "Lily &lt;3 4eva"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#tldr",
    "href": "posts/2020-06-06-acnh-swipe/index.html#tldr",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "tl;dr",
    "text": "tl;dr\nThe villagers of Animal Crossing: New Horizons are taking part in a popularity contest and youâ€™re the judge.\nI made an R Shiny app where you swipe right if you like a randomly-presented villager and left if you dislike them.\nVisit the app here and help decide the most popular villager! You can also visit the source code."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#tidy-tuesday",
    "href": "posts/2020-06-06-acnh-swipe/index.html#tidy-tuesday",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Tidy Tuesday",
    "text": "Tidy Tuesday\nTidy Tuesday is an open event for the R community. The organisers provide a data set and participants submit their take on wrangling and presenting the data, usually via Twitter with the hashtag #tidytuesday.\nA recent data set (week 19) via VillagerDB includes information about villager non-player characters from the wildly popular Animal Crossing: New Horizons game for the Nintendo Switch. A similar set of data was also uploaded to Kaggle.\nI couldnâ€™t resist, having recently written about learning R6 object-oriented programming with an Animal Crossing example.\nThis was also a good chance to learn more about two packages in particular: {shinysense} and {googlesheets4}.\n\n{shinysense}\nNick Strayerâ€˜s {shinysense} package lets Shiny â€™sense the world around itâ€™, with modules for touch, vision, hearing and motion.\nI wanted to try out shinyswipr, which presents a user with a â€˜cardâ€™ that they can swipe. The direction of swiping can be used to indicate something, like a preference. After swiping, the card content can be updated.\nYou can read Nickâ€™s blog post about its inception.\n\n\n{googlesheets4}\nIn Nickâ€™s shinyswipr example, he presents back to the user their swipe history, but how can we record the information from all users and return the collated results?\nThereâ€™s a number of ways to do persistent storing with Shiny, but a relatively simple one is to write the data to Google Sheets and read the entire sheet back into the app.\nThe {googlesheets4} package by Jenny Bryan helps you do exactly that, with functions like sheet_append() and read_sheet()."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#the-acnh-popularity-contest",
    "href": "posts/2020-06-06-acnh-swipe/index.html#the-acnh-popularity-contest",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "The ACNH Popularity Contest",
    "text": "The ACNH Popularity Contest\nThereâ€™s a lot of articles online about favourite villagers, but they arenâ€™t very democratic. They tend to cite characters like Raymond, Beau, Marshal, Judy and Audie.\nItâ€™s time to let the people speak."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#how-to-use",
    "href": "posts/2020-06-06-acnh-swipe/index.html#how-to-use",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "How to use",
    "text": "How to use\nIf you visit the app, or look at the image at the top of this post, youâ€™ll see that the user is presented with a card containing a randomly-selected villager and some details (name, species, personality and hobby).\nYou can move the card to the right to indicate you like the character, or to the left if you dislike them. On mobile you can swipe left or right with your finger. On desktop you can click and drag the card.\n\n\n\nNo dates guaranteed. The characters arenâ€™t actually real, yâ€™see.\n\n\nThe swipe event results in the information being written to a Google Sheet and triggers the entirety of the updated data set to be read back to the app. Itâ€™s then wrangled lightly and the information is presented as a table of the current top 10 villagers by â€˜likeâ€™ count. Finally, a new random villager is presented.\nThis is obviously a bit of fun and definitely not polished. Do let me know of any bugs that you find, though. Iâ€™m aware that mobiles may not display the fonts correctly, for example.\n\nData and hosting\nNo data about the user is stored. The app records only the date-time, the villager name and the swipe direction.\nThe app is hosted for free on shinyapps.io, so thereâ€™s a limited number of uptime hours it can use per month."
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#results",
    "href": "posts/2020-06-06-acnh-swipe/index.html#results",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Results",
    "text": "Results\nI hope that enough people cast a vote to make the results interestingâ€¦ but thereâ€™s nearly 400 villagers, so that seems unlikely!\n\n Note\nIâ€™ve written a more recent post where I aggregated the results for the thousands of swipes that people made in the app!"
  },
  {
    "objectID": "posts/2020-06-06-acnh-swipe/index.html#environment",
    "href": "posts/2020-06-06-acnh-swipe/index.html#environment",
    "title": "Animal Crossing Tinder with {shinysense}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:47:26 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#tldr",
    "href": "posts/2021-04-10-dialga/index.html#tldr",
    "title": "Convert R to cron to English with {dialga}",
    "section": "tl;dr",
    "text": "tl;dr\nI made the small proof-of-concept R package {dialga} to help build and interpret standard cron expressions using familiar R syntax. r2cron() converts R to cron; cron2eng() converts cron to English."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#cronwhat",
    "href": "posts/2021-04-10-dialga/index.html#cronwhat",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Cronwhat?",
    "text": "Cronwhat?\nYou can schedule scripts to run at specific times using software on your computer called â€˜cronâ€™. You can set up â€˜cron jobsâ€™ to specify what needs to be run. A key part of the recipe is a short cron string that provides instructions about when to run it.\nThe problem: cron strings are a bit cryptic if youâ€™re not a sysadmin and donâ€™t set up cron jobs very often. Hereâ€™s a contrived example: \"0/15 * 1,3,20 6 2,3\". What the heck does that mean?\nCase study: me. Iâ€™ve been scheduling GitHub Actions using cron strings to specify when the actions should be triggered. For example, I set up a Twitter bot called londonmapbot that currently tweets a random aerial image every half-hour.\nThereâ€™s a bunch of webservices like crontab.guru that help you construct cron expressions. I wondered if I could build one in R. Itâ€™s basically just a bunch of string handling and if statements, right? And while youâ€™re at it, why not offer translation the other way? You have a cron string and you want to â€˜translateâ€™ it to English. Could be helpful."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#new-development-paradigm",
    "href": "posts/2021-04-10-dialga/index.html#new-development-paradigm",
    "title": "Convert R to cron to English with {dialga}",
    "section": "New development paradigm",
    "text": "New development paradigm\nAn aside. Two things: the package is about time and Iâ€™ve been looking recently at RepokÃ©mon, a site that tracks which PokÃ©mon have GitHub repos named after them.\nTherefore the package is called Dialga,1 named for the â€˜temporal PokÃ©monâ€™, which is the legendary mascot of the PokÃ©mon Diamond game. The hex logo uses colours from the gameâ€™s sprite.\n\n\n\nDialga sprite from PokÃ©mon Diamond (bulbapedia.bulbagarden.net)\n\n\nWeâ€™ve been here before. Consider {safar6}, my R package that contains an R6-class object that lets you play a text version of the Safari Zone from PokÃ©mon Red and Blue. Or a PokÃ©mon carousel widget with {slickr}. Or PokÃ©balls in Super Smash Bros.\nI call this approach PokÃ©mon-Driven Development (PDD). I think PDD has real promise in the development of pointless side-projects like this one. Use it wisely."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#dialga-demo",
    "href": "posts/2021-04-10-dialga/index.html#dialga-demo",
    "title": "Convert R to cron to English with {dialga}",
    "section": "{dialga} demo",
    "text": "{dialga} demo\nThe package is available on GitHub; there are no plans for it to go on CRAN. You can use the {remotes} package to help you download {dialga} easily from the web.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/dialga\")\nlibrary(dialga)\n\nIn the same vein as the {r2eng} package, the two functions are named r2cron() and cron2eng(). This is pretty self-explanatory: r2cron() takes R inputs as integer vectors and spits out a cron string, and cron2eng() takes a valid cron string and prints out a readable English version.\nAs ever, it was banged-out in a couple of days and I canâ€™t promise itâ€™s bug-free. Let me know if you find anything broken horribly.\n\n Note\nThe package moved to v0.1 since this post was published. The update removed all dependencies, improved the documentation and set clipboard-copying behaviour to FALSE by default. Feel free to offer more improvements.\n\n\nA primer\nBut first, a quick demo on standard cron expressions. Their format is a string of five time-period â€˜slotsâ€™ separated by spaces. The slots from left to right specify the minutes, hours, days of the month, months, and days of the week that you want to schedule your script to run.\nThe format required for the values in these slots can be expressed relatively easily as R code, which is what r2cron() uses as input. For example, this table shows cron-string formats for the minutes slot and the corresponding R integer vector for them:\n\n\n\n\n\n\n\n\nDescription\nCron\nR\n\n\n\n\nEvery minute (minutes 0 to 59)\n*\n0:59\n\n\nA single minute (5)\n5\n5\n\n\nA consecutive sequence of minutes (1, 2 and 3)\n1-3\n1:3\n\n\nSeveral irregularly-spaced minutes (1, 15 and 17)\n1,15,17\nc(1, 15, 17)\n\n\nA sequence of minutes at regular intervals for the whole hour, starting with some value (every 15 minutes starting at minute 0)\n0/15\nseq(0, 59, 15)\n\n\n\nThe same principles extend to the other time-period slots, but the ranges will obviously differ. For example, the hour slot can take values 1 to 23 (i.e.Â a 24-hour clock), while the days of the week are zero-indexed from 0 (Sunday) to 6 (Saturday). An asterisk is a special character meaning every unit of that time period, like every minute and every hour.\nSo â€˜every 30th minute past the hourâ€™ would be \"30 * * * *\". The contrived example string from the opening of this postâ€”\"0/15 * 1,3,20 6 2,3\"â€”translates as â€˜every 15 minutes starting from minute 0 of every hour, on the 1st, 3rd and 20th of June; and Mondays and Tuesdaysâ€™.\nTo help simplify things, the r2cron() function lets you specify each slot in turn as arguments. Each input is an R expression like in the table above. You donâ€™t have to worry about cron-specific symbols, you just provide the appropriate integer vector.\n\n\nSimple example\nHow would you specify the 28th minute past 11PM every day with r2cron()? You pass the value 28 to the minutes argument and 23 to the hours argument. The resulting cron string has a 28 in the minutes slot and a 23 in the hours slot, as expected.\n\nx &lt;- dialga::r2cron(\n  minutes = 28, \n  hours = 23  # 24-hour clock\n)\n\nx\n\n[1] \"28 23 * * *\"\n\n\nGreat, thereâ€™s our cron string!\nYou may have noticed from the documentation that thereâ€™s also a clip argument. This is for your convenience; when set to TRUE, the output will be copied to the clipboard for you to paste elsewhere, like into the YAML of a GitHub Action in my case. You will need separately to install {clipr} yourself from CRAN if you want this functionality in {dialga}.\nCool, but how do we know this worked? We could pass the cron string into cron2eng() to confirm it.\n\ndialga::cron2eng(x)\n\nCron string '28 23 * * *' means:\n  - minute(s) 28\n  - hour(s) 11PM\n  - every day(s) of the month\n  - every month(s)\n  - any day(s) of the week\n\n\nThis text output isnâ€™t sophisticated, but it communicates the point. Iâ€™ve chosen to keep it simple by breaking it into bullet points, rather than wrestling the output into a potentially confusing single sentence.\nOf course, this means you could pipe these functions together to go from R to cron to English in one go.\n\nlibrary(magrittr)  # for %&gt;%\n\ndialga::r2cron(minutes = 28, hours = 23) %&gt;% \n  dialga::cron2eng()\n\nCron string '28 23 * * *' means:\n  - minute(s) 28\n  - hour(s) 11PM\n  - every day(s) of the month\n  - every month(s)\n  - any day(s) of the week\n\n\nIt might be nice to produce eventually an eng2cron() function that goes directly from a text description to the appropriate cron string, but I think that would be a fair amount of effort.\n\n\nMore complex example\nWe can see the flexibility of r2cron() with an unlikely scheduling request like â€˜every 20 minutes from the top of the hour (minute 0) of 3PM, 4PM and 5PM, on the 1st days of April, October and November, plus every weekendâ€™. Again, we can specify these as R integer vectors.\n\ny &lt;- dialga::r2cron(\n minutes = seq(0, 59, 20),\n hours = 15:17,  # 24-hr clock\n days_month = 1,\n months = c(4, 10, 11),\n days_week = c(1, 7)  # Sunday is '1'\n)\n\ny\n\n[1] \"0/20 15-17 1 4,10,11 0,6\"\n\n\nNote that the input to the days_week argument isnâ€™t zero-indexed even though the cron format is zero-indexed; Sunday is 1 in r2cron(), not 0. This is to conform better to the fact that R doesnâ€™t typically zero-index things. r2cron() converts days_week = 1 into 0 for this slot automatically.\nAnd of course, we can express the output of this complicated cron string in English:\n\ndialga::cron2eng(y)\n\nCron string '0/20 15-17 1 4,10,11 0,6' means:\n  - every 20 minute(s) starting from minute(s) 0\n  - hour(s) 3PM to 5PM\n  - day(s) of the month 1\n  - month(s) April, October and November\n  - and day(s) of the week Sunday and Saturday\n\n\n\n\nWarnings\nAs a courtesy, youâ€™ll be warned when unlikely dates arise. Some are impossible, like 31 September and others are rare, like 29 February. Itâ€™s important that these are warnings and not errors though, since you might legitimately want the job to run on 31sts when available, or the 29 February only (i.e.Â every four years).\nThis example hits all the warnings:\n\ndialga::r2cron(days_month = 28:31, months = 2)\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? There's no 31st in Feb, Apr, Jun, Sept nor Nov.\n\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? There's no 30th in Feb.\n\n\nWarning in dialga::r2cron(days_month = 28:31, months = 2): \n  Sure? 29 Feb is only in leap years.\n\n\n[1] \"* * 28-31 2 *\""
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#rs-scheduling-tools",
    "href": "posts/2021-04-10-dialga/index.html#rs-scheduling-tools",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Râ€™s scheduling tools",
    "text": "Râ€™s scheduling tools\nOf course, {dialga} just handles strings and doesnâ€™t help you set up schedules. If on Unix/Linux, you can use the {cronR} package to schedule tasks from R. The Windows alternative is the {taskscheduleR} package. These have their own tools, including a Shiny app, to help you with scheduling.\nAs for {dialga}, Iâ€™ll probably use it every now and again to help set up a scheduled GitHub Action. Whatever its use, {dialga} is really just another exercise in package writing and another classic example of PDD (I hope you havenâ€™t forgotten that acronym already)."
  },
  {
    "objectID": "posts/2021-04-10-dialga/index.html#environment",
    "href": "posts/2021-04-10-dialga/index.html#environment",
    "title": "Convert R to cron to English with {dialga}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:46:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3 dialga_0.1.1  \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         fontawesome_0.5.1\n [5] knitr_1.43.1      htmltools_0.5.5   rmarkdown_2.23    cli_3.6.1        \n [9] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       evaluate_0.21    \n[13] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#tldr",
    "href": "posts/2021-07-23-london-colour/index.html#tldr",
    "title": "What colour is London?",
    "section": "tl;dr",
    "text": "tl;dr\nI used the {rtweet} and {magick} R packages to fetch tweets of random satellite images of London from londonmapbot and then reduced each one to a single representative colour.\n\n Note\nlondonmapbot no longer posts to Twitter due to API changes. It can be found on Mastodon instead at botsin.space/@londonmapbot. You can read about that in a more recent post."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#greengrey-belt",
    "href": "posts/2021-07-23-london-colour/index.html#greengrey-belt",
    "title": "What colour is London?",
    "section": "Green/grey belt",
    "text": "Green/grey belt\nI created the @londonmapbot Twitter bot to tweet out satellite images of random points in Greater London. You can read earlier posts about how it was made and how I mapped the points interactively.\nI figured we could sample these to get to â€˜the colours of Londonâ€™, which can be mapped or tiled.\nThis is not too dissimilar to efforts to find the â€˜average colourâ€™ of countries of the world, which Erin wrote a nice post about, for example.1 The difference is that we arenâ€™t finding a colour to represent London, weâ€™re representing London with a series of single-colour points.\nThis is relatively trivial with the packages {rtweet} to pull tweets and {magick} to manipulate the images. We can use {sf} to place the points on a map and {ggplot2} for other visualisations."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#get-bot-log",
    "href": "posts/2021-07-23-london-colour/index.html#get-bot-log",
    "title": "What colour is London?",
    "section": "Get bot log",
    "text": "Get bot log\nFirst, load the packages we need. Youâ€™ll need to use install.packages() for each one if you havenâ€™t already installed them.\n\nsuppressPackageStartupMessages({\n  library(rtweet)\n  library(magick)\n  library(tidyverse)\n  library(sf)\n})\n\n{rtweet} makes it very easy to collect tweet content. To the get_timeline() function you can pass an account name and the number of tweets you want to fetch. Youâ€™ll need to set up authenication first, of course.\n\ntweets_read &lt;- get_timeline(\"londonmapbot\", n = 625)\n\nWhy do I want 625? Well, the bot has tweeted out nearly 9000 images at time of writing, but I want a useable number for this post. (Spoiler: I also want to make a 25 by 25 grid of squares as one of my outputs.)\nThe function actually returns more than 625 because {rtweet} maximises the number of tweets it fetches for each API call. Better to return more than you asked for, rather than less.\nThe returned tibble contains a lot of information. Iâ€™m only interested in the media_url and text columns, from which I can extract the satellite image URLs and, with some regular expressions, the coordinate information thatâ€™s provided in the body of the tweet.\n\ntweets &lt;- tweets_read %&gt;% \n  transmute(media_url = unlist(media_url), text) %&gt;% \n  transmute(\n    media_url,\n    latitude = str_extract(text, \"^\\\\d{2}.\\\\d{1,4}\"),\n    longitude = str_extract(text, \"(?&lt;=, ).*(?=\\nhttps)\")\n  ) %&gt;% \n  slice(1:625)\n\nSo weâ€™ve got a tibble with 3 columns and 625 rows.\n\nglimpse(tweets)\n\nRows: 625\nColumns: 3\n$ media_url &lt;chr&gt; \"http://pbs.twimg.com/media/E7BOglJVgAEE3XL.jpg\", \"http://pbâ€¦\n$ latitude  &lt;chr&gt; \"51.5651\", \"51.4665\", \"51.3752\", \"51.5041\", \"51.5668\", \"51.3â€¦\n$ longitude &lt;chr&gt; \"0.0466\", \"-0.3526\", \"-0.1997\", \"-0.0174\", \"-0.1882\", \"-0.13â€¦\nIâ€™m going to iterate through each URL to download the associated image to a temporary directory. Iâ€™ve used a walk() function from {purrr} rather than map() because we arenâ€™t returning anything; weâ€™re saving a file to a folder.\nSpecifically, I used walk2(), which lets me supply two values to the iterate process: the URL and also the iteration number for that URL. That means I can print a message in the form â€˜Fetching 1 of 625â€™ and get a rough idea of progress.\nIâ€™ve also added a Sys.sleep() call to slow the process, as not to hammer the Twitter API too hard.2\n\n# Function: download images from URLs\ndownload_images &lt;- function(paths, dir) {\n  \n  Sys.sleep(sample(0:2, 1))  # random pause\n  \n  tw_df &lt;- data.frame(number = 1:length(paths), url = paths)\n  \n  purrr::walk2(\n    tw_df$number, tw_df$url, \n    ~ { cat(\"Fetching\", .x, \"of\", length(tw_df$number), \"\\n\")\n      download.file(.y, file.path(dir, basename(.y))) }\n  )\n  \n}\n\nSo, you can pass a vector of URLs and a directory path to the function. For purposes of this post, Iâ€™m going to save the files to a temporary folder.\nThat call takes a little while and the duration will vary given the random pauses built into the function. Iâ€™ve hidden the output because there would be 625 items printed to the console. An example of the output:\n\nFetching 479 of 625 \ntrying URL 'http://pbs.twimg.com/media/E6Akw2fXMAA3VSk.jpg'\nContent type 'image/jpeg' length 113537 bytes (110 KB)\n==================================================\n  downloaded 110 KB\n\nTo prove this has worked, we can fetch all the image paths from the directory in which theyâ€™re stored and count how many there are.\n\nfiles &lt;- list.files(tmp, \".jpg$\", full.names = TRUE)\nlength(files)\n\n[1] 625\nGreat, as expected. Now we have a set of satellite images that we can manipulate."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#demo-one-image",
    "href": "posts/2021-07-23-london-colour/index.html#demo-one-image",
    "title": "What colour is London?",
    "section": "Demo: one image",
    "text": "Demo: one image\nAs a demo, letâ€™s take a look at the first image.\n\nex_in &lt;- image_read(files[1])\nex_in\n\n\nNow we can crop out the logos, reduce its colours and resize it using functions from the {magick} package.\nâ€˜Quantizationâ€™ is the process weâ€™ll use on each image; itâ€™s basically the algorithmic simplification of an image to the colours that best represent it. You could, for example, use this for reducing the number of colours in an image to make it easier to compress while minimising information loss. Weâ€™re going to quantize to just one colour to find the colour that best represents the image. Note that this isnâ€™t the same as â€˜taking an average colourâ€™.\n\nex_square &lt;- ex_in %&gt;%\n  image_crop(\"x420-0\") %&gt;%\n  image_quantize(1) %&gt;% \n  image_resize(\"100x100!\")\n\nex_square\n\n\nSo the colour of that square is what you get when you quantize the original satellite image down to one colour. What is that colour? We can extract the hex code.\n\nex_rgb &lt;- image_data(ex_square, channels = \"rgb\")[1:3]\nex_hex &lt;- toupper(paste0(\"#\", paste(as.character(ex_rgb), collapse = \"\")))\nex_hex\n\n[1] \"#48503E\"\nOf course, we can generally expect that the colour will be somewhere between very green (city fringes, parks, golf courses) and very grey (urban), while some may be more blue (reservoirs)."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#all-images",
    "href": "posts/2021-07-23-london-colour/index.html#all-images",
    "title": "What colour is London?",
    "section": "All images",
    "text": "All images\nThe image_*() functions in {magick} are generally vectorised, so we can pass it all of the paths to our files and apply the wrangling steps across all of the images at once.\n\nimgs_in &lt;- image_read(files)\nimgs &lt;- image_crop(imgs_in, \"x420-0\")\n\nI want to grab the single quantized hex value representing each image.\n\nimgs_dat &lt;- imgs %&gt;% image_quantize(1) %&gt;% image_resize(\"1x1!\")\nhex_dat &lt;- map(1:625, ~image_data(imgs_dat, \"rgb\", frame = .x))\nhex_cols &lt;- hex_dat %&gt;% \n  map_chr(~paste0(\"#\", toupper(paste(.[1:3], collapse = \"\"))))\n\nhead(hex_cols)\n\n[1] \"#48503E\" \"#535C3F\" \"#435034\" \"#415534\" \"#5D6152\" \"#535F44\"\nNow we can bind these to our tweets dataset.\n\ntweets_cols &lt;- tweets %&gt;% bind_cols(hex = hex_cols)\nglimpse(tweets_cols)\n\nRows: 625\nColumns: 4\n$ media_url &lt;chr&gt; \"http://pbs.twimg.com/media/E7BOglJVgAEE3XL.jpg\", \"http://pbâ€¦\n$ latitude  &lt;chr&gt; \"51.5651\", \"51.4665\", \"51.3752\", \"51.5041\", \"51.5668\", \"51.3â€¦\n$ longitude &lt;chr&gt; \"0.0466\", \"-0.3526\", \"-0.1997\", \"-0.0174\", \"-0.1882\", \"-0.13â€¦\n$ hex       &lt;chr&gt; \"#48503E\", \"#535C3F\", \"#435034\", \"#415534\", \"#5D6152\", \"#535â€¦\n\nVisualisation: map\nThe obvious thing to do is to create a map with each point marking the location of a satellite image tweeted by londonmapbot, filled with the single representative colour for that image.\nThe bot samples from a square roughly covering Greater London within the M25, so it might be nice to show the outline of London for reference. The {sf} package makes it straightforward to read a GeoJSON of the NUTS1 boundaries for the UK via the Open Geography Portal API, then convert it to latitude-longitude coordinates and filter for London only.\n\nnuts_path &lt;- \"https://opendata.arcgis.com/datasets/01fd6b2d7600446d8af768005992f76a_4.geojson\"\nldn_sf &lt;- st_read(nuts_path) %&gt;% \n  st_transform(crs = 4326) %&gt;%\n  filter(nuts118nm == \"London\")\n\nReading layer `NUTS_Level_1_(January_2018)_Boundaries' from data source `https://opendata.arcgis.com/datasets/01fd6b2d7600446d8af768005992f76a_4.geojson' using driver `GeoJSON'\nSimple feature collection with 12 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -8.649996 ymin: 49.88234 xmax: 1.762942 ymax: 60.86078\nGeodetic CRS:  WGS 84\nAnd we can convert our tweets tibble to an sf-class spatial object as well, given that it contains coordinate information.\n\ntweets_sf &lt;- tweets_cols %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nThen itâ€™s a case of adding these to a map, which in this case is a {ggplot2} object. The geom_sf() function is great at accepting and understanding polygons and points.\n\nggplot() +\n  geom_sf(data = tweets_sf, col = hex_cols, size = 3) +\n  geom_sf(data = ldn_sf, alpha = 0, size = 1, col = \"black\") +\n  theme_void()\n\n\n\n\n\n\nAre there any patterns here? Maybe itâ€™s greener in the suburbs? (Itâ€™s a serious question; Iâ€™m a deuteranope.)3\n\n\nVisualisation: tiles\nRecently Iâ€™ve written some posts involving R and abstract art (like pixel art and a Shiny app to remix art by Sol LeWitt).\nSo why not get more abstract with these data points? We can create squares of each colour and tile them.\nHere the tiles are laid out row by row from right to left, in a more-or-less random order.\n\nhex_tiles &lt;- crossing(x = 1:25, y = 1:25) %&gt;% \n  bind_cols(hex = tweets_cols$hex)\n\nggplot() +\n  geom_tile(aes(hex_tiles$x, hex_tiles$y), fill = hex_tiles$hex) +\n  theme_void()\n\n\n\n\n\n\nFor fans of order, we could instead arrange them by brightness, or â€˜luminanceâ€™.4 Here Iâ€™ve modified a simple approach by Wouter van der Bijl from a StackOverflow post.\n\n# Get luminance for hex values\nrgb_vals &lt;- col2rgb(tweets_cols$hex)  # Hex to RGB\nlab_vals &lt;- convertColor(t(rgb_vals), 'sRGB', 'Lab')  # RGB to Lab\nhex_lum &lt;- tweets_cols$hex[order(lab_vals[, 'L'])]  # luminance order\n\n# Set up dummy xy tile locations\ncross_xy &lt;- crossing(y = 1:25, x = 1:25)\n\n# Create tibble of x, y, hex luminance\nhex_tiles_bright &lt;- tibble(\n  x = cross_xy$x,\n  y = rev(cross_xy$y),\n  hex = hex_lum\n)\n\n# Plot so 'lightest' in top left, 'darkest' in bottom right\nggplot(hex_tiles_bright) +\n  geom_tile(aes(x, y), fill = rev(hex_tiles_bright$hex)) +\n  theme_void()\n\n\n\n\n\n\nThe colours make me think of the classic smoggy â€˜pea souperâ€™ of London in times past, which is fitting.\nOr, yâ€™know, sewage.\nOf course, thereâ€™s lots more images available in the londonmapbot feed and many other ways to visualise these data, so I may return to this idea in the future."
  },
  {
    "objectID": "posts/2021-07-23-london-colour/index.html#environment",
    "href": "posts/2021-07-23-london-colour/index.html#environment",
    "title": "What colour is London?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:33:02 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#tldr",
    "href": "posts/2022-06-07-assign-down/index.html#tldr",
    "title": "Down with Râ€™s assignment flamewars!",
    "section": "tl;dr",
    "text": "tl;dr\nAll &lt;- vs = flamewars are nullified forever with the introduction of my new â€˜down assignâ€™ operator for the R language:\n\n|\nv\n\n\n Note\nFolks, nerdsniping works:\n\nMatthew Kay has now written the {explodeAssign} package, which lets you use special (weaponised) down-assign arrows in an interactive session\nAntoine Fabri has followed up with a coded implementation for making this possible with a just a v operator (â€˜vassignâ€™)\n\nAs Matthew says, this is a â€˜terrible ideaâ€™ and you should use at your own risk, lol."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#get-down",
    "href": "posts/2022-06-07-assign-down/index.html#get-down",
    "title": "Down with Râ€™s assignment flamewars!",
    "section": "Get down",
    "text": "Get down\nI no longer set my calendar by the movement of the Earth around the hottest point in the solar system. I now set it by the recurrent emergence of the hottest take in the solar system: that Râ€™s assignment operator &lt;- is garbage and R users should be ashamed of themselves.\nLast time I spoke about this I made clear that our Strong Pointy Lad was the One True Operator for assignment. In that post, like some kind of modern Prometheus, I gave mortals the power to detect and destroy R scripts containing the weak and mundane equals assignment operator.\nBut with deference, I have come to realise something profound: we shouldnâ€™t fight about this. Itâ€™s not worth anyoneâ€™s time to debate the relative merits of using &lt;- or =. We should all relax. We can live in harmony.\nâ€¦Because Iâ€™ve invented a new assignment concept. Folks, say hello to the down assign operator.\n\n|\nv\n\nYes, itâ€™s still an â€˜arrowâ€™, but I think everyone will agree that it makes sense this time. Lateral assignment is unnatural and inefficient and is out of the natural order of things.\nNow the the value falls effortlessly down your script, under the weight of gravity, into the name of the object. If itâ€™s good enough Sir Isaac Newton, itâ€™s good enough for me. Or donâ€™t you believe in gravity? Exactly.\nSo x &lt;- 1 (or, shudder, x = 1) translates to:\n\n1\n|\nv\nx\n\nElegant, isnâ€™t it?\nWhile R Core perform the trivial task of cementing this feature into base R, Iâ€™ve prepared a small function that will take care of rudimentary usage for now.\nNote that this function wonâ€™t work in an interactive session; it takes the filepath to a script as its input. But thatâ€™s okay: I think &lt;- haters are often computer-scientist types and 1337 h4x0rz who never sully their code by playing around in filthy IDEs and notebooks anyway. Obviously we should emulate them.\nFirst Iâ€™ll write a demo script to a temporary file. It assigns the values of 1 and 2 to x and y, respectively, then adds them together.\n\ndemo_script &lt;- \"\n1\n|\nv\nx\n\n2\n|\nv\ny\n\nx + y\n\"\n\ndemo_file &lt;- tempfile(fileext = \".R\")\nwriteLines(demo_script, demo_file)\n\nNow to define the function. It reads our script file, finds the down arrows, substitutes them, returns them back to the expression from whence they came, then executes the script.\n\npoint_down &lt;- function(file) {\n  \n  content &lt;- readLines(file)\n  \n  for (i in seq(content)) {\n    \n    if (content[i] == \"|\" & content[i + 1] == \"v\") {\n      \n      combos &lt;- paste0(\n        content[i - 1], content[i], content[i + 1], content[i + 2]\n      )\n      \n      rm_index &lt;- c(i - 1, i, i + 1, i + 2)\n      \n      content[rm_index[1]] &lt;- combos\n      content[rm_index[2:4]] &lt;- \"\"\n      content &lt;- gsub(\"\\\\|v\", \"-&gt;\", content)\n      \n    }\n    \n  }\n  \n  path &lt;- tempfile(fileext = \".R\")\n  writeLines(content, path)\n  eval(parse(path))\n  \n}\n\nAnd now we execute.\n\npoint_down(demo_file)\n\n[1] 3\n\n\nSimply: wow."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#down-and-away",
    "href": "posts/2022-06-07-assign-down/index.html#down-and-away",
    "title": "Down with Râ€™s assignment flamewars!",
    "section": "Down and away",
    "text": "Down and away\nMy next step for unifying the community around R operators is the â€˜down pipeâ€™:\n\n_\nv\n\nSome use the term â€˜down pipeâ€™ to mean the exterior drainage tube that takes wastewater away from their homes. I hope we can use the down pipe operator as a way of siphoning away all the bilge around the %&gt;% vs |&gt; arguments once and for all. Youâ€™re welcome."
  },
  {
    "objectID": "posts/2022-06-07-assign-down/index.html#environment",
    "href": "posts/2022-06-07-assign-down/index.html#environment",
    "title": "Down with Râ€™s assignment flamewars!",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:14:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html",
    "href": "posts/2021-05-22-mission-across-iow/index.html",
    "title": "Mission Across the Isle of Wight",
    "section": "",
    "text": "Isle of Wight, coloured off-white."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#tldr",
    "href": "posts/2021-05-22-mission-across-iow/index.html#tldr",
    "title": "Mission Across the Isle of Wight",
    "section": "tl;dr",
    "text": "tl;dr\nI used R to identify and map hazards on a potential straight-line walking route across the Isle of Wight, mimicking Tom â€˜GeoWizardâ€™ Daviesâ€™s â€˜Mission Acrossâ€™ series of YouTube videos. You can jump straight to the interactive map."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#geowizard",
    "href": "posts/2021-05-22-mission-across-iow/index.html#geowizard",
    "title": "Mission Across the Isle of Wight",
    "section": "GeoWizard",
    "text": "GeoWizard\nTom â€˜GeoWizardâ€™ Davies is perhaps best known for his YouTube channel, where he posts Twitch stream highlights of Geoguessr, a game where you pinpoint a randomised location based only Google StreetView.\nHe also chronicles real-life trekking adventures, usually with a twist. Particularly captivating are the â€˜Mission Acrossâ€™ videos, where Tom attempts to cross a country in a straight line on foot. That includes having to clamber over hedges, swim across ponds, get stuck in bogs and risk the wrath of local farmers and landowners. So far this has covered Wales, Wales again and Norway, with a Scotland series due this month.\nOf course, this requires a lot of planning to decide what the best route is and to make sure you donâ€™t traipse directly through someoneâ€™s living room in your muddy boots. Typically this might involve lots of time in GIS software and various online mapping services.\nI learnt recently of the {osmextract} package for the R language, which fetches geographic features from OpenStreetMap, and wondered how easy it would be to use R to do a light-touch assessment of straight line routes in a â€˜Mission Acrossâ€™ style. Basically, can we work out the number and type of obstructions weâ€™d face on a given route?\nYou can jump straight to an interactive map with my example for the Isle of Wight, or keep reading for the code and an explanation.\nAs an aside, Tom has also made the album â€˜16 Bit Adventureâ€™ under the moniker â€˜Amyneddâ€™; music which accompanies the â€˜Mission Acrossâ€™ videos. Press play here for inspiration as you read on."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#code-walkthrough",
    "href": "posts/2021-05-22-mission-across-iow/index.html#code-walkthrough",
    "title": "Mission Across the Isle of Wight",
    "section": "Code walkthrough",
    "text": "Code walkthrough\n\nPackages\nR is very capable as a code-led tool for geospatial manipulation and mapping. Along with {tidyverse} for data wrangling, thereâ€™s a few geospatial packages we need: {geojsonio} lets us read GeoJSON files, {sf} is for handling â€˜special featuresâ€™ geometry in a â€˜tidyâ€™ way, and {leaflet} lets us create interactive maps. {osmextract} was the main motivation for this post; it fetches OpenStreetMap features pretty painlessly.\n\nsuppressPackageStartupMessages({\n  library(geojsonio)\n  library(leaflet)\n  library(leaflet.extras)\n  library(osmextract)\n  library(sf)\n  library(tidyverse)\n})\n\nAll these packages can all be downloaded from CRAN with install.packages().\nWhile weâ€™re here, Iâ€™m going to turn off â€˜spherical geometryâ€™. This is a fancy way of saying that weâ€™re going to pretend the Earth is flat (!) to avoid some awkward geospatial maths. I donâ€™t think thatâ€™s going to be a big deal for the scale of this demo.\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\n\n\n\nThe boundary\nFor purposes of this post, I wanted to look at a small, contained, â€˜regularly-shapedâ€™ geographic area to keep things simple. It didnâ€™t have to be a country.\nI settled on the Isle of Wight (IOW)1, a small island off the south-coast of England. Itâ€™s mostly rural, with farms, hedges and waterways to cross, but there are certainly more built-up areas. It also helps that the IOW is featured in the {osmextract} documentation!\n\n\n\nThe Isle of Wight: a vexillologistâ€™s delight.\n\n\nFirst thing is to fetch a polygon that represents the extent of the island. Fortunately, Local Authority District (LAD) boundaries for the UK are available to download from the Official for National Statistics (ONS) in GeoJSON form2. We can download the file and filter for the IOW, specifically.\n\n# Download geojson\ngeojson_url &lt;- \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/LAD_DEC_2020_UK_BGC/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\ntmp &lt;- tempdir()\ngeojson_path &lt;- file.path(tmp, \"lads.geojson\")\ndownload.file(geojson_url, geojson_path)\n\n# Read LAD boundaries, filter to IOW\niow_extent &lt;- geojson_read(geojson_path, what = \"sp\") %&gt;% \n  st_as_sf(crs = 4326) %&gt;%\n  filter(LAD20NM == \"Isle of Wight\")\n\nunlink(tmp)\n\nIâ€™ve used boundaries that are â€˜clipped to the coastlineâ€™ because I donâ€™t think you should have to swim out to the low-water mark to complete such a challenge.\n\n\nOpenStreetMap features\nWe want to identify features like hedgerows, buildings and waterways that will become obstructions for our imaginary walk across the island. The oe_get() function from {osmextra} is an easy way to pull features from OpenStreetMap en masse. You can supply a location and receive features within that area.\nFirst, the polygonal features, which you can get with argument layer = \"multipolygons\". You can see that a geometry column is returned, which contains the coordinates for the polygons.\n\n# Fetch polygonal features for IoW\nosm_polys &lt;- oe_get(\n  \"Isle of Wight\", # geographic area of interest\n  layer = \"multipolygons\",  # fetch polygons\n  stringsAsFactors = FALSE,  # return character-class\n  quiet = TRUE  # don't print info\n) %&gt;%\n  st_transform(crs = 4326)  # latlong coord reference system\n\n# Limited preview\nglimpse(select(osm_polys, osm_id, name, type, geometry))\n\nRows: 84,599\nColumns: 4\n$ osm_id   &lt;chr&gt; \"4763\", \"5922\", \"6022\", \"7141\", \"7316\", \"29744\", \"70978\", \"71â€¦\n$ name     &lt;chr&gt; NA, NA, NA, NA, NA, \"Ryde Canoe Lake\", \"Quarr Abbey\", NA, \"Beâ€¦\n$ type     &lt;chr&gt; \"multipolygon\", \"multipolygon\", \"multipolygon\", \"multipolygonâ€¦\n$ geometry &lt;MULTIPOLYGON [Â°]&gt; MULTIPOLYGON (((-1.251425 5..., MULTIPOLYGON (((â€¦\n\n\nOf course, we can grab line features too. The default for layer is lines, so we donâ€™t need to supply this argument.\n\n# Fetch line features for IoW\nosm_lines &lt;-  oe_get(\n  \"Isle of Wight\", \n  stringsAsFactors = FALSE,\n  quiet = TRUE\n) %&gt;%\n  st_transform(crs = 4326)\n\nFor convenience, Iâ€™m simplifying the features down to the ones we care about. For Tom, hedgerows were a constant nuisance, waterways were cold and perilous, and buildings could contain angry landowners. We want to avoid them all, ideally.\nWe can create a function to extract named features (we want rows containing â€˜barriersâ€™, â€˜buildingsâ€™, â€˜naturalâ€™ and â€˜waterwayâ€™ features), and then iterate over our lines and polygons to isolate them. Iâ€™ve put them into a single object so itâ€™s easier to reference them later.\n\n# Filter for a single feature type from oe_get() output\n# 'sf_in' is output from oe_get(); 'feature' is the feature we want\nisolate_feature &lt;- function(sf_in, feature) {\n  sf_in %&gt;% \n    filter(!is.na(sf_in[[feature]])) %&gt;%  # filter for feature\n    select(osm_id, type = all_of(feature), geometry)  # simplify object\n}\n\n# Get all the features as a list object with one element per feature\nfeatures &lt;- map2(\n  list(osm_lines, osm_polys, osm_polys, osm_lines),\n  list(\"barrier\", \"building\", \"natural\", \"waterway\"),\n  isolate_feature\n) %&gt;% \n  set_names(\"barrs\", \"bldgs\", \"natur\", \"wways\")\n\n# Limited preview of the waterways data\nglimpse(features$wways)\n\nRows: 2,714\nColumns: 3\n$ osm_id   &lt;chr&gt; \"3027797\", \"3127808\", \"4680059\", \"5171926\", \"5171930\", \"51722â€¦\n$ type     &lt;chr&gt; \"river\", \"river\", \"river\", \"stream\", \"ditch\", \"river\", \"streaâ€¦\n$ geometry &lt;LINESTRING [Â°]&gt; LINESTRING (-1.272943 50.62..., LINESTRING (-1.290â€¦\n\n\n\n\nThe line\nWe need to specify a straight-line route.3 For this demonstration, and in interests fo speed, Iâ€™ve just chosen one that looks alright by eye in terms of obstructions. Kinda.\nOf course, you can use the approach outlined in this post to try other lines and discover quantitatively which ones have the fewest obstructions. Thatâ€™s the subject of an upcoming Shiny app, which will allow the user to provide a line and get feedback on the number and count of hazards.\nCrucially, the line is clipped to the boundary of the island, so it goes from coast to coast.\n\n# Create a straight line\n# 'x1', etc, are start/end latlongs; 'boundary_poly' is the GeoJSON\nmake_line &lt;- function(x1, y1, x2, y2, boundary_poly) {\n  x &lt;- st_linestring(matrix(c(y1, y2, x1, x2), ncol = 2))  # to matrix\n  y &lt;- st_sfc(x, crs = 4326)  # set coord reference system\n  st_intersection(y, boundary_poly)  # clip line to island boundary\n}\n\n# Hard-coded start/end latlongs\nstart_x &lt;- 50.658; start_y &lt;- -1.472\nend_x &lt;- 50.707; end_y &lt;- -1.101\n\n# Build line between the points, clip to IOW boundary\nline &lt;- make_line(start_x, start_y, end_x, end_y, iow_extent)\n\nalthough coordinates are longitude/latitude, st_intersection assumes that they\nare planar\n\n# Preview\nglimpse(line)\n\nsfc_LINESTRING of length 1; first list element:  'XY' num [1:2, 1:2] -1.47 -1.1 50.66 50.71\n\n\nHereâ€™s a quick preview of where our line is:\n\nggplot() +\n  geom_sf(data = iow_extent) +\n  geom_sf(data = line) +\n  ggthemes::theme_map()\n\n\n\n\n\n\nThe platinum zone\nIn practice itâ€™s very difficult to keep exactly to the line and some deviation may be required at a landownerâ€™s request, for example. Whatâ€™s an acceptable amount of wiggle room?\nTom spoke in one of his videos about assigning scores to a mission based on minimal deviation from the line. For example, staying within 25 m of the line either side would be a â€˜platinumâ€™ standard.\nWe can build a buffer around our line to create a platinum zone, which will be a useful visual aid in the final map.\n\n# Create a buffer around the straight line\n# 'line' as created with make_line(); 25m is 'platinum' standard\nmake_buffer &lt;- function(straight_line, buffer_size = 25) { \n  x &lt;- st_transform(straight_line, crs = 27700)  # line to draw buffer around\n  y &lt;- st_buffer(x, dist = buffer_size)\n  st_transform(y, crs = 4326)  # reset coord reference system\n}\n\n# Generate a 25m buffer ('platinum standard') around the line\nbuffer &lt;- make_buffer(line)\n\n# Preview\nglimpse(buffer)\n\nsfc_POLYGON of length 1; first list element: List of 1\n $ : num [1:123, 1:2] -1.1 -1.1 -1.1 -1.1 -1.1 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n\n\n\n\nObstructions\nOur features object currently has all the lines and polygons within the IOW boundary, but we only want the ones that come in contact with (i.e.Â intersect) with our proposed route. The st_intersects() function from {sf} does exactly that.\n\n# Extract features that intersect with the line or buffer geometry\n# 'features_sf' contains the features; 'path_sf' for what to intersect\nfind_obs &lt;- function(features_sf, path_sf) { \n  row_nums &lt;- st_intersects(path_sf, features_sf)[[1]]  # rows with obstruction\n  slice(features_sf, row_nums)  # extract matching rows\n}\n\n# Find intersection between features and line\nobstructions &lt;- map(features, ~find_obs(.x, line)) %&gt;% \n  set_names(\"barrs\", \"bldgs\", \"natur\", \"wways\")\n\n# Limited preview\nglimpse(obstructions$wways)\n\nRows: 11\nColumns: 3\n$ osm_id   &lt;chr&gt; \"471224569\", \"552565448\", \"552565555\", \"552565565\", \"55650679â€¦\n$ type     &lt;chr&gt; \"stream\", \"stream\", \"stream\", \"stream\", \"ditch\", \"ditch\", \"diâ€¦\n$ geometry &lt;LINESTRING [Â°]&gt; LINESTRING (-1.285131 50.67..., LINESTRING (-1.216â€¦\n\n\nWe can create a quick table to see what the obstructions are for this route.\n\ntribble(\n  ~Type, ~Count,\n  \"Barriers\", nrow(obstructions$barrs),\n  \"Buildings\", nrow(obstructions$bldgs),\n  \"Waterways\", nrow(obstructions$wways),\n  \"Water bodies\", nrow(filter(obstructions$natur, type == \"water\")\n  )\n) %&gt;% knitr::kable()\n\n\n\n\nType\nCount\n\n\n\n\nBarriers\n92\n\n\nBuildings\n7\n\n\nWaterways\n11\n\n\nWater bodies\n4\n\n\n\n\n\nYou can see how this information is useful if you wanted to try other straight-line paths and see how they stack up against each other. Maybe you want to reduce the number of barriers (typically hedgerows); maybe you donâ€™t mind swimming across a large water body.\n\n\nMap\nSo we have the objects we need: our straight-line route, the platinum-zone buffer and all the features that cross our path. Now to map it. We can use the {leaflet} package to layer these up on an interactive map, allowing the user to inspect the route and the hazards along the way.\n\n\nClick to expand the full mapping code\n\nThe basic approach here is to addproviderTiles() for underlying maps (Iâ€™ve chosen these to help add extra context to the route); use addPolygons and addPolylines() to supply the line, buffer and the features as separate â€˜layersâ€™ that can be turned on or off; use addAwesomeMarkers() for clickable pop-up feature labels; and supply additional mapping conveniences with addMeasure() and, from {leaflet.extras}, addFullscreenControl() (both functions do what their names suggest).\n\n# Set multi-use variables\nmarker_fill &lt;- \"darkblue\"\nicon_fill &lt;- \"white\"\ncol_line &lt;- \"#000\"\ncol_artifical &lt;- \"#F00\"\ncol_water &lt;- \"#00F\"\nweight_line &lt;- 1\nweight_obstruction &lt;- 2\nalpha_all &lt;- 0.5\n\n# Interactive map\nleaflet() %&gt;% \n  # Base groups: map tiles\n  addProviderTiles(\"CartoDB.PositronNoLabels\", group = \"Simple\") %&gt;%\n  addProviderTiles(\"Esri.WorldTopoMap\", group = \"Terrain\") %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"Satellite\") %&gt;%\n  # Overlay groups: line and buffer\n  addPolygons(\n    data = buffer, group = \"Line/buffer\", \n    color = col_line, weight = weight_line, dashArray = 4, \n    fill = TRUE, opacity = alpha_all\n  ) %&gt;% \n  addPolylines(\n    data = line, group = \"Line/buffer\",\n    color = col_line, weight = weight_line, \n    fill = FALSE\n  ) %&gt;%\n  # Overlay groups: start and end points\n  addAwesomeMarkers(\n    lng = start_y, lat = start_x, group = \"Start/end\",\n    icon = awesomeIcons(\n      markerColor = \"blue\",\n      icon = \"play\", library = \"fa\", iconColor = \"#FFF\"\n    ),\n    popup = paste0(\"&lt;center&gt;Start&lt;br&gt;\", start_x, \", \", start_y, \"&lt;center&gt;\")\n  ) %&gt;% \n  addAwesomeMarkers(\n    lng = end_y, lat = end_x, group = \"Start/end\",\n    icon = awesomeIcons(\n      markerColor = \"blue\",\n      icon = \"stop\", library = \"fa\", iconColor = \"#FFF\"\n    ),\n    popup = paste0(\"&lt;center&gt;End&lt;br&gt;\", end_x, \", \", end_y, \"&lt;center&gt;\")\n  ) %&gt;% \n  # Overlay groups: features in buffer\n  addPolylines(\n    data = obstructions$barrs, group = \"Barriers\",\n    color = col_artifical, weight = weight_obstruction,\n    label = paste(\"Barrier:\", obstructions$barrs$type)\n  ) %&gt;% \n  addPolygons(\n    data = obstructions$bldgs, group = \"Buildings\",\n    color = col_artifical, weight = weight_obstruction, \n    fillColor = col_artifical, fillOpacity = alpha_all,\n    label = paste(\"Building:\", obstructions$bldgs$type)\n  ) %&gt;%\n  addPolygons(\n    data = filter(obstructions$natur, type == \"water\"), group = \"Water\",\n    color = col_water, weight = weight_obstruction, \n    fillColor = col_water, fillOpacity = alpha_all,\n    label = \"Water body\"\n  ) %&gt;% \n  addPolylines(\n    data = obstructions$wways, group = \"Water\",\n    color = col_water, weight = weight_obstruction,\n    label = paste(\"Waterway:\", obstructions$wways$type)\n  ) %&gt;% \n  # Control which layers are shown\n  addLayersControl(\n    baseGroups = c(\"Simple\", \"Terrain\", \"Satellite\"),  # radio button\n    overlayGroups = c(  # checkboxes\n      \"Line/buffer\", \"Start/end\",  # line-related\n      \"Water\", \"Barriers\", \"Buildings\"  # obstructions\n    ),\n    position = \"topright\",\n    options = layersControlOptions(collapsed = FALSE)\n  ) %&gt;% \n  # Other map features\n  addMeasure(  # tool for users to measure distances\n    position = \"topleft\",\n    primaryLengthUnit = \"meters\",\n    primaryAreaUnit = \"sqmeters\"\n  ) %&gt;% \n  addFullscreenControl()  # clickable full-screen button\n\n\n\n\n\n\n\n\nSo, you can inspect the route interactively by zoom and dragging, by hovering over highlighted features to see what they are, and by turning on and off the different map and feature layers for more or less context."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#next",
    "href": "posts/2021-05-22-mission-across-iow/index.html#next",
    "title": "Mission Across the Isle of Wight",
    "section": "Next",
    "text": "Next\nThereâ€™s a lot of stuff missing from this approach to make it useful for actually planning a straight-line route. For example, I havenâ€™t included elevation or land-use type (you donâ€™t want to spend a few kilometres in a marsh). Youâ€™re also restricted to a two-dimensional overhead view.\nOf course, I also hard-coded the start and end points for this demo. The real power of this approach would be to let the user choose where they want to start and end and feed back on the identity and number of obstructions for each line suggested. To this end, Iâ€™ve started developing a simple Shiny app."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#disclaimer",
    "href": "posts/2021-05-22-mission-across-iow/index.html#disclaimer",
    "title": "Mission Across the Isle of Wight",
    "section": "Disclaimer",
    "text": "Disclaimer\nAm I encouraging you to trespass? No.Â Am I encouraging you to take advantage of {osmextra}, {sf} and {leaflet} for mapping in R? Yes."
  },
  {
    "objectID": "posts/2021-05-22-mission-across-iow/index.html#environment",
    "href": "posts/2021-05-22-mission-across-iow/index.html#environment",
    "title": "Mission Across the Isle of Wight",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 13:42:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2      forcats_1.0.0        stringr_1.5.0       \n [4] dplyr_1.1.2          purrr_1.0.1          readr_2.1.4         \n [7] tidyr_1.3.0          tibble_3.2.1         ggplot2_3.4.2       \n[10] tidyverse_2.0.0      sf_1.0-14            osmextract_0.4.1    \n[13] leaflet.extras_1.0.0 leaflet_2.1.2        geojsonio_0.11.1    \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3            xfun_0.39               htmlwidgets_1.6.2      \n [4] lattice_0.21-8          tzdb_0.4.0              leaflet.providers_1.9.0\n [7] vctrs_0.6.3             tools_4.3.1             crosstalk_1.2.0        \n[10] generics_0.1.3          curl_5.0.1              proxy_0.4-27           \n[13] fansi_1.0.4             pkgconfig_2.0.3         KernSmooth_2.23-21     \n[16] lifecycle_1.0.3         farver_2.1.1            compiler_4.3.1         \n[19] munsell_0.5.0           jqr_1.2.3               htmltools_0.5.5        \n[22] class_7.3-22            yaml_2.3.7              lazyeval_0.2.2         \n[25] pillar_1.9.0            ellipsis_0.3.2          classInt_0.4-9         \n[28] tidyselect_1.2.0        digest_0.6.31           stringi_1.7.12         \n[31] ggthemes_4.2.4          fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.1               magrittr_2.0.3         \n[37] crul_1.4.0              utf8_1.2.3              e1071_1.7-13           \n[40] withr_2.5.0             scales_1.2.1            sp_2.0-0               \n[43] timechange_0.2.0        httr_1.4.6              rmarkdown_2.23         \n[46] hms_1.1.3               evaluate_0.21           knitr_1.43.1           \n[49] V8_4.3.2                geojson_0.3.4           rlang_1.1.1            \n[52] Rcpp_1.0.11             glue_1.6.2              DBI_1.1.3              \n[55] httpcode_0.3.0          geojsonsf_2.0.3         rstudioapi_0.15.0      \n[58] jsonlite_1.8.7          R6_2.5.1                units_0.8-2"
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#tldr",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#tldr",
    "title": "londonmapbot at LondonR",
    "section": "tl;dr",
    "text": "tl;dr\nI spoke at a LondonR hootenanny1 (in-person!) about how to create your own simple Twitter bot powered by GitHub Actions and {rtweet}, just like my @londonmapbot creation.\n\n Note\nThe bot no longer runs on Twitter. You can read about how I ported it to Mastodon at @londonmapbot@botsin.space."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#the-mapbotverse",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#the-mapbotverse",
    "title": "londonmapbot at LondonR",
    "section": "The mapbotverse",
    "text": "The mapbotverse\nI created a Twitter bot called @londonmapbot. It uses the {rtweet} package by Mike Kearney to tweet out a random satellite image of Greater London via Mapbox, scheduled and executed by GitHub Actions.\nIâ€™ve written about this before:\n\nA Twitter bot with {rtweet} and GitHub Actions (original post)\nMapping londonmapbot tweets with {leaflet}\nWhat colour is London?\n\nIâ€™ve noticed a number of other projects have used or developed the londonmapbot code, or else are inspired by it. Iâ€™ve created a Twitter List containing the ones I know about, whichâ€”in earnestâ€”Iâ€™ve called â€˜the mapbotverseâ€™.\nIt includes bots that tweet maps more cleverly, or do something else, like:\n\nRoberto JimÃ©nezâ€™s @esmapbot, which tweets images of Spain sampled from within a geojson of the countryâ€™s borders\nMatt Kerlogueâ€™s @narrowbotR, which tweets canal and river locations with geographically-coincident Flickr images, which have been rated for photo quality (!)\nOscar Baruffaâ€™s @BigBookofR, which tweets out a random section of the excellent Big Book of R resource\n\nI talked at LondonR about how you can be at least as cool as these folks.\nYes, you too can fork the source for londonmapbot on GitHub, or click the green â€˜use this templateâ€™ button in the repo to begin your own mapbot. Or you can can create something from scratch. Let me know what you get up to."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#slides",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#slides",
    "title": "londonmapbot at LondonR",
    "section": "Slides",
    "text": "Slides\nObviously I created some slides for the event. Consider them a more up-to-date (and simpler) version of my original blogpost.\nBelow is the presentation embedded2, but you can also visit the slides online, or go to the source on GitHub.\n\n Note\n{rtweet} version 1.0 was released with breaking changes in July 2022 and so Iâ€™ve tweaked the slides to reflect this. You can read a separate blogpost about these changes.\n\n\n\n\n\n\n\n\n\nWith the slides selected, press the left and right keys to navigate, F to go fullscreen and P to see the presenter notes."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#bonus",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#bonus",
    "title": "londonmapbot at LondonR",
    "section": "Bonus",
    "text": "Bonus\nJust after the talk, I found out I could mark the bot as â€˜automatedâ€™ from Twitter settings at: More &gt; Settings and Privacy &gt; Your account &gt; Account information &gt; Automation. I just had to log in as the â€˜managing accountâ€™ (i.e.Â my personal account) to connect the two profiles. This is now required as per terms of service, I believe.\n\nSo now the profile has a little robot icon and the phrase â€˜automated by @mattdrayâ€™."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#inevitable-bot-uprising",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#inevitable-bot-uprising",
    "title": "londonmapbot at LondonR",
    "section": "Inevitable bot uprising",
    "text": "Inevitable bot uprising\nItâ€™s another maybe two-or-so years until all of Twitter (Earth?) is just a bot singularity, so I suggest you get in early. I reckon a mapbot is a pretty cheap way to get in on the hype."
  },
  {
    "objectID": "posts/2022-02-12-mapbot-londonr/index.html#environment",
    "href": "posts/2022-02-12-mapbot-londonr/index.html#environment",
    "title": "londonmapbot at LondonR",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:16:49 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.31       rlang_1.1.1        \n[16] fontawesome_0.5.1   evaluate_0.21"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html",
    "href": "posts/2022-06-10-basic-search/index.html",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "",
    "text": "The enemy E chases the player @ who collects gold $ and and an apple a."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#tldr",
    "href": "posts/2022-06-10-basic-search/index.html#tldr",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve experimented with simple breadth-first search for {r.oguelike}, a work-in-progress game-in-a-package for R. This means enemies can pathfind and chase down the player character."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#hunting-the-hunter",
    "href": "posts/2022-06-10-basic-search/index.html#hunting-the-hunter",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Hunting the hunter",
    "text": "Hunting the hunter\nIâ€™ve written before about the inception of {r.oguelike}, a concept for a roguelike game written in R, along with a simple method for creating procedural tile-based cave-like dungeons.\n\nSo far the enemies in the game have been stationary.\nI could let them wander randomly on each turn, which is easy to implement, but boring and unrealistic. Far better would be to introduce some kind of pathfinding via an algorithm, which would make enemies head toward the player character to engage in battle.\nIn this post Iâ€™ll start with a naive approachâ€”simply labelling all tiles with distance from the targetâ€”then show how an approach called â€˜breadth-first searchâ€™ can alleviate the problem."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#layers-deep",
    "href": "posts/2022-06-10-basic-search/index.html#layers-deep",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Layers deep",
    "text": "Layers deep\nThereâ€™s a number of ways I could implement pathfinding in R. For purposes of this post, Iâ€™m using an approach that I think makes it easier to grasp conceptually.\nEach dungeon will be composed of two related matrices: one matrix is the tile map, which holds the tiles the user sees (i.e.Â # for walls, . for floor, @ for the player character, E for enemy); the second matrix isnâ€™t seen by the user, but holds travel-distance scores used by the enemy character to find a path to the target.\nIâ€™ll use m throughout as the name of the matrix object holding the tile map and d as the name of the matrix object holding the distance map.\nBear in mind that the characters can only move one tile per turn in a north, south, east or west direction, which has implications for how we label tiles with their distances."
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#dont-keep-it-simple-stupid",
    "href": "posts/2022-06-10-basic-search/index.html#dont-keep-it-simple-stupid",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Donâ€™t keep it simple, stupid",
    "text": "Donâ€™t keep it simple, stupid\nConsider this very basic dungeon room that hosts an enemy character E that is seeking the player character @. Itâ€™s just an R matrix object, but we can print it nicely so itâ€™s easier to read.\n\n\nClick for R code\n\nManually create a basic, rectangular dungeon room:\n\n# Create room\nn_rows &lt;- 9\nn_cols &lt;- 10\nm &lt;- matrix(rep(\".\", n_rows * n_cols), n_rows, n_cols)\nm[1, ] &lt;- \"#\"  # walls\nm[, 1] &lt;- \"#\"\nm[nrow(m), ] &lt;- \"#\"\nm[, ncol(m)] &lt;- \"#\"\n\n# Add player and enemy\nm[7, 3] &lt;- \"@\"  # player\nm[3, 3] &lt;- \"E\"  # enemy\n\nFor convenience, a function that pretty-prints the matrix to the console:\n\n# Function to print the map nicely\nprint_tiles &lt;- function(x) {\n  for (i in seq(nrow(x))) {\n    cat(x[i, ], \"\\n\")\n  }\n}\n\n\nprint_tiles(m)\n\n\n\nprint_tiles(m)\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# . . . . . . . . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\nWhatâ€™s the simplest way that the enemy can find a path to the player?\nProbably itâ€™s to label every traversable tile with a Manhattan-distance (i.e.Â like a taxicab would move on the gridded streets of New York) away from the playerâ€™s position. Then the enemy can check its neighbouring tiles on each turn and select the next highest distance score until it reaches the player.\nSo, below Iâ€™ve created a distance map by assigning the player position a score of 100, then Iâ€™ve decreased the score by 1 with each additional tile away from the player (remembering that characters can only move north, south, east or west). Walls score zero, so theyâ€™re effectively ignored.\n\n\nClick for R code\n\n\nget_distance &lt;- function(m, peak_score) {\n\n  # Initiate distance matrix filled with zero\n  n_rows &lt;- nrow(m)\n  n_cols &lt;- ncol(m)\n  d &lt;- matrix(rep(0, n_cols * n_rows), n_rows, n_cols)\n\n  # Player location gets peak_score\n  player_loc &lt;- which(m == \"@\", arr.ind = TRUE)\n  m[player_loc[1], player_loc[2]] &lt;- peak_score\n\n  # Surrounding tiles get successively smaller distance scores\n  for (col_ind in seq(n_cols)) {\n    for (row_ind in seq(n_rows)) {\n      distance &lt;- abs(player_loc[1] - row_ind) + abs(player_loc[2] - col_ind)\n      value &lt;- peak_score - distance\n      if (value &lt; 0) value &lt;- 0\n      d[row_ind, col_ind] &lt;- value\n    }\n  }\n\n  # Walls aren't traversable, assign low value\n  walls &lt;- which(m == \"#\")\n  d[walls] &lt;- 0\n\n  d\n\n}\n\n\nget_distance(m, 100)\n\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    0    0    0    0    0    0    0    0     0\n [2,]    0   94   95   94   93   92   91   90   89     0\n [3,]    0   95   96   95   94   93   92   91   90     0\n [4,]    0   96   97   96   95   94   93   92   91     0\n [5,]    0   97   98   97   96   95   94   93   92     0\n [6,]    0   98   99   98   97   96   95   94   93     0\n [7,]    0   99  100   99   98   97   96   95   94     0\n [8,]    0   98   99   98   97   96   95   94   93     0\n [9,]    0    0    0    0    0    0    0    0    0     0\n\n\nSee how the player-position at [7,3] is 100 and the values then drop by 1 in all directions?\nSo the enemy would move south from its start position at [3,3] to the target position at [7,3], moving along a score gradient of 96 to 100.\nThereâ€™s an issue with this though: obstacles. What do you think will happen if we put a dividing wall between the characters? Hereâ€™s the same room with a wall splitting the characters, plus the distance matrix using the same approach as above.\n\n\nClick for R code\n\n\nm[5, 2:8] &lt;- \"#\"\n\n\nprint_tiles(m)\n\n\n\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# # # # # # # # . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\n\n\nClick for R code\n\n\nd &lt;- get_distance(m, 100)\n\nd\n\n\n\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    0    0    0    0    0    0    0    0     0\n [2,]    0   94   95   94   93   92   91   90   89     0\n [3,]    0   95   96   95   94   93   92   91   90     0\n [4,]    0   96   97   96   95   94   93   92   91     0\n [5,]    0    0    0    0    0    0    0    0   92     0\n [6,]    0   98   99   98   97   96   95   94   93     0\n [7,]    0   99  100   99   98   97   96   95   94     0\n [8,]    0   98   99   98   97   96   95   94   93     0\n [9,]    0    0    0    0    0    0    0    0    0     0\n\n\nSo, as before, the enemy begins on a distance score of 96 at [3,3] and will move south to 97 on [4,3].\nNow what? The wall has been scored as zero, so the enemy looks around for the largest distance score of its remaining neighbours. They all score 96, so the enemy character just selects randomly one of west, north or east.\nUhoh: this means the enemy will be stuck in an infinite loop between the adjacent scores of 96 and 97. This isnâ€™t very intelligent.\nHow can we account for blockages like this?"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#here-comes-the-flood-fill",
    "href": "posts/2022-06-10-basic-search/index.html#here-comes-the-flood-fill",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Here comes the flood-fill",
    "text": "Here comes the flood-fill\nPerhaps a better approach is to â€˜flood fillâ€™ the distance scores. Imagine the start point is a source of water and itâ€™s filling up the dungeon. Obviously the water will have to flow around walls and the hardest-to-reach areas will be filled last.\nA basic flood-fill approach we can implement is â€˜breadth-firstâ€™, which visits tiles in a â€˜frontierâ€™ expanding from the start point. Distance scores are assigned once to frontier tiles and neighbours are consecutively added to a â€˜queueâ€™ to be checked.\nThis is slightly expensive because every traversable tile has to be assessed, but it means that multiple enemies can all use the same distance map to navigate.1\nWe donâ€™t need to get too complicated for {r.oguelike}; it just has to work. Iâ€™ll illustrate the breadth-first approach with a pretty basic and verbose implementation.2\n\nDeep breadth-first\nNow to implement it in R. Reminder: weâ€™ll use two matrices to represent the tile grid (seen by player) and the distance grid (just holds the distance scores).\nIâ€™m going to use three main functions:\n\ninitiate_distance_map(), which creates a distance-map matrix of equal size to the tile map and fills all traversable spaces with zero and all non-traversable spaces with Infinity (which the character will want to avoid)\npopulate_distance_map, which flood-fills the traversable space by expanding a frontier from the start point, assigning a distance score to each neighbour thatâ€™s +1 of the score of the parent tile and adding those neighbours to the frontier queue so they can be inspected next\nmove_enemy() to move the enemy character one tile per turn towards the tile with the lowest distance score (i.e.Â the tile that holds the player @)\n\n\nCreate the distance-score matrix\nUsing the same obstacle map from earlier in the post, we can first initiate a complementary distance-score matrix:\n\ninitiate_distance_map &lt;- function(m) {\n\n  d &lt;- m  # copy the tile map\n  d[which(d != \"#\")] &lt;- 0  # set non-wall tiles to 0\n  d[which(d == \"#\")] &lt;- Inf  # set wall tiles to infinity\n  matrix(as.numeric(d), nrow(d), ncol(d))  # recast as numeric\n\n}\n\nNow we can adjust those distance scores. The algorithm is basically:\n\nCreate a frontier vector of tile indices (i.e.Â the edges of the flood-fill as it moves outward) and add the starting tile (i.e.Â the tile index that holds the player character)\nCreate a vector to hold tile indices that weâ€™ve already visited\nBegin a loop where:\n\nthe first tile in the frontier queue becomes the â€˜currentâ€™ tile\nthe current tile is removed to the frontier\nthe current tile is added to the visited list\nthe tile indices of the current tileâ€™s neighbours (north, south, east and west) are identified\nif not yet visited, the neighbours are assigned distance scores that are +1 of the current tile\n\nContinue the loop until you run out of tiles in the frontier queue\n\nIâ€™ve written a small sub-function to handle neighbour-finding:\n\nget_neighbours &lt;- function(m, current) {\n\n  n_rows &lt;- nrow(m)\n\n  c(\n    if (m[current - n_rows] != \"#\") current - n_rows,\n    if (m[current - 1] != \"#\") current - 1,\n    if (m[current + 1] != \"#\") current + 1,\n    if (m[current + n_rows] != \"#\") current + n_rows\n  )\n\n}\n\nWhich plugs into the main function for implementing the algorithm that assigns distance scores:\n\npopulate_distance_map &lt;- function(m, d) {\n\n  start &lt;- which(m == \"@\")  # start tile, i.e. player tile\n  \n  # Initiate vectors\n  frontier &lt;- start  # to be assessed\n  visited &lt;- c()  # have been assessed\n\n  while (length(frontier) &gt; 0) {\n\n    current  &lt;- frontier[1]  # set first tile of frontier as current\n    frontier &lt;- frontier[!frontier == current]  # remove current tile from frontier\n    visited  &lt;- append(visited, current)  # mark current as visited\n\n    neighbours &lt;- get_neighbours(m, current)  # get vector of neighbour indices\n    neighbours &lt;- neighbours[!neighbours %in% visited]\n\n    for (neighbour in neighbours) {\n      if (!neighbour %in% visited) {  # only assign distance to unvisited neighbours\n        d[neighbour] &lt;- d[current] + 1  # assign distance, one more than parent\n      }\n    }\n\n    frontier &lt;- append(frontier, neighbours)  # add neighbour to the frontier\n\n  }\n\n  d\n\n}\n\n\n\nMove to target\nFinally, hereâ€™s the function that lets the enemy check its neighbours for the lowest distance score and move one tile in that direction:\n\nmove_enemy &lt;- function(m, d) {\n\n  # Find tiles of interest\n  en_loc &lt;- which(m == \"E\")\n  player_loc &lt;- which(m == \"@\")\n  n_rows &lt;- nrow(m)\n\n  # Get neighbour tile indices\n  ind &lt;- c(\n    n = en_loc - 1,\n    s = en_loc + 1,\n    e = en_loc + n_rows,\n    w = en_loc - n_rows\n  )\n\n  # Get tile content for neighbours\n  tiles &lt;- c(\n    n = m[ind[\"n\"]],\n    s = m[ind[\"s\"]],\n    e = m[ind[\"e\"]],\n    w = m[ind[\"w\"]]\n  )\n\n  # Get the distance score for a tile if traversable/target\n  dist &lt;- c(\n    n = if (tiles[\"n\"] %in% c(\".\", \"@\")) d[ind[\"n\"]],\n    s = if (tiles[\"s\"] %in% c(\".\", \"@\")) d[ind[\"s\"]],\n    e = if (tiles[\"e\"] %in% c(\".\", \"@\")) d[ind[\"e\"]],\n    w = if (tiles[\"w\"] %in% c(\".\", \"@\")) d[ind[\"w\"]]\n  )\n\n  # Sample a direction if there's ties, move there\n  direction &lt;- sample(names(dist[dist == min(dist)]), 1)\n  en_loc_new &lt;- ind[names(ind) == direction]\n  m[en_loc] &lt;- \".\"  # replace old location with floor tile\n  m[en_loc_new] &lt;- \"E\"  # place enemy in new location\n\n  m\n\n}\n\n\n\nPut it all together\nNow to apply the functions to our dungeon room, with its minor obstacle. Hereâ€™s a reminder of the layout:\n\nprint_tiles(m)\n\n# # # # # # # # # # \n# . . . . . . . . # \n# . E . . . . . . # \n# . . . . . . . . # \n# # # # # # # # . # \n# . . . . . . . . # \n# . @ . . . . . . # \n# . . . . . . . . # \n# # # # # # # # # # \n\n\nNow we can initiate the distance-score matrix:\n\nd &lt;- initiate_distance_map(m)\nd\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n [2,]  Inf    0    0    0    0    0    0    0    0   Inf\n [3,]  Inf    0    0    0    0    0    0    0    0   Inf\n [4,]  Inf    0    0    0    0    0    0    0    0   Inf\n [5,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf    0   Inf\n [6,]  Inf    0    0    0    0    0    0    0    0   Inf\n [7,]  Inf    0    0    0    0    0    0    0    0   Inf\n [8,]  Inf    0    0    0    0    0    0    0    0   Inf\n [9,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n\n\nThen populate the distance scores from the target:\n\nd &lt;- populate_distance_map(m, d)\nd\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n [2,]  Inf   18   17   16   15   14   13   12   11   Inf\n [3,]  Inf   17   16   15   14   13   12   11   10   Inf\n [4,]  Inf   16   15   14   13   12   11   10    9   Inf\n [5,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf    8   Inf\n [6,]  Inf    2    1    2    3    4    5    6    7   Inf\n [7,]  Inf    1    0    1    2    3    4    5    6   Inf\n [8,]  Inf    2    1    2    3    4    5    6    7   Inf\n [9,]  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf  Inf   Inf\n\n\nSuccess. You can see the start tile at [7,3] scores zero and emanates out to the right, around the obstacle, before wrapping back to the top-left and toward the enemy at position [3,3].\nThe enemy needs only to move to the neighbouring tile with the lowest distance score. So from 16 to 15 on either [4,3] or [3,4], then to 14, to 13, etc.\nSee how this time the character wonâ€™t get stuck trying to move south? The distance scores decrease from left to right before curving round the wall in the direction of the playerâ€™s tile.\nFor fun, we can print to the console an animation of the movement, which Iâ€™ve captured in gif form.\n\n\nClick for R code\n\n\nrepeat {\n  cat(\"\\014\")  # clear console\n  m &lt;- move_enemy(m, d)  # move enemy\n  print_tiles(m)  # print to console\n  Sys.sleep(0.5)  # wait\n  if (!any(m == \"@\")) break  # stop if player captured\n}\n\n\n\nYou can see the enemy go round the wall and reach the player using a pretty efficient path.\nAnd in a more dungeonlike room:"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#the-end-of-the-tunnel",
    "href": "posts/2022-06-10-basic-search/index.html#the-end-of-the-tunnel",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "The end of the tunnel?",
    "text": "The end of the tunnel?\nIâ€™ve smashed this together quickly with some completely un-optimised code. Once Iâ€™ve ironed out some kinks, itâ€™ll go into the {r.oguelike} package proper.\nOf course, Iâ€™ll need to consider:\n\na moving player-character, so the distances map will need to be updated every turn\nlimiting the range of the frontier to some specified distance away from the player, so that an enemy will only begin pathfinding when a player is closer and more â€˜detectableâ€™3\na â€˜vision-coneâ€™ so the enemy only â€˜seesâ€™ the player if thereâ€™s a clear set of floor tiles between them\nallowing different enemy classes to move differently, e.g.Â attack immediately, randomly, or when the player is within a certain distance\n\nAs a basic preview, hereâ€™s what it looks like when you throw the pathfinding into a procedurally-generated dungeon from {r.oguelike}:\n\nThis gives a nice impression of the panic that might set in if youâ€™re down to 1 HP and a monster is chasing you into a dead-end.\nPanic: a quintessential roguelike â€˜featureâ€™!"
  },
  {
    "objectID": "posts/2022-06-10-basic-search/index.html#environment",
    "href": "posts/2022-06-10-basic-search/index.html#environment",
    "title": "Automated pathfinding in {r.oguelike}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-02 12:57:10 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#tldr",
    "href": "posts/2022-07-08-rproj-dupes/index.html#tldr",
    "title": "Stop opening the same RStudio Project twice",
    "section": "tl;dr",
    "text": "tl;dr\nI keep opening more than one instance of the same RStudio Project and itâ€™s annoying me, so I wrote a function to warn me on startup."
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#double-trouble",
    "href": "posts/2022-07-08-rproj-dupes/index.html#double-trouble",
    "title": "Stop opening the same RStudio Project twice",
    "section": "Double trouble",
    "text": "Double trouble\nSometimes I write code in an RStudio Project and then go and do something else. My memory is terrible, so later I might open a second instance of the same project and wonder what happened to that code Iâ€™d written before.\nIs there a way to stop this from happening? Maybe thereâ€™s a setting in RStudio or something? Maybe I should just Google it?\nNah, instead I hacked together a little function that can be run on startup to warn meâ€”via both text and audioâ€”if I have multiple RStudio sessions open with the same name. Itâ€™s called check_rproj_dupes().\nNote that the function checks which OS youâ€™re using with .Platform$OS.type, with the hope that one day I (or you) will write some corresponding code that will work on Windows. I donâ€™t use Windows, so I canâ€™t test anything.\nThe code has a few steps:\n\nPass the ps (process status) command with flag -e (show all running processes) to the shell via the system() function, which is captured in a vector when intern = TRUE\nUse grepl() to isolate the strings that contain the â€˜.RProjâ€™ RStudio Project extension\nExtract the full paths to the .RProj files\nExtract the basenames from the paths (i.e.Â just the filename for the .RProj)\nCompare the basenames to see which are duplicated\nDisplay any matches in a warning message and, if speak = TRUE, read aloud a warning message thatâ€™s passed to the say function via system()\n\nYeah, this could be simplified, but Iâ€™m no code golfer. I just want it to work and for it to be pretty obvious what itâ€™s doing.\nHere it is (or see it in a GitHub Gist, where you can write your suggestions for how to improve it):\n\ncheck_rproj_dupes &lt;- function(speak = FALSE) {\n\n  os &lt;- .Platform$OS.type\n\n  if (os == \"unix\") {\n\n    ps_out &lt;- system(\"ps -e\", intern = TRUE)\n    ps_rproj &lt;- ps_out[grepl(\".Rproj\", ps_out)]\n    ps_split &lt;- strsplit(ps_rproj, \"\\\\s\")\n    rproj_paths &lt;- lapply(ps_split, function(x) x[grepl(\".Rproj$\", x)])\n    rproj_basenames &lt;- lapply(rproj_paths, basename)\n    rproj_dupes &lt;- sort(unlist(rproj_basenames[duplicated(rproj_basenames)]))\n\n  }\n\n  if (os == \"windows\") {\n    stop(\"Sorry, check_rproj_dupes() doesn't work on Windows yet :-(\")\n  }\n\n  if (length(rproj_dupes) &gt; 0) {\n\n    if (speak & os == \"unix\") {\n\n      dupes_string &lt;- paste(rproj_dupes, collapse = \", \")\n      dupes_string_say &lt;- gsub(\"\\\\.Rproj\", \" dot ar proj \", dupes_string)\n\n      message &lt;- paste(\n        \"say ha, you fool, you have more than one open RStudio Project with\",\n        ifelse(length(rproj_dupes) == 1, \"this name:\", \"these names:\"),\n        dupes_string_say\n      )\n\n      system(message)\n\n    }\n\n    warning(\n      \"You've got open RStudio Projects with the same name:\\n\",\n      paste(\"-\", rproj_dupes, collapse = \"\\n\"), \"\\n\",\n      call. = FALSE\n    )\n\n  }\n\n}\n\ncheck_rproj_dupes()\nrm(check_rproj_dupes)\n\nHow would you actually use this though?\nYou can add it to your â€˜hiddenâ€™ .Rprofile file, which is a place that you can store code that runs whenever RStudio is started.1 Perhaps the easiest way to open it is with usethis::edit_r_profile(). Then you can paste in all the code from the block above.2\nOn startup, the code will run and if thereâ€™s no problem, then youâ€™ll see no message. No news is good news.\nBut letâ€™s say I had opened sandbox.Rproj earlier and was now opening the file again. In this second RStudio instance, the usual R startup message will print, followed by a warning:\nWarning message:\nYou've got open RStudio Projects with the same name:\n- sandbox.Rproj \nIf speak = TRUE then youâ€™ll also hear this:\n\n\n\n\n\nSo hopefully now I will be less confused when trying to manage my RStudio sessions. At worst Iâ€™ll be shocked to hear the creepy computer voice tell me Iâ€™m a fool."
  },
  {
    "objectID": "posts/2022-07-08-rproj-dupes/index.html#environment",
    "href": "posts/2022-07-08-rproj-dupes/index.html#environment",
    "title": "Stop opening the same RStudio Project twice",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 23:59:43 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#tldr",
    "href": "posts/2022-02-19-backtick/index.html#tldr",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote a tiny R package called {backtick}, which contains an RStudio Addin with a handful of functions for inserting backticks into your R scripts and R Markdown documents (yes, really)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#plus-one",
    "href": "posts/2022-02-19-backtick/index.html#plus-one",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Plus one",
    "text": "Plus one\nRStudio Addins let you select an R function from a dropdown menu in the RStudio IDE. Theyâ€™re often functions that you donâ€™t need in your executed script, but can make your life easier by performing some kind of supportive action.\nFor example, you can use the RStudio Addin in the {remedy} package from ThinkR to add Markdown formatting to your text. RStudioâ€™s {reprex} package has a built-in RStudio Addin to create a reproducible example from highlighted code. Or how about Miles McBainâ€™s {datapasta} Addin for pasting conveniently into R scripts from external sources?\nYou can find many more examples in Dean Attaliâ€™s {addinslist} package, which itself contains an Addin forâ€¦ adding more Addins."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#in-addition",
    "href": "posts/2022-02-19-backtick/index.html#in-addition",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "In addition",
    "text": "In addition\nIâ€™ve written about RStudio Addins before.\nI have a GitHub-hosted package called {blogsnip} with an Addin to help me insert code into these blogposts.1 For example, to insert the session-information block at the end of each post, or to insert HTML to create more accessible images.\n{blogsnip} also hosts a concept function to add a comment to each closing bracket with the name of the function being closed. Iâ€™ve found it useful for keeping on top of deeply-nested Shiny apps.\nA while back I also wrote an Addin for the {r2eng} package to let your computer speak R code aloud as an English sentence.\nI also recently created the {snorkel} R package, which contains an Addin to help you insert {roxygen2} formatting to your function documentation. Turns out Jozef wrote a detailed series about how you can do something similar.\n\n\n\nYou put a snorkel in your mouth to help you breathe oxygen; you put a {snorkel} in your addins to help you write with {roxygen2}.\n\n\nI wanted to write something about how to quickly set up a package to insert or replace text, which I think is probably the most common (simple) use of RStudio Addins.\nEventually I was nerdsniped (unintentionally) on Twitter by Calum to do something about it."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#the-problem",
    "href": "posts/2022-02-19-backtick/index.html#the-problem",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "The problem",
    "text": "The problem\nProblem: Calumâ€™s backtick key, `, is being used to activate additional software thatâ€™s awkward to toggle on and off every time they wanted to use the backtick for R coding.2\nTo solve Calumâ€™s problem (and Italyâ€™s?3), you could try to use a custom keyboard shortcut, or maybe a snippet. And RStudio already has a button and shortcut in its IDE for inserting R Markdown code chunks, which require triple backticks to demarcate the start and end of the chunk.\nBut an RStudio Addin is another viable method that means you can bundle up a set of functions that insert each of the backtick â€˜constructionsâ€™, from a single backtick to an R Markdown chunk.\nAs a bonus, you can also set the functions of an Addin to custom keyboard shortcuts and quickly access them from the RStudio command palette (just hit Shift + Cmd + P, or Shift + Ctrl + P, then type the word â€˜backtickâ€™)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#a-solution",
    "href": "posts/2022-02-19-backtick/index.html#a-solution",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "A solution",
    "text": "A solution\nSo, the (very specific!) user need was clear and I created the {backtick} package with functions to:\n\ninsert a single backtick (i.e.Â `)\nsurround selected text with single backticks (i.e.Â selection becomes `selection`)\nsurround selected text with backticks for execution as inline R code in an R Markdown document (as above, but inserts an r and space after the first backtick)\nsurround selected text with backticks for execution as an R code chunk in an R Markdown document (selection is surrounded by ```{r} above and ``` below)\n\nThat last one is especially neat because the in-built RStudio function doesnâ€™t appear to put selected text inside an R Markdown chunk; it simply inserts the skeleton of a chunk.\nCalum notes that this solution worked, and that they were able to set the insert backtick Addin to the keyboard shortcut Alt + `, lol."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#add-your-own",
    "href": "posts/2022-02-19-backtick/index.html#add-your-own",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Add your own",
    "text": "Add your own\nI wanted to record for posterity how you (and me) can create this sort of thing.\n\nFirst, create a new packageâ€”I like to use usethis::create_package()â€”and complete basic things like the DESCRIPTION file (I wrote about this before)\nWrite functions in an R scriptâ€”I like to use usethis::use_r() to create this script in the packageâ€”that insert code or replace selected text using the {rstudioapi} package)\nAdd an inst/rstudio/addins.dcf file4 that declares each of your Addins\n\nPoints 2 and 3 are in scope for this quick post.\n\nUse {rstudioapi}\nWhat do I mean by â€˜write functions that insert or replaceâ€™ text?\nWell, insertion is straightforward. Hereâ€™s the function definition from {backtick} to insert a single backtick:\n\nbt_backtick &lt;- function() {\n  rstudioapi::insertText(\"`\")\n}\n\nIn other words, itâ€™s as simple as a function that contains rstudioapi::insertText(). This fetches information from the IDE to know where the cursor is placed in your script, which is where a supplied text string (a single backtick in this case) will be inserted.\nAnd what about text replacement? A similar story: the {rstudioapi} package is used to detect the selected text, which can then be pasted together with other strings to produce and insert a new compound string. Hereâ€™s an example from {backtick} for surrounding selected text with backticks:\n\nbt_backticks &lt;- function() {\n\n  active_doc &lt;- rstudioapi::getSourceEditorContext()\n\n  if (!is.null(active_doc)) {\n\n    selected_text &lt;- active_doc$selection[[1]]$text\n\n    text_replace &lt;- paste0(\"`\", selected_text, \"`\")\n\n    rstudioapi::modifyRange(\n      active_doc$selection[[1]]$range,\n      text_replace\n    )\n\n  }\n\n}\n\nSo, in short, rstudioapi::getSourceEditorContext() fetches information about the script pane, including the current selection. That selection can be pasted with other strings, such as a backtick character at the start and end, and then inserted back into the script pane with rstudioapi::modifyRange() to replace the original selection.\nAnd, wellâ€¦ thatâ€™s it for functions. All you need to do now is create a special text file so that the functions can be interpreted as Addins.\n\n\nCreate a dcf\nSo, for example, the bt_bactick() function can be exposed as an Addin function by adding the following to the inst/rstudio/addins.dcf file:\nName: Insert Backtick\nDescription: Insert a single backtick. In R Markdown file, one backtick will be\n    inserted. RStudio automatically adds a second backtick when this function is\n    used in an R script.\nBinding: bt_backtick\nInteractive: false\nThis is pretty straightforward: you provide a name (which will be the name you see in the RStudio Addins dropdown menu) and a description (I just copied the description I wrote for the function documentation), along with the binding (just the function name). Thereâ€™s also â€˜interactiveâ€™, which tells RStudio if it needs to wait for the user to do something (no, or false in our example)."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#addintional-resources",
    "href": "posts/2022-02-19-backtick/index.html#addintional-resources",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Addintional resources",
    "text": "Addintional resources\nThis was a quick roundup to help you (and me) remember quickly how to create this kind of simple insert/replace type of RStudio Addin.\nI recommend you check out a number of more in-depth resources:\n\nSharonâ€™s excellent video â€˜Write your own RStudio addinsâ€™\nJozefâ€™s in-depth blog series\nRStudioâ€™s very own introduction\n\nLet me know about other useful Addins or tutorials for making them.\nAnd perhaps begin lobbying the Italian government to a backtick key on their keyboards as a gesture of solidarity with developers."
  },
  {
    "objectID": "posts/2022-02-19-backtick/index.html#environment",
    "href": "posts/2022-02-19-backtick/index.html#environment",
    "title": "Add in an RStudio Addin to add in backticks",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:08:17 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#tldr",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#tldr",
    "title": "OG emoji SVGs",
    "section": "tl;dr",
    "text": "tl;dr\nI wrote code to produce SVG versions of the â€˜first-everâ€™ emoji set. Using R, I scraped Emojipedia with the {polite} package and then handled images with {png}, {magick} and {svglite}."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#important-archival-work",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#important-archival-work",
    "title": "OG emoji SVGs",
    "section": "Important archival work",
    "text": "Important archival work\nI posted recently on creating â€˜pixel artâ€™ in R and have since stumbled upon an old post by mikefc on the coolbutuseless blog with a method that makes it easier to convert from an image to its â€˜pixelsâ€™.\nIâ€™ve also learnt recently of Emilâ€™s development of the {emoji} package for R (superseding Hadleyâ€™s GitHub-only {emo} package).\nSpeaking of emoji, Jeremy Burge and colleagues have worked hard to archive and document them on Emojipedia. They posted recently about the discovery that the first emoji set was likely to be from SoftBank in 1997, rather than the NTT DOCOMO set that was acquired by MoMA.\nAs a mash-up of these things, Iâ€™ve decided to create SVG versions of the original SoftBank set. This format means that the images can be resized without loss of resolution and can be adapted in other ways, like being recoloured.\nThe approach:\n\nScrape the Emojipedia hub page for SoftBankâ€™s 1997 emojis\nScrape each emojiâ€™s dedicated page to retrieve its image path\nDownload each image (gif format)\nConvert gifs to PNGs to matrices\nConvert matrices to plots to SVGs\n\nThe packages we need are all available from CRAN with install.packages():\n\nsuppressPackageStartupMessages({\n  library(polite)\n  library(rvest)\n  library(purrr)\n  library(svglite)\n  library(png)\n  library(magick)\n})\n\nAll the code here is available in a GitHub repo."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#scrape-politely",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#scrape-politely",
    "title": "OG emoji SVGs",
    "section": "Scrape politely",
    "text": "Scrape politely\nItâ€™s best to scrape using the {polite} package, which allows you to identify yourself to the target website and observe any requests to delay between scrapes. Iâ€™ve written about this before.\nFirst we bow() to the site by providing our information and saying where we want to scrape. The returned object contains information that {polite} uses to decide whether scraping is allowed and whether a crawl delay is required.\n\nep_bow &lt;- bow(\n  url = \"https://emojipedia.org/softbank/1997\",\n  user_agent = \"M Dray &lt;https://www.matt-dray.com&gt;\"\n)\n\nep_bow\n\n&lt;polite session&gt; https://emojipedia.org/softbank/1997\n    User-agent: M Dray &lt;https://www.matt-dray.com&gt;\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nFrom the SoftBank 1997 hub page of Emojipedia we can scrape the URLs that lead to each emojiâ€™s dedicated page. The {rvest} package has some handy functions that help us manipulate the retrieved HTML after scraping with {polite}, which rate-limits us to a retrieval every 5 seconds, given the information returned from our bow().\n\nsb_urls &lt;- scrape(ep_bow) |&gt; html_nodes(\"a\") |&gt; html_attr(\"href\")\nsb97_urls &lt;- sb_urls[grepl(\"/1997/\", sb_urls) & !grepl(\"more\", sb_urls)]\nhead(sb97_urls)\n\n[1] \"/softbank/1997/grinning-face-with-big-eyes/\"   \n[2] \"/softbank/1997/smiling-face-with-smiling-eyes/\"\n[3] \"/softbank/1997/disappointed-face/\"             \n[4] \"/softbank/1997/angry-face/\"                    \n[5] \"/softbank/1997/pile-of-poo/\"                   \n[6] \"/softbank/1997/kiss-mark/\"                     \n\n\nFrom this we can get the full list of 90 emoji names for the 1997 SoftBank set.\n\n\nClick to expand full list of emoji names\n\n\nbasename(sb97_urls)\n\n [1] \"grinning-face-with-big-eyes\"    \"smiling-face-with-smiling-eyes\"\n [3] \"disappointed-face\"              \"angry-face\"                    \n [5] \"pile-of-poo\"                    \"kiss-mark\"                     \n [7] \"broken-heart\"                   \"red-heart\"                     \n [9] \"raised-hand\"                    \"victory-hand\"                  \n[11] \"index-pointing-up\"              \"thumbs-up\"                     \n[13] \"raised-fist\"                    \"oncoming-fist\"                 \n[15] \"boy\"                            \"girl\"                          \n[17] \"man\"                            \"woman\"                         \n[19] \"baby-angel\"                     \"person-surfing\"                \n[21] \"dog-face\"                       \"cat-face\"                      \n[23] \"tiger-face\"                     \"horse-face\"                    \n[25] \"mouse-face\"                     \"bear\"                          \n[27] \"penguin\"                        \"spouting-whale\"                \n[29] \"fish\"                           \"cherry-blossom\"                \n[31] \"rose\"                           \"shortcake\"                     \n[33] \"hot-beverage\"                   \"cocktail-glass\"                \n[35] \"beer-mug\"                       \"fork-and-knife\"                \n[37] \"mount-fuji\"                     \"house\"                         \n[39] \"office-building\"                \"church\"                        \n[41] \"sunrise-over-mountains\"         \"railway-car\"                   \n[43] \"bullet-train\"                   \"station\"                       \n[45] \"automobile\"                     \"fuel-pump\"                     \n[47] \"sailboat\"                       \"airplane\"                      \n[49] \"twelve-oclock\"                  \"one-oclock\"                    \n[51] \"two-oclocktime\"                 \"three-oclock\"                  \n[53] \"four-oclock\"                    \"five-oclock\"                   \n[55] \"six-oclock\"                     \"seven-oclock\"                  \n[57] \"eight-oclock\"                   \"nine-oclock\"                   \n[59] \"ten-oclock\"                     \"eleven-oclock\"                 \n[61] \"crescent-moon\"                  \"sun\"                           \n[63] \"cloud\"                          \"umbrella-with-rain-drops\"      \n[65] \"snowman-without-snow\"           \"christmas-tree\"                \n[67] \"soccer-ball\"                    \"baseball\"                      \n[69] \"tennis\"                         \"flag-in-hole\"                  \n[71] \"skis\"                           \"t-shirt\"                       \n[73] \"running-shoe\"                   \"ring\"                          \n[75] \"gem-stone\"                      \"musical-note\"                  \n[77] \"microphone\"                     \"saxophone\"                     \n[79] \"guitar\"                         \"trumpet\"                       \n[81] \"mobile-phone\"                   \"telephone\"                     \n[83] \"fax-machine\"                    \"laptop\"                        \n[85] \"movie-camera\"                   \"camera\"                        \n[87] \"key\"                            \"question-mark\"                 \n[89] \"exclamation-mark\"               \"trident-emblem\"                \n\n\n\nNow, thanks to the {purrr} package, we can iterate over these pages and extract each emoji image URL.1 You have to update your bow() with a nod() for each new page you want to scrape.\n\nscrape_sb_gif &lt;- function(sb_ext, bow = ep_bow) {\n  session &lt;- nod(ep_bow, sb_ext)\n  images &lt;- scrape(session) |&gt; html_nodes(\"img\") |&gt; html_attr(\"src\")\n  images[grepl(\".gif$\", images)]\n}\n\nsb97_img &lt;- map_chr(sb97_urls, scrape_sb_gif)\n\nhead(sb97_img)\n\n[1] \"https://em-content.zobj.net/thumbs/160/softbank/182/smiling-face-with-open-mouth_1f603.gif\"  \n[2] \"https://em-content.zobj.net/thumbs/160/softbank/182/smiling-face-with-smiling-eyes_1f60a.gif\"\n[3] \"https://em-content.zobj.net/thumbs/160/softbank/182/disappointed-face_1f61e.gif\"             \n[4] \"https://em-content.zobj.net/thumbs/160/softbank/182/angry-face_1f620.gif\"                    \n[5] \"https://em-content.zobj.net/thumbs/160/softbank/182/pile-of-poo_1f4a9.gif\"                   \n[6] \"https://em-content.zobj.net/thumbs/160/softbank/182/kiss-mark_1f48b.gif\"                     \n\n\nSo, looks like these are stored on AWS servers."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#download-and-convert",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#download-and-convert",
    "title": "OG emoji SVGs",
    "section": "Download and convert",
    "text": "Download and convert\nNow we can download the emoji images. Here Iâ€™m going to download them to a temporary folder. Iâ€™ve also chosen to insert manually a random one- to five-second delay between downloads here to limit the impact on the server.\nNote that the download.file() function prints an output for each downloaded file, but Iâ€™ve hidden this because thereâ€™s 90 outputs.\n\n# Create temporary folder to write into\ntmp &lt;- tempdir()\n\n# Download each file and give it the emoji name\nwalk2(\n  sb97_img,\n  basename(sb97_urls),\n  ~{ cat(\"Downloading\", .y, \"\\n\")\n    download.file(.x, file.path(tmp, paste0(.y, \".gif\")))\n    Sys.sleep(sample(1:5, 1)) }\n)\n\nWe actually want PNG format for the next step, not gifs. One way to do this is to read in the gifs as {magick} objects and then write them back out to png.\n\ngif_paths &lt;- list.files(tmp, pattern = \".gif\", full.names = TRUE)\npng_paths &lt;- gsub(\"gif\", \"png\", gif_paths)\n\nwalk2(\n  gif_paths,\n  png_paths,\n  ~image_read(.x) |&gt; image_write(.y, format = \"png\")\n)"
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#generate-outputs",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#generate-outputs",
    "title": "OG emoji SVGs",
    "section": "Generate outputs",
    "text": "Generate outputs\n\nPixel plots\nFirst, we need a function to read the PNGs and create a 32 by 32 matrix representing the pixels of the image.\n\npixelate_emoji &lt;- function(path_in) {\n  x &lt;- readPNG(path_in)\n  y &lt;- matrix(as.vector(x), 32)\n  t(y[nrow(y):1, 33:64])\n}\n\nWe can take the matrix output from pixelate_emoji() and create a plot of that emojiâ€™s pixels using the image() function from base R.\n\nplot_emoji &lt;- function(emo_mat, col_px = \"black\", col_bg = \"white\") {\n  image(\n    emo_mat,\n    col = c(col_bg, col_px),\n    useRaster = TRUE,\n    axes = FALSE, xaxs = NULL, yaxs = NULL\n  )\n}\n\nWe can create a grid of them all.\n\npar(mfrow = c(10, 9), mar = rep(1, 4))\nwalk(png_paths, ~pixelate_emoji(.x) |&gt; plot_emoji())\n\n\n\n\nSome are a bit peculiar. The faces look like onions or dumplings, for example. But the vast majority are recognisable as emoji that persist today. Note the poo with a smiley face; this emoji is not recent!\nHereâ€™s three emoji, but closer.\n\npar(mfrow = c(1, 3), mar = rep(1, 4))\nwalk(\n  png_paths[c(82, 19, 55)],\n  ~pixelate_emoji(.x) |&gt; plot_emoji()\n)\n\n\n\n\nOr, in modern parlance: ðŸ‘ðŸ˜žðŸ’©\n\n\nWrite SVGs\nWe can save each plot into SVG (Scalable Vector Graphics) format using the {svglite} package, which can be put in a function that accepts a matrix thatâ€™s output from pixelate_emoji().\n\nsave_emoji &lt;- function(emo_mat, file_out, dimn = 10) {\n  svglite(file_out, width = dimn, height = dimn)\n  par(mar = rep(0, 4), mfrow = c(1, 1))\n  plot_emoji(emo_mat)\n  dev.off()\n}\n\nNow to convert all the PNGs to SVGs.\n\nsvg_paths &lt;- gsub(\"png\", \"svg\", png_paths)\n\nwalk2(\n  png_paths, \n  svg_paths,\n  ~save_emoji(pixelate_emoji(.x), file_out = .y)\n) \n\nWe can demonstrate the benefit of SVGs by plotting a scraped PNG emoji (the excellent â€˜spouting whaleâ€™) at small, medium and large sizes (25, 100 and 500 pixels square) and then do the same for the SVGs.\nFirst the PNG, which look more fuzzy as the image gets larger:\n  \nNow the SVGs, which look sharp at all sizes:\n  \nThis happens because an SVG is basically a text file of instructions on how to build the image that an interpreter can re-build from scratch at any size. Hence the word â€˜scalableâ€™ in â€˜SVGâ€™."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#licensing",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#licensing",
    "title": "OG emoji SVGs",
    "section": "Licensing?",
    "text": "Licensing?\nThis was a project to remind me about â€˜politeâ€™ scraping and the powers of SVG graphics. But maybe the outputs could be useful for archival purposes or something?\nI canâ€™t be completely certain of licensing for this particular emoji set (even Emojipedia isnâ€™t always sure), but I certainly canâ€™t and donâ€™t condone their use for any commercial activities; they belong to SoftBank. Iâ€™ve used a few images in this post for demonstration purposes only.\nIâ€™ve made the code available in a GitHub repo that you can use for personal investigation, but I havenâ€™t included any of the outputs there. Let me know if you find a use for this, lol."
  },
  {
    "objectID": "posts/2021-07-31-og-emoji-svg/index.html#environment",
    "href": "posts/2021-07-31-og-emoji-svg/index.html#environment",
    "title": "OG emoji SVGs",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-09 11:20:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.7.4  png_0.1-8     svglite_2.1.1 purrr_1.0.1   rvest_1.0.3  \n[6] polite_0.1.3 \n\nloaded via a namespace (and not attached):\n [1] jsonlite_1.8.7    compiler_4.3.1    selectr_0.4-2     Rcpp_1.0.11      \n [5] xml2_1.3.4        stringr_1.5.0     assertthat_0.2.1  spiderbar_0.2.5  \n [9] systemfonts_1.0.4 yaml_2.3.7        fastmap_1.1.1     mime_0.12        \n[13] R6_2.5.1          curl_5.0.1        knitr_1.43.1      htmlwidgets_1.6.2\n[17] rlang_1.1.1       cachem_1.0.8      stringi_1.7.12    xfun_0.39        \n[21] fs_1.6.2          memoise_2.0.1     cli_3.6.1         magrittr_2.0.3   \n[25] digest_0.6.31     rstudioapi_0.14   lifecycle_1.0.3   ratelimitr_0.4.1 \n[29] vctrs_0.6.3       robotstxt_0.7.13  evaluate_0.21     glue_1.6.2       \n[33] rmarkdown_2.23    httr_1.4.6        tools_4.3.1       usethis_2.2.1    \n[37] htmltools_0.5.5"
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#tldr",
    "href": "posts/2021-11-27-lubridate-fns/index.html#tldr",
    "title": "{itdepends} on {lubridate}",
    "section": "tl;dr",
    "text": "tl;dr\nI used {itdepends} to see how CRAN packages depend on {lubridate}, which was not removed from CRAN recently."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#lubrigate",
    "href": "posts/2021-11-27-lubridate-fns/index.html#lubrigate",
    "title": "{itdepends} on {lubridate}",
    "section": "Lubrigate",
    "text": "Lubrigate\nA test failure in {lubridate} led to hundreds of R developers being emailed about its potential expulsion from CRAN, which also threatened the hundreds of packages that depend on it.\nI see the benefit of minimising dependencies. I also understand the drawbacks of reinventing the wheel. Maybe {lubridate} is a good dependency: a simple API, part of the popular {tidyverse}, and it handles stuff you canâ€™t be bothered with (like whatâ€™s 29 February plus one year?).\nJim Hester spoke at rstudio::conf(2019) about dependencies. His {itdepends} package helps you understand their scale and impact on your package.1\nSo, for fun, Iâ€™m looking at how {lubridate} is used by packages that import it."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#crank-it-up",
    "href": "posts/2021-11-27-lubridate-fns/index.html#crank-it-up",
    "title": "{itdepends} on {lubridate}",
    "section": "CRANk it up",
    "text": "CRANk it up\nCRAN_package_db() is a convenient function that returns information about packages available on CRAN. We can filter it for the packages that import {lubridate}, i.e.Â they have {lubridate} in the Imports section of their DESCRIPTION file.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(tidyr)\nlibrary(stringr)\n\ncran &lt;- tools::CRAN_package_db()\n\nimports_lubridate &lt;- cran |&gt; \n  filter(str_detect(Imports, \"lubridate\")) |&gt; \n  pull(Package)\n\nsample(imports_lubridate, 5)  # random sample\n\n[1] \"quantdates\"  \"GetDFPData2\" \"esmprep\"     \"strand\"      \"votesmart\"\nRight, so thatâ€™s 494 packages out of 18,515 (3%). Is that a lot? Well, the tidyverse package {dplyr}â€”the Swiss Army knife of data wranglingâ€”is listed in the Imports of 2353 by comparison."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#install",
    "href": "posts/2021-11-27-lubridate-fns/index.html#install",
    "title": "{itdepends} on {lubridate}",
    "section": "InstALL",
    "text": "InstALL\nSo, perhaps this is a little nuts, but weâ€™re going to install all the {lubridate}-dependent packages because {itdepends} works with locally-installed packages.\n\ntmp &lt;- tempdir()  # temporary folder\n\npurrr::walk(\n  imports_lubridate,\n  ~install.packages(\n    .x, \n    destdir = tmp, \n    dependencies = FALSE,  # skip installing dependencies\n    repos = \"https://cran.ma.imperial.ac.uk/\"  # mirror\n  )\n)\n\nThis takes a little while. Thereâ€™s probably faster methods, like maybe the {pak} package, but for now I just used what worked. Iâ€™ve also hidden the output, obviously. Itâ€™s also possible that some packages will error out and wonâ€™t install. Oh no! Ah well."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#it-depends-on-itdepends",
    "href": "posts/2021-11-27-lubridate-fns/index.html#it-depends-on-itdepends",
    "title": "{itdepends} on {lubridate}",
    "section": "It depends on {itdepends}",
    "text": "It depends on {itdepends}\n{itdepends} is not available from CRAN, but you can install from GitHub.\n\nremotes::install_github(\"jimhester/itdepends\")\n\nNow we can pass each of package name to the dep_usage_package() function of {itdepends} in a loop. We get back a dataframe for each package, listing each function call it makes and the package that the function comes from.\nIâ€™ve added a mildly unorthodox use of next, borrowed from StackOverflow, because I was having trouble with the loop after a failure.\n\ndep_list &lt;- vector(\"list\", length(imports_lubridate)) |&gt; \n  setNames(imports_lubridate)\n\nfor (i in imports_lubridate) {\n  \n  skip &lt;- FALSE\n  \n  tryCatch({ \n    dep_list[[i]] &lt;- itdepends::dep_usage_pkg(i)\n    dep_list[[i]]$focus &lt;- i\n  },\n  error = function(e) { \n    dep_list[[i]] &lt;- data.frame(\n      pkg   = NA_character_,\n      fun   = NA_character_,\n      focus = NA_character_\n    )\n    skip &lt;&lt;- TRUE \n  })\n  \n  if (skip) next\n  \n}\n\nI absolutely do not claim this to be the best, most optimised approach. But it works for me."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#dependensheeesh",
    "href": "posts/2021-11-27-lubridate-fns/index.html#dependensheeesh",
    "title": "{itdepends} on {lubridate}",
    "section": "Dependensheeesh",
    "text": "Dependensheeesh\nNow that {itdepends} has extracted all the function calls from each of the packages, we can take a look at their frequencies.\n\nExample\nHereâ€™s the top 10 most-used functions from the first package alphabetically: {academictwitteR}.\n\nex_pkg &lt;- \"academictwitteR\"\n\ndep_list[[ex_pkg]] |&gt; \n  count(pkg, fun, sort = TRUE) |&gt;\n  slice(1:5)\n\n# A tibble: 5 Ã— 3\n  pkg   fun       n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 base  &lt;-      228\n2 base  {       197\n3 base  if      109\n4 base  $        90\n5 base  !        42\nItâ€™s not particularly exciting to know that the top 5 are made up of base R functions like the assignment arrow (&lt;-), the dollar-sign ($) data accessor2 and the square bracket ([). We also donâ€™t really care about the packageâ€™s internal functions. Letâ€™s filter out these packages and re-count\n\nbase_pkgs &lt;- sessionInfo()$basePkgs\n\ndep_list[[ex_pkg]] |&gt;\n  filter(!pkg %in% c(base_pkgs, ex_pkg)) |&gt; \n  count(pkg, fun, sort = TRUE) |&gt; \n  slice(1:10)\n\n# A tibble: 10 Ã— 3\n   pkg       fun                n\n   &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt;\n 1 lifecycle deprecate_soft    16\n 2 magrittr  %&gt;%               14\n 3 dplyr     bind_rows          8\n 4 dplyr     left_join          5\n 5 dplyr     select_if          5\n 6 httr      status_code        4\n 7 jsonlite  read_json          4\n 8 purrr     map_dfr            4\n 9 tibble    tibble             4\n10 dplyr     distinct           3\nAha. We can see immediately that the authors have made use of tidyverse to write their package, since you can see {dplyr}, {tibble}, etc, in there. This makes the use of {lubridate} relatively unsurprising.\nHereâ€™s the {lubridate} functions used by this package.\n\ndep_list[[ex_pkg]] |&gt;\n  filter(pkg == \"lubridate\") |&gt; \n  count(pkg, fun, sort = TRUE)\n\n# A tibble: 4 Ã— 3\n  pkg       fun             n\n  &lt;chr&gt;     &lt;chr&gt;       &lt;int&gt;\n1 lubridate as_datetime     1\n2 lubridate seconds         1\n3 lubridate with_tz         1\n4 lubridate ymd_hms         1\nSo this package uses four {lubridate} functions for conversion and formatting of datetimes.\n\n\nAll packages\nNow letâ€™s take a look at the function calls across all the packages that import {lubridate}. Iâ€™m first going to convert the list of results to a dataframe.\n\ndep_df &lt;- do.call(rbind, dep_list)\n\n\nFunction use by package\nThis is a count of the number of uses of each {lubridate} function by each of the the focus packages (i.e.Â the packages we installed).\n\npkg_fn_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  count(focus, fun, sort = TRUE)\n\npkg_fn_count |&gt; slice(1:5)\n\n# A tibble: 5 Ã— 3\n  focus        fun         n\n  &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt;\n1 PriceIndices month    1096\n2 PriceIndices year      678\n3 tidyndr      as_date    53\n4 RClimacell   with_tz    52\n5 RobinHood    ymd_hms    52\nHoly moley, the {PriceIndices} package calls month() and year(), used to extract elements of a date, over 1400 times combined.\n\n\nUnique function use by package\nWe can also look at things like the packages that make calls to the greatest number of unique {lubridate} functions. Hereâ€™s the top 5.\n\nfn_distinct_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  distinct(focus, fun) |&gt;\n  count(focus, sort = TRUE) \n\nfn_distinct_count |&gt; slice(1:5)\n\n# A tibble: 5 Ã— 2\n  focus              n\n  &lt;chr&gt;          &lt;int&gt;\n1 photobiology      26\n2 mctq              25\n3 fmdates           21\n4 finbif            15\n5 xml2relational    15\nSo these packages are using more than 10 unique functions from {lubridate}, which is pretty extensive usage. It may be tricky to do away with the convenience of the dependnecy in these cases, especially.\nConversely, a quick histogram reveals that a large number of packages are actually using just a single {lubridate} function.\n\nhist(\n  fn_distinct_count$n,\n  breaks = 30,\n  main = \"Unique {lubridate} functions used by\\npackages importing {lubridate}\",\n  xlab = \"Function count\"\n)\n\n\nMaybe the dependency could be dropped in these cases?\nOut of interest, which {lubridate} function is the most frequent in packages that use just one?\n\nfocus_one_fn &lt;- fn_distinct_count |&gt;\n  filter(n == 1) |&gt;\n  pull(focus)\n\npkg_fn_count |&gt; \n  filter(focus %in% focus_one_fn) |&gt; \n  count(fun, sort = TRUE) |&gt; \n  slice(1:5)\n\n# A tibble: 5 Ã— 2\n  fun             n\n  &lt;chr&gt;       &lt;int&gt;\n1 as_datetime     7\n2 as_date         6\n3 ymd             6\n4 ymd_hms         6\n5 is.Date         4\nLooks like some pretty standard functions, like converting to a date (as_date(), as_datetime()) or to parse dates with a particular time component (ymd_hms for year, month, date, hour, minute, seconds, and ymd()).\nI think this is interesting: some packages are importing {lubridate} in its entirety to use a single function. And these functions have base R equivalents with no package-dependency cost. Without diving too deep, this implies that people are using {lubridate} because of syntax familiarity or perhaps because theyâ€™re already loading other tidyverse packages anyway.\n\n\nNon-unique function use by package\nWhat about total calls to {lubridate} functions by each of the dependent package? This is on-unique, so could include one function being called multiple times by a given package.\n\nfn_nondistinct_count &lt;- dep_df |&gt;\n  filter(pkg == \"lubridate\") |&gt;\n  count(focus, sort = TRUE)\n\ndep_df |&gt; \n  count(focus) |&gt; \n  left_join(\n    fn_nondistinct_count,\n    by = \"focus\",\n    suffix = c(\"_total\", \"_lub\")\n  ) |&gt; \n  mutate(percent_lub = round(100 * n_lub / n_total, 1)) |&gt; \n  arrange(desc(percent_lub)) |&gt;\n  slice(1:5)\n\n# A tibble: 5 Ã— 4\n  focus        n_total n_lub percent_lub\n  &lt;chr&gt;          &lt;int&gt; &lt;int&gt;       &lt;dbl&gt;\n1 RClimacell      2241   225        10  \n2 riem             113     9         8  \n3 quantdates       534    42         7.9\n4 rtrends          101     8         7.9\n5 PriceIndices   23235  1805         7.8\nWow, 10% of calls by the {RClimacell} package involve {lubridate} functions. Make sense: this package relates to weather readings at certain time intervals.\nAnd another quick histogram of what the distribution looks like.\n\nhist(\n  fn_nondistinct_count$n,\n  breaks = 30,\n  main = \"Non-unique {lubridate} functions used by\\npackages importing {lubridate}\",\n  xlab = \"Function count\"\n)\n\n\nHuh, so the number of non-unique {lubridate} calls is almost always less than 50 per package. Seems in general that a small number of {lubridate} functions are called per dependent package, but they might be called a lot."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#you-do-you",
    "href": "posts/2021-11-27-lubridate-fns/index.html#you-do-you",
    "title": "{itdepends} on {lubridate}",
    "section": "You do you",
    "text": "You do you\nDoes the information here imply that many developers could consider removing their small number of {lubridate} calls in favour of date-related base functions? Maybe. Thatâ€™s up to the developers.\nUltimately, {itdepends} might be a useful tool for you to work out if you need all the dependencies you have. Other tools are out there; I read recently about Ashley Baldryâ€™s {depcheck} package, for example\nIt might be interesting to redo this investigation for all CRAN packages and their dependencies, but I donâ€™t have a personal CRAN mirror and I donâ€™t write particularly performant code.\nAnyway, donâ€™t listen to me: I write joke packages that I donâ€™t put on CRAN, lol."
  },
  {
    "objectID": "posts/2021-11-27-lubridate-fns/index.html#environment",
    "href": "posts/2021-11-27-lubridate-fns/index.html#environment",
    "title": "{itdepends} on {lubridate}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 20:42:28 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html",
    "href": "posts/2020-09-27-targets-dsfest/index.html",
    "title": "Hit your reproducibility {targets}",
    "section": "",
    "text": "An excuse to use the dam good (lol) beavers1 data (Nature on PBS via Giphy)"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#tldr",
    "href": "posts/2020-09-27-targets-dsfest/index.html#tldr",
    "title": "Hit your reproducibility {targets}",
    "section": "tl;dr",
    "text": "tl;dr\nI spoke at the UK Government Data Science Festival about Will Landauâ€™s R package {targets} for workflow reproducibility. You can jump to the embedded slides below."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#targets",
    "href": "posts/2020-09-27-targets-dsfest/index.html#targets",
    "title": "Hit your reproducibility {targets}",
    "section": "{targets}",
    "text": "{targets}\nReproducibility is an important part of any data analysis. Will people be able to re-run your code from scratch on a different machine without you present?\nR has lots of solutions for making your analysis reproducible, but one thing that gets overlooked is the reproducibility of the workflow itself. In other words, the interdependencies between functions, file and objects and the order in which they run.\n\n\n\nThe R package {targets} â€˜remembersâ€™ these relationships. In short, {targets} makes sure that only the impacted objects are re-run when you update your analysis. This means you donâ€™t have to recreate everything from scratch each time.\nA very basic overview of using {targets}:\n\nWrite a pipeline script\nInspect the pipeline (including visually)\nExecute the pipeline\nChange stuff\nGo to 2\n\nWith functions:\n\ntar_script() creates a _targets.R file, which is where you declare you write functions and options and create your targets with tar_targets(), declaring the pipeline with tar_pipeline()\ntar_manifest() lets you check the configuration of your targets\ntar_visnetwork visualises your pipeline as a graph network\ntar_make() executes your pipeline, which caches outputs and metadata in a _targets/ directory that can be read from with tar_read() and tar_load() (you could use )\ntar_outdated() prints any targets that need to be updated following any changes to other targets, after which you can reinspect your pipeline and re-make it\n\nIâ€™m not going to use this post to explain how to use the package in depth, but do check out the {targets} manual or the many other resources Iâ€™ve listed in the resources section below."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#slides",
    "href": "posts/2020-09-27-targets-dsfest/index.html#slides",
    "title": "Hit your reproducibility {targets}",
    "section": "Slides and code",
    "text": "Slides and code\nThe slides1 are embedded below. The presentation considers the need for workflow reproducibility followed by a small, contrived demo of the {targets} package in action: a short pipeline for rendering an R Markdown report with a plot and a table.2\n\n\n\n\n\n\n\n\nYou can also open the slides in a dedicated browser window. Press P for presenter notes, O for a slide overview and F for fullscreen.\nThe presentationâ€™s source is in a GitHub repo that also contains {targets}-related files and scripts for running the example seen in the slides. See the â€˜Demo codeâ€™ section of the README for details.\nIt wasnâ€™t possible in this talk to go into greater depth on other excellent {targets} features like parallel computing and branching, but you can read about them in the {targets} manual."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#but-drake",
    "href": "posts/2020-09-27-targets-dsfest/index.html#but-drake",
    "title": "Hit your reproducibility {targets}",
    "section": "Butâ€¦ {drake}?",
    "text": "Butâ€¦ {drake}?\nYou may have noticed I have cunningly plagiarised myself by re-using slides from a presentation to Bioinformatics London in January 2020.\n\nThat presentation was about {drake}, another workflow reproducibility package by Will Landau. I also wrote about the {drake} package as a tool for the Reproducible Analytical Pipelines (RAP) movement in UK government.\nSo whatâ€™s the difference between the two packages? In Willâ€™s own words:\n\nyears of community feedback [on {drake}] have exposed major user-side limitations regarding data management, collaboration, parallel efficiency, and pipeline archetypes\n\n{drake} is the more mature package and certainly it works, but {targets} is designed to address certain {drake} issues that only became apparent with ongoing, large-scale user testing in the wild. While {targets} addresses these problems, itâ€™s worth noting that itâ€™s still in development (v0.0.0.9002 at time of writing) and changes may be implemented that limit the usefulness of this post in future.\nOn the plus side, the {targets} packageâ€“along with the helper package {tarchetypes}, which I havenâ€™t had time to mention hereâ€“is going through a peer review with rOpenSci (as of October 2020), which will help perfect the package and give people even greater confidence in its suitability for everyday use.\nUltimately itâ€™s up to the user to decide which package theyâ€™d prefer to use for now, but {targets} looks to be the future for workflow reproducibility implemented within the R ecosystem."
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#resources",
    "href": "posts/2020-09-27-targets-dsfest/index.html#resources",
    "title": "Hit your reproducibility {targets}",
    "section": "Resources",
    "text": "Resources\nWill has put a lot of effort into making some top quality documentation for {targets}, along with some handy learning tools:\n\nthe user manual, which includes a walkthrough\nthe reference website, which includes the statement of need vignette\nA tutorial, which can be run in the cloud\ntargetsketch: a Shiny app for learning and visualising\na repo with a minimal example (more complex examples are available too)\nslides from the Los Angeles R Users Group Meetup (October 2020)"
  },
  {
    "objectID": "posts/2020-09-27-targets-dsfest/index.html#environment",
    "href": "posts/2020-09-27-targets-dsfest/index.html#environment",
    "title": "Hit your reproducibility {targets}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:15:29 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2   compiler_4.3.1      fastmap_1.1.1      \n [4] cli_3.6.1           tools_4.3.1         htmltools_0.5.5    \n [7] xaringanExtra_0.7.0 rstudioapi_0.15.0   yaml_2.3.7         \n[10] rmarkdown_2.23      knitr_1.43.1        jsonlite_1.8.7     \n[13] xfun_0.39           digest_0.6.33       rlang_1.1.1        \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#tldr",
    "href": "posts/2020-09-15-rstudio-settings/index.html#tldr",
    "title": "Rate my RStudio setup",
    "section": "tl;dr",
    "text": "tl;dr\nI share my (current!) RStudio setup and some features of the IDE I often use. Tell me about your setup."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#configuration-ideation",
    "href": "posts/2020-09-15-rstudio-settings/index.html#configuration-ideation",
    "title": "Rate my RStudio setup",
    "section": "Configuration IDEation",
    "text": "Configuration IDEation\nR has a decent community online. People love to share opinions about design, customisation and workflow efficiencies. Why is there little at the intersection?\nWhat I do see is people excited to hear about a checkbox or shortcut they never knew existed. I also hear from colleagues who are learning R and want to know more about customising their experience.\nSo, this post covers some elements of my personal RStudio setup and some bits and bobs about how I use some of the features.1 Itâ€™s utterly non-exhaustive, but may be useful for someone. I may add some things every now and again.\nClick a section header to jump:\n\nTheme\nFont\nLayout\nAddins\nOther GUI elements and settings\n\nDocument outline\nMagic wand\nKeyboard shortcuts\n.RData\nOdds and ends\n\n\n\n How to\nThese boxes appear throughout this post to tell you how to change your RStudio settings."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#theme",
    "href": "posts/2020-09-15-rstudio-settings/index.html#theme",
    "title": "Rate my RStudio setup",
    "section": "Theme",
    "text": "Theme\n\n\n\nSyntax highlighting in action with viridis.\n\n\nIâ€™m using the viridis theme by CÃ©dric Scherer. Itâ€™s based on the viridis colour palette by David Cooley, which is designed with colour blindness in mind.\n\n How to\nYou can change to an inbuilt theme at Tools &gt; Global options &gt; Appearance &gt; Editor theme. Add a new theme by clicking Addâ€¦ and provide a new .tmtheme or .rstheme from file. You can find and tweak examples using the online tmTheme Editor tool by Allen Bargi.\n\n\nIâ€™m red-green colourblind and the syntax highlighting of this theme lets me distinguish easily between the different code elements. I also like the de-emphasised look of the comments, which are italicised and less bright, making it easier to focus on the code.\n\n How to\nI also use syntax highlighting in the console. You can get this by checking the box at Tools &gt; Global Options &gt; Code &gt; Display &gt; Show syntax highlighting in console input.\n\n\nSometimes I switch to a light theme, like the default one, when writing text-rich blog posts. Syntax highlighting is less important for me in these instances and dark-on-light text can be easier to read."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#font",
    "href": "posts/2020-09-15-rstudio-settings/index.html#font",
    "title": "Rate my RStudio setup",
    "section": "Font",
    "text": "Font\nIâ€™m using FiraCode, an extension of the Fira typeface designed originally by Carrois Type Design. I installed this to my machine after downloading from Google Fonts).\n\n How to\nSet the font in RStudio at Tools &gt; Global Options &gt; Appearance &gt; Editor font.\n\n\nI find FiraCode easy to read for both coding and for writing prose. Itâ€™s monospaced, of course, but gets away with being a decent sans-serif for longer text blocks too.\n\n\n\nThe assignment arrow and â€˜not equal toâ€™ characters are smushed into ligatures.\n\n\nFiraCodeâ€™s main draw is its ligatures. This is when certain sets of adjacent characters are combined to appear as a single character. For example, the assignment operator gets condensed from &lt; and - to a single, unbroken arrow character. This helps me locate and parse expressions more easily, but ligatures are certainly a Marmite topic."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#layout",
    "href": "posts/2020-09-15-rstudio-settings/index.html#layout",
    "title": "Rate my RStudio setup",
    "section": "Layout",
    "text": "Layout\nI have the console pane on the right-hand side rather than the default of being on the left (see the image at the top of this post). I tend to want to maximise the script and console panes side-by-side so I can focus purely on inputs and outputs.\n\n How to\nYou can change this setting by clicking the Workspace Panes button (looks like a window) on the â€˜taskbarâ€™ at the top of the interface, to the left of the Addins menu. From there you can change the individual tabs of the panes too, by clicking Pane Layoutâ€¦.\n\n\nI donâ€™t see a lot people doing this, but I think this kind of view is favoured in IDEs like VSCode.\n\n\n\nAre you right-paned or left-paned?\n\n\nI also like to maximise the amount I can see on my screen by zooming out and reducing the font size.\n\n How to\nYou can set font size at Tools &gt; Global Options &gt; Appearance &gt; Editor font size and Zoom is in the same location."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#addins",
    "href": "posts/2020-09-15-rstudio-settings/index.html#addins",
    "title": "Rate my RStudio setup",
    "section": "Addins",
    "text": "Addins\n\n\n\nAddins: exactly what it says on the tin.\n\n\nRStudio has a system of â€˜addinsâ€™ that act as extensions for RStudio. They let you execute shortcuts and other commands via a dropdown menu in the GUI or a keyboard shortcut. Often these are functions that relate to the GUI in some way, like modifying selected text.\n\n How to\nAddins are delivered in R packages. You can access them from the Addins dropdown menu. Thereâ€™s no official catalogue, but see a list of addins in the readme for {addinslist} by Dean Attali, which can also be installed as an addin that adds-in addins, capiche?\n\n\nI have many, many addins, but want to point out a few I use often:\n\n{blogdown} by Yihui Xie has an addin with selections for new posts and serving the site, which I use frequently\n{remedy} by ThinkR has a bunch of useful Markdown-insertion functions, while my {blogsnip} package has a few functions for helping me write {blogdown} posts (e.g.Â inserting code for an accessible image)2\n{datapasta} by Miles McBain lets me add data copied from elsewhere into R, with a handy function for pasting in as a vector\n{annotater} by Luis Verde adds a comment next to your library() calls to indicate packagesâ€™ purposes and versions, which I find useful when writing ad hoc scripts in a team that includes people who arenâ€™t necessarily familiar with the packages being used\n\n\n How to\nYou can set keyboard shortcuts for addins with Tools &gt; Modify Keyboard Shortcutsâ€¦."
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#other-settings",
    "href": "posts/2020-09-15-rstudio-settings/index.html#other-settings",
    "title": "Rate my RStudio setup",
    "section": "Other GUI elements and settings",
    "text": "Other GUI elements and settings\n\nDocument outline\nRStudio has a feature that lets you use comments with multiple hyphens to signal breaks in your code, which make it easier to visually separate different sections. You can insert one of these section breaks with Shift + Cmd + R, which provides a prompt for you to name the section.\n\n\n\nNot one, but two ways of navigating between sections.\n\n\nThe names of the sections can then be accessed from:\n\nthe document outline panel, which can be accessed by clicking the stacked-lines button in the top-right of the script pane (Shift + Cmd + O)\nthe â€˜jump toâ€™ menu in the lower left of the script pane, which also has a little icon to show you what type of section your cursor is in (for example, itâ€™ll show an â€˜fâ€™ if youâ€™re in a function definition)\n\n\n\nMagic wand\n\n\n\nSleight-of-cursor.\n\n\nThe â€˜magic wandâ€™ menu is available in the script pane and has some features that act a bit like addins. Some frequently-used tools in there for me are:\n\nReflow comment to break a long, ragged comment across multiple lines so it fits into the conventional 80-character width limit (also Ctrl + Shift + /)\nInsert roxygen skeleton to insert a basic {roxygen2} function-documentation block above your function when your cursor is inside it (also Alt + Shift + Cmd + R)\nRename in scope, which selects all instances of the given object name that youâ€™ve highlighted in the script, which means you can then change them all at once without getting into the potential danger of a find-and-replace-all (also Alt + Shift + Cmd + M)\n\n\n\nKeyboard shortcuts\nRStudio has modifiable keyboard shortcuts. Thereâ€™s a number of default shortcuts that I use frequently:\n\n\n\n\n\n\n\nKeys\nAction\n\n\n\n\nCmd + M\nInsert a {magrittr} pipe (%&gt;%)\n\n\nCmd + -\nInsert an assignment arrow (&lt;-)\n\n\nCmd + Shift + Fn + F10\nRestart RStudio\n\n\nCmd + Shift + C\nComment out a selected block\n\n\nCmd + I\nAuto-indent a line\n\n\nCmd + Shift + R\nAdd a section label\n\n\nCmd + D\nDocument an in-development package\n\n\nCmd + L\nLoad an in-development package\n\n\n\nSome shortcuts require you to be an octopus to reach all the keys (Iâ€™m looking at you, shortcut-to-restart-RStudio), so modifying your frequently used shortcuts might be a good idea. Iâ€™ve got a keyboard with F13 to F15 keys that are otherwise going to waste and as of a recent update, these can be used as mappable RStudio keys.\n\n How to\nYou can see the keyboard shortcuts at Tools &gt; Keyboard Shortcuts Help and modify them in Tools &gt; Modify Keyboard Shortcutsâ€¦.\n\n\n\n\n.RData\nI like to restart RStudio every few minutes so I know that my environment is empty. This stops me from modifying objects and forgetting about it, which could result in erroneous output.\nThere are default settings that let RStudio open from where you left off, so that the contents of your environment are intact. I donâ€™t like this and itâ€™s advised against in places like the R for Data Science book by Wickham and Grolemund.\n\n How to\nYou can turn off this behaviour in Tools &gt; Global Options &gt; General &gt; Basic &gt; Workspace by unchecking Restore .Rdata on startup and setting Save workspace to .RData on exit to Never.\n\n\n\nOdds and ends\nRapid fire! I also like:\n\nthe 80-character-width guide to show me where to set a line break (Tools &gt; Code &gt; Display &gt; Show margin)\nto be able to scroll beyond the end of a script, so the last line can be seen further up the page (Tools &gt; Code &gt; Display &gt; Allow scroll past end of document)\nto see .Last.value in the environment pane so I can see the most recently created object (Tools &gt; Global options &gt; Advanced &gt; Show .Last.value in environment listing)\nto click the little RStudio cube-logo in the upper-right of the file pane to return to the working directory\nthe spellcheck function (see the â€˜ABC-and-tickâ€™ button at the top of the scripting window)\nusing multiple cursors by holding Alt and dragging down, which makes insertion and deletion across multiple lines much easier\n\nYou can learn more tips and tricks from:\n\nthe RStudio cheatsheet\nRStudio tips on Twitter\na recent post by Antoine Soetewey\nthis dataquest post"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#it-never-ends",
    "href": "posts/2020-09-15-rstudio-settings/index.html#it-never-ends",
    "title": "Rate my RStudio setup",
    "section": "It never ends",
    "text": "It never ends\nThemes and fonts can always be tweaked. Youâ€™ll get bored of them at some point, or something better will come along. RStudioâ€™s customisability and ongoing development also means thatâ€™s a constant stream of new addins and discovered tricks.\nI donâ€™t really make use of snippets and I havenâ€™t really mapped any new keyboard shortcuts. I want to look into Garrick Aden-Buieâ€™s {shrtcuts} package (blog, package site) in particular.\nI tend to use the terminal window for everything Git-based and I know very little of the Git GUI built into RStudio. Iâ€™m comfortable with that, but many Iâ€™d like to learn a bit more so I can help colleagues transition more easily into using version control.\nLet me know about your themes, fonts, layouts, settings and tips and tricks for RStudio or whatever other IDE you use.\nSee back here when weâ€™ve all switched to another IDE and made this post redundant.3"
  },
  {
    "objectID": "posts/2020-09-15-rstudio-settings/index.html#environment",
    "href": "posts/2020-09-15-rstudio-settings/index.html#environment",
    "title": "Rate my RStudio setup",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 21:38:19 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#tldr",
    "href": "posts/2023-07-15-hiscore/index.html#tldr",
    "title": "Save high scores for your R game",
    "section": "tl;dr",
    "text": "tl;dr\nYou can save your high score in games made with R. See the package {hiscore} for a demo."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#boot-up",
    "href": "posts/2023-07-15-hiscore/index.html#boot-up",
    "title": "Save high scores for your R game",
    "section": "Boot up",
    "text": "Boot up\nI wrote recently about how R is a game engine and started a list of games written in R.\nAll good game engines should let you save a high score, right?\nSo Iâ€™ve done exactly this for a tiny concept package called {hiscore}1 that contains a simple game of luck\nThe package runs code that saves your high score, which is retained between play sessions."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#install",
    "href": "posts/2023-07-15-hiscore/index.html#install",
    "title": "Save high scores for your R game",
    "section": "Install",
    "text": "Install\nYou can install the package from GitHub. It has no dependencies, but youâ€™ll need to be running R version 4, at least.\n\ninstall.package(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/hiscore\")\nlibrary(hiscore)\n\nOf course, itâ€™s just a concept and Iâ€™ve intentionally kept this as trivial as possible, but you can leave an issue with bugs or ideas."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#play",
    "href": "posts/2023-07-15-hiscore/index.html#play",
    "title": "Save high scores for your R game",
    "section": "Play",
    "text": "Play\nFor demonstration purposes, the inbuilt game is super simple: get the longest streak of correctly guessed coinflips.\nTo play, run play_coinflip() and type H or T and Enter when prompted. Basically, a coinflip is simulated with sample(c(\"H\", \"T\"), 1) and then compared to the userâ€™s input, supplied from the console following a readline() call.\nKeep going until you get it wrong. If you get a new high score, itâ€™ll be saved.\n\nplay_coinflip()\n\n[H]eads or [T]ails? Answer: H\nCorrect! Current score: 1\n[H]eads or [T]ails? Answer: H\nIncorrect! Final score: 1\nNew high score!\nNew high score saved.\nYou can retrieve the current high score with get_save_data(), which returns a little table.\n\nget_save_data()\n\n      game high_score\n1 coinflip          1\nOf course, you could also set up the function so that it records different player names too. And you could add additional games that would get their own row in this table."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#memory",
    "href": "posts/2023-07-15-hiscore/index.html#memory",
    "title": "Save high scores for your R game",
    "section": "Memory",
    "text": "Memory\nNote that the high score data is retained on your computer even if you restart your session or reboot your machine. How so?\nThis is thanks to the tools::R_user_dir() function, which was added to R in version 4.0. It builds system-specific paths to â€˜directories for storing R-related user-specific data, configuration and cache filesâ€™ where you can save package-related information.\n{hiscore} records top scores in this fashion. On my machine, the save location resolves to the following:\n\ntools::R_user_dir(\"hiscore\", \"data\")\n\n[1] \"/Users/mattdray/Library/Application Support/org.R-project.R/R/hiscore\"\n\n\nRegular readers may remember that I used R_user_dir() in the {tamRgo} package (blog, source), which lets you look after a Tamagotchi-style cyber-pet in your console. I used the function to save a petâ€™s â€˜blueprintâ€™ (details such as name, age and hunger level) persistently."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#retry",
    "href": "posts/2023-07-15-hiscore/index.html#retry",
    "title": "Save high scores for your R game",
    "section": "Retry",
    "text": "Retry\nNow imagine you want to retry to beat that incredible top score of 1. Since you last played, you probably restarted your session or computer.\nRestarting R session...\nBut never fear: the high score was retained. You can see that when you run play_coinflip() again and are reminded of the current best.\n\nlibrary(hiscore)\nplay_coinflip()\n\nWelcome. Your current high score is 1\n[H]eads or [T]ails? Answer: h\nCorrect! Current score: 1\n[H]eads or [T]ails? Answer: t\nCorrect! Current score: 2\n[H]eads or [T]ails? Answer: h\nIncorrect! Final score: 2\nNew high score!\nNew high score saved.\nGreat job, you doubled the previous record!\nWhen you get a game over, the play_coinflip() function checks the current high score and compares it to the final score for the current play session. The saved data is overwritten if the score is higher.\n\nget_save_data()\n\n      game high_score\n1 coinflip          2\nI think itâ€™s a good idea to make it easy for people to destroy the stored data if they want, which you can do easily with delete_save_data().\n\ndelete_save_data()\n\nReally delete? [Y]es/[N]o: Y\nHigh score data deleted."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#game-over",
    "href": "posts/2023-07-15-hiscore/index.html#game-over",
    "title": "Save high scores for your R game",
    "section": "Game over",
    "text": "Game over\nHow else could this approach be used in an R gaming perspective? You could use this to save a game state, similar to whatâ€™s done for {tamRgo}. The user could input Save instead of performing a guess, which would record the current status of the game so the user can return later. But that would feel like cheating for a game like coinflip.\nSpeaking of, hereâ€™s a cheatcode as a bonus for reading this far:\n\ncheat &lt;- function(game, score) {\n  user_dir &lt;- tools::R_user_dir(\"hiscore\", \"data\")\n  score_path &lt;- file.path(user_dir, \"score_table.rds\")\n  score_table &lt;- readRDS(score_path)\n  score_game &lt;- score_table[score_table[[\"game\"]] == game, ]\n  score_game[[\"high_score\"]] &lt;- score\n  saveRDS(score_table, score_path)\n  message(\"Congrats! You scored \", score, \" at \", game, \"!\")\n}\n\ncheat(\"coinflip\", 1e100)\n\nCongrats! You scored 1e+100 at coinflip!\nHeh heh heh."
  },
  {
    "objectID": "posts/2023-07-15-hiscore/index.html#environment",
    "href": "posts/2023-07-15-hiscore/index.html#environment",
    "title": "Save high scores for your R game",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-16 11:02:06 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] hiscore_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#tldr",
    "href": "posts/2021-11-07-deepfry/index.html#tldr",
    "title": "Deep fried memes in R",
    "section": "tl;dr",
    "text": "tl;dr\nNow you can use a function to deep fry memes in R."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#extra-crispy",
    "href": "posts/2021-11-07-deepfry/index.html#extra-crispy",
    "title": "Deep fried memes in R",
    "section": "Extra crispy",
    "text": "Extra crispy\nYou can make memes in R with packages like Guangchang Yuâ€™s {meme}. You could even post them to Twitter with #RStatsMemes for @rstatsmemes to find.\nHowever, itâ€™s no longer enough to present memes as-is. They must be deep-fried to become modern and ironic. It will help people think that your meme is so edgy that itâ€™s been re-saved thousands of times."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#get-to-temperature",
    "href": "posts/2021-11-07-deepfry/index.html#get-to-temperature",
    "title": "Deep fried memes in R",
    "section": "Get to temperature",
    "text": "Get to temperature\nYouâ€™ll need image-manipulation wizardry from the {magick} package, along with {extrafont} to let you use fonts from your system.\nAt time of writing there is an issue with importing fonts, which requires an earlier version of {Rttf2pt1} to be installed.\n\ninstall.packages(c(\"magick\", \"extrafont\", \"remotes\"))\nremotes::install_version(\"Rttf2pt1\", version = \"1.3.8\")\n\nYou can then import fonts from your system.\n\nextrafont::font_import()\n\nImporting fonts may take a few minutes, depending on the number of fonts and the speed of the system.\nContinue? [y/n] \nNow we can use important joke fontsâ€”like Impact, Papyrus or Calibriâ€”in our memes, assuming theyâ€™re installed on your system."
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#small-fry",
    "href": "posts/2021-11-07-deepfry/index.html#small-fry",
    "title": "Deep fried memes in R",
    "section": "Small fry",
    "text": "Small fry\nIâ€™ve cooked up a single, low-quality function, fry(), that:\n\nReads a meme template image (or any image) from a path\nAdds top/bottom text in Impact font\nReads from a URL a specific (cursed) cry/laugh emoji thatâ€™s popular in deep-frying and places it in a random location (corners or left/right sides)\nAdjusts the image contrast, saturation, etc,1, tints it orange and bulges it from the centre\nWrites the image to a temporary jpeg fileâ€”compressing it horriblyâ€”and then reads it back in\nOutputs a magick-image object that you can save with magick::image_write() and send to all your friend (sic)\n\nIt does what I want it to do; adjust it as you please.\n\nsuppressPackageStartupMessages(library(magick))\n\nfry &lt;- function(\n  img_path, emoji_path,\n  text_top, text_bottom,\n  depth = c(\"shallow\", \"deep\")) {\n  \n  depth &lt;- match.arg(depth)\n  \n  cat(\"Heating oil... \")\n  \n  emoji &lt;- magick::image_read(emoji_path)\n  \n  emoji_where &lt;-  sample(c(  \n    paste0(\"north\", c(\"east\", \"west\")),\n    paste0(\"south\", c(\"east\", \"west\")),\n    \"east\", \"west\"  # e.g. 'east' is right\n  ), 1)\n  \n  img &lt;- image_read(img_path) |&gt; \n    image_annotate(\n      text_top, \"north\", size = 80, font = \"Impact\",\n      color = \"white\", strokecolor = \"black\"\n    ) |&gt;\n    image_annotate(\n      text_bottom, \"south\", size = 80, font = \"Impact\",\n      color = \"white\", strokecolor = \"black\"\n    ) |&gt;\n    image_scale(\"1000\") |&gt; \n    image_composite(emoji, gravity = emoji_where) |&gt; \n    image_colorize(30, \"orange\") |&gt;  # tint\n    image_modulate(brightness = 80, saturation = 120, hue = 90) |&gt;\n    image_contrast(sharpen = 100) |&gt; \n    image_noise()\n  \n  cat(\"dunking meme... \")\n  \n  if (depth == \"shallow\") {\n    img &lt;- img %&gt;% image_implode(-0.5)  # bulge\n    compress &lt;- 8\n  } else if (depth == \"deep\") {\n    img &lt;- img %&gt;% image_implode(-1)  # more bulge\n    compress &lt;- 1  # maximum compression\n  } \n  \n  path_out &lt;- tempfile(\"meme\", fileext = \".jpeg\")\n  image_write(img, path_out, \"jpeg\", compress)\n  \n  cat(\"crisp.\")\n  image_read(path_out)\n  \n}"
  },
  {
    "objectID": "posts/2021-11-07-deepfry/index.html#get-cooking",
    "href": "posts/2021-11-07-deepfry/index.html#get-cooking",
    "title": "Deep fried memes in R",
    "section": "Get cooking",
    "text": "Get cooking\nWhat spicy meme shall I make? Well, the = versus &lt;- assignment-operator flamewar has been cold for a few days, so time to heat it up again.2 And why not incorporate the worldâ€™s most famous fry cook (in sarcastic form)?\n\nsponge_path &lt;- paste0(  # URL to meme image\n  \"https://raw.githubusercontent.com/matt-dray/rostrum-blog/\",\n  \"master/static/post/2021-11-07-deepfry_files/spongebob.jpg\"\n)\n\nemoji_path &lt;- paste0(  # URL to cry/laugh emoji\n  \"https://raw.githubusercontent.com/matt-dray/rostrum-blog/\",\n  \"master/static/post/2021-11-07-deepfry_files/deepfry-emoji.jpg\"\n)\n\nbot_txt &lt;- \"= sAvEs KeYsTrOkEs Vs &lt;-\"  # sarcastic text\ntop_txt &lt;- tolower(bot_txt)\n\nFirst, a nice shallow fry.\n\nfry(sponge_path, emoji_path, top_txt, bot_txt, \"shallow\")\n\nHeating oil... dunking meme... crisp.\n\n\n\n\n\nAnd now we deep fry.\n\nfry(sponge_path, emoji_path, top_txt, bot_txt, \"deep\")\n\nHeating oil... dunking meme... crisp.\n\n\n\n\n\n*Fry-cookâ€™s kiss*"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html",
    "href": "posts/2020-12-30-coloratio/index.html",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "",
    "text": "This blogâ€™s original theme: insufficient contrast!"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#tldr",
    "href": "posts/2020-12-30-coloratio/index.html#tldr",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "tl;dr",
    "text": "tl;dr\nI made a small R package called {coloratio} to evaluate colour-contrast ratios for accessibility. Then I found out that {savonliquide} already exists to do this."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#accessible-charts",
    "href": "posts/2020-12-30-coloratio/index.html#accessible-charts",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Accessible charts",
    "text": "Accessible charts\nThe UK governmentâ€™s website, GOV.UK, was developed with user needs and accessibility in mind. Iâ€™ve been using {ggplot2} to recreate the simple, accessible chart styles suggested for use on GOV.UK by the Government Statistical Service.\nBut I wondered: is it possible to programmatically select a high-contrast text colour to overlay the fill colours of a {ggplot2} barplot? You would want black text over white and vice versa, for example.\nWhat is â€˜high contrastâ€™ anyway? GOV.UKâ€™s Design System refers to W3Câ€™s contrast guidance from WCAG 2.1, which suggests a ratio of 4.5:1 for regular text on a block-coloured background.\nIt isnâ€™t a big deal to program this â€˜manuallyâ€™, but thatâ€™s not fun."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#ratio-calculation",
    "href": "posts/2020-12-30-coloratio/index.html#ratio-calculation",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Ratio calculation",
    "text": "Ratio calculation\n\nIs the contrast accessible?\nHow about a small package with some functions to derive colour contrast ratios? Introducing {coloratio}.\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/coloratio\")\n\nPass two colours to cr_get_ratio() as hex values or named coloursâ€”see colors()â€”and it performs the necessary calculations to derive relative luminance and return a colour contrast ratio.\n\nlibrary(coloratio)  # attach package\n\ncr_get_ratio(\n  \"papayawhip\", \"#000000\",  # colours to compare\n  view = TRUE  # optional demo of colours \n)\n\n\n\n\n[1] 18.55942\n\n\nThis contrast value is above the 4.5 threshold, so weâ€™re good to go. Youâ€™ll get a warning if the contrast is insufficient.\n\ncr_get_ratio(\"olivedrab\", \"olivedrab2\")\n\nWarning in cr_get_ratio(\"olivedrab\", \"olivedrab2\"): Aim for a value of 4.5 or higher.\n\n\n[1] 2.755693\n\n\nSurprise: as stunning as an all-olivedrab palette might be, these colours arenâ€™t distinct enough to be accessible.\n\n\nBlack or white?\ncr_get_ratio() in turn powers the function cr_choose_bw(), which returns black or white depending on the greatest contrast with a supplied background colour.\n\ncr_choose_bw(\"snow\")\n\n[1] \"black\"\n\ncr_choose_bw(\"saddlebrown\")\n\n[1] \"white\"\n\n\nTo demonstrate better, letâ€™s create a grouped barplot with lighter (lemonchiffon3) and darker (hotpink4) fill colours, then use cr_choose_bw() to choose black or white for the overlaying text.\n\nlibrary(tidyverse)  # for data manipulation\n\n# Example data\nd &lt;- data.frame(\n  x_val = c(\"A\", \"A\", \"B\", \"B\"),\n  y_val = c(3, 6, 4, 10),\n  z_val = c(\"a\", \"b\", \"a\", \"b\")\n) %&gt;% \n  mutate(  # add colour columns\n    fill_col = rep(c(\"hotpink4\", \"lemonchiffon3\"), 2),\n    text_col = map_chr(fill_col, cr_choose_bw)\n  )\n\nd  # preview\n\n  x_val y_val z_val      fill_col text_col\n1     A     3     a      hotpink4    white\n2     A     6     b lemonchiffon3    black\n3     B     4     a      hotpink4    white\n4     B    10     b lemonchiffon3    black\n\n\nNo surprise: white was returned for the darker fill and black for the lighter fill.\nWe can now refer to this information in the colour argument of geom_text().\n\nggplot(d, aes(x_val, y_val, fill = z_val)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_manual(values = d$fill_col) +    # fill colour\n  geom_text(aes(y = 0.5, label = y_val), \n            position = position_dodge(0.9), \n            size = 5, colour = d$text_col) +  # text colour \n  coord_flip() + \n  theme_minimal(base_size = 16) +  # clean up the theme\n  theme(axis.text.x = element_blank(), axis.title = element_blank(), \n        legend.title = element_blank(), panel.grid = element_blank())\n\n\n\n\nAs desired: black on the lighter fill; white on the darker fill. The default would be black text, which would provide insufficient contrast for darker fills.\n\n\nAside: cr_choose_bw() in geom_text()?\nOriginally I wanted geom_text() to choose text colours on the fly, rather than adding them to the input data. This roundabout solutionâ€”which outputs a similar plot to the one aboveâ€”requires you to build the plot object, then interrogate it with ggplot_build() to identify the bar-fill colours.\n\n# Build simple grouped barplot again\np &lt;- ggplot(d, aes(x_val, y_val, fill = z_val)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_manual(values = c(\"hotpink4\", \"lemonchiffon3\")) +\n  coord_flip()\n\n# Extract the p-object fills and choose text overlay colour\np + geom_text(\n  aes(y = 0.5, label = y_val), position = position_dodge(0.9), size = 5,\n  colour = map_chr(  # make text colour dependent on bar colour\n    ggplot_build(p)[[1]][[1]]$fill,  # access p-object fills\n    coloratio::cr_choose_bw   # choose black/white text based on fill\n  )\n)\n\nI put this to the RStudio Community with no answer to date. Let me know if you have any ideas."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#a-soapy-slip-up",
    "href": "posts/2020-12-30-coloratio/index.html#a-soapy-slip-up",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "A soapy slip-up",
    "text": "A soapy slip-up\nHaving addressed my need, I was suspicious. Surely this has been done in R before?\nWhoops. {savonliquide} by Ihaddaden M. EL Fodil can query the WebAIM contrast checker API to get the contrast ratio for two colours. And itâ€™s on CRAN.\n\ninstall.packages(\"savonliquide\")\n\nMaybe I missed it because of the name, which translates to â€˜liquid soapâ€™?\nAnyway, like coloratio::cr_get_ratio(), you can pass two hex values or named colours to {savonliquide}â€™s check_contrast() function.\n\nsavonliquide::check_contrast(\"blanchedalmond\", \"bisque2\")\n\n\n* The Contrast Ratio is 1.04\n\n* The result for the AA check is : FAIL\n\n* The result for the AALarge check is : FAIL\n\n* The result for the AAA check is : FAIL\n\n* The result for the AAALarge check is : FAIL\n\n\nThe output is richer than coloratio::cr_get_ratio(). You can see here that the supplied colours fail additional accessibility checks from WCAG 2.1 that involve large text and more stringent contrast thresholds.\nHandily, thereâ€™s also the savonliquide::check_contrast_raw() variant that returns a list with each result as an element."
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#acceptance",
    "href": "posts/2020-12-30-coloratio/index.html#acceptance",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Acceptance",
    "text": "Acceptance\nSoâ€¦ should you wash your hands of {coloratio}?1 Well, it fills the micro-niche of an R package that doesnâ€™t require an internet connection to fetch colour contrast ratios. But itâ€™s probably never going to go on CRAN, so you should use {savonliquide}.\nI certainly learnt a lesson about due diligence during package development. Especially because I also discovered recently that I had also somehow managed to reinvent the {badger} package with my own {badgr} package.2 Whoops again.\nAt worst, I got to learn more about accessibility, practice some package building, and solve my initial problem (kinda).\nI also got to admire the creativity of the names in the named-colour set. â€˜Papayawhipâ€™ sounds really appealing. Or perhaps painful. Just like package development.3"
  },
  {
    "objectID": "posts/2020-12-30-coloratio/index.html#environment",
    "href": "posts/2020-12-30-coloratio/index.html#environment",
    "title": "Accessible colour contrasts with {coloratio}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 17:58:44 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.2      forcats_1.0.0        stringr_1.5.0       \n [4] dplyr_1.1.2          purrr_1.0.1          readr_2.1.4         \n [7] tidyr_1.3.0          tibble_3.2.1         ggplot2_3.4.2       \n[10] tidyverse_2.0.0      coloratio_0.0.0.9004\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.3       jsonlite_1.8.7     crayon_1.5.2       compiler_4.3.1    \n [5] tidyselect_1.2.0   scales_1.2.1       yaml_2.3.7         fastmap_1.1.1     \n [9] R6_2.5.1           labeling_0.4.2     generics_0.1.3     curl_5.0.1        \n[13] knitr_1.43.1       htmlwidgets_1.6.2  munsell_0.5.0      pillar_1.9.0      \n[17] tzdb_0.4.0         rlang_1.1.1        utf8_1.2.3         savonliquide_0.2.0\n[21] stringi_1.7.12     xfun_0.39          timechange_0.2.0   cli_3.6.1         \n[25] withr_2.5.0        magrittr_2.0.3     digest_0.6.31      grid_4.3.1        \n[29] rstudioapi_0.15.0  hms_1.1.3          lifecycle_1.0.3    vctrs_0.6.3       \n[33] evaluate_0.21      glue_1.6.2         farver_2.1.1       fansi_1.0.4       \n[37] colorspace_2.1-0   httr_1.4.6         rmarkdown_2.23     tools_4.3.1       \n[41] pkgconfig_2.0.3    htmltools_0.5.5"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#tldr",
    "href": "posts/2023-01-08-petrov/index.html#tldr",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "tl;dr",
    "text": "tl;dr\nIn which I prove wrong a tweeted Opta football statistic, using R and Transfermarkt data. Oh wait, actually Opta were right. Ah, heck."
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#petrov-rescue",
    "href": "posts/2023-01-08-petrov/index.html#petrov-rescue",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Petrov Rescue",
    "text": "Petrov Rescue\nBasically, for little reason, I dislike the style of the tweets on the Twitter feed for Opta1 (the company who do all the football stats).\nWhat is so outrageous? Each tweet always ends in a single, summary word that makes me cringe.\nWait, what? Letâ€™s take a look at their most recent tweet at time of writing:\n\n14 - Harry Kane has scored 14 goals in his last 14 appearances in the FA Cup, averaging a goal every 63 minutes in the competition in this period. Guarantee.\n\nâ€˜Guaranteeâ€™. Gah.\nOr this tweet:\n\n16 - Since his first appearance in the competition in January 2016, Leicesterâ€™s Kelechi Iheanacho has scored more FA Cup goals than any other player (16). Specialist.\n\nâ€˜Specialistâ€™. Sigh.\nA completely small and pointless thing to be annoyed by, right?\nBut hereâ€™s the scenario. Over the yuletide period (on Christmas day!) they ran this tweet:\n\n1 - Stiliyan Petrov (@StanPetrov19) is the only player to have played in the Premier League whose name contains all the letters in the word â€˜Nativityâ€™. Star.\n\nObviously, I have absolutely nothing against â€˜Big Stanâ€™. Heâ€™s a legend; a â€˜starâ€™, if you will. Captain of Aston Villa! Bulgaria! Battled leukaemia and still made it to nearly 600 games. One of the best Bulgarian/Premier League â€˜Petrovsâ€™, along with cult legend Martin.\nBut could this stat possibly be true? Surely thereâ€™s at least one other player. Perhaps a window of opportunity for me to avenge my feelings of cringe?\nOh, and obviously you can ignore the candid dismissals in the tweetâ€™s replies, for example:\n\nWhat are we supposed to do with this information? [Picture of wryly-smiling duck.]\n\nNo, this is more important than any Opta tweet ever: what if itâ€™sâ€¦ wrong?"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#stan-in-r-but-not-rstan",
    "href": "posts/2023-01-08-petrov/index.html#stan-in-r-but-not-rstan",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Stan in R, but not {rstan}",
    "text": "Stan in R, but not {rstan}\nSo I looked into it using R, of course.\nTurns out itâ€™s pretty straightforward with the excellent {worldfootballR} package by Jason Zivkovic, which helps fetch player data from Transfermarkt (among other suppliers).\nBasically, we can fetch data about footballers from every team in a given leagueâ€™s season since its inception. So, aha, you cannot escape, Opta!\nMy little {soccercolleagues} package that I wrote about in early 2022 is built heavily (heavily!) around {worldfootballR} and has a convenience function we can use.\nThe niche2 primary objective of {soccercolleagues} is to let you find pairs of football players that were colleagues at some point. Like: â€˜which current Premier League footballer has been team mates with each of the following: Kevin Phillips, Mark Viduka, Dejan Lovren, Danny Ings and Nicky Butt?â€™3\nFollow along. As ever, you can install the {soccercolleagues} package from GitHub:\n\nif(!require(remotes)) install.packages(\"remotes\")\nremotes::install_github(\"matt-dray/soccercolleagues\")\n\nWeâ€™ll also use the {tidyverse} for wrangling.\n\nlibrary(soccercolleagues)\nlibrary(tidyverse)\n\nSo we can ask Transfermarkt for all the years of the English Premier League, which began in 1992:\n\n# This will take quite a long time...\nepl_players &lt;- soccercolleagues::get_players(\n  seasons = 1992:2022,\n  country = \"England\"\n)\n\nAnd now we can look for the players whose names contain the letters in â€˜nativityâ€™:\n\nepl_players |&gt;\n  distinct(player_name) |&gt;\n  mutate(\n    player_name = str_remove_all(tolower(player_name), \" \"),\n    n_count = str_count(player_name, \"n\"),\n    a_count = str_count(player_name, \"a\"),\n    t_count = str_count(player_name, \"t\"),\n    i_count = str_count(player_name, \"i\"),\n    v_count = str_count(player_name, \"v\"),\n    y_count = str_count(player_name, \"y\")\n  ) |&gt;\n  filter(\n    n_count &gt;= 1 &\n      a_count &gt;= 1 &\n      t_count &gt;= 2 &\n      i_count &gt;= 2 &\n      v_count &gt;= 1 &\n      y_count &gt;= 1\n  )\n\n# A tibble: 1 Ã— 7\n  player_name    n_count a_count t_count i_count v_count y_count\n  &lt;chr&gt;            &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n1 stiliyanpetrov       1       1       2       2       1       1\nOofâ€¦ they were right. He is the only one.\nWow, this humble pie is so delicious, thank you so much Opta for unintentionally spoonfeeding it to me.\nTo be clear: Optaâ€™s data analysts have a good track record, as far as I know. But Iâ€™ve got my eye on you! Youâ€™ll slip up one day!\nâ€¦But wait. Opta were misnaming Stan as â€˜Stylian Petrovâ€™ in tweets as late as 2012. Get rekt! You missed the extra â€˜iâ€™ you need in â€˜nativityâ€™, fools! Put respect on Stiliyanâ€™s name!\nâ€˜Resultâ€™.4"
  },
  {
    "objectID": "posts/2023-01-08-petrov/index.html#environment",
    "href": "posts/2023-01-08-petrov/index.html#environment",
    "title": "Stiliyan Petrov: Jesus?",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:34 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#lewitt-remix",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#lewitt-remix",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "LeWitt ReMix",
    "text": "LeWitt ReMix\nThe third #RecreationThursday challenge involved Sol LeWittâ€™s Colour Bands (2000), which you can see on this prints catalogue. In short, each piece is square and contains patterns of colourful concentric lines that are arranged into panels of varying shapes with black borders.\nRather than recreate his artworks exactly, I decided to riff on the approach with a (very basic) Shiny app, which adds different types of lines and some randomisation.\nYou can access it by clicking this button (until I take it down1): \nAlternatively, download and launch it locally via an R session:\n\nshiny::runGitHub(\n  \"viz-recreation\", \"matt-dray\", \"main\",\n  \"2021-07-01_rt_lewitt/lewitt-remix-app\"\n)\n\nOr you can go to the appâ€™s source on GitHub.\nIn the app, you can change a few parameters and then hit the â€˜Generateâ€™ button for a new variant, which can be downloaded to your computer. Iâ€™ve limited the inputs so that you get relatively â€˜sensibleâ€™ outputs (whatever that means).\nYou could create something that looks similar to LeWittâ€™s original, or go off-piste and create a much larger number of panels or much thicker lines. Have fun!\nRead on for an explanation and for some examples."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#approach",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#approach",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Approach",
    "text": "Approach\nOnce again, Iâ€™ve used only base R functions to generate the outputs, just like my previous #RecreationThursday attempt. I have nothing against other tools, I just donâ€™t care much for dependencies.\n\nThe trick\nIâ€™ve used a cunning shortcut to mimic LeWitt: rather than draw any lines or shapes, Iâ€™ve just over-plotted points of decreasing size and variable colour with Râ€™s built-in plotting characters. For example, 21 is a filled circle, 22 a square and so on. Hereâ€™s the shapes I used:\n\n\n\n\n\nWhen several of these plotting points are stacked on the same origin, it gives the effect of concentric lines. Hereâ€™s an example of plotting 50 unfilled circles of decreasing size on the same point:\n\n# Set variables\nshape &lt;- 21  # plotting character\nshp_n &lt;- 50  # number of points to plot\nshp_x &lt;- 2   # point size multiplier ('thickness')\npal   &lt;- rainbow(5)  # colours\n\n# Set margins to zero, see only the plot\npar(mar = rep(0, 4))\n\n# Plot concentric circles\nplot(\n  x    = rep(0, shp_n),\n  y    = rep(0, shp_n),\n  axes = FALSE,\n  pch  = shape,\n  cex  = shp_x * shp_n:1,\n  col  = pal\n)\n\n\n\n\nIf these circles are filled from largest to smallest, it will give the impression that lines have been created, when really it is a stack of points. Iâ€™ve added in a â€˜multiplierâ€™ variable that increases the gap from the edge of one point to the edge of the next smallest. The larger that variable, the large the gap, which in the output makes it look like the â€˜linesâ€™ are thicker.\n\n\nFunctions\nThere are two custom functions in the app: one function uses this point-stacking principle to generate a single-panel LeWitt remix and the other function calls multiple of these panels into a square grid.2\nThe arguments include the plotting character (circle, diamond, etc), the origin position that the centre of the point-stack will take (named for cardinal directions, like NE to place the origin in the top-right), the colours, the number of shapes to overplot (you want enough to completely cover the plot surface), the apparent â€˜thicknessâ€™ of the â€˜linesâ€™ in the output, and the width of the box3 that surrounds the image.\n\n\nFunction demos\nSo hereâ€™s a demo of the function4 that generates a single panel. It uses uses the triangle plotting characters, which originate in the centre and alternate through rainbow colours. This is not too dissimilar from LeWittâ€™s originals.\n\n# Grab the functions from the repo\nsource(\"https://raw.githubusercontent.com/matt-dray/viz-recreation/main/2021-07-01_rt_lewitt/lewitt-remix-app/global.R\")\n\n# Demo: plot a single panel\njust_lewitt(\n  shape = 24,          # triangle plotting character\n  place = \"C\",         # 'centre'\n  pal   = rainbow(7),  # colours\n  shp_n = 200,         # number of points to plot\n  shp_x = 4,           # 'line thickness'\n  box_w = 20           # outer box thickness\n)\n\n\n\n\nAnd below is a panel made of four calls to the single-panel function. Elements like shape and the placement of the origin point are randomised.\nAlso, rather than use LeWittâ€™s colouring scheme, I decided to randomise the colour palette by sampling seven colours from Râ€™s built-in named colours(). This can produce some pretty garish results, but also some quite pleasing ones too. (Iâ€™m colourblind, so your mileage may vary.)\n\n# Set a seed for reproducibility\nset.seed(5)\n\n# Set up a colour palette\nmy_pal &lt;- sample(colours(), 7)\n\n# Demo: plot a grid of randomised panels\njust_lewitt2(\n  dimn  = 2,       # x and y dimensions of grid\n  pal   = my_pal,  # colour palette\n  shp_x = 4,       # 'line thickness'\n  box_w = 10       # outer box thickness\n)\n\n\n\n\nThis can end up looking like an eye-popping Magic Eye puzzle.\n\nset.seed(7)\njust_lewitt2(\n  dimn  = 10,\n  pal   = sample(colours(), 7),\n  shp_x = 1,\n  box_w = 0\n)\n\n\n\n\nOr a bit like semaphore.\n\nset.seed(7)\njust_lewitt2(\n  dimn  = 2,\n  pal   = sample(colours(), 7),\n  shp_x = 20,\n  box_w = 0\n)\n\n\n\n\nOr whatever this is.\n\nset.seed(2)\njust_lewitt2(\n  dimn  = 10,\n  pal   = sample(colours(), 7),\n  shp_x = 1,\n  box_w = 20\n)\n\n\n\n\nUh-oh, I think I may have slipped through space-time.\n\nset.seed(11)\njust_lewitt2(\n  dimn  = 2,\n  pal   = sample(colours(), 7),\n  shp_x = 0.4,\n  box_w = 0\n)\n\n\n\n\nThe Shiny app basically fills these function arguments with your inputs, providing some randomness with a new seed thatâ€™s generated with each click of the â€˜Generateâ€™ button or if you move any of the sliders.\nYou can control the number of panels in the grid, the â€˜thicknessâ€™ of the lines (which, remember, is just the relative gap between the overlapping plot points) and the thickness of the border (I could have made this value respond to other inputs, but I particularly like ignoring â€˜balanceâ€™ and choosing extremely thick borders, or none at all).5\nI would love it if you tried out the app, used the â€˜Downloadâ€™ button to save a PNG copy6, and then showed me on Twitter."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#get-involved",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#get-involved",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Get involved",
    "text": "Get involved\nCheck out #RecreationThursday on Twitter. Itâ€™s a community challenge to recreate an art piece selected each fortnight by a rotating curator.\nThe timetable, art pieces, curators and example alt-text are available in Sharla Gelfandâ€™s RecreationThursday repo on GitHub."
  },
  {
    "objectID": "posts/2021-07-05-recreate-lewitt/index.html#environment",
    "href": "posts/2021-07-05-recreate-lewitt/index.html#environment",
    "title": "#RecreationThursday: a LeWitt Shiny app",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "",
    "text": "Closest Iâ€™ve been to Leicester Square since the start of lockdown."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#tldr",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#tldr",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "tl;dr",
    "text": "tl;dr\nI recently made a Twitter bot with R, {rtweet}, MapBox and GitHub Actions â€“ londonmapbot â€“ that tweets images of random coordinates in London. I decided to explore them interactively by creating a simple {leaflet} map. You can jump directly to the map).\n\n Note\nTwitter changed its API terms in 2023. As a result, you probably canâ€™t re-run the code in this blog. Read about how I moved londonmapbot to Mastodon at botsin.space/@londonmapbot because of these changes."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#the-bot",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#the-bot",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "The bot",
    "text": "The bot\nI built the londonmapbot Twitter bot as a fun little project to get to grips with GitHub Actions. An action is scheduled every 30 minutes to run some R code that (1) selects random coordinates in London, (2) fetches a satellite image from the MapBox API, (3) generates an OpenStreetMap URL, all of which are (4) passed to {rtweet} to post to the londonmapbot account.\nThe outputs have been compelling so far. The composition is usually â€˜accidentallyâ€™ pleasing. Sometimes landmarks are captured, like The Shard, The Natural History Museum and V&A and Heathrow.\n\n\n\nThe Shard looks pointy even in 2D.\n\n\nI was wondering whether the bot has â€˜foundâ€™ other landmarks that I hadnâ€™t noticed or whether itâ€™s found my house. The londonmapbot source code doesnâ€™t have a log file for all the coordinates itâ€™s generated, so I figured the easiest way to get this information and explore it would be to grab all the tweets â€“ which contain the coordinates as text â€“ and then map the results."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#packages",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#packages",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Packages",
    "text": "Packages\nIâ€™m loading the tidyverse for data manipulation with {dplyr}, {tidyr} and {stringr}. {rtweet} greatly simplifies the Twitter API and the objects it returns. Weâ€™ll use it to fetch all the tweets from londonmapbot.\nIâ€™m using a few geography-related packages:\n\n{sf} for tidy dataframes with spatial information\n{geojsonio} to read spatial files in geojson format\n{PostcodesioR} to fetch additional geographic data given our x-y information\n{leaflet} to build interactive maps from spatial data.\n\n\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(rtweet)\n  library(sf)\n  library(geojsonio)\n  library(PostcodesioR)\n  library(leaflet)\n})\n\nA particular shoutout to rOpenSci for this post: {rtweet}, {geojsonio} and {PostcodesioR} have all passed muster to become part of the rOpenSci suite of approved packages."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#fetch-tweets",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#fetch-tweets",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Fetch tweets",
    "text": "Fetch tweets\n{rtweet} does all the legwork to fetch and parse information from the Twitter API, saving you loads of effort.\nThe rtweet::get_timeline() function is amazing in its user-side simplicity. Pass the account name from which to fetch tweets, along with the number of tweets to get (3200 is the maximum).\n\nlmb_tweets &lt;- get_timeline(\"londonmapbot\", n = 3200)\nlmb_tweets[1:5, c(\"created_at\", \"text\")]  # limited preview\n\n# A tibble: 5 x 2\n  created_at          text                                                      \n  &lt;dttm&gt;              &lt;chr&gt;                                                     \n1 2020-12-29 09:36:20 \"51.5519, -0.33\\nhttps://t.co/ica9ZypBLS https://t.co/5gSâ€¦\n2 2020-12-29 08:59:46 \"51.4392, 0.1636\\nhttps://t.co/2DsbbLYIDG https://t.co/KVâ€¦\n3 2020-12-29 06:28:48 \"51.6773, -0.2555\\nhttps://t.co/1hu2VoxCBF https://t.co/bâ€¦\n4 2020-12-29 05:56:15 \"51.674, -0.4042\\nhttps://t.co/HMhmUVVrIn https://t.co/mPâ€¦\n5 2020-12-29 05:31:03 \"51.4451, 0.1058\\nhttps://t.co/nWuqy4s7am https://t.co/qvâ€¦\n{rtweet} has a function to quick-plot tweets over time. Thereâ€™s meant to be a tweet every half-hour from londonmapbot, but GitHub Actions has been a little inconsistent and sometimes fails to post.\n\nrtweet::ts_plot(lmb_tweets) +  # plot daily tweets\n  labs(\n    title = \"@londonmapbot tweets per day\",\n    x = \"\", y = \"\", caption = \"Data collected via {rtweet}\"\n  )"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#extract-tweet-information",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#extract-tweet-information",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Extract tweet information",
    "text": "Extract tweet information\nThe dataframe returned by {rtweet} contains nearly 100 columns. For our purposes we can minimise to:\n\nthe unique tweet identifier, status_id, which we can use to build a URL back to the tweet\nthe datetime the tweet was created_at\nthe tweet text content, from which we can isolate the latitude and longitude values\nthe media_url to the MapBox image attached to each tweet\nthe full OpenStreetMap link in each tweet via urls_expanded_urls\n\n\nlmb_simple &lt;- lmb_tweets %&gt;% \n  filter(str_detect(text, \"^\\\\d\")) %&gt;%  # must start with a digit\n  separate(  # break column into new columns given separator\n    text,  # column to separate\n    into = c(\"lat\", \"lon\"),  # names to split into\n    sep = \"\\\\s\",  # separate on spaces\n    extra = \"drop\" # discard split elements\n  ) %&gt;% \n  mutate(  # tidy up variables \n    lat = str_remove(lat, \",\"),\n    across(c(lat, lon), as.numeric)\n  ) %&gt;% \n  select(  # focus variables\n    status_id, created_at, lat, lon,\n    osm_url = urls_expanded_url, media_url\n  )\n\nlmb_simple[1:5, c(\"status_id\", \"lat\", \"lon\")]  # limited preview\n\n# A tibble: 5 x 3\n  status_id             lat    lon\n  &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;\n1 1343853346478841862  51.6 -0.33 \n2 1343844145518026752  51.4  0.164\n3 1343806154397409280  51.7 -0.256\n4 1343797964645523456  51.7 -0.404\n5 1343791619049480192  51.4  0.106"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#reverse-geocode",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#reverse-geocode",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Reverse geocode",
    "text": "Reverse geocode\nTweets from londonmapbot are really simple by design; they only have the latitude and longitude, a link to OpenStreetMap and a satellite image pulled from the MapBox API. It might be interesting to provide additional geographic information.\n{PostcodesioR} can perform a â€˜reverse geocodeâ€™1 of our coordinates. Give latitude and longitude to PostcodesioR::reverse_geocoding() and it returns a list with various administrative geographies for that point.\n\nlmb_geocode &lt;-  lmb_simple %&gt;% \n  mutate(\n    reverse_geocode = map2(\n      .x = lon, .y = lat,\n      ~reverse_geocoding(.x, .y, limit = 1)  # limit to first result\n    )\n  ) %&gt;% \n  unnest(cols = reverse_geocode) %&gt;%  # unpack listcol\n  hoist(reverse_geocode, \"postcode\") %&gt;%  # pull out postcode into a \n  hoist(reverse_geocode, \"admin_district\") # pull out borough\n\nlmb_geocode[1:5, c(\"lat\", \"lon\", \"postcode\", \"admin_district\")]  # limited preview\n\n# A tibble: 5 x 4\n    lat    lon postcode admin_district\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;         \n1  51.6 -0.33  UB6 7QT  Ealing        \n2  51.4  0.164 DA5 2DJ  Bexley        \n3  51.7 -0.256 WD6 5PL  Hertsmere     \n4  51.7 -0.404 WD24 5TU Watford       \n5  51.4  0.106 DA15 9BQ Bexley\nThe object returned from the reverse geocode is a nested list that we can tidyr::hoist() the geographic information from. Here we grabbed the postcode and â€˜administrative districtâ€™, which for our purposes is the London borough that the point is in."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#convert-to-spatial-object",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#convert-to-spatial-object",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Convert to spatial object",
    "text": "Convert to spatial object\nRight now we have a dataframe where the geographic information is stored as numeric values. We can use the {sf} package to convert and handle this information as spatial information instead.\nBasically we can use {sf} to â€˜geographiseâ€™ our dataframe. It can add geometry (points in our case), dimensions (XY, meaning 2D), the maximum geographic extent (a â€˜bounding boxâ€™ that roughly covers London) and recognition of the coordinate reference system (â€˜4236â€™ for latitude-longitude).\nThe sf::st_as_sf() function performs the magic of converting our tidy dataframe into a tidy spatial dataframe. Youâ€™ll see that the print method provides us the extra spatial metadata and that our geographic information has been stored in a special geometry column with class sfc_POINT.\n\nlmb_sf &lt;- lmb_geocode %&gt;% \n  st_as_sf(\n    coords = c(\"lon\", \"lat\"),  # xy columns\n    crs = 4326,  # coordinate reference system code\n    remove = FALSE  # retain the xy columns\n  )\n\nlmb_sf[1:5, c(\"status_id\", \"geometry\")]  # limited preview\n\nSimple feature collection with 5 features and 1 field\ngeometry type:  POINT\ndimension:      XY\nbbox:           xmin: -0.4042 ymin: 51.4392 xmax: 0.1636 ymax: 51.6773\nCRS:            EPSG:4326\n# A tibble: 5 x 2\n  status_id                    geometry\n  &lt;chr&gt;                     &lt;POINT [Â°]&gt;\n1 1343853346478841862   (-0.33 51.5519)\n2 1343844145518026752  (0.1636 51.4392)\n3 1343806154397409280 (-0.2555 51.6773)\n4 1343797964645523456  (-0.4042 51.674)\n5 1343791619049480192  (0.1058 51.4451)"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#map-it",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#map-it",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Map it",
    "text": "Map it\n\nLondon boundary geojson\nCoordinates for londonmapbot tweets are selected randomly within a rectangle roughly within the boundary of the M25 motorway. We can grab a polygon of the Greater London boundary to see which points fall within the â€˜trueâ€™ extent of London.\nTo do this, Iâ€™m using a set of boundaries for Englandâ€™s regions2 via the Office for National Statisticsâ€™s Open Geography Portal API. The polygons are â€˜ultra generalisedâ€™ to be represented by very few points (every 500m). This means it doesnâ€™t follow the exact boundary of London, but thatâ€™s okay: itâ€™s only being used as a guide and we get the benefit of a small polygon file.\n\nldn_sf &lt;- geojson_read(\n  paste0(  # API endpoint for NUTS1 geography geojson\n    \"https://opendata.arcgis.com/datasets/\",\n    \"01fd6b2d7600446d8af768005992f76a_4.geojson\"\n  ), \n  what = \"sp\"  # read as spatial object\n) %&gt;% \n  st_as_sf() %&gt;%  # convert to sf object\n  filter(nuts118nm == \"London\")  # London polygon only\n\nldn_sf[, c(\"nuts118nm\", \"geometry\")]  # limited preview\n\nSimple feature collection with 1 feature and 1 field\ngeometry type:  MULTIPOLYGON\ndimension:      XY\nbbox:           xmin: -0.5097014 ymin: 51.28676 xmax: 0.3340242 ymax: 51.69188\nCRS:            unknown\n  nuts118nm                       geometry\n1    London MULTIPOLYGON (((-0.01191868...\n{ggplot2} has a geom for quick-plotting of {sf} objects, so we can check the boundary.\n\nggplot(ldn_sf) +\n  geom_sf() +\n  labs(\n    title = \"London boundary\",\n    subtitle = \"Ultra-generalised NUTS1 extent\",\n    caption = \"Data collected via ONS Open Geography Portal API\"\n  )\n\n\n\n\nBuild map with {leaflet}\nYou can build up layers in {leaflet} in a similar kind of way to a {ggplot2} graphic. The base map is applied with addProviderTiles(), followed by the London boundary with addPolygons(), with the points added as circle-shaped points with addCircleMarkers().\n\nlmb_map &lt;- leaflet(ldn_sf, width = '100%') %&gt;% \n  addProviderTiles(\"CartoDB.Positron\") %&gt;%\n  addPolygons(  # generalised London boundary\n    color = \"black\", weight = 2,\n    opacity = 1, fillOpacity = 0.2\n  ) %&gt;% \n  addCircleMarkers(  # locations as points\n    lng = lmb_sf$lon, lat = lmb_sf$lat,  # xy\n    radius = 5, stroke = FALSE,  # marker design\n    fillOpacity = 0.5, fillColor = \"#0000FF\",  # marker colours\n    clusterOptions = markerClusterOptions(),  # bunch-up markers\n    popup = ~paste0(  # dynamic HTML-creation for popup content\n      emo::ji(\"round_pushpin\"), \" \", lmb_sf$lat, \", \", lmb_sf$lon, \"&lt;br&gt;\",\n      emo::ji(\"postbox\"), lmb_sf$admin_district, \n      \", \", lmb_sf$postcode, \"&lt;br&gt;\",\n      emo::ji(\"bird\"), \" &lt;a href='https://twitter.com/londonmapbot/status/\",\n      lmb_sf$status_id, \"'&gt;Tweet&lt;/a&gt;&lt;br&gt;\",\n      emo::ji(\"world_map\"), \" \", \"&lt;a href='\",\n      lmb_sf$osm_url, \"' width='100%'&gt;OpenStreetMap&lt;/a&gt;&lt;br&gt;&lt;br&gt;\",\n      \"&lt;img src='\", lmb_sf$media_url, \"' width='200'&gt;\"\n    )\n  )\n\nThe markers, which are blue dots, have rich pop-ups when clicked. The information is generated dynamically for each point by pasting HTML strings with the content of the dataframe. Props to Matt Kerlogueâ€™s narrowbotR, which uses this emoji-info layout in its automated tweets.\nTo keep the design simple and uncluttered, Iâ€™ve intentionally used a muted base map (â€˜Positronâ€™ from CartoDB) and limited the amount of pop-up content.\nIn the pop-up youâ€™ll see information from the tweet, including the satellite image and printed coordinates; URLs to the original tweet and OpenStreetMap; plus the reverse-geocoded info we got from {PostcodesioR}.\nSince there are thousands of points, it makes sense to cluster them with markerClusterOptions() to avoid graphical and navigational troubles. Click a cluster to expand until you reach a marker."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#map",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#map",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "The map",
    "text": "The map\n\nlmb_map\n\nIf you canâ€™t see the satellite photos in each pop-up you may need to change browser.\nAnd no, it hasnâ€™t captured my house yet!"
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#development",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#development",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Development",
    "text": "Development\nI made this for my own amusement and as an excuse to use {PostcodesioR} and reacquaint myself with {leaflet}. If I were going to develop it, I would make a Shiny app that continuously refreshes with the latest tweet information. I may revisit londonmapbot in future, or create a new bot; in which case the reverse geocoding capabilities of {PostcodesioR} could come in handy for providing more content in tweet text."
  },
  {
    "objectID": "posts/2020-12-20-londonmapbot-leaflet/index.html#environment",
    "href": "posts/2020-12-20-londonmapbot-leaflet/index.html#environment",
    "title": "Mapping londonmapbot tweets with {leaflet}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 19:03:41 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#tldr",
    "href": "posts/2023-02-02-trapinch-begin/index.html#tldr",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve used the {httr2} R package to create {trapinch}, a package that wraps PokÃ©API for fetching PokÃ©mon data.\n\n Note\nI had found a couple of older, non-{httr2} PokÃ©API wrappers for R (see footnotes), but had somehow missed one that already uses {httr2}: see Ash Baldryâ€™s {pokeapi} package, which he wrote months ago!"
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#httr-me-baby-one-more-time",
    "href": "posts/2023-02-02-trapinch-begin/index.html#httr-me-baby-one-more-time",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "{httr} me baby one more time",
    "text": "{httr} me baby one more time\nThe {httr2} package lets you talk to the internet. Or, if youâ€™re fancy, it â€˜helps you deal programmatically with HTTP requests and responsesâ€™ so you can use it to fetch data from Application Programming Interfaces (APIs).\n{httr2} has functions that are prefixed consistently (req_*(), resp_()*, etc), are narrow in scope, pipeable (|&gt;) and which return nice errors and messages. These are neat improvements on the original {httr} package.\nIâ€™ve used {httr} before to explore R package startup messages and detect linkrot. Itâ€™s time to try out {httr2}. What simple API can I wrap into an R package?1"
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#poke-an-api",
    "href": "posts/2023-02-02-trapinch-begin/index.html#poke-an-api",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "Poke an API",
    "text": "Poke an API\nRegular readers will be unsurprised that Iâ€™ve chosen the PokÃ©API API for fetching all sorts of information related to the PokÃ©mon game franchise.2\nPokÃ©API provides a relatively simple API. You donâ€™t need to sign-up or use API tokens, you can only read (â€˜GETâ€™) data from itâ€™s not rate-limited.\nURL paths for fetching data are also straightforward: you append an endpoint and a resource of interest to the base URL in the form https://pokeapi.co/api/v2/{endpoint}/{resource}.3\nIn other words, you could type https://pokeapi.co/api/v2/pokemon/lotad in your browser and the API would respond with a JSON file containing data about Lotad, the best PokÃ©mon.\n{httr2} lets us do this programmatically and can return a more R-friendly list object."
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#its-a-trapinch",
    "href": "posts/2023-02-02-trapinch-begin/index.html#its-a-trapinch",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "Itâ€™s a trapinch",
    "text": "Itâ€™s a trapinch\nSo, Iâ€™ve created the {trapinch} package.\nItâ€™s a proof of concept; a work in progress. Thereâ€™s probably bugs. Iâ€™m sharing it in case I donâ€™t take it any further, or if you want to contribute an issue or pull request.\nYou can download it from GitHub. It depends on {httr2} (obviously), {rcurl} and R version 4.1 or higher4 and can be downloaded from GitHub:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/trapinch\")  # v0.0.1 in this post\nlibrary(trapinch)\n\nDonâ€™t be surprised if function names or general functionality change in future. In particular, Iâ€™d like to look at throttling (limiting the number of API calls to prevent misuse) and to provide sensible errors for timeouts or if the service is down.\n\nGotta GET â€™em all\nThereâ€™s a generic low-level function, get_pokeapi(), to which you pass the endpoint and resource ID (numeric) or name (character) of interest. Each endpoint also has its own dedicated function, like get_item() or get_move() that calls get_pokeapi() under the hood.\nYou can look at the inbuilt resource_lookups list to get a dataframe of resource IDs and names for each endpoint, as well as the full URL needed to query the API. Hereâ€™s the first few:\n\nhead(names(resource_lookups))\n\n[1] \"ability\"        \"berry\"          \"berry-firmness\" \"berry-flavor\"  \n[5] \"characteristic\" \"contest-effect\"\nSo hereâ€™s the first few rows of the resource dataframe for the â€˜pokemonâ€™ endpoint:\n\nhead(resource_lookups[[\"pokemon\"]])\n\n  id       name                                  url\n1  1  bulbasaur https://pokeapi.co/api/v2/pokemon/1/\n2  2    ivysaur https://pokeapi.co/api/v2/pokemon/2/\n3  3   venusaur https://pokeapi.co/api/v2/pokemon/3/\n4  4 charmander https://pokeapi.co/api/v2/pokemon/4/\n5  5 charmeleon https://pokeapi.co/api/v2/pokemon/5/\n6  6  charizard https://pokeapi.co/api/v2/pokemon/6/\nOne of these resource names is â€˜mewâ€™, the legendary first-generation PokÃ©mon.5 You could use get_pokeapi(\"pokemon\", \"mew\") to retrieve its data, or more simply:\n\nmew &lt;- get_pokemon(\"mew\")\n\nThe function returns a list of lists, which is parsed from the JSON response returned by the API. So for the â€˜pokemonâ€™ endpoint we get 18 different elements of various classes:\n\nstr(mew, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nIâ€™ve shown only the top level structure to hide some of the complexity. For example, the â€˜movesâ€™ item contains all the moves a PokÃ©mon can learn, at what level it can learn them, in which game it learns them, and so on. Grabbing the first of the 363 â€˜movesâ€™ items (!) listed for Mew looks like this (oof):\n\nmew[[\"moves\"]][[1]][[\"move\"]][[\"name\"]]\n\n[1] \"pound\"\nA future task might be to simplify some of this complexity by collapsing deep lists into dataframes where possible.\n\n\nThumbing the PokÃ©dex\nThe API responses are â€˜pagedâ€™, meaning that you must make successive requests of a set size to retrieve all the data for a given endpoint. The get_*() functions automatically expand the request to ask for all the items in one go.\nWe know the maximum number of items to be returned from an endpoint because the stored in the resource_lookups object, so this can be appended automatically to the request string.\n\n\nBILLâ€™s PC\nResponses are cached, which means that the data is saved on your computer. If you make the same request, the data will be retrieved first from the cache rather than calling the API again. That means thereâ€™s one less request for the API to deal with.\nThe cache is the path resolved by R_user_dir(\"trapinch\", \"cache\"). This function was introduced in R v4.0 for platform-independent storage of package-related data on a userâ€™s machine.6 You can delete everything from the cache with clear_cache().\n\n\nSubstitute\n{httptest2} is a handy package that lets you test code written with {httr2}, specifically.\nWhy would you need special testing for API calls? The idea is that you should be able to test your package without the need for an active internet connection. {httptest2} â€˜recordsâ€™ the calls you make when you run your tests, then chooses when testing between this â€˜mockâ€™ response and a â€˜liveâ€™ response.\nThe approach is pretty simple if youâ€™ve tested before with {testthat}: you wrap your normal test_that() call with httr2::with_mock_dir(). Hereâ€™s an example of a test that make sure we get a list back from the API when we use get_pokeapi():\n\nwith_mock_dir(\"endpoint\", {\n  test_that(\"a list is returned\", {\n    expect_type(get_pokeapi(\"move-battle-style\"), \"list\")\n  })\n})\n\nBy wrapping the test in with_mock_dir(), {httptest2} creates the directory tests/endpoint/ that stores a copy of the JSON returned for this call when an internet connection was live.\nAs an aside, I learnt about curl::has_internet() in Colinâ€™s blogpost, which can stop() the get_*() functions if thereâ€™s no internet connection. But has_internet() will trigger if youâ€™re offline when you test, defeating the purpose of {httptest2}! Luckily, I saw a timely post by MaÃ«lle about integrating this type of check into an â€˜escape hatchâ€™ so your unit tests can be run successfully in this scenario.\nThe rOpenSci HTTP Testing book is a good general port of call as well."
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#inside-the-pokÃ©-ball",
    "href": "posts/2023-02-02-trapinch-begin/index.html#inside-the-pokÃ©-ball",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "Inside the PokÃ© Ball",
    "text": "Inside the PokÃ© Ball\nThe user-facing functions of {trapinch} are therefore pretty simple. I could leave it at that.\nBut how daunting does the underlying {httr2} code look in the back-end? Turns out that itâ€™s not that scary, thanks to those friendly and modular functions of {httr2}.\nWe can walk through that earlier get_pokemon(\"mew\") call using bare {httr2} functions by:\n\nStarting with the base API URL\nAppending the endpoint and resource as extensions (i.e.Â in the form /pokemon/mew)\nAdding a query for the maximum number of items in this endpoint-resource combo (i.e.Â ?limit=1279)\nAnnouncing to the API, as courtesy, who has made the call (i.e.Â who is the â€˜user agentâ€™)\nSpecifying the cache location for results to be saved\n\nFirst some variables:\n\nendpoint &lt;- \"pokemon\"\nresource &lt;- \"mew\"\nbase_url &lt;- \"https://pokeapi.co/api/v2/\"\nuser_agent &lt;- \"trapinch (http://github.com/matt-dray/trapinch)\"\nresource_count &lt;- nrow(trapinch::resource_lookups[[endpoint]])\ncache_dir &lt;- tools::R_user_dir(\"trapinch\", which = \"cache\")\n\nAnd now we can build our request with {httr2} functions prefixed with req:\n\nlibrary(httr2)\n\nmew_request &lt;- request(base_url) |&gt;\n  req_url_path_append(endpoint, resource) |&gt;\n  req_url_query(limit = resource_count) |&gt;\n  req_user_agent(user_agent) |&gt;\n  req_cache(cache_dir)\n\nPrinting the object summarises the request:\n\nmew_request\n\n&lt;httr2_request&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nBody: empty\nOptions:\nâ€¢ useragent: 'trapinch (http://github.com/matt-dray/trapinch)'\nPolicies:\nâ€¢ cache_path: '/Users/mattdray/Library/Caches/org.R-project.R/R/trapinch'\nâ€¢ cache_use_on_error: FALSE\nâ€¢ cache_debug: FALSE\nThen we can actually execute the request:\n\nmew_perform &lt;- req_perform(mew_request)\n\nAgain, we can peek at the object to get some extra information about the processing of the request:\n\nmew_perform\n\n&lt;httr2_response&gt;\nGET https://pokeapi.co/api/v2/pokemon/mew?limit=1279\nStatus: 200 OK\nContent-Type: application/json\nBody: In memory (561317 bytes)\nWe can see the request was successful, since the HTTP status was 200 OK. Other status values are possible and may require us to try again later, for example.\nA couple of functions to mention here are last_request() and last_response(), which will also (surprise!) spit out info about the last request you made and the response received.\nFinally we can parse the JSON returned by the API. Again, Iâ€™m presenting the top-level structure only, given its complexity:\n\nmew_response &lt;- resp_body_json(mew_perform)\nstr(mew_response, max.level = 1)\n\nList of 18\n $ abilities               :List of 1\n $ base_experience         : int 300\n $ forms                   :List of 1\n $ game_indices            :List of 20\n $ height                  : int 4\n $ held_items              :List of 1\n $ id                      : int 151\n $ is_default              : logi TRUE\n $ location_area_encounters: chr \"https://pokeapi.co/api/v2/pokemon/151/encounters\"\n $ moves                   :List of 363\n $ name                    : chr \"mew\"\n $ order                   : int 248\n $ past_types              : list()\n $ species                 :List of 2\n $ sprites                 :List of 10\n $ stats                   :List of 6\n $ types                   :List of 1\n $ weight                  : int 40\nBoom: this matches the information we retrieved earlier with get_pokemon(\"mew\")."
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#whos-that-pokÃ©mon",
    "href": "posts/2023-02-02-trapinch-begin/index.html#whos-that-pokÃ©mon",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "Whoâ€™s that PokÃ©mon?",
    "text": "Whoâ€™s that PokÃ©mon?\nI know youâ€™re thinking â€˜why trapinch?â€™ In short, itâ€™s the name of a PokÃ©mon that contains the letters â€˜R APIâ€™, which is cute. It also makes for an easy hex sticker with the PokÃ©monâ€™s characteristic zigzag mouth and colour palette of orange and grey.\nSo why not â€˜rapidashâ€™, which starts with â€˜R APIâ€™? Easy, lol: trapinch isnâ€™t taken yet on RepokÃ©mon, a page by Chee Aun that lists GitHub repositories that are named after PokÃ©mon.7\n\nJoin me next time as I continue my quest to write (sometimes) useful R packages that help me squat all the remaining spots on RepokÃ©mon (I call this â€˜RDDâ€™).8"
  },
  {
    "objectID": "posts/2023-02-02-trapinch-begin/index.html#environment",
    "href": "posts/2023-02-02-trapinch-begin/index.html#environment",
    "title": "Wrapping PokÃ©API with {trapinch}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:09:24 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html",
    "title": "Friendship ended with Google Analytics",
    "section": "",
    "text": "mudasir.jpg"
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#tldr",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#tldr",
    "title": "Friendship ended with Google Analytics",
    "section": "tl;dr",
    "text": "tl;dr\nThis blog now uses GoatCounter instead of Google Analytics. GoatCounter is a lightweight and unobtrusive site-visit counter made by developer Martin Tournoij."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#do-blogposts-dream-of-electric-goats",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#do-blogposts-dream-of-electric-goats",
    "title": "Friendship ended with Google Analytics",
    "section": "Do blogposts dream of electric goats?",
    "text": "Do blogposts dream of electric goats?\nI write posts on this blog for me and for other learners. Itâ€™s great if people find the content useful or interesting.\nBut I donâ€™t and never will make money from this site, so why would I care how many visits it gets?\nA highly-viewed post indicates to me that the topic is worth talking about. Itâ€™s a signal that it might be worth writing more about that thing in future. Popular posts might also need updating over time to keep the information up to date.\nSo I think I have a use case. Except I donâ€™t want to â€˜trackâ€™ people; I just want to count visits and views."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#friendship-ended",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#friendship-ended",
    "title": "Friendship ended with Google Analytics",
    "section": "Friendship ended",
    "text": "Friendship ended\nIâ€™ve been using Google Analytics for this blog since it began in April 2018. Why? My naÃ¯ve reasons were that itâ€™s free, itâ€™s ubiquitous and itâ€™s easily implemented in {blogdown}.\nItâ€™s massively bloated for my use case though. Acquisition reports, revenue per user and cohort analysis are not relevant to me. And I donâ€™t even know what they mean.\nMore importantly, Iâ€™m uncomfortable with various privacy concerns around the company and platform. I donâ€™t need or want you to be the product.\nThis change has been a long time coming and follows my earlier removal of the Disqus comment platform, thanks to a MaÃ«lle Salmon post."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#new-best-friend",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#new-best-friend",
    "title": "Friendship ended with Google Analytics",
    "section": "New best friend",
    "text": "New best friend\nA number of alternatives are available,1 but I chose GoatCounter by independent developer Martin Tournoij. Why?\nTo summarise, the large type at the top of the GoatCounter home page says:\n\nEasy web analytics. No tracking of personal data.\n\nWhat does that encompass?\n\n\n\nWhat\nExplain\n\n\n\n\nPrivacy\nGoatCounter doesnâ€™t collect personally-identifiable data and as such it â€˜probably doesnâ€™t require a GDPR consent noticeâ€™.\n\n\nSimple web interface\nA clean interface with focus on visits and viewers over time (see a live demo).\n\n\nTransparent\nGoatCounter is open source and the creator is open about comparisons to other products.\n\n\nThoughtful\nThe creator has written openly about the rationale and has considered users of assistive tech.\n\n\nFree\nWith paid plans or donations available (Patreon, GitHub Sponsors).\n\n\nLightweight\nItâ€™s less than 3 kb."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#herding-goatcounter",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#herding-goatcounter",
    "title": "Friendship ended with Google Analytics",
    "section": "Herding GoatCounter",
    "text": "Herding GoatCounter\nSwitching to GoatCounter was straightforward.\nThis blog was created with the R package {blogdown}, which is built on the Hugo static site generator, and itâ€™s deployed via Netlify. Your mileage may vary, but there were basically three steps:\n\nRemove the Google Analytics token from the siteâ€™s config.toml file.\nCreate a GoatCounter account.\nAdd a single script tag to the &lt;body&gt; of your site2.\n\nFor that last step I used a special Netlify feature that inserts code snippets into the HTML of your site on deployment.3 I didnâ€™t have to worry about where to put it in the code of the site.\n\n\n\nAnalytics straight into the vein.\n\n\nYour stats will then be available from a URL in the form https://yoursite.goatcounter.com, which you set during the sign-up process.\nNow you can start counting sheep. Erâ€¦ goats."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#greatest-of-all-time-goat",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#greatest-of-all-time-goat",
    "title": "Friendship ended with Google Analytics",
    "section": "Greatest Of All Time (GOAT)",
    "text": "Greatest Of All Time (GOAT)\nThe switch does mean Iâ€™ll lose cumulative view counts for posts that already exist, but Iâ€™m not bothered about that. I can always export the Google Analytics data and manually add it to GoatCounterâ€™s counts.\nFor interest, hereâ€™s the most viewed posts as counted by Google Analytics:\n\nRepaying Tom Nook with {R6} (Apr 2020)\nPackages that Sparked Joy in 2019 (Dec 2019)\nPackage a {xaringan} template (May 2019)\nMail merge with R and Dawsonâ€™s Creek (Jun 2018)\nHow do you pronounce {dplyr}? (Sep 2019)\n\nIn particular, the post about {R6} is a good example of something I wanted to learn and then blog about for posterity. I think the timing helped in people viewing it, since Animal Crossing: New Horizons had just been released to great fanfare. To illustrate the â€˜zeitgeistinessâ€™, this post had the highest view spike of any post and has settled down a great deal since then.\nThe â€˜mail mergeâ€™ post is a good example of that classic David Robinson tweet:\n\nWhen youâ€™ve written the same code 3 times, write a function. When youâ€™ve given the same in-person advice 3 times, write a blog post\n\nGiven its popularity, I also decided to overhaul it to make it more simple and accessible. It also led to a later post on parameterised R Markdown reports, which I think is actually the better solution in most cases.\nI wouldnâ€™t have known any of this without having a record of page views, but the method for collecting that data no longer grinds my goat."
  },
  {
    "objectID": "posts/2020-09-16-goatcounter-blogdown/index.html#environment",
    "href": "posts/2020-09-16-goatcounter-blogdown/index.html#environment",
    "title": "Friendship ended with Google Analytics",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 08:15:58 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#tldr",
    "href": "posts/2020-11-21-president-tilemap/index.html#tldr",
    "title": "The US electoral college with {tilegramsR}",
    "section": "tl;dr",
    "text": "tl;dr\nThe {tilegramsR} package for R contains a geospatial object for mapping the US electoral college. I amended it for states that use the congressional district method and generated a minimalist map of the results for the 2020 US presidential election.1"
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#send-a-cartogram",
    "href": "posts/2020-11-21-president-tilemap/index.html#send-a-cartogram",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Send a cartogram",
    "text": "Send a cartogram\nItâ€™s usually best to scale subnational divisions by voter count when visualising election results. This is because election outcomes are decided by people, not land area. Cartograms are a good choice for this: theyâ€™re maps where geographic units are resized according to something other than area.\nOne format of the cartogram is the tilegram. Tilegrams disregard the shape of the geographic units entirely and represent them with uniformly-shaped â€˜tilesâ€™ instead. Squares are often used, but hexagons give you a bit more freedom to pack the units and approximate geographic location. Hexagons are the bestagons, after all.\nA tilegram may end up looking strange if youâ€™re used to looking at Mercator-projected maps, but itâ€™s a better reflection of relative voter contribution."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#back-to-college",
    "href": "posts/2020-11-21-president-tilemap/index.html#back-to-college",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Back to college",
    "text": "Back to college\nSo we could make a tilegram of the recent US presidential election with a separate shape for each state. Right? Well, yeah, but thereâ€™s a better way.\nThe US presidential election is special because the total vote count doesnâ€™t directly elect the leader. Instead thereâ€™s an â€˜electoral collegeâ€™ system. Put extremely simply, each state has a number of representatives (â€˜electorsâ€™) that are sent to vote for the candidate that got the majority vote share in their state. The winning national candidate has the majority of state electors declaring for them (270 of 538).\nSo itâ€™s electors, not states, that should be represented by each unit in a tilegram of US presidential election results."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#tile-style",
    "href": "posts/2020-11-21-president-tilemap/index.html#tile-style",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Tile style",
    "text": "Tile style\nFortunately for us, the {tilegramsR} package by Bhaskar V. Karambelkar has an sf_FiveThirtyEightElectoralCollege2 object that contains tilegram data for the US where each elector is represented by one hexagon.\nItâ€™s an sf-class object, which means it contains tidy geospatial information: each row is an elector, with a column for the state abbreviation and a column for the hexagon geometries.\nBefore we take a look, letâ€™s load the packages used in this post.\n\nsuppressPackageStartupMessages({\n  # Data wrangling\n  library(dplyr)       # data manipulation\n  library(stringr)     # string manipulation\n  # Mapping\n  library(tilegramsR)  # tilegram objects\n  library(ggplot2)     # plotting\n  library(ggtext)      # text rendering in plots\n  library(ggthemes)    # has a map theme\n  library(patchwork)   # organise plots\n})\n\nThe default print method for sf-class objects shows us a few things. We can see there are 538 two-dimensional shapes: one for each elector. Note that this map is built in arbitrary space: the bounding box doesnâ€™t reflect actual geography and thereâ€™s no coordinate reference system (CRS). The preview of the features shows us each row of the dataset with each state labelled with its abbreviation (CA is California, for example).\n\nsf_FiveThirtyEightElectoralCollege\n\nSimple feature collection with 538 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 293.6239 ymin: 16.95238 xmax: 2495.803 ymax: 1661.333\nCRS:           NA\nFirst 10 features:\n   FID state tilegramVa                       geometry\n1   02    AK          3 POLYGON ((293.6239 237.3333...\n2   06    CA         55 POLYGON ((352.3486 847.619,...\n3   06    CA         55 POLYGON ((322.9862 796.7619...\n4   06    CA         55 POLYGON ((352.3486 745.9048...\n5   06    CA         55 POLYGON ((322.9862 695.0476...\n6   06    CA         55 POLYGON ((352.3486 644.1905...\n7   02    AK          3 POLYGON ((322.9862 288.1905...\n8   02    AK          3 POLYGON ((352.3486 237.3333...\n9   06    CA         55 POLYGON ((411.0734 949.3333...\n10  06    CA         55 POLYGON ((381.711 898.4762,...\n\n\nSimilarly, thereâ€™s an object called sf_FiveThirtyEightElectoralCollege.states that contains geometry to delineate state boundaries in the sf_FiveThirtyEightElectoralCollege object. We can combine these and look at a quick tilegram of the US electoral college using {ggplot2} and the special geom_sf() geom for visualising geospatial data stored in sf format.\n\nggplot() + \n  geom_sf(data = sf_FiveThirtyEightElectoralCollege) + \n  geom_sf(\n    data = sf_FiveThirtyEightElectoralCollege.states,\n    color = \"black\", alpha = 0, size = 1\n  ) + \n  theme_map()\n\n\n\n\nYou can see that each elector is represented by a single hexagon and groups of hexagons are combined into states (thick outlines). Hexagons are placed roughly in the familiar shape of the US despite the change to the apparent area of each one. The non-contiguous regions in the lower left are Alaska (three electors) and Hawaii (four)."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#district-structure-strictures",
    "href": "posts/2020-11-21-president-tilemap/index.html#district-structure-strictures",
    "title": "The US electoral college with {tilegramsR}",
    "section": "District-structure strictures",
    "text": "District-structure strictures\nIn general, the winner of the popular vote within a state gains all the electors for that state. There are two exceptions: Nebraska (NE) and Maine (ME). These states use the â€˜congressional district methodâ€™.\nThe popular-vote winner gets two electors by default and the remaining electors are won by the winner of the popular vote in each district (three in Nebraska and two in Maine). In other words, the electors from these states could be from more than one party.\nThis is sometimes represented in electoral college maps by colouring Nebraska and Maine with stripes of with each partyâ€™s colour. We can avoid that suboptimal representation with a tilegram because we can individually colour our tiles.\nUnfortunately, the sf_FiveThirtyEightElectoralCollege doesnâ€™t account for the congressional district method, so weâ€™ll have to build this in ourselves. We can isolate rows for Nebraska and Maine and then generate a new column to create distinct names for the districts, which weâ€™ll number sequentially.\n\n# Isolate/update states with the congressional district method\ncdm_sf &lt;- sf_FiveThirtyEightElectoralCollege %&gt;% \n  filter(state %in% c(\"NE\", \"ME\")) %&gt;% \n  mutate(\n    state_cdm = c(\n      \"NE\", \"NE\", \"NE1\", \"NE2\", \"NE3\", \n      \"ME\", \"ME\", \"ME1\", \"ME2\"\n    )\n  ) %&gt;% \n  select(state, state_cdm, everything())\n\n# Preview\ncdm_sf\n\nSimple feature collection with 9 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 851.5092 ymin: 932.381 xmax: 2407.716 ymax: 1661.333\nCRS:           NA\n  state state_cdm FID tilegramVa                       geometry\n1    NE        NE  31          5 POLYGON ((851.5092 1000.19,...\n2    NE        NE  31          5 POLYGON ((910.2339 1000.19,...\n3    NE       NE1  31          5 POLYGON ((939.5963 949.3333...\n4    NE       NE2  31          5 POLYGON ((968.9587 1000.19,...\n5    NE       NE3  31          5 POLYGON ((998.3211 949.3333...\n6    ME        ME  23          4 POLYGON ((2290.266 1559.619...\n7    ME        ME  23          4 POLYGON ((2319.628 1610.476...\n8    ME       ME1  23          4 POLYGON ((2348.991 1559.619...\n9    ME       ME2  23          4 POLYGON ((2319.628 1508.762...\n\n\nYou can see that weâ€™ve retained the original state column and now also have a state_cdm column that contains tiles named by district.\nNow we can replace the data for these states in our original sf-class object.\n\n# Update the original object with the new information\nf38_cdm_sf &lt;- sf_FiveThirtyEightElectoralCollege %&gt;% \n  mutate(state_cdm = state) %&gt;%  # generate column\n  filter(!state %in% c(\"ME\", \"NE\")) %&gt;%  # remove old NE and ME\n  bind_rows(cdm_sf) %&gt;% # bind updated NE and ME \n  select(state, state_cdm, everything())  # relocate cols"
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#party-time",
    "href": "posts/2020-11-21-president-tilemap/index.html#party-time",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Party time",
    "text": "Party time\nWe have our geospatial information sorted; now to create vectors of the states won by each candidate as declared by the Associated Press (AP) at time of writing.\n\n# Vector of states/districts won by Democrat candidate\nd_states &lt;- c(\n  \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"GA\", \"HI\",\n  \"IL\", \"MA\", \"MD\", \"ME\", \"ME1\", \"MI\", \"MN\", \"NE2\",\n  \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OR\", \"PA\", \"RI\",\n  \"VA\", \"VT\", \"WA\", \"WI\"\n)\n\n# Vector of states/districts won by Republican candidate\nr_states &lt;- c(\n  \"AK\", \"AL\", \"AR\", \"FL\", \"IA\", \"ID\", \"IN\", \"KS\",\n  \"KY\", \"LA\", \"ME2\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\",\n  \"NE\", \"NE1\", \"NE3\", \"OH\", \"OK\", \"SC\", \"SD\", \"TN\",\n  \"TX\", \"UT\", \"WV\", \"WY\"\n)\n\nWith this information we can add a couple of columns to our geospatial object: result to indicate a Democrat or Republican winner, and the symbolic colour of the party (blue for Democrat and red for Republican). Weâ€™ll refer to this colour column in the plot so we can colour the tiles correctly.\n\n# Mark districts with winning party and provide colour\nresults_sf &lt;- f38_cdm_sf %&gt;% \n  mutate(\n    result = case_when(\n      state_cdm %in% d_states ~ \"D\",  # Democrat\n      state_cdm %in% r_states ~ \"R\"   # Republican\n    ),\n    colour = case_when(\n      result == \"D\" ~ \"#0000FF\",  # blue\n      result == \"R\" ~ \"#FF0000\"   # red\n    )\n  ) %&gt;% \n  select(state, state_cdm, result, colour, everything())\n\n# Preview\nresults_sf\n\nSimple feature collection with 538 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 293.6239 ymin: 16.95238 xmax: 2495.803 ymax: 1661.333\nCRS:           NA\nFirst 10 features:\n   state state_cdm result  colour FID tilegramVa                       geometry\n1     AK        AK      R #FF0000  02          3 POLYGON ((293.6239 237.3333...\n2     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 847.619,...\n3     CA        CA      D #0000FF  06         55 POLYGON ((322.9862 796.7619...\n4     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 745.9048...\n5     CA        CA      D #0000FF  06         55 POLYGON ((322.9862 695.0476...\n6     CA        CA      D #0000FF  06         55 POLYGON ((352.3486 644.1905...\n7     AK        AK      R #FF0000  02          3 POLYGON ((322.9862 288.1905...\n8     AK        AK      R #FF0000  02          3 POLYGON ((352.3486 237.3333...\n9     CA        CA      D #0000FF  06         55 POLYGON ((411.0734 949.3333...\n10    CA        CA      D #0000FF  06         55 POLYGON ((381.711 898.4762,..."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#gram-them-tiles",
    "href": "posts/2020-11-21-president-tilemap/index.html#gram-them-tiles",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Gram them tiles",
    "text": "Gram them tiles\nThe plot will be built from our sf-class object that has been edited for the congressional district method and contains the results; the state boundaries from sf_FiveThirtyEightElectoralCollege.states; and the title with coloured as a key matching the candidateâ€™s party.\nNote that Nebraska (centre-left) and Maine (upper-right) are indeed coloured to represent more than one party, given the share of votes in their congressional district systems.\n\n# Build plot object\np &lt;- ggplot() +\n  geom_sf(  # layer containing district hexagons\n    data = results_sf,\n    fill = results_sf$colour,  # hex interiors\n    color = results_sf$colour  # hex outlines\n  ) + \n  geom_sf(  # layer containing state hexagons\n    data = sf_FiveThirtyEightElectoralCollege.states,\n    color = \"white\",  # state boundaries\n    alpha = 0,  # transparent\n    size = 1  # thickness\n  ) +\n  theme_map() # remove non-data plot elements\n\np\n\n\n\n\nI think thatâ€™s quite pleasing.\nWe can add some more contextual information with titles. In particular, we can use the text rendering of {ggtext} to create a subtitle with the candidatesâ€™ names coloured as a key to the map.\n\np +  # the original plot object\n  labs(  # {ggtext} to colour names by party\n    title = \"&lt;span style='font-size:15pt'&gt;\n    US Presidential Election 2020\",\n    subtitle = \"&lt;span style='font-size:10pt'&gt;Electoral college votes for\n    &lt;span style='color:#0000FF;'&gt;Joe Biden&lt;/span&gt; (306) and \n    &lt;span style='color:#FF0000;'&gt;Donald Trump&lt;/span&gt; (232)\n    &lt;/span&gt;\",\n    caption = \"Made with {ggplot2}, {tilemapsR} and {ggtext}\"\n  ) +\n  theme(\n    plot.title = element_markdown(lineheight = 1.1),\n    plot.subtitle = element_markdown(lineheight = 1.1)\n  )"
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#zoom-enhance",
    "href": "posts/2020-11-21-president-tilemap/index.html#zoom-enhance",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Zoom! Enhance!",
    "text": "Zoom! Enhance!\nIn case you didnâ€™t spot Nebraska and Maine, we can plot these two alone and label them by state_cdm to expose the district names.\n\n# Quick and dirty function to plot each state\nplot_state &lt;- function(state_abbrev) {\n  \n  # Isolate state data\n  state_sf &lt;- results_sf %&gt;% \n    filter(str_detect(state, paste0(\"^\", state_abbrev)))\n  \n  # Build plot\n  p &lt;- ggplot() +\n    geom_sf(\n      data = state_sf,\n      fill = state_sf$colour, color = state_sf$colour\n    ) +\n    geom_sf_text(  # overlay state abbrev\n      data = state_sf, aes(label = state_cdm),\n      size = 5, color = \"white\"\n    ) +\n    theme_map()\n  \n  # Provide a \n  if (state_abbrev == \"NE\") {\n    p &lt;- p + labs(title = \"Nebraska\")\n  } else if (state_abbrev == \"ME\"){\n    p &lt;- p + labs(title = \"Maine\")\n  }\n  \n  return(p)\n  \n}\n\n# Arrange plots side-by-side with {patchwork}\nplot_state(\"NE\") + plot_state(\"ME\")\n\n\n\n\nNote that the districts arenâ€™t necessarily placed in geographically-accurate locations within each state, relatively speaking. But thatâ€™s okay, because the tilegram is not an accurate representation of geography anyway."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#development",
    "href": "posts/2020-11-21-president-tilemap/index.html#development",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Development",
    "text": "Development\nIâ€™ve chosen to keep these maps very simple, partly for the aesthetics, but also because the purpose is to communicate the share of electoral college votes with minimal distraction.\nYou could do a number of other things to provide further information, like label states with geom_sf_text(), colour the tiles by vote share rather than outright winner, or make it interactive with the {leaflet} package and include mouseovers to show a full breakdown of results."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#other-solutions",
    "href": "posts/2020-11-21-president-tilemap/index.html#other-solutions",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Other solutions",
    "text": "Other solutions\nYou can find many, many examples of cartograms or other map types used to display the presidential election results. For example, check out:\n\nThe Wall Street Journal has a square version of the hexagonal map in this post\nThe Financial Times shows a regular map with each stateâ€™s electoral college contribution overlaid as squares\nThe BBC and Reuters have a regular map with the option to switch to a cartogram with one square per state\n\nLet me know if you seen any particularly good examples."
  },
  {
    "objectID": "posts/2020-11-21-president-tilemap/index.html#environment",
    "href": "posts/2020-11-21-president-tilemap/index.html#environment",
    "title": "The US electoral college with {tilegramsR}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-18 20:56:59 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] patchwork_1.1.2  ggthemes_4.2.4   ggtext_0.1.2     ggplot2_3.4.2   \n[5] tilegramsR_0.2.0 sf_1.0-14        stringr_1.5.0    dplyr_1.1.2     \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3         generics_0.1.3     class_7.3-22       xml2_1.3.5        \n [5] KernSmooth_2.23-21 stringi_1.7.12     digest_0.6.31      magrittr_2.0.3    \n [9] evaluate_0.21      grid_4.3.1         fastmap_1.1.1      jsonlite_1.8.7    \n[13] e1071_1.7-13       DBI_1.1.3          purrr_1.0.1        fansi_1.0.4       \n[17] scales_1.2.1       cli_3.6.1          rlang_1.1.1        units_0.8-2       \n[21] commonmark_1.9.0   munsell_0.5.0      withr_2.5.0        yaml_2.3.7        \n[25] tools_4.3.1        colorspace_2.1-0   vctrs_0.6.3        R6_2.5.1          \n[29] proxy_0.4-27       lifecycle_1.0.3    classInt_0.4-9     htmlwidgets_1.6.2 \n[33] pkgconfig_2.0.3    pillar_1.9.0       gtable_0.3.3       glue_1.6.2        \n[37] Rcpp_1.0.11        xfun_0.39          tibble_3.2.1       tidyselect_1.2.0  \n[41] rstudioapi_0.15.0  knitr_1.43.1       farver_2.1.1       htmltools_0.5.5   \n[45] rmarkdown_2.23     compiler_4.3.1     markdown_1.7       gridtext_0.1.5"
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#tldr",
    "href": "posts/2022-01-19-keypress/index.html#tldr",
    "title": "Impress with {keypress} minigames",
    "section": "tl;dr",
    "text": "tl;dr\nThe {keypress} R package by GÃ¡bor CsÃ¡rdi records input from a simple keyboard-button press. You can use this to control games, like the ones in the tiny {hokey} package."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#whaddup-gamers",
    "href": "posts/2022-01-19-keypress/index.html#whaddup-gamers",
    "title": "Impress with {keypress} minigames",
    "section": "Whaddup gameRs?",
    "text": "Whaddup gameRs?\nIâ€™ve made some silly games in R using the {R6} package for encapsulated OOP. For example:\n\n{ActionSquirrel} a 2D action-adventure game (blog, source)\n{safar6} a text-based recreation of PokÃ©monâ€™s Safari Zone (blog, source)\nan â€˜Automatic Bell Dispenserâ€™ to mimics the cash machine used in Animal Crossing: New Horizons (blog)\n\nIn {ActionSquirrel} you move a character around a 2D grid. Problem (kinda): to go up you type x$move(\"up\"), which means â€˜apply the move method to the previously-initialised R6 object called x, and supply to the where argument the direction \"up\"â€™. A bit long-winded, eh?\nIt would be more natural to provide a single keyboard input to a game scenario, so a left-arrow press moves the player to the left, right? Right.1"
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#record-inputs",
    "href": "posts/2022-01-19-keypress/index.html#record-inputs",
    "title": "Impress with {keypress} minigames",
    "section": "Record inputs",
    "text": "Record inputs\nSure, Râ€™s readline() can take user input, but you would literally have to type l, e, f, t and Enter, because the function doesnâ€™t recognise key presses directly.\nThis is where GÃ¡bor CsÃ¡rdiâ€™s {keypress} package comes in. It accepts a single button press from the keyboard, including the arrow keys. Itâ€™s available on CRAN:\n\ninstall.packages(\"keypress\")\nkey &lt;- keypress::keypress()  # up arrow pressed\nkey\n\n\"up\"\n{keypress} works in the terminal but doesnâ€™t work everywhere, such as RStudio. Use keypress::has_keypress_support() to see if itâ€™s supported by the console youâ€™re using. See the package README for details of the platforms supported and the keys that are accepted as input."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#minigames",
    "href": "posts/2022-01-19-keypress/index.html#minigames",
    "title": "Impress with {keypress} minigames",
    "section": "Minigames",
    "text": "Minigames\nI thought Iâ€™d try out with {keypress} with three tiny interactive games, which Iâ€™ve bundled into a pico package2 called {hokey}.\n\nremotes::install_github(\"matt-dray/hokey\")\n\nEach one takes a keypress input from keypress::keypress() to affect the game, which is just a bunch of if or while statements, basically. You can see the functions in the {hokey} package itself, if youâ€™re a nerd.3\nThe games in order of complexity:\n\ntype(), a test of typing skills\nadventure(), a 2D side-scrollling adventure\nbattle(), a clicker-style monster smasher\n\nThese arenâ€™t properly documented ot tested or anything. Theyâ€™re just for demoâ€™s sake.\nThe rest of this post describes the games with a dash of dry humour.\n\n1. Typing test\nHow fast you can you type randomly-selected letters?\nIn the type() game a countdown will begin and then youâ€™ll be prompted to type one letter at a time, the total number of which can be controlled with the n argument.\nHereâ€™s what a completed game might look like, where each letter is revealed sequentially after typing the previous one.\n\nhokey::type(n = 5)\n\n3... 2... 1... Go!\nPress 'r'! Hit!\nPress 'o'! Hit!\nPress 'f'! Hit!\nPress 'l'! 'h'? Miss!\nPress 'z'! Hit!\nEnd! 4/5 in 5.403 seconds.\nYes, three decimal places in the elapsed time so that people can be more easily ranked on speedruns.com.\n\n\n2. An adventure\nYouâ€™ve played 2D games (e.g.Â Mario). Youâ€™ve played 2.5D games (e.g.Â Mario). Youâ€™ve played 3D games (e.g.Â Mario).\nYouâ€™re thinking the future is four-dimensional Mario. But youâ€™re wrong.\nInstead, hokey::adventure() explores the full power of moving along a one-dimensional line.\nTake control of the hero. Which is a dot. Move around the overworld. Which is a line. Simulate the lustrous points of Lineland from Edwin A Abbottâ€™s Flatland!\n\nhokey::adventure(len = 10)\n\nPress left/right arrow keys\n--.------- \nBelow is a demo of what happens if you start the game and travel to the dangerous lands of the west (two left-key presses, resulting in you being bumped back on course), before heading for the utopian kingdom in the east (multiple right-key presses).\nThe symbol to the right of the line explains whatâ€™s happened (&lt; is left, &gt; is right, x is an illegal move, ! is a win).\nPress left/right arrow keys\n--.------- \n-.-------- &lt; \n.--------- x \n-.-------- &gt; \n--.------- &gt; \n---.------ &gt; \n----.----- &gt; \n-----.---- &gt; \n------.--- &gt; \n-------.-- &gt; \n--------.- &gt; \n---------. ! \nSuch graphics! Such dimensions!\n\n\n3. A clicker\nEver heard of Cookie Clicker? Itâ€™s a game where you click. A cookie. A whole bunch of times. Like, seriously, a whole bunch of times. Why? To win, of course.\nHere instead is a â€˜presserâ€™, where where you tap keys to vanquish randomised foes. Are there upgrades? No.Â Are there cool sprites? Not really. But do you click a lot? Also no, but you get to press buttons a lot.\nSo, initiate a battle with hokey::battle() and youâ€™re faced with monstrous foes, who have terrifying randomised faces made of letters and symbols.\n\nhokey::battle(n = 3)\n\nNEW FOE! { O _ O } 10 HP \nSmash a key (I recommend Enter because of its large surface area) to deplete the foeâ€™s hit points (HP) until theyâ€™re defeated. Each hit is printed as a period.\nNEW FOE! { O _ O } 10 HP \n..........\nVICTORY! { x _ x }  0 HP\nIncrementally more powerful foes will appear!\nNEW FOE! | - o - | 20 HP \n....................\nVICTORY! | x o x |  0 HP\n\nNEW FOE! [ ' v ' ] 30 HP \n..............................\nVICTORY! [ x v x ]  0 HP\nYou know theyâ€™re beaten because their eyes become crosses."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#game-over",
    "href": "posts/2022-01-19-keypress/index.html#game-over",
    "title": "Impress with {keypress} minigames",
    "section": "Game over",
    "text": "Game over\nChallenging. A test of wits. Worth your time.\nAll are phrases that do not sum up the games of {hokey}.\nBut, for me at least, Iâ€™ve got a better understanding of how {keypress} could be used for games written in R, a burgeoning field in the world of R programming.4\nLet me know how much you enjoyed these games and how much itâ€™s going to suck to go back to your cutting-edge Neo Geo or Master System or whatever the kids are playing these days."
  },
  {
    "objectID": "posts/2022-01-19-keypress/index.html#environment",
    "href": "posts/2022-01-19-keypress/index.html#environment",
    "title": "Impress with {keypress} minigames",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:38 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] keypress_1.3.0\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html",
    "href": "posts/2023-05-07-bd2q/index.html",
    "title": "Automate {blogdown} to Quarto",
    "section": "",
    "text": "gRaPhIc DeSiGn Is My PaSsIoN."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#tldr",
    "href": "posts/2023-05-07-bd2q/index.html#tldr",
    "title": "Automate {blogdown} to Quarto",
    "section": "tl;dr",
    "text": "tl;dr\nIâ€™ve written a quick R package, {bd2q}, to help me convert my {blogdown} blog to Quarto. Whether Iâ€™ll actually complete the conversion is another story."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "href": "posts/2023-05-07-bd2q/index.html#upside-blogdown",
    "title": "Automate {blogdown} to Quarto",
    "section": "Upside blogdown",
    "text": "Upside blogdown\nIt is destiny: no-one is ever completely happy with their blog.\nThis site was built five years ago1 with {blogdown}, which lets you write R Markdown files and have them knitted into a blog. I ignored the newer {distill} package2, but Quarto may be worth the switch. Itâ€™ll let me simplify the blogâ€™s structure3 and take advantage of Quartoâ€™s snazzy features4.\nBut I didnâ€™t fancy transferring and editing ~150 posts by hand, so Iâ€™ve written a few functions to help out."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "href": "posts/2023-05-07-bd2q/index.html#when-in-doubt-make-a-package",
    "title": "Automate {blogdown} to Quarto",
    "section": "When in doubt, make a package",
    "text": "When in doubt, make a package\nAnd so the {bd2q} R package5 is available from GitHub. It does what I need it to do for now, but note it only has basic error checking, has no unit tests, etc. Use at own risk, etc. Itâ€™s likely to remain unpolished forever, but feel free to add issues or pull requests. To install:\n\ninstall.packages(\"remotes\")  # if not yet installed\nremotes::install_github(\"matt-dray/bd2q\")\n\nThree things were in scope for this package:\n\nCreate a template Quarto blog.\nCreate the necessary Quarto folder structure for posts, then transfer posts and resources from the old {blogdown} blog.\nTweak the posts to remove or replace selected lines.\n\n\n1. Quarto blog template\nI assume someone has already written a version of usethis::create_project() for creating a Quarto blog. Regardless, Iâ€™ve written bd2q::create_template() to generate a folder with the minimal structure required, which makes my life easier for testing purposes.\n\nbd2q::create_template(q_path = \"~/new-quarto-blog\")\n\nâœ” Created template Quarto blog at /Users/mattdray/new-quarto-blog\nThe skeleton content is opinionated and differs a bit to the one generated through RStudioâ€™s â€˜new projectâ€™ menu, for example, but the structure is the same:\nblog\nâ”œâ”€â”€ about.qmd\nâ”œâ”€â”€ index.qmd\nâ”œâ”€â”€ posts/\nâ”‚   â””â”€â”€ metadata.yml\nâ”œâ”€â”€ styles.css\nâ””â”€â”€ blog.rproj\nOf course, now we need to pull in the posts from the old {blogdown} blog.\n\n\n2. Transfer posts and resources\nTypically in a {blogdown} blog, all R Markdown posts and their rendered HTML files are stored together in content/post/ in the form YYYY-MM-DD-post-name.Rmd and YYYY-MM-DD-post-name.html. Resources, like images, live separately in static/post/ with a folder per post in the form YYYY-MM-DD-post-name_files/.\nHereâ€™s a simplified folder structure that focuses on a single post and its resources:\nblog/\nâ”œâ”€â”€ content/\nâ”‚   â””â”€â”€ post/\nâ”‚       â”œâ”€â”€ YYYY-MM-DD-post-name.Rmd\nâ”‚       â””â”€â”€ YYYY-MM-DD-post-name.html\nâ””â”€â”€ static/\n    â””â”€â”€ post/\n        â””â”€â”€ YYYY-MM-DD-post-name_files/\n            â””â”€â”€ image.png\nQuarto simplifies this structure. Each post gets its own folder in posts/, like YYYY-MM-DD-post-name, which contains the post as index.qmd and a folder of resources. This means the post and all its content are stored together in one containing folder.\nblog/\nâ””â”€â”€ posts/\n    â””â”€â”€ YYYY-MM-DD-post-name/\n        â”œâ”€â”€ index.qmd\n        â””â”€â”€ resources/\n            â””â”€â”€ image.png\nTo do the conversion, bd2q::transfer_posts() copies posts from a {blogdown} blog structure to a Quarto blog structure, setting up the required folders and renaming each post to index.qmd.\n\ntransfer_posts(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\"\n)\n\nâœ” Created posts/ directory structure.\nâ„¹ Copying posts.\nâœ” Copied 148 posts to /Users/mattdray/new-quarto-blog.\nOnce thatâ€™s been run, bd2q::transfer_resources() can copy each postâ€™s resources into an accompanying subfolder, which defaults to the name â€˜resourcesâ€™. You can choose which file types you want transfer with the exts_keep argument.\n\ntransfer_resources(\n  bd_path = \"~/old-blogdown-blog\",\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  exts_keep = c(\"gif\", \"jpg\", \"jpeg\", \"png\", \"svg\", \"wav\"),\n)\n\nâ„¹ Copying resources.\nâœ” Copied 455 resources to each post's resources/ folder in Users/mattdray/new-quarto-blog/posts.\nOf course this doesnâ€™t account for everything, like bits of JavaScript and CSS related to the use of htmlwidgets. Iâ€™m not really bothered about this, because these should be recreated when I re-render each post.\nNote that you can use bd2q::create_and_transfer() if you want to run create_template(), transfer_posts() and transfer_resources() all at once. Regardless, once youâ€™ve got the structure sorted, you can begin to adjust the posts if you need to.\n\n\n3. Tweak post content\nThereâ€™s content in the body of each post that I want to get rid of or make more Quarto-like. I made a few functions that iterate over all the index.qmd files and replace or remove certain content.\nOne obvious necessity is to rebuild the resource paths (to images, sound files, etc), which can be done specifically with bd2q::update_resource_paths(). It defaults to creating paths to each postâ€™s â€˜resourcesâ€™ subfolder, as generated by bd2q::transfer_resources(). For example, you could use a regular expression to match rows you know will contain a resource path and have them updated for the new Quarto folder structure (I tend to insert images with HTML rather than Markdown, hence the &lt;img&gt; tag in the example below).\n\nupdate_resource_paths(\n  q_path = \"~/new-quarto-blog\",\n  resources_dir = \"resources\",\n  resource_rx = \"&lt;img src=\"\n)\n\nâ„¹ Updating posts.\nâœ” 148 posts updated.  \nI also added two replace/remove functions that are a little more generic.\nThe first is bd2q::remove_line(), which deletes a single line from each post based on a provided regular expression. When I was messing around with converting the blog to Quarto manually, I found that the presence of the â€˜draftâ€™ status in the YAML header would prevent the post from appearing on the homepage, even if was set to â€˜noâ€™. As a result, you can run something like this to find and remove the lines that start with â€˜draftâ€™:\n\nbd2q::remove_line(\n  q_path = \"~/new-quarto-blog\",\n  detect_rx = \"^draft:\"\n)\n\nâ„¹ Making corrections.\nâœ” Removed lines matching the regular expression '^draft:' from 128 out of 148 posts.\nThatâ€™s fine for individual lines, but what if you have a sequence of consecutive lines that you want to find and remove, or replace with some other text?\nThatâ€™s what bd2q::replace_lines() does. Provide a vector of strings that exactly match some consecutive lines in each post, then provide a vector of strings to replace them with (or NULL to simply remove them)6.\nThis addresses another specific problem I was having. I wanted to update my custom session-info blocks at the bottom of each post so that they instead appear as a Quarto â€˜appendixâ€™. That can be done like this:\n\nold_lines &lt;- c(\n  \"---\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r eval=TRUE, sessioninfo, echo=FALSE}\",\n  \"sessioninfo::session_info()\",\n  \"```\",\n  \"&lt;/details&gt;\"\n)\n\nnew_lines &lt;- c(\n  \"## Details {.appendix}\",\n  \"&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;\",\n  \"```{r}\",\n  \"#' eval = TRUE,\",\n  \"#' echo = FALSE\",\n  'cat(\"Date:\", cat(format(Sys.time(), format = \"%Y-%m-%d\")), \"\\n\\n\"); sessionInfo()',\n  \"```\"\n)\n\nbd2q::replace_lines(\n  q_path = \"~/new-quarto-blog\",\n  match_str = old_lines,\n  replacement_str = new_lines\n)\n\nâ„¹ Making corrections.\nâœ” Removed lines matching the provided string vector from 9 out of 148 posts.   \nHaha, uhoh, I was expecting to have fixed more posts than that! Looks like I might have written my custom session-info block slightly differently in each post (maybe an extra space or empty line?), so Iâ€™ll have to run the bd2q::replace_lines() multiple times to make sure I can replace it in each post that it appears."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "href": "posts/2023-05-07-bd2q/index.html#actually-use-the-package-pfft",
    "title": "Automate {blogdown} to Quarto",
    "section": "Actually use the package? Pfft!",
    "text": "Actually use the package? Pfft!\nSo, is {bd2q} objectively good? No.Â Does it do what I personally want it to do? Absolutely. Mostly. Yeah?\nOf course, transferring files into a new structure is the easy part. The hard part is to see if each post will still re-render after all these years. Itâ€™s unlikely! Thereâ€™s no dependency management in this blog because there was no easy easy to do it. Quarto, meanwhile, has the ability to â€˜freezeâ€™ posts and link each post to a {renv} lockfile (thanks Albert) that captures each postâ€™s package dependencies.\nThere are some other dependencies outside of packages though. For example, I have posts that use the {rtweet} package to fetch tweets from Twitter, but Twitter is a garbage fire and I may never be able to fetch tweets from the API in future. I may have to just copy-paste the outputs that were created when the post was originally rendered, oh well.\nTo be clear: this is hard work. I may not be brave enough to do it any time soon. Iâ€™ve set up a GitHub repo for â€˜rostrum-blog-2â€™ where Iâ€™ve been experimenting with styles and structure, so if I ever get round to this task then thatâ€™s where the fireworks will be happening.\nAnd hey, at worst I got more familiar with the {fs} and {cli} packages when making {bd2q}, which are for â€˜tidyâ€™ path handling and nice user interfaces. A convoluted way to learn!\nBut thatâ€™s what this blog is all about, amirite."
  },
  {
    "objectID": "posts/2023-05-07-bd2q/index.html#environment",
    "href": "posts/2023-05-07-bd2q/index.html#environment",
    "title": "Automate {blogdown} to Quarto",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-06-29 15:25:33 CEST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] bd2q_0.0.0.9000\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43.1      jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#tldr",
    "href": "posts/2022-01-14-wordle/index.html#tldr",
    "title": "Wordle, twirdle and eldrow",
    "section": "tl;dr",
    "text": "tl;dr\nTwo toy R functions for playing with Wordle results: twirdle() extracts gameplay data from tweets, and eldrow() finds potential prior guesses given the answer.\n\n Note\nThe Twitter API is pretty borked as of mid-2023, so the functions in this post are unlikely to work anymore."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#whats-the-wordle",
    "href": "posts/2022-01-14-wordle/index.html#whats-the-wordle",
    "title": "Wordle, twirdle and eldrow",
    "section": "Whatâ€™s the Wordle?",
    "text": "Whatâ€™s the Wordle?\nNothing is more zeitgeisty right now than Wordle, a once-a-day web-based five-letter-word-guessing puzzle-logic game.\nThe app lets you copy your results in a consistent format for pasting into a tweet or whatever.\n\nIt begins with a string of meta information, â€˜Wordle X Y/Zâ€™, where X is the edition number, Y is the attempts taken and Z is the maximum allowed guesses. Then thereâ€™s a grid of coloured emoji squares, where each row represents a guessed word and each emoji a letter.\nGreen emojis (orange in colorblind mode) represent a letter in the correct place, yellow (blue in colorblind mode) in the wrong place and white for an incorrect letter (or black if playing in dark mode). The emojis obscure your guesses so that people can see how well you did without spoiling the answer.\nFolks have already put together some neat R tools, like solvers and ways to play in the console or in other languages. See mikefcâ€™s {wordle} R package and PachÃ¡â€™s Shiny app, for example."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#wordle-up",
    "href": "posts/2022-01-14-wordle/index.html#wordle-up",
    "title": "Wordle, twirdle and eldrow",
    "section": "Wordle up",
    "text": "Wordle up\nSurprise: I havenâ€™t actually played the game.1\nBut that didnâ€™t stop me from writing a couple of modest functions to practice my regex and base-R skills: twirdle() and eldrow().2\nAs ever, I can call them â€˜toyâ€™ functions and get away without proper error-checking and code optimisation.\n\ntwirdle\nThe consistent Wordle template makes it straightforward to extract peopleâ€™s results from tweets. Iâ€™ve made the twirdle() function to do this.3\ntwirdle() makes use of regular expressions and functions like regmatches() and regexpr() to extract:\n\nthe Wordle edition number, e.g.Â â€˜206â€™\nthe attempts required, e.g.Â â€˜4â€™, but also failures symbolised with â€˜Xâ€™\nthe maximum allowed attempts (max), i.e.Â â€˜6â€™\nwhether the user was playing in light or dark mode\nwhether the user was using colorblind mode\na string of characters representing the emoji grid, e.g.Â \"YG----G-GYGGGGG\", to symbolise a correct guess (i.e.Â a Green emoji), a correct letter but in the wrong place (i.e.Â Yellow), and a miss (-)\nthe tweet status_id so you can visit the original tweets\n\n\nCode\n\n\nClick for the full twirdle() function definition\n\n\ntwirdle &lt;- function(tweets) {\n  \n  g   &lt;- \"\\U1F7E9\"\n  o   &lt;- \"\\U1F7E7\"\n  y   &lt;- \"\\U1F7E8\"\n  blu &lt;- \"\\U1F7E6\"\n  bla &lt;- \"\\U2B1B\"\n  w   &lt;- \"\\U2B1C\"\n  \n  rx_all   &lt;- paste(g, o, y, blu, bla, w, sep = \"|\")\n  rx_right &lt;- paste(g, o, sep = \"|\")\n  rx_place &lt;- paste(y, blu, sep = \"|\")\n  rx_wrong &lt;- paste(bla, w, sep = \"|\")\n  rx_color &lt;- paste(o, blu, sep = \"|\")\n\n  tweets$meta &lt;- regexpr(\n    \"Wordle \\\\d{1,} [\\\\d{1}|X]/\\\\d{1}\",\n    tweets$text,\n    perl = TRUE\n  )\n  \n  tweets$meta &lt;- setNames(\n    tweets$meta, \n    ifelse(tweets$meta &lt; 0, FALSE, TRUE)\n  )\n  \n  tweets$meta &lt;- ifelse(\n    names(tweets$meta),\n    regmatches(tweets$text, tweets$meta),\n    NA_character_\n  )\n  \n  tweets &lt;- tweets[!is.na(tweets$meta), ]\n  \n  tweets$edition &lt;- as.numeric(\n    regmatches(\n      tweets$meta, \n      regexpr(\"\\\\d{1,}\", tweets$meta)\n    )\n  )\n  \n  tweets$attempts &lt;- regmatches(\n    tweets$meta,\n    regexpr(\"[\\\\d{1}|X](?=/)\", tweets$meta, perl = TRUE)\n  )\n  \n  tweets$attempts &lt;- ifelse(\n    tweets$attempts == \"X\",\n    NA_character_,\n    tweets$attempts\n  )\n  \n  tweets$attempts &lt;- as.numeric(tweets$attempts)\n  \n  tweets$allowed &lt;- as.numeric(\n    regmatches(\n      tweets$meta, \n      regexpr(\"(?&lt;=/)\\\\d{1}\", tweets$meta, perl = TRUE)\n    )\n  )\n  \n  tweets$grid &lt;- regmatches(\n    tweets$text, \n    gregexpr(rx_all, tweets$text) \n  )\n  \n  tweets$grid &lt;- lapply(\n    tweets$grid, \n    function(x) paste(x, collapse = \"\")\n  )\n  \n  tweets$colorblind &lt;- ifelse(\n    grepl(rx_color, tweets$grid), TRUE, FALSE\n  )\n  \n  tweets$mode &lt;- ifelse(\n    grepl(bla, tweets$grid), \"dark\",\n    ifelse(grepl(w, tweets$grid), \"light\", \"unknown\")\n  )\n  \n  tweets$grid &lt;- gsub(rx_right, \"G\", tweets$grid)\n  tweets$grid &lt;- gsub(rx_place, \"Y\", tweets$grid)\n  tweets$grid &lt;- gsub(rx_wrong, \"-\", tweets$grid)\n  \n  tweets[, c(\"edition\", \"attempts\", \"allowed\", \"mode\",\n             \"colorblind\", \"grid\", \"status_id\")]\n  \n}\n\n\nI also put the code for the function in a GitHub Gist.\n\n\nExample\nTo give an example of twirdle() in action, letâ€™s first grab a small number of tweets using the {rtweet} package by Mike Kearney. I think itâ€™s best to supply the query string of search_tweets() with the word â€˜Wordleâ€™ and at least one white or black emoji (signifying an incorrect letter).4\n\ntweets &lt;- rtweet::search_tweets(\n  q = \"Wordle \\U2B1B OR \\U2B1C\",\n  n = 10,  # return 10 tweets\n  include_rts = FALSE  # no retweets\n)\n\nAnd now we can pass the returned dataframe of tweets to twirdle(). It outputs a row per tweet, but there may be fewer tweets than we asked for because the content doesnâ€™t conform to the output provided by Wordle. Sometimes people add their own comments into the results, disrupting the expected format. Thereâ€™s also a Spanish version that has â€˜(ES)â€™ in the meta information that weâ€™re going to exclude for our purposes.\nNote that anyone who didnâ€™t complete the puzzle in six tries gets a score of â€˜X/6â€™, which is returned as NA_real_ in the attempts column.\n\ntwirdle(tweets)\n\n# A tibble: 7 Ã— 7\n  edition attempts allowed mode  colorblind grid                 status_id      \n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;      &lt;chr&gt;                &lt;chr&gt;          \n1     213        5       6 light FALSE      GY--YGGG--GGG--GGG-â€¦ 14834445690229â€¦\n2     213        3       6 dark  FALSE      Y-----YY--GGGGG      14834445680161â€¦\n3     213        6       6 dark  FALSE      --Y-----YG-G--G--G-â€¦ 14834445678988â€¦\n4     213        6       6 light FALSE      -----Y------Y-G-G--â€¦ 14834445674540â€¦\n5     213       NA       6 light FALSE      ---Y---G-YGGG--GGG-â€¦ 14834445662083â€¦\n6     213        5       6 dark  FALSE      -G------YYGGG--GGG-â€¦ 14834445661120â€¦\n7     213        3       6 dark  FALSE      ----Y--GY--GG--GGG-â€¦ 14834445648075â€¦\nYou could use this to do a number of things, like calculate the mean number of attempts for each dayâ€™s puzzle, look for guess patterns at scale, or maybe see whether dark-mode users are more skilled than light-mode users.\n\n\n\neldrow\nOf course, the whole purpose of sharing an encoded emoji grid is to prevent spoilers. No-one reading your result can see the answer or your guesses.\nBut, if you do know the answer, could you backwards-engineer prior guesses from the emoji grid?\nIntroducing eldrow(),5 which does exactly this with some help from mikefcâ€™s {wordle} package for filtering from the Wordle wordlist.6\nYou pass to it the answer and the encoding of the last guess in the form \"Y-GY-\". As per the twirdle() output, the characters G, Y and - refer to a letter in the right place, wrong place, or not in the word. The function returns a vector of all the possible words given the guess and the answer.\nOne thing it doesnâ€™t deal with is whether people are playing in â€˜hard modeâ€™, where â€˜any revealed hints must be used in subsequent guessesâ€™. I think you could infer if someone was playing this way, but you could never be completely sure.\n\nCode\n\n\nClick for the full eldrow() definition\n\n\neldrow &lt;- function(guess, answer, words = wordle::wordle_dict){\n  \n  answer &lt;- tolower(answer)\n  guess &lt;- toupper(guess)\n  \n  guess_chars &lt;- strsplit(guess, \"\")[[1]]\n  answer_chars &lt;- strsplit(answer, \"\")[[1]]\n  \n  exact &lt;- ifelse(guess_chars == \"G\", answer_chars, \".\") |&gt;\n    paste0(collapse = \"\")\n  \n  wrong_spot &lt;- gsub(\n    \"\\\\.\", \"\", ifelse(guess_chars == \"Y\", answer_chars, \".\")\n  )\n  \n  exact_chars &lt;- regmatches(exact, gregexpr(\"\\\\w\", exact))[[1]]\n  correct_chars_table &lt;- table(\n    c(exact_chars, wrong_spot[wrong_spot != \"\"])\n  )\n  min_count &lt;- as.vector(correct_chars_table)\n  names(min_count) &lt;- names(correct_chars_table)\n  \n  possibles &lt;- wordle::filter_words(\n    words, exact, wrong_spot, min_count, min_count\n  )\n  \n  possibles &lt;- possibles[which(possibles != answer)]\n  possibles[order(possibles)]\n  \n}\n\n\nI also put the code for this in a GitHub Gist.\n\n\nExample\nSo, letâ€™s say someone took three attempts at the word â€˜shirtâ€™7 and their first and second guesses gave encodings of \"YGG--\" then \"-GGG-\".\nWe can start by passing the answer and the encoding for the prior guess.\n\nguess_2 &lt;- eldrow(guess = \"-GGG-\", answer = \"shirt\")\nguess_2\n\n [1] \"chirk\" \"chirl\" \"chirm\" \"chiro\" \"chirp\" \"chirt\" \"chiru\" \"shire\" \"shirk\"\n[10] \"shirs\" \"third\" \"thirl\" \"whirl\" \"whirs\"\nOkay, so logicically they could have guessed any of these 14 options before their final, correct guess.\nNaturally, we can extrapolate one step further back and infer the earlier potential guesses.\nYou can iterate over these 14 possible words as the answer argument to eldrow(), setting the guess argument to the encoding for the previous attempt (i.e.Â \"YGG--\" was the first guess in our example).\n\nguesses_1_2 &lt;- lapply(\n  guess_2,\n  \\(x) eldrow(\"YGG--\", x)\n) |&gt; \n  lapply(\\(x) x[which(x != \"shirt\")]) |&gt;\n  setNames(guess_2)\n\nstr(guesses_1_2)\n\nList of 14\n $ chirk: chr \"thick\"\n $ chirl: chr \"thick\"\n $ chirm: chr \"thick\"\n $ chiro: chr \"thick\"\n $ chirp: chr \"thick\"\n $ chirt: chr \"thick\"\n $ chiru: chr \"thick\"\n $ shire: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ shirk: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ shirs: chr [1:22] \"chias\" \"chibs\" \"chics\" \"chiks\" ...\n $ third: chr [1:13] \"ahint\" \"chirt\" \"chits\" \"shift\" ...\n $ thirl: chr [1:13] \"ahint\" \"chirt\" \"chits\" \"shift\" ...\n $ whirl: chr(0) \n $ whirs: chr(0)\nThe output is a list with elements containing the potential first guesses and is named for each of the potential second guesses. So, logically, a possible set of guesses by this imaginary person was â€˜shiftâ€™ then â€˜thirdâ€™ then â€˜shirtsâ€™.\nOf course, you can eliminate any potential second guesses that failed to yield a potential first guess, like â€˜whirlâ€™ in this example.\nYouâ€™ll also notice a number of the potential first guesses are the same word. The more they appear, the more likely that word is to have been the actual starting guess, I suppose?\n\nwords &lt;- c()\nfor (i in guesses_1_2) {\n  words &lt;- c(words, i)\n}\n\ncounts &lt;- as.data.frame(\n  table(words),\n  responseName = \"n\"\n)\ncounts$total &lt;- sum(counts$n)\ncounts$percent &lt;- round(100 * (counts$n / counts$total), 1)\n\nlikeliest &lt;- counts[order(-counts$percent), ]\nrownames(likeliest) &lt;- NULL\nhead(likeliest, 3)\n\n  words n total percent\n1 thick 7    99     7.1\n2 chits 5    99     5.1\n3 whist 5    99     5.1\nSo, purely on the basis of this frequency, â€˜thickâ€™ was most likely to be the first guess in this contrived example. You might want to consider how likely someone is to actually submit some of these words, given their obscurity.8"
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#hurdle",
    "href": "posts/2022-01-14-wordle/index.html#hurdle",
    "title": "Wordle, twirdle and eldrow",
    "section": "Hurdle?",
    "text": "Hurdle?\nI hope you werenâ€™t expecting anything more from this post. Maybe consider some meme variants, like Curdle, Birdle, Tetris, or this absolute banger.\nOkay, showâ€™s over, you can stop the Wordling now."
  },
  {
    "objectID": "posts/2022-01-14-wordle/index.html#environment",
    "href": "posts/2022-01-14-wordle/index.html#environment",
    "title": "Wordle, twirdle and eldrow",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:17:30 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#tldr",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#tldr",
    "title": "Building a {r.oguelike} in R",
    "section": "tl;dr",
    "text": "tl;dr\nI started writing a roguelike game (well, more of a â€˜tech demoâ€™) in an R package called {r.oguelike}."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#rogue-like",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#rogue-like",
    "title": "Building a {r.oguelike} in R",
    "section": "Rogueâ€¦ like?",
    "text": "Rogueâ€¦ like?\nThereâ€™s loads of video game genres: beat â€™em up, platformer, rhythm, MMORPG, sports, puzzle. Have you heard of roguelikes?\nThe name is literal: theyâ€™re games that play like Rogue, a legendary dungeon-explorer from 1980 that set the bar for role-playing games.\nPerhaps most recognisably, it used ASCII text as â€˜graphicsâ€™: the player controls a character denoted by the at symbol (@), while floor tiles are made of periods (.), for example.\n\n\n\nScreenshot of Rogue via Thedarkb on Wikipedia\n\n\nThere are many interpretations of what exactly constitutes a â€˜roguelikeâ€™, one of which is the strict â€˜Berlin Interpretationâ€™1. Must-haves include:\n\nrandomly-generated dungeons (a different map every time)\npermadeath (itâ€™s game over when you die)\nturn-based battles (limitless thinking time, then one action)\ngrid-based (everything takes up one tile of space)\nnon-modal (all actions are possible at any time)\ncomplexity (rich problem solving with items, characters and interactions)\nresource management (items are limited and must be managed)\nhack â€˜nâ€™ slash (kill lots of monsters)\nexploration and discovery (find all corners of the map to solve problems)\n\nThese arenâ€™t necessarily hard and fast rulesâ€”many games have added their own twistâ€”but they provide the essence of the genre."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#like-rogue",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#like-rogue",
    "title": "Building a {r.oguelike} in R",
    "section": "Like Rogue!",
    "text": "Like Rogue!\nSo, what would it take to make a roguelike using R?\nI once made a tiny game-in-a-package called {ActionSquirrel}. You control an emoji squirrel on the R console, moving around a forest grid to collect randomly-placed nuts. Collect enough nuts to survive winter, which arrives within a certain number of turns, while avoiding a randomly-moving owl.\n\nx &lt;- ActionSquirrel::ActionSquirrel$new()\n\n\fðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ° ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸ¿ ðŸŒ³ \nðŸŒ³ ðŸ¦‰ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ ðŸŒ³ \nMoves: 0 \nNuts: 0\n\n\nThatâ€™s not far off from some of the roguelike requirements: it has randomness and permadeath, is turn-based and grid-based and has non-modality. But itâ€™s missing complexity, resource management, hack â€˜nâ€™ slash gameplay and exploration.\nAnd the aesthetic isnâ€™t particularlyâ€¦ dungeony?"
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#r.oguelike",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#r.oguelike",
    "title": "Building a {r.oguelike} in R",
    "section": "{r.oguelike}",
    "text": "{r.oguelike}\nSo I started to build an R package containing an â€˜engineâ€™ for a game in the roguelike style, called {r.oguelike}.\nYou can visit the package website or look at the source code in the GitHub repo.\n\nFor now itâ€™s just a toy to demo some possible approaches for some of the main game elements: â€˜graphicsâ€™, movement, an inventory, item use and battling.\nAs ever, everything in the package is subject to change and improvement (though I also may never finish it). Consider this a quick devlog about progress so far.2\n\nInstall (or donâ€™t)\nYou can install from GitHub to make the package available on your machine.\n\ninstall.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"matt-dray/r.oguelike\")\n\nIf you prefer, you can also play in your browser without having to install anything. Iâ€™ve set up a Binder instance of RStudio with {r.oguelike} preinstalled so you can just click the button below to launch it (it may take a moment to load):\n\n\n\nLaunch Rstudio Binder\n\n\nThis also means itâ€™s possible to play this game from your phone, lol.\n\n Note\nThe {r.oguelike} package is a work in progress and is developing at pace. Many things explained below may have been superseded or changed by the time you read this.\n\n\n\nDemo\nTop-tip: improve immersion by changing your console colour palette to dark mode, so itâ€™s like youâ€™re really inside a cave, wow.\nTo begin:\n\nr.oguelike::start_game()\n\nWhen you start, the console clears and the user interface is printed.\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . a . . # \n# . . . . . @ . # \n# # # # # # # # # \nT: 25 | HP: 10 | G: 0 | A: 0\nPress key to start\nInput: \nAt the top is a map of a dungeon room, made of floor (.) and wall (#) tiles. The room has randomly-selected dimensions from within a certain range. Within the room are randomly-placed characters and objects: the player (@), an enemy (E), and a collectible apple (a) and gold ($).\nBelow the dungeon room thereâ€™s:\n\na status/inventory bar, which gives a numeric value for Turns remaining, Hit Points, Gold and Apples3\na status message to provide information, usually to let the user know what has just happened\na prompt for the user to input a key press\n\nThe game is turn-based and begins when the user chooses a direction to move the player character. There are two methods for registering a key press:\n\npress W, A, S or D (i.e.Â up, left, down or right) and hit Enter\njust press an arrow key if your console supports {keypress} (not available in RStudio), a package from GÃ¡bor CsÃ¡rdi that I wrote about recently\n\nIn this demo, letâ€™s aim first for the apple. The apple will return us 1 HP when consumed, so itâ€™s a good idea to get it in our inventory as soon as possible. So, letâ€™s input W and Enter (or press the up arrow if {keypress} is enabled).\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . a @ . # \n# . . . . . . . # \n# # # # # # # # # \nT: 24 | HP: 10 | G: 0 | A: 0\nMoved up\nInput: \nThe console will wipe the user interface will be re-printed. Youâ€™ll notice that your character has moved up one tile, the turn counter has decreased by 1 and the status message has changed to say â€˜Moved upâ€™.\nNow we can move left to collect the apple.\n# # # # # # # # # \n# . . $ . . E . # \n# . . . . . . . # \n# . . . . @ . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 23 | HP: 10 | G: 0 | A: 1\nCollected apple (+1 A)\nInput: \nAgain, you can see the player has progressed one tile and the turn counter decreased. Youâ€™ll notice that the inventory spot for the apple increased by 1 and the status message has changed to Collected apple (+1 A) so we know what happened.\nWhat next? Letâ€™s aim for the loot, signified by $ on the map. Iâ€™ll fast-forward to show you what happens after moving left twice and up twice.\n# # # # # # # # # \n# . . @ . . E . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 19 | HP: 10 | G: 1 | A: 1\nFound gold (+1 G)\nInput: \nThe player now occupies the space where the gold was and the turn counter has decreased by 4. Youâ€™ll see that the status messages has updated to Found gold (+1 G) and the gold spot in the inventory has increased by 1, but note that the amount of gold is randomly selected from a range of possible values.\nThereâ€™s one obvious target left: the enemy character (E). So if we move right twice, weâ€™ll start an encounter.\nWhen you occupy the space of the enemy, you begin a turn-based battle. At the moment, this is actually an â€˜auto-battlerâ€™: a routine is run under-the-hood where the player and enemy trade blows until one is vanquished.\nEach character has attack and HP values. Of course, you can see that the player has 10 HP to start, but they also have attack strength of 2. The enemy character starts with a randomly selected HP value from within a range, and their attack strength is 1. The player attacks first, so will receive three points of damage from the enemy that has 4 HP, for example.\n# # # # # # # # # \n# . . . . . @ . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 12 | HP: 7 | G: 1 | A: 1\nYou win! (-3 HP)\nInput: \nSo we know we won because the status message changed to You win! and a note of how many hit points we lost: (-3 HP). Concurrently the HP in the inventory bar has reduced by that amount.\nHaving lost some HP, we can add some back by consuming the apple, an action mapped to the number 1 key on your keyboard (regardless of whether youâ€™re using {keypress} or not).\n# # # # # # # # # \n# . . . . . @ . # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# # # # # # # # # \nT: 11 | HP: 8 | G: 1 | A: 0\nAte apple (+1 HP)\nInput: \nSo we get a message Ate apple and that our hit points have increased as a result: (+1 HP). Of course, this means that the apple spot in the inventory has decreased to zero. Note that the HP maxes out at 10, so eating the apple wonâ€™t raise the HP value above that.\nThis is the end of the demo: youâ€™ve collected all the items and defeated the enemy. But I also added a lose condition, which occurs when you run out of turns.\n# # # # # # # # # \n# . . . . . . . # \n# . . . . . . . # \n# . . . . . . . # \n# @ . . . . . . # \n# # # # # # # # # \nT: 1 | HP: 8 | G: 1 | A: 0\nMoved left\nInput: a\nYou died (max turns)! Try again!\n&gt; \nThe game ends and the command prompt (&gt;) returns.\n\n\nEngine?\nThe technicals arenâ€™t much to marvel at, really, but you can take a look at the code in the GitHub repo or on the website.\nI called it an â€˜engineâ€™ earlier, but that was deceitful, lol.\nItâ€™s just a while loop that keeps running so long as the is_alive state is set to TRUE. So running out of turns sets the is_alive value to FALSE and the loop is broken.\nThe content of the loop is run after the player inputs a key press, which results in various counters being adjusted for the HP, etc. The loop concludes by printing the room with updated player locations, inventory bar and status messsage, ready for the next input.\nThe room itself is just a matrix. When you move the player, a small calculation is done to determine where the player character should be in the next iteration. Imagine the player is in the centre of a 3 by 3 room, i.e.Â theyâ€™re in position [2,2] of a matrix with x and y dimensions of 3. If they move down, thatâ€™s equivalent to adding 1 to their current position, so 5 + 1 = 6. Similarly, moving right would be equivalent to adding 3, so 5 + 3 = 8.\n\nmatrix(1:9, 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nThe code is pretty rough and you can see that the logic can start to become complicated quickly, but remember itâ€™s just a demo for now.\n\n\nObvious improvements\nThereâ€™s some obvious user-facing improvements to the features that are already in place:\n\ninteractive turn-based battles, where the user can choose what move to make (perhaps defensive moves, HP replenishment or magic)\nenemy movement, so they arenâ€™t just stationary\ndifferent enemy types, with differing â€˜AIâ€™ (random movement, â€˜chaseâ€™ player, etc) and attack/HP stats\ntraps (e.g.Â certain tiles are hidden traps, some collectible items are bogus)\nfog of war/vision cones (you canâ€™t see whatâ€™s ahead until you get there, or you can only see a certain distance around you at all times)\n\nThereâ€™s also a big-ticket item I havenâ€™t touched: randomised or procedural dungeon generation. This is quite a big task and might end up as a blog post of its own. I encourage you to watch Herbert Wolversonâ€™s talk at Roguelike Celebration 2020 for some ideas on this. At least at first, it could simply involve letting the player walk through doors to a few other rooms that contain randomised items.\nOn the back-end, Iâ€™ve so far written everything in base R; the only dependency is {keypress} to make inputs easier for consoles that support it. But thereâ€™s only so many if-else statements you can write before your brain explodes. To this end, Iâ€™m working in a branch to make use of the object-oriented approach of the {R6} packageâ€“as used in {ActionSquirrel}â€“to create general objects like enemies, rooms, etc, that should make it easier to handle and work with the elements of the game."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#the-future",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#the-future",
    "title": "Building a {r.oguelike} in R",
    "section": "The future",
    "text": "The future\nThe package will change and grow as I add stuff, so do check out the repo on GitHub for any updates that may happened since you read this post.\nObviously Iâ€™ll need some seed funding to set up my indie game company so I can begin making a cool 3D version of this. Oh, wait, mifekc is already on the case!\nAlright, nevermind. How about, erm, a roguelike-themed Wordle? Oh wait, itâ€™s already been done!\nMight just take a nap instead, to be honest.\n\n Note\nYou can now read about how Iâ€™ve generated and integrated (very simple) procedural dungeons into the package, replacing the rectangular rooms demonstrated above."
  },
  {
    "objectID": "posts/2022-04-25-r.oguelike-dev/index.html#environment",
    "href": "posts/2022-04-25-r.oguelike-dev/index.html#environment",
    "title": "Building a {r.oguelike} in R",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 18:15:40 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31        R6_2.5.1             fastmap_1.1.1       \n [4] xfun_0.39            fontawesome_0.5.1    knitr_1.43.1        \n [7] htmltools_0.5.5      rmarkdown_2.23       cli_3.6.1           \n[10] ActionSquirrel_0.1.0 compiler_4.3.1       rstudioapi_0.15.0   \n[13] tools_4.3.1          evaluate_0.21        yaml_2.3.7          \n[16] rlang_1.1.1          jsonlite_1.8.7       htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html",
    "href": "posts/2020-06-13-ghdump/index.html",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "",
    "text": "My garbage GitHub repos being dumped onto my local machine."
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#tldr",
    "href": "posts/2020-06-13-ghdump/index.html#tldr",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "tl;dr",
    "text": "tl;dr\nRun ghd_copy() from the {ghdump} package to either clone or download all the GitHub repositories for a given user. Intended for archival purposes or setting up a new computer.\nThe package comes with no guarantees and will likely be in a perpetual work-in-progress state. Please submit issues or pull requests."
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#clone-army",
    "href": "posts/2020-06-13-ghdump/index.html#clone-army",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Clone army",
    "text": "Clone army\nSituation:\n\nSometimes I get a new computer and want to clone all my repos to it\nSometimes I want to be able to archive my repos so Iâ€™m not dependent on GitHub nor any given computer\nit would be tedious to download or clone the repos one-by-one from the GitHub interface\n\nWants:\n\nTo clone (with HTTPS or SSH) or download all of my repos with one command\nBe able to unzip downloaded repos en masse if I want to\nDo all this from within R, mostly for the learning experience, but also to allow for user interactivity\n\nObservations:\n\nI donâ€™t know of a specific R function that automates mass-downloading or mass-cloning of GitHub repos\nthe {gh} package provides a lightweight GitHub API wrapper for R thatâ€™s likely to be helpful\nR has many file-handling functions that will be helpful"
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#ghdump",
    "href": "posts/2020-06-13-ghdump/index.html#ghdump",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "{ghdump}",
    "text": "{ghdump}\nThe result is that I wrote a function, ghd_copy(), that copies (clones or downloads) all the repos for a given user to a specified location. You can get it in the tiny {ghdump} package.\nThe function interacts with the GitHub API thanks to the {gh} package by GÃ¡bor CsÃ¡rdi, Jenny Bryan and Hadley Wickham, while iterating over repos comes thanks to the {purrr} package by Lionel Henry and Hadley Wickham.\n\n Update\nAs of May 2022 thereâ€™s also a handy rOpenSci package called {gitcellar}, by MaÃ«lle Salmon and Jeroen Ooms, which is for downloading an organisationâ€™s repos for archival purposes.\n\n\nGet and use\nInstall with:\n\nremotes::install_github(\"matt-dray/ghdump\")\nlibrary(ghdump)\n\nTo use the package, youâ€™ll need a GitHub account and a GitHub Personal Access Token (PAT) stored in your .Renviron file. You can do this with the following steps:\n\nusethis::browse_github_pat()  # opens browser to generate token\nusethis::edit_r_environ()     # add your token to the .Renviron\n# then restart R\n\nYou can use {ghdump} to download the repos for a specified user:\n\nghd_copy(\n  gh_user = \"matt-dray\",           # download repos for this user\n  dest_dir = \"~/Documents/repos\",  # full local file path to copy to\n  copy_type = \"download\"           # \"download\" or \"clone\" the repos\n)\n\nOr clone them:\n\nghd_copy(\n  gh_user = \"matt-dray\",\n  dest_dir = \"~/Documents/repos\",\n  copy_type = \"clone\",\n  protocol = \"https\" # specify \"https\" or \"ssh\"\n)\n\nIf you want to use the SSH protocol when cloning, you need to make sure that youâ€™ve set up your keys.\n\n\nInteractivity\nMy expectation is to use ghd_copy() infrequently and in a non-programmatic way, so Iâ€™ve made it quite interactive. This means user input is required; youâ€™ll get some yes/no questions in the console that will affect how the function runs.\nHereâ€™s an imaginary demo of the output from ghd_copy() when copy_type = \"download\":\n\nghd_copy(\"made-up-user\", \"~/Desktop/test-download\", \"download\")\n\nFetching GitHub repos for user made-up-user... 3 repos found\nCreate new directory at path ~/Desktop/test-download? y/n: y\nDefinitely download all 3 repos? y/n: y\nDownloading zipped repositories to ~/Desktop/test-download\n\ntrying URL 'https://github.com/made-up-user/fake-repo-1/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\ntrying URL 'https://github.com/made-up-user/fake-repo-2/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\ntrying URL 'https://github.com/made-up-user/fake-repo-3/archive/master.zip'\nContent type 'application/zip' length 100 bytes\n==================================================\ndownloaded 100 bytes\n\nUnzip all folders? y/n: y\nUnzipping repositories\nRetain the zip files? y/n: y\nKeeping zipped folders.\nRemove '-master' suffix from unzipped directory names? y/n: y\nRenaming files to remove '-master' suffix\nFinished downloading\nAnd now imaginary demo of the output from ghd_copy() when copy_type = \"clone\":\n\nghd_copy(\"made-up-user\", \"~/Desktop/test-clone\", \"clone\", \"ssh\")\n\nFetching GitHub repos for user made-up-user... 3 repos found\nCreate new directory at path ~/Desktop/test-clone? y/n: y\nDefinitely clone all 3 repos? y/n: y\nCloning repositories to ~/Desktop/test-clone \nCloning into 'fake-repo-1'...\nCloning into 'fake-repo-2'...\nCloning into 'fake-repo-3'...\nFinished cloning\nNote that cloning has only been tested on my own Mac OS machine at this point (June 2020) and is not guaranteed to work elsewhere yet. Please submit issues or pull requests to help improve this.\n\n\nUnder the hood\nWhat are the steps to downloading repos with ghdump::ghd_copy()? Each of the functions in this section are not exported from the package, but you can access them by prefacing with ghdump::: (the rare triple-colon operator) if you want to see their code.\nFirst, to get repo info:\n\nghd_get_repos() passes a GitHub username to gh::gh(), which contacts the GitHub API to return a gh_response object that contains info about each of that userâ€™s repos\nghd_extract_names() takes the gh_response object from ghd_get_repos() and extracts the names into a character vector\n\nThen to download (if copy_type = \"download\"):\n\nghd_enframe_urls() turns the character vector of repo names into a data.frame, with a corresponding column that contains the URL to a zip file for that repo\nghd_copy_zips() takes each zip file URL from that data frame and downloads them to the file path provided by the user\nghd_unzip() unzips the zipped repos\n\nYou can, of course, use these intermediate functions if you have slightly different needs. Maybe you want to limit the repos that are downloaded; do this by filtering the vector output from ghd_extract_names() for example.\nOr to clone (if copy_type = \"clone\"):\n\nghd_clone_multi() that iterates cloning over the repos, itself calling ghd_clone_one()"
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#why-bother",
    "href": "posts/2020-06-13-ghdump/index.html#why-bother",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Why bother?",
    "text": "Why bother?\nWhat did I learn from doing this? As if I have to explain myuself to you, lol.\n\n1. Iteration\nAside from {gh}, the package also depends on {purrr} for iterative programming.\nFor example, the gh_response object output from ghdump:::ghd_get_repos() is passed to map() with the pluck() function to extract the repo names.\nAnother example is the use of walk(), which is like map(), except we use it when the output is some â€˜side effectâ€™. By â€˜side effectâ€™, we mean that it doesnâ€™t return an R object. For example, we can walk() the unzip() function over the path to each zip file. This doesnâ€™t return anything in R; it results in some local files being manipulated.\n\n\n2. File manipulation\nR can be used to interact with files on your computer. Thereâ€™s a number of these base R functions in the package:\n\ndir.create() to create a new folder\nfile.remove() to remove a file or folder\nlist.files() and list.dirs() to return a character vector files and folders at some path\nfile.rename to change the name of a file or folder\nunzip() to unpack a zipped folder\n\n\n\n3. User input\nHow do you ask questions of your user and get answers? This interactivity is made possible by readline(). You pass it a string to prompt the user, whose return value can be stored.\nFor example, this is how it looks in the console:\n\nanswer &lt;- readline(\"Do you like pizza? \") \n\nDo you like pizza? yes\n\nanswer\n\n[1] \"yes\"\nWhere a user has written yes after the prompt on the second line.\n\n\n4. Stickers\nIâ€™ve designed a few hex stickers with the {hexSticker} package; you can see them in my â€˜stickersâ€™ GitHub repo. This time I made the sticker for {ghdump} using Dmytro Perepolkinâ€™s {bunny} package, which is a helper for the {magick} package from Jeroen Ooms. Itâ€™s a very smooth process with much flexibility."
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#this-belongs-in-a-dump",
    "href": "posts/2020-06-13-ghdump/index.html#this-belongs-in-a-dump",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "This belongs in a dump",
    "text": "This belongs in a dump\nYeah, maybe. Itâ€™s not sophisticated, but Iâ€™ve found it useful for my own specific purposes."
  },
  {
    "objectID": "posts/2020-06-13-ghdump/index.html#environment",
    "href": "posts/2020-06-13-ghdump/index.html#environment",
    "title": "Take a {ghdump} to download GitHub repos",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-19 21:36:03 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.15.0 yaml_2.3.7       \n [9] rmarkdown_2.23    knitr_1.43.1      jsonlite_1.8.7    xfun_0.39        \n[13] digest_0.6.33     rlang_1.1.1       fontawesome_0.5.1 evaluate_0.21"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-foundations/index.html",
    "href": "posts/2021-01-28-adv-r-foundations/index.html",
    "title": "Râ€™s names and values as anchovy pizza",
    "section": "",
    "text": "Queued two hours for this. Râ€™s names and values system is faster to learn, but not as delicious."
  },
  {
    "objectID": "posts/2021-01-28-adv-r-foundations/index.html#tldr",
    "href": "posts/2021-01-28-adv-r-foundations/index.html#tldr",
    "title": "Râ€™s names and values as anchovy pizza",
    "section": "tl;dr",
    "text": "tl;dr\nI bought Hadley Wickhamâ€™s Advanced R book1 to help me better understand Râ€™s quirks. Can names and values (chapter 2) be explained with a contrived pizzeria analogy?2"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-foundations/index.html#a-pizza-by-any-other-name",
    "href": "posts/2021-01-28-adv-r-foundations/index.html#a-pizza-by-any-other-name",
    "title": "Râ€™s names and values as anchovy pizza",
    "section": "A pizza by any other name",
    "text": "A pizza by any other name\nWelcome to the pizzeria. Itâ€™s called â€˜La PizzRiaâ€™ because our owner likes to code and is really lazy at puns.\n\nToppings as vectors\nOur specialty (and only!) pizza is pizza alla napoletana, which is topped with mozzarella, tomatoes and anchovies.\n\n# Create a character-vector object\nnapoletana &lt;- c(\"mozzarella\", \"tomato\", \"anchovy\")\n\nThe English version of the menu calls it â€˜Neapolitanâ€™ pizza, but itâ€™s the same thing.\n\nneapolitan &lt;- napoletana       # copy the object\nall(neapolitan == napoletana)  # they're equal\n\n[1] TRUE\n\n\nWe store our unique sets of pizza toppings in a special recipe book. If you look up â€˜napoletanaâ€™ and â€˜Neapolitanâ€™ in the bookâ€™s index, youâ€™ll see they point to the same recipe.\n\n# The {lobstr} package helps understand object structure\nlibrary(lobstr)  # after install.packages(\"lobstr\")\n\n# Get the specific object 'address' in your computer's memory\n# Both names point to the same object\nobj_addr(napoletana)  # original object\n\n[1] \"0x12383f708\"\n\nobj_addr(neapolitan)  # the copy\n\n[1] \"0x12383f708\"\n\n\nBasically, the pizzaiolos donâ€™t care: different names, same pizza. The recipe codes are the same.\n\n Advanced R, p19\nâ€œThe object, or value, doesnâ€™t have a name; itâ€™s actually the name that has a value.â€\n\n\n\n\nCopying a recipe, modifying it\nWe recently added pizza pugliese to the menu. We copied our napoletana in the recipe book and then modified it to have onions instead of anchovies.\n\npugliese &lt;- napoletana       # copy the object\nall(pugliese == napoletana)  # the objects are the same\n\n[1] TRUE\n\npugliese[[3]] &lt;- \"onion\"  # modify the third element\npugliese == napoletana    # they're no longer the same\n\n[1]  TRUE  TRUE FALSE\n\n\nWhen we look up these names in the index of our recipe book, we see that they point to different places, despite having copied the napoletana to get the pugliese.\n\n# Now the names point to different objects\n# We modified the copy, so it becomes a new object in memory\nobj_addr(napoletana)  # original object\n\n[1] \"0x12383f708\"\n\nobj_addr(pugliese)    # the modified copy\n\n[1] \"0x1238caa48\"\n\n\n\n Advanced R, p22\nâ€œThis behaviour is called copy-on-modify.â€\n\n\nSo, hereâ€™s our full pizza lineup in Italian and English.\n\napulian &lt;- pugliese  # specify English name for the pugliese\n\n# A comparison of the pizza object structures\nknitr::kable(\n  tibble::tribble(\n    ~Language, ~Name, ~`Toppings`, ~`Recipe code`, \n    \"ITA\", \"Pizza alla napoletana\", napoletana, obj_addr(napoletana),\n    \"ENG\", \"Neapolitan pizza\", neapolitan, obj_addr(neapolitan),\n    \"ITA\", \"Pizza pugliese\", pugliese, obj_addr(pugliese),\n    \"ENG\", \"Apulian pizza\", apulian, obj_addr(apulian)\n  )\n)\n\n\n\n\n\n\n\n\n\n\nLanguage\nName\nToppings\nRecipe code\n\n\n\n\nITA\nPizza alla napoletana\nmozzarella, tomato , anchovy\n0x12383f708\n\n\nENG\nNeapolitan pizza\nmozzarella, tomato , anchovy\n0x12383f708\n\n\nITA\nPizza pugliese\nmozzarella, tomato , onion\n0x1238caa48\n\n\nENG\nApulian pizza\nmozzarella, tomato , onion\n0x1238caa48\n\n\n\n\n\nPizza alla napoletana and its copy, Neapolitan pizza, point to the same recipe code.\nPizza pugliese was a copy of pizza alla napoletana, but it now points to a different recipe code. Why? An element was changed, anchovies to onions, so a new recipe code was required.\nFinally, Apulian pizza is a copy of the pizza pugliese recipe, so they both point to the same unique topping set.\n\n\nToppings as lists\nOur knowledge management system was, however, a bit inefficient: the mozzarella and tomato toppings existed twice in our recipe book; once for each pizza.\nSo we decided to update our recipe system to store each topping separately, each with its own special reference code too.\nAgain, we wrote down the pizza napoletana toppings, copied them, then switched the anchovies for onions. Like in our old system, the two pizzas differ in their third element.\n\n# Toppings now as list elements\nnapoletana &lt;- list(\"mozzarella\", \"tomato\", \"anchovy\")\npugliese &lt;- napoletana          # make a copy\nidentical(pugliese, napoletana) # they're the same\n\n[1] TRUE\n\npugliese[[3]] &lt;- \"onion\"        # make a change\nidentical(pugliese, napoletana) # now they're different\n\n[1] FALSE\n\n\nSo in the new system, each topping has its own unique ingredient code. This means both pizza recipes point to the same ingredient codes for tomato and mozzarella.\n\n# Compare addresses in memory for the lists\n# Each 'block' below is a list object (pizza)\n# Each element is a character vector (topping)\nref(napoletana, pugliese)\n\nâ–ˆ [1:0x123a362c8] &lt;list&gt; \nâ”œâ”€[2:0x125f3ccf8] &lt;chr&gt; \nâ”œâ”€[3:0x125f3ccc0] &lt;chr&gt; \nâ””â”€[4:0x125f3cc88] &lt;chr&gt; \n \nâ–ˆ [5:0x123a0e2f8] &lt;list&gt; \nâ”œâ”€[2:0x125f3ccf8] \nâ”œâ”€[3:0x125f3ccc0] \nâ””â”€[6:0x125f3cb70] &lt;chr&gt; \n\n\nBasically, our pizza names point to pizza recipes that themselves point out to toppings.\n\n Advanced R, p25\nâ€œThis list is more complex [than a vector] because instead of storing the values itself, it stores references to them.â€\n\n\nThis means we can be more efficient in storing our pizza recipes: we write down â€˜mozzarellaâ€™ and â€˜tomatoesâ€™ only once. This could become much more efficient when storing more than the two pizzas we have on La PizzRiaâ€™s menu.3\n\n\nCustomer orders as data frames\nHow do we manage orders? Wait-staff write down each order in a column, with a row for each topping.\n\n Advanced R, p26\nâ€œData frames are lists of vectors.â€\n\n\nLetâ€™s say a couple orders a pizza napoletana and a pizza pugliese.\n\n# Create a data.frame, which is a list of vectors\n# Column behaviour is vector behaviour\norder &lt;- data.frame(\n  napoletana = c(\"mozzarella\", \"tomato\", \"anchovy\"),\n  pugliese = c(\"mozzarella\", \"tomato\", \"onion\")\n)\n\norder\n\n  napoletana   pugliese\n1 mozzarella mozzarella\n2     tomato     tomato\n3    anchovy      onion\n\n\nAs we know, these pizzas both have mozzarella and tomatoes, but the third topping is different.\nBut wait: the customer who ordered the napoletana is hungry for more anchovies!\n\norder_update &lt;- order  # copy the data.frame object\norder_update[3, 1] &lt;- \"anchovy (extra)\"  # modify the new object\norder_update\n\n       napoletana   pugliese\n1      mozzarella mozzarella\n2          tomato     tomato\n3 anchovy (extra)      onion\n\n\nWe use a code reference system for our orders too and it works just like our old recipe system.\nSince one of the pizza orders was changed, our reference code for the entire order was changed too.\nThe napoletana was modified after it was copied, so the recipe code for that pizza was updated. The pugliese didnâ€™t change, so its code was maintained.\n\n# Compare the data.frame structures\n# Modified column gets new code, object gets new code\n# Second column unchanged, code stays the same\nref(order, order_update)\n\nâ–ˆ [1:0x12353cd08] &lt;df[,2]&gt; \nâ”œâ”€napoletana = [2:0x1244769d8] &lt;chr&gt; \nâ””â”€pugliese = [3:0x1244768e8] &lt;chr&gt; \n \nâ–ˆ [4:0x124a09988] &lt;df[,2]&gt; \nâ”œâ”€napoletana = [5:0x124b82f78] &lt;chr&gt; \nâ””â”€pugliese = [3:0x1244768e8] \n\n\n\n Advanced R, p26\nâ€œIf you modify a column, only that column needs to be modified.â€\n\n\nThe mozzarella is especially bountiful this year; the waiter suggests both patrons take advantage.\nThey strongly agree. The order is copied once more and the waiter modifies the â€˜cheese rowâ€™ for both pizzas.\n\norder_final &lt;- order_update  # copy the object\norder_final[1, 1:2] &lt;- \"mozzarella (extra)\"  # modify row one of both columns\norder_final\n\n          napoletana           pugliese\n1 mozzarella (extra) mozzarella (extra)\n2             tomato             tomato\n3    anchovy (extra)              onion\n\n\nAltering the cheese row means both pizza columns are copied and given new codes. Of course, the order gets a whole new code of its own because the toppings were changed.\n\n# Compare data.frame structures again\n# All columns modified, so copies made\n# data.frame and column memory locations all differ\nref(order, order_final)\n\nâ–ˆ [1:0x12353cd08] &lt;df[,2]&gt; \nâ”œâ”€napoletana = [2:0x1244769d8] &lt;chr&gt; \nâ””â”€pugliese = [3:0x1244768e8] &lt;chr&gt; \n \nâ–ˆ [4:0x125dee488] &lt;df[,2]&gt; \nâ”œâ”€napoletana = [5:0x123a316c8] &lt;chr&gt; \nâ””â”€pugliese = [6:0x123a31678] &lt;chr&gt; \n\n\n\n Advanced R, p27\nâ€œIf you modify a row, every column is modified, which means every column must be copied.â€\n\n\nBuon appetito!"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-foundations/index.html#il-conto",
    "href": "posts/2021-01-28-adv-r-foundations/index.html#il-conto",
    "title": "Râ€™s names and values as anchovy pizza",
    "section": "Il conto",
    "text": "Il conto\nSo can names and values be explained with this analogy?\nKinda? The basic premise is there: names and pizzas, names and values, etc. But itâ€™s definitely contrived. Why are wait staff writing down pizza orders in a dataframe, etc?\nIâ€™ve also deceived you with some â€˜polite fictionâ€™, in Hadleyâ€™s words. In a numeric vector, the name points to the values. In a character vector, the name actually points to a vector of pointers, which themselves reference unique character strings.\n\n Advanced R, p27\nâ€œR actually uses a global string pool where each element of a character vector is a pointer to a unique string in the pool.â€\n\n\nBut I donâ€™t think thatâ€™s a big deal for getting the point across.\nAnyway, your orderâ€™s here.\nMangia! Mangia!"
  },
  {
    "objectID": "posts/2021-01-28-adv-r-foundations/index.html#environment",
    "href": "posts/2021-01-28-adv-r-foundations/index.html#environment",
    "title": "Râ€™s names and values as anchovy pizza",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-17 22:03:15 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] lobstr_1.1.2\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     utf8_1.2.3        fastmap_1.1.1     xfun_0.39        \n [5] fontawesome_0.5.1 magrittr_2.0.3    glue_1.6.2        tibble_3.2.1     \n [9] knitr_1.43.1      pkgconfig_2.0.3   htmltools_0.5.5   rmarkdown_2.23   \n[13] lifecycle_1.0.3   cli_3.6.1         fansi_1.0.4       vctrs_0.6.3      \n[17] compiler_4.3.1    rstudioapi_0.15.0 tools_4.3.1       pillar_1.9.0     \n[21] evaluate_0.21     yaml_2.3.7        crayon_1.5.2      rlang_1.1.1      \n[25] jsonlite_1.8.7    htmlwidgets_1.6.2"
  },
  {
    "objectID": "posts/2021-09-14-wot-ldn-emojis/index.html",
    "href": "posts/2021-09-14-wot-ldn-emojis/index.html",
    "title": "Wot3LdnEmojis",
    "section": "",
    "text": "I made Wot3LdnEmojis: a London-only clone of What3Emojis using London-related emojis and very little R code.\n\n\n\n\n\n\nHover over a grid cell to get the emoji-triplet reference. Zoom and pan, change to dark mode, toggle the grid."
  },
  {
    "objectID": "posts/2021-09-14-wot-ldn-emojis/index.html#tldr",
    "href": "posts/2021-09-14-wot-ldn-emojis/index.html#tldr",
    "title": "Wot3LdnEmojis",
    "section": "",
    "text": "I made Wot3LdnEmojis: a London-only clone of What3Emojis using London-related emojis and very little R code.\n\n\n\n\n\n\nHover over a grid cell to get the emoji-triplet reference. Zoom and pan, change to dark mode, toggle the grid."
  },
  {
    "objectID": "posts/2021-09-14-wot-ldn-emojis/index.html#u-wot-m8",
    "href": "posts/2021-09-14-wot-ldn-emojis/index.html#u-wot-m8",
    "title": "Wot3LdnEmojis",
    "section": "U wot m8",
    "text": "U wot m8\nBy now youâ€™ve heard about various â€˜alternativeâ€™ location systems that split the world into a grid and assign each with a value thatâ€™s more human-interpretable than latitude and longitude. For example, Google Plus Codes and What3Words.\nThe latter has been in the news a lot.1 In the meantime, their product has spawned a raft of spoofs, like the NSFW Four Kings Map, What3Emojis and What2Numbers, lol.2\nI like What3Emojis because itâ€™s tongue-in-cheek3, yes, but they also understand the 21st Century mantra that:\n\nNo system is perfect, except for emoji.\n\nThe What3Emojis code is openly available, but of course I wondered how easy it would be to make something like this in R.\nIâ€™ve limited it to London because us Londoners arenâ€™t aware of anything outside of the M25. Read on for the how-to of this obnoxiously-named, cockney-baiting Wot3LdnEmojis system."
  },
  {
    "objectID": "posts/2021-09-14-wot-ldn-emojis/index.html#adam-n-eve-it",
    "href": "posts/2021-09-14-wot-ldn-emojis/index.html#adam-n-eve-it",
    "title": "Wot3LdnEmojis",
    "section": "Adam â€˜nâ€™ Eve it",
    "text": "Adam â€˜nâ€™ Eve it\nFirst we need to attach the {sf} package for geospatial operations; {leaflet} for interactive mapping; and {tidyverse} for data wrangling. Weâ€™ll also set a seed here for reproducible results.4\n\nlibrary(sf)\nlibrary(leaflet)\nsuppressPackageStartupMessages(library(tidyverse))\nset.seed(9002488)\n\nWe can grab the official Greater London boundary from a GeoJSON of geographic units in the UK5, which is served by the Open Geography Portal from the Office for National Statistics.\nOr we would, if the site wasnâ€™t down when I went to run this. Instead, we can use the handy JSONs hosted by Martin Chorley on GitHub. Hero.\n\nnuts_path &lt;- paste0(\n  \"https://raw.githubusercontent.com/martinjc/UK-GeoJSON/\",\n  \"master/json/eurostat/ew/nuts1.json\"\n)\n\nldn_sf &lt;- st_read(nuts_path, quiet = TRUE) %&gt;% \n  filter(NUTS112NM == \"London\")\n\nldn_sf\n\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -0.5102962 ymin: 51.28676 xmax: 0.3339957 ymax: 51.69187\nGeodetic CRS:  WGS 84\n  NUTS112CD NUTS112NM                       geometry\n1       UKI    London MULTIPOLYGON (((-0.3210316 ...\n\n\nSo, itâ€™s an sf-class object that behaves like a dataframe, but has some extra geospatial information stored in it.\nWeâ€™ve got the boundary, how do we do a grid?\nWhat3Emojis say they used â€˜gazillions of 4mÃ—4m trianglesâ€™ in their grid, but I donâ€™t have the computing power for that and I canâ€™t count that high.\nInstead, I bring you low-fidelity, massive hexagons. But hexagons are the patron shape of R users, so I think thatâ€™s okay.\n{sf} has st_make_grid() makes gridding easy. We can pass arguments for size and shape, then st_intersection() limits the grid to the area inside the London boundary only.\n\ngrid_sf &lt;- ldn_sf %&gt;% \n  st_make_grid(cellsize = 0.01, square = FALSE, flat_topped = TRUE) %&gt;% \n  st_intersection(ldn_sf)\n\nlength(grid_sf)\n\n[1] 2554\n\n\nIâ€™ve checked the length of the object so we know how many grid cells we need to label uniquely. The fewest number of emoji weâ€™ll need is therefore 14, since 14^3 is 2744.\nOf course, I have chosen emojis that at least vaguely represent London. Below Iâ€™ve added names and commented with my interpretation. Let me know if you have better ideas.\n\nldn_emo &lt;- c(\n  metro           = \"ðŸš‡\",  # the tube\n  guard           = \"ðŸ’‚\",  # Queen's Guard\n  queen           = \"ðŸ‘¸\",  # HMQE2\n  castle          = \"ðŸ°\",  # Tower of London\n  ferris_wheel    = \"ðŸŽ¡\",  # London Eye\n  bell            = \"ðŸ””\",  # Big Ben (not a clock!)\n  whale           = \"ðŸ‹\",  # Natural History Museum\n  cityscape       = \"ðŸ™ï¸\",  # Canary Wharf\n  cucumber        = \"ðŸ¥’\",  # The Gherkin\n  performing_arts = \"ðŸŽ­\",  # Theatre District\n  stadium         = \"ðŸŸï¸\",  # Wembley Stadium\n  dragon          = \"ðŸ‰\",  # City of London emblem\n  bird            = \"ðŸ¦\",  # pigeon\n  deciduous_tree  = \"ðŸŒ³\"   # London plane tree\n)\n\nDepending on your operating system, thereâ€™s a chance you might note be able to see some of these emoji. Oh no! Ah well.\nYou may also have noticed that itâ€™s utterly ridiculous to use London-related emojis to label locations in London. â€˜Where are you?â€™ â€˜London Eye, London Eye, London Eyeâ€™. â€˜Youâ€™re at the London Eye?â€™ â€˜No.â€™ Oh no! Ah well.\nAnyway, we can get all three-way combinations of these with expand.grid(), then shuffle them randomly.\n\nldn_emo_combo &lt;- expand.grid(\n  emo_a = ldn_emo, emo_b = ldn_emo, emo_c = ldn_emo\n) %&gt;% \n  sample_n(length(grid_sf)) %&gt;%\n  transmute(emo_triplet = paste(emo_a, emo_b, emo_c))\n\nldn_emo_combo$emo_triplet[1:3]\n\n[1] \"ðŸ‹ ðŸŸï¸ ðŸŒ³\"  \"ðŸš‡ ðŸ° ðŸŽ¡\" \"ðŸŸï¸ ðŸŽ­ ðŸ¥’\" \n\n\nThen itâ€™s a case of adding the emoji information into the grid_sf object, which can be done via st_df().\n\ngrid_sf_emo &lt;- grid_sf %&gt;% \n  st_sf(ldn_emo_combo) %&gt;%\n  rename(., geometry = .)\n\nhead(grid_sf_emo)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -0.1289476 ymin: 51.28676 xmax: 0.07882465 ymax: 51.29676\nGeodetic CRS:  WGS 84\n  emo_triplet                       geometry\n1     ðŸ‹ ðŸŸï¸ ðŸŒ³ POLYGON ((-0.123496 51.2868...\n2    ðŸš‡ ðŸ° ðŸŽ¡ POLYGON ((-0.114679 51.2917...\n3     ðŸŸï¸ ðŸŽ­ ðŸ¥’ POLYGON ((0.06512026 51.290...\n4    ðŸ¦ ðŸŽ¡ ðŸ‹ POLYGON ((0.07882465 51.291...\n5     ðŸŸï¸ ðŸŒ³ ðŸŽ­ POLYGON ((-0.1149681 51.291...\n6       ðŸŸï¸ ðŸŸï¸ ðŸŸï¸ POLYGON ((-0.1003241 51.296...\n\n\nYou can see the triplets have been added as an extra column so thereâ€™s one triplet per grid cell.\nTime to create the interactive map with {leaflet}, which is built up in layers.\nIâ€™ve added a light and a dark underlying map that you can toggle between6 Iâ€™ve also made the hexagons transparent with thin borders to itâ€™s easier to see the map, but you can toggle the grid on and off to help pinpoint a location.\n\nleaflet() %&gt;% \n  addProviderTiles(\"CartoDB.Voyager\", group = \"Light\") %&gt;%\n  addProviderTiles(\"CartoDB.DarkMatter\", group = \"Dark\") %&gt;%\n  addPolygons(\n    data = grid_sf_emo, group = \"Grid\", \n    color = \"grey\", weight = 1, opacity = 0.5,\n    fill = TRUE, fillOpacity = 0,\n    label = paste(grid_sf_emo$emo_triplet),\n    labelOptions = labelOptions(\n      direction = \"top\", style = list(\"font-size\" = \"35px\")\n    ),\n    highlightOptions = highlightOptions(color = \"blue\", weight = 3,)\n  ) %&gt;% \n  addLayersControl(\n    baseGroups = c(\"Light\", \"Dark\"),\n    overlayGroups = \"Grid\",\n    position = \"topright\",\n    options = layersControlOptions(collapsed = FALSE)\n  )\n\nI found:\n\nBuckingham Palace at ðŸ””ðŸ¦ðŸ¥’ (Big Ben, pigeon, gherkin)\nLeicester Square at ðŸŒ³ðŸŒ³ðŸ™ï¸ (plane tree, plane tree, Canary Wharf)\nThe Shard at ðŸ¦ðŸ‹ðŸ’‚ (pigeon, whale, guard)\nWimbledon at ðŸ’‚ðŸŒ³ðŸŸ (guard, plane tree, Wembley)\nThe Millennium Dome at ðŸ‘¸ðŸš‡ðŸ‰ (Queen, tube, dragon)\n\nLiterally minutes of fun. Of course, you shouldnâ€™t use this map for anything whatsoever, possibly not even for your own amusement. I, on the other hand, can do whatever I like."
  },
  {
    "objectID": "posts/2021-09-14-wot-ldn-emojis/index.html#environment",
    "href": "posts/2021-09-14-wot-ldn-emojis/index.html#environment",
    "title": "Wot3LdnEmojis",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-08 12:39:37 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] leaflet_2.1.2   lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [5] dplyr_1.1.2     purrr_1.0.1     readr_2.1.4     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.2   tidyverse_2.0.0 sf_1.0-13      \n\nloaded via a namespace (and not attached):\n [1] s2_1.1.4                utf8_1.2.3              generics_0.1.3         \n [4] class_7.3-22            KernSmooth_2.23-21      stringi_1.7.12         \n [7] hms_1.1.3               digest_0.6.31           magrittr_2.0.3         \n[10] timechange_0.2.0        evaluate_0.21           grid_4.3.1             \n[13] fastmap_1.1.1           jsonlite_1.8.7          e1071_1.7-13           \n[16] DBI_1.1.3               fansi_1.0.4             crosstalk_1.2.0        \n[19] scales_1.2.1            cli_3.6.1               rlang_1.1.1            \n[22] units_0.8-2             ellipsis_0.3.2          munsell_0.5.0          \n[25] withr_2.5.0             yaml_2.3.7              tools_4.3.1            \n[28] tzdb_0.4.0              colorspace_2.1-0        vctrs_0.6.3            \n[31] R6_2.5.1                proxy_0.4-27            lifecycle_1.0.3        \n[34] classInt_0.4-9          leaflet.providers_1.9.0 htmlwidgets_1.6.2      \n[37] pkgconfig_2.0.3         pillar_1.9.0            gtable_0.3.3           \n[40] glue_1.6.2              Rcpp_1.0.10             xfun_0.39              \n[43] tidyselect_1.2.0        rstudioapi_0.14         knitr_1.43.1           \n[46] htmltools_0.5.5         rmarkdown_2.23          wk_0.7.3               \n[49] compiler_4.3.1"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html",
    "href": "posts/2023-05-10-spear-ggplot2/index.html",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "",
    "text": "Theyâ€™re the same picture. Nearly."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#tldr",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#tldr",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "tl;dr",
    "text": "tl;dr\nTwo years ago I won a data-viz recreation competition run by the Royal Statistical Society (RSS) using base Râ€™s plotting. I wrote a short {ggplot2} how-to for RSSâ€™s â€˜Significanceâ€™ magazine that was never published1, so here it is now."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#recreate",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#recreate",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Recreate",
    "text": "Recreate\nThis short code walkthrough will get you started on recreating Mary Eleanor Spearâ€™s cotton plot (1952), as used in the Royal Statistical Societyâ€™s #CottonViz challenge. Weâ€™ll concentrate on the line chart for now.\n\nThe {ggplot2} package in R is a good choice, since we can build up the chart in steps: first, weâ€™ll build a basic line chart, remove unneeded elements, fix the axes and finally add the labels. It wonâ€™t look perfectly like Spearâ€™s original, but weâ€™ll get close.\nThis isnâ€™t a guide to learn {ggplot2}, so you may want to learn the basics first. Alternatively, I wrote a blog post about building Spearâ€™s entire visualisation using base R only."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#requirements",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#requirements",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Requirements",
    "text": "Requirements\nFirst, some preparation. If you havenâ€™t already, install the {ggplot2} package for plotting, {tidyr} data reshaping and {extrafont} for font handling.\n\ninstall.packages(\"ggplot2\", \"tidyr\", \"extrafont\")\n\nYou can download for free the Routed Gothic font by Darren Embry, which is a good approximation of the stencil lettering used by Spear. Installation will depend on your system, but in macOS you can simply drag the font files to the Font Book app. When you attach {extrafont} itâ€™ll fetch automatically your installed fonts (including Routhed Gothic) so you can use them in R.\n\nlibrary(extrafont)"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#tidying-up",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#tidying-up",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Tidying up",
    "text": "Tidying up\nThe cotton dataset is quite small, so we can create the dataframe ourselves. It provides information on the supply of cotton in the USA in the 1940s.\n\ncotton_raw &lt;- data.frame(\n  year           = 1942:1948,\n  us_consumption = c(11160, 9993,  9693,  9423,  10072, 9374,  7833),\n  exports        = c(1480,  1139,  2007,  3613,  3545,  1968,  4785),\n  stocks         = c(10657, 10744, 11164, 7326,  2530,  3080,  5283),\n  total_supply   = c(23297, 21876, 22864, 20362, 16147, 14422, 17901)\n)\n\nItâ€™s preferable to make the data â€˜tidyâ€™ so that thereâ€™s one row per year and consumption type, and one column for each variable. The {tidyr} package can help us pivot the data to â€˜longâ€™ format from this â€˜wideâ€™ format.\n\nlibrary(tidyr)\n\ncotton &lt;- cotton_raw %&gt;% \n  pivot_longer(\n    c(us_consumption, exports, stocks), \n    names_to = \"consumption_type\", values_to = \"boles\"\n  )\n\nhead(cotton, 4)  # preview first few rows\n\n# A tibble: 4 Ã— 4\n   year total_supply consumption_type boles\n  &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  1942        23297 us_consumption   11160\n2  1942        23297 exports           1480\n3  1942        23297 stocks           10657\n4  1943        21876 us_consumption    9993"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#how-to",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#how-to",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "How-to",
    "text": "How-to\n\nStep 1: line chart\nNow we can create a basic line chart of the data with geom_line() and set with scale_linetype_manual() a unique dashed line per group. Further arguments set the title and the typeface to be used throughout the plot, while a small tweak to theme() adjusts the titleâ€™s position.\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot() +\n  geom_line(\n    data = cotton,\n    aes(x = year, y = boles / 1000, linetype = consumption_type),\n    linewidth = 1.5\n  ) +\n  scale_linetype_manual(values = c(\"longdash\", \"dashed\", \"solid\")) +\n  labs(title = \"Millions of Boles\") +\n  theme(\n    plot.title = element_text(hjust = -0.05),\n    text = element_text(family = \"Routed Gothic\")\n  )\n\np1\n\n\n\n\n\n\nStep 2: remove features\nLetâ€™s clear away the unneeded features: the background panel, the axes titles and the legend. You can empty these with element_blank() in the theme() function.\n\np2 &lt;- p1 + \n  theme(\n    panel.background = element_blank(),\n    axis.title = element_blank(),\n    legend.position = \"none\"\n  )\n\np2\n\n\n\n\n\n\nStep 3: correct the axes\nNow we can address the axes. Use the scale_*_continuous() functions to set the axes values, limits, origin and labels. With sec.axis you can create a secondary y-axis that mirrors the first, then remove the tick labels in the theme() function. You can also put a box around the chart area with the panel.border argument.\n\np3 &lt;- p2 +\n  scale_x_continuous(\n    breaks = seq(1942, 1948, 1),\n    labels = c(\"1942\", paste0(\"'\", 43:48)),\n    expand = c(0, 0)\n  ) +\n  scale_y_continuous(\n    breaks = seq(0, 12, 2),\n    limits = c(0, 12),\n    expand = c(0, 0),\n    sec.axis = dup_axis()\n  ) +\n  theme(\n    axis.ticks = element_line(linewidth = c(0, rep(0.5, 5), 0)),\n    axis.ticks.length = unit(-0.5, \"lines\"),\n    axis.text.y.right = element_blank(),\n    panel.border = element_rect(fill = NA, linewidth = 1)\n  )\n\np3\n\n\n\n\n\n\nStep 4: labels\nThe only missing features are the labels and arrows, which can be added with the annotate() and geom_segment(), respectively. A bit of trial-and-error will help you find the correct coordinates to place these elements.\n\np4 &lt;- p3 +\n  annotate(\n    geom = \"text\",\n    x = c(1946.1, 1945.9, 1943.75),\n    y = c(10.8, 7.1, 3.2),\n    label = c(\"U. S. Consumption\", \"Carry â€“ over\\nStocks\", \"Exports\"),\n    family = \"Routed Gothic\"\n  ) +\n  geom_segment(\n    aes(\n      x = c(1945.2, 1945.3, 1944.2),\n      y = c(10.5, 7.4, 3.1),\n      xend = c(1945, 1945.1, 1944.4), \n      yend = c(9.7, 7.1, 2.8)\n    ),\n    arrow = arrow(\n      length = unit(2, \"mm\"),\n      type = \"closed\"\n    )\n  )\n\np4"
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#next-steps",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#next-steps",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Next steps",
    "text": "Next steps\nFinally weâ€™ve got a lineplot that looks pretty close to Spearâ€™s visualisation. What subtle differences do you notice, though? Try to find ways to improve them.\nNext, try to recreate the stacked-barchart from Spearâ€™s original and then arrange the plots with a main title and surrounding text labels. The {ggpattern} package may help you recreate the hatchlines on the bars and {patchwork} could help with the arrangement of the plot and text elements."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#full-base-r-alternative",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#full-base-r-alternative",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Full base R alternative",
    "text": "Full base R alternative\nFor the original challenge I used only base Râ€™s plotting system rather than {ggplot2}. This is what my submitted image looked like:\n\nYou can read more about it in the accompanying blog post and you can find the original code on GitHub."
  },
  {
    "objectID": "posts/2023-05-10-spear-ggplot2/index.html#environment",
    "href": "posts/2023-05-10-spear-ggplot2/index.html#environment",
    "title": "Recreating a dataviz with {ggplot2}",
    "section": "Environment",
    "text": "Environment\n\n\n\nSession info\n\n\n\nLast rendered: 2023-07-06 19:27:43 BST\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/London\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.2 tidyr_1.3.0  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.3       cli_3.6.1         knitr_1.43.1      rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.7   \n [9] labeling_0.4.2    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5  \n[13] scales_1.2.1      fansi_1.0.4       rmarkdown_2.23    grid_4.3.1       \n[17] munsell_0.5.0     evaluate_0.21     tibble_3.2.1      fastmap_1.1.1    \n[21] yaml_2.3.7        lifecycle_1.0.3   compiler_4.3.1    dplyr_1.1.2      \n[25] htmlwidgets_1.6.2 pkgconfig_2.0.3   rstudioapi_0.14   farver_2.1.1     \n[29] digest_0.6.31     R6_2.5.1          tidyselect_1.2.0  utf8_1.2.3       \n[33] pillar_1.9.0      magrittr_2.0.3    gtable_0.3.3      tools_4.3.1      \n[37] withr_2.5.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rostrum.blog (test)",
    "section": "",
    "text": "Save high scores for your R game\n\n\n\n2023-07-15\n\n\n\n\n\n\n\n\n\n\n\nConvert a Word table to Markdown\n\n\n\n2023-06-21\n\n\n\n\n\n\n\n\n\n\n\nPanic! In The Toolshed\n\n\n\n2023-06-13\n\n\n\n\n\n\n\n\n\n\n\nExtract run data from Apple Health (redux)\n\n\n\n2023-06-11\n\n\n\n\n\n\n\n\n\n\n\nRectangularise Word tables extracted by {officer}\n\n\n\n2023-06-07\n\n\n\n\n\n\n\n\n\n\n\nRecreating a dataviz with {ggplot2}\n\n\n\n2023-05-10\n\n\n\n\n\n\n\n\n\n\n\nAutomate {blogdown} to Quarto\n\n\n\n2023-05-07\n\n\n\n\n\n\n\n\n\n\n\nMatt Dray Teaches (Data) Typing\n\n\n\n2023-04-23\n\n\n\n\n\n\n\n\n\n\n\nR is a game engine, fight me\n\n\n\n2023-04-02\n\n\n\n\n\n\n\n\n\n\n\nPlaygrounds with WebR and Quarto\n\n\n\n2023-03-16\n\n\n\n\n\n\n\n\n\n\n\nFun and learning. In a dungeon!\n\n\n\n2023-03-15\n\n\n\n\n\n\n\n\n\n\n\nI canâ€™t be parsed, mate\n\n\n\n2023-03-03\n\n\n\n\n\n\n\n\n\n\n\nRepaying Tom Nook with {S7}\n\n\n\n2023-02-26\n\n\n\n\n\n\n\n\n\n\n\nPorting a Twitter bot to Mastodon\n\n\n\n2023-02-09\n\n\n\n\n\n\n\n\n\n\n\nWrapping PokÃ©API with {trapinch}\n\n\n\n2023-02-02\n\n\n\n\n\n\n\n\n\n\n\nStiliyan Petrov: Jesus?\n\n\n\n2023-01-08\n\n\n\n\n\n\n\n\n\n\n\n.-././â€“/â€”/.-./â€¦/.\n\n\n\n2023-01-06\n\n\n\n\n\n\n\n\n\n\n\nDing! Sound effects in {r.oguelike}\n\n\n\n2023-01-04\n\n\n\n\n\n\n\n\n\n\n\nAnimate sprites in R with {pixeltrix}\n\n\n\n2022-12-11\n\n\n\n\n\n\n\n\n\n\n\nTamagotchi in R?\n\n\n\n2022-11-13\n\n\n\n\n\n\n\n\n\n\n\nInteractive pixel art in R with {pixeltrix}\n\n\n\n2022-09-24\n\n\n\n\n\n\n\n\n\n\n\nYou are a halfling, trying to harvest {potato}\n\n\n\n2022-09-13\n\n\n\n\n\n\n\n\n\n\n\nEARL 22: {a11ytables} for better spreadsheets\n\n\n\n2022-09-07\n\n\n\n\n\n\n\n\n\n\n\nTwo RStudio Addins: {quartostamp} and {snorkel}\n\n\n\n2022-08-11\n\n\n\n\n\n\n\n\n\n\n\nFixing londonmapbot for {rtweet} v1.0\n\n\n\n2022-07-22\n\n\n\n\n\n\n\n\n\n\n\nStop opening the same RStudio Project twice\n\n\n\n2022-07-08\n\n\n\n\n\n\n\n\n\n\n\nAn isometric dungeon chase in R\n\n\n\n2022-06-28\n\n\n\n\n\n\n\n\n\n\n\nAutomated pathfinding in {r.oguelike}\n\n\n\n2022-06-10\n\n\n\n\n\n\n\n\n\n\n\nDown with Râ€™s assignment flamewars!\n\n\n\n2022-06-07\n\n\n\n\n\n\n\n\n\n\n\nTry R v4.2 in your browser\n\n\n\n2022-06-01\n\n\n\n\n\n\n\n\n\n\n\nSimple procedural dungeons in R\n\n\n\n2022-05-01\n\n\n\n\n\n\n\n\n\n\n\nTurn the {tide} on Râ€™s secret spreadsheet editor\n\n\n\n2022-04-27\n\n\n\n\n\n\n\n\n\n\n\nBuilding a {r.oguelike} in R\n\n\n\n2022-04-25\n\n\n\n\n\n\n\n\n\n\n\nInteractive maps of Hastings Half Marathon\n\n\n\n2022-03-31\n\n\n\n\n\n\n\n\n\n\n\nReproducible {distill} posts with {renv} profiles\n\n\n\n2022-03-15\n\n\n\n\n\n\n\n\n\n\n\nAdd in an RStudio Addin to add in backticks\n\n\n\n2022-02-19\n\n\n\n\n\n\n\n\n\n\n\nlondonmapbot at LondonR\n\n\n\n2022-02-12\n\n\n\n\n\n\n\n\n\n\n\nIntroduce me to your {soccercolleagues}\n\n\n\n2022-02-04\n\n\n\n\n\n\n\n\n\n\n\nImpress with {keypress} minigames\n\n\n\n2022-01-19\n\n\n\n\n\n\n\n\n\n\n\nWordle, twirdle and eldrow\n\n\n\n2022-01-14\n\n\n\n\n\n\n\n\n\n\n\nThe most popular Animal Crossing villagers\n\n\n\n2022-01-07\n\n\n\n\n\n\n\n\n\n\n\nYour workout route (in three dimensions!)\n\n\n\n2021-12-30\n\n\n\n\n\n\n\n\n\n\n\nR has obscenely long function names\n\n\n\n2021-11-27\n\n\n\n\n\n\n\n\n\n\n\n{itdepends} on {lubridate}\n\n\n\n2021-11-27\n\n\n\n\n\n\n\n\n\n\n\nDeep fried memes in R\n\n\n\n2021-11-07\n\n\n\n\n\n\n\n\n\n\n\nGet coordinates from fictitious maps\n\n\n\n2021-11-04\n\n\n\n\n\n\n\n\n\n\n\nReveal a hidden gorilla with {magick}\n\n\n\n2021-10-05\n\n\n\n\n\n\n\n\n\n\n\n{ActionSquirrel}: a game in the R console\n\n\n\n2021-10-03\n\n\n\n\n\n\n\n\n\n\n\nWot3LdnEmojis\n\n\n\n2021-09-14\n\n\n\n\n\n\n\n\n\n\n\nExtract punctuation from books with R\n\n\n\n2021-09-12\n\n\n\n\n\n\n\n\n\n\n\nAuto-label closing parentheses in RStudio\n\n\n\n2021-08-31\n\n\n\n\n\n\n\n\n\n\n\nAdding a Shiny app to {dehex}\n\n\n\n2021-08-27\n\n\n\n\n\n\n\n\n\n\n\nExploring R package startup messages\n\n\n\n2021-08-27\n\n\n\n\n\n\n\n\n\n\n\nRead a hex colour code with {dehex}\n\n\n\n2021-08-10\n\n\n\n\n\n\n\n\n\n\n\nOG emoji SVGs\n\n\n\n2021-07-31\n\n\n\n\n\n\n\n\n\n\n\nMake an art gallery with {bs4cards}\n\n\n\n2021-07-25\n\n\n\n\n\n\n\n\n\n\n\nWhat colour is London?\n\n\n\n2021-07-23\n\n\n\n\n\n\n\n\n\n\n\nEXPOSED: a Kiwi conspiracy built into R!\n\n\n\n2021-07-15\n\n\n\n\n\n\n\n\n\n\n\nDecay is inevitable, accept {linkrot}?\n\n\n\n2021-07-10\n\n\n\n\n\n\n\n\n\n\n\nRecreationThursday: a LeWitt Shiny app\n\n\n\n2021-07-05\n\n\n\n\n\n\n\n\n\n\n\nVery simple pixel art in R\n\n\n\n2021-06-28\n\n\n\n\n\n\n\n\n\n\n\nGenerate an {emojiscape}\n\n\n\n2021-06-26\n\n\n\n\n\n\n\n\n\n\n\nRecreationThursday: Hlito with base R\n\n\n\n2021-06-21\n\n\n\n\n\n\n\n\n\n\n\nRecreating Spearâ€™s #CottonViz in base R\n\n\n\n2021-06-08\n\n\n\n\n\n\n\n\n\n\n\nMission Across the Isle of Wight\n\n\n\n2021-05-22\n\n\n\n\n\n\n\n\n\n\n\nEncrypt and host a knitted R Markdown file\n\n\n\n2021-05-07\n\n\n\n\n\n\n\n\n\n\n\nMake the simplest R package with {pico}\n\n\n\n2021-04-18\n\n\n\n\n\n\n\n\n\n\n\nUp-to-date blog stats in your README\n\n\n\n2021-04-14\n\n\n\n\n\n\n\n\n\n\n\nConvert R to cron to English with {dialga}\n\n\n\n2021-04-10\n\n\n\n\n\n\n\n\n\n\n\nApple Health and Nike Run Club with {xml2}\n\n\n\n2021-03-23\n\n\n\n\n\n\n\n\n\n\n\nMake a {shiny} app README badge\n\n\n\n2021-03-23\n\n\n\n\n\n\n\n\n\n\n\nA tiny {shiny} flag challenge\n\n\n\n2021-03-02\n\n\n\n\n\n\n\n\n\n\n\nTypo-shaming my Git commits\n\n\n\n2021-02-27\n\n\n\n\n\n\n\n\n\n\n\nGithubSkyline but hear me out\n\n\n\n2021-02-21\n\n\n\n\n\n\n\n\n\n\n\nWhat does a year of COVID-19 sound like?\n\n\n\n2021-02-02\n\n\n\n\n\n\n\n\n\n\n\nRâ€™s names and values as anchovy pizza\n\n\n\n2021-01-28\n\n\n\n\n\n\n\n\n\n\n\nPlay PokÃ©monâ€™s Safari Zone in R\n\n\n\n2021-01-04\n\n\n\n\n\n\n\n\n\n\n\nAccessible colour contrasts with {coloratio}\n\n\n\n2020-12-30\n\n\n\n\n\n\n\n\n\n\n\nMapping londonmapbot tweets with {leaflet}\n\n\n\n2020-12-20\n\n\n\n\n\n\n\n\n\n\n\nSending {postcards} with Netlify and Namecheap\n\n\n\n2020-12-08\n\n\n\n\n\n\n\n\n\n\n\nThe US electoral college with {tilegramsR}\n\n\n\n2020-11-21\n\n\n\n\n\n\n\n\n\n\n\nTranslate R to English with {r2eng}\n\n\n\n2020-11-14\n\n\n\n\n\n\n\n\n\n\n\nHit your reproducibility {targets}\n\n\n\n2020-09-27\n\n\n\n\n\n\n\n\n\n\n\nA Twitter bot with {rtweet} and GitHub Actions\n\n\n\n2020-09-21\n\n\n\n\n\n\n\n\n\n\n\nFriendship ended with Google Analytics\n\n\n\n2020-09-16\n\n\n\n\n\n\n\n\n\n\n\nRate my RStudio setup\n\n\n\n2020-09-15\n\n\n\n\n\n\n\n\n\n\n\n{units} of uncleaned herring\n\n\n\n2020-09-12\n\n\n\n\n\n\n\n\n\n\n\nGitHub Actions for R packages\n\n\n\n2020-08-09\n\n\n\n\n\n\n\n\n\n\n\nSet up R on Raspberry Pi for blogging\n\n\n\n2020-07-11\n\n\n\n\n\n\n\n\n\n\n\nTake a {ghdump} to download GitHub repos\n\n\n\n2020-06-14\n\n\n\n\n\n\n\n\n\n\n\nAnimal Crossing Tinder with {shinysense}\n\n\n\n2020-06-06\n\n\n\n\n\n\n\n\nNo matching items"
  }
]